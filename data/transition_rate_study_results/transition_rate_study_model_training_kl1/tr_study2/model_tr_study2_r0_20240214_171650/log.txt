Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r0', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 139973167

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/20] avg loss: 7.23282313585343		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.07562884393128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.154225989892355 | validation: 4.794741729458508]
	TIME [epoch: 49.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/20] avg loss: 3.5683997622085166		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.9617692161736278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2650844891910724 | validation: 2.230248535915811]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/20] avg loss: 2.8843397279286207		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.5031156623054143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6937276951170177 | validation: 3.4253568604252655]
	TIME [epoch: 8.94 sec]
EPOCH 4/500:
	Training over batches...
		[batch 10/20] avg loss: 2.444374029351604		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.264429749202262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.354401889276933 | validation: 2.0805512501607826]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/20] avg loss: 1.9476882592652458		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.9097617305444596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9287249949048522 | validation: 2.3186418130206956]
	TIME [epoch: 8.9 sec]
EPOCH 6/500:
	Training over batches...
		[batch 10/20] avg loss: 1.6913930705057492		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.49200815762568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5917006140657146 | validation: 1.754152809699498]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4581319264865242		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3675886668081139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.412860296647319 | validation: 2.9806013960683715]
	TIME [epoch: 8.93 sec]
EPOCH 8/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5374895106948776		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.148481153616555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3429853321557164 | validation: 1.5144488733116142]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1422904660967323		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.142392536598782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.142341501347757 | validation: 0.8873067284146928]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1983051963391764		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9569113367125887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0776082665258826 | validation: 1.6719940730734437]
	TIME [epoch: 8.9 sec]
EPOCH 11/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0743664039646543		[learning rate: 0.0099789]
		[batch 20/20] avg loss: 0.8627480562033323		[learning rate: 0.0099555]
	Learning Rate: 0.00995546
	LOSS [training: 0.9685572300839935 | validation: 0.7815341081352215]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7838890558972297		[learning rate: 0.0099321]
		[batch 20/20] avg loss: 0.84779614582788		[learning rate: 0.0099088]
	Learning Rate: 0.00990879
	LOSS [training: 0.8158426008625549 | validation: 0.7547943334327581]
	TIME [epoch: 8.94 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7277911730363317		[learning rate: 0.0098855]
		[batch 20/20] avg loss: 0.841737260352262		[learning rate: 0.0098623]
	Learning Rate: 0.00986233
	LOSS [training: 0.7847642166942969 | validation: 0.42681900854692784]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5958899715605673		[learning rate: 0.0098392]
		[batch 20/20] avg loss: 0.5957584963471813		[learning rate: 0.0098161]
	Learning Rate: 0.0098161
	LOSS [training: 0.5958242339538743 | validation: 0.3465820938949087]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5395788911229109		[learning rate: 0.0097931]
		[batch 20/20] avg loss: 0.5122560330961679		[learning rate: 0.0097701]
	Learning Rate: 0.00977008
	LOSS [training: 0.5259174621095394 | validation: 0.5142962752048165]
	TIME [epoch: 8.89 sec]
EPOCH 16/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49209597509445385		[learning rate: 0.0097471]
		[batch 20/20] avg loss: 0.48424412773092185		[learning rate: 0.0097243]
	Learning Rate: 0.00972427
	LOSS [training: 0.48817005141268793 | validation: 0.36160975679361823]
	TIME [epoch: 8.91 sec]
EPOCH 17/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5244254714540066		[learning rate: 0.0097015]
		[batch 20/20] avg loss: 0.7640552654279043		[learning rate: 0.0096787]
	Learning Rate: 0.00967868
	LOSS [training: 0.6442403684409553 | validation: 0.5115429297045868]
	TIME [epoch: 8.93 sec]
EPOCH 18/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4630586409799308		[learning rate: 0.009656]
		[batch 20/20] avg loss: 0.46438363943093747		[learning rate: 0.0096333]
	Learning Rate: 0.00963331
	LOSS [training: 0.46372114020543426 | validation: 0.29317010449546155]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5344376673248482		[learning rate: 0.0096107]
		[batch 20/20] avg loss: 0.5081377619203012		[learning rate: 0.0095881]
	Learning Rate: 0.00958815
	LOSS [training: 0.5212877146225748 | validation: 0.3228736084564127]
	TIME [epoch: 8.91 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/20] avg loss: 0.39745574243254767		[learning rate: 0.0095656]
		[batch 20/20] avg loss: 0.48263713640733596		[learning rate: 0.0095432]
	Learning Rate: 0.0095432
	LOSS [training: 0.44004643941994176 | validation: 0.406355542797772]
	TIME [epoch: 8.9 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4960020065086688		[learning rate: 0.0095208]
		[batch 20/20] avg loss: 0.4041777684958866		[learning rate: 0.0094985]
	Learning Rate: 0.00949846
	LOSS [training: 0.45008988750227774 | validation: 0.5369564321872173]
	TIME [epoch: 8.93 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44545925172606465		[learning rate: 0.0094762]
		[batch 20/20] avg loss: 0.49630343223195367		[learning rate: 0.0094539]
	Learning Rate: 0.00945393
	LOSS [training: 0.47088134197900927 | validation: 0.6046010883467896]
	TIME [epoch: 8.91 sec]
EPOCH 23/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4845912147611243		[learning rate: 0.0094317]
		[batch 20/20] avg loss: 0.4960569870382792		[learning rate: 0.0094096]
	Learning Rate: 0.00940961
	LOSS [training: 0.4903241008997018 | validation: 0.4598479783758711]
	TIME [epoch: 8.91 sec]
EPOCH 24/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5440625459514086		[learning rate: 0.0093875]
		[batch 20/20] avg loss: 0.5059977706592803		[learning rate: 0.0093655]
	Learning Rate: 0.00936549
	LOSS [training: 0.5250301583053445 | validation: 0.6660155788474649]
	TIME [epoch: 8.9 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4800625590969432		[learning rate: 0.0093435]
		[batch 20/20] avg loss: 0.4323115039274281		[learning rate: 0.0093216]
	Learning Rate: 0.00932159
	LOSS [training: 0.45618703151218565 | validation: 0.8275278028310068]
	TIME [epoch: 8.91 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4831015506432787		[learning rate: 0.0092997]
		[batch 20/20] avg loss: 0.4269327387114772		[learning rate: 0.0092779]
	Learning Rate: 0.00927788
	LOSS [training: 0.45501714467737797 | validation: 0.3268335138562961]
	TIME [epoch: 8.93 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5400293302271286		[learning rate: 0.0092561]
		[batch 20/20] avg loss: 0.42125592339417545		[learning rate: 0.0092344]
	Learning Rate: 0.00923439
	LOSS [training: 0.480642626810652 | validation: 0.4711681695409963]
	TIME [epoch: 8.9 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4609112339652319		[learning rate: 0.0092127]
		[batch 20/20] avg loss: 0.4295615592120748		[learning rate: 0.0091911]
	Learning Rate: 0.0091911
	LOSS [training: 0.4452363965886533 | validation: 0.5824468569020804]
	TIME [epoch: 8.91 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4075172752498061		[learning rate: 0.0091695]
		[batch 20/20] avg loss: 0.4017627649712323		[learning rate: 0.009148]
	Learning Rate: 0.00914801
	LOSS [training: 0.404640020110519 | validation: 0.3465134287927446]
	TIME [epoch: 8.9 sec]
EPOCH 30/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4698639199713897		[learning rate: 0.0091265]
		[batch 20/20] avg loss: 0.40930328692454065		[learning rate: 0.0091051]
	Learning Rate: 0.00910512
	LOSS [training: 0.4395836034479652 | validation: 0.342914574954264]
	TIME [epoch: 8.91 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5455902301027409		[learning rate: 0.0090838]
		[batch 20/20] avg loss: 0.4341495855295297		[learning rate: 0.0090624]
	Learning Rate: 0.00906243
	LOSS [training: 0.48986990781613526 | validation: 0.25652822914081896]
	TIME [epoch: 8.94 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4035531308562989		[learning rate: 0.0090412]
		[batch 20/20] avg loss: 0.482945736758211		[learning rate: 0.0090199]
	Learning Rate: 0.00901995
	LOSS [training: 0.44324943380725496 | validation: 0.28072990937972964]
	TIME [epoch: 8.9 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44508584869908596		[learning rate: 0.0089988]
		[batch 20/20] avg loss: 0.36934635434882424		[learning rate: 0.0089777]
	Learning Rate: 0.00897766
	LOSS [training: 0.40721610152395515 | validation: 0.28387060389789165]
	TIME [epoch: 8.91 sec]
EPOCH 34/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40386888922349085		[learning rate: 0.0089566]
		[batch 20/20] avg loss: 0.5530651567879741		[learning rate: 0.0089356]
	Learning Rate: 0.00893557
	LOSS [training: 0.47846702300573246 | validation: 0.44083062627665537]
	TIME [epoch: 8.9 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/20] avg loss: 0.37322625087591343		[learning rate: 0.0089146]
		[batch 20/20] avg loss: 0.37973794970387226		[learning rate: 0.0088937]
	Learning Rate: 0.00889368
	LOSS [training: 0.3764821002898929 | validation: 0.48077661431686586]
	TIME [epoch: 8.92 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49513389761259247		[learning rate: 0.0088728]
		[batch 20/20] avg loss: 0.35901738065831645		[learning rate: 0.008852]
	Learning Rate: 0.00885199
	LOSS [training: 0.4270756391354545 | validation: 0.5093547892712801]
	TIME [epoch: 8.9 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4149409158948517		[learning rate: 0.0088312]
		[batch 20/20] avg loss: 0.4136198713638664		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.4142803936293591 | validation: 0.342901145792987]
	TIME [epoch: 8.89 sec]
EPOCH 38/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34053275551572654		[learning rate: 0.0087898]
		[batch 20/20] avg loss: 0.4683570379688661		[learning rate: 0.0087692]
	Learning Rate: 0.00876918
	LOSS [training: 0.40444489674229633 | validation: 0.331892759573268]
	TIME [epoch: 8.9 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4087905654859417		[learning rate: 0.0087486]
		[batch 20/20] avg loss: 0.3968004249445138		[learning rate: 0.0087281]
	Learning Rate: 0.00872807
	LOSS [training: 0.40279549521522773 | validation: 0.6459434374316209]
	TIME [epoch: 8.91 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/20] avg loss: 0.47217239184182985		[learning rate: 0.0087076]
		[batch 20/20] avg loss: 0.40536880051304774		[learning rate: 0.0086872]
	Learning Rate: 0.00868715
	LOSS [training: 0.43877059617743874 | validation: 0.34044570243880523]
	TIME [epoch: 8.93 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36227014467468244		[learning rate: 0.0086668]
		[batch 20/20] avg loss: 0.4025926051631313		[learning rate: 0.0086464]
	Learning Rate: 0.00864643
	LOSS [training: 0.38243137491890683 | validation: 0.4767762217940175]
	TIME [epoch: 8.9 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3648043825346402		[learning rate: 0.0086261]
		[batch 20/20] avg loss: 0.34320235171356395		[learning rate: 0.0086059]
	Learning Rate: 0.00860589
	LOSS [training: 0.3540033671241021 | validation: 0.37255414156001254]
	TIME [epoch: 8.99 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3864068059645699		[learning rate: 0.0085857]
		[batch 20/20] avg loss: 0.3714990206945674		[learning rate: 0.0085655]
	Learning Rate: 0.00856555
	LOSS [training: 0.37895291332956865 | validation: 0.5471303065115994]
	TIME [epoch: 8.9 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3978822940226483		[learning rate: 0.0085454]
		[batch 20/20] avg loss: 0.4197157505240626		[learning rate: 0.0085254]
	Learning Rate: 0.00852539
	LOSS [training: 0.40879902227335546 | validation: 0.3885117399560238]
	TIME [epoch: 8.9 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3657599084910726		[learning rate: 0.0085054]
		[batch 20/20] avg loss: 0.34521456950172064		[learning rate: 0.0084854]
	Learning Rate: 0.00848542
	LOSS [training: 0.3554872389963966 | validation: 0.38563690394634087]
	TIME [epoch: 8.93 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34332390945931773		[learning rate: 0.0084655]
		[batch 20/20] avg loss: 0.3906029000883766		[learning rate: 0.0084456]
	Learning Rate: 0.00844564
	LOSS [training: 0.36696340477384715 | validation: 0.3457947004330467]
	TIME [epoch: 8.9 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33022908941614204		[learning rate: 0.0084258]
		[batch 20/20] avg loss: 0.3851663656288007		[learning rate: 0.008406]
	Learning Rate: 0.00840605
	LOSS [training: 0.3576977275224714 | validation: 0.27944006162080154]
	TIME [epoch: 8.89 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5044263877897978		[learning rate: 0.0083863]
		[batch 20/20] avg loss: 0.33274304410314987		[learning rate: 0.0083666]
	Learning Rate: 0.00836664
	LOSS [training: 0.41858471594647384 | validation: 0.4040207313633483]
	TIME [epoch: 8.9 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32066249753172144		[learning rate: 0.008347]
		[batch 20/20] avg loss: 0.3567166288895624		[learning rate: 0.0083274]
	Learning Rate: 0.00832742
	LOSS [training: 0.338689563210642 | validation: 0.379391501012637]
	TIME [epoch: 8.93 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3358770289017137		[learning rate: 0.0083079]
		[batch 20/20] avg loss: 0.4404332129075955		[learning rate: 0.0082884]
	Learning Rate: 0.00828838
	LOSS [training: 0.38815512090465465 | validation: 0.3542503813971567]
	TIME [epoch: 8.9 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40831274623253205		[learning rate: 0.0082689]
		[batch 20/20] avg loss: 0.36463258808900456		[learning rate: 0.0082495]
	Learning Rate: 0.00824952
	LOSS [training: 0.38647266716076834 | validation: 0.3109304044908257]
	TIME [epoch: 8.89 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36401258515781143		[learning rate: 0.0082302]
		[batch 20/20] avg loss: 0.31610004665322744		[learning rate: 0.0082108]
	Learning Rate: 0.00821084
	LOSS [training: 0.3400563159055194 | validation: 0.3204476385576494]
	TIME [epoch: 8.9 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3603187517834282		[learning rate: 0.0081916]
		[batch 20/20] avg loss: 0.35110615284303726		[learning rate: 0.0081723]
	Learning Rate: 0.00817235
	LOSS [training: 0.3557124523132327 | validation: 0.2725246755530768]
	TIME [epoch: 8.89 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3443706284471828		[learning rate: 0.0081532]
		[batch 20/20] avg loss: 0.3870328133545672		[learning rate: 0.008134]
	Learning Rate: 0.00813404
	LOSS [training: 0.36570172090087494 | validation: 0.46615355442189826]
	TIME [epoch: 8.92 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3303072946444532		[learning rate: 0.0081149]
		[batch 20/20] avg loss: 0.3981911988647331		[learning rate: 0.0080959]
	Learning Rate: 0.0080959
	LOSS [training: 0.36424924675459325 | validation: 0.34302755903458837]
	TIME [epoch: 8.91 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/20] avg loss: 0.317392425938249		[learning rate: 0.0080769]
		[batch 20/20] avg loss: 0.31781465466517117		[learning rate: 0.0080579]
	Learning Rate: 0.00805795
	LOSS [training: 0.3176035403017101 | validation: 0.4579877194634989]
	TIME [epoch: 8.9 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33109872666265117		[learning rate: 0.008039]
		[batch 20/20] avg loss: 0.3489467625175796		[learning rate: 0.0080202]
	Learning Rate: 0.00802017
	LOSS [training: 0.34002274459011533 | validation: 0.4356152336212318]
	TIME [epoch: 8.9 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3073455760328783		[learning rate: 0.0080013]
		[batch 20/20] avg loss: 0.3110893123174738		[learning rate: 0.0079826]
	Learning Rate: 0.00798257
	LOSS [training: 0.30921744417517605 | validation: 0.3551740633295778]
	TIME [epoch: 8.91 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4100407745406189		[learning rate: 0.0079638]
		[batch 20/20] avg loss: 0.33168443398392816		[learning rate: 0.0079451]
	Learning Rate: 0.00794515
	LOSS [training: 0.3708626042622735 | validation: 0.38122462909385013]
	TIME [epoch: 8.93 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3222451576886815		[learning rate: 0.0079265]
		[batch 20/20] avg loss: 0.31752154365005797		[learning rate: 0.0079079]
	Learning Rate: 0.0079079
	LOSS [training: 0.3198833506693697 | validation: 0.3070575363286777]
	TIME [epoch: 8.91 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3145256717297053		[learning rate: 0.0078893]
		[batch 20/20] avg loss: 0.33215642311264865		[learning rate: 0.0078708]
	Learning Rate: 0.00787083
	LOSS [training: 0.323341047421177 | validation: 0.35825869803333776]
	TIME [epoch: 8.9 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3128241797635936		[learning rate: 0.0078524]
		[batch 20/20] avg loss: 0.3146520424702072		[learning rate: 0.0078339]
	Learning Rate: 0.00783393
	LOSS [training: 0.3137381111169004 | validation: 0.315924920831796]
	TIME [epoch: 8.9 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3578646043497723		[learning rate: 0.0078155]
		[batch 20/20] avg loss: 0.3587703528361024		[learning rate: 0.0077972]
	Learning Rate: 0.0077972
	LOSS [training: 0.35831747859293733 | validation: 0.32893244989932846]
	TIME [epoch: 8.92 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4084431002447585		[learning rate: 0.0077789]
		[batch 20/20] avg loss: 0.2942177896365682		[learning rate: 0.0077606]
	Learning Rate: 0.00776065
	LOSS [training: 0.3513304449406633 | validation: 0.4531951029865663]
	TIME [epoch: 8.91 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3212988862372291		[learning rate: 0.0077424]
		[batch 20/20] avg loss: 0.326239881576272		[learning rate: 0.0077243]
	Learning Rate: 0.00772426
	LOSS [training: 0.32376938390675053 | validation: 0.21626765017514293]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29469402570808895		[learning rate: 0.0077061]
		[batch 20/20] avg loss: 0.29624492599338376		[learning rate: 0.0076881]
	Learning Rate: 0.00768805
	LOSS [training: 0.29546947585073635 | validation: 0.2241223940041459]
	TIME [epoch: 8.91 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31570412631723704		[learning rate: 0.00767]
		[batch 20/20] avg loss: 0.40034663712406526		[learning rate: 0.007652]
	Learning Rate: 0.00765201
	LOSS [training: 0.35802538172065124 | validation: 0.20416308829327875]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_67.pth
	Model improved!!!
EPOCH 68/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2568793881878245		[learning rate: 0.0076341]
		[batch 20/20] avg loss: 0.2713465246512449		[learning rate: 0.0076161]
	Learning Rate: 0.00761614
	LOSS [training: 0.26411295641953475 | validation: 0.26383216807640464]
	TIME [epoch: 8.95 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23356826665499608		[learning rate: 0.0075983]
		[batch 20/20] avg loss: 0.2537374552927648		[learning rate: 0.0075804]
	Learning Rate: 0.00758043
	LOSS [training: 0.24365286097388053 | validation: 0.36535109921789327]
	TIME [epoch: 8.91 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3123773442965832		[learning rate: 0.0075626]
		[batch 20/20] avg loss: 0.3331141571232036		[learning rate: 0.0075449]
	Learning Rate: 0.00754489
	LOSS [training: 0.3227457507098934 | validation: 0.4043227328004305]
	TIME [epoch: 8.92 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4213028963473122		[learning rate: 0.0075272]
		[batch 20/20] avg loss: 0.23617198292361657		[learning rate: 0.0075095]
	Learning Rate: 0.00750952
	LOSS [training: 0.3287374396354644 | validation: 0.21156881566714109]
	TIME [epoch: 8.91 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29630784127300136		[learning rate: 0.0074919]
		[batch 20/20] avg loss: 0.24093575926157432		[learning rate: 0.0074743]
	Learning Rate: 0.00747431
	LOSS [training: 0.2686218002672879 | validation: 0.43002934491702677]
	TIME [epoch: 8.92 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2732215101751826		[learning rate: 0.0074568]
		[batch 20/20] avg loss: 0.2513924356609386		[learning rate: 0.0074393]
	Learning Rate: 0.00743927
	LOSS [training: 0.2623069729180606 | validation: 0.2827716068412981]
	TIME [epoch: 8.93 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22541377308889352		[learning rate: 0.0074218]
		[batch 20/20] avg loss: 0.29926541899101716		[learning rate: 0.0074044]
	Learning Rate: 0.0074044
	LOSS [training: 0.2623395960399554 | validation: 0.22857570011151326]
	TIME [epoch: 8.91 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2406903736912626		[learning rate: 0.007387]
		[batch 20/20] avg loss: 0.2396152291186527		[learning rate: 0.0073697]
	Learning Rate: 0.00736969
	LOSS [training: 0.24015280140495765 | validation: 0.4696052712164517]
	TIME [epoch: 8.91 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5355728600904603		[learning rate: 0.0073524]
		[batch 20/20] avg loss: 0.3031559526158148		[learning rate: 0.0073351]
	Learning Rate: 0.00733514
	LOSS [training: 0.4193644063531375 | validation: 0.22344079913560017]
	TIME [epoch: 8.93 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2171873370893865		[learning rate: 0.0073179]
		[batch 20/20] avg loss: 0.21277638161805737		[learning rate: 0.0073007]
	Learning Rate: 0.00730075
	LOSS [training: 0.21498185935372197 | validation: 0.19894765719076685]
	TIME [epoch: 8.94 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_77.pth
	Model improved!!!
EPOCH 78/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20198147646957967		[learning rate: 0.0072836]
		[batch 20/20] avg loss: 0.23091069740448247		[learning rate: 0.0072665]
	Learning Rate: 0.00726652
	LOSS [training: 0.21644608693703105 | validation: 0.16776747758462027]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_78.pth
	Model improved!!!
EPOCH 79/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2628216925822727		[learning rate: 0.0072495]
		[batch 20/20] avg loss: 0.2656666873069028		[learning rate: 0.0072325]
	Learning Rate: 0.00723246
	LOSS [training: 0.26424418994458776 | validation: 0.3220193626066873]
	TIME [epoch: 8.91 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/20] avg loss: 0.182047272662009		[learning rate: 0.0072155]
		[batch 20/20] avg loss: 0.1823548545125065		[learning rate: 0.0071985]
	Learning Rate: 0.00719855
	LOSS [training: 0.18220106358725777 | validation: 0.16079563586513201]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_80.pth
	Model improved!!!
EPOCH 81/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2444270200092582		[learning rate: 0.0071817]
		[batch 20/20] avg loss: 0.2969489354028757		[learning rate: 0.0071648]
	Learning Rate: 0.0071648
	LOSS [training: 0.27068797770606695 | validation: 0.313558501520475]
	TIME [epoch: 8.9 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25635081637754537		[learning rate: 0.007148]
		[batch 20/20] avg loss: 0.21281693499951954		[learning rate: 0.0071312]
	Learning Rate: 0.00713121
	LOSS [training: 0.23458387568853242 | validation: 0.19305099898673628]
	TIME [epoch: 8.92 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20938240082368917		[learning rate: 0.0071145]
		[batch 20/20] avg loss: 0.24788826200817052		[learning rate: 0.0070978]
	Learning Rate: 0.00709778
	LOSS [training: 0.22863533141592987 | validation: 0.11346210859843407]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2814396918406017		[learning rate: 0.0070811]
		[batch 20/20] avg loss: 0.20102253657853858		[learning rate: 0.0070645]
	Learning Rate: 0.0070645
	LOSS [training: 0.24123111420957014 | validation: 0.22261576007502243]
	TIME [epoch: 8.9 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19604329064764803		[learning rate: 0.0070479]
		[batch 20/20] avg loss: 0.16685011122653345		[learning rate: 0.0070314]
	Learning Rate: 0.00703138
	LOSS [training: 0.18144670093709078 | validation: 0.14274500087956826]
	TIME [epoch: 8.91 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21030740448427312		[learning rate: 0.0070149]
		[batch 20/20] avg loss: 0.176806261035074		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.19355683275967356 | validation: 0.2134837757934104]
	TIME [epoch: 8.91 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18791880087664792		[learning rate: 0.006982]
		[batch 20/20] avg loss: 0.2654163085330435		[learning rate: 0.0069656]
	Learning Rate: 0.00696561
	LOSS [training: 0.2266675547048457 | validation: 0.7526191090059663]
	TIME [epoch: 8.92 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32345209681906584		[learning rate: 0.0069493]
		[batch 20/20] avg loss: 0.17276825523556924		[learning rate: 0.006933]
	Learning Rate: 0.00693295
	LOSS [training: 0.24811017602731752 | validation: 0.16062296455128894]
	TIME [epoch: 8.89 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18254910389916032		[learning rate: 0.0069167]
		[batch 20/20] avg loss: 0.224987982977556		[learning rate: 0.0069005]
	Learning Rate: 0.00690045
	LOSS [training: 0.20376854343835818 | validation: 0.27233800152707166]
	TIME [epoch: 8.89 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24844923642961825		[learning rate: 0.0068843]
		[batch 20/20] avg loss: 0.19638691218168475		[learning rate: 0.0068681]
	Learning Rate: 0.0068681
	LOSS [training: 0.22241807430565147 | validation: 0.15983345712806318]
	TIME [epoch: 8.89 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14026935320243863		[learning rate: 0.006852]
		[batch 20/20] avg loss: 0.16899784588530117		[learning rate: 0.0068359]
	Learning Rate: 0.0068359
	LOSS [training: 0.15463359954386988 | validation: 0.29506285028954315]
	TIME [epoch: 8.92 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15446638003484667		[learning rate: 0.0068199]
		[batch 20/20] avg loss: 0.19448454977339275		[learning rate: 0.0068039]
	Learning Rate: 0.00680386
	LOSS [training: 0.17447546490411966 | validation: 0.06415339623985519]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_92.pth
	Model improved!!!
EPOCH 93/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16297882326369095		[learning rate: 0.0067879]
		[batch 20/20] avg loss: 0.19458331523550168		[learning rate: 0.006772]
	Learning Rate: 0.00677196
	LOSS [training: 0.1787810692495963 | validation: 0.16930935339115455]
	TIME [epoch: 8.9 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1856345054323457		[learning rate: 0.0067561]
		[batch 20/20] avg loss: 0.16697455974625944		[learning rate: 0.0067402]
	Learning Rate: 0.00674021
	LOSS [training: 0.17630453258930254 | validation: 0.1814239629540762]
	TIME [epoch: 8.89 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19095607168693346		[learning rate: 0.0067244]
		[batch 20/20] avg loss: 0.20452874416442834		[learning rate: 0.0067086]
	Learning Rate: 0.00670861
	LOSS [training: 0.1977424079256809 | validation: 0.15174043089722178]
	TIME [epoch: 8.89 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15219669733263025		[learning rate: 0.0066929]
		[batch 20/20] avg loss: 0.15008611508359676		[learning rate: 0.0066772]
	Learning Rate: 0.00667716
	LOSS [training: 0.1511414062081135 | validation: 0.12257187684295505]
	TIME [epoch: 8.92 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22895320857545945		[learning rate: 0.0066615]
		[batch 20/20] avg loss: 0.18397037524355336		[learning rate: 0.0066459]
	Learning Rate: 0.00664586
	LOSS [training: 0.20646179190950642 | validation: 0.2659675230352915]
	TIME [epoch: 8.9 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16590353462428456		[learning rate: 0.0066303]
		[batch 20/20] avg loss: 0.17408929349860863		[learning rate: 0.0066147]
	Learning Rate: 0.0066147
	LOSS [training: 0.16999641406144658 | validation: 0.1621400137617856]
	TIME [epoch: 8.89 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17279488212795738		[learning rate: 0.0065992]
		[batch 20/20] avg loss: 0.16784932469028618		[learning rate: 0.0065837]
	Learning Rate: 0.00658369
	LOSS [training: 0.1703221034091218 | validation: 0.1379211496169275]
	TIME [epoch: 8.9 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18312225128668508		[learning rate: 0.0065682]
		[batch 20/20] avg loss: 0.14720235942611515		[learning rate: 0.0065528]
	Learning Rate: 0.00655282
	LOSS [training: 0.16516230535640006 | validation: 0.16994862719298617]
	TIME [epoch: 8.89 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18826137171894813		[learning rate: 0.0065374]
		[batch 20/20] avg loss: 0.21371313499280364		[learning rate: 0.0065221]
	Learning Rate: 0.0065221
	LOSS [training: 0.20098725335587592 | validation: 0.12697987361300211]
	TIME [epoch: 8.92 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1453686046811209		[learning rate: 0.0065068]
		[batch 20/20] avg loss: 0.20882575752158025		[learning rate: 0.0064915]
	Learning Rate: 0.00649153
	LOSS [training: 0.1770971811013506 | validation: 0.09515169884245188]
	TIME [epoch: 8.89 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13804468652988594		[learning rate: 0.0064763]
		[batch 20/20] avg loss: 0.13461490127179268		[learning rate: 0.0064611]
	Learning Rate: 0.0064611
	LOSS [training: 0.1363297939008393 | validation: 0.17080945648064993]
	TIME [epoch: 8.89 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14114613917026497		[learning rate: 0.0064459]
		[batch 20/20] avg loss: 0.1631197647421546		[learning rate: 0.0064308]
	Learning Rate: 0.0064308
	LOSS [training: 0.15213295195620974 | validation: 0.11959267661734518]
	TIME [epoch: 8.88 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19205288664219491		[learning rate: 0.0064157]
		[batch 20/20] avg loss: 0.151523606770608		[learning rate: 0.0064007]
	Learning Rate: 0.00640066
	LOSS [training: 0.17178824670640147 | validation: 0.18047187793135616]
	TIME [epoch: 8.92 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15080617478910244		[learning rate: 0.0063856]
		[batch 20/20] avg loss: 0.10721206106179866		[learning rate: 0.0063706]
	Learning Rate: 0.00637065
	LOSS [training: 0.12900911792545053 | validation: 0.12071445926715706]
	TIME [epoch: 8.9 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15168999594632232		[learning rate: 0.0063557]
		[batch 20/20] avg loss: 0.08370848374944652		[learning rate: 0.0063408]
	Learning Rate: 0.00634078
	LOSS [training: 0.11769923984788441 | validation: 0.06395871670210082]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_107.pth
	Model improved!!!
EPOCH 108/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1443465139717251		[learning rate: 0.0063259]
		[batch 20/20] avg loss: 0.11447799517760412		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.12941225457466463 | validation: 0.157625877832464]
	TIME [epoch: 8.89 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13076720386709773		[learning rate: 0.0062962]
		[batch 20/20] avg loss: 0.16941884012134845		[learning rate: 0.0062815]
	Learning Rate: 0.00628147
	LOSS [training: 0.15009302199422309 | validation: 0.11455133039933463]
	TIME [epoch: 8.92 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13430641814864194		[learning rate: 0.0062667]
		[batch 20/20] avg loss: 0.1239858808091244		[learning rate: 0.006252]
	Learning Rate: 0.00625202
	LOSS [training: 0.12914614947888314 | validation: 0.2613053024411885]
	TIME [epoch: 8.95 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1827157662548659		[learning rate: 0.0062373]
		[batch 20/20] avg loss: 0.1477413926081813		[learning rate: 0.0062227]
	Learning Rate: 0.00622271
	LOSS [training: 0.1652285794315236 | validation: 0.19258892476921197]
	TIME [epoch: 8.92 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14930186188633476		[learning rate: 0.0062081]
		[batch 20/20] avg loss: 0.11616747084113925		[learning rate: 0.0061935]
	Learning Rate: 0.00619354
	LOSS [training: 0.13273466636373701 | validation: 0.12477582801034118]
	TIME [epoch: 8.92 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17049560206693365		[learning rate: 0.006179]
		[batch 20/20] avg loss: 0.23122823013337573		[learning rate: 0.0061645]
	Learning Rate: 0.0061645
	LOSS [training: 0.20086191610015472 | validation: 0.1744988746813564]
	TIME [epoch: 8.91 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16313945528311882		[learning rate: 0.00615]
		[batch 20/20] avg loss: 0.16097017418455767		[learning rate: 0.0061356]
	Learning Rate: 0.0061356
	LOSS [training: 0.1620548147338383 | validation: 0.08621718887240547]
	TIME [epoch: 8.9 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11393191445574571		[learning rate: 0.0061212]
		[batch 20/20] avg loss: 0.12748555277558696		[learning rate: 0.0061068]
	Learning Rate: 0.00610684
	LOSS [training: 0.12070873361566634 | validation: 0.2179651685374186]
	TIME [epoch: 8.94 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12544218214018665		[learning rate: 0.0060925]
		[batch 20/20] avg loss: 0.10724648877532919		[learning rate: 0.0060782]
	Learning Rate: 0.00607821
	LOSS [training: 0.11634433545775794 | validation: 0.11119374748573274]
	TIME [epoch: 8.91 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15883942308879945		[learning rate: 0.0060639]
		[batch 20/20] avg loss: 0.12468709414167886		[learning rate: 0.0060497]
	Learning Rate: 0.00604971
	LOSS [training: 0.14176325861523914 | validation: 0.10778871409132537]
	TIME [epoch: 8.89 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14343597026823973		[learning rate: 0.0060355]
		[batch 20/20] avg loss: 0.12282674769859743		[learning rate: 0.0060213]
	Learning Rate: 0.00602135
	LOSS [training: 0.1331313589834186 | validation: 0.10904650002952755]
	TIME [epoch: 8.89 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10591810345114298		[learning rate: 0.0060072]
		[batch 20/20] avg loss: 0.10752033626526576		[learning rate: 0.0059931]
	Learning Rate: 0.00599312
	LOSS [training: 0.10671921985820434 | validation: 0.1437895993666634]
	TIME [epoch: 8.91 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12505318407304877		[learning rate: 0.0059791]
		[batch 20/20] avg loss: 0.13891925624998105		[learning rate: 0.005965]
	Learning Rate: 0.00596502
	LOSS [training: 0.13198622016151496 | validation: 0.08333992645849675]
	TIME [epoch: 8.9 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1834231364201235		[learning rate: 0.005951]
		[batch 20/20] avg loss: 0.1628632299579491		[learning rate: 0.0059371]
	Learning Rate: 0.00593706
	LOSS [training: 0.17314318318903635 | validation: 0.05341037000753964]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_121.pth
	Model improved!!!
EPOCH 122/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09785766650028871		[learning rate: 0.0059231]
		[batch 20/20] avg loss: 0.1163976572225559		[learning rate: 0.0059092]
	Learning Rate: 0.00590923
	LOSS [training: 0.10712766186142231 | validation: 0.06477656420437303]
	TIME [epoch: 8.88 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11087330236857411		[learning rate: 0.0058954]
		[batch 20/20] avg loss: 0.1601508754687601		[learning rate: 0.0058815]
	Learning Rate: 0.00588152
	LOSS [training: 0.13551208891866712 | validation: 0.09422436203899143]
	TIME [epoch: 8.88 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10400693336645103		[learning rate: 0.0058677]
		[batch 20/20] avg loss: 0.1565435404113839		[learning rate: 0.0058539]
	Learning Rate: 0.00585395
	LOSS [training: 0.1302752368889175 | validation: 0.14318203911621366]
	TIME [epoch: 8.9 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12207754830613829		[learning rate: 0.0058402]
		[batch 20/20] avg loss: 0.12923862970613473		[learning rate: 0.0058265]
	Learning Rate: 0.00582651
	LOSS [training: 0.1256580890061365 | validation: 0.11459468027064795]
	TIME [epoch: 8.89 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1345395197703852		[learning rate: 0.0058128]
		[batch 20/20] avg loss: 0.11424419575667091		[learning rate: 0.0057992]
	Learning Rate: 0.00579919
	LOSS [training: 0.12439185776352804 | validation: 0.14117108737291992]
	TIME [epoch: 8.88 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/20] avg loss: 0.124622989074709		[learning rate: 0.0057856]
		[batch 20/20] avg loss: 0.10317024825101688		[learning rate: 0.005772]
	Learning Rate: 0.005772
	LOSS [training: 0.11389661866286296 | validation: 0.07691757750513485]
	TIME [epoch: 8.88 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13460697700644114		[learning rate: 0.0057585]
		[batch 20/20] avg loss: 0.14558003709425507		[learning rate: 0.0057449]
	Learning Rate: 0.00574494
	LOSS [training: 0.1400935070503481 | validation: 0.12898393423937043]
	TIME [epoch: 8.88 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11054196311533356		[learning rate: 0.0057315]
		[batch 20/20] avg loss: 0.08692632007276466		[learning rate: 0.005718]
	Learning Rate: 0.00571801
	LOSS [training: 0.09873414159404911 | validation: 0.11807280871471794]
	TIME [epoch: 8.91 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10874452661010539		[learning rate: 0.0057046]
		[batch 20/20] avg loss: 0.13070855453505495		[learning rate: 0.0056912]
	Learning Rate: 0.0056912
	LOSS [training: 0.11972654057258017 | validation: 0.06814578197406868]
	TIME [epoch: 8.89 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09082172144388512		[learning rate: 0.0056778]
		[batch 20/20] avg loss: 0.07541601335748606		[learning rate: 0.0056645]
	Learning Rate: 0.00566452
	LOSS [training: 0.0831188674006856 | validation: 0.09608445853008056]
	TIME [epoch: 8.89 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12442300800405866		[learning rate: 0.0056512]
		[batch 20/20] avg loss: 0.13118932791933205		[learning rate: 0.005638]
	Learning Rate: 0.00563797
	LOSS [training: 0.12780616796169536 | validation: 0.1388436088217076]
	TIME [epoch: 8.88 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12931715510987063		[learning rate: 0.0056247]
		[batch 20/20] avg loss: 0.1327621201501174		[learning rate: 0.0056115]
	Learning Rate: 0.00561153
	LOSS [training: 0.13103963762999404 | validation: 0.21768150728893138]
	TIME [epoch: 8.89 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10846564066561533		[learning rate: 0.0055984]
		[batch 20/20] avg loss: 0.12387839350474934		[learning rate: 0.0055852]
	Learning Rate: 0.00558523
	LOSS [training: 0.11617201708518232 | validation: 0.2894936004375907]
	TIME [epoch: 8.9 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12440063772232128		[learning rate: 0.0055721]
		[batch 20/20] avg loss: 0.07543095079411258		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.09991579425821692 | validation: 0.07601001510914972]
	TIME [epoch: 8.88 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07133742887206834		[learning rate: 0.005546]
		[batch 20/20] avg loss: 0.11986185785705958		[learning rate: 0.005533]
	Learning Rate: 0.00553298
	LOSS [training: 0.09559964336456396 | validation: 0.10828632286223046]
	TIME [epoch: 8.88 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10058561537332437		[learning rate: 0.00552]
		[batch 20/20] avg loss: 0.1148172800264416		[learning rate: 0.005507]
	Learning Rate: 0.00550704
	LOSS [training: 0.10770144769988296 | validation: 0.08636293290268111]
	TIME [epoch: 8.88 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11982240201705616		[learning rate: 0.0054941]
		[batch 20/20] avg loss: 0.08856607476458615		[learning rate: 0.0054812]
	Learning Rate: 0.00548122
	LOSS [training: 0.10419423839082116 | validation: 0.06792644029123113]
	TIME [epoch: 8.91 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09040329152154095		[learning rate: 0.0054684]
		[batch 20/20] avg loss: 0.10314277916731607		[learning rate: 0.0054555]
	Learning Rate: 0.00545553
	LOSS [training: 0.09677303534442852 | validation: 0.07406046751302585]
	TIME [epoch: 8.89 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09192497596670138		[learning rate: 0.0054427]
		[batch 20/20] avg loss: 0.10319440863422188		[learning rate: 0.00543]
	Learning Rate: 0.00542995
	LOSS [training: 0.09755969230046165 | validation: 0.09649886766867624]
	TIME [epoch: 8.89 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09399906041747953		[learning rate: 0.0054172]
		[batch 20/20] avg loss: 0.08497143471997708		[learning rate: 0.0054045]
	Learning Rate: 0.00540449
	LOSS [training: 0.0894852475687283 | validation: 0.2832109935581609]
	TIME [epoch: 8.88 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11014014175836029		[learning rate: 0.0053918]
		[batch 20/20] avg loss: 0.05761656700172844		[learning rate: 0.0053792]
	Learning Rate: 0.00537916
	LOSS [training: 0.08387835438004436 | validation: 0.10672135407074926]
	TIME [epoch: 8.89 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10074384203755		[learning rate: 0.0053665]
		[batch 20/20] avg loss: 0.11742986447798412		[learning rate: 0.0053539]
	Learning Rate: 0.00535394
	LOSS [training: 0.10908685325776704 | validation: 0.04932647611664741]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_143.pth
	Model improved!!!
EPOCH 144/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06755362297796678		[learning rate: 0.0053414]
		[batch 20/20] avg loss: 0.1144359118704549		[learning rate: 0.0053288]
	Learning Rate: 0.00532884
	LOSS [training: 0.09099476742421084 | validation: 0.039976940949287526]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_144.pth
	Model improved!!!
EPOCH 145/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06956985047023065		[learning rate: 0.0053163]
		[batch 20/20] avg loss: 0.07963085319035626		[learning rate: 0.0053039]
	Learning Rate: 0.00530386
	LOSS [training: 0.07460035183029345 | validation: 0.22326813481099106]
	TIME [epoch: 8.89 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08116027642269014		[learning rate: 0.0052914]
		[batch 20/20] avg loss: 0.10551907400378306		[learning rate: 0.005279]
	Learning Rate: 0.00527899
	LOSS [training: 0.09333967521323663 | validation: 0.11792432686281963]
	TIME [epoch: 8.89 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09508983944728532		[learning rate: 0.0052666]
		[batch 20/20] avg loss: 0.09625036283062283		[learning rate: 0.0052542]
	Learning Rate: 0.00525424
	LOSS [training: 0.09567010113895408 | validation: 0.08880117064512501]
	TIME [epoch: 8.9 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08769296793471137		[learning rate: 0.0052419]
		[batch 20/20] avg loss: 0.0738390642926203		[learning rate: 0.0052296]
	Learning Rate: 0.00522961
	LOSS [training: 0.08076601611366584 | validation: 0.10034283323688609]
	TIME [epoch: 8.9 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10746740546003722		[learning rate: 0.0052173]
		[batch 20/20] avg loss: 0.0962032852341565		[learning rate: 0.0052051]
	Learning Rate: 0.00520509
	LOSS [training: 0.10183534534709686 | validation: 0.05914992700573865]
	TIME [epoch: 8.88 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11344981225412468		[learning rate: 0.0051929]
		[batch 20/20] avg loss: 0.07802984074976613		[learning rate: 0.0051807]
	Learning Rate: 0.00518069
	LOSS [training: 0.09573982650194542 | validation: 0.19067871935141034]
	TIME [epoch: 8.89 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12974602254715503		[learning rate: 0.0051685]
		[batch 20/20] avg loss: 0.09279672277325605		[learning rate: 0.0051564]
	Learning Rate: 0.0051564
	LOSS [training: 0.11127137266020555 | validation: 0.05674434291889713]
	TIME [epoch: 8.89 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07011103894138698		[learning rate: 0.0051443]
		[batch 20/20] avg loss: 0.08002004124535164		[learning rate: 0.0051322]
	Learning Rate: 0.00513223
	LOSS [training: 0.07506554009336931 | validation: 0.13131910294031635]
	TIME [epoch: 8.91 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08705056388257026		[learning rate: 0.0051202]
		[batch 20/20] avg loss: 0.13683037520017924		[learning rate: 0.0051082]
	Learning Rate: 0.00510817
	LOSS [training: 0.11194046954137475 | validation: 0.08745200642164104]
	TIME [epoch: 8.89 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10052610606342764		[learning rate: 0.0050962]
		[batch 20/20] avg loss: 0.0673851693490591		[learning rate: 0.0050842]
	Learning Rate: 0.00508422
	LOSS [training: 0.08395563770624338 | validation: 0.08821969504286482]
	TIME [epoch: 8.89 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10217898635962377		[learning rate: 0.0050723]
		[batch 20/20] avg loss: 0.11648943317179897		[learning rate: 0.0050604]
	Learning Rate: 0.00506039
	LOSS [training: 0.10933420976571136 | validation: 0.10448985899093044]
	TIME [epoch: 8.89 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11037619741103495		[learning rate: 0.0050485]
		[batch 20/20] avg loss: 0.10921150663792023		[learning rate: 0.0050367]
	Learning Rate: 0.00503666
	LOSS [training: 0.10979385202447758 | validation: 0.07483455218610091]
	TIME [epoch: 8.89 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3031127006719458		[learning rate: 0.0050248]
		[batch 20/20] avg loss: 0.16359164351352434		[learning rate: 0.005013]
	Learning Rate: 0.00501305
	LOSS [training: 0.2333521720927351 | validation: 0.0669568250129835]
	TIME [epoch: 8.91 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0808836288261175		[learning rate: 0.0050013]
		[batch 20/20] avg loss: 0.08757014833835382		[learning rate: 0.0049895]
	Learning Rate: 0.00498955
	LOSS [training: 0.08422688858223565 | validation: 0.05324949477916694]
	TIME [epoch: 8.89 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09553857742522617		[learning rate: 0.0049778]
		[batch 20/20] avg loss: 0.10328356393714835		[learning rate: 0.0049662]
	Learning Rate: 0.00496616
	LOSS [training: 0.09941107068118725 | validation: 0.07799329393703386]
	TIME [epoch: 8.89 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15138453029775661		[learning rate: 0.0049545]
		[batch 20/20] avg loss: 0.12252951937426457		[learning rate: 0.0049429]
	Learning Rate: 0.00494287
	LOSS [training: 0.1369570248360106 | validation: 0.07395819329951862]
	TIME [epoch: 8.89 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0558814665604214		[learning rate: 0.0049313]
		[batch 20/20] avg loss: 0.0562328343995261		[learning rate: 0.0049197]
	Learning Rate: 0.0049197
	LOSS [training: 0.05605715047997375 | validation: 0.10904436874790491]
	TIME [epoch: 8.89 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1189360112421907		[learning rate: 0.0049082]
		[batch 20/20] avg loss: 0.12296710727711584		[learning rate: 0.0048966]
	Learning Rate: 0.00489664
	LOSS [training: 0.12095155925965326 | validation: 0.06569175383383186]
	TIME [epoch: 8.91 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11425181079724148		[learning rate: 0.0048851]
		[batch 20/20] avg loss: 0.15039455847301747		[learning rate: 0.0048737]
	Learning Rate: 0.00487368
	LOSS [training: 0.13232318463512943 | validation: 0.07483055724847901]
	TIME [epoch: 8.89 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06577787648297793		[learning rate: 0.0048622]
		[batch 20/20] avg loss: 0.04573791964128564		[learning rate: 0.0048508]
	Learning Rate: 0.00485083
	LOSS [training: 0.055757898062131786 | validation: 0.026785074777558135]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_164.pth
	Model improved!!!
EPOCH 165/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10156804830438615		[learning rate: 0.0048394]
		[batch 20/20] avg loss: 0.07086559293880099		[learning rate: 0.0048281]
	Learning Rate: 0.00482809
	LOSS [training: 0.08621682062159355 | validation: 0.1392497855884689]
	TIME [epoch: 8.89 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11671982300013999		[learning rate: 0.0048168]
		[batch 20/20] avg loss: 0.04859611554886332		[learning rate: 0.0048055]
	Learning Rate: 0.00480546
	LOSS [training: 0.08265796927450166 | validation: 0.20061772894655913]
	TIME [epoch: 8.91 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08434238318792384		[learning rate: 0.0047942]
		[batch 20/20] avg loss: 0.15561085760904125		[learning rate: 0.0047829]
	Learning Rate: 0.00478293
	LOSS [training: 0.11997662039848259 | validation: 0.16636868311415423]
	TIME [epoch: 8.89 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09959116579819174		[learning rate: 0.0047717]
		[batch 20/20] avg loss: 0.10126799233426267		[learning rate: 0.0047605]
	Learning Rate: 0.00476051
	LOSS [training: 0.10042957906622721 | validation: 0.06286413657210634]
	TIME [epoch: 8.88 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07175072920965163		[learning rate: 0.0047493]
		[batch 20/20] avg loss: 0.13906976042619149		[learning rate: 0.0047382]
	Learning Rate: 0.00473819
	LOSS [training: 0.10541024481792154 | validation: 0.07991457489149054]
	TIME [epoch: 8.89 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06160959140780473		[learning rate: 0.0047271]
		[batch 20/20] avg loss: 0.041273281867187796		[learning rate: 0.004716]
	Learning Rate: 0.00471597
	LOSS [training: 0.051441436637496264 | validation: 0.07583581792602952]
	TIME [epoch: 8.88 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09810015941592143		[learning rate: 0.0047049]
		[batch 20/20] avg loss: 0.05635456463588108		[learning rate: 0.0046939]
	Learning Rate: 0.00469386
	LOSS [training: 0.07722736202590126 | validation: 0.0781068015309744]
	TIME [epoch: 8.92 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0767661836584744		[learning rate: 0.0046828]
		[batch 20/20] avg loss: 0.07079636824778716		[learning rate: 0.0046719]
	Learning Rate: 0.00467186
	LOSS [training: 0.07378127595313078 | validation: 0.052796240784753985]
	TIME [epoch: 8.9 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08523656940595181		[learning rate: 0.0046609]
		[batch 20/20] avg loss: 0.09250924813345061		[learning rate: 0.00465]
	Learning Rate: 0.00464996
	LOSS [training: 0.08887290876970123 | validation: 0.05547813434407696]
	TIME [epoch: 8.89 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08749424476973909		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.10941296499661828		[learning rate: 0.0046282]
	Learning Rate: 0.00462816
	LOSS [training: 0.0984536048831787 | validation: 0.06456933651136611]
	TIME [epoch: 8.89 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08654496159931842		[learning rate: 0.0046173]
		[batch 20/20] avg loss: 0.06310166390179549		[learning rate: 0.0046065]
	Learning Rate: 0.00460646
	LOSS [training: 0.07482331275055695 | validation: 0.03872115061225695]
	TIME [epoch: 8.9 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07080849077773195		[learning rate: 0.0045956]
		[batch 20/20] avg loss: 0.09869349183964995		[learning rate: 0.0045849]
	Learning Rate: 0.00458486
	LOSS [training: 0.08475099130869095 | validation: 0.051457687376701096]
	TIME [epoch: 8.92 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05541843926188611		[learning rate: 0.0045741]
		[batch 20/20] avg loss: 0.0818070623248242		[learning rate: 0.0045634]
	Learning Rate: 0.00456337
	LOSS [training: 0.06861275079335515 | validation: 0.06179714493140452]
	TIME [epoch: 8.9 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21862449989381783		[learning rate: 0.0045527]
		[batch 20/20] avg loss: 0.14796832180823732		[learning rate: 0.004542]
	Learning Rate: 0.00454198
	LOSS [training: 0.18329641085102757 | validation: 0.06322433891313249]
	TIME [epoch: 8.89 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19594767889500983		[learning rate: 0.0045313]
		[batch 20/20] avg loss: 0.15838129586788735		[learning rate: 0.0045207]
	Learning Rate: 0.00452068
	LOSS [training: 0.17716448738144858 | validation: 0.31201650797757985]
	TIME [epoch: 8.89 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13672776436797277		[learning rate: 0.0045101]
		[batch 20/20] avg loss: 0.058466192173024054		[learning rate: 0.0044995]
	Learning Rate: 0.00449949
	LOSS [training: 0.0975969782704984 | validation: 0.017834380011319054]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_180.pth
	Model improved!!!
EPOCH 181/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04741730441177995		[learning rate: 0.0044889]
		[batch 20/20] avg loss: 0.14338389281652977		[learning rate: 0.0044784]
	Learning Rate: 0.0044784
	LOSS [training: 0.09540059861415487 | validation: 0.41294559775751316]
	TIME [epoch: 8.88 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20007094546030593		[learning rate: 0.0044679]
		[batch 20/20] avg loss: 0.14425975006727762		[learning rate: 0.0044574]
	Learning Rate: 0.0044574
	LOSS [training: 0.17216534776379175 | validation: 0.23682740463989022]
	TIME [epoch: 8.87 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12451923836804095		[learning rate: 0.0044469]
		[batch 20/20] avg loss: 0.07277420134144755		[learning rate: 0.0044365]
	Learning Rate: 0.0044365
	LOSS [training: 0.09864671985474426 | validation: 0.040355049844045816]
	TIME [epoch: 8.88 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05648194712739975		[learning rate: 0.0044261]
		[batch 20/20] avg loss: 0.06623124025755837		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.06135659369247905 | validation: 0.11138857759742793]
	TIME [epoch: 8.88 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08446144488824311		[learning rate: 0.0044053]
		[batch 20/20] avg loss: 0.08114092919276042		[learning rate: 0.004395]
	Learning Rate: 0.004395
	LOSS [training: 0.08280118704050175 | validation: 0.20041013103545585]
	TIME [epoch: 8.9 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09168422668587808		[learning rate: 0.0043847]
		[batch 20/20] avg loss: 0.075941505756914		[learning rate: 0.0043744]
	Learning Rate: 0.0043744
	LOSS [training: 0.08381286622139605 | validation: 0.06001145374132882]
	TIME [epoch: 8.88 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11174321549128408		[learning rate: 0.0043641]
		[batch 20/20] avg loss: 0.11696714047696		[learning rate: 0.0043539]
	Learning Rate: 0.00435389
	LOSS [training: 0.11435517798412206 | validation: 0.1514757434856432]
	TIME [epoch: 8.87 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07164071747192069		[learning rate: 0.0043437]
		[batch 20/20] avg loss: 0.08059509766607452		[learning rate: 0.0043335]
	Learning Rate: 0.00433348
	LOSS [training: 0.07611790756899758 | validation: 0.11837892984428387]
	TIME [epoch: 8.87 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0775705444393663		[learning rate: 0.0043233]
		[batch 20/20] avg loss: 0.10074967959393408		[learning rate: 0.0043132]
	Learning Rate: 0.00431316
	LOSS [training: 0.08916011201665017 | validation: 0.312033566402985]
	TIME [epoch: 8.88 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1676123020860696		[learning rate: 0.004303]
		[batch 20/20] avg loss: 0.07966984028483146		[learning rate: 0.0042929]
	Learning Rate: 0.00429294
	LOSS [training: 0.12364107118545047 | validation: 0.06952418854783964]
	TIME [epoch: 8.9 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/20] avg loss: 0.060502545562839974		[learning rate: 0.0042829]
		[batch 20/20] avg loss: 0.09414309006809958		[learning rate: 0.0042728]
	Learning Rate: 0.00427282
	LOSS [training: 0.07732281781546978 | validation: 0.031823313011969015]
	TIME [epoch: 8.88 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09436308077197306		[learning rate: 0.0042628]
		[batch 20/20] avg loss: 0.057398218414997516		[learning rate: 0.0042528]
	Learning Rate: 0.00425279
	LOSS [training: 0.07588064959348528 | validation: 0.03755918833166312]
	TIME [epoch: 8.87 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06987058931606213		[learning rate: 0.0042428]
		[batch 20/20] avg loss: 0.09469967927256875		[learning rate: 0.0042328]
	Learning Rate: 0.00423285
	LOSS [training: 0.08228513429431544 | validation: 0.11481612215229994]
	TIME [epoch: 8.87 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12884965795714515		[learning rate: 0.0042229]
		[batch 20/20] avg loss: 0.14931259093531724		[learning rate: 0.004213]
	Learning Rate: 0.004213
	LOSS [training: 0.13908112444623116 | validation: 0.07483746949433469]
	TIME [epoch: 8.9 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14268766751699		[learning rate: 0.0042031]
		[batch 20/20] avg loss: 0.04696947982193207		[learning rate: 0.0041933]
	Learning Rate: 0.00419325
	LOSS [training: 0.09482857366946104 | validation: 0.09635140056028144]
	TIME [epoch: 8.89 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0687467544364513		[learning rate: 0.0041834]
		[batch 20/20] avg loss: 0.08538902700416443		[learning rate: 0.0041736]
	Learning Rate: 0.00417359
	LOSS [training: 0.07706789072030784 | validation: 0.06541358014660362]
	TIME [epoch: 8.89 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1005236772525501		[learning rate: 0.0041638]
		[batch 20/20] avg loss: 0.08656950453052739		[learning rate: 0.004154]
	Learning Rate: 0.00415403
	LOSS [training: 0.09354659089153874 | validation: 0.05892645899988347]
	TIME [epoch: 8.88 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08085965241587387		[learning rate: 0.0041443]
		[batch 20/20] avg loss: 0.07738849343042856		[learning rate: 0.0041346]
	Learning Rate: 0.00413455
	LOSS [training: 0.07912407292315123 | validation: 0.03658898473694198]
	TIME [epoch: 8.88 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08493094658204879		[learning rate: 0.0041249]
		[batch 20/20] avg loss: 0.08508905433936828		[learning rate: 0.0041152]
	Learning Rate: 0.00411517
	LOSS [training: 0.08501000046070854 | validation: 0.05290192233326939]
	TIME [epoch: 8.91 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04813187049978686		[learning rate: 0.0041055]
		[batch 20/20] avg loss: 0.049967899697801556		[learning rate: 0.0040959]
	Learning Rate: 0.00409588
	LOSS [training: 0.04904988509879421 | validation: 0.0484733353129396]
	TIME [epoch: 8.89 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06295303045129427		[learning rate: 0.0040863]
		[batch 20/20] avg loss: 0.09718762183565031		[learning rate: 0.0040767]
	Learning Rate: 0.00407667
	LOSS [training: 0.08007032614347231 | validation: 0.11612437319405777]
	TIME [epoch: 8.88 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08958457322208511		[learning rate: 0.0040671]
		[batch 20/20] avg loss: 0.055158860889808356		[learning rate: 0.0040576]
	Learning Rate: 0.00405756
	LOSS [training: 0.07237171705594672 | validation: 0.05188442762270553]
	TIME [epoch: 8.88 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05304272316639306		[learning rate: 0.004048]
		[batch 20/20] avg loss: 0.04740776936556228		[learning rate: 0.0040385]
	Learning Rate: 0.00403854
	LOSS [training: 0.050225246265977665 | validation: 0.08028147524172335]
	TIME [epoch: 8.89 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06470458524793204		[learning rate: 0.0040291]
		[batch 20/20] avg loss: 0.07223103814327383		[learning rate: 0.0040196]
	Learning Rate: 0.00401961
	LOSS [training: 0.06846781169560294 | validation: 0.05044519249390955]
	TIME [epoch: 8.91 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0595729728113103		[learning rate: 0.0040102]
		[batch 20/20] avg loss: 0.10454178437071893		[learning rate: 0.0040008]
	Learning Rate: 0.00400076
	LOSS [training: 0.08205737859101463 | validation: 0.10947683530534769]
	TIME [epoch: 8.89 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10800081609511372		[learning rate: 0.0039914]
		[batch 20/20] avg loss: 0.04301772471500055		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.07550927040505714 | validation: 0.044940855226097504]
	TIME [epoch: 8.89 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04407611017061518		[learning rate: 0.0039727]
		[batch 20/20] avg loss: 0.04464646892678899		[learning rate: 0.0039633]
	Learning Rate: 0.00396334
	LOSS [training: 0.044361289548702096 | validation: 0.028830186667259103]
	TIME [epoch: 8.88 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07382391985316186		[learning rate: 0.003954]
		[batch 20/20] avg loss: 0.11061395422585348		[learning rate: 0.0039448]
	Learning Rate: 0.00394476
	LOSS [training: 0.09221893703950765 | validation: 0.09873480426579899]
	TIME [epoch: 8.88 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/20] avg loss: 0.047702676123370806		[learning rate: 0.0039355]
		[batch 20/20] avg loss: 0.10067145619153813		[learning rate: 0.0039263]
	Learning Rate: 0.00392627
	LOSS [training: 0.07418706615745449 | validation: 0.12254416776918586]
	TIME [epoch: 8.91 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0687688067176468		[learning rate: 0.0039171]
		[batch 20/20] avg loss: 0.128829596903166		[learning rate: 0.0039079]
	Learning Rate: 0.00390786
	LOSS [training: 0.0987992018104064 | validation: 0.08173036001167888]
	TIME [epoch: 8.89 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06812933697713096		[learning rate: 0.0038987]
		[batch 20/20] avg loss: 0.07515292022131687		[learning rate: 0.0038895]
	Learning Rate: 0.00388954
	LOSS [training: 0.07164112859922392 | validation: 0.031488799894404965]
	TIME [epoch: 8.89 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05604953566268828		[learning rate: 0.0038804]
		[batch 20/20] avg loss: 0.05633990062011327		[learning rate: 0.0038713]
	Learning Rate: 0.0038713
	LOSS [training: 0.05619471814140077 | validation: 0.13891532858871308]
	TIME [epoch: 8.88 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0769175727237574		[learning rate: 0.0038622]
		[batch 20/20] avg loss: 0.06247761272805051		[learning rate: 0.0038532]
	Learning Rate: 0.00385315
	LOSS [training: 0.06969759272590395 | validation: 0.05384616465219942]
	TIME [epoch: 8.9 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06285165539885944		[learning rate: 0.0038441]
		[batch 20/20] avg loss: 0.10308023881884872		[learning rate: 0.0038351]
	Learning Rate: 0.00383509
	LOSS [training: 0.08296594710885409 | validation: 0.20385719177137152]
	TIME [epoch: 8.89 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10191014200969509		[learning rate: 0.0038261]
		[batch 20/20] avg loss: 0.062131816534515286		[learning rate: 0.0038171]
	Learning Rate: 0.00381711
	LOSS [training: 0.0820209792721052 | validation: 0.056709324468493735]
	TIME [epoch: 8.88 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07430142176652389		[learning rate: 0.0038082]
		[batch 20/20] avg loss: 0.08757903134700538		[learning rate: 0.0037992]
	Learning Rate: 0.00379921
	LOSS [training: 0.08094022655676464 | validation: 0.045628246020233985]
	TIME [epoch: 8.89 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/20] avg loss: 0.060420691748626985		[learning rate: 0.0037903]
		[batch 20/20] avg loss: 0.0530659247539376		[learning rate: 0.0037814]
	Learning Rate: 0.0037814
	LOSS [training: 0.05674330825128231 | validation: 0.035206017721255284]
	TIME [epoch: 8.89 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06021634080693809		[learning rate: 0.0037725]
		[batch 20/20] avg loss: 0.05898434318796973		[learning rate: 0.0037637]
	Learning Rate: 0.00376368
	LOSS [training: 0.05960034199745392 | validation: 0.11882167064983935]
	TIME [epoch: 8.91 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07085799502710083		[learning rate: 0.0037548]
		[batch 20/20] avg loss: 0.06685726913810106		[learning rate: 0.003746]
	Learning Rate: 0.00374603
	LOSS [training: 0.06885763208260094 | validation: 0.048436586238483056]
	TIME [epoch: 8.88 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06546170425453549		[learning rate: 0.0037372]
		[batch 20/20] avg loss: 0.06688677649511458		[learning rate: 0.0037285]
	Learning Rate: 0.00372847
	LOSS [training: 0.06617424037482503 | validation: 0.06339353588638441]
	TIME [epoch: 8.89 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08751540683576248		[learning rate: 0.0037197]
		[batch 20/20] avg loss: 0.048052870208131426		[learning rate: 0.003711]
	Learning Rate: 0.00371099
	LOSS [training: 0.06778413852194695 | validation: 0.022537232239510374]
	TIME [epoch: 8.88 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06091155956250923		[learning rate: 0.0037023]
		[batch 20/20] avg loss: 0.07035180131291867		[learning rate: 0.0036936]
	Learning Rate: 0.00369359
	LOSS [training: 0.06563168043771395 | validation: 0.0643901633505551]
	TIME [epoch: 8.88 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/20] avg loss: 0.056903281499665406		[learning rate: 0.0036849]
		[batch 20/20] avg loss: 0.11735015247809352		[learning rate: 0.0036763]
	Learning Rate: 0.00367628
	LOSS [training: 0.08712671698887946 | validation: 0.17757279378337404]
	TIME [epoch: 8.89 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06338657366349361		[learning rate: 0.0036676]
		[batch 20/20] avg loss: 0.1340419111070948		[learning rate: 0.003659]
	Learning Rate: 0.00365904
	LOSS [training: 0.09871424238529419 | validation: 0.19243863008706946]
	TIME [epoch: 8.88 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08826161362571273		[learning rate: 0.0036505]
		[batch 20/20] avg loss: 0.055575243015028364		[learning rate: 0.0036419]
	Learning Rate: 0.00364189
	LOSS [training: 0.07191842832037054 | validation: 0.07744895720338933]
	TIME [epoch: 8.87 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07961257902087579		[learning rate: 0.0036333]
		[batch 20/20] avg loss: 0.04381531747815531		[learning rate: 0.0036248]
	Learning Rate: 0.00362481
	LOSS [training: 0.06171394824951555 | validation: 0.029839288573398324]
	TIME [epoch: 8.88 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06931463234909314		[learning rate: 0.0036163]
		[batch 20/20] avg loss: 0.050960938009191256		[learning rate: 0.0036078]
	Learning Rate: 0.00360782
	LOSS [training: 0.060137785179142186 | validation: 0.07958918941879627]
	TIME [epoch: 8.9 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09629825059371269		[learning rate: 0.0035994]
		[batch 20/20] avg loss: 0.09387277935692581		[learning rate: 0.0035909]
	Learning Rate: 0.00359091
	LOSS [training: 0.09508551497531925 | validation: 0.035519705577074706]
	TIME [epoch: 8.88 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05228568565289091		[learning rate: 0.0035825]
		[batch 20/20] avg loss: 0.036315119996901624		[learning rate: 0.0035741]
	Learning Rate: 0.00357407
	LOSS [training: 0.044300402824896265 | validation: 0.10768876366073458]
	TIME [epoch: 8.88 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05489355575000372		[learning rate: 0.0035657]
		[batch 20/20] avg loss: 0.04744668927008722		[learning rate: 0.0035573]
	Learning Rate: 0.00355732
	LOSS [training: 0.05117012251004547 | validation: 0.03397791762889959]
	TIME [epoch: 8.88 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/20] avg loss: 0.049394803402683644		[learning rate: 0.003549]
		[batch 20/20] avg loss: 0.06396508657693928		[learning rate: 0.0035406]
	Learning Rate: 0.00354064
	LOSS [training: 0.05667994498981146 | validation: 0.027980896290473588]
	TIME [epoch: 8.88 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/20] avg loss: 0.039361960632386575		[learning rate: 0.0035323]
		[batch 20/20] avg loss: 0.04475145639598531		[learning rate: 0.003524]
	Learning Rate: 0.00352404
	LOSS [training: 0.04205670851418593 | validation: 0.05354396433451201]
	TIME [epoch: 8.9 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11695979586034488		[learning rate: 0.0035158]
		[batch 20/20] avg loss: 0.07158514068279694		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.09427246827157092 | validation: 0.054616404796764544]
	TIME [epoch: 8.88 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07877318787616605		[learning rate: 0.0034993]
		[batch 20/20] avg loss: 0.0667295276935401		[learning rate: 0.0034911]
	Learning Rate: 0.00349107
	LOSS [training: 0.07275135778485307 | validation: 0.09058443109198301]
	TIME [epoch: 8.9 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07098105741400362		[learning rate: 0.0034829]
		[batch 20/20] avg loss: 0.03137710673331566		[learning rate: 0.0034747]
	Learning Rate: 0.00347471
	LOSS [training: 0.051179082073659635 | validation: 0.014796103903909402]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_235.pth
	Model improved!!!
EPOCH 236/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03067761599188466		[learning rate: 0.0034666]
		[batch 20/20] avg loss: 0.0628141165336594		[learning rate: 0.0034584]
	Learning Rate: 0.00345842
	LOSS [training: 0.04674586626277203 | validation: 0.03155059779198781]
	TIME [epoch: 8.88 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05894308853122691		[learning rate: 0.0034503]
		[batch 20/20] avg loss: 0.059347983499431836		[learning rate: 0.0034422]
	Learning Rate: 0.00344221
	LOSS [training: 0.05914553601532936 | validation: 0.03255619527813572]
	TIME [epoch: 8.9 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04258629444173607		[learning rate: 0.0034341]
		[batch 20/20] avg loss: 0.0604741599538404		[learning rate: 0.0034261]
	Learning Rate: 0.00342607
	LOSS [training: 0.051530227197788235 | validation: 0.05231029666196543]
	TIME [epoch: 8.89 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05610532261535388		[learning rate: 0.003418]
		[batch 20/20] avg loss: 0.08078583464814651		[learning rate: 0.00341]
	Learning Rate: 0.00341001
	LOSS [training: 0.0684455786317502 | validation: 0.048027334467646586]
	TIME [epoch: 8.88 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05218963855742779		[learning rate: 0.003402]
		[batch 20/20] avg loss: 0.052466323108710265		[learning rate: 0.003394]
	Learning Rate: 0.00339402
	LOSS [training: 0.05232798083306904 | validation: 0.07989704422401471]
	TIME [epoch: 8.89 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05094541657757329		[learning rate: 0.0033861]
		[batch 20/20] avg loss: 0.05821156528891257		[learning rate: 0.0033781]
	Learning Rate: 0.00337811
	LOSS [training: 0.05457849093324292 | validation: 0.021922923781404993]
	TIME [epoch: 8.9 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0615447290634082		[learning rate: 0.0033702]
		[batch 20/20] avg loss: 0.050648934197152495		[learning rate: 0.0033623]
	Learning Rate: 0.00336227
	LOSS [training: 0.056096831630280355 | validation: 0.024409995364144302]
	TIME [epoch: 8.88 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05156335851237613		[learning rate: 0.0033544]
		[batch 20/20] avg loss: 0.06276530627685459		[learning rate: 0.0033465]
	Learning Rate: 0.00334651
	LOSS [training: 0.057164332394615346 | validation: 0.10940130198920903]
	TIME [epoch: 8.87 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08032000080894129		[learning rate: 0.0033387]
		[batch 20/20] avg loss: 0.035730198958297446		[learning rate: 0.0033308]
	Learning Rate: 0.00333082
	LOSS [training: 0.05802509988361938 | validation: 0.054958904335482214]
	TIME [epoch: 8.87 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/20] avg loss: 0.049839012512242695		[learning rate: 0.003323]
		[batch 20/20] avg loss: 0.033419580718821694		[learning rate: 0.0033152]
	Learning Rate: 0.0033152
	LOSS [training: 0.0416292966155322 | validation: 0.02304758347167317]
	TIME [epoch: 8.87 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/20] avg loss: 0.041690766857295336		[learning rate: 0.0033074]
		[batch 20/20] avg loss: 0.04330365390308569		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.04249721038019051 | validation: 0.06653448199114251]
	TIME [epoch: 8.9 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/20] avg loss: 0.047485461729919416		[learning rate: 0.0032919]
		[batch 20/20] avg loss: 0.10717701566918796		[learning rate: 0.0032842]
	Learning Rate: 0.00328419
	LOSS [training: 0.0773312386995537 | validation: 0.05612305007945668]
	TIME [epoch: 8.87 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0494956135620251		[learning rate: 0.0032765]
		[batch 20/20] avg loss: 0.03211697043839805		[learning rate: 0.0032688]
	Learning Rate: 0.0032688
	LOSS [training: 0.040806292000211575 | validation: 0.03420508146629868]
	TIME [epoch: 8.88 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/20] avg loss: 0.036705838467514816		[learning rate: 0.0032611]
		[batch 20/20] avg loss: 0.05204449748643845		[learning rate: 0.0032535]
	Learning Rate: 0.00325347
	LOSS [training: 0.04437516797697664 | validation: 0.034270173394597675]
	TIME [epoch: 8.88 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06431644662084426		[learning rate: 0.0032458]
		[batch 20/20] avg loss: 0.05341345415908984		[learning rate: 0.0032382]
	Learning Rate: 0.00323822
	LOSS [training: 0.058864950389967044 | validation: 0.07992020142124985]
	TIME [epoch: 8.88 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0405205437960819		[learning rate: 0.0032306]
		[batch 20/20] avg loss: 0.06856504087263729		[learning rate: 0.003223]
	Learning Rate: 0.00322304
	LOSS [training: 0.05454279233435959 | validation: 0.04683825945097407]
	TIME [epoch: 8.9 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05326564565643348		[learning rate: 0.0032155]
		[batch 20/20] avg loss: 0.040287009022110624		[learning rate: 0.0032079]
	Learning Rate: 0.00320793
	LOSS [training: 0.046776327339272054 | validation: 0.04319200948753345]
	TIME [epoch: 8.88 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05775387342388024		[learning rate: 0.0032004]
		[batch 20/20] avg loss: 0.04872741995492338		[learning rate: 0.0031929]
	Learning Rate: 0.00319289
	LOSS [training: 0.053240646689401795 | validation: 0.03157022023056721]
	TIME [epoch: 8.88 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/20] avg loss: 0.041645111073207036		[learning rate: 0.0031854]
		[batch 20/20] avg loss: 0.06963464283798447		[learning rate: 0.0031779]
	Learning Rate: 0.00317792
	LOSS [training: 0.05563987695559573 | validation: 0.04923582963171544]
	TIME [epoch: 8.88 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04331641357198572		[learning rate: 0.0031705]
		[batch 20/20] avg loss: 0.06573475597422886		[learning rate: 0.003163]
	Learning Rate: 0.00316302
	LOSS [training: 0.05452558477310728 | validation: 0.009894444259934363]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_255.pth
	Model improved!!!
EPOCH 256/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03785077638853197		[learning rate: 0.0031556]
		[batch 20/20] avg loss: 0.047747806972266466		[learning rate: 0.0031482]
	Learning Rate: 0.00314819
	LOSS [training: 0.04279929168039921 | validation: 0.061343949759148315]
	TIME [epoch: 8.89 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03444122154082846		[learning rate: 0.0031408]
		[batch 20/20] avg loss: 0.03872945791500687		[learning rate: 0.0031334]
	Learning Rate: 0.00313343
	LOSS [training: 0.03658533972791768 | validation: 0.01520949668395654]
	TIME [epoch: 8.86 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/20] avg loss: 0.042630909156952154		[learning rate: 0.0031261]
		[batch 20/20] avg loss: 0.05283239796036323		[learning rate: 0.0031187]
	Learning Rate: 0.00311874
	LOSS [training: 0.04773165355865769 | validation: 0.02441453299140577]
	TIME [epoch: 8.87 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04304066303836196		[learning rate: 0.0031114]
		[batch 20/20] avg loss: 0.08824257455323403		[learning rate: 0.0031041]
	Learning Rate: 0.00310412
	LOSS [training: 0.065641618795798 | validation: 0.019015966756316335]
	TIME [epoch: 8.87 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04339583141907005		[learning rate: 0.0030968]
		[batch 20/20] avg loss: 0.08897031930346683		[learning rate: 0.0030896]
	Learning Rate: 0.00308957
	LOSS [training: 0.06618307536126844 | validation: 0.048656664741174895]
	TIME [epoch: 8.89 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02705864168738038		[learning rate: 0.0030823]
		[batch 20/20] avg loss: 0.07952597460863531		[learning rate: 0.0030751]
	Learning Rate: 0.00307509
	LOSS [training: 0.05329230814800784 | validation: 0.08035701467964351]
	TIME [epoch: 8.88 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06042386613138058		[learning rate: 0.0030679]
		[batch 20/20] avg loss: 0.057772571850388886		[learning rate: 0.0030607]
	Learning Rate: 0.00306067
	LOSS [training: 0.05909821899088473 | validation: 0.019577992595638957]
	TIME [epoch: 8.86 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04717853077615372		[learning rate: 0.0030535]
		[batch 20/20] avg loss: 0.03315822484220217		[learning rate: 0.0030463]
	Learning Rate: 0.00304632
	LOSS [training: 0.040168377809177945 | validation: 0.00872750248587766]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_263.pth
	Model improved!!!
EPOCH 264/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028519241719714865		[learning rate: 0.0030392]
		[batch 20/20] avg loss: 0.035563508512910035		[learning rate: 0.003032]
	Learning Rate: 0.00303204
	LOSS [training: 0.03204137511631246 | validation: 0.03499073936160707]
	TIME [epoch: 8.87 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04979927420904311		[learning rate: 0.0030249]
		[batch 20/20] avg loss: 0.04123403026394458		[learning rate: 0.0030178]
	Learning Rate: 0.00301782
	LOSS [training: 0.04551665223649384 | validation: 0.07399642211079441]
	TIME [epoch: 8.88 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05804119676443457		[learning rate: 0.0030107]
		[batch 20/20] avg loss: 0.04233217893768174		[learning rate: 0.0030037]
	Learning Rate: 0.00300368
	LOSS [training: 0.050186687851058155 | validation: 0.03502225325956937]
	TIME [epoch: 8.87 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04288255659240628		[learning rate: 0.0029966]
		[batch 20/20] avg loss: 0.04248524375499233		[learning rate: 0.0029896]
	Learning Rate: 0.00298959
	LOSS [training: 0.04268390017369931 | validation: 0.12793411329561244]
	TIME [epoch: 8.87 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08238642008669095		[learning rate: 0.0029826]
		[batch 20/20] avg loss: 0.06922000420294104		[learning rate: 0.0029756]
	Learning Rate: 0.00297558
	LOSS [training: 0.075803212144816 | validation: 0.025560197597001958]
	TIME [epoch: 8.88 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07431069579101512		[learning rate: 0.0029686]
		[batch 20/20] avg loss: 0.09900381371728002		[learning rate: 0.0029616]
	Learning Rate: 0.00296163
	LOSS [training: 0.08665725475414757 | validation: 0.15476823079719088]
	TIME [epoch: 8.87 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0985990992834437		[learning rate: 0.0029547]
		[batch 20/20] avg loss: 0.07045252771115768		[learning rate: 0.0029477]
	Learning Rate: 0.00294774
	LOSS [training: 0.08452581349730069 | validation: 0.0593108401223246]
	TIME [epoch: 8.89 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05322975987623868		[learning rate: 0.0029408]
		[batch 20/20] avg loss: 0.07867115501507276		[learning rate: 0.0029339]
	Learning Rate: 0.00293393
	LOSS [training: 0.06595045744565571 | validation: 0.0430427615075388]
	TIME [epoch: 8.86 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0643911925785984		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.05636830656237864		[learning rate: 0.0029202]
	Learning Rate: 0.00292017
	LOSS [training: 0.06037974957048851 | validation: 0.06482173832180538]
	TIME [epoch: 8.86 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0865848056649007		[learning rate: 0.0029133]
		[batch 20/20] avg loss: 0.08478246559039093		[learning rate: 0.0029065]
	Learning Rate: 0.00290648
	LOSS [training: 0.08568363562764585 | validation: 0.07600528198902194]
	TIME [epoch: 8.87 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11226101312645753		[learning rate: 0.0028997]
		[batch 20/20] avg loss: 0.06866257384509408		[learning rate: 0.0028929]
	Learning Rate: 0.00289285
	LOSS [training: 0.0904617934857758 | validation: 0.0567954701269093]
	TIME [epoch: 8.89 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04099070763046604		[learning rate: 0.0028861]
		[batch 20/20] avg loss: 0.058443901952604474		[learning rate: 0.0028793]
	Learning Rate: 0.00287929
	LOSS [training: 0.04971730479153526 | validation: 0.05704205872365517]
	TIME [epoch: 8.87 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04997475026357726		[learning rate: 0.0028725]
		[batch 20/20] avg loss: 0.04964166251147599		[learning rate: 0.0028658]
	Learning Rate: 0.00286579
	LOSS [training: 0.04980820638752663 | validation: 0.07106008854444615]
	TIME [epoch: 8.87 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/20] avg loss: 0.053418596517054495		[learning rate: 0.0028591]
		[batch 20/20] avg loss: 0.0505297086861473		[learning rate: 0.0028524]
	Learning Rate: 0.00285236
	LOSS [training: 0.05197415260160091 | validation: 0.03227718119121216]
	TIME [epoch: 8.86 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04078376892368217		[learning rate: 0.0028457]
		[batch 20/20] avg loss: 0.11883377684355145		[learning rate: 0.002839]
	Learning Rate: 0.00283899
	LOSS [training: 0.07980877288361683 | validation: 0.2336684022661989]
	TIME [epoch: 8.87 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/20] avg loss: 0.072898992317774		[learning rate: 0.0028323]
		[batch 20/20] avg loss: 0.08078309217217092		[learning rate: 0.0028257]
	Learning Rate: 0.00282568
	LOSS [training: 0.07684104224497247 | validation: 0.06008682539041009]
	TIME [epoch: 8.89 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/20] avg loss: 0.043768228824827594		[learning rate: 0.002819]
		[batch 20/20] avg loss: 0.04272652462157224		[learning rate: 0.0028124]
	Learning Rate: 0.00281243
	LOSS [training: 0.04324737672319992 | validation: 0.051260833587776354]
	TIME [epoch: 8.87 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04342379886997862		[learning rate: 0.0028058]
		[batch 20/20] avg loss: 0.029890708340019216		[learning rate: 0.0027992]
	Learning Rate: 0.00279924
	LOSS [training: 0.03665725360499892 | validation: 0.01778697276498683]
	TIME [epoch: 8.87 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05925873275382008		[learning rate: 0.0027927]
		[batch 20/20] avg loss: 0.05665519541161439		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.05795696408271724 | validation: 0.07904025688813643]
	TIME [epoch: 8.87 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09691509946880357		[learning rate: 0.0027796]
		[batch 20/20] avg loss: 0.08822583750041842		[learning rate: 0.0027731]
	Learning Rate: 0.00277306
	LOSS [training: 0.092570468484611 | validation: 0.04371457897810483]
	TIME [epoch: 8.87 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03969322508374934		[learning rate: 0.0027666]
		[batch 20/20] avg loss: 0.051012097441886964		[learning rate: 0.0027601]
	Learning Rate: 0.00276006
	LOSS [training: 0.045352661262818145 | validation: 0.03288400132746597]
	TIME [epoch: 8.89 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05111659995530373		[learning rate: 0.0027536]
		[batch 20/20] avg loss: 0.060231289969080545		[learning rate: 0.0027471]
	Learning Rate: 0.00274712
	LOSS [training: 0.05567394496219215 | validation: 0.0790691910824612]
	TIME [epoch: 8.87 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/20] avg loss: 0.054511837988673116		[learning rate: 0.0027407]
		[batch 20/20] avg loss: 0.048426351780728814		[learning rate: 0.0027342]
	Learning Rate: 0.00273424
	LOSS [training: 0.05146909488470096 | validation: 0.018879882841810934]
	TIME [epoch: 8.87 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04324042003009766		[learning rate: 0.0027278]
		[batch 20/20] avg loss: 0.03606837410136089		[learning rate: 0.0027214]
	Learning Rate: 0.00272142
	LOSS [training: 0.03965439706572928 | validation: 0.0880323054722608]
	TIME [epoch: 8.86 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11575554756277869		[learning rate: 0.002715]
		[batch 20/20] avg loss: 0.05963706302512885		[learning rate: 0.0027087]
	Learning Rate: 0.00270866
	LOSS [training: 0.08769630529395375 | validation: 0.03646526105521808]
	TIME [epoch: 8.89 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/20] avg loss: 0.037895329240526146		[learning rate: 0.0027023]
		[batch 20/20] avg loss: 0.02352857374980413		[learning rate: 0.002696]
	Learning Rate: 0.00269597
	LOSS [training: 0.030711951495165136 | validation: 0.016487704021583425]
	TIME [epoch: 8.87 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/20] avg loss: 0.036011296402832835		[learning rate: 0.0026896]
		[batch 20/20] avg loss: 0.026462836457528106		[learning rate: 0.0026833]
	Learning Rate: 0.00268333
	LOSS [training: 0.031237066430180472 | validation: 0.010660147061771291]
	TIME [epoch: 8.87 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/20] avg loss: 0.046149566136148894		[learning rate: 0.002677]
		[batch 20/20] avg loss: 0.038891496497291705		[learning rate: 0.0026707]
	Learning Rate: 0.00267075
	LOSS [training: 0.0425205313167203 | validation: 0.020204384205752313]
	TIME [epoch: 8.87 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0539108135255581		[learning rate: 0.0026645]
		[batch 20/20] avg loss: 0.0550901424911288		[learning rate: 0.0026582]
	Learning Rate: 0.00265823
	LOSS [training: 0.054500478008343435 | validation: 0.028852710626772603]
	TIME [epoch: 8.86 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/20] avg loss: 0.036718814618964014		[learning rate: 0.002652]
		[batch 20/20] avg loss: 0.04308349685843641		[learning rate: 0.0026458]
	Learning Rate: 0.00264576
	LOSS [training: 0.0399011557387002 | validation: 0.03514889149382098]
	TIME [epoch: 8.89 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0519430577691531		[learning rate: 0.0026396]
		[batch 20/20] avg loss: 0.040943507270625186		[learning rate: 0.0026334]
	Learning Rate: 0.00263336
	LOSS [training: 0.04644328251988915 | validation: 0.014631113276750936]
	TIME [epoch: 8.87 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05845317169121711		[learning rate: 0.0026272]
		[batch 20/20] avg loss: 0.03958711135827261		[learning rate: 0.002621]
	Learning Rate: 0.00262101
	LOSS [training: 0.04902014152474487 | validation: 0.04808528071234575]
	TIME [epoch: 8.87 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026825796476018893		[learning rate: 0.0026149]
		[batch 20/20] avg loss: 0.03630369396676646		[learning rate: 0.0026087]
	Learning Rate: 0.00260873
	LOSS [training: 0.03156474522139268 | validation: 0.05013748517398683]
	TIME [epoch: 8.87 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/20] avg loss: 0.056492604262849674		[learning rate: 0.0026026]
		[batch 20/20] avg loss: 0.05343720928520111		[learning rate: 0.0025965]
	Learning Rate: 0.0025965
	LOSS [training: 0.05496490677402539 | validation: 0.025420310140439946]
	TIME [epoch: 8.86 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04468555952536815		[learning rate: 0.0025904]
		[batch 20/20] avg loss: 0.03760969526034598		[learning rate: 0.0025843]
	Learning Rate: 0.00258432
	LOSS [training: 0.041147627392857065 | validation: 0.06715295879292768]
	TIME [epoch: 8.9 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/20] avg loss: 0.040813959412564396		[learning rate: 0.0025783]
		[batch 20/20] avg loss: 0.07784331870136132		[learning rate: 0.0025722]
	Learning Rate: 0.00257221
	LOSS [training: 0.05932863905696286 | validation: 0.05108886518374426]
	TIME [epoch: 8.87 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05366864800130218		[learning rate: 0.0025662]
		[batch 20/20] avg loss: 0.03645041709144604		[learning rate: 0.0025601]
	Learning Rate: 0.00256015
	LOSS [training: 0.04505953254637411 | validation: 0.020272209102679167]
	TIME [epoch: 8.86 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020161249353098317		[learning rate: 0.0025541]
		[batch 20/20] avg loss: 0.036663766552058046		[learning rate: 0.0025481]
	Learning Rate: 0.00254815
	LOSS [training: 0.028412507952578193 | validation: 0.05057202149209418]
	TIME [epoch: 8.86 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/20] avg loss: 0.056442255989960576		[learning rate: 0.0025422]
		[batch 20/20] avg loss: 0.038489903057430774		[learning rate: 0.0025362]
	Learning Rate: 0.0025362
	LOSS [training: 0.04746607952369568 | validation: 0.013558532459120412]
	TIME [epoch: 8.87 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03513645797968566		[learning rate: 0.0025302]
		[batch 20/20] avg loss: 0.06477795950475816		[learning rate: 0.0025243]
	Learning Rate: 0.00252431
	LOSS [training: 0.049957208742221905 | validation: 0.06850263210412033]
	TIME [epoch: 8.89 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10825179312939318		[learning rate: 0.0025184]
		[batch 20/20] avg loss: 0.07426524231081237		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.09125851772010277 | validation: 0.0847822025051706]
	TIME [epoch: 8.86 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06855549144333276		[learning rate: 0.0025066]
		[batch 20/20] avg loss: 0.05022184845423382		[learning rate: 0.0025007]
	Learning Rate: 0.0025007
	LOSS [training: 0.0593886699487833 | validation: 0.08501673805875619]
	TIME [epoch: 8.86 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/20] avg loss: 0.056204781775605464		[learning rate: 0.0024948]
		[batch 20/20] avg loss: 0.03203963243326106		[learning rate: 0.002489]
	Learning Rate: 0.00248897
	LOSS [training: 0.04412220710443325 | validation: 0.02691794231723955]
	TIME [epoch: 8.87 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04723628929132048		[learning rate: 0.0024831]
		[batch 20/20] avg loss: 0.050719884184045515		[learning rate: 0.0024773]
	Learning Rate: 0.00247731
	LOSS [training: 0.048978086737682995 | validation: 0.050745781666009473]
	TIME [epoch: 8.89 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03321481147249866		[learning rate: 0.0024715]
		[batch 20/20] avg loss: 0.04253527236028822		[learning rate: 0.0024657]
	Learning Rate: 0.00246569
	LOSS [training: 0.037875041916393445 | validation: 0.018099757182599603]
	TIME [epoch: 8.87 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04211547855664103		[learning rate: 0.0024599]
		[batch 20/20] avg loss: 0.03276795739033419		[learning rate: 0.0024541]
	Learning Rate: 0.00245413
	LOSS [training: 0.037441717973487616 | validation: 0.01670317685873847]
	TIME [epoch: 8.87 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0417064577350286		[learning rate: 0.0024484]
		[batch 20/20] avg loss: 0.03588424931772653		[learning rate: 0.0024426]
	Learning Rate: 0.00244263
	LOSS [training: 0.03879535352637756 | validation: 0.04303367631495847]
	TIME [epoch: 8.87 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04572039829502542		[learning rate: 0.0024369]
		[batch 20/20] avg loss: 0.02330907667719611		[learning rate: 0.0024312]
	Learning Rate: 0.00243118
	LOSS [training: 0.034514737486110766 | validation: 0.02215749314302219]
	TIME [epoch: 8.87 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/20] avg loss: 0.046952571843082054		[learning rate: 0.0024255]
		[batch 20/20] avg loss: 0.02656868826379593		[learning rate: 0.0024198]
	Learning Rate: 0.00241978
	LOSS [training: 0.036760630053439 | validation: 0.01556867617238229]
	TIME [epoch: 8.9 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01973844924189122		[learning rate: 0.0024141]
		[batch 20/20] avg loss: 0.027525804216063765		[learning rate: 0.0024084]
	Learning Rate: 0.00240843
	LOSS [training: 0.023632126728977493 | validation: 0.039474519241081404]
	TIME [epoch: 8.87 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/20] avg loss: 0.049443594292293905		[learning rate: 0.0024028]
		[batch 20/20] avg loss: 0.030770348601720048		[learning rate: 0.0023971]
	Learning Rate: 0.00239714
	LOSS [training: 0.04010697144700697 | validation: 0.010653661334651607]
	TIME [epoch: 8.87 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/20] avg loss: 0.019597062647238876		[learning rate: 0.0023915]
		[batch 20/20] avg loss: 0.037097525942241485		[learning rate: 0.0023859]
	Learning Rate: 0.0023859
	LOSS [training: 0.028347294294740182 | validation: 0.027689258023060916]
	TIME [epoch: 8.86 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025323054569623256		[learning rate: 0.0023803]
		[batch 20/20] avg loss: 0.046007969977091404		[learning rate: 0.0023747]
	Learning Rate: 0.00237472
	LOSS [training: 0.03566551227335733 | validation: 0.016587778909328294]
	TIME [epoch: 8.87 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0333756241880017		[learning rate: 0.0023691]
		[batch 20/20] avg loss: 0.03142677580764143		[learning rate: 0.0023636]
	Learning Rate: 0.00236359
	LOSS [training: 0.03240119999782156 | validation: 0.07054153256683451]
	TIME [epoch: 8.89 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030175084510446305		[learning rate: 0.002358]
		[batch 20/20] avg loss: 0.11795756751431745		[learning rate: 0.0023525]
	Learning Rate: 0.00235251
	LOSS [training: 0.07406632601238188 | validation: 0.03034623076745149]
	TIME [epoch: 8.87 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02563130387001869		[learning rate: 0.002347]
		[batch 20/20] avg loss: 0.03331921029839906		[learning rate: 0.0023415]
	Learning Rate: 0.00234148
	LOSS [training: 0.029475257084208874 | validation: 0.04894671158898764]
	TIME [epoch: 8.87 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05809525466867621		[learning rate: 0.002336]
		[batch 20/20] avg loss: 0.02580961389529527		[learning rate: 0.0023305]
	Learning Rate: 0.0023305
	LOSS [training: 0.04195243428198575 | validation: 0.027232058334107974]
	TIME [epoch: 8.87 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03436676071717111		[learning rate: 0.002325]
		[batch 20/20] avg loss: 0.04593493188062794		[learning rate: 0.0023196]
	Learning Rate: 0.00231957
	LOSS [training: 0.04015084629889952 | validation: 0.02227310426195554]
	TIME [epoch: 8.89 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030940974380477167		[learning rate: 0.0023141]
		[batch 20/20] avg loss: 0.049998871258372775		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.04046992281942497 | validation: 0.04011885528951854]
	TIME [epoch: 8.87 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04919572604510742		[learning rate: 0.0023033]
		[batch 20/20] avg loss: 0.04427219197026567		[learning rate: 0.0022979]
	Learning Rate: 0.00229788
	LOSS [training: 0.046733959007686544 | validation: 0.0507653056357816]
	TIME [epoch: 8.87 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0680452985382802		[learning rate: 0.0022925]
		[batch 20/20] avg loss: 0.035332149365837826		[learning rate: 0.0022871]
	Learning Rate: 0.0022871
	LOSS [training: 0.05168872395205902 | validation: 0.012691352684029473]
	TIME [epoch: 8.86 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/20] avg loss: 0.034787886730156564		[learning rate: 0.0022817]
		[batch 20/20] avg loss: 0.05337269565958096		[learning rate: 0.0022764]
	Learning Rate: 0.00227638
	LOSS [training: 0.04408029119486877 | validation: 0.07250426258814963]
	TIME [epoch: 8.86 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04127613065383108		[learning rate: 0.002271]
		[batch 20/20] avg loss: 0.03041806397007371		[learning rate: 0.0022657]
	Learning Rate: 0.00226571
	LOSS [training: 0.03584709731195239 | validation: 0.05471963400823275]
	TIME [epoch: 8.89 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10475953257755959		[learning rate: 0.0022604]
		[batch 20/20] avg loss: 0.07116706140800924		[learning rate: 0.0022551]
	Learning Rate: 0.00225509
	LOSS [training: 0.0879632969927844 | validation: 0.0408314687649903]
	TIME [epoch: 8.87 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03218449558989157		[learning rate: 0.0022498]
		[batch 20/20] avg loss: 0.044185764634343		[learning rate: 0.0022445]
	Learning Rate: 0.00224451
	LOSS [training: 0.038185130112117285 | validation: 0.07423317071485226]
	TIME [epoch: 8.86 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03966635728747579		[learning rate: 0.0022392]
		[batch 20/20] avg loss: 0.05858682681493579		[learning rate: 0.002234]
	Learning Rate: 0.00223399
	LOSS [training: 0.04912659205120579 | validation: 0.08673785976575829]
	TIME [epoch: 8.87 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/20] avg loss: 0.054001271939863496		[learning rate: 0.0022287]
		[batch 20/20] avg loss: 0.052105714243910015		[learning rate: 0.0022235]
	Learning Rate: 0.00222352
	LOSS [training: 0.05305349309188676 | validation: 0.009226201265037495]
	TIME [epoch: 8.87 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/20] avg loss: 0.041064407713656555		[learning rate: 0.0022183]
		[batch 20/20] avg loss: 0.02702481249810676		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.034044610105881654 | validation: 0.017616919926242886]
	TIME [epoch: 8.88 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02642659917517488		[learning rate: 0.0022079]
		[batch 20/20] avg loss: 0.019513248128120306		[learning rate: 0.0022027]
	Learning Rate: 0.00220272
	LOSS [training: 0.022969923651647593 | validation: 0.01810655620724308]
	TIME [epoch: 8.87 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05107602353376152		[learning rate: 0.0021976]
		[batch 20/20] avg loss: 0.08859819656646566		[learning rate: 0.0021924]
	Learning Rate: 0.00219239
	LOSS [training: 0.06983711005011359 | validation: 0.023863912011375714]
	TIME [epoch: 8.86 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05443763327472477		[learning rate: 0.0021872]
		[batch 20/20] avg loss: 0.06106348961360307		[learning rate: 0.0021821]
	Learning Rate: 0.00218211
	LOSS [training: 0.05775056144416392 | validation: 0.031001100233082206]
	TIME [epoch: 8.87 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0419033348700265		[learning rate: 0.002177]
		[batch 20/20] avg loss: 0.0388663486971592		[learning rate: 0.0021719]
	Learning Rate: 0.00217188
	LOSS [training: 0.04038484178359286 | validation: 0.036220995178889374]
	TIME [epoch: 8.87 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05479109442055703		[learning rate: 0.0021668]
		[batch 20/20] avg loss: 0.028670902591040225		[learning rate: 0.0021617]
	Learning Rate: 0.0021617
	LOSS [training: 0.04173099850579863 | validation: 0.013421270242171305]
	TIME [epoch: 8.88 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06170033634244253		[learning rate: 0.0021566]
		[batch 20/20] avg loss: 0.044860561689435405		[learning rate: 0.0021516]
	Learning Rate: 0.00215157
	LOSS [training: 0.053280449015938966 | validation: 0.030041828802589307]
	TIME [epoch: 8.87 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03672291553054607		[learning rate: 0.0021465]
		[batch 20/20] avg loss: 0.03670299930313192		[learning rate: 0.0021415]
	Learning Rate: 0.00214148
	LOSS [training: 0.036712957416838984 | validation: 0.04534465624848273]
	TIME [epoch: 8.87 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03280775110913191		[learning rate: 0.0021365]
		[batch 20/20] avg loss: 0.023642816333412774		[learning rate: 0.0021314]
	Learning Rate: 0.00213144
	LOSS [training: 0.028225283721272344 | validation: 0.02705909207154852]
	TIME [epoch: 8.87 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03661265963754541		[learning rate: 0.0021264]
		[batch 20/20] avg loss: 0.024255991741278276		[learning rate: 0.0021214]
	Learning Rate: 0.00212145
	LOSS [training: 0.030434325689411845 | validation: 0.018806091681879016]
	TIME [epoch: 8.89 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/20] avg loss: 0.033152816826205474		[learning rate: 0.0021165]
		[batch 20/20] avg loss: 0.02911886050098611		[learning rate: 0.0021115]
	Learning Rate: 0.0021115
	LOSS [training: 0.031135838663595795 | validation: 0.08373471050098495]
	TIME [epoch: 8.87 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/20] avg loss: 0.038371756525571336		[learning rate: 0.0021065]
		[batch 20/20] avg loss: 0.03660276729522289		[learning rate: 0.0021016]
	Learning Rate: 0.0021016
	LOSS [training: 0.03748726191039712 | validation: 0.053966223195628826]
	TIME [epoch: 8.86 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07937145462108729		[learning rate: 0.0020967]
		[batch 20/20] avg loss: 0.0329311075742612		[learning rate: 0.0020918]
	Learning Rate: 0.00209175
	LOSS [training: 0.056151281097674255 | validation: 0.009066711929518391]
	TIME [epoch: 8.87 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03815756239629223		[learning rate: 0.0020868]
		[batch 20/20] avg loss: 0.07445825978661312		[learning rate: 0.0020819]
	Learning Rate: 0.00208195
	LOSS [training: 0.05630791109145268 | validation: 0.05019137234857016]
	TIME [epoch: 8.87 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/20] avg loss: 0.039215941389332605		[learning rate: 0.0020771]
		[batch 20/20] avg loss: 0.029221945787765845		[learning rate: 0.0020722]
	Learning Rate: 0.00207219
	LOSS [training: 0.034218943588549225 | validation: 0.04473783467886576]
	TIME [epoch: 8.89 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03415697834498187		[learning rate: 0.0020673]
		[batch 20/20] avg loss: 0.06793986210959356		[learning rate: 0.0020625]
	Learning Rate: 0.00206247
	LOSS [training: 0.051048420227287714 | validation: 0.17188845576488787]
	TIME [epoch: 8.88 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12030078589902923		[learning rate: 0.0020576]
		[batch 20/20] avg loss: 0.043206824599139264		[learning rate: 0.0020528]
	Learning Rate: 0.0020528
	LOSS [training: 0.08175380524908425 | validation: 0.0200902368876643]
	TIME [epoch: 8.88 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04589533851941152		[learning rate: 0.002048]
		[batch 20/20] avg loss: 0.051285259873320034		[learning rate: 0.0020432]
	Learning Rate: 0.00204318
	LOSS [training: 0.04859029919636577 | validation: 0.02684557763606792]
	TIME [epoch: 8.86 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0520331082982476		[learning rate: 0.0020384]
		[batch 20/20] avg loss: 0.03976193210962153		[learning rate: 0.0020336]
	Learning Rate: 0.0020336
	LOSS [training: 0.04589752020393457 | validation: 0.016840479418427746]
	TIME [epoch: 8.88 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027088931341765637		[learning rate: 0.0020288]
		[batch 20/20] avg loss: 0.06784935736779447		[learning rate: 0.0020241]
	Learning Rate: 0.00202407
	LOSS [training: 0.04746914435478006 | validation: 0.08685178547798347]
	TIME [epoch: 8.9 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/20] avg loss: 0.044912513821539934		[learning rate: 0.0020193]
		[batch 20/20] avg loss: 0.038691582196036724		[learning rate: 0.0020146]
	Learning Rate: 0.00201458
	LOSS [training: 0.041802048008788326 | validation: 0.02974961329478841]
	TIME [epoch: 8.87 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03552976328960044		[learning rate: 0.0020098]
		[batch 20/20] avg loss: 0.0559135321039288		[learning rate: 0.0020051]
	Learning Rate: 0.00200513
	LOSS [training: 0.04572164769676461 | validation: 0.05503480241374578]
	TIME [epoch: 8.88 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04299772866784718		[learning rate: 0.0020004]
		[batch 20/20] avg loss: 0.028887692179868744		[learning rate: 0.0019957]
	Learning Rate: 0.00199573
	LOSS [training: 0.03594271042385796 | validation: 0.0833112347589022]
	TIME [epoch: 8.87 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05890213066336414		[learning rate: 0.001991]
		[batch 20/20] avg loss: 0.04177684357569707		[learning rate: 0.0019864]
	Learning Rate: 0.00198637
	LOSS [training: 0.05033948711953061 | validation: 0.08206560801625216]
	TIME [epoch: 8.89 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0811889092835088		[learning rate: 0.0019817]
		[batch 20/20] avg loss: 0.053949970004843285		[learning rate: 0.0019771]
	Learning Rate: 0.00197706
	LOSS [training: 0.06756943964417603 | validation: 0.017027793834378253]
	TIME [epoch: 8.87 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0362549634614404		[learning rate: 0.0019724]
		[batch 20/20] avg loss: 0.047829967776012325		[learning rate: 0.0019678]
	Learning Rate: 0.00196779
	LOSS [training: 0.04204246561872636 | validation: 0.008020572766615428]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_356.pth
	Model improved!!!
EPOCH 357/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027477652479059145		[learning rate: 0.0019632]
		[batch 20/20] avg loss: 0.034032518548861475		[learning rate: 0.0019586]
	Learning Rate: 0.00195857
	LOSS [training: 0.030755085513960306 | validation: 0.017684397124731886]
	TIME [epoch: 8.87 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018717876028862795		[learning rate: 0.001954]
		[batch 20/20] avg loss: 0.01571683480555449		[learning rate: 0.0019494]
	Learning Rate: 0.00194939
	LOSS [training: 0.017217355417208643 | validation: 0.017253312895351768]
	TIME [epoch: 8.87 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022723170902588814		[learning rate: 0.0019448]
		[batch 20/20] avg loss: 0.033967704985307545		[learning rate: 0.0019402]
	Learning Rate: 0.00194025
	LOSS [training: 0.028345437943948178 | validation: 0.03589659536640827]
	TIME [epoch: 8.89 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0324573022374084		[learning rate: 0.0019357]
		[batch 20/20] avg loss: 0.04392412621333558		[learning rate: 0.0019312]
	Learning Rate: 0.00193115
	LOSS [training: 0.038190714225371986 | validation: 0.058036048617207306]
	TIME [epoch: 8.87 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03252655140941035		[learning rate: 0.0019266]
		[batch 20/20] avg loss: 0.0388959224625787		[learning rate: 0.0019221]
	Learning Rate: 0.0019221
	LOSS [training: 0.035711236935994525 | validation: 0.030082394925779826]
	TIME [epoch: 8.87 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021204135948873618		[learning rate: 0.0019176]
		[batch 20/20] avg loss: 0.01846563766548388		[learning rate: 0.0019131]
	Learning Rate: 0.00191309
	LOSS [training: 0.01983488680717875 | validation: 0.016980056032460056]
	TIME [epoch: 8.88 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025859132213802916		[learning rate: 0.0019086]
		[batch 20/20] avg loss: 0.014679488956690412		[learning rate: 0.0019041]
	Learning Rate: 0.00190412
	LOSS [training: 0.020269310585246662 | validation: 0.010160521033341472]
	TIME [epoch: 8.87 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/20] avg loss: 0.034171390467616865		[learning rate: 0.0018996]
		[batch 20/20] avg loss: 0.022270272978816875		[learning rate: 0.0018952]
	Learning Rate: 0.00189519
	LOSS [training: 0.028220831723216877 | validation: 0.021961556945768197]
	TIME [epoch: 8.89 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018406666646751748		[learning rate: 0.0018907]
		[batch 20/20] avg loss: 0.054809603860856614		[learning rate: 0.0018863]
	Learning Rate: 0.00188631
	LOSS [training: 0.036608135253804186 | validation: 0.025259299863471973]
	TIME [epoch: 8.87 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/20] avg loss: 0.039553142772326445		[learning rate: 0.0018819]
		[batch 20/20] avg loss: 0.040189093782653236		[learning rate: 0.0018775]
	Learning Rate: 0.00187746
	LOSS [training: 0.039871118277489834 | validation: 0.060849694440101375]
	TIME [epoch: 8.87 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/20] avg loss: 0.043272700581914146		[learning rate: 0.0018731]
		[batch 20/20] avg loss: 0.02060886317604531		[learning rate: 0.0018687]
	Learning Rate: 0.00186866
	LOSS [training: 0.031940781878979724 | validation: 0.01541718738285637]
	TIME [epoch: 8.87 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029480708229027104		[learning rate: 0.0018643]
		[batch 20/20] avg loss: 0.022594179568850372		[learning rate: 0.0018599]
	Learning Rate: 0.0018599
	LOSS [training: 0.02603744389893874 | validation: 0.03858488153239084]
	TIME [epoch: 8.89 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02842721630811783		[learning rate: 0.0018555]
		[batch 20/20] avg loss: 0.02689166202969797		[learning rate: 0.0018512]
	Learning Rate: 0.00185118
	LOSS [training: 0.027659439168907902 | validation: 0.03407395588115529]
	TIME [epoch: 8.87 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014697926855023653		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.023724124481835227		[learning rate: 0.0018425]
	Learning Rate: 0.0018425
	LOSS [training: 0.019211025668429447 | validation: 0.03002114992484093]
	TIME [epoch: 8.87 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/20] avg loss: 0.024936647797905487		[learning rate: 0.0018382]
		[batch 20/20] avg loss: 0.018893129048935888		[learning rate: 0.0018339]
	Learning Rate: 0.00183386
	LOSS [training: 0.02191488842342069 | validation: 0.01269685682625425]
	TIME [epoch: 8.87 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02337871305128942		[learning rate: 0.0018296]
		[batch 20/20] avg loss: 0.024140576914287684		[learning rate: 0.0018253]
	Learning Rate: 0.00182527
	LOSS [training: 0.02375964498278855 | validation: 0.02078965668077374]
	TIME [epoch: 8.88 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020379427854974715		[learning rate: 0.001821]
		[batch 20/20] avg loss: 0.027111105180312726		[learning rate: 0.0018167]
	Learning Rate: 0.00181671
	LOSS [training: 0.02374526651764372 | validation: 0.007043561741392441]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_373.pth
	Model improved!!!
EPOCH 374/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015493066791929948		[learning rate: 0.0018124]
		[batch 20/20] avg loss: 0.0488704614235031		[learning rate: 0.0018082]
	Learning Rate: 0.00180819
	LOSS [training: 0.032181764107716525 | validation: 0.033894297744400254]
	TIME [epoch: 8.87 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022340414525847223		[learning rate: 0.001804]
		[batch 20/20] avg loss: 0.014380583228121155		[learning rate: 0.0017997]
	Learning Rate: 0.00179972
	LOSS [training: 0.018360498876984193 | validation: 0.04196049493821083]
	TIME [epoch: 8.87 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01917175111742543		[learning rate: 0.0017955]
		[batch 20/20] avg loss: 0.016299694868450794		[learning rate: 0.0017913]
	Learning Rate: 0.00179128
	LOSS [training: 0.017735722992938113 | validation: 0.004586756425192431]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_376.pth
	Model improved!!!
EPOCH 377/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03197395747800909		[learning rate: 0.0017871]
		[batch 20/20] avg loss: 0.020163770419846582		[learning rate: 0.0017829]
	Learning Rate: 0.00178288
	LOSS [training: 0.02606886394892783 | validation: 0.023388388936649386]
	TIME [epoch: 8.87 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027556000183548007		[learning rate: 0.0017787]
		[batch 20/20] avg loss: 0.023925802699978856		[learning rate: 0.0017745]
	Learning Rate: 0.00177452
	LOSS [training: 0.025740901441763435 | validation: 0.042008271440817625]
	TIME [epoch: 8.89 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03442298632931014		[learning rate: 0.0017704]
		[batch 20/20] avg loss: 0.042501502254219135		[learning rate: 0.0017662]
	Learning Rate: 0.0017662
	LOSS [training: 0.03846224429176463 | validation: 0.009426036945073064]
	TIME [epoch: 8.88 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/20] avg loss: 0.016845396808368156		[learning rate: 0.0017621]
		[batch 20/20] avg loss: 0.04599292862433278		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.031419162716350466 | validation: 0.03195565067047551]
	TIME [epoch: 8.86 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02882716639938776		[learning rate: 0.0017538]
		[batch 20/20] avg loss: 0.03164279125274822		[learning rate: 0.0017497]
	Learning Rate: 0.00174968
	LOSS [training: 0.030234978826067987 | validation: 0.032096199704028876]
	TIME [epoch: 8.88 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02415022444219394		[learning rate: 0.0017456]
		[batch 20/20] avg loss: 0.03565650944692586		[learning rate: 0.0017415]
	Learning Rate: 0.00174148
	LOSS [training: 0.0299033669445599 | validation: 0.015347196356615078]
	TIME [epoch: 8.88 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/20] avg loss: 0.038098799846305646		[learning rate: 0.0017374]
		[batch 20/20] avg loss: 0.0440925567097048		[learning rate: 0.0017333]
	Learning Rate: 0.00173331
	LOSS [training: 0.04109567827800524 | validation: 0.02583878473146526]
	TIME [epoch: 8.89 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/20] avg loss: 0.024306464994776015		[learning rate: 0.0017292]
		[batch 20/20] avg loss: 0.031227219220593284		[learning rate: 0.0017252]
	Learning Rate: 0.00172519
	LOSS [training: 0.027766842107684653 | validation: 0.012858491733475254]
	TIME [epoch: 8.87 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01717834670572268		[learning rate: 0.0017211]
		[batch 20/20] avg loss: 0.029616446587512772		[learning rate: 0.0017171]
	Learning Rate: 0.0017171
	LOSS [training: 0.023397396646617726 | validation: 0.024130376902037984]
	TIME [epoch: 8.87 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023157013324147026		[learning rate: 0.0017131]
		[batch 20/20] avg loss: 0.025846864588462463		[learning rate: 0.0017091]
	Learning Rate: 0.00170905
	LOSS [training: 0.02450193895630474 | validation: 0.04169232665711264]
	TIME [epoch: 8.88 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026063824485103776		[learning rate: 0.001705]
		[batch 20/20] avg loss: 0.015612979591462916		[learning rate: 0.001701]
	Learning Rate: 0.00170104
	LOSS [training: 0.020838402038283348 | validation: 0.012129820543411378]
	TIME [epoch: 8.89 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02371444127811472		[learning rate: 0.001697]
		[batch 20/20] avg loss: 0.02438347522888782		[learning rate: 0.0016931]
	Learning Rate: 0.00169306
	LOSS [training: 0.024048958253501267 | validation: 0.009588012847622654]
	TIME [epoch: 8.89 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012028381224045228		[learning rate: 0.0016891]
		[batch 20/20] avg loss: 0.02170313363943912		[learning rate: 0.0016851]
	Learning Rate: 0.00168513
	LOSS [training: 0.016865757431742175 | validation: 0.012664807953829906]
	TIME [epoch: 8.87 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/20] avg loss: 0.019118366206249328		[learning rate: 0.0016812]
		[batch 20/20] avg loss: 0.02695829746204571		[learning rate: 0.0016772]
	Learning Rate: 0.00167723
	LOSS [training: 0.02303833183414752 | validation: 0.052249738539817014]
	TIME [epoch: 8.87 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/20] avg loss: 0.033030531241254796		[learning rate: 0.0016733]
		[batch 20/20] avg loss: 0.01777049394269753		[learning rate: 0.0016694]
	Learning Rate: 0.00166936
	LOSS [training: 0.02540051259197616 | validation: 0.0130760214787198]
	TIME [epoch: 8.87 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01386307834109569		[learning rate: 0.0016654]
		[batch 20/20] avg loss: 0.06377412945341228		[learning rate: 0.0016615]
	Learning Rate: 0.00166154
	LOSS [training: 0.03881860389725397 | validation: 0.039198227903497244]
	TIME [epoch: 8.9 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017538082117897986		[learning rate: 0.0016576]
		[batch 20/20] avg loss: 0.016120350166580154		[learning rate: 0.0016537]
	Learning Rate: 0.00165375
	LOSS [training: 0.01682921614223907 | validation: 0.030727875214786385]
	TIME [epoch: 8.88 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01835731280387635		[learning rate: 0.0016499]
		[batch 20/20] avg loss: 0.01613485659101778		[learning rate: 0.001646]
	Learning Rate: 0.001646
	LOSS [training: 0.017246084697447067 | validation: 0.03133182636651579]
	TIME [epoch: 8.88 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/20] avg loss: 0.016842374332731027		[learning rate: 0.0016421]
		[batch 20/20] avg loss: 0.042005920137114586		[learning rate: 0.0016383]
	Learning Rate: 0.00163828
	LOSS [training: 0.029424147234922805 | validation: 0.019817469526520547]
	TIME [epoch: 8.87 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02941842258725358		[learning rate: 0.0016344]
		[batch 20/20] avg loss: 0.03529144960220839		[learning rate: 0.0016306]
	Learning Rate: 0.0016306
	LOSS [training: 0.03235493609473098 | validation: 0.023499165738255706]
	TIME [epoch: 8.87 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01880446797915597		[learning rate: 0.0016268]
		[batch 20/20] avg loss: 0.02586783112990909		[learning rate: 0.001623]
	Learning Rate: 0.00162295
	LOSS [training: 0.02233614955453253 | validation: 0.012162059838638944]
	TIME [epoch: 8.9 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03410899052529698		[learning rate: 0.0016191]
		[batch 20/20] avg loss: 0.037949216462374466		[learning rate: 0.0016153]
	Learning Rate: 0.00161535
	LOSS [training: 0.03602910349383572 | validation: 0.01881176818319727]
	TIME [epoch: 8.87 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03679542282774985		[learning rate: 0.0016116]
		[batch 20/20] avg loss: 0.015740317173945813		[learning rate: 0.0016078]
	Learning Rate: 0.00160777
	LOSS [training: 0.026267870000847838 | validation: 0.05368586860244649]
	TIME [epoch: 8.86 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05394030046220668		[learning rate: 0.001604]
		[batch 20/20] avg loss: 0.07097517737605832		[learning rate: 0.0016002]
	Learning Rate: 0.00160023
	LOSS [training: 0.06245773891913249 | validation: 0.07848614210553458]
	TIME [epoch: 8.86 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06565353799773106		[learning rate: 0.0015965]
		[batch 20/20] avg loss: 0.028718813438155726		[learning rate: 0.0015927]
	Learning Rate: 0.00159273
	LOSS [training: 0.0471861757179434 | validation: 0.03285321112270066]
	TIME [epoch: 8.89 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02973575322310131		[learning rate: 0.001589]
		[batch 20/20] avg loss: 0.02089583198077457		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.02531579260193794 | validation: 0.015587114190151153]
	TIME [epoch: 8.87 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015644263747562264		[learning rate: 0.0015815]
		[batch 20/20] avg loss: 0.03148114529688224		[learning rate: 0.0015778]
	Learning Rate: 0.00157783
	LOSS [training: 0.02356270452222225 | validation: 0.005166505988119269]
	TIME [epoch: 8.87 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017228846620911103		[learning rate: 0.0015741]
		[batch 20/20] avg loss: 0.05035300789258447		[learning rate: 0.0015704]
	Learning Rate: 0.00157044
	LOSS [training: 0.03379092725674778 | validation: 0.05566610197931444]
	TIME [epoch: 8.87 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/20] avg loss: 0.035430952287479986		[learning rate: 0.0015668]
		[batch 20/20] avg loss: 0.03219438377859036		[learning rate: 0.0015631]
	Learning Rate: 0.00156307
	LOSS [training: 0.033812668033035176 | validation: 0.06271247037391346]
	TIME [epoch: 8.87 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03361811109441801		[learning rate: 0.0015594]
		[batch 20/20] avg loss: 0.013195730629801861		[learning rate: 0.0015557]
	Learning Rate: 0.00155575
	LOSS [training: 0.02340692086210993 | validation: 0.026748813135651653]
	TIME [epoch: 8.9 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025624352643704024		[learning rate: 0.0015521]
		[batch 20/20] avg loss: 0.02190528318574133		[learning rate: 0.0015485]
	Learning Rate: 0.00154845
	LOSS [training: 0.023764817914722677 | validation: 0.03198477706875714]
	TIME [epoch: 8.87 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028483350141687413		[learning rate: 0.0015448]
		[batch 20/20] avg loss: 0.010394592356365908		[learning rate: 0.0015412]
	Learning Rate: 0.00154119
	LOSS [training: 0.019438971249026663 | validation: 0.00817024696681255]
	TIME [epoch: 8.86 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01794989336381613		[learning rate: 0.0015376]
		[batch 20/20] avg loss: 0.02158124762514222		[learning rate: 0.001534]
	Learning Rate: 0.00153397
	LOSS [training: 0.019765570494479176 | validation: 0.008351444386132879]
	TIME [epoch: 8.87 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0097730267389604		[learning rate: 0.0015304]
		[batch 20/20] avg loss: 0.023241315738456454		[learning rate: 0.0015268]
	Learning Rate: 0.00152678
	LOSS [training: 0.016507171238708422 | validation: 0.012226537067499252]
	TIME [epoch: 8.87 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023112122282493097		[learning rate: 0.0015232]
		[batch 20/20] avg loss: 0.01837249114969346		[learning rate: 0.0015196]
	Learning Rate: 0.00151962
	LOSS [training: 0.020742306716093277 | validation: 0.026057668108456136]
	TIME [epoch: 8.89 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021963100235841145		[learning rate: 0.0015161]
		[batch 20/20] avg loss: 0.030095860327738692		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.02602948028178992 | validation: 0.0435900950060729]
	TIME [epoch: 8.86 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0313290343427189		[learning rate: 0.0015089]
		[batch 20/20] avg loss: 0.01570723485196512		[learning rate: 0.0015054]
	Learning Rate: 0.0015054
	LOSS [training: 0.023518134597342012 | validation: 0.01660420173590668]
	TIME [epoch: 8.86 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01499091165919173		[learning rate: 0.0015019]
		[batch 20/20] avg loss: 0.014435967136848119		[learning rate: 0.0014983]
	Learning Rate: 0.00149835
	LOSS [training: 0.014713439398019926 | validation: 0.034914676450720106]
	TIME [epoch: 8.86 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/20] avg loss: 0.024232392276294118		[learning rate: 0.0014948]
		[batch 20/20] avg loss: 0.009734404198983016		[learning rate: 0.0014913]
	Learning Rate: 0.00149132
	LOSS [training: 0.016983398237638565 | validation: 0.017206763557936756]
	TIME [epoch: 8.88 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/20] avg loss: 0.019034053718235362		[learning rate: 0.0014878]
		[batch 20/20] avg loss: 0.024377437347686777		[learning rate: 0.0014843]
	Learning Rate: 0.00148433
	LOSS [training: 0.02170574553296107 | validation: 0.021667281208194826]
	TIME [epoch: 8.87 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011998376754142729		[learning rate: 0.0014808]
		[batch 20/20] avg loss: 0.017091066858888847		[learning rate: 0.0014774]
	Learning Rate: 0.00147737
	LOSS [training: 0.014544721806515786 | validation: 0.021246996988432493]
	TIME [epoch: 8.86 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0273113792088575		[learning rate: 0.0014739]
		[batch 20/20] avg loss: 0.04445787252678911		[learning rate: 0.0014704]
	Learning Rate: 0.00147045
	LOSS [training: 0.0358846258678233 | validation: 0.04003260429734863]
	TIME [epoch: 8.86 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025490192831865793		[learning rate: 0.001467]
		[batch 20/20] avg loss: 0.025144350611330656		[learning rate: 0.0014636]
	Learning Rate: 0.00146355
	LOSS [training: 0.025317271721598228 | validation: 0.029828728878243192]
	TIME [epoch: 8.87 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0396864604614122		[learning rate: 0.0014601]
		[batch 20/20] avg loss: 0.014099231261802713		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.02689284586160746 | validation: 0.009944117572869806]
	TIME [epoch: 8.89 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/20] avg loss: 0.008424217977396741		[learning rate: 0.0014533]
		[batch 20/20] avg loss: 0.011279699931129986		[learning rate: 0.0014499]
	Learning Rate: 0.00144986
	LOSS [training: 0.009851958954263364 | validation: 0.004522248096905897]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_421.pth
	Model improved!!!
EPOCH 422/500:
	Training over batches...
		[batch 10/20] avg loss: 0.007504066111463861		[learning rate: 0.0014465]
		[batch 20/20] avg loss: 0.01992733793656897		[learning rate: 0.0014431]
	Learning Rate: 0.00144306
	LOSS [training: 0.013715702024016419 | validation: 0.01062154206945193]
	TIME [epoch: 8.89 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013434253820410769		[learning rate: 0.0014397]
		[batch 20/20] avg loss: 0.005941697192194539		[learning rate: 0.0014363]
	Learning Rate: 0.0014363
	LOSS [training: 0.009687975506302657 | validation: 0.010615143359525988]
	TIME [epoch: 8.89 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02986832420148059		[learning rate: 0.0014329]
		[batch 20/20] avg loss: 0.0281740033376769		[learning rate: 0.0014296]
	Learning Rate: 0.00142957
	LOSS [training: 0.029021163769578744 | validation: 0.03402790399719045]
	TIME [epoch: 8.89 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04059967378236332		[learning rate: 0.0014262]
		[batch 20/20] avg loss: 0.013249353374051049		[learning rate: 0.0014229]
	Learning Rate: 0.00142286
	LOSS [training: 0.026924513578207188 | validation: 0.0018373918786430859]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_425.pth
	Model improved!!!
EPOCH 426/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021266543949330065		[learning rate: 0.0014195]
		[batch 20/20] avg loss: 0.017384911125000617		[learning rate: 0.0014162]
	Learning Rate: 0.00141619
	LOSS [training: 0.019325727537165344 | validation: 0.007891124786951212]
	TIME [epoch: 8.89 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01710149977106455		[learning rate: 0.0014129]
		[batch 20/20] avg loss: 0.024451492404217397		[learning rate: 0.0014096]
	Learning Rate: 0.00140955
	LOSS [training: 0.020776496087640976 | validation: 0.013512497189650825]
	TIME [epoch: 8.89 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013323051628781623		[learning rate: 0.0014062]
		[batch 20/20] avg loss: 0.02058707209271742		[learning rate: 0.0014029]
	Learning Rate: 0.00140295
	LOSS [training: 0.01695506186074952 | validation: 0.017482083395454782]
	TIME [epoch: 8.89 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027343182557644164		[learning rate: 0.0013997]
		[batch 20/20] avg loss: 0.028967615337333046		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.028155398947488603 | validation: 0.024311596509534333]
	TIME [epoch: 8.91 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03405628287703223		[learning rate: 0.0013931]
		[batch 20/20] avg loss: 0.03293209765746083		[learning rate: 0.0013898]
	Learning Rate: 0.00138982
	LOSS [training: 0.033494190267246524 | validation: 0.026345013876749722]
	TIME [epoch: 8.89 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020874465596996777		[learning rate: 0.0013866]
		[batch 20/20] avg loss: 0.03290542491898433		[learning rate: 0.0013833]
	Learning Rate: 0.00138331
	LOSS [training: 0.026889945257990554 | validation: 0.12271974176828124]
	TIME [epoch: 8.89 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0486233979866336		[learning rate: 0.0013801]
		[batch 20/20] avg loss: 0.009783379468193963		[learning rate: 0.0013768]
	Learning Rate: 0.00137682
	LOSS [training: 0.029203388727413782 | validation: 0.008997736429966713]
	TIME [epoch: 8.89 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010074770277901024		[learning rate: 0.0013736]
		[batch 20/20] avg loss: 0.014196582048003822		[learning rate: 0.0013704]
	Learning Rate: 0.00137037
	LOSS [training: 0.012135676162952424 | validation: -0.00010504143822274666]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_433.pth
	Model improved!!!
EPOCH 434/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014615982437913805		[learning rate: 0.0013672]
		[batch 20/20] avg loss: 0.020630208293838347		[learning rate: 0.0013639]
	Learning Rate: 0.00136394
	LOSS [training: 0.017623095365876078 | validation: 0.009978826072339643]
	TIME [epoch: 8.91 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01740814606817565		[learning rate: 0.0013607]
		[batch 20/20] avg loss: 0.017157005444461627		[learning rate: 0.0013575]
	Learning Rate: 0.00135755
	LOSS [training: 0.017282575756318638 | validation: 0.0399973345986855]
	TIME [epoch: 8.89 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015540941183800496		[learning rate: 0.0013544]
		[batch 20/20] avg loss: 0.007988700815506612		[learning rate: 0.0013512]
	Learning Rate: 0.00135118
	LOSS [training: 0.011764820999653555 | validation: 0.019991413021332703]
	TIME [epoch: 8.89 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01761077401682445		[learning rate: 0.001348]
		[batch 20/20] avg loss: 0.026356979744556575		[learning rate: 0.0013448]
	Learning Rate: 0.00134485
	LOSS [training: 0.021983876880690516 | validation: 0.045946931834996325]
	TIME [epoch: 8.89 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021649515166304964		[learning rate: 0.0013417]
		[batch 20/20] avg loss: 0.013995939483951919		[learning rate: 0.0013385]
	Learning Rate: 0.00133854
	LOSS [training: 0.01782272732512844 | validation: 0.006607205493649661]
	TIME [epoch: 8.89 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012206683327105408		[learning rate: 0.0013354]
		[batch 20/20] avg loss: 0.02183830564918851		[learning rate: 0.0013323]
	Learning Rate: 0.00133227
	LOSS [training: 0.01702249448814696 | validation: 0.013038787266604533]
	TIME [epoch: 8.91 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011506920505449375		[learning rate: 0.0013291]
		[batch 20/20] avg loss: 0.013868991778114282		[learning rate: 0.001326]
	Learning Rate: 0.00132602
	LOSS [training: 0.012687956141781826 | validation: 0.04818583457376027]
	TIME [epoch: 8.89 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03498452840700361		[learning rate: 0.0013229]
		[batch 20/20] avg loss: 0.0398489866494284		[learning rate: 0.0013198]
	Learning Rate: 0.00131981
	LOSS [training: 0.03741675752821601 | validation: 0.05332979989538986]
	TIME [epoch: 8.89 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04674141932140167		[learning rate: 0.0013167]
		[batch 20/20] avg loss: 0.03213032257593834		[learning rate: 0.0013136]
	Learning Rate: 0.00131362
	LOSS [training: 0.03943587094867 | validation: 0.020863577667281162]
	TIME [epoch: 8.89 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04293107316109077		[learning rate: 0.0013105]
		[batch 20/20] avg loss: 0.054279982317740005		[learning rate: 0.0013075]
	Learning Rate: 0.00130746
	LOSS [training: 0.048605527739415386 | validation: 0.06446338543578897]
	TIME [epoch: 8.9 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0383240822081658		[learning rate: 0.0013044]
		[batch 20/20] avg loss: 0.028905653419500094		[learning rate: 0.0013013]
	Learning Rate: 0.00130133
	LOSS [training: 0.03361486781383295 | validation: 0.0249394216739014]
	TIME [epoch: 8.9 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026231847252020945		[learning rate: 0.0012983]
		[batch 20/20] avg loss: 0.016485075213714808		[learning rate: 0.0012952]
	Learning Rate: 0.00129523
	LOSS [training: 0.021358461232867876 | validation: 0.011526185449727274]
	TIME [epoch: 8.89 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011514563783386738		[learning rate: 0.0012922]
		[batch 20/20] avg loss: 0.020642713493539085		[learning rate: 0.0012892]
	Learning Rate: 0.00128916
	LOSS [training: 0.01607863863846291 | validation: 0.021188390812901907]
	TIME [epoch: 8.88 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/20] avg loss: 0.019030504830952928		[learning rate: 0.0012861]
		[batch 20/20] avg loss: 0.01695823830446581		[learning rate: 0.0012831]
	Learning Rate: 0.00128311
	LOSS [training: 0.017994371567709368 | validation: 0.012801078900708652]
	TIME [epoch: 8.89 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/20] avg loss: 0.009814627604600046		[learning rate: 0.0012801]
		[batch 20/20] avg loss: 0.013037843658094312		[learning rate: 0.0012771]
	Learning Rate: 0.0012771
	LOSS [training: 0.011426235631347178 | validation: 0.026102143616776343]
	TIME [epoch: 8.91 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018622350441675664		[learning rate: 0.0012741]
		[batch 20/20] avg loss: 0.029019735682146504		[learning rate: 0.0012711]
	Learning Rate: 0.00127111
	LOSS [training: 0.023821043061911084 | validation: 0.012964970562529172]
	TIME [epoch: 8.89 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01568645766642299		[learning rate: 0.0012681]
		[batch 20/20] avg loss: 0.008261092531166745		[learning rate: 0.0012652]
	Learning Rate: 0.00126515
	LOSS [training: 0.011973775098794869 | validation: 0.0033611487088895105]
	TIME [epoch: 8.89 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015476530062272129		[learning rate: 0.0012622]
		[batch 20/20] avg loss: 0.0022343049377458292		[learning rate: 0.0012592]
	Learning Rate: 0.00125922
	LOSS [training: 0.00885541750000898 | validation: 0.012518261364336954]
	TIME [epoch: 8.88 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010413295894969194		[learning rate: 0.0012563]
		[batch 20/20] avg loss: 0.013696654672805583		[learning rate: 0.0012533]
	Learning Rate: 0.00125332
	LOSS [training: 0.01205497528388739 | validation: 0.010164911123446578]
	TIME [epoch: 8.89 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030894110992452418		[learning rate: 0.0012504]
		[batch 20/20] avg loss: 0.030616113769807624		[learning rate: 0.0012474]
	Learning Rate: 0.00124744
	LOSS [training: 0.03075511238113001 | validation: 0.0294998263815856]
	TIME [epoch: 8.91 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028327886173098372		[learning rate: 0.0012445]
		[batch 20/20] avg loss: 0.02890564512972349		[learning rate: 0.0012416]
	Learning Rate: 0.00124159
	LOSS [training: 0.02861676565141093 | validation: 0.008430814331395014]
	TIME [epoch: 8.89 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01017684941968763		[learning rate: 0.0012387]
		[batch 20/20] avg loss: 0.02743607785468598		[learning rate: 0.0012358]
	Learning Rate: 0.00123577
	LOSS [training: 0.018806463637186806 | validation: 0.016779933860222408]
	TIME [epoch: 8.89 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015223272142843766		[learning rate: 0.0012329]
		[batch 20/20] avg loss: 0.008157447028559035		[learning rate: 0.00123]
	Learning Rate: 0.00122998
	LOSS [training: 0.011690359585701401 | validation: 0.024925469278634538]
	TIME [epoch: 8.89 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015602150865038064		[learning rate: 0.0012271]
		[batch 20/20] avg loss: 0.02106455340723255		[learning rate: 0.0012242]
	Learning Rate: 0.00122421
	LOSS [training: 0.01833335213613531 | validation: 0.013517962146036904]
	TIME [epoch: 8.9 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/20] avg loss: 0.003251680080079921		[learning rate: 0.0012213]
		[batch 20/20] avg loss: 0.01777679109890851		[learning rate: 0.0012185]
	Learning Rate: 0.00121847
	LOSS [training: 0.010514235589494216 | validation: 0.02659044422756008]
	TIME [epoch: 8.91 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018013854834141314		[learning rate: 0.0012156]
		[batch 20/20] avg loss: 0.017794580060106924		[learning rate: 0.0012128]
	Learning Rate: 0.00121276
	LOSS [training: 0.017904217447124112 | validation: 0.01246794057932238]
	TIME [epoch: 8.89 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027956627693216368		[learning rate: 0.0012099]
		[batch 20/20] avg loss: 0.03276677551856507		[learning rate: 0.0012071]
	Learning Rate: 0.00120708
	LOSS [training: 0.030361701605890724 | validation: 0.014700921967546375]
	TIME [epoch: 8.89 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017009320497575527		[learning rate: 0.0012042]
		[batch 20/20] avg loss: 0.020012921092887055		[learning rate: 0.0012014]
	Learning Rate: 0.00120142
	LOSS [training: 0.018511120795231286 | validation: 0.02023014234621059]
	TIME [epoch: 8.88 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/20] avg loss: 0.016209774187031376		[learning rate: 0.0011986]
		[batch 20/20] avg loss: 0.012079095191728634		[learning rate: 0.0011958]
	Learning Rate: 0.00119578
	LOSS [training: 0.014144434689380005 | validation: -0.00117786448669703]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_462.pth
	Model improved!!!
EPOCH 463/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013643890718734519		[learning rate: 0.001193]
		[batch 20/20] avg loss: 0.019661057370533513		[learning rate: 0.0011902]
	Learning Rate: 0.00119018
	LOSS [training: 0.016652474044634012 | validation: 0.010817094838708975]
	TIME [epoch: 8.89 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/20] avg loss: 0.016061021728206674		[learning rate: 0.0011874]
		[batch 20/20] avg loss: 0.012805404656457329		[learning rate: 0.0011846]
	Learning Rate: 0.0011846
	LOSS [training: 0.014433213192332001 | validation: 0.009378062751438291]
	TIME [epoch: 8.89 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011877431190433763		[learning rate: 0.0011818]
		[batch 20/20] avg loss: 0.011653746083215174		[learning rate: 0.001179]
	Learning Rate: 0.00117905
	LOSS [training: 0.01176558863682447 | validation: 0.014809525766812161]
	TIME [epoch: 8.89 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010515498556867718		[learning rate: 0.0011763]
		[batch 20/20] avg loss: 0.02194804924379728		[learning rate: 0.0011735]
	Learning Rate: 0.00117352
	LOSS [training: 0.016231773900332497 | validation: 0.016089612212929236]
	TIME [epoch: 8.89 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027932014729925785		[learning rate: 0.0011708]
		[batch 20/20] avg loss: 0.005107170389240817		[learning rate: 0.001168]
	Learning Rate: 0.00116802
	LOSS [training: 0.0165195925595833 | validation: 0.005878082087542982]
	TIME [epoch: 8.92 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010513798854723038		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.00827716777847719		[learning rate: 0.0011625]
	Learning Rate: 0.00116254
	LOSS [training: 0.009395483316600112 | validation: -0.004532806130434598]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_468.pth
	Model improved!!!
EPOCH 469/500:
	Training over batches...
		[batch 10/20] avg loss: 0.006720979127504996		[learning rate: 0.0011598]
		[batch 20/20] avg loss: 0.015337923174910678		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.011029451151207839 | validation: 0.028670863194408803]
	TIME [epoch: 8.89 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01244709307787242		[learning rate: 0.0011544]
		[batch 20/20] avg loss: 0.014765498109625047		[learning rate: 0.0011517]
	Learning Rate: 0.00115167
	LOSS [training: 0.01360629559374873 | validation: 0.02963457140194544]
	TIME [epoch: 8.89 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025563756097781925		[learning rate: 0.001149]
		[batch 20/20] avg loss: 0.0006171748873755124		[learning rate: 0.0011463]
	Learning Rate: 0.00114627
	LOSS [training: 0.013090465492578718 | validation: 0.013305348473044784]
	TIME [epoch: 8.89 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014154332156103738		[learning rate: 0.0011436]
		[batch 20/20] avg loss: 0.010659589683222042		[learning rate: 0.0011409]
	Learning Rate: 0.00114089
	LOSS [training: 0.012406960919662893 | validation: 0.014321653426931381]
	TIME [epoch: 8.91 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013259313134979894		[learning rate: 0.0011382]
		[batch 20/20] avg loss: 0.0020802525766242105		[learning rate: 0.0011355]
	Learning Rate: 0.00113554
	LOSS [training: 0.007669782855802052 | validation: -0.005511976990229022]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240214_171650/states/model_tr_study2_473.pth
	Model improved!!!
EPOCH 474/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013426675170889177		[learning rate: 0.0011329]
		[batch 20/20] avg loss: 0.005658815148931755		[learning rate: 0.0011302]
	Learning Rate: 0.00113022
	LOSS [training: 0.009542745159910465 | validation: 0.0009621042066877527]
	TIME [epoch: 8.88 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01956238411870816		[learning rate: 0.0011276]
		[batch 20/20] avg loss: 0.014863169981406535		[learning rate: 0.0011249]
	Learning Rate: 0.00112492
	LOSS [training: 0.01721277705005735 | validation: 0.01981539003351657]
	TIME [epoch: 8.88 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02022620169124923		[learning rate: 0.0011223]
		[batch 20/20] avg loss: 0.005921046602381283		[learning rate: 0.0011196]
	Learning Rate: 0.00111965
	LOSS [training: 0.013073624146815257 | validation: 0.016592740441372576]
	TIME [epoch: 8.9 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022032012881456495		[learning rate: 0.001117]
		[batch 20/20] avg loss: 0.012742978080589162		[learning rate: 0.0011144]
	Learning Rate: 0.0011144
	LOSS [training: 0.01738749548102283 | validation: 0.013731961641287073]
	TIME [epoch: 8.89 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/20] avg loss: 0.009469791635820396		[learning rate: 0.0011118]
		[batch 20/20] avg loss: 0.005604808319108898		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.0075372999774646465 | validation: -0.0028795322105362566]
	TIME [epoch: 8.88 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012385840027855838		[learning rate: 0.0011066]
		[batch 20/20] avg loss: 0.019172865657372924		[learning rate: 0.001104]
	Learning Rate: 0.00110397
	LOSS [training: 0.015779352842614384 | validation: 0.040418942962205266]
	TIME [epoch: 8.88 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011263107629200568		[learning rate: 0.0011014]
		[batch 20/20] avg loss: 0.010373214518196526		[learning rate: 0.0010988]
	Learning Rate: 0.0010988
	LOSS [training: 0.010818161073698549 | validation: 0.007099965774828038]
	TIME [epoch: 8.88 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/20] avg loss: 0.00928785197372072		[learning rate: 0.0010962]
		[batch 20/20] avg loss: 0.0044211696472465185		[learning rate: 0.0010936]
	Learning Rate: 0.00109365
	LOSS [training: 0.006854510810483619 | validation: 0.009487026701999721]
	TIME [epoch: 8.9 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011363957151278541		[learning rate: 0.0010911]
		[batch 20/20] avg loss: 0.017381568738701385		[learning rate: 0.0010885]
	Learning Rate: 0.00108852
	LOSS [training: 0.014372762944989964 | validation: 0.013409061680955148]
	TIME [epoch: 8.88 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/20] avg loss: 0.005090360118884841		[learning rate: 0.001086]
		[batch 20/20] avg loss: 0.004928979953103026		[learning rate: 0.0010834]
	Learning Rate: 0.00108342
	LOSS [training: 0.0050096700359939334 | validation: 0.02243646438307617]
	TIME [epoch: 8.88 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01464872901974742		[learning rate: 0.0010809]
		[batch 20/20] avg loss: 0.01549878388089564		[learning rate: 0.0010783]
	Learning Rate: 0.00107834
	LOSS [training: 0.015073756450321529 | validation: -0.0038771406935361585]
	TIME [epoch: 8.88 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02104806264781706		[learning rate: 0.0010758]
		[batch 20/20] avg loss: 0.003817853092225598		[learning rate: 0.0010733]
	Learning Rate: 0.00107328
	LOSS [training: 0.012432957870021327 | validation: 0.021310581672907548]
	TIME [epoch: 8.88 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017729661476293773		[learning rate: 0.0010708]
		[batch 20/20] avg loss: 0.016076060360515197		[learning rate: 0.0010683]
	Learning Rate: 0.00106825
	LOSS [training: 0.01690286091840449 | validation: 0.0063051244840507965]
	TIME [epoch: 8.9 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013643735852457192		[learning rate: 0.0010657]
		[batch 20/20] avg loss: 0.011183339098303564		[learning rate: 0.0010632]
	Learning Rate: 0.00106324
	LOSS [training: 0.012413537475380374 | validation: 0.01285720305873823]
	TIME [epoch: 8.88 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01637006284864694		[learning rate: 0.0010607]
		[batch 20/20] avg loss: 0.02390827442776223		[learning rate: 0.0010583]
	Learning Rate: 0.00105826
	LOSS [training: 0.02013916863820459 | validation: 0.02671574075006619]
	TIME [epoch: 8.87 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014276535184994266		[learning rate: 0.0010558]
		[batch 20/20] avg loss: 0.01140692515989189		[learning rate: 0.0010533]
	Learning Rate: 0.0010533
	LOSS [training: 0.012841730172443078 | validation: 0.015105458436392355]
	TIME [epoch: 8.88 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01674683487192068		[learning rate: 0.0010508]
		[batch 20/20] avg loss: 0.013437181393059439		[learning rate: 0.0010484]
	Learning Rate: 0.00104836
	LOSS [training: 0.015092008132490056 | validation: 0.010890506865845103]
	TIME [epoch: 8.9 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012073771266991813		[learning rate: 0.0010459]
		[batch 20/20] avg loss: 0.023685548932593205		[learning rate: 0.0010434]
	Learning Rate: 0.00104344
	LOSS [training: 0.017879660099792513 | validation: 0.00248630559854591]
	TIME [epoch: 8.88 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/20] avg loss: 0.006484381093909551		[learning rate: 0.001041]
		[batch 20/20] avg loss: 0.015625672384238544		[learning rate: 0.0010386]
	Learning Rate: 0.00103855
	LOSS [training: 0.01105502673907405 | validation: 0.019365503757988414]
	TIME [epoch: 8.88 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/20] avg loss: 0.009755446636046857		[learning rate: 0.0010361]
		[batch 20/20] avg loss: 0.006573261123860706		[learning rate: 0.0010337]
	Learning Rate: 0.00103368
	LOSS [training: 0.008164353879953781 | validation: -0.005482552800071594]
	TIME [epoch: 8.87 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028404819749657036		[learning rate: 0.0010313]
		[batch 20/20] avg loss: 0.016943657027185595		[learning rate: 0.0010288]
	Learning Rate: 0.00102884
	LOSS [training: 0.022674238388421315 | validation: 0.004798363743713249]
	TIME [epoch: 8.88 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/20] avg loss: 0.004978126785876132		[learning rate: 0.0010264]
		[batch 20/20] avg loss: 0.01656084551604021		[learning rate: 0.001024]
	Learning Rate: 0.00102401
	LOSS [training: 0.010769486150958173 | validation: 0.0043396216068051245]
	TIME [epoch: 8.9 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011586647779791773		[learning rate: 0.0010216]
		[batch 20/20] avg loss: 0.008283620747573953		[learning rate: 0.0010192]
	Learning Rate: 0.00101921
	LOSS [training: 0.009935134263682862 | validation: 0.016797856557326428]
	TIME [epoch: 8.89 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012727045199517575		[learning rate: 0.0010168]
		[batch 20/20] avg loss: 0.02297928301230892		[learning rate: 0.0010144]
	Learning Rate: 0.00101444
	LOSS [training: 0.01785316410591325 | validation: 0.011519901874338162]
	TIME [epoch: 8.91 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/20] avg loss: 0.007086140999129953		[learning rate: 0.0010121]
		[batch 20/20] avg loss: 0.012692809806516292		[learning rate: 0.0010097]
	Learning Rate: 0.00100968
	LOSS [training: 0.009889475402823124 | validation: -0.0006044445517800826]
	TIME [epoch: 8.92 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010147658845741949		[learning rate: 0.0010073]
		[batch 20/20] avg loss: 0.014926113272273986		[learning rate: 0.0010049]
	Learning Rate: 0.00100495
	LOSS [training: 0.012536886059007967 | validation: 0.012517845777641116]
	TIME [epoch: 8.9 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010400011191493636		[learning rate: 0.0010026]
		[batch 20/20] avg loss: 0.013015047535298002		[learning rate: 0.0010002]
	Learning Rate: 0.00100023
	LOSS [training: 0.01170752936339582 | validation: 0.004657408944162181]
	TIME [epoch: 8.93 sec]
Finished training in 4505.259 seconds.
