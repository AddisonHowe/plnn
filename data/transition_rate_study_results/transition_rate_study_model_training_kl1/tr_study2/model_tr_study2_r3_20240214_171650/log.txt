Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r3', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3468101207

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/20] avg loss: 8.8500956730458		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.555721176094897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.20290842457035 | validation: 6.99560400578557]
	TIME [epoch: 49.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/20] avg loss: 6.4884764584078045		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.5573198267744095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.022898142591108 | validation: 5.097936037294238]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/20] avg loss: 4.368037788134649		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.9066629843541287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.637350386244389 | validation: 3.3431052422540053]
	TIME [epoch: 8.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/20] avg loss: 2.839587589569853		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.604143076458119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7218653330139864 | validation: 2.2671164892871296]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/20] avg loss: 2.504844736499237		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.414295387233952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.459570061866594 | validation: 2.126925453721908]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/20] avg loss: 2.3637172525902823		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.3029966656836223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3333569591369527 | validation: 1.7989132767907816]
	TIME [epoch: 8.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/20] avg loss: 2.400785874610487		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.097992370207439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.249389122408963 | validation: 1.96755670428454]
	TIME [epoch: 8.79 sec]
EPOCH 8/500:
	Training over batches...
		[batch 10/20] avg loss: 2.143378265765848		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.839967983449855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.991673124607851 | validation: 1.4374780838435761]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/20] avg loss: 2.324346751514177		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7565155869075326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0404311692108545 | validation: 1.4423545531130673]
	TIME [epoch: 8.77 sec]
EPOCH 10/500:
	Training over batches...
		[batch 10/20] avg loss: 1.505784706832407		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.8423395492982073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6740621280653074 | validation: 1.3620352634437791]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4754117425414826		[learning rate: 0.0099789]
		[batch 20/20] avg loss: 1.3545214281749005		[learning rate: 0.0099555]
	Learning Rate: 0.00995546
	LOSS [training: 1.4149665853581914 | validation: 2.0189385653499423]
	TIME [epoch: 8.77 sec]
EPOCH 12/500:
	Training over batches...
		[batch 10/20] avg loss: 1.327046691231586		[learning rate: 0.0099321]
		[batch 20/20] avg loss: 1.4548996256833133		[learning rate: 0.0099088]
	Learning Rate: 0.00990879
	LOSS [training: 1.3909731584574498 | validation: 1.05720849713554]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5504635683603807		[learning rate: 0.0098855]
		[batch 20/20] avg loss: 1.062077283764205		[learning rate: 0.0098623]
	Learning Rate: 0.00986233
	LOSS [training: 1.3062704260622926 | validation: 0.6180978906389045]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3375427407910017		[learning rate: 0.0098392]
		[batch 20/20] avg loss: 0.933410344637098		[learning rate: 0.0098161]
	Learning Rate: 0.0098161
	LOSS [training: 1.1354765427140499 | validation: 1.9284878540249415]
	TIME [epoch: 8.78 sec]
EPOCH 15/500:
	Training over batches...
		[batch 10/20] avg loss: 1.163752221344701		[learning rate: 0.0097931]
		[batch 20/20] avg loss: 0.9620126648893486		[learning rate: 0.0097701]
	Learning Rate: 0.00977008
	LOSS [training: 1.0628824431170245 | validation: 1.6817841106364122]
	TIME [epoch: 8.77 sec]
EPOCH 16/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9948593071357731		[learning rate: 0.0097471]
		[batch 20/20] avg loss: 0.8680496789798386		[learning rate: 0.0097243]
	Learning Rate: 0.00972427
	LOSS [training: 0.9314544930578057 | validation: 0.7175498523049431]
	TIME [epoch: 8.75 sec]
EPOCH 17/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7984378955619063		[learning rate: 0.0097015]
		[batch 20/20] avg loss: 0.8140716064425912		[learning rate: 0.0096787]
	Learning Rate: 0.00967868
	LOSS [training: 0.8062547510022486 | validation: 0.5975312580481583]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9362380119860877		[learning rate: 0.009656]
		[batch 20/20] avg loss: 0.7961734447930098		[learning rate: 0.0096333]
	Learning Rate: 0.00963331
	LOSS [training: 0.8662057283895486 | validation: 0.4468119089863573]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7534417910087438		[learning rate: 0.0096107]
		[batch 20/20] avg loss: 0.7787748020588339		[learning rate: 0.0095881]
	Learning Rate: 0.00958815
	LOSS [training: 0.7661082965337886 | validation: 0.8555296366871991]
	TIME [epoch: 8.76 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6486344116435173		[learning rate: 0.0095656]
		[batch 20/20] avg loss: 0.6080283866988314		[learning rate: 0.0095432]
	Learning Rate: 0.0095432
	LOSS [training: 0.6283313991711743 | validation: 1.1973116223511417]
	TIME [epoch: 8.78 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/20] avg loss: 0.716126566559236		[learning rate: 0.0095208]
		[batch 20/20] avg loss: 0.6111135355881604		[learning rate: 0.0094985]
	Learning Rate: 0.00949846
	LOSS [training: 0.663620051073698 | validation: 0.44892052916433367]
	TIME [epoch: 8.77 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5626280513584387		[learning rate: 0.0094762]
		[batch 20/20] avg loss: 0.6328765580096194		[learning rate: 0.0094539]
	Learning Rate: 0.00945393
	LOSS [training: 0.5977523046840292 | validation: 0.35309795173346725]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5636555361105617		[learning rate: 0.0094317]
		[batch 20/20] avg loss: 0.6333722914905626		[learning rate: 0.0094096]
	Learning Rate: 0.00940961
	LOSS [training: 0.5985139138005622 | validation: 0.42173163360110255]
	TIME [epoch: 8.79 sec]
EPOCH 24/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5972835546712394		[learning rate: 0.0093875]
		[batch 20/20] avg loss: 0.5710395209685063		[learning rate: 0.0093655]
	Learning Rate: 0.00936549
	LOSS [training: 0.5841615378198729 | validation: 0.35325826319625087]
	TIME [epoch: 8.77 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4942113005380471		[learning rate: 0.0093435]
		[batch 20/20] avg loss: 0.5232028038268508		[learning rate: 0.0093216]
	Learning Rate: 0.00932159
	LOSS [training: 0.508707052182449 | validation: 0.687253866774272]
	TIME [epoch: 8.77 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6946469286667786		[learning rate: 0.0092997]
		[batch 20/20] avg loss: 0.5908935147030493		[learning rate: 0.0092779]
	Learning Rate: 0.00927788
	LOSS [training: 0.642770221684914 | validation: 0.5005020143451314]
	TIME [epoch: 8.77 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5757884115879305		[learning rate: 0.0092561]
		[batch 20/20] avg loss: 0.5114853592485495		[learning rate: 0.0092344]
	Learning Rate: 0.00923439
	LOSS [training: 0.54363688541824 | validation: 0.3816830679699922]
	TIME [epoch: 8.77 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4845505465278978		[learning rate: 0.0092127]
		[batch 20/20] avg loss: 0.6249052094589397		[learning rate: 0.0091911]
	Learning Rate: 0.0091911
	LOSS [training: 0.5547278779934187 | validation: 0.532338945138874]
	TIME [epoch: 8.78 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4591889607101421		[learning rate: 0.0091695]
		[batch 20/20] avg loss: 0.4371687572030156		[learning rate: 0.009148]
	Learning Rate: 0.00914801
	LOSS [training: 0.4481788589565789 | validation: 0.40255351966375097]
	TIME [epoch: 8.78 sec]
EPOCH 30/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4679208150564421		[learning rate: 0.0091265]
		[batch 20/20] avg loss: 0.4490208202957267		[learning rate: 0.0091051]
	Learning Rate: 0.00910512
	LOSS [training: 0.45847081767608433 | validation: 0.49594746537224726]
	TIME [epoch: 8.76 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/20] avg loss: 0.48868072526839673		[learning rate: 0.0090838]
		[batch 20/20] avg loss: 0.45097406054037165		[learning rate: 0.0090624]
	Learning Rate: 0.00906243
	LOSS [training: 0.46982739290438424 | validation: 0.34807033183441155]
	TIME [epoch: 8.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 10/20] avg loss: 0.41204651784191093		[learning rate: 0.0090412]
		[batch 20/20] avg loss: 0.6666660079901615		[learning rate: 0.0090199]
	Learning Rate: 0.00901995
	LOSS [training: 0.5393562629160361 | validation: 0.8453946693091214]
	TIME [epoch: 8.73 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44446424959959296		[learning rate: 0.0089988]
		[batch 20/20] avg loss: 0.3646067245306091		[learning rate: 0.0089777]
	Learning Rate: 0.00897766
	LOSS [training: 0.40453548706510106 | validation: 0.29665119496789877]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4533525117103969		[learning rate: 0.0089566]
		[batch 20/20] avg loss: 0.40691954202079855		[learning rate: 0.0089356]
	Learning Rate: 0.00893557
	LOSS [training: 0.4301360268655977 | validation: 0.42948571183835055]
	TIME [epoch: 8.73 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4838924008469057		[learning rate: 0.0089146]
		[batch 20/20] avg loss: 0.45862943921350274		[learning rate: 0.0088937]
	Learning Rate: 0.00889368
	LOSS [training: 0.4712609200302042 | validation: 0.3951123143827081]
	TIME [epoch: 8.73 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4289206712119145		[learning rate: 0.0088728]
		[batch 20/20] avg loss: 0.527678995879551		[learning rate: 0.008852]
	Learning Rate: 0.00885199
	LOSS [training: 0.4782998335457327 | validation: 0.4166103574010415]
	TIME [epoch: 8.74 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4487163645678981		[learning rate: 0.0088312]
		[batch 20/20] avg loss: 0.42065111102084174		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.43468373779436986 | validation: 0.2525739728871068]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36510123060650496		[learning rate: 0.0087898]
		[batch 20/20] avg loss: 0.3987243256393269		[learning rate: 0.0087692]
	Learning Rate: 0.00876918
	LOSS [training: 0.38191277812291585 | validation: 0.3054633017936594]
	TIME [epoch: 8.77 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5850116059042684		[learning rate: 0.0087486]
		[batch 20/20] avg loss: 0.33243649576580137		[learning rate: 0.0087281]
	Learning Rate: 0.00872807
	LOSS [training: 0.45872405083503487 | validation: 0.295554743506648]
	TIME [epoch: 8.74 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3654283814711747		[learning rate: 0.0087076]
		[batch 20/20] avg loss: 0.27733651155060773		[learning rate: 0.0086872]
	Learning Rate: 0.00868715
	LOSS [training: 0.32138244651089126 | validation: 0.24317320572594034]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4446785299977294		[learning rate: 0.0086668]
		[batch 20/20] avg loss: 0.34759736046942236		[learning rate: 0.0086464]
	Learning Rate: 0.00864643
	LOSS [training: 0.39613794523357587 | validation: 0.32199510087117333]
	TIME [epoch: 8.75 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2674093282646732		[learning rate: 0.0086261]
		[batch 20/20] avg loss: 0.8345646163384506		[learning rate: 0.0086059]
	Learning Rate: 0.00860589
	LOSS [training: 0.5509869723015619 | validation: 0.3017909759537643]
	TIME [epoch: 8.74 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29245839939307017		[learning rate: 0.0085857]
		[batch 20/20] avg loss: 0.3738149357320264		[learning rate: 0.0085655]
	Learning Rate: 0.00856555
	LOSS [training: 0.3331366675625483 | validation: 0.749754326904725]
	TIME [epoch: 8.77 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3188816026137916		[learning rate: 0.0085454]
		[batch 20/20] avg loss: 0.3072357878710509		[learning rate: 0.0085254]
	Learning Rate: 0.00852539
	LOSS [training: 0.3130586952424212 | validation: 0.2381473838061944]
	TIME [epoch: 8.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_44.pth
	Model improved!!!
EPOCH 45/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3865042652794147		[learning rate: 0.0085054]
		[batch 20/20] avg loss: 0.45061603734590544		[learning rate: 0.0084854]
	Learning Rate: 0.00848542
	LOSS [training: 0.4185601513126601 | validation: 0.2887316840060059]
	TIME [epoch: 8.75 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26150995413790734		[learning rate: 0.0084655]
		[batch 20/20] avg loss: 0.2979785972741359		[learning rate: 0.0084456]
	Learning Rate: 0.00844564
	LOSS [training: 0.2797442757060217 | validation: 0.16595304491033325]
	TIME [epoch: 8.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3063240918999318		[learning rate: 0.0084258]
		[batch 20/20] avg loss: 0.23560408648599857		[learning rate: 0.008406]
	Learning Rate: 0.00840605
	LOSS [training: 0.27096408919296516 | validation: 0.25263647080996193]
	TIME [epoch: 8.77 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28311470145000117		[learning rate: 0.0083863]
		[batch 20/20] avg loss: 0.3040587867288259		[learning rate: 0.0083666]
	Learning Rate: 0.00836664
	LOSS [training: 0.29358674408941354 | validation: 0.12421441855135004]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_48.pth
	Model improved!!!
EPOCH 49/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1916304832133584		[learning rate: 0.008347]
		[batch 20/20] avg loss: 0.309014693985239		[learning rate: 0.0083274]
	Learning Rate: 0.00832742
	LOSS [training: 0.25032258859929873 | validation: 0.23864902880622652]
	TIME [epoch: 8.78 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24963654872711225		[learning rate: 0.0083079]
		[batch 20/20] avg loss: 0.18416796299152488		[learning rate: 0.0082884]
	Learning Rate: 0.00828838
	LOSS [training: 0.21690225585931855 | validation: 0.14756317205254826]
	TIME [epoch: 8.76 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24375059557569895		[learning rate: 0.0082689]
		[batch 20/20] avg loss: 0.280550069046477		[learning rate: 0.0082495]
	Learning Rate: 0.00824952
	LOSS [training: 0.262150332311088 | validation: 0.08761594014528351]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2520724301086858		[learning rate: 0.0082302]
		[batch 20/20] avg loss: 0.416555528935624		[learning rate: 0.0082108]
	Learning Rate: 0.00821084
	LOSS [training: 0.3343139795221549 | validation: 0.0846067760047595]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1998821862194378		[learning rate: 0.0081916]
		[batch 20/20] avg loss: 0.2281069957784382		[learning rate: 0.0081723]
	Learning Rate: 0.00817235
	LOSS [training: 0.21399459099893803 | validation: 0.15547772520138298]
	TIME [epoch: 8.78 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1452136842796658		[learning rate: 0.0081532]
		[batch 20/20] avg loss: 0.3084226348599687		[learning rate: 0.008134]
	Learning Rate: 0.00813404
	LOSS [training: 0.22681815956981718 | validation: 0.29884025290566274]
	TIME [epoch: 8.79 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2847276236357638		[learning rate: 0.0081149]
		[batch 20/20] avg loss: 0.2989587133843442		[learning rate: 0.0080959]
	Learning Rate: 0.0080959
	LOSS [training: 0.29184316851005404 | validation: 0.19375150301999444]
	TIME [epoch: 8.78 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34149163490695494		[learning rate: 0.0080769]
		[batch 20/20] avg loss: 0.21277280900924747		[learning rate: 0.0080579]
	Learning Rate: 0.00805795
	LOSS [training: 0.2771322219581013 | validation: 0.1164285805054586]
	TIME [epoch: 8.78 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2079182941121777		[learning rate: 0.008039]
		[batch 20/20] avg loss: 0.24002181990176222		[learning rate: 0.0080202]
	Learning Rate: 0.00802017
	LOSS [training: 0.22397005700696998 | validation: 0.2555345642597495]
	TIME [epoch: 8.76 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22352488049578248		[learning rate: 0.0080013]
		[batch 20/20] avg loss: 0.253298880076735		[learning rate: 0.0079826]
	Learning Rate: 0.00798257
	LOSS [training: 0.2384118802862587 | validation: 0.34571735323347774]
	TIME [epoch: 8.77 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24119379926892873		[learning rate: 0.0079638]
		[batch 20/20] avg loss: 0.18589946302618204		[learning rate: 0.0079451]
	Learning Rate: 0.00794515
	LOSS [training: 0.2135466311475554 | validation: 0.11214430671129101]
	TIME [epoch: 8.79 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3465541641884232		[learning rate: 0.0079265]
		[batch 20/20] avg loss: 0.20173095928296517		[learning rate: 0.0079079]
	Learning Rate: 0.0079079
	LOSS [training: 0.2741425617356942 | validation: 0.16122790129628292]
	TIME [epoch: 8.77 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2166302955814004		[learning rate: 0.0078893]
		[batch 20/20] avg loss: 0.3740551914258547		[learning rate: 0.0078708]
	Learning Rate: 0.00787083
	LOSS [training: 0.2953427435036275 | validation: 0.548939129620311]
	TIME [epoch: 8.77 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2605829505508404		[learning rate: 0.0078524]
		[batch 20/20] avg loss: 0.17371396458223262		[learning rate: 0.0078339]
	Learning Rate: 0.00783393
	LOSS [training: 0.2171484575665366 | validation: 0.2128226317751725]
	TIME [epoch: 8.77 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2000503046926104		[learning rate: 0.0078155]
		[batch 20/20] avg loss: 0.32675931681715986		[learning rate: 0.0077972]
	Learning Rate: 0.0077972
	LOSS [training: 0.2634048107548851 | validation: 0.4593689568074061]
	TIME [epoch: 8.79 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25195605724382625		[learning rate: 0.0077789]
		[batch 20/20] avg loss: 0.23078678078688228		[learning rate: 0.0077606]
	Learning Rate: 0.00776065
	LOSS [training: 0.24137141901535425 | validation: 0.16776843066136013]
	TIME [epoch: 8.77 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17758714611135323		[learning rate: 0.0077424]
		[batch 20/20] avg loss: 0.19296883051319508		[learning rate: 0.0077243]
	Learning Rate: 0.00772426
	LOSS [training: 0.1852779883122741 | validation: 0.15391329725231045]
	TIME [epoch: 8.78 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29466857143109126		[learning rate: 0.0077061]
		[batch 20/20] avg loss: 0.19863629444582617		[learning rate: 0.0076881]
	Learning Rate: 0.00768805
	LOSS [training: 0.24665243293845873 | validation: 0.7243772582936507]
	TIME [epoch: 8.76 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29208635126598836		[learning rate: 0.00767]
		[batch 20/20] avg loss: 0.3285281688936836		[learning rate: 0.007652]
	Learning Rate: 0.00765201
	LOSS [training: 0.310307260079836 | validation: 0.2693194979929917]
	TIME [epoch: 8.77 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/20] avg loss: 0.47287431347216746		[learning rate: 0.0076341]
		[batch 20/20] avg loss: 0.28057591250127956		[learning rate: 0.0076161]
	Learning Rate: 0.00761614
	LOSS [training: 0.3767251129867235 | validation: 0.18673254821498325]
	TIME [epoch: 8.78 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1995128614708168		[learning rate: 0.0075983]
		[batch 20/20] avg loss: 0.1911422929214505		[learning rate: 0.0075804]
	Learning Rate: 0.00758043
	LOSS [training: 0.19532757719613364 | validation: 0.17711073347993278]
	TIME [epoch: 8.8 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22128637601638199		[learning rate: 0.0075626]
		[batch 20/20] avg loss: 0.23122150090973773		[learning rate: 0.0075449]
	Learning Rate: 0.00754489
	LOSS [training: 0.22625393846305983 | validation: 0.34680779091934333]
	TIME [epoch: 8.77 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24394849958207548		[learning rate: 0.0075272]
		[batch 20/20] avg loss: 0.1915304824096064		[learning rate: 0.0075095]
	Learning Rate: 0.00750952
	LOSS [training: 0.21773949099584092 | validation: 0.1258406392159062]
	TIME [epoch: 8.76 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3867400352291958		[learning rate: 0.0074919]
		[batch 20/20] avg loss: 0.15378281477367897		[learning rate: 0.0074743]
	Learning Rate: 0.00747431
	LOSS [training: 0.2702614250014374 | validation: 0.1339972336161841]
	TIME [epoch: 8.77 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16143486410071609		[learning rate: 0.0074568]
		[batch 20/20] avg loss: 0.16050409199867482		[learning rate: 0.0074393]
	Learning Rate: 0.00743927
	LOSS [training: 0.16096947804969544 | validation: 0.1947889423117661]
	TIME [epoch: 8.79 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29502022518469084		[learning rate: 0.0074218]
		[batch 20/20] avg loss: 0.26313855253211055		[learning rate: 0.0074044]
	Learning Rate: 0.0074044
	LOSS [training: 0.2790793888584008 | validation: 0.11637662343639295]
	TIME [epoch: 8.79 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18349468417411416		[learning rate: 0.007387]
		[batch 20/20] avg loss: 0.13521273115638105		[learning rate: 0.0073697]
	Learning Rate: 0.00736969
	LOSS [training: 0.15935370766524756 | validation: 0.09901508081969453]
	TIME [epoch: 8.78 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24509617472791553		[learning rate: 0.0073524]
		[batch 20/20] avg loss: 0.17942655205941743		[learning rate: 0.0073351]
	Learning Rate: 0.00733514
	LOSS [training: 0.21226136339366647 | validation: 0.24328135457853495]
	TIME [epoch: 8.77 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13337864310480146		[learning rate: 0.0073179]
		[batch 20/20] avg loss: 0.15934426311175598		[learning rate: 0.0073007]
	Learning Rate: 0.00730075
	LOSS [training: 0.14636145310827875 | validation: 0.22751511471305352]
	TIME [epoch: 8.77 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16708036720865263		[learning rate: 0.0072836]
		[batch 20/20] avg loss: 0.19738019499397774		[learning rate: 0.0072665]
	Learning Rate: 0.00726652
	LOSS [training: 0.18223028110131517 | validation: 0.17824340483316226]
	TIME [epoch: 8.78 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19158267652085165		[learning rate: 0.0072495]
		[batch 20/20] avg loss: 0.16179881419219455		[learning rate: 0.0072325]
	Learning Rate: 0.00723246
	LOSS [training: 0.1766907453565231 | validation: 0.14599640935926045]
	TIME [epoch: 8.76 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14834965186860455		[learning rate: 0.0072155]
		[batch 20/20] avg loss: 0.3769695369535509		[learning rate: 0.0071985]
	Learning Rate: 0.00719855
	LOSS [training: 0.2626595944110778 | validation: 0.09538491490912304]
	TIME [epoch: 8.76 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19711157262722373		[learning rate: 0.0071817]
		[batch 20/20] avg loss: 0.10756847294449287		[learning rate: 0.0071648]
	Learning Rate: 0.0071648
	LOSS [training: 0.1523400227858583 | validation: 0.10845822602456921]
	TIME [epoch: 8.75 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13839253256842982		[learning rate: 0.007148]
		[batch 20/20] avg loss: 0.0917771433109037		[learning rate: 0.0071312]
	Learning Rate: 0.00713121
	LOSS [training: 0.11508483793966676 | validation: 0.19727508618664244]
	TIME [epoch: 8.76 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14740703680372125		[learning rate: 0.0071145]
		[batch 20/20] avg loss: 0.4770563725145812		[learning rate: 0.0070978]
	Learning Rate: 0.00709778
	LOSS [training: 0.3122317046591512 | validation: 0.07987226471778786]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12944176803447555		[learning rate: 0.0070811]
		[batch 20/20] avg loss: 0.12744551462420378		[learning rate: 0.0070645]
	Learning Rate: 0.0070645
	LOSS [training: 0.12844364132933966 | validation: 0.0992928200806626]
	TIME [epoch: 8.77 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19108034961888057		[learning rate: 0.0070479]
		[batch 20/20] avg loss: 0.1847851693209291		[learning rate: 0.0070314]
	Learning Rate: 0.00703138
	LOSS [training: 0.1879327594699048 | validation: 0.07345751544745732]
	TIME [epoch: 8.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19393913794331516		[learning rate: 0.0070149]
		[batch 20/20] avg loss: 0.18720891438693105		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.1905740261651231 | validation: 0.09679238219268782]
	TIME [epoch: 8.75 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15561145412557786		[learning rate: 0.006982]
		[batch 20/20] avg loss: 0.14934257719512		[learning rate: 0.0069656]
	Learning Rate: 0.00696561
	LOSS [training: 0.15247701566034894 | validation: 0.10670792041744298]
	TIME [epoch: 9.36 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3939418462657204		[learning rate: 0.0069493]
		[batch 20/20] avg loss: 0.14825585388033036		[learning rate: 0.006933]
	Learning Rate: 0.00693295
	LOSS [training: 0.27109885007302537 | validation: 0.18534559295514805]
	TIME [epoch: 8.79 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19071920029158934		[learning rate: 0.0069167]
		[batch 20/20] avg loss: 0.13379737086080687		[learning rate: 0.0069005]
	Learning Rate: 0.00690045
	LOSS [training: 0.1622582855761981 | validation: 0.2255406483744548]
	TIME [epoch: 8.77 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19692246230567823		[learning rate: 0.0068843]
		[batch 20/20] avg loss: 0.18007656394909546		[learning rate: 0.0068681]
	Learning Rate: 0.0068681
	LOSS [training: 0.1884995131273869 | validation: 0.15827595048467066]
	TIME [epoch: 8.77 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16201269492864684		[learning rate: 0.006852]
		[batch 20/20] avg loss: 0.13087036167615224		[learning rate: 0.0068359]
	Learning Rate: 0.0068359
	LOSS [training: 0.1464415283023995 | validation: 0.08107914479142579]
	TIME [epoch: 8.76 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14666605087657383		[learning rate: 0.0068199]
		[batch 20/20] avg loss: 0.10377869981798904		[learning rate: 0.0068039]
	Learning Rate: 0.00680386
	LOSS [training: 0.12522237534728142 | validation: 0.13269570586379165]
	TIME [epoch: 8.76 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15206029478918956		[learning rate: 0.0067879]
		[batch 20/20] avg loss: 0.1278246543308996		[learning rate: 0.006772]
	Learning Rate: 0.00677196
	LOSS [training: 0.13994247456004455 | validation: 0.09987651236785958]
	TIME [epoch: 8.77 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1287503455574434		[learning rate: 0.0067561]
		[batch 20/20] avg loss: 0.14617348393526047		[learning rate: 0.0067402]
	Learning Rate: 0.00674021
	LOSS [training: 0.13746191474635194 | validation: 0.125748992124921]
	TIME [epoch: 8.76 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13485960330561897		[learning rate: 0.0067244]
		[batch 20/20] avg loss: 0.15823688465505226		[learning rate: 0.0067086]
	Learning Rate: 0.00670861
	LOSS [training: 0.1465482439803356 | validation: 0.12534900842716853]
	TIME [epoch: 8.76 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15430492288561096		[learning rate: 0.0066929]
		[batch 20/20] avg loss: 0.10704479678168673		[learning rate: 0.0066772]
	Learning Rate: 0.00667716
	LOSS [training: 0.13067485983364882 | validation: 0.10893717289223381]
	TIME [epoch: 8.76 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1529596073918444		[learning rate: 0.0066615]
		[batch 20/20] avg loss: 0.1286848573340038		[learning rate: 0.0066459]
	Learning Rate: 0.00664586
	LOSS [training: 0.14082223236292413 | validation: 0.1647286549984635]
	TIME [epoch: 8.76 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1353732382175938		[learning rate: 0.0066303]
		[batch 20/20] avg loss: 0.17902700368562913		[learning rate: 0.0066147]
	Learning Rate: 0.0066147
	LOSS [training: 0.15720012095161148 | validation: 0.10311035052011754]
	TIME [epoch: 8.78 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10749291498493745		[learning rate: 0.0065992]
		[batch 20/20] avg loss: 0.16808143693053434		[learning rate: 0.0065837]
	Learning Rate: 0.00658369
	LOSS [training: 0.13778717595773587 | validation: 0.2243457180950931]
	TIME [epoch: 8.76 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2680206872186087		[learning rate: 0.0065682]
		[batch 20/20] avg loss: 0.15071395192538922		[learning rate: 0.0065528]
	Learning Rate: 0.00655282
	LOSS [training: 0.2093673195719989 | validation: 0.15524224508456913]
	TIME [epoch: 8.75 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11205280225345045		[learning rate: 0.0065374]
		[batch 20/20] avg loss: 0.14433596979984997		[learning rate: 0.0065221]
	Learning Rate: 0.0065221
	LOSS [training: 0.1281943860266502 | validation: 0.1264795246518232]
	TIME [epoch: 8.77 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14433002447664345		[learning rate: 0.0065068]
		[batch 20/20] avg loss: 0.1334475255476646		[learning rate: 0.0064915]
	Learning Rate: 0.00649153
	LOSS [training: 0.13888877501215402 | validation: 0.09093832172257404]
	TIME [epoch: 8.76 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11197752630635646		[learning rate: 0.0064763]
		[batch 20/20] avg loss: 0.16230722120643598		[learning rate: 0.0064611]
	Learning Rate: 0.0064611
	LOSS [training: 0.1371423737563962 | validation: 0.040772729830713166]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_103.pth
	Model improved!!!
EPOCH 104/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09294311206621327		[learning rate: 0.0064459]
		[batch 20/20] avg loss: 0.14699569946213703		[learning rate: 0.0064308]
	Learning Rate: 0.0064308
	LOSS [training: 0.11996940576417517 | validation: 0.10718877007713407]
	TIME [epoch: 8.78 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16881740429049047		[learning rate: 0.0064157]
		[batch 20/20] avg loss: 0.11284890706332824		[learning rate: 0.0064007]
	Learning Rate: 0.00640066
	LOSS [training: 0.1408331556769093 | validation: 0.12241668871228689]
	TIME [epoch: 8.78 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10689050853959241		[learning rate: 0.0063856]
		[batch 20/20] avg loss: 0.13969558951068609		[learning rate: 0.0063706]
	Learning Rate: 0.00637065
	LOSS [training: 0.1232930490251392 | validation: 0.07353688232447059]
	TIME [epoch: 8.78 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10282434446525641		[learning rate: 0.0063557]
		[batch 20/20] avg loss: 0.14513812258058992		[learning rate: 0.0063408]
	Learning Rate: 0.00634078
	LOSS [training: 0.12398123352292316 | validation: 0.08494536781091473]
	TIME [epoch: 8.79 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1846368107981159		[learning rate: 0.0063259]
		[batch 20/20] avg loss: 0.12475188148830382		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.1546943461432099 | validation: 0.08822484298619167]
	TIME [epoch: 8.79 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12977809245700245		[learning rate: 0.0062962]
		[batch 20/20] avg loss: 0.11341619333318957		[learning rate: 0.0062815]
	Learning Rate: 0.00628147
	LOSS [training: 0.12159714289509602 | validation: 0.07111010246843137]
	TIME [epoch: 8.79 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08614630560773084		[learning rate: 0.0062667]
		[batch 20/20] avg loss: 0.12708892033384828		[learning rate: 0.006252]
	Learning Rate: 0.00625202
	LOSS [training: 0.10661761297078956 | validation: 0.1375237155429828]
	TIME [epoch: 8.8 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21943160644352355		[learning rate: 0.0062373]
		[batch 20/20] avg loss: 0.13280985016942856		[learning rate: 0.0062227]
	Learning Rate: 0.00622271
	LOSS [training: 0.17612072830647602 | validation: 0.0631695955283696]
	TIME [epoch: 8.79 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1113390509411158		[learning rate: 0.0062081]
		[batch 20/20] avg loss: 0.10775366502808133		[learning rate: 0.0061935]
	Learning Rate: 0.00619354
	LOSS [training: 0.10954635798459858 | validation: 0.08395686473119439]
	TIME [epoch: 8.77 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23192833056499634		[learning rate: 0.006179]
		[batch 20/20] avg loss: 0.1415330994336676		[learning rate: 0.0061645]
	Learning Rate: 0.0061645
	LOSS [training: 0.18673071499933197 | validation: 0.10028616457659892]
	TIME [epoch: 8.8 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1102333281964791		[learning rate: 0.00615]
		[batch 20/20] avg loss: 0.13014913314526902		[learning rate: 0.0061356]
	Learning Rate: 0.0061356
	LOSS [training: 0.12019123067087405 | validation: 0.09589637283523601]
	TIME [epoch: 8.78 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15872998808136		[learning rate: 0.0061212]
		[batch 20/20] avg loss: 0.17859636439824275		[learning rate: 0.0061068]
	Learning Rate: 0.00610684
	LOSS [training: 0.16866317623980137 | validation: 0.08417728387369185]
	TIME [epoch: 8.8 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08595358794028898		[learning rate: 0.0060925]
		[batch 20/20] avg loss: 0.09553449706471416		[learning rate: 0.0060782]
	Learning Rate: 0.00607821
	LOSS [training: 0.09074404250250157 | validation: 0.11144201973807666]
	TIME [epoch: 8.79 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08258585366718546		[learning rate: 0.0060639]
		[batch 20/20] avg loss: 0.08777912974777875		[learning rate: 0.0060497]
	Learning Rate: 0.00604971
	LOSS [training: 0.0851824917074821 | validation: 0.08074628519769605]
	TIME [epoch: 8.81 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09481545262292763		[learning rate: 0.0060355]
		[batch 20/20] avg loss: 0.11782962576672988		[learning rate: 0.0060213]
	Learning Rate: 0.00602135
	LOSS [training: 0.10632253919482874 | validation: 0.13378307909544018]
	TIME [epoch: 8.8 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09176837965726195		[learning rate: 0.0060072]
		[batch 20/20] avg loss: 0.11912834382141413		[learning rate: 0.0059931]
	Learning Rate: 0.00599312
	LOSS [training: 0.10544836173933807 | validation: 0.20485471984217857]
	TIME [epoch: 8.78 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2138306033892711		[learning rate: 0.0059791]
		[batch 20/20] avg loss: 0.11693273303242072		[learning rate: 0.005965]
	Learning Rate: 0.00596502
	LOSS [training: 0.16538166821084593 | validation: 0.09234354812241126]
	TIME [epoch: 8.78 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12050030855759897		[learning rate: 0.005951]
		[batch 20/20] avg loss: 0.1259708648042491		[learning rate: 0.0059371]
	Learning Rate: 0.00593706
	LOSS [training: 0.12323558668092408 | validation: 0.07121914291568893]
	TIME [epoch: 8.78 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0959152089128051		[learning rate: 0.0059231]
		[batch 20/20] avg loss: 0.22710105428801652		[learning rate: 0.0059092]
	Learning Rate: 0.00590923
	LOSS [training: 0.1615081316004108 | validation: 0.051135925628915446]
	TIME [epoch: 8.83 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09912461319739799		[learning rate: 0.0058954]
		[batch 20/20] avg loss: 0.14080755480203383		[learning rate: 0.0058815]
	Learning Rate: 0.00588152
	LOSS [training: 0.11996608399971591 | validation: 0.0928114298543612]
	TIME [epoch: 8.79 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12295127093832872		[learning rate: 0.0058677]
		[batch 20/20] avg loss: 0.09497010784423013		[learning rate: 0.0058539]
	Learning Rate: 0.00585395
	LOSS [training: 0.10896068939127942 | validation: 0.05982873050315504]
	TIME [epoch: 8.78 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10462940648800609		[learning rate: 0.0058402]
		[batch 20/20] avg loss: 0.11985303673997753		[learning rate: 0.0058265]
	Learning Rate: 0.00582651
	LOSS [training: 0.11224122161399183 | validation: 0.11984756530450691]
	TIME [epoch: 8.78 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11201101741207906		[learning rate: 0.0058128]
		[batch 20/20] avg loss: 0.10739258142973569		[learning rate: 0.0057992]
	Learning Rate: 0.00579919
	LOSS [training: 0.10970179942090737 | validation: 0.07088309119764212]
	TIME [epoch: 8.8 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11970910774799896		[learning rate: 0.0057856]
		[batch 20/20] avg loss: 0.10252912719364674		[learning rate: 0.005772]
	Learning Rate: 0.005772
	LOSS [training: 0.11111911747082286 | validation: 0.06488324826498351]
	TIME [epoch: 8.78 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12442097413207118		[learning rate: 0.0057585]
		[batch 20/20] avg loss: 0.11310698237149319		[learning rate: 0.0057449]
	Learning Rate: 0.00574494
	LOSS [training: 0.11876397825178217 | validation: 0.06345317815592376]
	TIME [epoch: 8.78 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12473363312816706		[learning rate: 0.0057315]
		[batch 20/20] avg loss: 0.12389609037896805		[learning rate: 0.005718]
	Learning Rate: 0.00571801
	LOSS [training: 0.12431486175356754 | validation: 0.09153333267466615]
	TIME [epoch: 8.78 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11136067157765131		[learning rate: 0.0057046]
		[batch 20/20] avg loss: 0.12556427778224014		[learning rate: 0.0056912]
	Learning Rate: 0.0056912
	LOSS [training: 0.11846247467994572 | validation: 0.05559922258955895]
	TIME [epoch: 8.78 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10164235971863986		[learning rate: 0.0056778]
		[batch 20/20] avg loss: 0.12292950335321522		[learning rate: 0.0056645]
	Learning Rate: 0.00566452
	LOSS [training: 0.11228593153592756 | validation: 0.0332208487395121]
	TIME [epoch: 8.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_131.pth
	Model improved!!!
EPOCH 132/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07175176225570706		[learning rate: 0.0056512]
		[batch 20/20] avg loss: 0.32220603843358625		[learning rate: 0.005638]
	Learning Rate: 0.00563797
	LOSS [training: 0.19697890034464666 | validation: 0.10620241574883796]
	TIME [epoch: 8.81 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12076422678441581		[learning rate: 0.0056247]
		[batch 20/20] avg loss: 0.09602099837306423		[learning rate: 0.0056115]
	Learning Rate: 0.00561153
	LOSS [training: 0.10839261257874003 | validation: 0.130583646366459]
	TIME [epoch: 8.8 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12293330356037627		[learning rate: 0.0055984]
		[batch 20/20] avg loss: 0.11428877926141272		[learning rate: 0.0055852]
	Learning Rate: 0.00558523
	LOSS [training: 0.11861104141089449 | validation: 0.07137226562136656]
	TIME [epoch: 8.78 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08349729607619838		[learning rate: 0.0055721]
		[batch 20/20] avg loss: 0.10470156539636603		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.09409943073628221 | validation: 0.022904131020298413]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_135.pth
	Model improved!!!
EPOCH 136/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0878243797038328		[learning rate: 0.005546]
		[batch 20/20] avg loss: 0.0998247424558584		[learning rate: 0.005533]
	Learning Rate: 0.00553298
	LOSS [training: 0.0938245610798456 | validation: 0.0437023774743977]
	TIME [epoch: 8.8 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07885517572182475		[learning rate: 0.00552]
		[batch 20/20] avg loss: 0.08735707628991528		[learning rate: 0.005507]
	Learning Rate: 0.00550704
	LOSS [training: 0.08310612600587002 | validation: 0.04527051182850512]
	TIME [epoch: 8.84 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09589112944033795		[learning rate: 0.0054941]
		[batch 20/20] avg loss: 0.0972112425836639		[learning rate: 0.0054812]
	Learning Rate: 0.00548122
	LOSS [training: 0.09655118601200093 | validation: 0.0477055960176392]
	TIME [epoch: 8.83 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07409609247588309		[learning rate: 0.0054684]
		[batch 20/20] avg loss: 0.07259565028525108		[learning rate: 0.0054555]
	Learning Rate: 0.00545553
	LOSS [training: 0.07334587138056708 | validation: 0.029297926675955585]
	TIME [epoch: 8.83 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09162697099632539		[learning rate: 0.0054427]
		[batch 20/20] avg loss: 0.1838888557481653		[learning rate: 0.00543]
	Learning Rate: 0.00542995
	LOSS [training: 0.13775791337224533 | validation: 0.12458916681488855]
	TIME [epoch: 8.83 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07547637760754741		[learning rate: 0.0054172]
		[batch 20/20] avg loss: 0.07922750954308429		[learning rate: 0.0054045]
	Learning Rate: 0.00540449
	LOSS [training: 0.07735194357531586 | validation: 0.17103756307631032]
	TIME [epoch: 8.83 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09308430264271408		[learning rate: 0.0053918]
		[batch 20/20] avg loss: 0.09997339155604153		[learning rate: 0.0053792]
	Learning Rate: 0.00537916
	LOSS [training: 0.0965288470993778 | validation: 0.13379785059076005]
	TIME [epoch: 8.85 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23590240831536263		[learning rate: 0.0053665]
		[batch 20/20] avg loss: 0.09144851429346065		[learning rate: 0.0053539]
	Learning Rate: 0.00535394
	LOSS [training: 0.1636754613044116 | validation: 0.04818719462800348]
	TIME [epoch: 8.83 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1016026456497325		[learning rate: 0.0053414]
		[batch 20/20] avg loss: 0.09366206355591024		[learning rate: 0.0053288]
	Learning Rate: 0.00532884
	LOSS [training: 0.09763235460282135 | validation: 0.09714710833024884]
	TIME [epoch: 8.83 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12995802181391697		[learning rate: 0.0053163]
		[batch 20/20] avg loss: 0.0884659212946379		[learning rate: 0.0053039]
	Learning Rate: 0.00530386
	LOSS [training: 0.10921197155427745 | validation: 0.07270087845184205]
	TIME [epoch: 8.81 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07777033035026529		[learning rate: 0.0052914]
		[batch 20/20] avg loss: 0.09702269417792943		[learning rate: 0.005279]
	Learning Rate: 0.00527899
	LOSS [training: 0.08739651226409736 | validation: 0.06819412882246191]
	TIME [epoch: 8.84 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09320794558765441		[learning rate: 0.0052666]
		[batch 20/20] avg loss: 0.12233292531997889		[learning rate: 0.0052542]
	Learning Rate: 0.00525424
	LOSS [training: 0.10777043545381666 | validation: 0.07522139573153735]
	TIME [epoch: 8.84 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07350011080678029		[learning rate: 0.0052419]
		[batch 20/20] avg loss: 0.09211567428802099		[learning rate: 0.0052296]
	Learning Rate: 0.00522961
	LOSS [training: 0.08280789254740063 | validation: 0.09404408734698662]
	TIME [epoch: 8.82 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09593965212315214		[learning rate: 0.0052173]
		[batch 20/20] avg loss: 0.08853592705758344		[learning rate: 0.0052051]
	Learning Rate: 0.00520509
	LOSS [training: 0.0922377895903678 | validation: 0.07040344132705068]
	TIME [epoch: 8.83 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09898531830538118		[learning rate: 0.0051929]
		[batch 20/20] avg loss: 0.09175988124352462		[learning rate: 0.0051807]
	Learning Rate: 0.00518069
	LOSS [training: 0.0953725997744529 | validation: 0.03372858288317374]
	TIME [epoch: 8.84 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1481504158292769		[learning rate: 0.0051685]
		[batch 20/20] avg loss: 0.11244625316767576		[learning rate: 0.0051564]
	Learning Rate: 0.0051564
	LOSS [training: 0.1302983344984763 | validation: 0.07608875240223203]
	TIME [epoch: 8.85 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06767185365397592		[learning rate: 0.0051443]
		[batch 20/20] avg loss: 0.07588353319435118		[learning rate: 0.0051322]
	Learning Rate: 0.00513223
	LOSS [training: 0.07177769342416357 | validation: 0.12670476673627323]
	TIME [epoch: 8.83 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07450671812834234		[learning rate: 0.0051202]
		[batch 20/20] avg loss: 0.07873249037674682		[learning rate: 0.0051082]
	Learning Rate: 0.00510817
	LOSS [training: 0.07661960425254459 | validation: 0.0169318523900293]
	TIME [epoch: 8.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_153.pth
	Model improved!!!
EPOCH 154/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08300219394676722		[learning rate: 0.0050962]
		[batch 20/20] avg loss: 0.0851400369546838		[learning rate: 0.0050842]
	Learning Rate: 0.00508422
	LOSS [training: 0.0840711154507255 | validation: 0.02445397102775256]
	TIME [epoch: 8.8 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05892182330646001		[learning rate: 0.0050723]
		[batch 20/20] avg loss: 0.0893430323937457		[learning rate: 0.0050604]
	Learning Rate: 0.00506039
	LOSS [training: 0.07413242785010285 | validation: 0.10272008092127474]
	TIME [epoch: 8.81 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08734406446447908		[learning rate: 0.0050485]
		[batch 20/20] avg loss: 0.061385547944689936		[learning rate: 0.0050367]
	Learning Rate: 0.00503666
	LOSS [training: 0.07436480620458451 | validation: 0.08357924894319364]
	TIME [epoch: 8.85 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30763438487318895		[learning rate: 0.0050248]
		[batch 20/20] avg loss: 0.1730199286120505		[learning rate: 0.005013]
	Learning Rate: 0.00501305
	LOSS [training: 0.24032715674261967 | validation: 0.16396088942730064]
	TIME [epoch: 8.82 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13744075384934434		[learning rate: 0.0050013]
		[batch 20/20] avg loss: 0.07882341170269552		[learning rate: 0.0049895]
	Learning Rate: 0.00498955
	LOSS [training: 0.10813208277601993 | validation: 0.1295862820049402]
	TIME [epoch: 8.83 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1028252621142132		[learning rate: 0.0049778]
		[batch 20/20] avg loss: 0.08116982100051083		[learning rate: 0.0049662]
	Learning Rate: 0.00496616
	LOSS [training: 0.09199754155736203 | validation: 0.07735996048711523]
	TIME [epoch: 8.82 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13921693896989257		[learning rate: 0.0049545]
		[batch 20/20] avg loss: 0.05659273474230682		[learning rate: 0.0049429]
	Learning Rate: 0.00494287
	LOSS [training: 0.09790483685609969 | validation: 0.1116534975304791]
	TIME [epoch: 8.8 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09617305818153864		[learning rate: 0.0049313]
		[batch 20/20] avg loss: 0.209807682037354		[learning rate: 0.0049197]
	Learning Rate: 0.0049197
	LOSS [training: 0.15299037010944633 | validation: 0.162680701041375]
	TIME [epoch: 8.86 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16206624801155833		[learning rate: 0.0049082]
		[batch 20/20] avg loss: 0.10164368901525714		[learning rate: 0.0048966]
	Learning Rate: 0.00489664
	LOSS [training: 0.13185496851340775 | validation: 0.09018956937593627]
	TIME [epoch: 8.83 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06455777818165756		[learning rate: 0.0048851]
		[batch 20/20] avg loss: 0.09494063626963661		[learning rate: 0.0048737]
	Learning Rate: 0.00487368
	LOSS [training: 0.07974920722564709 | validation: 0.060148178975579045]
	TIME [epoch: 8.82 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08009852534437066		[learning rate: 0.0048622]
		[batch 20/20] avg loss: 0.045849318656072204		[learning rate: 0.0048508]
	Learning Rate: 0.00485083
	LOSS [training: 0.06297392200022144 | validation: 0.1158071704732209]
	TIME [epoch: 8.84 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08697668311115858		[learning rate: 0.0048394]
		[batch 20/20] avg loss: 0.12792799043727987		[learning rate: 0.0048281]
	Learning Rate: 0.00482809
	LOSS [training: 0.10745233677421921 | validation: 0.062403047953234585]
	TIME [epoch: 8.83 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08619972681989219		[learning rate: 0.0048168]
		[batch 20/20] avg loss: 0.08091007606959515		[learning rate: 0.0048055]
	Learning Rate: 0.00480546
	LOSS [training: 0.08355490144474366 | validation: 0.05954850252193367]
	TIME [epoch: 8.83 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08497365782959006		[learning rate: 0.0047942]
		[batch 20/20] avg loss: 0.07152875827217503		[learning rate: 0.0047829]
	Learning Rate: 0.00478293
	LOSS [training: 0.07825120805088254 | validation: 0.05741445274501938]
	TIME [epoch: 8.84 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04503639915290155		[learning rate: 0.0047717]
		[batch 20/20] avg loss: 0.09467665413989651		[learning rate: 0.0047605]
	Learning Rate: 0.00476051
	LOSS [training: 0.069856526646399 | validation: 0.08475517942391496]
	TIME [epoch: 8.84 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09293706489496711		[learning rate: 0.0047493]
		[batch 20/20] avg loss: 0.0960860098633953		[learning rate: 0.0047382]
	Learning Rate: 0.00473819
	LOSS [training: 0.0945115373791812 | validation: 0.2162868935815367]
	TIME [epoch: 8.81 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08972707643093958		[learning rate: 0.0047271]
		[batch 20/20] avg loss: 0.09000491054002369		[learning rate: 0.004716]
	Learning Rate: 0.00471597
	LOSS [training: 0.08986599348548163 | validation: 0.1542504893102627]
	TIME [epoch: 8.84 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18991678524917335		[learning rate: 0.0047049]
		[batch 20/20] avg loss: 0.14438908472435324		[learning rate: 0.0046939]
	Learning Rate: 0.00469386
	LOSS [training: 0.1671529349867633 | validation: 0.10591916678569797]
	TIME [epoch: 8.86 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0859236732989175		[learning rate: 0.0046828]
		[batch 20/20] avg loss: 0.07396872723568623		[learning rate: 0.0046719]
	Learning Rate: 0.00467186
	LOSS [training: 0.07994620026730187 | validation: 0.08480035989295924]
	TIME [epoch: 8.85 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10576634426699431		[learning rate: 0.0046609]
		[batch 20/20] avg loss: 0.12194297561087705		[learning rate: 0.00465]
	Learning Rate: 0.00464996
	LOSS [training: 0.1138546599389357 | validation: 0.04447869527103156]
	TIME [epoch: 8.83 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06966862258070974		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.1277787075513812		[learning rate: 0.0046282]
	Learning Rate: 0.00462816
	LOSS [training: 0.09872366506604549 | validation: 0.05549786048281002]
	TIME [epoch: 8.84 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06547948495846281		[learning rate: 0.0046173]
		[batch 20/20] avg loss: 0.07668032548056318		[learning rate: 0.0046065]
	Learning Rate: 0.00460646
	LOSS [training: 0.071079905219513 | validation: 0.06964051319693154]
	TIME [epoch: 8.84 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06522479392265591		[learning rate: 0.0045956]
		[batch 20/20] avg loss: 0.08434290115261216		[learning rate: 0.0045849]
	Learning Rate: 0.00458486
	LOSS [training: 0.07478384753763404 | validation: 0.08344752934113844]
	TIME [epoch: 8.85 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08425061281584927		[learning rate: 0.0045741]
		[batch 20/20] avg loss: 0.05725775004044927		[learning rate: 0.0045634]
	Learning Rate: 0.00456337
	LOSS [training: 0.0707541814281493 | validation: 0.07325352202566694]
	TIME [epoch: 8.81 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08334571188990689		[learning rate: 0.0045527]
		[batch 20/20] avg loss: 0.06387938462914075		[learning rate: 0.004542]
	Learning Rate: 0.00454198
	LOSS [training: 0.07361254825952383 | validation: 0.056820828411944385]
	TIME [epoch: 8.84 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0925410056264908		[learning rate: 0.0045313]
		[batch 20/20] avg loss: 0.05458347646552834		[learning rate: 0.0045207]
	Learning Rate: 0.00452068
	LOSS [training: 0.07356224104600957 | validation: 0.0577299184907097]
	TIME [epoch: 8.82 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05158395815350193		[learning rate: 0.0045101]
		[batch 20/20] avg loss: 0.06587413996744593		[learning rate: 0.0044995]
	Learning Rate: 0.00449949
	LOSS [training: 0.05872904906047392 | validation: 0.09501479521386691]
	TIME [epoch: 8.83 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06275692591012758		[learning rate: 0.0044889]
		[batch 20/20] avg loss: 0.1842404189796322		[learning rate: 0.0044784]
	Learning Rate: 0.0044784
	LOSS [training: 0.12349867244487989 | validation: 0.10445317553831845]
	TIME [epoch: 8.81 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23609573914013068		[learning rate: 0.0044679]
		[batch 20/20] avg loss: 0.1562132205654408		[learning rate: 0.0044574]
	Learning Rate: 0.0044574
	LOSS [training: 0.19615447985278572 | validation: 0.05733979782826471]
	TIME [epoch: 8.8 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0653768398536067		[learning rate: 0.0044469]
		[batch 20/20] avg loss: 0.06768592726876707		[learning rate: 0.0044365]
	Learning Rate: 0.0044365
	LOSS [training: 0.06653138356118689 | validation: 0.11707187077205095]
	TIME [epoch: 8.83 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1213209297319634		[learning rate: 0.0044261]
		[batch 20/20] avg loss: 0.06546610067694514		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.09339351520445427 | validation: 0.01476002299882834]
	TIME [epoch: 8.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_184.pth
	Model improved!!!
EPOCH 185/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04680886802319058		[learning rate: 0.0044053]
		[batch 20/20] avg loss: 0.11901269147993035		[learning rate: 0.004395]
	Learning Rate: 0.004395
	LOSS [training: 0.08291077975156046 | validation: 0.11122654781134406]
	TIME [epoch: 8.83 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08911789843438891		[learning rate: 0.0043847]
		[batch 20/20] avg loss: 0.10832129432221545		[learning rate: 0.0043744]
	Learning Rate: 0.0043744
	LOSS [training: 0.09871959637830217 | validation: 0.0751822465367564]
	TIME [epoch: 8.81 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09658501226774727		[learning rate: 0.0043641]
		[batch 20/20] avg loss: 0.06785252346534507		[learning rate: 0.0043539]
	Learning Rate: 0.00435389
	LOSS [training: 0.08221876786654615 | validation: 0.026093875794888845]
	TIME [epoch: 8.83 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06119571355410823		[learning rate: 0.0043437]
		[batch 20/20] avg loss: 0.07960448298756548		[learning rate: 0.0043335]
	Learning Rate: 0.00433348
	LOSS [training: 0.07040009827083685 | validation: 0.06212574040341726]
	TIME [epoch: 8.83 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/20] avg loss: 0.060667172529676204		[learning rate: 0.0043233]
		[batch 20/20] avg loss: 0.05870070920024271		[learning rate: 0.0043132]
	Learning Rate: 0.00431316
	LOSS [training: 0.05968394086495944 | validation: 0.06821178316488165]
	TIME [epoch: 8.83 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07422720844488805		[learning rate: 0.004303]
		[batch 20/20] avg loss: 0.039537052828736055		[learning rate: 0.0042929]
	Learning Rate: 0.00429294
	LOSS [training: 0.05688213063681206 | validation: 0.013135120447027769]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_190.pth
	Model improved!!!
EPOCH 191/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05625134106627812		[learning rate: 0.0042829]
		[batch 20/20] avg loss: 0.06964863417308946		[learning rate: 0.0042728]
	Learning Rate: 0.00427282
	LOSS [training: 0.06294998761968379 | validation: 0.1266403999311533]
	TIME [epoch: 8.86 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2063436513321502		[learning rate: 0.0042628]
		[batch 20/20] avg loss: 0.0841548748167032		[learning rate: 0.0042528]
	Learning Rate: 0.00425279
	LOSS [training: 0.1452492630744267 | validation: 0.04677182478962533]
	TIME [epoch: 8.85 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0767520377351147		[learning rate: 0.0042428]
		[batch 20/20] avg loss: 0.07950461893208154		[learning rate: 0.0042328]
	Learning Rate: 0.00423285
	LOSS [training: 0.07812832833359812 | validation: 0.049783952569613134]
	TIME [epoch: 8.82 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05198786652268652		[learning rate: 0.0042229]
		[batch 20/20] avg loss: 0.08184756853081139		[learning rate: 0.004213]
	Learning Rate: 0.004213
	LOSS [training: 0.06691771752674895 | validation: 0.11348853798409546]
	TIME [epoch: 8.82 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06310114669430354		[learning rate: 0.0042031]
		[batch 20/20] avg loss: 0.04838015108578507		[learning rate: 0.0041933]
	Learning Rate: 0.00419325
	LOSS [training: 0.0557406488900443 | validation: 0.031923991842989864]
	TIME [epoch: 8.84 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04554712452718028		[learning rate: 0.0041834]
		[batch 20/20] avg loss: 0.056006467628447874		[learning rate: 0.0041736]
	Learning Rate: 0.00417359
	LOSS [training: 0.05077679607781407 | validation: 0.038532067354810955]
	TIME [epoch: 8.82 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05277241115498652		[learning rate: 0.0041638]
		[batch 20/20] avg loss: 0.048663216110115357		[learning rate: 0.004154]
	Learning Rate: 0.00415403
	LOSS [training: 0.05071781363255094 | validation: 0.016137624609774564]
	TIME [epoch: 8.83 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0427431730073693		[learning rate: 0.0041443]
		[batch 20/20] avg loss: 0.05064065656271625		[learning rate: 0.0041346]
	Learning Rate: 0.00413455
	LOSS [training: 0.046691914785042775 | validation: 0.05649111823780756]
	TIME [epoch: 8.84 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06738700404782413		[learning rate: 0.0041249]
		[batch 20/20] avg loss: 0.060372164615265456		[learning rate: 0.0041152]
	Learning Rate: 0.00411517
	LOSS [training: 0.06387958433154478 | validation: 0.037343846800958716]
	TIME [epoch: 8.82 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05344283189596073		[learning rate: 0.0041055]
		[batch 20/20] avg loss: 0.09012419733070602		[learning rate: 0.0040959]
	Learning Rate: 0.00409588
	LOSS [training: 0.07178351461333338 | validation: 0.04925225226221491]
	TIME [epoch: 8.86 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06847786195339502		[learning rate: 0.0040863]
		[batch 20/20] avg loss: 0.05750094037209404		[learning rate: 0.0040767]
	Learning Rate: 0.00407667
	LOSS [training: 0.06298940116274451 | validation: 0.03017571057223272]
	TIME [epoch: 8.85 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09151660248152779		[learning rate: 0.0040671]
		[batch 20/20] avg loss: 0.0714954110800517		[learning rate: 0.0040576]
	Learning Rate: 0.00405756
	LOSS [training: 0.08150600678078973 | validation: 0.023201287820452166]
	TIME [epoch: 8.83 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07723323172959674		[learning rate: 0.004048]
		[batch 20/20] avg loss: 0.0523973561634038		[learning rate: 0.0040385]
	Learning Rate: 0.00403854
	LOSS [training: 0.06481529394650028 | validation: 0.06689915840820308]
	TIME [epoch: 8.84 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07526835030980432		[learning rate: 0.0040291]
		[batch 20/20] avg loss: 0.040508161591514005		[learning rate: 0.0040196]
	Learning Rate: 0.00401961
	LOSS [training: 0.05788825595065915 | validation: 0.03879486390245914]
	TIME [epoch: 8.83 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05936529928823621		[learning rate: 0.0040102]
		[batch 20/20] avg loss: 0.061013876391823915		[learning rate: 0.0040008]
	Learning Rate: 0.00400076
	LOSS [training: 0.060189587840030055 | validation: 0.05331820537244139]
	TIME [epoch: 8.86 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08675263667694982		[learning rate: 0.0039914]
		[batch 20/20] avg loss: 0.08449620457793054		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.08562442062744019 | validation: 0.07151111000453973]
	TIME [epoch: 8.83 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/20] avg loss: 0.052298008405698135		[learning rate: 0.0039727]
		[batch 20/20] avg loss: 0.05745463811240568		[learning rate: 0.0039633]
	Learning Rate: 0.00396334
	LOSS [training: 0.05487632325905191 | validation: 0.008972177127817815]
	TIME [epoch: 8.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_207.pth
	Model improved!!!
EPOCH 208/500:
	Training over batches...
		[batch 10/20] avg loss: 0.046447870517904916		[learning rate: 0.003954]
		[batch 20/20] avg loss: 0.13073129357130828		[learning rate: 0.0039448]
	Learning Rate: 0.00394476
	LOSS [training: 0.08858958204460661 | validation: 0.11259817024916235]
	TIME [epoch: 8.83 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20413964081251107		[learning rate: 0.0039355]
		[batch 20/20] avg loss: 0.2543787443103846		[learning rate: 0.0039263]
	Learning Rate: 0.00392627
	LOSS [training: 0.22925919256144783 | validation: 0.16206628315837407]
	TIME [epoch: 8.86 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07941382988953313		[learning rate: 0.0039171]
		[batch 20/20] avg loss: 0.06341169380106615		[learning rate: 0.0039079]
	Learning Rate: 0.00390786
	LOSS [training: 0.07141276184529965 | validation: 0.06332705013112172]
	TIME [epoch: 8.84 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07229162924329788		[learning rate: 0.0038987]
		[batch 20/20] avg loss: 0.04440763337073012		[learning rate: 0.0038895]
	Learning Rate: 0.00388954
	LOSS [training: 0.058349631307014004 | validation: 0.08812161510204661]
	TIME [epoch: 8.83 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06353198750232289		[learning rate: 0.0038804]
		[batch 20/20] avg loss: 0.060742665133550644		[learning rate: 0.0038713]
	Learning Rate: 0.0038713
	LOSS [training: 0.06213732631793676 | validation: 0.03387050303718293]
	TIME [epoch: 8.82 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06022834110277926		[learning rate: 0.0038622]
		[batch 20/20] avg loss: 0.0564069181032798		[learning rate: 0.0038532]
	Learning Rate: 0.00385315
	LOSS [training: 0.05831762960302954 | validation: 0.0073363364713418385]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_213.pth
	Model improved!!!
EPOCH 214/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04314639151646942		[learning rate: 0.0038441]
		[batch 20/20] avg loss: 0.04384875055652308		[learning rate: 0.0038351]
	Learning Rate: 0.00383509
	LOSS [training: 0.043497571036496256 | validation: 0.04882914279201096]
	TIME [epoch: 8.83 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04166655529459016		[learning rate: 0.0038261]
		[batch 20/20] avg loss: 0.07243107491121016		[learning rate: 0.0038171]
	Learning Rate: 0.00381711
	LOSS [training: 0.05704881510290016 | validation: 0.02833672508868358]
	TIME [epoch: 8.85 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11719612249594027		[learning rate: 0.0038082]
		[batch 20/20] avg loss: 0.0707487438228484		[learning rate: 0.0037992]
	Learning Rate: 0.00379921
	LOSS [training: 0.09397243315939434 | validation: 0.03853091964808128]
	TIME [epoch: 8.83 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03691522493466367		[learning rate: 0.0037903]
		[batch 20/20] avg loss: 0.11073946043792338		[learning rate: 0.0037814]
	Learning Rate: 0.0037814
	LOSS [training: 0.07382734268629351 | validation: 0.10113761210900513]
	TIME [epoch: 8.84 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08678192477104965		[learning rate: 0.0037725]
		[batch 20/20] avg loss: 0.059731866067479086		[learning rate: 0.0037637]
	Learning Rate: 0.00376368
	LOSS [training: 0.07325689541926436 | validation: 0.03894749317344867]
	TIME [epoch: 8.84 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05695602004414359		[learning rate: 0.0037548]
		[batch 20/20] avg loss: 0.053183661431903194		[learning rate: 0.003746]
	Learning Rate: 0.00374603
	LOSS [training: 0.05506984073802339 | validation: 0.02934843794708322]
	TIME [epoch: 8.84 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/20] avg loss: 0.040671566189385555		[learning rate: 0.0037372]
		[batch 20/20] avg loss: 0.04104557140013254		[learning rate: 0.0037285]
	Learning Rate: 0.00372847
	LOSS [training: 0.040858568794759055 | validation: 0.014708840558774543]
	TIME [epoch: 8.88 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05104687272012295		[learning rate: 0.0037197]
		[batch 20/20] avg loss: 0.060584236349790196		[learning rate: 0.003711]
	Learning Rate: 0.00371099
	LOSS [training: 0.05581555453495657 | validation: 0.05833994326930976]
	TIME [epoch: 8.83 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05523488965072758		[learning rate: 0.0037023]
		[batch 20/20] avg loss: 0.06581432294186645		[learning rate: 0.0036936]
	Learning Rate: 0.00369359
	LOSS [training: 0.06052460629629701 | validation: 0.014881024658785156]
	TIME [epoch: 8.84 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04263827462045853		[learning rate: 0.0036849]
		[batch 20/20] avg loss: 0.03938186983374421		[learning rate: 0.0036763]
	Learning Rate: 0.00367628
	LOSS [training: 0.041010072227101374 | validation: 0.006512627260624776]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_223.pth
	Model improved!!!
EPOCH 224/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09309051841865787		[learning rate: 0.0036676]
		[batch 20/20] avg loss: 0.0779031536520767		[learning rate: 0.003659]
	Learning Rate: 0.00365904
	LOSS [training: 0.08549683603536727 | validation: 0.07893670126545416]
	TIME [epoch: 8.78 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05923548128806831		[learning rate: 0.0036505]
		[batch 20/20] avg loss: 0.047893598249258235		[learning rate: 0.0036419]
	Learning Rate: 0.00364189
	LOSS [training: 0.05356453976866328 | validation: 0.00581058331742264]
	TIME [epoch: 8.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_225.pth
	Model improved!!!
EPOCH 226/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05990850780888137		[learning rate: 0.0036333]
		[batch 20/20] avg loss: 0.07505644837010114		[learning rate: 0.0036248]
	Learning Rate: 0.00362481
	LOSS [training: 0.06748247808949126 | validation: 0.015541736632751824]
	TIME [epoch: 8.74 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/20] avg loss: 0.054442817847112454		[learning rate: 0.0036163]
		[batch 20/20] avg loss: 0.06341915486946798		[learning rate: 0.0036078]
	Learning Rate: 0.00360782
	LOSS [training: 0.058930986358290215 | validation: 0.01681550061561085]
	TIME [epoch: 8.76 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05353234911214847		[learning rate: 0.0035994]
		[batch 20/20] avg loss: 0.0385487483447912		[learning rate: 0.0035909]
	Learning Rate: 0.00359091
	LOSS [training: 0.046040548728469834 | validation: 0.02424472334356309]
	TIME [epoch: 8.76 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04869384133361961		[learning rate: 0.0035825]
		[batch 20/20] avg loss: 0.058508598183820246		[learning rate: 0.0035741]
	Learning Rate: 0.00357407
	LOSS [training: 0.05360121975871994 | validation: 0.035248321912037694]
	TIME [epoch: 8.76 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07869287500568317		[learning rate: 0.0035657]
		[batch 20/20] avg loss: 0.06588033242958105		[learning rate: 0.0035573]
	Learning Rate: 0.00355732
	LOSS [training: 0.07228660371763211 | validation: 0.029148606071307787]
	TIME [epoch: 8.78 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/20] avg loss: 0.046319460698348226		[learning rate: 0.003549]
		[batch 20/20] avg loss: 0.053533737034812276		[learning rate: 0.0035406]
	Learning Rate: 0.00354064
	LOSS [training: 0.049926598866580255 | validation: 0.015323970275743452]
	TIME [epoch: 8.78 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04266341569491681		[learning rate: 0.0035323]
		[batch 20/20] avg loss: 0.04418144701675552		[learning rate: 0.003524]
	Learning Rate: 0.00352404
	LOSS [training: 0.043422431355836164 | validation: 0.014786498558858044]
	TIME [epoch: 8.75 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03405541191704245		[learning rate: 0.0035158]
		[batch 20/20] avg loss: 0.067738094709993		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.050896753313517715 | validation: 0.029801579489049528]
	TIME [epoch: 8.77 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07227062508248139		[learning rate: 0.0034993]
		[batch 20/20] avg loss: 0.05266702696086356		[learning rate: 0.0034911]
	Learning Rate: 0.00349107
	LOSS [training: 0.062468826021672495 | validation: 0.013535603693650916]
	TIME [epoch: 8.76 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04457459878289195		[learning rate: 0.0034829]
		[batch 20/20] avg loss: 0.0574615684093429		[learning rate: 0.0034747]
	Learning Rate: 0.00347471
	LOSS [training: 0.051018083596117425 | validation: 0.01744074996493371]
	TIME [epoch: 8.78 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07635455032254966		[learning rate: 0.0034666]
		[batch 20/20] avg loss: 0.0344879681106652		[learning rate: 0.0034584]
	Learning Rate: 0.00345842
	LOSS [training: 0.055421259216607434 | validation: 0.02557645721888075]
	TIME [epoch: 8.76 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/20] avg loss: 0.040816273256115025		[learning rate: 0.0034503]
		[batch 20/20] avg loss: 0.05155424345938202		[learning rate: 0.0034422]
	Learning Rate: 0.00344221
	LOSS [training: 0.046185258357748525 | validation: 0.013301555045246678]
	TIME [epoch: 8.76 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04393641208532898		[learning rate: 0.0034341]
		[batch 20/20] avg loss: 0.03609277771389496		[learning rate: 0.0034261]
	Learning Rate: 0.00342607
	LOSS [training: 0.04001459489961197 | validation: 0.043080323675444954]
	TIME [epoch: 8.77 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05651863520701448		[learning rate: 0.003418]
		[batch 20/20] avg loss: 0.06292571399860805		[learning rate: 0.00341]
	Learning Rate: 0.00341001
	LOSS [training: 0.05972217460281126 | validation: 0.030348454445518834]
	TIME [epoch: 8.77 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0510733478206591		[learning rate: 0.003402]
		[batch 20/20] avg loss: 0.06264150468835869		[learning rate: 0.003394]
	Learning Rate: 0.00339402
	LOSS [training: 0.05685742625450889 | validation: 0.026500701424886013]
	TIME [epoch: 8.79 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/20] avg loss: 0.039252959706943535		[learning rate: 0.0033861]
		[batch 20/20] avg loss: 0.042183716890541165		[learning rate: 0.0033781]
	Learning Rate: 0.00337811
	LOSS [training: 0.04071833829874235 | validation: 0.05312398207859113]
	TIME [epoch: 8.75 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07988414812252041		[learning rate: 0.0033702]
		[batch 20/20] avg loss: 0.044517129544133324		[learning rate: 0.0033623]
	Learning Rate: 0.00336227
	LOSS [training: 0.06220063883332687 | validation: 0.04077377040272777]
	TIME [epoch: 8.78 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05549747990848867		[learning rate: 0.0033544]
		[batch 20/20] avg loss: 0.06951599201753245		[learning rate: 0.0033465]
	Learning Rate: 0.00334651
	LOSS [training: 0.06250673596301055 | validation: 0.011582339905487803]
	TIME [epoch: 8.75 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03983916818049841		[learning rate: 0.0033387]
		[batch 20/20] avg loss: 0.050760666234454896		[learning rate: 0.0033308]
	Learning Rate: 0.00333082
	LOSS [training: 0.045299917207476635 | validation: 0.061039402334744974]
	TIME [epoch: 8.78 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09767029969753734		[learning rate: 0.003323]
		[batch 20/20] avg loss: 0.18125107442430904		[learning rate: 0.0033152]
	Learning Rate: 0.0033152
	LOSS [training: 0.1394606870609232 | validation: 0.07143591775015458]
	TIME [epoch: 8.8 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05801588288875974		[learning rate: 0.0033074]
		[batch 20/20] avg loss: 0.08137587168580515		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.06969587728728245 | validation: 0.10250909238382716]
	TIME [epoch: 8.77 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05944144787745762		[learning rate: 0.0032919]
		[batch 20/20] avg loss: 0.03883059663764577		[learning rate: 0.0032842]
	Learning Rate: 0.00328419
	LOSS [training: 0.0491360222575517 | validation: 0.01703912581597388]
	TIME [epoch: 8.76 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/20] avg loss: 0.058403429399695214		[learning rate: 0.0032765]
		[batch 20/20] avg loss: 0.10183234733234495		[learning rate: 0.0032688]
	Learning Rate: 0.0032688
	LOSS [training: 0.08011788836602009 | validation: 0.263766945638728]
	TIME [epoch: 8.75 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4016559394648948		[learning rate: 0.0032611]
		[batch 20/20] avg loss: 0.3697238610356524		[learning rate: 0.0032535]
	Learning Rate: 0.00325347
	LOSS [training: 0.3856899002502736 | validation: 0.25180915195330145]
	TIME [epoch: 8.76 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1787298646218888		[learning rate: 0.0032458]
		[batch 20/20] avg loss: 0.08801768771068885		[learning rate: 0.0032382]
	Learning Rate: 0.00323822
	LOSS [training: 0.1333737761662888 | validation: 0.024674885914270344]
	TIME [epoch: 8.77 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05497446168550517		[learning rate: 0.0032306]
		[batch 20/20] avg loss: 0.12601273363015028		[learning rate: 0.003223]
	Learning Rate: 0.00322304
	LOSS [training: 0.09049359765782773 | validation: 0.2902673567989731]
	TIME [epoch: 8.77 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16190819188210082		[learning rate: 0.0032155]
		[batch 20/20] avg loss: 0.10925734822769415		[learning rate: 0.0032079]
	Learning Rate: 0.00320793
	LOSS [training: 0.13558277005489747 | validation: 0.15409572475340932]
	TIME [epoch: 8.76 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09347718826817272		[learning rate: 0.0032004]
		[batch 20/20] avg loss: 0.07152125122453748		[learning rate: 0.0031929]
	Learning Rate: 0.00319289
	LOSS [training: 0.08249921974635512 | validation: 0.04844018770615506]
	TIME [epoch: 8.76 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07283489109287015		[learning rate: 0.0031854]
		[batch 20/20] avg loss: 0.050345255127919944		[learning rate: 0.0031779]
	Learning Rate: 0.00317792
	LOSS [training: 0.061590073110395036 | validation: 0.027345377348151092]
	TIME [epoch: 8.77 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05188260161996385		[learning rate: 0.0031705]
		[batch 20/20] avg loss: 0.06152495785857992		[learning rate: 0.003163]
	Learning Rate: 0.00316302
	LOSS [training: 0.05670377973927189 | validation: 0.01753981965172152]
	TIME [epoch: 8.74 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04146322232860841		[learning rate: 0.0031556]
		[batch 20/20] avg loss: 0.045302338684634416		[learning rate: 0.0031482]
	Learning Rate: 0.00314819
	LOSS [training: 0.04338278050662142 | validation: 0.015082267313541892]
	TIME [epoch: 8.76 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04220460387556766		[learning rate: 0.0031408]
		[batch 20/20] avg loss: 0.0589272726068092		[learning rate: 0.0031334]
	Learning Rate: 0.00313343
	LOSS [training: 0.050565938241188435 | validation: 0.011012871738293326]
	TIME [epoch: 8.77 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07493022505768403		[learning rate: 0.0031261]
		[batch 20/20] avg loss: 0.03613824785028287		[learning rate: 0.0031187]
	Learning Rate: 0.00311874
	LOSS [training: 0.055534236453983456 | validation: 0.027233427430218032]
	TIME [epoch: 8.78 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03987055337945801		[learning rate: 0.0031114]
		[batch 20/20] avg loss: 0.048168281485699224		[learning rate: 0.0031041]
	Learning Rate: 0.00310412
	LOSS [training: 0.04401941743257861 | validation: 0.019955453968918534]
	TIME [epoch: 8.79 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03395842261446807		[learning rate: 0.0030968]
		[batch 20/20] avg loss: 0.04310468191638735		[learning rate: 0.0030896]
	Learning Rate: 0.00308957
	LOSS [training: 0.03853155226542772 | validation: 0.006753887299204807]
	TIME [epoch: 8.78 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04039370780415706		[learning rate: 0.0030823]
		[batch 20/20] avg loss: 0.02952362401544235		[learning rate: 0.0030751]
	Learning Rate: 0.00307509
	LOSS [training: 0.03495866590979971 | validation: 0.08326268489941926]
	TIME [epoch: 8.76 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04780770974160348		[learning rate: 0.0030679]
		[batch 20/20] avg loss: 0.05619922284899535		[learning rate: 0.0030607]
	Learning Rate: 0.00306067
	LOSS [training: 0.052003466295299415 | validation: 0.012992680518782558]
	TIME [epoch: 8.76 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/20] avg loss: 0.051567196708235896		[learning rate: 0.0030535]
		[batch 20/20] avg loss: 0.06346982641154372		[learning rate: 0.0030463]
	Learning Rate: 0.00304632
	LOSS [training: 0.05751851155988981 | validation: 0.0291564762943193]
	TIME [epoch: 8.74 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10333118495773382		[learning rate: 0.0030392]
		[batch 20/20] avg loss: 0.02925409767836758		[learning rate: 0.003032]
	Learning Rate: 0.00303204
	LOSS [training: 0.0662926413180507 | validation: 0.02003583331320221]
	TIME [epoch: 8.78 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05170648147640113		[learning rate: 0.0030249]
		[batch 20/20] avg loss: 0.0660313880690365		[learning rate: 0.0030178]
	Learning Rate: 0.00301782
	LOSS [training: 0.05886893477271882 | validation: 0.030916108248626374]
	TIME [epoch: 8.77 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06476069170187485		[learning rate: 0.0030107]
		[batch 20/20] avg loss: 0.03605048171002641		[learning rate: 0.0030037]
	Learning Rate: 0.00300368
	LOSS [training: 0.05040558670595062 | validation: 0.0031603075078620074]
	TIME [epoch: 8.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_266.pth
	Model improved!!!
EPOCH 267/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025678899094039642		[learning rate: 0.0029966]
		[batch 20/20] avg loss: 0.04538024237181365		[learning rate: 0.0029896]
	Learning Rate: 0.00298959
	LOSS [training: 0.03552957073292666 | validation: 0.01639865353603108]
	TIME [epoch: 8.76 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05296533975904185		[learning rate: 0.0029826]
		[batch 20/20] avg loss: 0.06408061761320748		[learning rate: 0.0029756]
	Learning Rate: 0.00297558
	LOSS [training: 0.05852297868612466 | validation: 0.03157088909229864]
	TIME [epoch: 8.78 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04695399327892002		[learning rate: 0.0029686]
		[batch 20/20] avg loss: 0.03888536196221658		[learning rate: 0.0029616]
	Learning Rate: 0.00296163
	LOSS [training: 0.042919677620568294 | validation: 0.01549678711641561]
	TIME [epoch: 8.77 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/20] avg loss: 0.040551113617018714		[learning rate: 0.0029547]
		[batch 20/20] avg loss: 0.03708845292051054		[learning rate: 0.0029477]
	Learning Rate: 0.00294774
	LOSS [training: 0.03881978326876463 | validation: 0.0332021097933797]
	TIME [epoch: 8.75 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/20] avg loss: 0.045127099307904386		[learning rate: 0.0029408]
		[batch 20/20] avg loss: 0.03820544793887494		[learning rate: 0.0029339]
	Learning Rate: 0.00293393
	LOSS [training: 0.041666273623389656 | validation: 0.019637855800532022]
	TIME [epoch: 8.77 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05344115635038902		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.04526609687291564		[learning rate: 0.0029202]
	Learning Rate: 0.00292017
	LOSS [training: 0.049353626611652324 | validation: 0.0355705539735231]
	TIME [epoch: 8.76 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027967229742299527		[learning rate: 0.0029133]
		[batch 20/20] avg loss: 0.04654510621777165		[learning rate: 0.0029065]
	Learning Rate: 0.00290648
	LOSS [training: 0.03725616798003559 | validation: 0.004718417951057812]
	TIME [epoch: 8.77 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/20] avg loss: 0.047937806093417426		[learning rate: 0.0028997]
		[batch 20/20] avg loss: 0.055888917431945885		[learning rate: 0.0028929]
	Learning Rate: 0.00289285
	LOSS [training: 0.051913361762681666 | validation: 0.011297625529599314]
	TIME [epoch: 8.77 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03527508299130142		[learning rate: 0.0028861]
		[batch 20/20] avg loss: 0.037596350025560374		[learning rate: 0.0028793]
	Learning Rate: 0.00287929
	LOSS [training: 0.0364357165084309 | validation: 0.02595525682043822]
	TIME [epoch: 8.76 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04228859269888274		[learning rate: 0.0028725]
		[batch 20/20] avg loss: 0.045745489918699665		[learning rate: 0.0028658]
	Learning Rate: 0.00286579
	LOSS [training: 0.04401704130879121 | validation: 0.02490726322848075]
	TIME [epoch: 8.75 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03951182191724954		[learning rate: 0.0028591]
		[batch 20/20] avg loss: 0.05287097330638094		[learning rate: 0.0028524]
	Learning Rate: 0.00285236
	LOSS [training: 0.04619139761181523 | validation: 0.05529233770225514]
	TIME [epoch: 8.74 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/20] avg loss: 0.032901599059463646		[learning rate: 0.0028457]
		[batch 20/20] avg loss: 0.03861711346993776		[learning rate: 0.002839]
	Learning Rate: 0.00283899
	LOSS [training: 0.0357593562647007 | validation: 0.02505485805939498]
	TIME [epoch: 8.78 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03297494417781689		[learning rate: 0.0028323]
		[batch 20/20] avg loss: 0.02904287194567403		[learning rate: 0.0028257]
	Learning Rate: 0.00282568
	LOSS [training: 0.031008908061745465 | validation: 0.023897773797528204]
	TIME [epoch: 8.75 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/20] avg loss: 0.041831250279119846		[learning rate: 0.002819]
		[batch 20/20] avg loss: 0.04307719858707426		[learning rate: 0.0028124]
	Learning Rate: 0.00281243
	LOSS [training: 0.042454224433097064 | validation: 0.05110854439779729]
	TIME [epoch: 8.76 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05318779282750637		[learning rate: 0.0028058]
		[batch 20/20] avg loss: 0.02961716404042939		[learning rate: 0.0027992]
	Learning Rate: 0.00279924
	LOSS [training: 0.04140247843396788 | validation: 0.01477677159061632]
	TIME [epoch: 8.76 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03775997917304743		[learning rate: 0.0027927]
		[batch 20/20] avg loss: 0.03377108774179881		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.035765533457423115 | validation: 0.02543408177771926]
	TIME [epoch: 8.77 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03818998359388948		[learning rate: 0.0027796]
		[batch 20/20] avg loss: 0.022782603620759578		[learning rate: 0.0027731]
	Learning Rate: 0.00277306
	LOSS [training: 0.030486293607324532 | validation: 0.0020956142601051934]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_283.pth
	Model improved!!!
EPOCH 284/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04574877469423384		[learning rate: 0.0027666]
		[batch 20/20] avg loss: 0.06765794672437231		[learning rate: 0.0027601]
	Learning Rate: 0.00276006
	LOSS [training: 0.0567033607093031 | validation: 0.018629382431215605]
	TIME [epoch: 8.79 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04609303590913962		[learning rate: 0.0027536]
		[batch 20/20] avg loss: 0.035121113608695534		[learning rate: 0.0027471]
	Learning Rate: 0.00274712
	LOSS [training: 0.040607074758917575 | validation: 0.014008846871358243]
	TIME [epoch: 8.77 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03961419216029169		[learning rate: 0.0027407]
		[batch 20/20] avg loss: 0.045551224790268914		[learning rate: 0.0027342]
	Learning Rate: 0.00273424
	LOSS [training: 0.042582708475280305 | validation: 0.014710997779228279]
	TIME [epoch: 8.78 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030440873067405432		[learning rate: 0.0027278]
		[batch 20/20] avg loss: 0.05210319174305992		[learning rate: 0.0027214]
	Learning Rate: 0.00272142
	LOSS [training: 0.041272032405232674 | validation: 0.06440342630469602]
	TIME [epoch: 8.78 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/20] avg loss: 0.045731893715209845		[learning rate: 0.002715]
		[batch 20/20] avg loss: 0.0316262399182148		[learning rate: 0.0027087]
	Learning Rate: 0.00270866
	LOSS [training: 0.03867906681671233 | validation: 0.02173272989937406]
	TIME [epoch: 8.78 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05026952959560049		[learning rate: 0.0027023]
		[batch 20/20] avg loss: 0.04157002509463818		[learning rate: 0.002696]
	Learning Rate: 0.00269597
	LOSS [training: 0.04591977734511934 | validation: 0.002853189479036026]
	TIME [epoch: 8.78 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03255962204812694		[learning rate: 0.0026896]
		[batch 20/20] avg loss: 0.06642992455433186		[learning rate: 0.0026833]
	Learning Rate: 0.00268333
	LOSS [training: 0.0494947733012294 | validation: 0.021191489164892583]
	TIME [epoch: 8.78 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05326421942920715		[learning rate: 0.002677]
		[batch 20/20] avg loss: 0.05086159729571017		[learning rate: 0.0026707]
	Learning Rate: 0.00267075
	LOSS [training: 0.05206290836245865 | validation: 0.0183997559265611]
	TIME [epoch: 8.78 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04319363883198656		[learning rate: 0.0026645]
		[batch 20/20] avg loss: 0.0363929383474207		[learning rate: 0.0026582]
	Learning Rate: 0.00265823
	LOSS [training: 0.039793288589703636 | validation: 0.01800483457075422]
	TIME [epoch: 8.78 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04367694508430532		[learning rate: 0.002652]
		[batch 20/20] avg loss: 0.04243020900072912		[learning rate: 0.0026458]
	Learning Rate: 0.00264576
	LOSS [training: 0.043053577042517215 | validation: 0.011295659373193248]
	TIME [epoch: 8.79 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04037841401902607		[learning rate: 0.0026396]
		[batch 20/20] avg loss: 0.034176106170902915		[learning rate: 0.0026334]
	Learning Rate: 0.00263336
	LOSS [training: 0.037277260094964494 | validation: 0.005613087190366583]
	TIME [epoch: 8.8 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03487492426923		[learning rate: 0.0026272]
		[batch 20/20] avg loss: 0.045734986781864495		[learning rate: 0.002621]
	Learning Rate: 0.00262101
	LOSS [training: 0.04030495552554725 | validation: 0.01784463544263094]
	TIME [epoch: 8.76 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03171525130703909		[learning rate: 0.0026149]
		[batch 20/20] avg loss: 0.03497018045875864		[learning rate: 0.0026087]
	Learning Rate: 0.00260873
	LOSS [training: 0.03334271588289886 | validation: 0.018570692674927468]
	TIME [epoch: 8.78 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03600428711184156		[learning rate: 0.0026026]
		[batch 20/20] avg loss: 0.030342629247493914		[learning rate: 0.0025965]
	Learning Rate: 0.0025965
	LOSS [training: 0.033173458179667735 | validation: 0.02993323256278393]
	TIME [epoch: 8.75 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/20] avg loss: 0.049669571283620664		[learning rate: 0.0025904]
		[batch 20/20] avg loss: 0.036934268609013166		[learning rate: 0.0025843]
	Learning Rate: 0.00258432
	LOSS [training: 0.04330191994631692 | validation: 0.030268419369642544]
	TIME [epoch: 8.8 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03788346918429153		[learning rate: 0.0025783]
		[batch 20/20] avg loss: 0.017250968640846777		[learning rate: 0.0025722]
	Learning Rate: 0.00257221
	LOSS [training: 0.027567218912569146 | validation: -0.0011301403260918976]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_299.pth
	Model improved!!!
EPOCH 300/500:
	Training over batches...
		[batch 10/20] avg loss: 0.041606200080471674		[learning rate: 0.0025662]
		[batch 20/20] avg loss: 0.020586638117208775		[learning rate: 0.0025601]
	Learning Rate: 0.00256015
	LOSS [training: 0.031096419098840217 | validation: -0.002467473455186676]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_300.pth
	Model improved!!!
EPOCH 301/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03642379295335461		[learning rate: 0.0025541]
		[batch 20/20] avg loss: 0.027882790373550424		[learning rate: 0.0025481]
	Learning Rate: 0.00254815
	LOSS [training: 0.03215329166345252 | validation: 0.028515081690689812]
	TIME [epoch: 8.78 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0489995501285095		[learning rate: 0.0025422]
		[batch 20/20] avg loss: 0.03214384290773396		[learning rate: 0.0025362]
	Learning Rate: 0.0025362
	LOSS [training: 0.040571696518121717 | validation: 0.01318299619760338]
	TIME [epoch: 8.79 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022603929398932333		[learning rate: 0.0025302]
		[batch 20/20] avg loss: 0.045808863297687144		[learning rate: 0.0025243]
	Learning Rate: 0.00252431
	LOSS [training: 0.03420639634830974 | validation: -0.0003609622749819316]
	TIME [epoch: 8.81 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/20] avg loss: 0.036329591921093404		[learning rate: 0.0025184]
		[batch 20/20] avg loss: 0.04061178200339498		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.03847068696224419 | validation: 0.06710297835180795]
	TIME [epoch: 8.79 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11162797074335526		[learning rate: 0.0025066]
		[batch 20/20] avg loss: 0.0498810312403549		[learning rate: 0.0025007]
	Learning Rate: 0.0025007
	LOSS [training: 0.08075450099185509 | validation: 0.011987134284681301]
	TIME [epoch: 8.79 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05316052276268794		[learning rate: 0.0024948]
		[batch 20/20] avg loss: 0.0560766023384814		[learning rate: 0.002489]
	Learning Rate: 0.00248897
	LOSS [training: 0.05461856255058467 | validation: 0.00464652624316308]
	TIME [epoch: 8.8 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/20] avg loss: 0.034137128707979525		[learning rate: 0.0024831]
		[batch 20/20] avg loss: 0.04685076895495102		[learning rate: 0.0024773]
	Learning Rate: 0.00247731
	LOSS [training: 0.04049394883146527 | validation: 0.01581282539174625]
	TIME [epoch: 8.8 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03187187924927663		[learning rate: 0.0024715]
		[batch 20/20] avg loss: 0.03303055896134613		[learning rate: 0.0024657]
	Learning Rate: 0.00246569
	LOSS [training: 0.03245121910531138 | validation: 0.0032362159465665046]
	TIME [epoch: 8.83 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03597924972169341		[learning rate: 0.0024599]
		[batch 20/20] avg loss: 0.031723848015722034		[learning rate: 0.0024541]
	Learning Rate: 0.00245413
	LOSS [training: 0.03385154886870772 | validation: 0.00417481568306137]
	TIME [epoch: 8.8 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03491005587355778		[learning rate: 0.0024484]
		[batch 20/20] avg loss: 0.043852101328254026		[learning rate: 0.0024426]
	Learning Rate: 0.00244263
	LOSS [training: 0.0393810786009059 | validation: 0.012296644681928393]
	TIME [epoch: 8.81 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030262015552071014		[learning rate: 0.0024369]
		[batch 20/20] avg loss: 0.038536015323435764		[learning rate: 0.0024312]
	Learning Rate: 0.00243118
	LOSS [training: 0.034399015437753394 | validation: 0.005265318615049308]
	TIME [epoch: 8.8 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0328350080899122		[learning rate: 0.0024255]
		[batch 20/20] avg loss: 0.02721271422324928		[learning rate: 0.0024198]
	Learning Rate: 0.00241978
	LOSS [training: 0.03002386115658074 | validation: 0.02917309923200599]
	TIME [epoch: 8.81 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04086598243329004		[learning rate: 0.0024141]
		[batch 20/20] avg loss: 0.0405687062857832		[learning rate: 0.0024084]
	Learning Rate: 0.00240843
	LOSS [training: 0.040717344359536625 | validation: 0.020969017342202644]
	TIME [epoch: 8.83 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05719473846850796		[learning rate: 0.0024028]
		[batch 20/20] avg loss: 0.04110254170562107		[learning rate: 0.0023971]
	Learning Rate: 0.00239714
	LOSS [training: 0.0491486400870645 | validation: 0.008939592891915487]
	TIME [epoch: 8.78 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03212658432129271		[learning rate: 0.0023915]
		[batch 20/20] avg loss: 0.03709200929543864		[learning rate: 0.0023859]
	Learning Rate: 0.0023859
	LOSS [training: 0.034609296808365664 | validation: 0.01539241412001478]
	TIME [epoch: 8.79 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03211620494748334		[learning rate: 0.0023803]
		[batch 20/20] avg loss: 0.037462467912717845		[learning rate: 0.0023747]
	Learning Rate: 0.00237472
	LOSS [training: 0.034789336430100584 | validation: 0.01088306751053911]
	TIME [epoch: 8.76 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03557039111922455		[learning rate: 0.0023691]
		[batch 20/20] avg loss: 0.03450284339747785		[learning rate: 0.0023636]
	Learning Rate: 0.00236359
	LOSS [training: 0.0350366172583512 | validation: 0.032236653809661106]
	TIME [epoch: 8.79 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0252946455710495		[learning rate: 0.002358]
		[batch 20/20] avg loss: 0.02505347230087186		[learning rate: 0.0023525]
	Learning Rate: 0.00235251
	LOSS [training: 0.02517405893596068 | validation: 0.012903529776910151]
	TIME [epoch: 8.79 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025336910021412463		[learning rate: 0.002347]
		[batch 20/20] avg loss: 0.049813740527381335		[learning rate: 0.0023415]
	Learning Rate: 0.00234148
	LOSS [training: 0.0375753252743969 | validation: 0.013359746025977937]
	TIME [epoch: 8.81 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04527248769915125		[learning rate: 0.002336]
		[batch 20/20] avg loss: 0.03662657671120162		[learning rate: 0.0023305]
	Learning Rate: 0.0023305
	LOSS [training: 0.040949532205176435 | validation: 0.01593981023342835]
	TIME [epoch: 8.79 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/20] avg loss: 0.024384745015775474		[learning rate: 0.002325]
		[batch 20/20] avg loss: 0.03816189898138804		[learning rate: 0.0023196]
	Learning Rate: 0.00231957
	LOSS [training: 0.03127332199858176 | validation: 0.020393581035812618]
	TIME [epoch: 8.8 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02072861135232786		[learning rate: 0.0023141]
		[batch 20/20] avg loss: 0.020339601650086865		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.02053410650120736 | validation: 0.025017752816351543]
	TIME [epoch: 8.82 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/20] avg loss: 0.050023630032980534		[learning rate: 0.0023033]
		[batch 20/20] avg loss: 0.04579512417986789		[learning rate: 0.0022979]
	Learning Rate: 0.00229788
	LOSS [training: 0.04790937710642421 | validation: 0.01859189908333051]
	TIME [epoch: 8.8 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01897098310840941		[learning rate: 0.0022925]
		[batch 20/20] avg loss: 0.03576177780670128		[learning rate: 0.0022871]
	Learning Rate: 0.0022871
	LOSS [training: 0.027366380457555343 | validation: 0.015663847569936856]
	TIME [epoch: 8.8 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03143641117098037		[learning rate: 0.0022817]
		[batch 20/20] avg loss: 0.021724029200727298		[learning rate: 0.0022764]
	Learning Rate: 0.00227638
	LOSS [training: 0.02658022018585384 | validation: 0.00802203159416838]
	TIME [epoch: 8.8 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03396173227694432		[learning rate: 0.002271]
		[batch 20/20] avg loss: 0.025398508698917372		[learning rate: 0.0022657]
	Learning Rate: 0.00226571
	LOSS [training: 0.029680120487930846 | validation: 0.004420786654821825]
	TIME [epoch: 8.8 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023180875171148092		[learning rate: 0.0022604]
		[batch 20/20] avg loss: 0.07480282253507839		[learning rate: 0.0022551]
	Learning Rate: 0.00225509
	LOSS [training: 0.04899184885311324 | validation: 0.02249638034314062]
	TIME [epoch: 8.81 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03600095937335722		[learning rate: 0.0022498]
		[batch 20/20] avg loss: 0.03179390987542301		[learning rate: 0.0022445]
	Learning Rate: 0.00224451
	LOSS [training: 0.03389743462439011 | validation: 0.004763401592588418]
	TIME [epoch: 8.81 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025979010930535996		[learning rate: 0.0022392]
		[batch 20/20] avg loss: 0.04495214188607135		[learning rate: 0.002234]
	Learning Rate: 0.00223399
	LOSS [training: 0.03546557640830366 | validation: 0.03931539137059195]
	TIME [epoch: 8.79 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05208426679305637		[learning rate: 0.0022287]
		[batch 20/20] avg loss: 0.0574733711440625		[learning rate: 0.0022235]
	Learning Rate: 0.00222352
	LOSS [training: 0.05477881896855943 | validation: 0.03340926319951151]
	TIME [epoch: 8.78 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04513065719669224		[learning rate: 0.0022183]
		[batch 20/20] avg loss: 0.04819973879546797		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.04666519799608011 | validation: 0.018647318797407327]
	TIME [epoch: 8.79 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/20] avg loss: 0.039883148350106236		[learning rate: 0.0022079]
		[batch 20/20] avg loss: 0.0765526113018396		[learning rate: 0.0022027]
	Learning Rate: 0.00220272
	LOSS [training: 0.05821787982597291 | validation: 0.024154553722198796]
	TIME [epoch: 8.83 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03553564850405506		[learning rate: 0.0021976]
		[batch 20/20] avg loss: 0.04796806113390887		[learning rate: 0.0021924]
	Learning Rate: 0.00219239
	LOSS [training: 0.04175185481898197 | validation: 0.08260985856261702]
	TIME [epoch: 8.78 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12058486192826885		[learning rate: 0.0021872]
		[batch 20/20] avg loss: 0.08711153544064809		[learning rate: 0.0021821]
	Learning Rate: 0.00218211
	LOSS [training: 0.10384819868445845 | validation: 0.020029122181904578]
	TIME [epoch: 8.8 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03195174674557512		[learning rate: 0.002177]
		[batch 20/20] avg loss: 0.020997279839952934		[learning rate: 0.0021719]
	Learning Rate: 0.00217188
	LOSS [training: 0.026474513292764023 | validation: 0.015071900274692714]
	TIME [epoch: 8.81 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03402988456781576		[learning rate: 0.0021668]
		[batch 20/20] avg loss: 0.03373171970066169		[learning rate: 0.0021617]
	Learning Rate: 0.0021617
	LOSS [training: 0.03388080213423872 | validation: 0.012325321191159682]
	TIME [epoch: 8.82 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03632860674599218		[learning rate: 0.0021566]
		[batch 20/20] avg loss: 0.06604362254158025		[learning rate: 0.0021516]
	Learning Rate: 0.00215157
	LOSS [training: 0.05118611464378622 | validation: 0.0157957263594847]
	TIME [epoch: 8.82 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018652057266086177		[learning rate: 0.0021465]
		[batch 20/20] avg loss: 0.041391417648725545		[learning rate: 0.0021415]
	Learning Rate: 0.00214148
	LOSS [training: 0.03002173745740585 | validation: 0.009138313895745823]
	TIME [epoch: 8.79 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03258759804328645		[learning rate: 0.0021365]
		[batch 20/20] avg loss: 0.016370492049971232		[learning rate: 0.0021314]
	Learning Rate: 0.00213144
	LOSS [training: 0.024479045046628845 | validation: 0.00870519110023311]
	TIME [epoch: 8.81 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028187970466419403		[learning rate: 0.0021264]
		[batch 20/20] avg loss: 0.025998469716164273		[learning rate: 0.0021214]
	Learning Rate: 0.00212145
	LOSS [training: 0.027093220091291843 | validation: 0.012538546508936465]
	TIME [epoch: 8.82 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/20] avg loss: 0.031129440357890125		[learning rate: 0.0021165]
		[batch 20/20] avg loss: 0.020357699463179328		[learning rate: 0.0021115]
	Learning Rate: 0.0021115
	LOSS [training: 0.025743569910534725 | validation: 0.010090830470740235]
	TIME [epoch: 8.83 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023595597011368964		[learning rate: 0.0021065]
		[batch 20/20] avg loss: 0.03399470218139522		[learning rate: 0.0021016]
	Learning Rate: 0.0021016
	LOSS [training: 0.028795149596382092 | validation: 0.07171501976903173]
	TIME [epoch: 8.82 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04543253067089937		[learning rate: 0.0020967]
		[batch 20/20] avg loss: 0.0256651533734348		[learning rate: 0.0020918]
	Learning Rate: 0.00209175
	LOSS [training: 0.035548842022167085 | validation: 0.0185492403385599]
	TIME [epoch: 8.79 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03104757225623699		[learning rate: 0.0020868]
		[batch 20/20] avg loss: 0.03150441299228682		[learning rate: 0.0020819]
	Learning Rate: 0.00208195
	LOSS [training: 0.0312759926242619 | validation: 0.008407495219935392]
	TIME [epoch: 8.79 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017318804217800802		[learning rate: 0.0020771]
		[batch 20/20] avg loss: 0.02909056788597591		[learning rate: 0.0020722]
	Learning Rate: 0.00207219
	LOSS [training: 0.02320468605188835 | validation: 0.00807055989311698]
	TIME [epoch: 8.8 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023040041027308656		[learning rate: 0.0020673]
		[batch 20/20] avg loss: 0.05351108531623568		[learning rate: 0.0020625]
	Learning Rate: 0.00206247
	LOSS [training: 0.038275563171772164 | validation: 0.04537413691902556]
	TIME [epoch: 8.81 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03152493034744365		[learning rate: 0.0020576]
		[batch 20/20] avg loss: 0.02128440482556114		[learning rate: 0.0020528]
	Learning Rate: 0.0020528
	LOSS [training: 0.026404667586502402 | validation: 0.007223025161620559]
	TIME [epoch: 8.81 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015468477855778557		[learning rate: 0.002048]
		[batch 20/20] avg loss: 0.0176141433023341		[learning rate: 0.0020432]
	Learning Rate: 0.00204318
	LOSS [training: 0.01654131057905633 | validation: 0.004442738525042824]
	TIME [epoch: 8.8 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025134530837633368		[learning rate: 0.0020384]
		[batch 20/20] avg loss: 0.021825527876016694		[learning rate: 0.0020336]
	Learning Rate: 0.0020336
	LOSS [training: 0.023480029356825034 | validation: 0.028686384204216826]
	TIME [epoch: 8.81 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02535540118429343		[learning rate: 0.0020288]
		[batch 20/20] avg loss: 0.027562345602606668		[learning rate: 0.0020241]
	Learning Rate: 0.00202407
	LOSS [training: 0.026458873393450044 | validation: 0.012164850926827606]
	TIME [epoch: 8.79 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020357416642391556		[learning rate: 0.0020193]
		[batch 20/20] avg loss: 0.031101867140517193		[learning rate: 0.0020146]
	Learning Rate: 0.00201458
	LOSS [training: 0.025729641891454373 | validation: 0.018245691385911478]
	TIME [epoch: 8.82 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029376709103726095		[learning rate: 0.0020098]
		[batch 20/20] avg loss: 0.049588397231890215		[learning rate: 0.0020051]
	Learning Rate: 0.00200513
	LOSS [training: 0.03948255316780815 | validation: 0.014430095871107863]
	TIME [epoch: 8.81 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029541622596947238		[learning rate: 0.0020004]
		[batch 20/20] avg loss: 0.020663391542776917		[learning rate: 0.0019957]
	Learning Rate: 0.00199573
	LOSS [training: 0.025102507069862074 | validation: 0.024770095211594366]
	TIME [epoch: 8.81 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/20] avg loss: 0.036635964670896526		[learning rate: 0.001991]
		[batch 20/20] avg loss: 0.023955884965387995		[learning rate: 0.0019864]
	Learning Rate: 0.00198637
	LOSS [training: 0.03029592481814226 | validation: 0.021106745026006332]
	TIME [epoch: 8.81 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04244685214340056		[learning rate: 0.0019817]
		[batch 20/20] avg loss: 0.02427589446223167		[learning rate: 0.0019771]
	Learning Rate: 0.00197706
	LOSS [training: 0.03336137330281612 | validation: 0.0008064280770356397]
	TIME [epoch: 8.81 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03304206569714967		[learning rate: 0.0019724]
		[batch 20/20] avg loss: 0.01648548315074482		[learning rate: 0.0019678]
	Learning Rate: 0.00196779
	LOSS [training: 0.024763774423947244 | validation: 0.01624819245831024]
	TIME [epoch: 8.83 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01692657234495506		[learning rate: 0.0019632]
		[batch 20/20] avg loss: 0.04324120144486522		[learning rate: 0.0019586]
	Learning Rate: 0.00195857
	LOSS [training: 0.030083886894910133 | validation: 0.032771323757897076]
	TIME [epoch: 8.78 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09695018926059049		[learning rate: 0.001954]
		[batch 20/20] avg loss: 0.1262271275856383		[learning rate: 0.0019494]
	Learning Rate: 0.00194939
	LOSS [training: 0.11158865842311441 | validation: 0.042234797025078055]
	TIME [epoch: 8.79 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06341465118259462		[learning rate: 0.0019448]
		[batch 20/20] avg loss: 0.06764851183601313		[learning rate: 0.0019402]
	Learning Rate: 0.00194025
	LOSS [training: 0.06553158150930387 | validation: 0.005248150984310943]
	TIME [epoch: 8.8 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05465446858737353		[learning rate: 0.0019357]
		[batch 20/20] avg loss: 0.01720650579878614		[learning rate: 0.0019312]
	Learning Rate: 0.00193115
	LOSS [training: 0.03593048719307983 | validation: 0.00013195563084638024]
	TIME [epoch: 8.82 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017831608067485426		[learning rate: 0.0019266]
		[batch 20/20] avg loss: 0.041461488464513224		[learning rate: 0.0019221]
	Learning Rate: 0.0019221
	LOSS [training: 0.02964654826599933 | validation: 0.053927139073477987]
	TIME [epoch: 8.82 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/20] avg loss: 0.052998761559282584		[learning rate: 0.0019176]
		[batch 20/20] avg loss: 0.08053658137318466		[learning rate: 0.0019131]
	Learning Rate: 0.00191309
	LOSS [training: 0.06676767146623361 | validation: 0.09214199912355343]
	TIME [epoch: 8.82 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/20] avg loss: 0.059623637907176376		[learning rate: 0.0019086]
		[batch 20/20] avg loss: 0.04167097493530985		[learning rate: 0.0019041]
	Learning Rate: 0.00190412
	LOSS [training: 0.05064730642124311 | validation: 0.013008334758577773]
	TIME [epoch: 8.81 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012512956470155077		[learning rate: 0.0018996]
		[batch 20/20] avg loss: 0.01860203072914978		[learning rate: 0.0018952]
	Learning Rate: 0.00189519
	LOSS [training: 0.015557493599652425 | validation: 0.01813513469409841]
	TIME [epoch: 8.8 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023071801209806654		[learning rate: 0.0018907]
		[batch 20/20] avg loss: 0.04624665006334107		[learning rate: 0.0018863]
	Learning Rate: 0.00188631
	LOSS [training: 0.03465922563657386 | validation: 0.047452798435560196]
	TIME [epoch: 8.82 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05379690122431744		[learning rate: 0.0018819]
		[batch 20/20] avg loss: 0.02397783881998945		[learning rate: 0.0018775]
	Learning Rate: 0.00187746
	LOSS [training: 0.038887370022153436 | validation: 0.01732059918003838]
	TIME [epoch: 8.83 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01883162597662228		[learning rate: 0.0018731]
		[batch 20/20] avg loss: 0.02944431019899904		[learning rate: 0.0018687]
	Learning Rate: 0.00186866
	LOSS [training: 0.024137968087810664 | validation: 0.016436613767171197]
	TIME [epoch: 8.82 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017499203401209366		[learning rate: 0.0018643]
		[batch 20/20] avg loss: 0.027240405218788226		[learning rate: 0.0018599]
	Learning Rate: 0.0018599
	LOSS [training: 0.0223698043099988 | validation: 0.000801887873071571]
	TIME [epoch: 8.82 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/20] avg loss: 0.052890818513709706		[learning rate: 0.0018555]
		[batch 20/20] avg loss: 0.05421323783612607		[learning rate: 0.0018512]
	Learning Rate: 0.00185118
	LOSS [training: 0.05355202817491789 | validation: 0.03654997712250171]
	TIME [epoch: 8.81 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04492001371573991		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.05302324822595596		[learning rate: 0.0018425]
	Learning Rate: 0.0018425
	LOSS [training: 0.048971630970847925 | validation: 0.05574945921143434]
	TIME [epoch: 8.84 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07002308357374551		[learning rate: 0.0018382]
		[batch 20/20] avg loss: 0.07201755125193839		[learning rate: 0.0018339]
	Learning Rate: 0.00183386
	LOSS [training: 0.07102031741284194 | validation: 0.03384414387949921]
	TIME [epoch: 8.8 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03004924526575608		[learning rate: 0.0018296]
		[batch 20/20] avg loss: 0.03702125231350374		[learning rate: 0.0018253]
	Learning Rate: 0.00182527
	LOSS [training: 0.03353524878962991 | validation: 0.016246961651251578]
	TIME [epoch: 8.8 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02991508201430649		[learning rate: 0.001821]
		[batch 20/20] avg loss: 0.03822046802753586		[learning rate: 0.0018167]
	Learning Rate: 0.00181671
	LOSS [training: 0.03406777502092116 | validation: 0.009022398782672551]
	TIME [epoch: 8.8 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03006707290500101		[learning rate: 0.0018124]
		[batch 20/20] avg loss: 0.0331482464005558		[learning rate: 0.0018082]
	Learning Rate: 0.00180819
	LOSS [training: 0.03160765965277841 | validation: 0.008400810900319014]
	TIME [epoch: 8.8 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022118646488791114		[learning rate: 0.001804]
		[batch 20/20] avg loss: 0.026199080234268163		[learning rate: 0.0017997]
	Learning Rate: 0.00179972
	LOSS [training: 0.024158863361529635 | validation: 0.04097733184639293]
	TIME [epoch: 8.83 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02175393804285014		[learning rate: 0.0017955]
		[batch 20/20] avg loss: 0.02082831258821653		[learning rate: 0.0017913]
	Learning Rate: 0.00179128
	LOSS [training: 0.021291125315533337 | validation: -0.004965335566654778]
	TIME [epoch: 8.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_376.pth
	Model improved!!!
EPOCH 377/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04462051180856489		[learning rate: 0.0017871]
		[batch 20/20] avg loss: 0.05108302398488712		[learning rate: 0.0017829]
	Learning Rate: 0.00178288
	LOSS [training: 0.047851767896726 | validation: 0.04160520493806934]
	TIME [epoch: 8.82 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026973212817122373		[learning rate: 0.0017787]
		[batch 20/20] avg loss: 0.045436105423064685		[learning rate: 0.0017745]
	Learning Rate: 0.00177452
	LOSS [training: 0.03620465912009353 | validation: 0.020980660376313708]
	TIME [epoch: 8.82 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03396746693069416		[learning rate: 0.0017704]
		[batch 20/20] avg loss: 0.06392067656129795		[learning rate: 0.0017662]
	Learning Rate: 0.0017662
	LOSS [training: 0.048944071745996055 | validation: 0.025872906913892497]
	TIME [epoch: 8.84 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04262472330456214		[learning rate: 0.0017621]
		[batch 20/20] avg loss: 0.06674041613003719		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.05468256971729966 | validation: 0.0445452490298501]
	TIME [epoch: 8.81 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06233639469243194		[learning rate: 0.0017538]
		[batch 20/20] avg loss: 0.09078026976045397		[learning rate: 0.0017497]
	Learning Rate: 0.00174968
	LOSS [training: 0.07655833222644294 | validation: 0.04110571566749109]
	TIME [epoch: 8.81 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0389393763745918		[learning rate: 0.0017456]
		[batch 20/20] avg loss: 0.022977103886178452		[learning rate: 0.0017415]
	Learning Rate: 0.00174148
	LOSS [training: 0.030958240130385124 | validation: 0.00906041427318342]
	TIME [epoch: 8.8 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03024867047912593		[learning rate: 0.0017374]
		[batch 20/20] avg loss: 0.04481401203376656		[learning rate: 0.0017333]
	Learning Rate: 0.00173331
	LOSS [training: 0.03753134125644624 | validation: 0.009747006657897336]
	TIME [epoch: 8.81 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03357297898059035		[learning rate: 0.0017292]
		[batch 20/20] avg loss: 0.04638105649752499		[learning rate: 0.0017252]
	Learning Rate: 0.00172519
	LOSS [training: 0.03997701773905767 | validation: 0.027562470960631996]
	TIME [epoch: 8.81 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04309202594025688		[learning rate: 0.0017211]
		[batch 20/20] avg loss: 0.03556129451482373		[learning rate: 0.0017171]
	Learning Rate: 0.0017171
	LOSS [training: 0.039326660227540305 | validation: 0.029622564420586434]
	TIME [epoch: 8.82 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04249238887627255		[learning rate: 0.0017131]
		[batch 20/20] avg loss: 0.036744765967963756		[learning rate: 0.0017091]
	Learning Rate: 0.00170905
	LOSS [training: 0.03961857742211815 | validation: 0.03336739956876833]
	TIME [epoch: 8.8 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03954996050630414		[learning rate: 0.001705]
		[batch 20/20] avg loss: 0.039509552149800786		[learning rate: 0.001701]
	Learning Rate: 0.00170104
	LOSS [training: 0.03952975632805246 | validation: 0.02303812503947248]
	TIME [epoch: 8.82 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0342395008264134		[learning rate: 0.001697]
		[batch 20/20] avg loss: 0.036033956124398525		[learning rate: 0.0016931]
	Learning Rate: 0.00169306
	LOSS [training: 0.03513672847540596 | validation: 0.03762895508837282]
	TIME [epoch: 8.81 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03900217584803442		[learning rate: 0.0016891]
		[batch 20/20] avg loss: 0.03787435486333031		[learning rate: 0.0016851]
	Learning Rate: 0.00168513
	LOSS [training: 0.038438265355682365 | validation: 0.041777633949196945]
	TIME [epoch: 8.84 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/20] avg loss: 0.035471777830259496		[learning rate: 0.0016812]
		[batch 20/20] avg loss: 0.03677196251524751		[learning rate: 0.0016772]
	Learning Rate: 0.00167723
	LOSS [training: 0.03612187017275351 | validation: 0.0264944669433838]
	TIME [epoch: 8.83 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03394533867437263		[learning rate: 0.0016733]
		[batch 20/20] avg loss: 0.03594109416334255		[learning rate: 0.0016694]
	Learning Rate: 0.00166936
	LOSS [training: 0.03494321641885759 | validation: 0.025217480463692675]
	TIME [epoch: 8.8 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03255260938125736		[learning rate: 0.0016654]
		[batch 20/20] avg loss: 0.03772637377142645		[learning rate: 0.0016615]
	Learning Rate: 0.00166154
	LOSS [training: 0.03513949157634191 | validation: 0.009994224103294199]
	TIME [epoch: 8.81 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/20] avg loss: 0.024072627462471508		[learning rate: 0.0016576]
		[batch 20/20] avg loss: 0.02689706818625464		[learning rate: 0.0016537]
	Learning Rate: 0.00165375
	LOSS [training: 0.025484847824363065 | validation: 0.0062336445090005535]
	TIME [epoch: 8.82 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02133686932368758		[learning rate: 0.0016499]
		[batch 20/20] avg loss: 0.02903798681087938		[learning rate: 0.001646]
	Learning Rate: 0.001646
	LOSS [training: 0.025187428067283475 | validation: 0.01330464899492606]
	TIME [epoch: 8.84 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018725815172771706		[learning rate: 0.0016421]
		[batch 20/20] avg loss: 0.029183441850711485		[learning rate: 0.0016383]
	Learning Rate: 0.00163828
	LOSS [training: 0.023954628511741592 | validation: 0.012802041008586633]
	TIME [epoch: 8.82 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020835314495812794		[learning rate: 0.0016344]
		[batch 20/20] avg loss: 0.012254746348310853		[learning rate: 0.0016306]
	Learning Rate: 0.0016306
	LOSS [training: 0.016545030422061825 | validation: -0.0019007880816525355]
	TIME [epoch: 8.81 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04391714554863711		[learning rate: 0.0016268]
		[batch 20/20] avg loss: 0.023025392010289913		[learning rate: 0.001623]
	Learning Rate: 0.00162295
	LOSS [training: 0.03347126877946351 | validation: 0.023493396976457033]
	TIME [epoch: 8.81 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03224561214429277		[learning rate: 0.0016191]
		[batch 20/20] avg loss: 0.026347204324969637		[learning rate: 0.0016153]
	Learning Rate: 0.00161535
	LOSS [training: 0.029296408234631206 | validation: 0.011174141677116233]
	TIME [epoch: 8.79 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02615134747432386		[learning rate: 0.0016116]
		[batch 20/20] avg loss: 0.02956591428160918		[learning rate: 0.0016078]
	Learning Rate: 0.00160777
	LOSS [training: 0.027858630877966518 | validation: 0.026185133695305958]
	TIME [epoch: 8.83 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020593123328563476		[learning rate: 0.001604]
		[batch 20/20] avg loss: 0.036845167355290635		[learning rate: 0.0016002]
	Learning Rate: 0.00160023
	LOSS [training: 0.028719145341927054 | validation: 0.008088799785531658]
	TIME [epoch: 8.81 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02228300395304089		[learning rate: 0.0015965]
		[batch 20/20] avg loss: 0.018061381406124306		[learning rate: 0.0015927]
	Learning Rate: 0.00159273
	LOSS [training: 0.020172192679582594 | validation: 0.02084931409573199]
	TIME [epoch: 8.82 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018575811286833218		[learning rate: 0.001589]
		[batch 20/20] avg loss: 0.031402461594592604		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.024989136440712913 | validation: 0.02182950233581203]
	TIME [epoch: 8.81 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0251990448755193		[learning rate: 0.0015815]
		[batch 20/20] avg loss: 0.02053096481250013		[learning rate: 0.0015778]
	Learning Rate: 0.00157783
	LOSS [training: 0.02286500484400971 | validation: 0.0023041481460653436]
	TIME [epoch: 8.83 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026757644402522547		[learning rate: 0.0015741]
		[batch 20/20] avg loss: 0.032211338376467086		[learning rate: 0.0015704]
	Learning Rate: 0.00157044
	LOSS [training: 0.02948449138949481 | validation: -0.001218017095862685]
	TIME [epoch: 8.81 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03949894263906191		[learning rate: 0.0015668]
		[batch 20/20] avg loss: 0.012263976395881728		[learning rate: 0.0015631]
	Learning Rate: 0.00156307
	LOSS [training: 0.02588145951747182 | validation: 0.007256187049631165]
	TIME [epoch: 8.82 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017524603755171137		[learning rate: 0.0015594]
		[batch 20/20] avg loss: 0.017645582897505275		[learning rate: 0.0015557]
	Learning Rate: 0.00155575
	LOSS [training: 0.017585093326338206 | validation: 0.011578441653336125]
	TIME [epoch: 8.83 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02781648480913883		[learning rate: 0.0015521]
		[batch 20/20] avg loss: 0.02064295497957657		[learning rate: 0.0015485]
	Learning Rate: 0.00154845
	LOSS [training: 0.024229719894357703 | validation: 0.005958798339438495]
	TIME [epoch: 8.82 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014489926836594714		[learning rate: 0.0015448]
		[batch 20/20] avg loss: 0.03666232505175006		[learning rate: 0.0015412]
	Learning Rate: 0.00154119
	LOSS [training: 0.025576125944172384 | validation: 0.0023118877080476976]
	TIME [epoch: 8.84 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01810942060220604		[learning rate: 0.0015376]
		[batch 20/20] avg loss: 0.02053721731268386		[learning rate: 0.001534]
	Learning Rate: 0.00153397
	LOSS [training: 0.01932331895744495 | validation: 0.016491715132474105]
	TIME [epoch: 8.82 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015227423409983575		[learning rate: 0.0015304]
		[batch 20/20] avg loss: 0.01374810324057687		[learning rate: 0.0015268]
	Learning Rate: 0.00152678
	LOSS [training: 0.014487763325280224 | validation: 0.014508165679559948]
	TIME [epoch: 8.81 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021541269104469265		[learning rate: 0.0015232]
		[batch 20/20] avg loss: 0.015995777628610663		[learning rate: 0.0015196]
	Learning Rate: 0.00151962
	LOSS [training: 0.018768523366539964 | validation: -0.005990886521016797]
	TIME [epoch: 8.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_411.pth
	Model improved!!!
EPOCH 412/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022202711037234434		[learning rate: 0.0015161]
		[batch 20/20] avg loss: 0.033187825560918684		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.027695268299076557 | validation: 0.007537067541582251]
	TIME [epoch: 8.81 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01931051050772397		[learning rate: 0.0015089]
		[batch 20/20] avg loss: 0.018542975898980678		[learning rate: 0.0015054]
	Learning Rate: 0.0015054
	LOSS [training: 0.018926743203352327 | validation: 0.011982796888263798]
	TIME [epoch: 8.84 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028918428647131518		[learning rate: 0.0015019]
		[batch 20/20] avg loss: 0.02231788263485739		[learning rate: 0.0014983]
	Learning Rate: 0.00149835
	LOSS [training: 0.025618155640994445 | validation: 0.01573080831849841]
	TIME [epoch: 8.81 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03278145365268367		[learning rate: 0.0014948]
		[batch 20/20] avg loss: 0.03525042793598104		[learning rate: 0.0014913]
	Learning Rate: 0.00149132
	LOSS [training: 0.03401594079433236 | validation: 0.015241124933881547]
	TIME [epoch: 8.82 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026537694225952806		[learning rate: 0.0014878]
		[batch 20/20] avg loss: 0.029310564157795392		[learning rate: 0.0014843]
	Learning Rate: 0.00148433
	LOSS [training: 0.027924129191874102 | validation: -0.00032679270844856556]
	TIME [epoch: 8.82 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022041366368558517		[learning rate: 0.0014808]
		[batch 20/20] avg loss: 0.02440600370082863		[learning rate: 0.0014774]
	Learning Rate: 0.00147737
	LOSS [training: 0.023223685034693575 | validation: 0.014826078794270992]
	TIME [epoch: 8.82 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027342446702203475		[learning rate: 0.0014739]
		[batch 20/20] avg loss: 0.03009422775753472		[learning rate: 0.0014704]
	Learning Rate: 0.00147045
	LOSS [training: 0.0287183372298691 | validation: 0.0022630924724309502]
	TIME [epoch: 8.84 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018744293960481533		[learning rate: 0.001467]
		[batch 20/20] avg loss: 0.020955810619621935		[learning rate: 0.0014636]
	Learning Rate: 0.00146355
	LOSS [training: 0.019850052290051733 | validation: 0.00766421443628391]
	TIME [epoch: 8.84 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0317745829674143		[learning rate: 0.0014601]
		[batch 20/20] avg loss: 0.022644037904751346		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.027209310436082823 | validation: 0.010986991027825256]
	TIME [epoch: 8.81 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020809899131411215		[learning rate: 0.0014533]
		[batch 20/20] avg loss: 0.04024594050810236		[learning rate: 0.0014499]
	Learning Rate: 0.00144986
	LOSS [training: 0.030527919819756794 | validation: 0.022190186869779166]
	TIME [epoch: 8.83 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03453182123102787		[learning rate: 0.0014465]
		[batch 20/20] avg loss: 0.01369399976436346		[learning rate: 0.0014431]
	Learning Rate: 0.00144306
	LOSS [training: 0.024112910497695664 | validation: 0.014376770524476043]
	TIME [epoch: 8.79 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022312216363200847		[learning rate: 0.0014397]
		[batch 20/20] avg loss: 0.02087179535326264		[learning rate: 0.0014363]
	Learning Rate: 0.0014363
	LOSS [training: 0.021592005858231744 | validation: 0.02487031842245834]
	TIME [epoch: 8.85 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03028975808670096		[learning rate: 0.0014329]
		[batch 20/20] avg loss: 0.014603895463964312		[learning rate: 0.0014296]
	Learning Rate: 0.00142957
	LOSS [training: 0.022446826775332638 | validation: 0.007305833045609309]
	TIME [epoch: 8.81 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02996523111033249		[learning rate: 0.0014262]
		[batch 20/20] avg loss: 0.020483521692302362		[learning rate: 0.0014229]
	Learning Rate: 0.00142286
	LOSS [training: 0.025224376401317427 | validation: 0.018366350575283786]
	TIME [epoch: 8.8 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/20] avg loss: 0.019019222925899117		[learning rate: 0.0014195]
		[batch 20/20] avg loss: 0.028825079645411877		[learning rate: 0.0014162]
	Learning Rate: 0.00141619
	LOSS [training: 0.023922151285655495 | validation: 0.03478498399278773]
	TIME [epoch: 8.81 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04130760707985462		[learning rate: 0.0014129]
		[batch 20/20] avg loss: 0.015618541427736988		[learning rate: 0.0014096]
	Learning Rate: 0.00140955
	LOSS [training: 0.028463074253795805 | validation: -0.0018030428668513602]
	TIME [epoch: 8.83 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/20] avg loss: 0.009836197796456983		[learning rate: 0.0014062]
		[batch 20/20] avg loss: 0.018483632644264714		[learning rate: 0.0014029]
	Learning Rate: 0.00140295
	LOSS [training: 0.014159915220360846 | validation: -0.00034168888022282403]
	TIME [epoch: 8.82 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011513102256428808		[learning rate: 0.0013997]
		[batch 20/20] avg loss: 0.010158998804207517		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.010836050530318162 | validation: -0.00040817484134972586]
	TIME [epoch: 8.81 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011224717024013255		[learning rate: 0.0013931]
		[batch 20/20] avg loss: 0.030720270263827888		[learning rate: 0.0013898]
	Learning Rate: 0.00138982
	LOSS [training: 0.020972493643920575 | validation: 0.04515552224162824]
	TIME [epoch: 8.83 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03702802992156663		[learning rate: 0.0013866]
		[batch 20/20] avg loss: 0.024055167151084973		[learning rate: 0.0013833]
	Learning Rate: 0.00138331
	LOSS [training: 0.030541598536325803 | validation: 0.0004607559703620317]
	TIME [epoch: 8.82 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014728132271607903		[learning rate: 0.0013801]
		[batch 20/20] avg loss: 0.012947868668706846		[learning rate: 0.0013768]
	Learning Rate: 0.00137682
	LOSS [training: 0.013838000470157374 | validation: 0.01049165879451703]
	TIME [epoch: 8.85 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0080771899788357		[learning rate: 0.0013736]
		[batch 20/20] avg loss: 0.05961339265911451		[learning rate: 0.0013704]
	Learning Rate: 0.00137037
	LOSS [training: 0.033845291318975096 | validation: 0.002665377421085023]
	TIME [epoch: 8.82 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/20] avg loss: 0.009570617424879215		[learning rate: 0.0013672]
		[batch 20/20] avg loss: 0.011522241737479266		[learning rate: 0.0013639]
	Learning Rate: 0.00136394
	LOSS [training: 0.010546429581179241 | validation: 0.000501167965960959]
	TIME [epoch: 8.83 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02377813187776502		[learning rate: 0.0013607]
		[batch 20/20] avg loss: 0.01941585262758037		[learning rate: 0.0013575]
	Learning Rate: 0.00135755
	LOSS [training: 0.021596992252672698 | validation: 0.002871650032578766]
	TIME [epoch: 8.83 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017838484657438848		[learning rate: 0.0013544]
		[batch 20/20] avg loss: 0.0331749178698197		[learning rate: 0.0013512]
	Learning Rate: 0.00135118
	LOSS [training: 0.02550670126362927 | validation: 0.00891274939740284]
	TIME [epoch: 8.83 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013130371004332573		[learning rate: 0.001348]
		[batch 20/20] avg loss: 0.01810588350695739		[learning rate: 0.0013448]
	Learning Rate: 0.00134485
	LOSS [training: 0.015618127255644978 | validation: -0.0025299750644438273]
	TIME [epoch: 8.85 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017512531230204208		[learning rate: 0.0013417]
		[batch 20/20] avg loss: 0.014466682898314712		[learning rate: 0.0013385]
	Learning Rate: 0.00133854
	LOSS [training: 0.01598960706425946 | validation: 0.020935044674230123]
	TIME [epoch: 8.81 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030341719126472672		[learning rate: 0.0013354]
		[batch 20/20] avg loss: 0.02720367743513616		[learning rate: 0.0013323]
	Learning Rate: 0.00133227
	LOSS [training: 0.028772698280804414 | validation: 0.022638226018633793]
	TIME [epoch: 8.81 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02185840799665726		[learning rate: 0.0013291]
		[batch 20/20] avg loss: 0.032854272637678116		[learning rate: 0.001326]
	Learning Rate: 0.00132602
	LOSS [training: 0.027356340317167688 | validation: 0.02312856332677303]
	TIME [epoch: 8.81 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02009371055585358		[learning rate: 0.0013229]
		[batch 20/20] avg loss: 0.018602928607689515		[learning rate: 0.0013198]
	Learning Rate: 0.00131981
	LOSS [training: 0.019348319581771547 | validation: -0.0012954438261660562]
	TIME [epoch: 8.82 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02259320245093723		[learning rate: 0.0013167]
		[batch 20/20] avg loss: 0.012186063002488886		[learning rate: 0.0013136]
	Learning Rate: 0.00131362
	LOSS [training: 0.01738963272671306 | validation: 0.01018737321432098]
	TIME [epoch: 8.82 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018196952963800073		[learning rate: 0.0013105]
		[batch 20/20] avg loss: 0.027582131247746156		[learning rate: 0.0013075]
	Learning Rate: 0.00130746
	LOSS [training: 0.022889542105773115 | validation: 0.012075356115139994]
	TIME [epoch: 8.83 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/20] avg loss: 0.019490864763954407		[learning rate: 0.0013044]
		[batch 20/20] avg loss: 0.02206155652288071		[learning rate: 0.0013013]
	Learning Rate: 0.00130133
	LOSS [training: 0.020776210643417562 | validation: 0.015689248187429564]
	TIME [epoch: 8.83 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025709246686380065		[learning rate: 0.0012983]
		[batch 20/20] avg loss: 0.02513227917729748		[learning rate: 0.0012952]
	Learning Rate: 0.00129523
	LOSS [training: 0.025420762931838776 | validation: 0.004296644816647681]
	TIME [epoch: 8.83 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029492688086624003		[learning rate: 0.0012922]
		[batch 20/20] avg loss: 0.021240153083211966		[learning rate: 0.0012892]
	Learning Rate: 0.00128916
	LOSS [training: 0.025366420584917983 | validation: 0.018307577410036475]
	TIME [epoch: 8.84 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025597880352352876		[learning rate: 0.0012861]
		[batch 20/20] avg loss: 0.012745075608499518		[learning rate: 0.0012831]
	Learning Rate: 0.00128311
	LOSS [training: 0.0191714779804262 | validation: 0.01221834462460163]
	TIME [epoch: 8.82 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02352871813952912		[learning rate: 0.0012801]
		[batch 20/20] avg loss: 0.023957229905274054		[learning rate: 0.0012771]
	Learning Rate: 0.0012771
	LOSS [training: 0.023742974022401588 | validation: 0.014288268325583543]
	TIME [epoch: 8.82 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/20] avg loss: 0.024029646912138873		[learning rate: 0.0012741]
		[batch 20/20] avg loss: 0.032130944507188744		[learning rate: 0.0012711]
	Learning Rate: 0.00127111
	LOSS [training: 0.028080295709663805 | validation: 0.014358052293697715]
	TIME [epoch: 8.81 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015881141980811753		[learning rate: 0.0012681]
		[batch 20/20] avg loss: 0.01430459106704049		[learning rate: 0.0012652]
	Learning Rate: 0.00126515
	LOSS [training: 0.015092866523926125 | validation: 0.017919742157164072]
	TIME [epoch: 8.81 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022707706305109147		[learning rate: 0.0012622]
		[batch 20/20] avg loss: 0.021276324180854133		[learning rate: 0.0012592]
	Learning Rate: 0.00125922
	LOSS [training: 0.021992015242981645 | validation: 0.02943016798568892]
	TIME [epoch: 8.82 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/20] avg loss: 0.032247414227263474		[learning rate: 0.0012563]
		[batch 20/20] avg loss: 0.01787534459527324		[learning rate: 0.0012533]
	Learning Rate: 0.00125332
	LOSS [training: 0.025061379411268358 | validation: 0.029713388031584666]
	TIME [epoch: 8.8 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028213054138647477		[learning rate: 0.0012504]
		[batch 20/20] avg loss: 0.016854873225263932		[learning rate: 0.0012474]
	Learning Rate: 0.00124744
	LOSS [training: 0.0225339636819557 | validation: -0.0013291064706340379]
	TIME [epoch: 8.78 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01659640195839831		[learning rate: 0.0012445]
		[batch 20/20] avg loss: 0.019446134505841102		[learning rate: 0.0012416]
	Learning Rate: 0.00124159
	LOSS [training: 0.018021268232119705 | validation: -0.0005875674733069637]
	TIME [epoch: 8.78 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014028016463628501		[learning rate: 0.0012387]
		[batch 20/20] avg loss: 0.016060099049910032		[learning rate: 0.0012358]
	Learning Rate: 0.00123577
	LOSS [training: 0.015044057756769267 | validation: 0.0036625169545479366]
	TIME [epoch: 8.8 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015178244307846242		[learning rate: 0.0012329]
		[batch 20/20] avg loss: 0.012925752626398617		[learning rate: 0.00123]
	Learning Rate: 0.00122998
	LOSS [training: 0.01405199846712243 | validation: 0.013558634183915529]
	TIME [epoch: 8.82 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01822767461980819		[learning rate: 0.0012271]
		[batch 20/20] avg loss: 0.030122898564713358		[learning rate: 0.0012242]
	Learning Rate: 0.00122421
	LOSS [training: 0.024175286592260772 | validation: 0.023825383833411994]
	TIME [epoch: 8.81 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03789144802579454		[learning rate: 0.0012213]
		[batch 20/20] avg loss: 0.027790200117034057		[learning rate: 0.0012185]
	Learning Rate: 0.00121847
	LOSS [training: 0.032840824071414296 | validation: 0.012305002463063671]
	TIME [epoch: 8.81 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021914997395744366		[learning rate: 0.0012156]
		[batch 20/20] avg loss: 0.01853386624867491		[learning rate: 0.0012128]
	Learning Rate: 0.00121276
	LOSS [training: 0.020224431822209635 | validation: 0.009685220479386674]
	TIME [epoch: 8.8 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/20] avg loss: 0.033189654056752144		[learning rate: 0.0012099]
		[batch 20/20] avg loss: 0.01910579220652204		[learning rate: 0.0012071]
	Learning Rate: 0.00120708
	LOSS [training: 0.02614772313163709 | validation: -0.0030666638238864034]
	TIME [epoch: 8.81 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013388960237749834		[learning rate: 0.0012042]
		[batch 20/20] avg loss: 0.011191800653654067		[learning rate: 0.0012014]
	Learning Rate: 0.00120142
	LOSS [training: 0.012290380445701951 | validation: 0.005583632975124642]
	TIME [epoch: 8.83 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01453253167903123		[learning rate: 0.0011986]
		[batch 20/20] avg loss: 0.0173051394901212		[learning rate: 0.0011958]
	Learning Rate: 0.00119578
	LOSS [training: 0.01591883558457622 | validation: -0.006520768706708599]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_462.pth
	Model improved!!!
EPOCH 463/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012310543056798014		[learning rate: 0.001193]
		[batch 20/20] avg loss: 0.018094447944892216		[learning rate: 0.0011902]
	Learning Rate: 0.00119018
	LOSS [training: 0.015202495500845117 | validation: 0.005549312312156182]
	TIME [epoch: 8.81 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0205957308961743		[learning rate: 0.0011874]
		[batch 20/20] avg loss: 0.01561462212280682		[learning rate: 0.0011846]
	Learning Rate: 0.0011846
	LOSS [training: 0.01810517650949056 | validation: 0.012320666945080775]
	TIME [epoch: 8.82 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018972373180411048		[learning rate: 0.0011818]
		[batch 20/20] avg loss: 0.016076946306018382		[learning rate: 0.001179]
	Learning Rate: 0.00117905
	LOSS [training: 0.017524659743214717 | validation: 0.0011260011891621687]
	TIME [epoch: 8.83 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012762441553923445		[learning rate: 0.0011763]
		[batch 20/20] avg loss: 0.024508946510242442		[learning rate: 0.0011735]
	Learning Rate: 0.00117352
	LOSS [training: 0.018635694032082945 | validation: 0.019257415982692865]
	TIME [epoch: 8.84 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020425651151439427		[learning rate: 0.0011708]
		[batch 20/20] avg loss: 0.014213648923277278		[learning rate: 0.001168]
	Learning Rate: 0.00116802
	LOSS [training: 0.01731965003735835 | validation: -0.001475224909814421]
	TIME [epoch: 8.82 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013502167467736945		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.013896545458794124		[learning rate: 0.0011625]
	Learning Rate: 0.00116254
	LOSS [training: 0.013699356463265533 | validation: 0.011926756724330894]
	TIME [epoch: 8.83 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02431368847414205		[learning rate: 0.0011598]
		[batch 20/20] avg loss: 0.014300466946980155		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.01930707771056111 | validation: 0.003677168640848613]
	TIME [epoch: 8.83 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014404925402124347		[learning rate: 0.0011544]
		[batch 20/20] avg loss: 0.019110573171145197		[learning rate: 0.0011517]
	Learning Rate: 0.00115167
	LOSS [training: 0.01675774928663477 | validation: 0.0018270956618524753]
	TIME [epoch: 8.84 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/20] avg loss: 0.019682285687677898		[learning rate: 0.001149]
		[batch 20/20] avg loss: 0.007245425528650836		[learning rate: 0.0011463]
	Learning Rate: 0.00114627
	LOSS [training: 0.013463855608164366 | validation: 0.005046200411248953]
	TIME [epoch: 8.84 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013723282724183092		[learning rate: 0.0011436]
		[batch 20/20] avg loss: 0.01358468675318826		[learning rate: 0.0011409]
	Learning Rate: 0.00114089
	LOSS [training: 0.013653984738685676 | validation: 0.013525172728005158]
	TIME [epoch: 8.82 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02819429519438561		[learning rate: 0.0011382]
		[batch 20/20] avg loss: 0.025442108448555833		[learning rate: 0.0011355]
	Learning Rate: 0.00113554
	LOSS [training: 0.02681820182147072 | validation: 0.0015396138779952139]
	TIME [epoch: 8.84 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/20] avg loss: 0.016164749039452288		[learning rate: 0.0011329]
		[batch 20/20] avg loss: 0.03423604101828949		[learning rate: 0.0011302]
	Learning Rate: 0.00113022
	LOSS [training: 0.025200395028870892 | validation: 0.018291931822016876]
	TIME [epoch: 8.83 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/20] avg loss: 0.031408105532333065		[learning rate: 0.0011276]
		[batch 20/20] avg loss: 0.030127667089452193		[learning rate: 0.0011249]
	Learning Rate: 0.00112492
	LOSS [training: 0.03076788631089263 | validation: 0.003067969690207174]
	TIME [epoch: 8.86 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026182636994568374		[learning rate: 0.0011223]
		[batch 20/20] avg loss: 0.02388809903882636		[learning rate: 0.0011196]
	Learning Rate: 0.00111965
	LOSS [training: 0.025035368016697368 | validation: 0.024185757620260484]
	TIME [epoch: 8.84 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028435420591071115		[learning rate: 0.001117]
		[batch 20/20] avg loss: 0.0776323273744399		[learning rate: 0.0011144]
	Learning Rate: 0.0011144
	LOSS [training: 0.05303387398275552 | validation: 0.044987472138244805]
	TIME [epoch: 8.84 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/20] avg loss: 0.041997917800315414		[learning rate: 0.0011118]
		[batch 20/20] avg loss: 0.024956093229725095		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.03347700551502026 | validation: 0.01195681920240385]
	TIME [epoch: 8.83 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0431041124331953		[learning rate: 0.0011066]
		[batch 20/20] avg loss: 0.05386151141406783		[learning rate: 0.001104]
	Learning Rate: 0.00110397
	LOSS [training: 0.04848281192363157 | validation: 0.04410826275818187]
	TIME [epoch: 8.83 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04115794353880336		[learning rate: 0.0011014]
		[batch 20/20] avg loss: 0.04394275200042846		[learning rate: 0.0010988]
	Learning Rate: 0.0010988
	LOSS [training: 0.0425503477696159 | validation: 0.00864007726556831]
	TIME [epoch: 8.86 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/20] avg loss: 0.032556219521807		[learning rate: 0.0010962]
		[batch 20/20] avg loss: 0.036718115878631975		[learning rate: 0.0010936]
	Learning Rate: 0.00109365
	LOSS [training: 0.03463716770021948 | validation: 0.040230514182015197]
	TIME [epoch: 8.83 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/20] avg loss: 0.045653144270614614		[learning rate: 0.0010911]
		[batch 20/20] avg loss: 0.02925008908703868		[learning rate: 0.0010885]
	Learning Rate: 0.00108852
	LOSS [training: 0.03745161667882664 | validation: 0.025464522432951615]
	TIME [epoch: 8.82 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/20] avg loss: 0.053053775390131216		[learning rate: 0.001086]
		[batch 20/20] avg loss: 0.03194866018895052		[learning rate: 0.0010834]
	Learning Rate: 0.00108342
	LOSS [training: 0.04250121778954087 | validation: 0.014038018178823365]
	TIME [epoch: 8.82 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01406345714438494		[learning rate: 0.0010809]
		[batch 20/20] avg loss: 0.01170053058065983		[learning rate: 0.0010783]
	Learning Rate: 0.00107834
	LOSS [training: 0.012881993862522385 | validation: -0.0042728200066935885]
	TIME [epoch: 8.84 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013645482945068354		[learning rate: 0.0010758]
		[batch 20/20] avg loss: 0.014273192837635434		[learning rate: 0.0010733]
	Learning Rate: 0.00107328
	LOSS [training: 0.013959337891351897 | validation: -0.005574309627766901]
	TIME [epoch: 8.83 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011670019024037045		[learning rate: 0.0010708]
		[batch 20/20] avg loss: 0.013435005907687949		[learning rate: 0.0010683]
	Learning Rate: 0.00106825
	LOSS [training: 0.012552512465862494 | validation: -0.002606896881132823]
	TIME [epoch: 8.83 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010573826142741664		[learning rate: 0.0010657]
		[batch 20/20] avg loss: 0.015150371778769262		[learning rate: 0.0010632]
	Learning Rate: 0.00106324
	LOSS [training: 0.012862098960755467 | validation: 0.0016507060107294133]
	TIME [epoch: 8.82 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022476923605519943		[learning rate: 0.0010607]
		[batch 20/20] avg loss: 0.010099514245171477		[learning rate: 0.0010583]
	Learning Rate: 0.00105826
	LOSS [training: 0.01628821892534571 | validation: -0.0017493262364593673]
	TIME [epoch: 8.81 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017902087072521528		[learning rate: 0.0010558]
		[batch 20/20] avg loss: 0.022502306893995485		[learning rate: 0.0010533]
	Learning Rate: 0.0010533
	LOSS [training: 0.020202196983258505 | validation: 0.02510301612606778]
	TIME [epoch: 8.84 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04757924516939001		[learning rate: 0.0010508]
		[batch 20/20] avg loss: 0.028312812566022045		[learning rate: 0.0010484]
	Learning Rate: 0.00104836
	LOSS [training: 0.03794602886770602 | validation: 0.0187169381682195]
	TIME [epoch: 8.84 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03525421723826621		[learning rate: 0.0010459]
		[batch 20/20] avg loss: 0.0229260781812309		[learning rate: 0.0010434]
	Learning Rate: 0.00104344
	LOSS [training: 0.029090147709748555 | validation: 0.006633967291607766]
	TIME [epoch: 8.82 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023037100585666635		[learning rate: 0.001041]
		[batch 20/20] avg loss: 0.01174502424531693		[learning rate: 0.0010386]
	Learning Rate: 0.00103855
	LOSS [training: 0.017391062415491786 | validation: -0.002834085077386681]
	TIME [epoch: 8.82 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028446624437552664		[learning rate: 0.0010361]
		[batch 20/20] avg loss: 0.021228508846375498		[learning rate: 0.0010337]
	Learning Rate: 0.00103368
	LOSS [training: 0.024837566641964084 | validation: 0.010654704951210877]
	TIME [epoch: 8.81 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010456422168067279		[learning rate: 0.0010313]
		[batch 20/20] avg loss: 0.027933328537206502		[learning rate: 0.0010288]
	Learning Rate: 0.00102884
	LOSS [training: 0.019194875352636892 | validation: 0.004452893242937546]
	TIME [epoch: 8.83 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0254711667516568		[learning rate: 0.0010264]
		[batch 20/20] avg loss: 0.031472448236843066		[learning rate: 0.001024]
	Learning Rate: 0.00102401
	LOSS [training: 0.028471807494249934 | validation: 0.014272046633908112]
	TIME [epoch: 8.82 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0244996752796033		[learning rate: 0.0010216]
		[batch 20/20] avg loss: 0.012263502506257438		[learning rate: 0.0010192]
	Learning Rate: 0.00101921
	LOSS [training: 0.018381588892930366 | validation: -0.0010039532783949132]
	TIME [epoch: 8.82 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022573100568506275		[learning rate: 0.0010168]
		[batch 20/20] avg loss: 0.022391799176486964		[learning rate: 0.0010144]
	Learning Rate: 0.00101444
	LOSS [training: 0.022482449872496618 | validation: 0.004802339429677285]
	TIME [epoch: 8.82 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0152301902503123		[learning rate: 0.0010121]
		[batch 20/20] avg loss: 0.02276850713008245		[learning rate: 0.0010097]
	Learning Rate: 0.00100968
	LOSS [training: 0.018999348690197378 | validation: 0.0005770145859773628]
	TIME [epoch: 8.81 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022365144384860293		[learning rate: 0.0010073]
		[batch 20/20] avg loss: 0.0375022731548878		[learning rate: 0.0010049]
	Learning Rate: 0.00100495
	LOSS [training: 0.02993370876987405 | validation: 0.03537497180474537]
	TIME [epoch: 8.86 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029317167725543908		[learning rate: 0.0010026]
		[batch 20/20] avg loss: 0.011736339597776082		[learning rate: 0.0010002]
	Learning Rate: 0.00100023
	LOSS [training: 0.020526753661659992 | validation: -0.010357895031469513]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240214_171650/states/model_tr_study2_500.pth
	Model improved!!!
Finished training in 4463.316 seconds.
