Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r3', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1137109822

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.777425573443088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.777425573443088 | validation: 4.6760502625582925]
	TIME [epoch: 94 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.592068820647502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.592068820647502 | validation: 4.889225237463668]
	TIME [epoch: 5.79 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.284643177202129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.284643177202129 | validation: 3.658034876926048]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9375361748601883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9375361748601883 | validation: 3.7674965856704627]
	TIME [epoch: 5.73 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5692953009624873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5692953009624873 | validation: 3.0489317971738066]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3539649274404293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3539649274404293 | validation: 3.6498051169465078]
	TIME [epoch: 5.72 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.342411203142039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.342411203142039 | validation: 2.8825173002715663]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.193383590884996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.193383590884996 | validation: 2.923141974570059]
	TIME [epoch: 5.75 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.059849322011559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.059849322011559 | validation: 2.686426331947099]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0865349123027785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0865349123027785 | validation: 2.604798231717058]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8107388584004758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8107388584004758 | validation: 2.5445824314053302]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8813323739689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8813323739689 | validation: 2.479789188309635]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6345250723845437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6345250723845437 | validation: 2.487247347621525]
	TIME [epoch: 5.71 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5518742501284377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5518742501284377 | validation: 2.317388186080215]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5883294959376566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5883294959376566 | validation: 2.463107321124618]
	TIME [epoch: 5.73 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.557895526857296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.557895526857296 | validation: 2.4954128616761078]
	TIME [epoch: 5.72 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2479768488863536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2479768488863536 | validation: 2.083208397903446]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.533959847026833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.533959847026833 | validation: 2.2094564038987303]
	TIME [epoch: 5.71 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2432774356242047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2432774356242047 | validation: 1.9505137913629529]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.114948711884476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.114948711884476 | validation: 2.3119004441736]
	TIME [epoch: 5.73 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245732844124308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.245732844124308 | validation: 2.0318901760910073]
	TIME [epoch: 5.73 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8256530180002097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8256530180002097 | validation: 2.2232727574175586]
	TIME [epoch: 5.71 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6896799704348715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6896799704348715 | validation: 7.327773454237902]
	TIME [epoch: 5.71 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.906891183454589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.906891183454589 | validation: 1.9737570702142946]
	TIME [epoch: 5.71 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9797864042466933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9797864042466933 | validation: 2.015906487872868]
	TIME [epoch: 5.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2490799152074765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2490799152074765 | validation: 2.1485809625004304]
	TIME [epoch: 5.71 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.019364624330069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.019364624330069 | validation: 1.7037008185280087]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7713079564539702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7713079564539702 | validation: 1.7407064714848348]
	TIME [epoch: 5.71 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8402095408874568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8402095408874568 | validation: 2.0063631057238185]
	TIME [epoch: 5.72 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8183404393986158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8183404393986158 | validation: 1.8184223089992275]
	TIME [epoch: 5.72 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7353249921272078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7353249921272078 | validation: 2.1023048501122537]
	TIME [epoch: 5.72 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6275021432219932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6275021432219932 | validation: 1.4024978117245173]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6713288172383696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6713288172383696 | validation: 1.5956565202063269]
	TIME [epoch: 5.76 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5634330511911372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5634330511911372 | validation: 1.3532421066575282]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.587882905956341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.587882905956341 | validation: 1.8500647138546458]
	TIME [epoch: 5.72 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6104601961922969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6104601961922969 | validation: 1.3804996344472984]
	TIME [epoch: 5.72 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5504306912310712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5504306912310712 | validation: 1.8564439303757925]
	TIME [epoch: 5.72 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4399697836367111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4399697836367111 | validation: 1.6491212484899822]
	TIME [epoch: 5.72 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3284485574716878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3284485574716878 | validation: 1.2883160226937904]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7493753599308977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7493753599308977 | validation: 1.173066248240435]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4391578105897969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4391578105897969 | validation: 1.1886200520129453]
	TIME [epoch: 5.71 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.269254515214889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.269254515214889 | validation: 1.7488278722624326]
	TIME [epoch: 5.71 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4471669584948257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4471669584948257 | validation: 1.6883657886839831]
	TIME [epoch: 5.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3877464713006853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3877464713006853 | validation: 1.3794010006839037]
	TIME [epoch: 5.72 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1467540110423153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1467540110423153 | validation: 0.8292715441512953]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4390648338148768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4390648338148768 | validation: 0.8727732534911565]
	TIME [epoch: 5.73 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2758012611431673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2758012611431673 | validation: 0.9736429103201403]
	TIME [epoch: 5.73 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3692849914347687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3692849914347687 | validation: 1.30064134824512]
	TIME [epoch: 5.71 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102938259238917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.102938259238917 | validation: 1.7636386697871624]
	TIME [epoch: 5.71 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234393712538155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.234393712538155 | validation: 0.9064005802845612]
	TIME [epoch: 5.71 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2780688630668975		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.2780688630668975 | validation: 0.7943949794079858]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2727040820689475		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.2727040820689475 | validation: 0.9797284282175471]
	TIME [epoch: 5.76 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0563936235751221		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.0563936235751221 | validation: 1.4927285169322178]
	TIME [epoch: 5.71 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1255160223903153		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.1255160223903153 | validation: 1.2708637870005066]
	TIME [epoch: 5.72 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601981864416934		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.0601981864416934 | validation: 0.7346303152472191]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2865848995036384		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.2865848995036384 | validation: 0.7690782525704956]
	TIME [epoch: 5.72 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5840288207168884		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.5840288207168884 | validation: 1.1210326073145063]
	TIME [epoch: 5.74 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2830618748526477		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.2830618748526477 | validation: 0.7829940736189027]
	TIME [epoch: 5.76 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0385570704953035		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.0385570704953035 | validation: 1.5302072931405641]
	TIME [epoch: 5.73 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2738605612127663		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.2738605612127663 | validation: 0.7710482566772352]
	TIME [epoch: 5.73 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.939594377695853		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.939594377695853 | validation: 0.7260277051389729]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0017315630819308		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.0017315630819308 | validation: 1.1439400981537875]
	TIME [epoch: 5.73 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9118693215980261		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.9118693215980261 | validation: 0.6974643491805286]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8918301261356114		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.8918301261356114 | validation: 1.412479876940309]
	TIME [epoch: 5.77 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0064432991439438		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.0064432991439438 | validation: 0.5918505644098487]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879123944184365		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.6879123944184365 | validation: 1.7620426143099377]
	TIME [epoch: 5.73 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1486594952676794		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.1486594952676794 | validation: 0.6147828732059618]
	TIME [epoch: 5.73 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7065889462307897		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.7065889462307897 | validation: 0.8807687691698988]
	TIME [epoch: 5.73 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8833627703701942		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.8833627703701942 | validation: 0.9649619275486003]
	TIME [epoch: 5.75 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7976341727192463		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.7976341727192463 | validation: 1.1248788981483298]
	TIME [epoch: 5.75 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1767327444149347		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.1767327444149347 | validation: 0.5139579697684422]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6273866912779718		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.6273866912779718 | validation: 0.9044109871067602]
	TIME [epoch: 5.73 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2926288158407468		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.2926288158407468 | validation: 0.6359236541735096]
	TIME [epoch: 5.73 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9270242087097409		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.9270242087097409 | validation: 0.8180560642524634]
	TIME [epoch: 5.73 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7979713097317519		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.7979713097317519 | validation: 0.7257967572998433]
	TIME [epoch: 5.75 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8641078414453893		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.8641078414453893 | validation: 0.8872497817500548]
	TIME [epoch: 5.75 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8336580100881789		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.8336580100881789 | validation: 0.8313485429106332]
	TIME [epoch: 5.72 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.76245534755026		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.76245534755026 | validation: 0.4435863337031894]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7797456641310474		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7797456641310474 | validation: 0.4750732667118329]
	TIME [epoch: 5.73 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5711724632114914		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.5711724632114914 | validation: 1.0695479061500905]
	TIME [epoch: 5.73 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070408099564403		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.7070408099564403 | validation: 1.184790886388924]
	TIME [epoch: 5.75 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9227455890915469		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.9227455890915469 | validation: 0.7446792848859835]
	TIME [epoch: 5.75 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8201846448289346		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.8201846448289346 | validation: 0.5222004941708971]
	TIME [epoch: 5.72 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911642131388669		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.6911642131388669 | validation: 0.45063210780098945]
	TIME [epoch: 5.73 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6455438238549707		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.6455438238549707 | validation: 0.8097579703721158]
	TIME [epoch: 5.72 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.747968121541722		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.747968121541722 | validation: 0.4972713925557439]
	TIME [epoch: 5.72 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5574169539787331		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.5574169539787331 | validation: 0.9004978829720457]
	TIME [epoch: 5.75 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9742132061130886		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.9742132061130886 | validation: 0.6334095323426039]
	TIME [epoch: 5.75 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.819067271261675		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.819067271261675 | validation: 0.5763600453201267]
	TIME [epoch: 5.73 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7970680283657778		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.7970680283657778 | validation: 1.0257766833528872]
	TIME [epoch: 5.73 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616368401349368		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6616368401349368 | validation: 0.58503537059201]
	TIME [epoch: 5.73 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5814037047604264		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.5814037047604264 | validation: 0.4881221991081776]
	TIME [epoch: 5.72 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5738317921266467		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.5738317921266467 | validation: 0.8381144335718176]
	TIME [epoch: 5.75 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7767364350970037		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.7767364350970037 | validation: 0.5533772170750486]
	TIME [epoch: 5.75 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5945947166093469		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.5945947166093469 | validation: 0.49932853562729224]
	TIME [epoch: 5.73 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8109641317750905		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.8109641317750905 | validation: 1.0103294942464487]
	TIME [epoch: 5.72 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484126848865311		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.7484126848865311 | validation: 0.431286769640046]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462949619212052		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.5462949619212052 | validation: 0.6408583375119458]
	TIME [epoch: 5.73 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266008362639218		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.7266008362639218 | validation: 0.49279566765877686]
	TIME [epoch: 5.75 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5903305550057798		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.5903305550057798 | validation: 0.5437905074704272]
	TIME [epoch: 5.75 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5942580786861451		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.5942580786861451 | validation: 0.6769004016675894]
	TIME [epoch: 5.73 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6257272169151122		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.6257272169151122 | validation: 0.6571687714797139]
	TIME [epoch: 5.72 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5298170325872384		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.5298170325872384 | validation: 0.8210753815287731]
	TIME [epoch: 5.72 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555175494223406		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.555175494223406 | validation: 0.62843019748312]
	TIME [epoch: 5.72 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5445790066405065		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.5445790066405065 | validation: 0.3157053458490535]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7431467559590669		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.7431467559590669 | validation: 0.6473402058324402]
	TIME [epoch: 5.75 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329991779262205		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.7329991779262205 | validation: 0.4569502544889838]
	TIME [epoch: 5.73 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5522890056135386		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.5522890056135386 | validation: 1.682417062703232]
	TIME [epoch: 5.72 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9545508917292687		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.9545508917292687 | validation: 0.42223326629594754]
	TIME [epoch: 5.73 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46761416494428754		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.46761416494428754 | validation: 0.4995845331439195]
	TIME [epoch: 5.72 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520209076574798		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.7520209076574798 | validation: 0.3197484357554479]
	TIME [epoch: 5.75 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45645055951319036		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.45645055951319036 | validation: 0.4296589152543889]
	TIME [epoch: 5.74 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4482628795015557		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.4482628795015557 | validation: 0.8728273435129833]
	TIME [epoch: 5.73 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974662537246583		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.6974662537246583 | validation: 0.28800573388555734]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189657325364639		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.7189657325364639 | validation: 0.40469944860886414]
	TIME [epoch: 5.71 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5882173282634856		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.5882173282634856 | validation: 0.3353559350027531]
	TIME [epoch: 5.71 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4033082714109152		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.4033082714109152 | validation: 0.3441184865233399]
	TIME [epoch: 5.74 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.893681924361862		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.893681924361862 | validation: 1.3375694528661337]
	TIME [epoch: 5.72 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9253339806038754		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.9253339806038754 | validation: 0.42435037301123646]
	TIME [epoch: 5.72 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.524732034382636		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.524732034382636 | validation: 0.3848140857792089]
	TIME [epoch: 5.71 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4327239821556724		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.4327239821556724 | validation: 0.3822754079752663]
	TIME [epoch: 5.71 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5716116725381662		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.5716116725381662 | validation: 0.3767117691748109]
	TIME [epoch: 5.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938661165282342		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.3938661165282342 | validation: 0.31571422866513227]
	TIME [epoch: 5.73 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43143848193037004		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.43143848193037004 | validation: 0.46505142213121864]
	TIME [epoch: 5.73 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5775776163961317		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5775776163961317 | validation: 0.36581924759927037]
	TIME [epoch: 5.71 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4620616517313552		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.4620616517313552 | validation: 0.3689800235926466]
	TIME [epoch: 5.71 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48079078496616307		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.48079078496616307 | validation: 0.7078361763314673]
	TIME [epoch: 5.71 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.503893249928952		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.503893249928952 | validation: 0.2768023801369387]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4941084783002581		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.4941084783002581 | validation: 0.4377558087754527]
	TIME [epoch: 5.75 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4182970350069871		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.4182970350069871 | validation: 0.35130808828189936]
	TIME [epoch: 5.73 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41033449276329165		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.41033449276329165 | validation: 0.2673047977596066]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5153252280841135		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.5153252280841135 | validation: 0.6875280009750947]
	TIME [epoch: 5.71 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49125382523656164		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.49125382523656164 | validation: 0.33712188355412365]
	TIME [epoch: 5.73 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5096072580525128		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.5096072580525128 | validation: 0.40591451282010815]
	TIME [epoch: 5.72 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5705558637067525		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.5705558637067525 | validation: 1.2789081022576654]
	TIME [epoch: 5.75 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6913435682401938		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.6913435682401938 | validation: 0.48811587049375366]
	TIME [epoch: 5.73 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47373531605045294		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.47373531605045294 | validation: 0.3895964800025667]
	TIME [epoch: 5.71 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5012654982231963		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.5012654982231963 | validation: 0.5518273984367931]
	TIME [epoch: 5.71 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7451852848412671		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.7451852848412671 | validation: 0.3048313936254721]
	TIME [epoch: 5.72 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743192155695634		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.3743192155695634 | validation: 0.35133656294326854]
	TIME [epoch: 5.71 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42565998997921217		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.42565998997921217 | validation: 0.6053855065438422]
	TIME [epoch: 5.73 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48373911886019894		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.48373911886019894 | validation: 0.26376538968568214]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35272039867617705		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.35272039867617705 | validation: 0.3359504992801064]
	TIME [epoch: 5.73 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4962525985401047		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.4962525985401047 | validation: 0.7426644807107116]
	TIME [epoch: 5.73 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45033071393588736		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.45033071393588736 | validation: 0.33904708901191655]
	TIME [epoch: 5.73 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472613191029017		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.4472613191029017 | validation: 0.5350811514959259]
	TIME [epoch: 5.73 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4847341563642899		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.4847341563642899 | validation: 0.35276408725843156]
	TIME [epoch: 5.77 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4329463476687784		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.4329463476687784 | validation: 0.32875130843213335]
	TIME [epoch: 5.74 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126991258123825		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.5126991258123825 | validation: 0.2790404387149244]
	TIME [epoch: 5.73 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48237844326281387		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.48237844326281387 | validation: 0.35874660790075635]
	TIME [epoch: 5.73 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3900899494471183		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.3900899494471183 | validation: 0.24734776839732717]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496219424378252		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3496219424378252 | validation: 0.2488838832428185]
	TIME [epoch: 5.73 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2815937964727978		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.2815937964727978 | validation: 0.2767358869781129]
	TIME [epoch: 5.76 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3257609257869486		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.3257609257869486 | validation: 0.4285810323606393]
	TIME [epoch: 5.74 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6982010963780827		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.6982010963780827 | validation: 0.2805158207197706]
	TIME [epoch: 5.73 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43484047239992174		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.43484047239992174 | validation: 0.4507450570242714]
	TIME [epoch: 5.73 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.444840382639285		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.444840382639285 | validation: 0.21720824132494415]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36649913884509877		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.36649913884509877 | validation: 0.3414694567604266]
	TIME [epoch: 5.73 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35847684365585153		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.35847684365585153 | validation: 0.3950052776212354]
	TIME [epoch: 5.76 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40822799935615667		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.40822799935615667 | validation: 0.18448347765656084]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47959207695003403		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.47959207695003403 | validation: 0.3889284887071352]
	TIME [epoch: 5.73 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918339964580059		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.3918339964580059 | validation: 0.3677272869378397]
	TIME [epoch: 5.73 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024492115976358		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.5024492115976358 | validation: 0.40167899460405293]
	TIME [epoch: 5.73 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4120999876497823		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.4120999876497823 | validation: 0.21968346713875064]
	TIME [epoch: 5.73 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35266639840751285		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.35266639840751285 | validation: 0.5519481504865836]
	TIME [epoch: 5.76 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5354174897687778		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.5354174897687778 | validation: 0.3148992032497075]
	TIME [epoch: 5.74 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3752146898536579		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.3752146898536579 | validation: 0.3147744369394766]
	TIME [epoch: 5.73 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38458233878839404		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.38458233878839404 | validation: 0.6722764361783742]
	TIME [epoch: 5.73 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47062552121653733		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.47062552121653733 | validation: 0.4071636399504353]
	TIME [epoch: 5.73 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643038537596179		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.4643038537596179 | validation: 0.26095263197008334]
	TIME [epoch: 5.73 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.391910069141592		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.391910069141592 | validation: 0.35167302854874144]
	TIME [epoch: 5.76 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3897621814563371		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.3897621814563371 | validation: 0.46967910765217463]
	TIME [epoch: 5.74 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4209594721299051		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.4209594721299051 | validation: 0.26181875369528196]
	TIME [epoch: 5.73 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36662392234930535		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.36662392234930535 | validation: 0.3849935677039051]
	TIME [epoch: 5.73 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37831246997923884		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.37831246997923884 | validation: 0.3837031799371094]
	TIME [epoch: 5.73 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39925138019428064		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.39925138019428064 | validation: 0.20939023847498003]
	TIME [epoch: 5.73 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3406079736995522		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.3406079736995522 | validation: 0.3404984163053974]
	TIME [epoch: 5.76 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33055700633619733		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.33055700633619733 | validation: 0.4321730235350957]
	TIME [epoch: 5.74 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4829495755938753		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.4829495755938753 | validation: 0.36469872527604835]
	TIME [epoch: 5.73 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37055682267588375		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.37055682267588375 | validation: 0.22517293532521898]
	TIME [epoch: 5.73 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28954996945669315		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.28954996945669315 | validation: 0.36413578151924186]
	TIME [epoch: 5.73 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926297422242164		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.3926297422242164 | validation: 0.4279665727149012]
	TIME [epoch: 5.73 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45941063315406544		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.45941063315406544 | validation: 0.3759238690503892]
	TIME [epoch: 5.76 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3287953217378364		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.3287953217378364 | validation: 0.22500335609282507]
	TIME [epoch: 5.74 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31751355787706653		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.31751355787706653 | validation: 0.5657271412939752]
	TIME [epoch: 5.73 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889775530413384		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.3889775530413384 | validation: 0.2635479744526291]
	TIME [epoch: 5.73 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3076250852213849		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.3076250852213849 | validation: 0.24997579798531974]
	TIME [epoch: 5.73 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2479326537206826		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2479326537206826 | validation: 0.21457505511265088]
	TIME [epoch: 5.73 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3761351813989828		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.3761351813989828 | validation: 0.3592330943010667]
	TIME [epoch: 5.76 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4447851696965749		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.4447851696965749 | validation: 0.25565374136895774]
	TIME [epoch: 5.74 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.450575808708538		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.450575808708538 | validation: 0.24089930242435226]
	TIME [epoch: 5.73 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2833408209955862		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.2833408209955862 | validation: 0.2818198561233424]
	TIME [epoch: 5.73 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38122599589075934		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.38122599589075934 | validation: 0.2773146758587399]
	TIME [epoch: 5.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42206817651872136		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.42206817651872136 | validation: 0.49310545081196283]
	TIME [epoch: 5.73 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5752723488718027		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.5752723488718027 | validation: 0.2719128309951917]
	TIME [epoch: 5.76 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29680576240748846		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.29680576240748846 | validation: 0.3570298995625653]
	TIME [epoch: 5.74 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3394085236685134		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.3394085236685134 | validation: 0.2549538505897113]
	TIME [epoch: 5.73 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32858507279522836		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.32858507279522836 | validation: 0.4122676626839423]
	TIME [epoch: 5.73 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3052266483002054		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.3052266483002054 | validation: 0.17996335107308034]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27616529843827387		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.27616529843827387 | validation: 0.33153880638711947]
	TIME [epoch: 5.73 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36197609534706165		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.36197609534706165 | validation: 0.3397560857389054]
	TIME [epoch: 5.76 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36769925955035154		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.36769925955035154 | validation: 0.2512760939030796]
	TIME [epoch: 5.74 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666285130826561		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.2666285130826561 | validation: 0.16292651030539912]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286216540402682		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.286216540402682 | validation: 0.3098800127492124]
	TIME [epoch: 5.73 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3684463180151877		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.3684463180151877 | validation: 0.2640020872456137]
	TIME [epoch: 5.73 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31188455931045755		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.31188455931045755 | validation: 0.24375265652525357]
	TIME [epoch: 5.73 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.447220893817469		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.447220893817469 | validation: 0.38239923841724394]
	TIME [epoch: 5.76 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3874981120238503		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.3874981120238503 | validation: 0.1936940455425641]
	TIME [epoch: 5.74 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642838083123644		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2642838083123644 | validation: 0.1727672029837629]
	TIME [epoch: 5.73 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4115064281993862		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.4115064281993862 | validation: 0.3035039291591407]
	TIME [epoch: 5.73 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25780817425607894		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.25780817425607894 | validation: 0.1596310201657634]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25244683779930965		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.25244683779930965 | validation: 0.17445162173268217]
	TIME [epoch: 5.73 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30261926174819137		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.30261926174819137 | validation: 0.3565980396792256]
	TIME [epoch: 5.76 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2818395689432452		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.2818395689432452 | validation: 0.35187942957667295]
	TIME [epoch: 5.74 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3051550428563416		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3051550428563416 | validation: 0.18588712810715893]
	TIME [epoch: 5.73 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24147437099775965		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.24147437099775965 | validation: 0.17713439941121023]
	TIME [epoch: 5.73 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781352430501463		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.2781352430501463 | validation: 0.2998704572415455]
	TIME [epoch: 5.72 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28985949949589057		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.28985949949589057 | validation: 0.1947294677145613]
	TIME [epoch: 5.73 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544901840121423		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.2544901840121423 | validation: 0.1631596847961331]
	TIME [epoch: 5.76 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27046037135623446		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.27046037135623446 | validation: 0.2289023188455877]
	TIME [epoch: 5.74 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4979283807819713		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.4979283807819713 | validation: 0.29352763940807136]
	TIME [epoch: 5.73 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3085308200193268		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.3085308200193268 | validation: 0.2982054863064245]
	TIME [epoch: 5.73 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3456588111271883		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.3456588111271883 | validation: 0.34253547029633424]
	TIME [epoch: 5.73 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4558340940693567		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.4558340940693567 | validation: 0.3172966897020851]
	TIME [epoch: 5.73 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3079749892847121		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.3079749892847121 | validation: 0.31536168743083054]
	TIME [epoch: 5.76 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33497575196487017		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.33497575196487017 | validation: 0.2564810547530302]
	TIME [epoch: 5.74 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517157671526816		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.2517157671526816 | validation: 0.24188230283247653]
	TIME [epoch: 5.73 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671588769571098		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.2671588769571098 | validation: 0.20282536342020344]
	TIME [epoch: 5.73 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39661719858585576		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.39661719858585576 | validation: 0.21494693841300128]
	TIME [epoch: 5.73 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31251553625632644		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.31251553625632644 | validation: 0.2505185058648713]
	TIME [epoch: 5.73 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36842173659770955		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.36842173659770955 | validation: 0.4574511589380396]
	TIME [epoch: 5.76 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4133348889149268		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.4133348889149268 | validation: 0.2757685651163691]
	TIME [epoch: 5.74 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889230702209578		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.2889230702209578 | validation: 0.18484252603588844]
	TIME [epoch: 5.73 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26237843308806835		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.26237843308806835 | validation: 0.15602286551245245]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501293383905025		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.2501293383905025 | validation: 0.3826646611618375]
	TIME [epoch: 5.73 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158530995028042		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.5158530995028042 | validation: 0.14943638133607687]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23360419213422529		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.23360419213422529 | validation: 0.18916845269501373]
	TIME [epoch: 5.76 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512638713419745		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.2512638713419745 | validation: 0.34004325148702835]
	TIME [epoch: 5.73 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37732975370763916		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.37732975370763916 | validation: 0.20405490242223645]
	TIME [epoch: 5.73 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003558556567257		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.3003558556567257 | validation: 0.2920437835903834]
	TIME [epoch: 5.79 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25187500145237224		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.25187500145237224 | validation: 0.16471385368189803]
	TIME [epoch: 5.73 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24625742544693816		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.24625742544693816 | validation: 0.1725291200821728]
	TIME [epoch: 5.73 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22261773602247925		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.22261773602247925 | validation: 0.45332834224465496]
	TIME [epoch: 5.76 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349223536193494		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.3349223536193494 | validation: 0.2263557998020831]
	TIME [epoch: 5.74 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285666396619138		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.285666396619138 | validation: 0.16781745977235663]
	TIME [epoch: 5.73 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2329949145253707		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.2329949145253707 | validation: 0.1974879494706447]
	TIME [epoch: 5.73 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31729632966086296		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.31729632966086296 | validation: 0.15104522808531667]
	TIME [epoch: 5.73 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17806080007617306		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.17806080007617306 | validation: 0.19220889252826454]
	TIME [epoch: 5.73 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24168848776451404		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.24168848776451404 | validation: 0.14916179364886908]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24416426100137223		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.24416426100137223 | validation: 0.15287810446038408]
	TIME [epoch: 5.74 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2164356080132015		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2164356080132015 | validation: 0.16703929340800472]
	TIME [epoch: 5.73 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2663421087154408		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.2663421087154408 | validation: 0.29892588249936675]
	TIME [epoch: 5.73 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3502682259330145		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.3502682259330145 | validation: 0.2017117204571104]
	TIME [epoch: 5.73 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26683740161154923		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.26683740161154923 | validation: 0.2862124745851493]
	TIME [epoch: 5.73 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2346765728038986		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.2346765728038986 | validation: 0.20864513212748698]
	TIME [epoch: 5.76 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19922577949817868		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.19922577949817868 | validation: 0.11346900245794801]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3183097430470402		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.3183097430470402 | validation: 0.42602210597819423]
	TIME [epoch: 5.73 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27035364425742586		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.27035364425742586 | validation: 0.31438881881110564]
	TIME [epoch: 5.73 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2547225973797227		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.2547225973797227 | validation: 0.47199786251002485]
	TIME [epoch: 5.73 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783811018678629		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2783811018678629 | validation: 0.14379844991030286]
	TIME [epoch: 5.73 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2886686240721498		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.2886686240721498 | validation: 0.20134578924083696]
	TIME [epoch: 5.76 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22547159739252332		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.22547159739252332 | validation: 0.15043153595568928]
	TIME [epoch: 5.73 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334869460546691		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.3334869460546691 | validation: 0.17635401355500668]
	TIME [epoch: 5.73 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30740711335222803		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.30740711335222803 | validation: 0.33601718136264097]
	TIME [epoch: 5.73 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28916067702683823		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.28916067702683823 | validation: 0.18242592331403834]
	TIME [epoch: 5.73 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2579966931337013		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.2579966931337013 | validation: 0.18840447002724173]
	TIME [epoch: 5.73 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23518438226380153		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.23518438226380153 | validation: 0.16942718423956962]
	TIME [epoch: 5.76 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21344302715061972		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.21344302715061972 | validation: 0.32434881930498477]
	TIME [epoch: 5.73 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2944506725799233		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.2944506725799233 | validation: 0.15141124429532846]
	TIME [epoch: 5.73 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25061368634563486		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.25061368634563486 | validation: 0.14400152022651003]
	TIME [epoch: 5.73 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19600546518095935		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.19600546518095935 | validation: 0.1900765349828587]
	TIME [epoch: 5.73 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1932921762538843		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.1932921762538843 | validation: 0.21379141230862686]
	TIME [epoch: 5.73 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32711745917094326		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.32711745917094326 | validation: 0.20845596549584436]
	TIME [epoch: 5.76 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3078642408780288		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.3078642408780288 | validation: 0.3289304020536082]
	TIME [epoch: 5.74 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3294697296697612		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.3294697296697612 | validation: 0.30130113601470515]
	TIME [epoch: 5.73 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31916442731825956		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.31916442731825956 | validation: 0.1547184340498948]
	TIME [epoch: 5.73 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22257752298731603		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.22257752298731603 | validation: 0.17712829348117987]
	TIME [epoch: 5.73 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24635509959532678		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.24635509959532678 | validation: 0.23982909512862244]
	TIME [epoch: 5.73 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21056645564671278		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.21056645564671278 | validation: 0.11303805347942993]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1928345790609359		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.1928345790609359 | validation: 0.4640351050073687]
	TIME [epoch: 5.74 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3627529684384961		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.3627529684384961 | validation: 0.22223373117926903]
	TIME [epoch: 5.73 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21433888050222477		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.21433888050222477 | validation: 0.2621489389756105]
	TIME [epoch: 5.73 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710227388633283		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.2710227388633283 | validation: 0.18244377701850964]
	TIME [epoch: 5.73 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20317651220225955		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.20317651220225955 | validation: 0.2994377295073957]
	TIME [epoch: 5.73 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26569008732381816		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.26569008732381816 | validation: 0.20779476396283847]
	TIME [epoch: 5.77 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20492768463328798		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.20492768463328798 | validation: 0.1768701678543224]
	TIME [epoch: 5.73 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21081800104582987		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.21081800104582987 | validation: 0.11971708223275995]
	TIME [epoch: 5.73 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21918578802553113		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.21918578802553113 | validation: 0.16618201128968063]
	TIME [epoch: 5.73 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21606262323082795		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.21606262323082795 | validation: 0.18253988240990532]
	TIME [epoch: 5.73 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17803487866973222		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.17803487866973222 | validation: 0.2190619757681622]
	TIME [epoch: 5.73 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701363207297294		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.2701363207297294 | validation: 0.25182011349516453]
	TIME [epoch: 5.77 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24911601670448566		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.24911601670448566 | validation: 0.20643576515635023]
	TIME [epoch: 5.73 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2051086774723778		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.2051086774723778 | validation: 0.22386026745507018]
	TIME [epoch: 5.73 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41351732324799845		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.41351732324799845 | validation: 0.27471943316057906]
	TIME [epoch: 5.73 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25198844325175523		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.25198844325175523 | validation: 0.14915674891359765]
	TIME [epoch: 5.73 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1752332124450048		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.1752332124450048 | validation: 0.16216702793712287]
	TIME [epoch: 5.73 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841517315345635		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.1841517315345635 | validation: 0.12717793421917845]
	TIME [epoch: 5.77 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2264974905976571		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.2264974905976571 | validation: 0.1847520373452989]
	TIME [epoch: 5.73 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2024825592612897		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.2024825592612897 | validation: 0.19667359282529556]
	TIME [epoch: 5.73 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23137933106605896		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.23137933106605896 | validation: 0.1141645573991353]
	TIME [epoch: 5.73 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425431150767581		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.3425431150767581 | validation: 0.16873520977720616]
	TIME [epoch: 5.73 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1977914493151677		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.1977914493151677 | validation: 0.19170787560497504]
	TIME [epoch: 5.73 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23468720648770633		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.23468720648770633 | validation: 0.21819463792728755]
	TIME [epoch: 5.76 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29706677668048537		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.29706677668048537 | validation: 0.1985706107733191]
	TIME [epoch: 5.74 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2566609898126079		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.2566609898126079 | validation: 0.16821122021859847]
	TIME [epoch: 5.73 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821830352281593		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.2821830352281593 | validation: 0.24469134751010096]
	TIME [epoch: 5.73 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21743431653002723		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.21743431653002723 | validation: 0.12214839287380834]
	TIME [epoch: 5.73 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646632362911205		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.1646632362911205 | validation: 0.15139704079616195]
	TIME [epoch: 5.73 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24779202690384866		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.24779202690384866 | validation: 0.14316885037818605]
	TIME [epoch: 5.76 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18434661433154104		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.18434661433154104 | validation: 0.11990027071547811]
	TIME [epoch: 5.74 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14075844388939115		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.14075844388939115 | validation: 0.30852312613086097]
	TIME [epoch: 5.73 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509086638614998		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.2509086638614998 | validation: 0.18028593498608053]
	TIME [epoch: 5.73 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1867851238225213		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.1867851238225213 | validation: 0.11823915768845009]
	TIME [epoch: 5.73 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023695738861086		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2023695738861086 | validation: 0.23141264823323493]
	TIME [epoch: 5.73 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17912264073937378		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.17912264073937378 | validation: 0.1859100567340289]
	TIME [epoch: 5.76 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21074586682836996		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.21074586682836996 | validation: 0.3382807779054299]
	TIME [epoch: 5.74 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2102508831354215		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.2102508831354215 | validation: 0.19149133825866038]
	TIME [epoch: 5.73 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545084369531247		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.2545084369531247 | validation: 0.2829451334595147]
	TIME [epoch: 5.73 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22992124739435904		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.22992124739435904 | validation: 0.21549956215288824]
	TIME [epoch: 5.73 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2850951410228524		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.2850951410228524 | validation: 0.1452387415847498]
	TIME [epoch: 5.73 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16601714061234407		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.16601714061234407 | validation: 0.11117247800802187]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19041033358556292		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.19041033358556292 | validation: 0.20189635215873675]
	TIME [epoch: 5.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16708375151967145		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.16708375151967145 | validation: 0.1151414214366117]
	TIME [epoch: 5.73 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537995673924773		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.1537995673924773 | validation: 0.17823720696451717]
	TIME [epoch: 5.73 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1850330891270558		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.1850330891270558 | validation: 0.21147125773206477]
	TIME [epoch: 5.73 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17446957457208515		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.17446957457208515 | validation: 0.24187324154560447]
	TIME [epoch: 5.73 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21276090375989176		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.21276090375989176 | validation: 0.14973855315504778]
	TIME [epoch: 5.76 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19715444891032188		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.19715444891032188 | validation: 0.1812807327122703]
	TIME [epoch: 5.74 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18954353075083175		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.18954353075083175 | validation: 0.12421332572786256]
	TIME [epoch: 5.73 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25015150101327743		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.25015150101327743 | validation: 0.13525203215830453]
	TIME [epoch: 5.73 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23501775555464288		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.23501775555464288 | validation: 0.12679049380236532]
	TIME [epoch: 5.73 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19566466626411244		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.19566466626411244 | validation: 0.2680397620476487]
	TIME [epoch: 5.73 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18265279015647135		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.18265279015647135 | validation: 0.26206594532637684]
	TIME [epoch: 5.76 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19104419159213182		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.19104419159213182 | validation: 0.12052607842630605]
	TIME [epoch: 5.74 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16293601768645213		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.16293601768645213 | validation: 0.09328227888184434]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28952531216603705		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.28952531216603705 | validation: 0.18666996096450303]
	TIME [epoch: 5.73 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14675098003873555		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.14675098003873555 | validation: 0.10617672532092025]
	TIME [epoch: 5.73 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14936555817193653		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.14936555817193653 | validation: 0.30766204327853763]
	TIME [epoch: 5.73 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22200675751832366		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.22200675751832366 | validation: 0.10420481345231292]
	TIME [epoch: 5.75 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20062822425751425		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.20062822425751425 | validation: 0.5136836933036769]
	TIME [epoch: 5.72 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837766826128322		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.2837766826128322 | validation: 0.14394931123243396]
	TIME [epoch: 5.72 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25303451987870385		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.25303451987870385 | validation: 0.14160656915816516]
	TIME [epoch: 5.71 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2212053336240708		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.2212053336240708 | validation: 0.10183444451468426]
	TIME [epoch: 5.71 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15156485290792507		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.15156485290792507 | validation: 0.1304461946938516]
	TIME [epoch: 5.73 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16246171402604734		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.16246171402604734 | validation: 0.10804326559114963]
	TIME [epoch: 5.75 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1837875999514908		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.1837875999514908 | validation: 0.11933692278258776]
	TIME [epoch: 5.74 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17967068461387461		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.17967068461387461 | validation: 0.11398079186042548]
	TIME [epoch: 5.72 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13276225161531774		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.13276225161531774 | validation: 0.18846717304761154]
	TIME [epoch: 5.72 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2020322879432959		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.2020322879432959 | validation: 0.09862894107767925]
	TIME [epoch: 5.71 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16390575134954863		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16390575134954863 | validation: 0.16128651287047188]
	TIME [epoch: 5.72 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18008355342165952		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.18008355342165952 | validation: 0.08845775913302864]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_351.pth
	Model improved!!!
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19591607661282207		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.19591607661282207 | validation: 0.11680662468442007]
	TIME [epoch: 5.74 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18354634056678054		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.18354634056678054 | validation: 0.13728085019020372]
	TIME [epoch: 5.73 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728918914128548		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.1728918914128548 | validation: 0.1265158859955422]
	TIME [epoch: 5.73 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1879021753836172		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1879021753836172 | validation: 0.3515355433744533]
	TIME [epoch: 5.73 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412061170901036		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.3412061170901036 | validation: 0.12237496200728337]
	TIME [epoch: 5.73 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23096222718771903		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.23096222718771903 | validation: 0.1567896426253816]
	TIME [epoch: 5.76 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18985545807261753		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.18985545807261753 | validation: 0.16388186044240788]
	TIME [epoch: 5.74 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21641975425118246		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.21641975425118246 | validation: 0.10246910347060449]
	TIME [epoch: 5.73 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17604255245441747		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.17604255245441747 | validation: 0.15520136922982067]
	TIME [epoch: 5.72 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16704402925343725		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.16704402925343725 | validation: 0.13585491779113773]
	TIME [epoch: 5.72 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15036323203025057		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.15036323203025057 | validation: 0.2613082359412236]
	TIME [epoch: 5.73 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2049403368073594		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.2049403368073594 | validation: 0.11311054117967131]
	TIME [epoch: 5.76 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17320987528821524		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.17320987528821524 | validation: 0.18717518142043793]
	TIME [epoch: 5.74 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18645038182988238		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.18645038182988238 | validation: 0.12741480686759202]
	TIME [epoch: 5.72 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705584843248396		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.1705584843248396 | validation: 0.08507540561229288]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11900608178629163		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.11900608178629163 | validation: 0.1519829397506206]
	TIME [epoch: 5.73 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1684700583753861		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.1684700583753861 | validation: 0.14336540674586545]
	TIME [epoch: 5.73 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16423636435983893		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.16423636435983893 | validation: 0.1258506064384327]
	TIME [epoch: 5.77 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2160456178801642		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.2160456178801642 | validation: 0.3801397491930958]
	TIME [epoch: 5.73 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2265483928283869		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2265483928283869 | validation: 0.09753853934634474]
	TIME [epoch: 5.72 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14794757655545054		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.14794757655545054 | validation: 0.17812635675530694]
	TIME [epoch: 5.73 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15940506919585945		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.15940506919585945 | validation: 0.10240491575145808]
	TIME [epoch: 5.72 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14294326517437472		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.14294326517437472 | validation: 0.205646882602127]
	TIME [epoch: 5.71 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1892663881778459		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1892663881778459 | validation: 0.13175773169703928]
	TIME [epoch: 5.76 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15060646692970434		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.15060646692970434 | validation: 0.10766859499690207]
	TIME [epoch: 5.72 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15839097321679269		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.15839097321679269 | validation: 0.11582002321372085]
	TIME [epoch: 5.72 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15776724209640958		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.15776724209640958 | validation: 0.08733777320990285]
	TIME [epoch: 5.73 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16763631824894698		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.16763631824894698 | validation: 0.2406391064249393]
	TIME [epoch: 5.71 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1769043599443346		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.1769043599443346 | validation: 0.15132076943647121]
	TIME [epoch: 5.73 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17221614589859235		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.17221614589859235 | validation: 0.10586904947031657]
	TIME [epoch: 5.74 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17399914863061675		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.17399914863061675 | validation: 0.16226860677594865]
	TIME [epoch: 5.73 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17226073480535822		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.17226073480535822 | validation: 0.10838888218921165]
	TIME [epoch: 5.71 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18144758463950245		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.18144758463950245 | validation: 0.1004875906190857]
	TIME [epoch: 5.71 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12767429545048584		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.12767429545048584 | validation: 0.08704005019466855]
	TIME [epoch: 5.71 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11149126269994013		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.11149126269994013 | validation: 0.16235810880004725]
	TIME [epoch: 5.72 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256945422420528		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.1256945422420528 | validation: 0.10253784129529933]
	TIME [epoch: 5.76 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22300157981777619		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.22300157981777619 | validation: 0.14194191213342114]
	TIME [epoch: 5.73 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365995659771531		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.1365995659771531 | validation: 0.09058815247609474]
	TIME [epoch: 5.71 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18034355806983032		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.18034355806983032 | validation: 0.07712819213816344]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586002375251339		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.1586002375251339 | validation: 0.14148106047279504]
	TIME [epoch: 5.71 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23579231801319625		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.23579231801319625 | validation: 0.1827517958947092]
	TIME [epoch: 5.71 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20611480065111112		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.20611480065111112 | validation: 0.11491584516357567]
	TIME [epoch: 5.75 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2167932569302915		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.2167932569302915 | validation: 0.18300911228971714]
	TIME [epoch: 5.72 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18608886581313916		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.18608886581313916 | validation: 0.15520559117867835]
	TIME [epoch: 5.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20407144128244098		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.20407144128244098 | validation: 0.1873984516921545]
	TIME [epoch: 5.72 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488689325422296		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.1488689325422296 | validation: 0.18033789454847082]
	TIME [epoch: 5.72 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17680136704711635		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.17680136704711635 | validation: 0.12696640611639717]
	TIME [epoch: 5.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15831036802811876		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.15831036802811876 | validation: 0.1265261831236619]
	TIME [epoch: 5.74 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13722841383901907		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.13722841383901907 | validation: 0.08826672945182386]
	TIME [epoch: 5.72 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11354030710854086		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.11354030710854086 | validation: 0.12357844419358299]
	TIME [epoch: 5.71 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16941499987413833		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.16941499987413833 | validation: 0.12052934483034924]
	TIME [epoch: 5.72 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18278592731926485		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.18278592731926485 | validation: 0.0791661220662045]
	TIME [epoch: 5.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318496877004473		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.1318496877004473 | validation: 0.08343144985540539]
	TIME [epoch: 5.71 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12028061440805973		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.12028061440805973 | validation: 0.1244502406158772]
	TIME [epoch: 5.74 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18058553899823956		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.18058553899823956 | validation: 0.2836543529325974]
	TIME [epoch: 5.72 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20711134415884763		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.20711134415884763 | validation: 0.14868565659400276]
	TIME [epoch: 5.71 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14790345077062117		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.14790345077062117 | validation: 0.11212576758771522]
	TIME [epoch: 5.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13542836558599994		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.13542836558599994 | validation: 0.10719498483655877]
	TIME [epoch: 5.71 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13454560927173034		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.13454560927173034 | validation: 0.09073065647236636]
	TIME [epoch: 5.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15185745117406482		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.15185745117406482 | validation: 0.11622367629102957]
	TIME [epoch: 5.74 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13652373559338365		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.13652373559338365 | validation: 0.13311695713073501]
	TIME [epoch: 5.72 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549957293719761		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.1549957293719761 | validation: 0.07738020183140096]
	TIME [epoch: 5.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14629024546466463		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.14629024546466463 | validation: 0.17820212599357896]
	TIME [epoch: 5.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342835588022271		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.1342835588022271 | validation: 0.21537667055505685]
	TIME [epoch: 5.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18996809460251587		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.18996809460251587 | validation: 0.0866265432375666]
	TIME [epoch: 5.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14314863727673846		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.14314863727673846 | validation: 0.16783214058763332]
	TIME [epoch: 5.73 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13469502844366635		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.13469502844366635 | validation: 0.07026184492859142]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1848908063870589		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.1848908063870589 | validation: 0.08378617055911164]
	TIME [epoch: 5.71 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13208976395852912		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.13208976395852912 | validation: 0.1163767132253794]
	TIME [epoch: 5.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14768919718211337		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.14768919718211337 | validation: 0.09479730026699855]
	TIME [epoch: 5.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12927611297638303		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.12927611297638303 | validation: 0.1503787918371463]
	TIME [epoch: 5.72 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20239657956640103		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.20239657956640103 | validation: 0.17039403063366648]
	TIME [epoch: 5.74 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24646772739685466		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.24646772739685466 | validation: 0.20123328609316132]
	TIME [epoch: 5.73 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098620715670822		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.2098620715670822 | validation: 0.13283728276743215]
	TIME [epoch: 5.71 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12505690491144816		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.12505690491144816 | validation: 0.08829707958473812]
	TIME [epoch: 5.72 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11976387449567193		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.11976387449567193 | validation: 0.11970267355284453]
	TIME [epoch: 5.71 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145572591231506		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.145572591231506 | validation: 0.09648965707474397]
	TIME [epoch: 5.72 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13175550286247067		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.13175550286247067 | validation: 0.15525837517957125]
	TIME [epoch: 5.74 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13687322797762294		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.13687322797762294 | validation: 0.08807511559769213]
	TIME [epoch: 5.73 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269843491674082		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.1269843491674082 | validation: 0.083207540656877]
	TIME [epoch: 5.72 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20597681380325866		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.20597681380325866 | validation: 0.16180790311423188]
	TIME [epoch: 5.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14821239199040934		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.14821239199040934 | validation: 0.13031653182022981]
	TIME [epoch: 5.71 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14362828185220577		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.14362828185220577 | validation: 0.2636313903167291]
	TIME [epoch: 5.71 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18752747542711865		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.18752747542711865 | validation: 0.08574165655985487]
	TIME [epoch: 5.73 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13334157823161272		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.13334157823161272 | validation: 0.12780346355804084]
	TIME [epoch: 5.73 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365700971170733		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.1365700971170733 | validation: 0.09012697421401505]
	TIME [epoch: 5.71 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1183344996919427		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.1183344996919427 | validation: 0.09184314513167881]
	TIME [epoch: 5.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363660072122726		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.1363660072122726 | validation: 0.18652300130845023]
	TIME [epoch: 5.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13872097110479842		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.13872097110479842 | validation: 0.07779288866060996]
	TIME [epoch: 5.71 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13722972926470137		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.13722972926470137 | validation: 0.11145159002443496]
	TIME [epoch: 5.73 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555641365838001		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.1555641365838001 | validation: 0.11345203942914406]
	TIME [epoch: 5.73 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15313548985382516		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.15313548985382516 | validation: 0.07665157175504078]
	TIME [epoch: 5.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1109745608159229		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.1109745608159229 | validation: 0.10287075487864393]
	TIME [epoch: 5.71 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13510536264586906		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.13510536264586906 | validation: 0.2858037209710565]
	TIME [epoch: 5.71 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.169070336068886		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.169070336068886 | validation: 0.13726917832646923]
	TIME [epoch: 5.71 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16939658198887128		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.16939658198887128 | validation: 0.08757297713779505]
	TIME [epoch: 5.75 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284655737841659		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.1284655737841659 | validation: 0.08610802565553265]
	TIME [epoch: 5.74 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13425723185669367		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.13425723185669367 | validation: 0.06565286541122421]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10589442122919354		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.10589442122919354 | validation: 0.1166091012686881]
	TIME [epoch: 5.72 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17115829230493573		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.17115829230493573 | validation: 0.1497306061135715]
	TIME [epoch: 5.71 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12874921396841127		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.12874921396841127 | validation: 0.12037655382259878]
	TIME [epoch: 5.72 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12786150522326986		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.12786150522326986 | validation: 0.11961249190999974]
	TIME [epoch: 5.74 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12135425302830488		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.12135425302830488 | validation: 0.1218117702140128]
	TIME [epoch: 5.74 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14067043825332987		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.14067043825332987 | validation: 0.08476564728110257]
	TIME [epoch: 5.71 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11709880588707938		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.11709880588707938 | validation: 0.05694006275757179]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12471145536956171		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.12471145536956171 | validation: 0.07544029239542475]
	TIME [epoch: 5.71 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12234080492536721		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.12234080492536721 | validation: 0.09344084968761734]
	TIME [epoch: 5.71 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409254246297958		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.10409254246297958 | validation: 0.06884555886151338]
	TIME [epoch: 5.75 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13409134066411155		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.13409134066411155 | validation: 0.08773121238500668]
	TIME [epoch: 5.75 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10455363168270526		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.10455363168270526 | validation: 0.06558824044780255]
	TIME [epoch: 5.71 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134787686446752		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.1134787686446752 | validation: 0.08214592453401917]
	TIME [epoch: 5.71 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11224738184220803		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.11224738184220803 | validation: 0.06605330461672818]
	TIME [epoch: 5.71 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11125884642615849		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.11125884642615849 | validation: 0.2003151106206852]
	TIME [epoch: 5.72 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14505987945283694		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.14505987945283694 | validation: 0.07783398478593992]
	TIME [epoch: 5.75 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11865443333680953		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.11865443333680953 | validation: 0.07892947862299342]
	TIME [epoch: 5.74 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10478494158544618		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.10478494158544618 | validation: 0.08105056494426023]
	TIME [epoch: 5.72 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10753078169859115		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.10753078169859115 | validation: 0.0971792862941561]
	TIME [epoch: 5.72 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10075458634406333		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.10075458634406333 | validation: 0.07987269741759662]
	TIME [epoch: 5.72 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09252092136233908		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.09252092136233908 | validation: 0.05061665014877845]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_470.pth
	Model improved!!!
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442335298905149		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.10442335298905149 | validation: 0.06502117385794864]
	TIME [epoch: 5.74 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432459902885226		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.1432459902885226 | validation: 0.1017696128240591]
	TIME [epoch: 5.75 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10796572892259701		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.10796572892259701 | validation: 0.14517094673685868]
	TIME [epoch: 5.71 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13858674833595014		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.13858674833595014 | validation: 0.0561405174911335]
	TIME [epoch: 5.72 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08524685021831553		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.08524685021831553 | validation: 0.07124044946608646]
	TIME [epoch: 5.72 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388086351771012		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.1388086351771012 | validation: 0.062087730034594064]
	TIME [epoch: 5.72 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08942234960690593		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.08942234960690593 | validation: 0.05143477286875868]
	TIME [epoch: 5.75 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10423832615734846		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.10423832615734846 | validation: 0.15109742225756287]
	TIME [epoch: 5.75 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12805629788774966		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.12805629788774966 | validation: 0.29432900602647727]
	TIME [epoch: 5.71 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1833662487467634		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.1833662487467634 | validation: 0.08157441308186078]
	TIME [epoch: 5.72 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427011378529516		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.1427011378529516 | validation: 0.2238962181965355]
	TIME [epoch: 5.72 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33908689409447745		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.33908689409447745 | validation: 0.2946760944987651]
	TIME [epoch: 5.72 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1837520058331109		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.1837520058331109 | validation: 0.13838179809064294]
	TIME [epoch: 5.75 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12756023252489743		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.12756023252489743 | validation: 0.0616014496057633]
	TIME [epoch: 5.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936166947250234		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.07936166947250234 | validation: 0.09253975325766618]
	TIME [epoch: 5.72 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12137991789567462		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.12137991789567462 | validation: 0.23216961030434483]
	TIME [epoch: 5.72 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18208273705533445		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.18208273705533445 | validation: 0.16105811687864666]
	TIME [epoch: 5.72 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11356568982389215		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.11356568982389215 | validation: 0.09893214176604655]
	TIME [epoch: 5.72 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108102805123021		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.1108102805123021 | validation: 0.15207639899731665]
	TIME [epoch: 5.75 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1095125278047016		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1095125278047016 | validation: 0.05306353359154312]
	TIME [epoch: 5.75 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09665734339106516		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.09665734339106516 | validation: 0.10640589467688724]
	TIME [epoch: 5.72 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13350613165136915		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.13350613165136915 | validation: 0.09428079122734183]
	TIME [epoch: 5.71 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11219650257389352		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.11219650257389352 | validation: 0.08756560600252124]
	TIME [epoch: 5.73 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10229619197244935		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.10229619197244935 | validation: 0.10138541896620325]
	TIME [epoch: 5.72 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09474762424277983		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.09474762424277983 | validation: 0.07191087401749931]
	TIME [epoch: 5.75 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991332124874843		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.08991332124874843 | validation: 0.08996532873071175]
	TIME [epoch: 5.74 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08558711053891721		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.08558711053891721 | validation: 0.05253343734372737]
	TIME [epoch: 5.73 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09963524060638926		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.09963524060638926 | validation: 0.1500617425072036]
	TIME [epoch: 5.72 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13435163612533302		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.13435163612533302 | validation: 0.06601332761853679]
	TIME [epoch: 5.73 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09569378972149237		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.09569378972149237 | validation: 0.08845932898434036]
	TIME [epoch: 5.72 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11019504981047715		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.11019504981047715 | validation: 0.1147247630379312]
	TIME [epoch: 5.75 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10724150899349418		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.10724150899349418 | validation: 0.12385191802837046]
	TIME [epoch: 5.74 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11589049986476745		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.11589049986476745 | validation: 0.07986157620860165]
	TIME [epoch: 5.72 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13409403041711357		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.13409403041711357 | validation: 0.1413175129174535]
	TIME [epoch: 5.72 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24014821348165322		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.24014821348165322 | validation: 0.5953992898870996]
	TIME [epoch: 5.72 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31904022950132965		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.31904022950132965 | validation: 0.10902312564318041]
	TIME [epoch: 5.72 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13759568959606322		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.13759568959606322 | validation: 0.06485898596999248]
	TIME [epoch: 5.75 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09455088918425832		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.09455088918425832 | validation: 0.07794244543937842]
	TIME [epoch: 5.74 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09119378971982592		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.09119378971982592 | validation: 0.07205985607060558]
	TIME [epoch: 5.73 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07716872856066366		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.07716872856066366 | validation: 0.0634801198825396]
	TIME [epoch: 5.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702171821267848		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.08702171821267848 | validation: 0.14573456994715672]
	TIME [epoch: 5.73 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10390058239686775		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.10390058239686775 | validation: 0.06644497119262716]
	TIME [epoch: 5.71 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09157175753886965		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.09157175753886965 | validation: 0.06999054768954685]
	TIME [epoch: 5.74 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10899420376024488		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.10899420376024488 | validation: 0.08662073514669252]
	TIME [epoch: 5.75 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10699980117555413		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.10699980117555413 | validation: 0.07188417046656924]
	TIME [epoch: 5.72 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08853767744403152		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.08853767744403152 | validation: 0.0674092538573895]
	TIME [epoch: 5.73 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09080212868271265		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.09080212868271265 | validation: 0.06396149589490575]
	TIME [epoch: 5.73 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08158203089507912		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.08158203089507912 | validation: 0.06736975575584805]
	TIME [epoch: 5.73 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11149133597390372		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.11149133597390372 | validation: 0.047582563333964746]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_519.pth
	Model improved!!!
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989801805625529		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.0989801805625529 | validation: 0.06745395606917773]
	TIME [epoch: 5.75 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087436772902108		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.087436772902108 | validation: 0.07084209453628891]
	TIME [epoch: 5.72 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11952319080933532		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.11952319080933532 | validation: 0.09489317776204201]
	TIME [epoch: 5.71 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09290004840961866		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.09290004840961866 | validation: 0.08823854062981143]
	TIME [epoch: 5.71 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162898698826098		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.162898698826098 | validation: 0.07868933023067914]
	TIME [epoch: 5.71 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12144104875369936		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.12144104875369936 | validation: 0.08435008063464818]
	TIME [epoch: 5.74 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09515031542067284		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.09515031542067284 | validation: 0.11789021488993956]
	TIME [epoch: 5.74 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10582387483226675		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.10582387483226675 | validation: 0.10836252228861433]
	TIME [epoch: 5.72 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11083896184564201		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.11083896184564201 | validation: 0.0889510924952182]
	TIME [epoch: 5.72 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11215942777488423		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.11215942777488423 | validation: 0.06466121658003485]
	TIME [epoch: 5.72 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08921573018675454		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.08921573018675454 | validation: 0.08576989684782675]
	TIME [epoch: 5.72 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909163598457285		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.0909163598457285 | validation: 0.0957160362089296]
	TIME [epoch: 5.74 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09182891769239451		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.09182891769239451 | validation: 0.10592666987548514]
	TIME [epoch: 5.74 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14717899072130847		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.14717899072130847 | validation: 0.07922438306746153]
	TIME [epoch: 5.72 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086026645932384		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.08086026645932384 | validation: 0.056919693542622884]
	TIME [epoch: 5.72 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248131922071085		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.10248131922071085 | validation: 0.06161595161147252]
	TIME [epoch: 5.72 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11174416732458956		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.11174416732458956 | validation: 0.04863852975580362]
	TIME [epoch: 5.72 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12638685993278934		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.12638685993278934 | validation: 0.19531238668653467]
	TIME [epoch: 5.74 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747343004197813		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.1747343004197813 | validation: 0.1230024236134667]
	TIME [epoch: 5.74 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14543577660613316		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.14543577660613316 | validation: 0.1134024714457986]
	TIME [epoch: 5.72 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16529651060904288		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.16529651060904288 | validation: 0.1120568948487684]
	TIME [epoch: 5.72 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10322199632496558		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.10322199632496558 | validation: 0.059594485165287814]
	TIME [epoch: 5.72 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10372767441375975		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.10372767441375975 | validation: 0.0660612491202943]
	TIME [epoch: 5.72 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07873654549203278		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.07873654549203278 | validation: 0.06315372655940876]
	TIME [epoch: 5.73 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757353730839386		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.0757353730839386 | validation: 0.05768503368513621]
	TIME [epoch: 5.75 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0911241727293599		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.0911241727293599 | validation: 0.08587993323313307]
	TIME [epoch: 5.72 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296843784166129		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.10296843784166129 | validation: 0.06112875588860056]
	TIME [epoch: 5.72 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12670649624048735		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.12670649624048735 | validation: 0.22540269483553207]
	TIME [epoch: 5.72 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15850383260250822		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.15850383260250822 | validation: 0.15212281421575877]
	TIME [epoch: 5.72 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488703603697732		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.1488703603697732 | validation: 0.13764393893070725]
	TIME [epoch: 5.73 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11718037557922723		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.11718037557922723 | validation: 0.09196390293894913]
	TIME [epoch: 5.75 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09695333964447957		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.09695333964447957 | validation: 0.07219034656703373]
	TIME [epoch: 5.72 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0979496934632428		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.0979496934632428 | validation: 0.06867517238241973]
	TIME [epoch: 5.72 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07987504942941517		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.07987504942941517 | validation: 0.06092136607362861]
	TIME [epoch: 5.72 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08913653610402567		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.08913653610402567 | validation: 0.1310992104936659]
	TIME [epoch: 5.72 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10893731760339871		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.10893731760339871 | validation: 0.0874571601534224]
	TIME [epoch: 5.72 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0873601736227827		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.0873601736227827 | validation: 0.0429234908771171]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06628313622455792		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.06628313622455792 | validation: 0.13591440045378117]
	TIME [epoch: 5.72 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10350222016930537		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.10350222016930537 | validation: 0.054476684398259784]
	TIME [epoch: 5.71 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07716443749866107		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.07716443749866107 | validation: 0.07322039944400084]
	TIME [epoch: 5.71 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12369916478676526		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.12369916478676526 | validation: 0.07382048134644682]
	TIME [epoch: 5.71 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10348708984106975		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.10348708984106975 | validation: 0.12046581886825529]
	TIME [epoch: 5.72 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11525750920077157		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.11525750920077157 | validation: 0.15721365222510345]
	TIME [epoch: 5.74 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12634536491605358		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.12634536491605358 | validation: 0.0506104240222601]
	TIME [epoch: 5.72 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08497493237771724		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.08497493237771724 | validation: 0.07411625514159258]
	TIME [epoch: 5.71 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09527140572203396		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.09527140572203396 | validation: 0.07083036887023351]
	TIME [epoch: 5.71 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17111999332081182		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.17111999332081182 | validation: 0.10624970265868605]
	TIME [epoch: 5.71 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09450765545442731		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.09450765545442731 | validation: 0.04418352821050649]
	TIME [epoch: 5.72 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089086228438054		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.089086228438054 | validation: 0.051133364627203276]
	TIME [epoch: 5.75 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07983634317223615		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.07983634317223615 | validation: 0.08274131204893356]
	TIME [epoch: 5.72 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15049569914804034		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15049569914804034 | validation: 0.08601630983547744]
	TIME [epoch: 5.71 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12611467737914292		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.12611467737914292 | validation: 0.11294738514294014]
	TIME [epoch: 5.71 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12131833560346394		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.12131833560346394 | validation: 0.052594824645199136]
	TIME [epoch: 5.71 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08071034570187194		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.08071034570187194 | validation: 0.06574569582316274]
	TIME [epoch: 5.72 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07860953819980769		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.07860953819980769 | validation: 0.06161065944461089]
	TIME [epoch: 5.74 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08701811602234272		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.08701811602234272 | validation: 0.08816360931209012]
	TIME [epoch: 5.72 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11507940317542523		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.11507940317542523 | validation: 0.08568055774581254]
	TIME [epoch: 5.71 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11301339429539434		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.11301339429539434 | validation: 0.14487533016259732]
	TIME [epoch: 5.71 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11546186718750609		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.11546186718750609 | validation: 0.04624992264683383]
	TIME [epoch: 5.71 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07433751023892646		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.07433751023892646 | validation: 0.08852450556604353]
	TIME [epoch: 5.72 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09277202248534465		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.09277202248534465 | validation: 0.06163631904478924]
	TIME [epoch: 5.74 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10001928484360476		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.10001928484360476 | validation: 0.09522756136062704]
	TIME [epoch: 5.72 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10058595306024867		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.10058595306024867 | validation: 0.07917801900057814]
	TIME [epoch: 5.71 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0815634761562128		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.0815634761562128 | validation: 0.04727373900902555]
	TIME [epoch: 5.71 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708757226098444		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.06708757226098444 | validation: 0.04473364558356004]
	TIME [epoch: 5.71 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07439397698979221		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.07439397698979221 | validation: 0.054081117791427324]
	TIME [epoch: 5.72 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09657593822709898		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.09657593822709898 | validation: 0.05000329965748154]
	TIME [epoch: 5.74 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111499043114638		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.08111499043114638 | validation: 0.04339729387394444]
	TIME [epoch: 5.71 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837379754021844		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.0837379754021844 | validation: 0.08789912335560039]
	TIME [epoch: 5.71 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08215287470228774		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.08215287470228774 | validation: 0.0847787677146451]
	TIME [epoch: 5.71 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10144226552487226		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.10144226552487226 | validation: 0.060080277501318426]
	TIME [epoch: 5.71 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08311620345613732		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.08311620345613732 | validation: 0.06317271882915235]
	TIME [epoch: 5.72 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08846539172515223		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.08846539172515223 | validation: 0.09402646163577139]
	TIME [epoch: 5.74 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10777605781012614		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.10777605781012614 | validation: 0.06967680556354512]
	TIME [epoch: 5.72 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09407833871051327		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.09407833871051327 | validation: 0.11583201115937382]
	TIME [epoch: 5.71 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09982758455685718		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.09982758455685718 | validation: 0.1670491941663751]
	TIME [epoch: 5.71 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12005193255780809		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.12005193255780809 | validation: 0.0862305761020476]
	TIME [epoch: 5.71 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09567220798357373		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.09567220798357373 | validation: 0.10516087175473582]
	TIME [epoch: 5.71 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442421570734062		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.10442421570734062 | validation: 0.07966413097043507]
	TIME [epoch: 5.75 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11475812887063107		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.11475812887063107 | validation: 0.08394606977634533]
	TIME [epoch: 5.72 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14211093307294764		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.14211093307294764 | validation: 0.0650870763785819]
	TIME [epoch: 5.71 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07752058324837423		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.07752058324837423 | validation: 0.06331643776367239]
	TIME [epoch: 5.71 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08351788172366578		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.08351788172366578 | validation: 0.09447695289708159]
	TIME [epoch: 5.71 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08978490330394584		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.08978490330394584 | validation: 0.05370571621268775]
	TIME [epoch: 5.71 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07444268387409232		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.07444268387409232 | validation: 0.04990734867679196]
	TIME [epoch: 5.75 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06877314929855669		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.06877314929855669 | validation: 0.04962590859359386]
	TIME [epoch: 5.72 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028799567036363		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.08028799567036363 | validation: 0.05077973176806028]
	TIME [epoch: 5.71 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08736019739845578		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.08736019739845578 | validation: 0.05556830793332306]
	TIME [epoch: 5.71 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07759447574500053		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.07759447574500053 | validation: 0.06984807289560419]
	TIME [epoch: 5.71 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09460354991695599		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.09460354991695599 | validation: 0.0547781693132488]
	TIME [epoch: 5.71 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394945092679182		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.07394945092679182 | validation: 0.07079195076538122]
	TIME [epoch: 5.75 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09567522479167472		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.09567522479167472 | validation: 0.11129870460760202]
	TIME [epoch: 5.72 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10686338392892293		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.10686338392892293 | validation: 0.08807886825858699]
	TIME [epoch: 5.71 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08376744433012999		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.08376744433012999 | validation: 0.06810126340260446]
	TIME [epoch: 5.71 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06860548778871131		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.06860548778871131 | validation: 0.05455775052967221]
	TIME [epoch: 5.71 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09457506435409743		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.09457506435409743 | validation: 0.08947293265504412]
	TIME [epoch: 5.72 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07287280763197616		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.07287280763197616 | validation: 0.05100238845026016]
	TIME [epoch: 5.75 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09534471935937813		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.09534471935937813 | validation: 0.07227536117490194]
	TIME [epoch: 5.72 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11080333412655394		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.11080333412655394 | validation: 0.054846417070315116]
	TIME [epoch: 5.71 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08068859567371012		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.08068859567371012 | validation: 0.06021994085045291]
	TIME [epoch: 5.71 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07521664702766827		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.07521664702766827 | validation: 0.10276216915002095]
	TIME [epoch: 5.71 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09077130620810736		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.09077130620810736 | validation: 0.04857641176904025]
	TIME [epoch: 5.71 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06609717041996331		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.06609717041996331 | validation: 0.09407070585221904]
	TIME [epoch: 5.75 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10635319870752374		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.10635319870752374 | validation: 0.061724821144015875]
	TIME [epoch: 5.72 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0850663573746764		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.0850663573746764 | validation: 0.10146867768831856]
	TIME [epoch: 5.71 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.090442861701732		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.090442861701732 | validation: 0.0653272741843181]
	TIME [epoch: 5.71 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07644430279918582		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.07644430279918582 | validation: 0.06897200636183133]
	TIME [epoch: 5.71 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10840346327267233		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.10840346327267233 | validation: 0.0414085787660473]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_627.pth
	Model improved!!!
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06898354713462054		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.06898354713462054 | validation: 0.06602218513759751]
	TIME [epoch: 5.75 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0932973138221925		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.0932973138221925 | validation: 0.08827428796018126]
	TIME [epoch: 5.72 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11810722723918507		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.11810722723918507 | validation: 0.07059326514045075]
	TIME [epoch: 5.72 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0699806196330528		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.0699806196330528 | validation: 0.055096855403709344]
	TIME [epoch: 5.72 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09091615175259403		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.09091615175259403 | validation: 0.052492784402507306]
	TIME [epoch: 5.71 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06868475544212808		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.06868475544212808 | validation: 0.03905580230060194]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_633.pth
	Model improved!!!
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821442194601332		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.06821442194601332 | validation: 0.1040281000028453]
	TIME [epoch: 5.77 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346277027938116		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.1346277027938116 | validation: 0.07355386719080624]
	TIME [epoch: 5.71 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07704524718359246		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.07704524718359246 | validation: 0.07692283523114007]
	TIME [epoch: 5.72 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0932838546150196		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.0932838546150196 | validation: 0.11769879540768756]
	TIME [epoch: 5.72 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08279807656413758		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.08279807656413758 | validation: 0.06224318675120756]
	TIME [epoch: 5.72 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08606987943446297		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.08606987943446297 | validation: 0.03812948510736268]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0636395691376076		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.0636395691376076 | validation: 0.05360848506218369]
	TIME [epoch: 5.76 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0777625040124578		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.0777625040124578 | validation: 0.12452681535628106]
	TIME [epoch: 5.73 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17763063913195304		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.17763063913195304 | validation: 0.1009212128367246]
	TIME [epoch: 5.72 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08498179146114773		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.08498179146114773 | validation: 0.088668980146712]
	TIME [epoch: 5.72 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07286693711656758		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.07286693711656758 | validation: 0.04649841174534984]
	TIME [epoch: 5.72 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07116324816145891		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.07116324816145891 | validation: 0.05553133009544408]
	TIME [epoch: 5.73 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06742159955551516		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.06742159955551516 | validation: 0.04176070901236792]
	TIME [epoch: 5.76 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10506861547329037		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.10506861547329037 | validation: 0.10475765562728137]
	TIME [epoch: 5.73 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09055077883898073		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.09055077883898073 | validation: 0.07387893019588793]
	TIME [epoch: 5.72 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08974308299281378		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.08974308299281378 | validation: 0.051185281661615054]
	TIME [epoch: 5.72 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06895096560472075		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.06895096560472075 | validation: 0.051951288715389135]
	TIME [epoch: 5.72 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07006438871076046		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.07006438871076046 | validation: 0.0416728949668844]
	TIME [epoch: 5.72 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07784801048304221		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.07784801048304221 | validation: 0.05948196876116924]
	TIME [epoch: 5.76 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08003492179603544		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.08003492179603544 | validation: 0.10410194576265525]
	TIME [epoch: 5.73 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07678297445877827		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.07678297445877827 | validation: 0.038893125962396836]
	TIME [epoch: 5.73 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059514431795198414		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.059514431795198414 | validation: 0.05543394066085661]
	TIME [epoch: 5.72 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737662703891416		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.0737662703891416 | validation: 0.052752282324049056]
	TIME [epoch: 5.73 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08976620871156837		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.08976620871156837 | validation: 0.07833380703845369]
	TIME [epoch: 5.73 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0900295337745324		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.0900295337745324 | validation: 0.08598873822941702]
	TIME [epoch: 5.76 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08355485171130406		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.08355485171130406 | validation: 0.0939167336577854]
	TIME [epoch: 5.73 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0859009111809664		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.0859009111809664 | validation: 0.04244494266802311]
	TIME [epoch: 5.73 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059419450786122874		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.059419450786122874 | validation: 0.04810079910165186]
	TIME [epoch: 5.72 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06844714833021599		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.06844714833021599 | validation: 0.0620321502376156]
	TIME [epoch: 5.72 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07902607174923902		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.07902607174923902 | validation: 0.04579520867534312]
	TIME [epoch: 5.73 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13188631931179878		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.13188631931179878 | validation: 0.11085701684688908]
	TIME [epoch: 5.77 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09320087443659651		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.09320087443659651 | validation: 0.06196971916712175]
	TIME [epoch: 5.73 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07590930510813448		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.07590930510813448 | validation: 0.07257620342774485]
	TIME [epoch: 5.72 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0767242725487263		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.0767242725487263 | validation: 0.05677654158195737]
	TIME [epoch: 5.74 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07634707089721782		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.07634707089721782 | validation: 0.0653466042517689]
	TIME [epoch: 5.72 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06954024908294527		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.06954024908294527 | validation: 0.07322035558400627]
	TIME [epoch: 5.73 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12016745568719908		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.12016745568719908 | validation: 0.10789243476905687]
	TIME [epoch: 5.76 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10497557120005821		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.10497557120005821 | validation: 0.08587704368262411]
	TIME [epoch: 5.73 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09657896147172927		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.09657896147172927 | validation: 0.06591208602734262]
	TIME [epoch: 5.73 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10667317293663811		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.10667317293663811 | validation: 0.05958033397926166]
	TIME [epoch: 5.72 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06354743394943171		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.06354743394943171 | validation: 0.05269929016002966]
	TIME [epoch: 5.71 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10197361461727138		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.10197361461727138 | validation: 0.047436262588340425]
	TIME [epoch: 5.73 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07606215446779221		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.07606215446779221 | validation: 0.04997480558880712]
	TIME [epoch: 5.76 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06599061311738631		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.06599061311738631 | validation: 0.07515471120055502]
	TIME [epoch: 5.73 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07415948819283573		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.07415948819283573 | validation: 0.06124847939839229]
	TIME [epoch: 5.72 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06397875468536375		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.06397875468536375 | validation: 0.05903528490952315]
	TIME [epoch: 5.72 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08588259290090454		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.08588259290090454 | validation: 0.08600647903934804]
	TIME [epoch: 5.72 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14163357990189507		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.14163357990189507 | validation: 0.05934811187029711]
	TIME [epoch: 5.71 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07098204569372106		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.07098204569372106 | validation: 0.031122255781736722]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0638887301913522		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.0638887301913522 | validation: 0.05025249672891282]
	TIME [epoch: 5.72 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08981892068163833		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.08981892068163833 | validation: 0.10853624190889448]
	TIME [epoch: 5.72 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10575903500887768		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.10575903500887768 | validation: 0.1254878047867562]
	TIME [epoch: 5.72 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09108636916992421		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.09108636916992421 | validation: 0.053585622528178396]
	TIME [epoch: 5.72 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06538797830578374		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.06538797830578374 | validation: 0.07505277210326716]
	TIME [epoch: 5.73 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10494424239325348		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.10494424239325348 | validation: 0.12227866934244672]
	TIME [epoch: 5.74 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09530117260332818		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.09530117260332818 | validation: 0.05126271921796805]
	TIME [epoch: 5.71 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07998210975008463		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.07998210975008463 | validation: 0.14555356437368347]
	TIME [epoch: 5.71 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15159674210685237		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.15159674210685237 | validation: 0.06277982030984688]
	TIME [epoch: 5.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07702825195929369		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.07702825195929369 | validation: 0.039965291136653265]
	TIME [epoch: 5.71 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06804804708022834		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.06804804708022834 | validation: 0.06674558434448292]
	TIME [epoch: 5.71 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0669980981838242		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0669980981838242 | validation: 0.04517756809879513]
	TIME [epoch: 5.75 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08877704699784672		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.08877704699784672 | validation: 0.09422886839566585]
	TIME [epoch: 5.71 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12479443432543137		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.12479443432543137 | validation: 0.1557475702088907]
	TIME [epoch: 5.71 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10029454374317764		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.10029454374317764 | validation: 0.05576323830679662]
	TIME [epoch: 5.71 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06945655768728533		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.06945655768728533 | validation: 0.04145685155369677]
	TIME [epoch: 5.71 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05790250224713127		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.05790250224713127 | validation: 0.043484308775272]
	TIME [epoch: 5.71 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06613700221885421		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.06613700221885421 | validation: 0.04499585567882269]
	TIME [epoch: 5.75 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08365701539039568		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.08365701539039568 | validation: 0.0366303733730423]
	TIME [epoch: 5.73 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062200750921409545		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.062200750921409545 | validation: 0.07009356327925285]
	TIME [epoch: 5.73 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11699742628423125		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.11699742628423125 | validation: 0.059152448597972945]
	TIME [epoch: 5.73 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08860870882819173		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.08860870882819173 | validation: 0.04668532554542517]
	TIME [epoch: 5.72 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06324023041188191		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.06324023041188191 | validation: 0.04129727414431424]
	TIME [epoch: 5.73 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715147785740722		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.06715147785740722 | validation: 0.04106179460452641]
	TIME [epoch: 5.77 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07359221734959362		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.07359221734959362 | validation: 0.08040990790936679]
	TIME [epoch: 5.71 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07679400164808418		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.07679400164808418 | validation: 0.0387799185007756]
	TIME [epoch: 5.71 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001033786550413		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.1001033786550413 | validation: 0.08226589128597869]
	TIME [epoch: 5.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0726887896696422		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.0726887896696422 | validation: 0.07979317308168908]
	TIME [epoch: 5.72 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07422741882621481		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.07422741882621481 | validation: 0.06713460127518926]
	TIME [epoch: 5.73 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09543572728969676		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.09543572728969676 | validation: 0.06656294399463702]
	TIME [epoch: 5.76 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07858355631812246		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.07858355631812246 | validation: 0.052325994227916776]
	TIME [epoch: 5.73 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06897213043390521		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.06897213043390521 | validation: 0.04098033858235456]
	TIME [epoch: 5.71 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07150262034514182		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.07150262034514182 | validation: 0.0690084251089412]
	TIME [epoch: 5.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06613594078567858		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.06613594078567858 | validation: 0.0423445156068902]
	TIME [epoch: 5.71 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0603080372094688		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.0603080372094688 | validation: 0.040289950283645855]
	TIME [epoch: 5.71 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07391973850558595		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.07391973850558595 | validation: 0.04613927698420719]
	TIME [epoch: 5.75 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09958951461620671		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.09958951461620671 | validation: 0.06030838844946265]
	TIME [epoch: 5.71 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07733499987294858		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.07733499987294858 | validation: 0.046898987384809576]
	TIME [epoch: 5.71 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060661502076056015		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.060661502076056015 | validation: 0.05089812627461024]
	TIME [epoch: 5.71 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07748506390761487		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.07748506390761487 | validation: 0.08599096322462031]
	TIME [epoch: 5.71 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07582052825599905		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.07582052825599905 | validation: 0.06237232799991742]
	TIME [epoch: 5.71 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08281741761192467		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.08281741761192467 | validation: 0.038259112722286985]
	TIME [epoch: 5.74 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06103701635987487		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.06103701635987487 | validation: 0.06452960706573052]
	TIME [epoch: 5.72 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07708275652871756		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.07708275652871756 | validation: 0.05111662367004634]
	TIME [epoch: 5.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09386894464263854		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.09386894464263854 | validation: 0.08952928209400039]
	TIME [epoch: 5.71 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08269250111401957		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.08269250111401957 | validation: 0.03875148877197819]
	TIME [epoch: 5.71 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06536857913211223		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.06536857913211223 | validation: 0.03449308449447028]
	TIME [epoch: 5.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08244348234739499		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.08244348234739499 | validation: 0.10197069974794226]
	TIME [epoch: 5.76 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10055305323615252		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.10055305323615252 | validation: 0.04975585553663823]
	TIME [epoch: 5.74 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05595872352428883		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.05595872352428883 | validation: 0.07633167139103816]
	TIME [epoch: 5.72 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11841863822435268		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.11841863822435268 | validation: 0.06468344865692943]
	TIME [epoch: 5.72 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07104049792698455		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.07104049792698455 | validation: 0.057715920113724256]
	TIME [epoch: 5.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08024122883579693		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.08024122883579693 | validation: 0.04553678359947565]
	TIME [epoch: 5.72 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05997516427343964		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.05997516427343964 | validation: 0.03730598497981841]
	TIME [epoch: 5.74 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11841860687063394		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.11841860687063394 | validation: 0.11612385395348028]
	TIME [epoch: 5.72 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08970748333119676		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.08970748333119676 | validation: 0.07645658340436491]
	TIME [epoch: 5.71 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0975127046002371		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.0975127046002371 | validation: 0.0507221514362228]
	TIME [epoch: 5.71 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05612199512176905		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.05612199512176905 | validation: 0.03337234822734649]
	TIME [epoch: 5.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06857412705091956		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.06857412705091956 | validation: 0.06649093754096894]
	TIME [epoch: 5.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07623285617384166		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.07623285617384166 | validation: 0.07228827970661185]
	TIME [epoch: 5.74 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06377566539144751		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.06377566539144751 | validation: 0.04772201452101374]
	TIME [epoch: 5.72 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889208928149114		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.05889208928149114 | validation: 0.055022290366779955]
	TIME [epoch: 5.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09237535571594696		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.09237535571594696 | validation: 0.06271073834695949]
	TIME [epoch: 5.72 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07101318337961132		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.07101318337961132 | validation: 0.06782853467122679]
	TIME [epoch: 5.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0899261942264178		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.0899261942264178 | validation: 0.050484264797544046]
	TIME [epoch: 5.71 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05994052390781418		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.05994052390781418 | validation: 0.052490171533535454]
	TIME [epoch: 5.74 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06564478021226607		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.06564478021226607 | validation: 0.06279952583175982]
	TIME [epoch: 5.73 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06312487944581004		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.06312487944581004 | validation: 0.05452560893064808]
	TIME [epoch: 5.71 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821468915591003		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.06821468915591003 | validation: 0.0432705640220121]
	TIME [epoch: 5.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05558363533768443		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.05558363533768443 | validation: 0.034568870930511954]
	TIME [epoch: 5.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056392361155868334		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.056392361155868334 | validation: 0.04005650497751338]
	TIME [epoch: 5.73 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06139195580595408		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.06139195580595408 | validation: 0.05067432642833167]
	TIME [epoch: 5.74 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05738194820007525		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.05738194820007525 | validation: 0.044532115745414436]
	TIME [epoch: 5.72 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059549003726600554		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.059549003726600554 | validation: 0.05577073634184977]
	TIME [epoch: 5.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09997255313798774		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.09997255313798774 | validation: 0.350083716881051]
	TIME [epoch: 5.72 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.221775646929314		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.221775646929314 | validation: 0.06812241172459524]
	TIME [epoch: 5.72 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0721076990017993		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.0721076990017993 | validation: 0.06687739001775057]
	TIME [epoch: 5.72 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08180335760170489		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.08180335760170489 | validation: 0.047926174704910326]
	TIME [epoch: 5.74 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057473777476322735		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.057473777476322735 | validation: 0.06387648351797832]
	TIME [epoch: 5.73 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611977291968141		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.06611977291968141 | validation: 0.048866737229300225]
	TIME [epoch: 5.72 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062483236674206126		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.062483236674206126 | validation: 0.04378910967095185]
	TIME [epoch: 5.72 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06043100761254274		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.06043100761254274 | validation: 0.03696388203308326]
	TIME [epoch: 5.72 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06987993981171314		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.06987993981171314 | validation: 0.05211369073797684]
	TIME [epoch: 5.72 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05870938725303303		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.05870938725303303 | validation: 0.0590532287852849]
	TIME [epoch: 5.74 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13073207042693655		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.13073207042693655 | validation: 0.09270915087309797]
	TIME [epoch: 5.74 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0959617042467761		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.0959617042467761 | validation: 0.06270546147084052]
	TIME [epoch: 5.71 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06822043371373092		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.06822043371373092 | validation: 0.05106821961561906]
	TIME [epoch: 5.72 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06397438654901261		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.06397438654901261 | validation: 0.04757231005140557]
	TIME [epoch: 5.71 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06482442181518425		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.06482442181518425 | validation: 0.04384001989026005]
	TIME [epoch: 5.72 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07218275159278126		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.07218275159278126 | validation: 0.04938828872641948]
	TIME [epoch: 5.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07057794588044525		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.07057794588044525 | validation: 0.04509664526539857]
	TIME [epoch: 5.74 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05320509504270681		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.05320509504270681 | validation: 0.0352776465656749]
	TIME [epoch: 5.71 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08121223714674189		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.08121223714674189 | validation: 0.060657613648310696]
	TIME [epoch: 5.72 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07826133348060747		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.07826133348060747 | validation: 0.07284152686673265]
	TIME [epoch: 5.71 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06598348322377279		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.06598348322377279 | validation: 0.05083757302425447]
	TIME [epoch: 5.72 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06842501300004117		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.06842501300004117 | validation: 0.04918999704564508]
	TIME [epoch: 5.73 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06328289821694293		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.06328289821694293 | validation: 0.06152625586020022]
	TIME [epoch: 5.74 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07117607067770818		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.07117607067770818 | validation: 0.056170137327938505]
	TIME [epoch: 5.71 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05982159743711725		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.05982159743711725 | validation: 0.040630608397014656]
	TIME [epoch: 5.71 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059800449977483634		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.059800449977483634 | validation: 0.03829779474331599]
	TIME [epoch: 5.72 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06758506768192894		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.06758506768192894 | validation: 0.05645608274790238]
	TIME [epoch: 5.71 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059045382782421454		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.059045382782421454 | validation: 0.09280451085738958]
	TIME [epoch: 5.74 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10127900013102557		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.10127900013102557 | validation: 0.060212058045296876]
	TIME [epoch: 5.73 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06563577824146492		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.06563577824146492 | validation: 0.04282196849711539]
	TIME [epoch: 5.72 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06204030124321672		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.06204030124321672 | validation: 0.05596335382323546]
	TIME [epoch: 5.71 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09640934325151487		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.09640934325151487 | validation: 0.06122739374307733]
	TIME [epoch: 5.73 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316815134104224		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.06316815134104224 | validation: 0.043710222701102024]
	TIME [epoch: 5.71 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0624235564415263		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.0624235564415263 | validation: 0.04968962717019459]
	TIME [epoch: 5.74 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07903669213405431		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.07903669213405431 | validation: 0.0748197144302967]
	TIME [epoch: 5.73 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07659801459004123		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.07659801459004123 | validation: 0.1286979010542023]
	TIME [epoch: 5.71 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11164393733893721		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.11164393733893721 | validation: 0.04735211579369803]
	TIME [epoch: 5.71 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06310767003617246		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.06310767003617246 | validation: 0.04538464891250202]
	TIME [epoch: 5.72 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0531768124087649		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.0531768124087649 | validation: 0.04888611965140241]
	TIME [epoch: 5.71 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07130058758809478		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.07130058758809478 | validation: 0.06343293930821822]
	TIME [epoch: 5.74 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06838641271065157		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.06838641271065157 | validation: 0.034060273956366266]
	TIME [epoch: 5.74 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05273403041208983		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.05273403041208983 | validation: 0.0540056795295752]
	TIME [epoch: 5.71 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689471196883484		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.05689471196883484 | validation: 0.036472866752679065]
	TIME [epoch: 5.72 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05750036306600227		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.05750036306600227 | validation: 0.0375219050603422]
	TIME [epoch: 5.71 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05961604716111875		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.05961604716111875 | validation: 0.043957024005263426]
	TIME [epoch: 5.72 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06437443907286686		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.06437443907286686 | validation: 0.036985495474832195]
	TIME [epoch: 5.74 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05369685033429249		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.05369685033429249 | validation: 0.05488911730421551]
	TIME [epoch: 5.74 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06593252524746		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.06593252524746 | validation: 0.05826952477771275]
	TIME [epoch: 5.73 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06430357567420235		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.06430357567420235 | validation: 0.039611431145950914]
	TIME [epoch: 5.71 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06308833182038094		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.06308833182038094 | validation: 0.04239085157859973]
	TIME [epoch: 5.72 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06046576353318109		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.06046576353318109 | validation: 0.04359134336372638]
	TIME [epoch: 5.71 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0628790921577953		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.0628790921577953 | validation: 0.06328652624643144]
	TIME [epoch: 5.75 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08690329812919871		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.08690329812919871 | validation: 0.06901770993861828]
	TIME [epoch: 5.74 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08134175549856384		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.08134175549856384 | validation: 0.04464949722446738]
	TIME [epoch: 5.72 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057704440895137626		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.057704440895137626 | validation: 0.0409148432670561]
	TIME [epoch: 5.71 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05854300602355713		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.05854300602355713 | validation: 0.03293343345713651]
	TIME [epoch: 5.71 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04918360582892663		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04918360582892663 | validation: 0.03584632921194853]
	TIME [epoch: 5.71 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04688549464279467		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.04688549464279467 | validation: 0.03009975543653366]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_814.pth
	Model improved!!!
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05367780771499708		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.05367780771499708 | validation: 0.029660927954260227]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_815.pth
	Model improved!!!
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05346041100306985		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.05346041100306985 | validation: 0.05525412923772459]
	TIME [epoch: 5.74 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059045632473564286		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.059045632473564286 | validation: 0.03962679877840272]
	TIME [epoch: 5.71 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0570597415021827		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.0570597415021827 | validation: 0.04169950704113552]
	TIME [epoch: 5.72 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052738296218781656		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.052738296218781656 | validation: 0.05248451252126276]
	TIME [epoch: 5.71 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08938249273299487		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.08938249273299487 | validation: 0.0496408527927027]
	TIME [epoch: 5.74 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06082781840712975		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.06082781840712975 | validation: 0.03357296097617215]
	TIME [epoch: 5.74 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055809670618495316		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.055809670618495316 | validation: 0.03948314265540302]
	TIME [epoch: 5.71 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0715762586257968		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.0715762586257968 | validation: 0.06125089482657689]
	TIME [epoch: 5.72 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771643328219743		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.0771643328219743 | validation: 0.043356974531168005]
	TIME [epoch: 5.71 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0613303456386432		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0613303456386432 | validation: 0.046561149917030746]
	TIME [epoch: 5.71 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059215497052984706		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.059215497052984706 | validation: 0.05281124094348451]
	TIME [epoch: 5.74 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07173286858646369		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.07173286858646369 | validation: 0.05255834247132166]
	TIME [epoch: 5.73 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06597802854253842		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.06597802854253842 | validation: 0.04074245814539974]
	TIME [epoch: 5.72 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06429775509034827		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.06429775509034827 | validation: 0.047779758624591315]
	TIME [epoch: 5.72 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0597123204836862		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.0597123204836862 | validation: 0.049948390133805844]
	TIME [epoch: 5.71 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0763570993587021		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0763570993587021 | validation: 0.04429775584277368]
	TIME [epoch: 5.72 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05987735313456397		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.05987735313456397 | validation: 0.04263077948897102]
	TIME [epoch: 5.73 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05599758168729371		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.05599758168729371 | validation: 0.048344128952890426]
	TIME [epoch: 5.74 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05824677045467433		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.05824677045467433 | validation: 0.04641386267613964]
	TIME [epoch: 5.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06305287220061115		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.06305287220061115 | validation: 0.051389662906637205]
	TIME [epoch: 5.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06336924669243016		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.06336924669243016 | validation: 0.05700971540879613]
	TIME [epoch: 5.72 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060350877030434416		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.060350877030434416 | validation: 0.04214136275965824]
	TIME [epoch: 5.71 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050841312651733216		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.050841312651733216 | validation: 0.031159208951975464]
	TIME [epoch: 5.74 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050465808314750074		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.050465808314750074 | validation: 0.03446661267927529]
	TIME [epoch: 5.73 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09361605076305168		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09361605076305168 | validation: 0.17231483442927498]
	TIME [epoch: 5.71 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12216403670100276		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.12216403670100276 | validation: 0.04388466694210829]
	TIME [epoch: 5.72 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04450654418802709		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.04450654418802709 | validation: 0.03273246206134156]
	TIME [epoch: 5.71 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04651998722025992		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.04651998722025992 | validation: 0.04204150025041438]
	TIME [epoch: 5.71 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051633275025182224		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.051633275025182224 | validation: 0.03508794456008795]
	TIME [epoch: 5.74 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04991397711694306		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.04991397711694306 | validation: 0.06839963885215304]
	TIME [epoch: 5.74 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832703245547081		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.0832703245547081 | validation: 0.05929694804416814]
	TIME [epoch: 5.71 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08376357718444695		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.08376357718444695 | validation: 0.07140807335136849]
	TIME [epoch: 5.72 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06878078758044784		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.06878078758044784 | validation: 0.06603704947898048]
	TIME [epoch: 5.71 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06558545495543003		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.06558545495543003 | validation: 0.031771532622094256]
	TIME [epoch: 5.71 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05366461359475967		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.05366461359475967 | validation: 0.05647928994547753]
	TIME [epoch: 5.73 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057389364783706626		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.057389364783706626 | validation: 0.03345272372955084]
	TIME [epoch: 5.75 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049940734386896925		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.049940734386896925 | validation: 0.022755034358825244]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_852.pth
	Model improved!!!
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042966063407631046		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.042966063407631046 | validation: 0.03740222140263177]
	TIME [epoch: 5.71 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053143285443369756		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.053143285443369756 | validation: 0.04761474127769568]
	TIME [epoch: 5.72 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08733632925866568		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.08733632925866568 | validation: 0.0708426827632459]
	TIME [epoch: 5.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06921625203443452		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.06921625203443452 | validation: 0.1052387119912813]
	TIME [epoch: 5.74 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07658125498180386		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.07658125498180386 | validation: 0.03359609578557486]
	TIME [epoch: 5.73 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05155880055392049		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.05155880055392049 | validation: 0.031363424910488706]
	TIME [epoch: 5.72 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286812814580231		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.05286812814580231 | validation: 0.04384527041611431]
	TIME [epoch: 5.72 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629580729282708		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.06629580729282708 | validation: 0.06665287154198636]
	TIME [epoch: 5.71 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056578498939116484		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.056578498939116484 | validation: 0.029653456008097587]
	TIME [epoch: 5.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06271258299909749		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.06271258299909749 | validation: 0.0863033853888062]
	TIME [epoch: 5.73 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09923242435914405		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.09923242435914405 | validation: 0.05304094078135713]
	TIME [epoch: 5.74 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07459304159984217		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.07459304159984217 | validation: 0.05125178483758787]
	TIME [epoch: 5.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05119441626180235		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.05119441626180235 | validation: 0.04792177589187066]
	TIME [epoch: 5.72 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06276824536495586		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.06276824536495586 | validation: 0.04151175723316825]
	TIME [epoch: 5.71 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05093714080069838		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.05093714080069838 | validation: 0.04233716693259203]
	TIME [epoch: 5.72 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05261555365392272		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.05261555365392272 | validation: 0.029875993915578738]
	TIME [epoch: 5.72 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0447845448551311		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.0447845448551311 | validation: 0.03910649059913439]
	TIME [epoch: 5.72 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050532832415842686		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.050532832415842686 | validation: 0.04839552399056091]
	TIME [epoch: 5.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06001220926978756		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.06001220926978756 | validation: 0.04709215086695293]
	TIME [epoch: 5.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054161233644588025		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.054161233644588025 | validation: 0.04215055612527783]
	TIME [epoch: 5.71 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06092673497330924		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.06092673497330924 | validation: 0.051341186334184975]
	TIME [epoch: 5.72 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06691946625548247		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.06691946625548247 | validation: 0.05278399764496283]
	TIME [epoch: 5.73 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06359721419529046		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.06359721419529046 | validation: 0.05116692444721158]
	TIME [epoch: 5.74 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05698392305409973		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.05698392305409973 | validation: 0.05661018454987847]
	TIME [epoch: 5.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07125088282986283		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.07125088282986283 | validation: 0.04531828487262063]
	TIME [epoch: 5.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056323410332222254		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.056323410332222254 | validation: 0.049904037885697666]
	TIME [epoch: 5.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061927294444171485		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.061927294444171485 | validation: 0.03221078158243869]
	TIME [epoch: 5.71 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206623937258614		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.05206623937258614 | validation: 0.03016527016165952]
	TIME [epoch: 5.74 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04928720317411538		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.04928720317411538 | validation: 0.03478230713108405]
	TIME [epoch: 5.74 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049283485311545625		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.049283485311545625 | validation: 0.04217866925361204]
	TIME [epoch: 5.72 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048013562566706275		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.048013562566706275 | validation: 0.035694459529850224]
	TIME [epoch: 5.71 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05486945078928885		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.05486945078928885 | validation: 0.04082994857785439]
	TIME [epoch: 5.71 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0693637282653902		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.0693637282653902 | validation: 0.05647004954185923]
	TIME [epoch: 5.71 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05108008807929068		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.05108008807929068 | validation: 0.051379767932028066]
	TIME [epoch: 5.72 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06454159601810129		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.06454159601810129 | validation: 0.022579860537091847]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_887.pth
	Model improved!!!
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06631794837275981		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.06631794837275981 | validation: 0.07972852753856531]
	TIME [epoch: 5.72 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07537897452934775		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.07537897452934775 | validation: 0.03948530769935548]
	TIME [epoch: 5.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05315732307128424		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.05315732307128424 | validation: 0.04288771742960568]
	TIME [epoch: 5.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0610581611972794		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.0610581611972794 | validation: 0.041230903121515276]
	TIME [epoch: 5.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04917476897577504		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.04917476897577504 | validation: 0.029850699980290513]
	TIME [epoch: 5.73 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047904132255349605		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.047904132255349605 | validation: 0.04011195631066253]
	TIME [epoch: 5.73 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04805107695887524		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.04805107695887524 | validation: 0.03292251849256361]
	TIME [epoch: 5.72 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051467318679173577		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.051467318679173577 | validation: 0.02641442341563097]
	TIME [epoch: 5.72 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05149844571207316		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.05149844571207316 | validation: 0.07917404034769619]
	TIME [epoch: 5.72 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1226934948142671		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.1226934948142671 | validation: 0.0783513123631347]
	TIME [epoch: 5.72 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05929402290634855		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.05929402290634855 | validation: 0.0415211660489389]
	TIME [epoch: 5.74 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574609087540765		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.0574609087540765 | validation: 0.0446960828572845]
	TIME [epoch: 5.74 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04895944014344161		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.04895944014344161 | validation: 0.03629560225630425]
	TIME [epoch: 5.72 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050455478764509586		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.050455478764509586 | validation: 0.054106344635214756]
	TIME [epoch: 5.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06588692536098431		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.06588692536098431 | validation: 0.04024956000684875]
	TIME [epoch: 5.72 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053168949867728535		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.053168949867728535 | validation: 0.03492462331124166]
	TIME [epoch: 5.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05114171883184457		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.05114171883184457 | validation: 0.0473691319584197]
	TIME [epoch: 5.74 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356383191304936		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.06356383191304936 | validation: 0.04003857166914306]
	TIME [epoch: 5.74 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04536875121601753		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.04536875121601753 | validation: 0.03517049797269231]
	TIME [epoch: 5.72 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06857347932128127		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.06857347932128127 | validation: 0.14986932958241814]
	TIME [epoch: 5.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993338564372847		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.0993338564372847 | validation: 0.0530137368716492]
	TIME [epoch: 5.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05542211833723769		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.05542211833723769 | validation: 0.030428108259939166]
	TIME [epoch: 5.72 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04717880034595194		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.04717880034595194 | validation: 0.030736957096911186]
	TIME [epoch: 5.72 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041866722216695275		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.041866722216695275 | validation: 0.03633864855863333]
	TIME [epoch: 5.75 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05210510770314181		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.05210510770314181 | validation: 0.05148413785495191]
	TIME [epoch: 5.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05504747309652686		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.05504747309652686 | validation: 0.03681479451402959]
	TIME [epoch: 5.71 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048797817084835805		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.048797817084835805 | validation: 0.029494319224754078]
	TIME [epoch: 5.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047024174362962336		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.047024174362962336 | validation: 0.03181381525912656]
	TIME [epoch: 5.71 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052017835518726345		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.052017835518726345 | validation: 0.05382643684104887]
	TIME [epoch: 5.72 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05875473139064006		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.05875473139064006 | validation: 0.04534451611848733]
	TIME [epoch: 5.75 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05427530458339464		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.05427530458339464 | validation: 0.04670882384374954]
	TIME [epoch: 5.71 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058992329560435604		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.058992329560435604 | validation: 0.018802005924594162]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_919.pth
	Model improved!!!
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05040556771943669		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.05040556771943669 | validation: 0.050077901359493124]
	TIME [epoch: 5.72 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05978870218144369		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.05978870218144369 | validation: 0.03492148564686902]
	TIME [epoch: 5.72 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04675196117897234		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.04675196117897234 | validation: 0.035021406659692875]
	TIME [epoch: 5.74 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0481119788669939		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0481119788669939 | validation: 0.035316019362313864]
	TIME [epoch: 5.74 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657418288911543		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.05657418288911543 | validation: 0.03878016631639671]
	TIME [epoch: 5.72 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04466941352757959		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.04466941352757959 | validation: 0.038434297186485326]
	TIME [epoch: 5.72 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0536884458923139		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.0536884458923139 | validation: 0.03833583878745294]
	TIME [epoch: 5.72 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047785540506653255		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.047785540506653255 | validation: 0.02973117253311681]
	TIME [epoch: 5.72 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309088571173557		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.04309088571173557 | validation: 0.04923933680039205]
	TIME [epoch: 5.74 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873073052741203		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.05873073052741203 | validation: 0.04750725544115207]
	TIME [epoch: 5.74 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06724115627975333		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.06724115627975333 | validation: 0.03595310340823333]
	TIME [epoch: 5.72 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05816340858088029		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.05816340858088029 | validation: 0.05967080982658722]
	TIME [epoch: 5.72 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07377197604794515		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.07377197604794515 | validation: 0.03871737018905745]
	TIME [epoch: 5.72 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04729261217670692		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.04729261217670692 | validation: 0.03543369486432718]
	TIME [epoch: 5.72 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05402341502491539		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.05402341502491539 | validation: 0.02715846519631607]
	TIME [epoch: 5.74 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0444342719440527		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.0444342719440527 | validation: 0.04096857189231496]
	TIME [epoch: 5.74 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045542771438654095		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.045542771438654095 | validation: 0.03847276054175951]
	TIME [epoch: 5.72 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045331938208956285		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.045331938208956285 | validation: 0.024450494631619524]
	TIME [epoch: 5.72 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04499841687430782		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.04499841687430782 | validation: 0.040128982764774515]
	TIME [epoch: 5.72 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058673293215811814		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.058673293215811814 | validation: 0.10972006683765613]
	TIME [epoch: 5.72 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10071530580133757		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.10071530580133757 | validation: 0.05071924572739936]
	TIME [epoch: 5.74 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057773138317485255		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.057773138317485255 | validation: 0.04164517169460617]
	TIME [epoch: 5.74 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050962899731086156		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.050962899731086156 | validation: 0.038232465587221674]
	TIME [epoch: 5.72 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049354824551097624		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.049354824551097624 | validation: 0.03914882049325948]
	TIME [epoch: 5.72 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04409276830644651		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.04409276830644651 | validation: 0.033859281960144594]
	TIME [epoch: 5.72 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206270293900221		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.05206270293900221 | validation: 0.04688735507589636]
	TIME [epoch: 5.72 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06917931025295418		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.06917931025295418 | validation: 0.09956279280554638]
	TIME [epoch: 5.72 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06945873018728745		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.06945873018728745 | validation: 0.04381725514933083]
	TIME [epoch: 5.75 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046928224984327624		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.046928224984327624 | validation: 0.038920689767865516]
	TIME [epoch: 5.72 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063534356463642		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.06063534356463642 | validation: 0.04381144855827633]
	TIME [epoch: 5.72 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04981368416907132		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.04981368416907132 | validation: 0.05832104777621078]
	TIME [epoch: 5.72 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05941136560562508		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.05941136560562508 | validation: 0.04281350140387466]
	TIME [epoch: 5.72 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05291016150756478		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.05291016150756478 | validation: 0.04881459840158362]
	TIME [epoch: 5.73 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04961064089238717		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.04961064089238717 | validation: 0.04033963042792352]
	TIME [epoch: 5.75 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05841847710901629		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.05841847710901629 | validation: 0.04437824330652256]
	TIME [epoch: 5.72 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05623691269125626		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.05623691269125626 | validation: 0.05142689254991652]
	TIME [epoch: 5.72 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05993423889885963		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.05993423889885963 | validation: 0.04610425370885669]
	TIME [epoch: 5.71 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04690284954947377		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.04690284954947377 | validation: 0.03020877290439657]
	TIME [epoch: 5.72 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04539425198558883		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.04539425198558883 | validation: 0.037032823469973386]
	TIME [epoch: 5.72 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0455640535208457		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.0455640535208457 | validation: 0.031029952605259956]
	TIME [epoch: 5.75 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05041294975312941		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.05041294975312941 | validation: 0.042032158528914]
	TIME [epoch: 5.72 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05770915060903171		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.05770915060903171 | validation: 0.050676389531591454]
	TIME [epoch: 5.72 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061853593307951475		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.061853593307951475 | validation: 0.03435252018419699]
	TIME [epoch: 5.72 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048435247968231517		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.048435247968231517 | validation: 0.04821947771617085]
	TIME [epoch: 5.72 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06061291842609645		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.06061291842609645 | validation: 0.05285869083581285]
	TIME [epoch: 5.72 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06432447649520197		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.06432447649520197 | validation: 0.044926935905505026]
	TIME [epoch: 5.75 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05284396296606256		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.05284396296606256 | validation: 0.05326185885194347]
	TIME [epoch: 5.72 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060757499647870736		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.060757499647870736 | validation: 0.04542664949816488]
	TIME [epoch: 5.72 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048522458115591534		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.048522458115591534 | validation: 0.044668056226199106]
	TIME [epoch: 5.72 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05990524096139087		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.05990524096139087 | validation: 0.06921916954333]
	TIME [epoch: 5.71 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06463843356382298		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.06463843356382298 | validation: 0.039464458559744404]
	TIME [epoch: 5.72 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044700656027671155		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.044700656027671155 | validation: 0.04038073111983655]
	TIME [epoch: 5.75 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07764377442519627		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.07764377442519627 | validation: 0.04645829313326234]
	TIME [epoch: 5.72 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052815260864424216		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.052815260864424216 | validation: 0.032563016933692776]
	TIME [epoch: 5.72 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057148383351354554		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.057148383351354554 | validation: 0.06502060438710917]
	TIME [epoch: 5.72 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06400069924209342		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.06400069924209342 | validation: 0.03723631444655163]
	TIME [epoch: 5.72 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05359399541387356		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.05359399541387356 | validation: 0.04370299241346346]
	TIME [epoch: 5.72 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06363931055976721		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.06363931055976721 | validation: 0.030684149014621305]
	TIME [epoch: 5.75 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05244958915281209		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.05244958915281209 | validation: 0.040683759016429885]
	TIME [epoch: 5.72 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04713041190872995		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.04713041190872995 | validation: 0.04918607797271883]
	TIME [epoch: 5.72 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04968959638186304		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.04968959638186304 | validation: 0.046422827156117744]
	TIME [epoch: 5.72 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058044083617506154		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.058044083617506154 | validation: 0.03628617704244732]
	TIME [epoch: 5.72 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048797954514468965		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.048797954514468965 | validation: 0.031020978989928248]
	TIME [epoch: 5.72 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196706088463039		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.04196706088463039 | validation: 0.03405387599016116]
	TIME [epoch: 5.75 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04869970197300605		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.04869970197300605 | validation: 0.044303522980543505]
	TIME [epoch: 5.72 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05636278473889761		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.05636278473889761 | validation: 0.04407008060693434]
	TIME [epoch: 5.72 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05435252730950908		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.05435252730950908 | validation: 0.04511357740548557]
	TIME [epoch: 5.72 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04573575454795101		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.04573575454795101 | validation: 0.028358154661904333]
	TIME [epoch: 5.71 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059391174539249546		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.059391174539249546 | validation: 0.07063272262272488]
	TIME [epoch: 5.73 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05764718103018911		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.05764718103018911 | validation: 0.0379338614930037]
	TIME [epoch: 5.75 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04898170919014973		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.04898170919014973 | validation: 0.02890943538433795]
	TIME [epoch: 5.72 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039855278917262295		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.039855278917262295 | validation: 0.04008668039777793]
	TIME [epoch: 5.72 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05090538589598539		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.05090538589598539 | validation: 0.03004598673705752]
	TIME [epoch: 5.72 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04348013497132361		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.04348013497132361 | validation: 0.03506596857661787]
	TIME [epoch: 5.72 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049923520570354506		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.049923520570354506 | validation: 0.040560347247152524]
	TIME [epoch: 5.72 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429658893816461		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.05429658893816461 | validation: 0.030109109970674685]
	TIME [epoch: 5.75 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040792235273931984		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.040792235273931984 | validation: 0.024601154887417313]
	TIME [epoch: 5.72 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059659413682720056		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.059659413682720056 | validation: 0.049994871215266114]
	TIME [epoch: 5.72 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0538786121982027		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.0538786121982027 | validation: 0.042817099058690085]
	TIME [epoch: 5.72 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050050569896097616		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.050050569896097616 | validation: 0.02252016780056665]
	TIME [epoch: 5.72 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043877162001646826		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.043877162001646826 | validation: 0.02948135037000411]
	TIME [epoch: 5.72 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052329755392073914		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.052329755392073914 | validation: 0.04661102970886127]
	TIME [epoch: 5.75 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815475533410269		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.04815475533410269 | validation: 0.045714268135690794]
	TIME [epoch: 5.72 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050712288566270296		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.050712288566270296 | validation: 0.037364118078009774]
	TIME [epoch: 5.72 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045821362912592103		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.045821362912592103 | validation: 0.03103671991335815]
	TIME [epoch: 5.72 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05025331666713919		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.05025331666713919 | validation: 0.04067435718544484]
	TIME [epoch: 5.71 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044586352151502376		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.044586352151502376 | validation: 0.02815255589191547]
	TIME [epoch: 5.72 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05932495495567587		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.05932495495567587 | validation: 0.053746241068050295]
	TIME [epoch: 5.75 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06606510603862065		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.06606510603862065 | validation: 0.041716754803792944]
	TIME [epoch: 5.72 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052220812899031244		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.052220812899031244 | validation: 0.045496173202056414]
	TIME [epoch: 5.72 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049774918092517675		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.049774918092517675 | validation: 0.043709239369453194]
	TIME [epoch: 5.72 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04704831538727154		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.04704831538727154 | validation: 0.035566255856733835]
	TIME [epoch: 5.71 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048856491717646285		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.048856491717646285 | validation: 0.0374922388695572]
	TIME [epoch: 5.72 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045901306522449815		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.045901306522449815 | validation: 0.033049454358178895]
	TIME [epoch: 5.75 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04957559978025712		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.04957559978025712 | validation: 0.0356642013171212]
	TIME [epoch: 5.72 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040294831504913184		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.040294831504913184 | validation: 0.03729872501809491]
	TIME [epoch: 5.72 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04620871278400248		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.04620871278400248 | validation: 0.03159602306277762]
	TIME [epoch: 5.72 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04534233919378823		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.04534233919378823 | validation: 0.0269609358794472]
	TIME [epoch: 5.72 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04777124507914306		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.04777124507914306 | validation: 0.04059062533860521]
	TIME [epoch: 5.72 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04631744274768642		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.04631744274768642 | validation: 0.03033561037557484]
	TIME [epoch: 5.75 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043144517839548306		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.043144517839548306 | validation: 0.03188880642707877]
	TIME [epoch: 5.72 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04573452480026435		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.04573452480026435 | validation: 0.039572069783892196]
	TIME [epoch: 5.71 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05067775404769274		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.05067775404769274 | validation: 0.03147236835117593]
	TIME [epoch: 5.72 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03893207091120539		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.03893207091120539 | validation: 0.03303583749436591]
	TIME [epoch: 5.71 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03871647408516739		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.03871647408516739 | validation: 0.033694088240937246]
	TIME [epoch: 5.72 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04286351564293826		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.04286351564293826 | validation: 0.0336738665462884]
	TIME [epoch: 5.75 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04673062311810569		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.04673062311810569 | validation: 0.0428243312484739]
	TIME [epoch: 5.72 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04721127903429223		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.04721127903429223 | validation: 0.02703357568302786]
	TIME [epoch: 5.71 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03919983870268978		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.03919983870268978 | validation: 0.04562363128676122]
	TIME [epoch: 5.72 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06889345807213335		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.06889345807213335 | validation: 0.03676709949499295]
	TIME [epoch: 5.71 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05092691270639975		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.05092691270639975 | validation: 0.03718285478968398]
	TIME [epoch: 5.72 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0408887316002297		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.0408887316002297 | validation: 0.037731738173304316]
	TIME [epoch: 5.75 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05677387300300256		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.05677387300300256 | validation: 0.07627844563435165]
	TIME [epoch: 5.72 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06737016976150458		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.06737016976150458 | validation: 0.036964997747518054]
	TIME [epoch: 5.72 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048240230282863394		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.048240230282863394 | validation: 0.03629529093332288]
	TIME [epoch: 5.72 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733431586467454		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.04733431586467454 | validation: 0.03274840936993088]
	TIME [epoch: 5.71 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054257043457406166		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.054257043457406166 | validation: 0.03937577542926195]
	TIME [epoch: 5.72 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04987017908567126		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.04987017908567126 | validation: 0.03558455896297835]
	TIME [epoch: 5.75 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04621624838501834		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.04621624838501834 | validation: 0.03420346535620108]
	TIME [epoch: 5.72 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0437510189302901		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.0437510189302901 | validation: 0.029191021531098524]
	TIME [epoch: 5.71 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426932579696913		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.0426932579696913 | validation: 0.0366502962042064]
	TIME [epoch: 5.71 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05455416714227341		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.05455416714227341 | validation: 0.034775237090485835]
	TIME [epoch: 5.71 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05006133254776143		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.05006133254776143 | validation: 0.03313239628330683]
	TIME [epoch: 5.72 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04591289757047297		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.04591289757047297 | validation: 0.027955808690892377]
	TIME [epoch: 5.75 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045775189362283614		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.045775189362283614 | validation: 0.04129840431521508]
	TIME [epoch: 5.72 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049736323210992556		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.049736323210992556 | validation: 0.029264177578813336]
	TIME [epoch: 5.71 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04431540229633555		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.04431540229633555 | validation: 0.02789150207391554]
	TIME [epoch: 5.71 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042852964216042455		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.042852964216042455 | validation: 0.03215988361488311]
	TIME [epoch: 5.71 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045078504631341075		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.045078504631341075 | validation: 0.036795043990874056]
	TIME [epoch: 5.72 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049573250013292616		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.049573250013292616 | validation: 0.03310091888138282]
	TIME [epoch: 5.75 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046547030751829664		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.046547030751829664 | validation: 0.03322042692178961]
	TIME [epoch: 5.72 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042658028667476144		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.042658028667476144 | validation: 0.026761661648488866]
	TIME [epoch: 5.71 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045484211380667126		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.045484211380667126 | validation: 0.02913609478741126]
	TIME [epoch: 5.71 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04280903895612302		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.04280903895612302 | validation: 0.027419910041483444]
	TIME [epoch: 5.71 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03748205693654114		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.03748205693654114 | validation: 0.026331776454729033]
	TIME [epoch: 5.72 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042078550875534824		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.042078550875534824 | validation: 0.03169686860328323]
	TIME [epoch: 5.75 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04367898222344229		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.04367898222344229 | validation: 0.024300535473299877]
	TIME [epoch: 5.72 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044648468240117756		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.044648468240117756 | validation: 0.029902545305172612]
	TIME [epoch: 5.71 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04500982147259778		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.04500982147259778 | validation: 0.027931833609531786]
	TIME [epoch: 5.71 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047156160567500036		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.047156160567500036 | validation: 0.046407536933351146]
	TIME [epoch: 5.71 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05133056479321038		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.05133056479321038 | validation: 0.033837658609654646]
	TIME [epoch: 5.72 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04891355091344651		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.04891355091344651 | validation: 0.04229476241223094]
	TIME [epoch: 5.75 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05244800090955439		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.05244800090955439 | validation: 0.04560193574190909]
	TIME [epoch: 5.72 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049534473464773146		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.049534473464773146 | validation: 0.03078482597087284]
	TIME [epoch: 5.71 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03838063170632191		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.03838063170632191 | validation: 0.038412752353968356]
	TIME [epoch: 5.72 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0423676607808568		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.0423676607808568 | validation: 0.032311673253417585]
	TIME [epoch: 5.71 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04800742856636676		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.04800742856636676 | validation: 0.03667576418359153]
	TIME [epoch: 5.72 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04687379004162934		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.04687379004162934 | validation: 0.03258991976572688]
	TIME [epoch: 5.75 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047082838904111926		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.047082838904111926 | validation: 0.028722706101079413]
	TIME [epoch: 5.72 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04830081208123921		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.04830081208123921 | validation: 0.03881573056222049]
	TIME [epoch: 5.71 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04088915332669701		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.04088915332669701 | validation: 0.03615761707799695]
	TIME [epoch: 5.71 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046825686878059034		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.046825686878059034 | validation: 0.03771962349066326]
	TIME [epoch: 5.71 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04869536580161215		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.04869536580161215 | validation: 0.03393910873424974]
	TIME [epoch: 5.72 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06069043464628811		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.06069043464628811 | validation: 0.040233646017739544]
	TIME [epoch: 5.75 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043078774549412245		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.043078774549412245 | validation: 0.030778727507022267]
	TIME [epoch: 5.72 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042411353733887006		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.042411353733887006 | validation: 0.029836509973639326]
	TIME [epoch: 5.71 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038485130617345334		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.038485130617345334 | validation: 0.042661369712911075]
	TIME [epoch: 5.71 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055382328022854276		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.055382328022854276 | validation: 0.043401870957562906]
	TIME [epoch: 5.71 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04975143146354914		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.04975143146354914 | validation: 0.026040609663405895]
	TIME [epoch: 5.71 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042329618836186425		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.042329618836186425 | validation: 0.04671433731049673]
	TIME [epoch: 5.74 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04651596330009243		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.04651596330009243 | validation: 0.036149252402550375]
	TIME [epoch: 5.72 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043590887160906165		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.043590887160906165 | validation: 0.03595856361705863]
	TIME [epoch: 5.71 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046994337839128014		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.046994337839128014 | validation: 0.030477027518602418]
	TIME [epoch: 5.71 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04584027473342765		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.04584027473342765 | validation: 0.028764257388982868]
	TIME [epoch: 5.71 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0514895033917001		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.0514895033917001 | validation: 0.027295706360655505]
	TIME [epoch: 5.71 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045604451844512374		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.045604451844512374 | validation: 0.03474634765298346]
	TIME [epoch: 5.75 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050789481139462966		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.050789481139462966 | validation: 0.03569738735565026]
	TIME [epoch: 5.72 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04141880489278546		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.04141880489278546 | validation: 0.025610961678357136]
	TIME [epoch: 5.72 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043950275416107236		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.043950275416107236 | validation: 0.022430816172299667]
	TIME [epoch: 5.71 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04235310425945767		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.04235310425945767 | validation: 0.025855820353275417]
	TIME [epoch: 5.71 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04673636129876381		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.04673636129876381 | validation: 0.028451472093045962]
	TIME [epoch: 5.71 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042082903318047364		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.042082903318047364 | validation: 0.04509571767154496]
	TIME [epoch: 5.75 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047746634730752024		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.047746634730752024 | validation: 0.03464991426659286]
	TIME [epoch: 5.72 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04492240535553994		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.04492240535553994 | validation: 0.03002028164443276]
	TIME [epoch: 5.71 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414521783376242		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.0414521783376242 | validation: 0.03630248582510897]
	TIME [epoch: 5.71 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04223348547484384		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.04223348547484384 | validation: 0.04358963808191687]
	TIME [epoch: 5.72 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04698135566406388		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.04698135566406388 | validation: 0.03434257765790266]
	TIME [epoch: 5.71 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046475048946741565		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.046475048946741565 | validation: 0.030893178168182593]
	TIME [epoch: 5.75 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043135667369658244		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.043135667369658244 | validation: 0.026893052724599308]
	TIME [epoch: 5.72 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042960377518096754		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.042960377518096754 | validation: 0.032185142119220446]
	TIME [epoch: 5.71 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03989816976566289		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.03989816976566289 | validation: 0.029329607018089884]
	TIME [epoch: 5.71 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04799111705478523		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.04799111705478523 | validation: 0.03376675929900592]
	TIME [epoch: 5.71 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04166631771236725		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.04166631771236725 | validation: 0.02527243772822811]
	TIME [epoch: 5.71 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04323194005424852		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.04323194005424852 | validation: 0.04129424722150061]
	TIME [epoch: 5.75 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0455463572081012		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.0455463572081012 | validation: 0.027256934562368725]
	TIME [epoch: 5.72 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041879059652963777		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.041879059652963777 | validation: 0.03313609109451534]
	TIME [epoch: 5.71 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04489769900741465		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.04489769900741465 | validation: 0.02685444820925775]
	TIME [epoch: 5.71 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04239507410123344		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.04239507410123344 | validation: 0.03755946887199479]
	TIME [epoch: 5.71 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039999556350609845		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.039999556350609845 | validation: 0.021452309869523206]
	TIME [epoch: 5.71 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0510735398102968		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.0510735398102968 | validation: 0.032480080329812915]
	TIME [epoch: 5.74 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04538634201791702		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.04538634201791702 | validation: 0.043522342456409395]
	TIME [epoch: 5.72 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043316890517539564		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.043316890517539564 | validation: 0.027515626149095553]
	TIME [epoch: 5.71 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04158522204439557		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.04158522204439557 | validation: 0.03236002076308618]
	TIME [epoch: 5.71 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038642738120485666		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.038642738120485666 | validation: 0.03153346021398058]
	TIME [epoch: 5.71 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03935341614504098		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.03935341614504098 | validation: 0.028089318697683514]
	TIME [epoch: 5.71 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041167773549132786		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.041167773549132786 | validation: 0.026929853315763346]
	TIME [epoch: 5.74 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04076977167174709		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.04076977167174709 | validation: 0.02635537858635403]
	TIME [epoch: 5.72 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04063458883852813		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.04063458883852813 | validation: 0.027093870629305065]
	TIME [epoch: 5.71 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039189538836260536		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.039189538836260536 | validation: 0.026375950725473142]
	TIME [epoch: 5.71 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038187676980350804		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.038187676980350804 | validation: 0.028176213153015744]
	TIME [epoch: 5.72 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041788285603609365		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.041788285603609365 | validation: 0.04500594404930892]
	TIME [epoch: 5.71 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05885985184645716		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.05885985184645716 | validation: 0.04933592162400203]
	TIME [epoch: 5.74 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05344178103114956		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.05344178103114956 | validation: 0.05464618210768728]
	TIME [epoch: 5.72 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053410813069607065		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.053410813069607065 | validation: 0.03559540718724019]
	TIME [epoch: 5.71 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049362274392125184		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.049362274392125184 | validation: 0.031888759711464466]
	TIME [epoch: 5.71 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044003990744299844		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.044003990744299844 | validation: 0.03880921908220127]
	TIME [epoch: 5.71 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04286505446294563		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.04286505446294563 | validation: 0.03270454925739243]
	TIME [epoch: 5.71 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04114169785881649		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.04114169785881649 | validation: 0.028581864408285806]
	TIME [epoch: 5.74 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040761885718341606		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.040761885718341606 | validation: 0.026343696455694135]
	TIME [epoch: 5.72 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039801261229032124		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.039801261229032124 | validation: 0.034482428557250526]
	TIME [epoch: 5.71 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042395782845207314		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.042395782845207314 | validation: 0.027754812018011325]
	TIME [epoch: 5.71 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03519689249147079		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.03519689249147079 | validation: 0.02697588747504584]
	TIME [epoch: 5.71 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04064278875796599		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.04064278875796599 | validation: 0.03232986112224145]
	TIME [epoch: 5.71 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04754728095773587		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.04754728095773587 | validation: 0.039430459466145075]
	TIME [epoch: 5.74 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04639128471293612		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.04639128471293612 | validation: 0.025582463364316528]
	TIME [epoch: 5.72 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196392580871144		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.04196392580871144 | validation: 0.03348563162353438]
	TIME [epoch: 5.71 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042805659989093525		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.042805659989093525 | validation: 0.02536424477413815]
	TIME [epoch: 5.71 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041437081414868		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.041437081414868 | validation: 0.021827811189533107]
	TIME [epoch: 5.71 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04469517441748996		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.04469517441748996 | validation: 0.029202702373762185]
	TIME [epoch: 5.71 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03981115742955564		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.03981115742955564 | validation: 0.035260703334995064]
	TIME [epoch: 5.74 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03857978111061476		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.03857978111061476 | validation: 0.029761956477421095]
	TIME [epoch: 5.72 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039718762262496654		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.039718762262496654 | validation: 0.040071651997234684]
	TIME [epoch: 5.71 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052291930792155245		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.052291930792155245 | validation: 0.04445835996464809]
	TIME [epoch: 5.71 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04370097111018301		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.04370097111018301 | validation: 0.024765188546551693]
	TIME [epoch: 5.71 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0424281371018187		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.0424281371018187 | validation: 0.032689052535857376]
	TIME [epoch: 5.72 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04171403987068178		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.04171403987068178 | validation: 0.030658502472262344]
	TIME [epoch: 5.74 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041005910459270455		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.041005910459270455 | validation: 0.02108044920932545]
	TIME [epoch: 5.72 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03790969727139221		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.03790969727139221 | validation: 0.02802722870731527]
	TIME [epoch: 5.71 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03642747535980411		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.03642747535980411 | validation: 0.027649058249362292]
	TIME [epoch: 5.71 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04503475738594962		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.04503475738594962 | validation: 0.02555842251308235]
	TIME [epoch: 5.71 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04280395117924184		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.04280395117924184 | validation: 0.02397302148324136]
	TIME [epoch: 5.72 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0394456275415264		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.0394456275415264 | validation: 0.02323778090416214]
	TIME [epoch: 5.74 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05007515312069727		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.05007515312069727 | validation: 0.03267041793249177]
	TIME [epoch: 5.72 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03942927180004229		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.03942927180004229 | validation: 0.02692076664073447]
	TIME [epoch: 5.71 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042865075214235465		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.042865075214235465 | validation: 0.028094699528467916]
	TIME [epoch: 5.71 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04278773629922225		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.04278773629922225 | validation: 0.02916916562053511]
	TIME [epoch: 5.72 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04265575007940502		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.04265575007940502 | validation: 0.030305055983161414]
	TIME [epoch: 5.71 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051097686382899875		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.051097686382899875 | validation: 0.036700514798674866]
	TIME [epoch: 5.74 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050482335085226517		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.050482335085226517 | validation: 0.031844480888482435]
	TIME [epoch: 5.73 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03930975925909263		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.03930975925909263 | validation: 0.02778193014644529]
	TIME [epoch: 5.72 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040004129600676196		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.040004129600676196 | validation: 0.02641544863675544]
	TIME [epoch: 5.71 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03671377990193825		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.03671377990193825 | validation: 0.024887605054443027]
	TIME [epoch: 5.71 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03936121064504678		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.03936121064504678 | validation: 0.028002971911981513]
	TIME [epoch: 5.71 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037386621892118305		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.037386621892118305 | validation: 0.022346638909603495]
	TIME [epoch: 5.74 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03785337330539902		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.03785337330539902 | validation: 0.026715808986027097]
	TIME [epoch: 5.73 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04004739973469507		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.04004739973469507 | validation: 0.03283530860987344]
	TIME [epoch: 5.72 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04342316735063105		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.04342316735063105 | validation: 0.02859868046283501]
	TIME [epoch: 5.71 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041754072106993216		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.041754072106993216 | validation: 0.03341247503115671]
	TIME [epoch: 5.71 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042800692074230845		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.042800692074230845 | validation: 0.023867249108126574]
	TIME [epoch: 5.71 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03707040494289674		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.03707040494289674 | validation: 0.03315348314712043]
	TIME [epoch: 5.74 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03957962377253063		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.03957962377253063 | validation: 0.027879813809505122]
	TIME [epoch: 5.73 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04022816786706093		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.04022816786706093 | validation: 0.02948097774225458]
	TIME [epoch: 5.71 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040597715053415945		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.040597715053415945 | validation: 0.025521357034794346]
	TIME [epoch: 5.71 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03925510477920136		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.03925510477920136 | validation: 0.03420815748337128]
	TIME [epoch: 5.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03967396594271588		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.03967396594271588 | validation: 0.03508825613922948]
	TIME [epoch: 5.71 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04564174069829571		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.04564174069829571 | validation: 0.026489675386178017]
	TIME [epoch: 5.74 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0394409395383235		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.0394409395383235 | validation: 0.023539855895551583]
	TIME [epoch: 5.72 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03806120735603557		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.03806120735603557 | validation: 0.022079850174461683]
	TIME [epoch: 5.71 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050455368831920096		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.050455368831920096 | validation: 0.05260557129150758]
	TIME [epoch: 5.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05186249766237048		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.05186249766237048 | validation: 0.03831564268345366]
	TIME [epoch: 5.71 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04102901844922903		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.04102901844922903 | validation: 0.020351894779374758]
	TIME [epoch: 5.71 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03770070730521415		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.03770070730521415 | validation: 0.021928817863806262]
	TIME [epoch: 5.74 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039063190736533616		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.039063190736533616 | validation: 0.027956366181848682]
	TIME [epoch: 5.73 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03923384083231166		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.03923384083231166 | validation: 0.01811166664790352]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_1183.pth
	Model improved!!!
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04285485045948698		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.04285485045948698 | validation: 0.027531485366535834]
	TIME [epoch: 5.72 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04028129565952126		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.04028129565952126 | validation: 0.02283358797228959]
	TIME [epoch: 5.72 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04049695879061253		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.04049695879061253 | validation: 0.030822154306868296]
	TIME [epoch: 5.7 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04462326631848634		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.04462326631848634 | validation: 0.02981947920101567]
	TIME [epoch: 5.72 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04103273543219518		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.04103273543219518 | validation: 0.027842722389765453]
	TIME [epoch: 5.72 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040634547265175056		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.040634547265175056 | validation: 0.02064961355215595]
	TIME [epoch: 5.7 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924955243572463		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.03924955243572463 | validation: 0.02346166987788894]
	TIME [epoch: 5.72 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04119514237058652		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.04119514237058652 | validation: 0.03423744999777082]
	TIME [epoch: 5.71 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04729475689919098		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.04729475689919098 | validation: 0.033261350851192015]
	TIME [epoch: 5.71 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04081076505522856		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.04081076505522856 | validation: 0.022875875167114677]
	TIME [epoch: 5.73 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037836471299555065		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.037836471299555065 | validation: 0.028771423789378928]
	TIME [epoch: 5.74 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03562486847783324		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.03562486847783324 | validation: 0.02932636979623217]
	TIME [epoch: 5.72 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03623819427540985		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.03623819427540985 | validation: 0.018831870173154745]
	TIME [epoch: 5.72 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040198229479968636		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.040198229479968636 | validation: 0.028540087079764777]
	TIME [epoch: 5.72 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04642055071161607		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.04642055071161607 | validation: 0.020107643992345433]
	TIME [epoch: 5.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03398036510181557		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.03398036510181557 | validation: 0.030384895971095883]
	TIME [epoch: 5.74 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036371749861822816		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.036371749861822816 | validation: 0.025941811058843557]
	TIME [epoch: 5.74 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037943824197528356		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.037943824197528356 | validation: 0.02920246332917003]
	TIME [epoch: 5.72 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03835684068001656		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.03835684068001656 | validation: 0.0371729083656751]
	TIME [epoch: 5.72 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0471281091780456		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0471281091780456 | validation: 0.03065821452135756]
	TIME [epoch: 5.72 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0449198801617935		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.0449198801617935 | validation: 0.03214015571286942]
	TIME [epoch: 5.72 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04595716279097447		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.04595716279097447 | validation: 0.03227905206167389]
	TIME [epoch: 5.75 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0460937044615204		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.0460937044615204 | validation: 0.026393183568320266]
	TIME [epoch: 5.74 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04609831428734078		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.04609831428734078 | validation: 0.016042434653859447]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_1207.pth
	Model improved!!!
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04653825540648206		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.04653825540648206 | validation: 0.034922899859389976]
	TIME [epoch: 5.72 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03926843165474748		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.03926843165474748 | validation: 0.02375549269833954]
	TIME [epoch: 5.73 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034128916465735494		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.034128916465735494 | validation: 0.024235054757366946]
	TIME [epoch: 5.72 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03995434453265189		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.03995434453265189 | validation: 0.018524851353196453]
	TIME [epoch: 5.74 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03725504792365014		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.03725504792365014 | validation: 0.025111168069187388]
	TIME [epoch: 5.74 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03702706264349731		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.03702706264349731 | validation: 0.02665600019833079]
	TIME [epoch: 5.72 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477153703224513		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.03477153703224513 | validation: 0.026493878920064884]
	TIME [epoch: 5.72 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03722976259634561		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.03722976259634561 | validation: 0.026709959610942306]
	TIME [epoch: 5.72 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044007430697028116		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.044007430697028116 | validation: 0.02971144196864166]
	TIME [epoch: 5.72 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040083789781379456		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.040083789781379456 | validation: 0.02851127926691267]
	TIME [epoch: 5.76 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03869000007973984		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.03869000007973984 | validation: 0.03184419882395163]
	TIME [epoch: 5.74 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04295594787093535		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.04295594787093535 | validation: 0.030718194346603275]
	TIME [epoch: 5.72 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04331762146164153		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.04331762146164153 | validation: 0.024475004017804513]
	TIME [epoch: 5.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03840380536309951		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.03840380536309951 | validation: 0.029870674326943167]
	TIME [epoch: 5.71 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038549803401347754		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.038549803401347754 | validation: 0.020292398383701147]
	TIME [epoch: 5.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03867821172377033		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.03867821172377033 | validation: 0.017072938348709054]
	TIME [epoch: 5.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347999923407052		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.04347999923407052 | validation: 0.025469949504398293]
	TIME [epoch: 5.72 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04054669387338671		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.04054669387338671 | validation: 0.02335437612717464]
	TIME [epoch: 5.71 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03688081383548108		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.03688081383548108 | validation: 0.03180984108155706]
	TIME [epoch: 5.71 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03461600314720811		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.03461600314720811 | validation: 0.02603976510186891]
	TIME [epoch: 5.71 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04003987730231298		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.04003987730231298 | validation: 0.025347709559126085]
	TIME [epoch: 5.71 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03880494804681088		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.03880494804681088 | validation: 0.01970565529894597]
	TIME [epoch: 5.73 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04062040205853534		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.04062040205853534 | validation: 0.03282859332678274]
	TIME [epoch: 5.73 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03735831684298037		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.03735831684298037 | validation: 0.027636881097108993]
	TIME [epoch: 5.71 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03761740458045453		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.03761740458045453 | validation: 0.022715871393027325]
	TIME [epoch: 5.71 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03801272490653707		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.03801272490653707 | validation: 0.029888461034504078]
	TIME [epoch: 5.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03452741358588336		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.03452741358588336 | validation: 0.026823296604023]
	TIME [epoch: 5.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03633420162446442		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.03633420162446442 | validation: 0.021382072322968657]
	TIME [epoch: 5.73 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03576728093680028		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.03576728093680028 | validation: 0.021463887453327227]
	TIME [epoch: 5.72 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03922836990421845		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.03922836990421845 | validation: 0.024701096203342852]
	TIME [epoch: 5.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03810644188402691		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.03810644188402691 | validation: 0.023041563268981494]
	TIME [epoch: 5.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03832758013492191		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03832758013492191 | validation: 0.027752921392115448]
	TIME [epoch: 5.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0346864197877909		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.0346864197877909 | validation: 0.024961016232734706]
	TIME [epoch: 5.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038370397693071184		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.038370397693071184 | validation: 0.02006186622409367]
	TIME [epoch: 5.75 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04402262072459262		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.04402262072459262 | validation: 0.020462387238062534]
	TIME [epoch: 5.73 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035761143263180604		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.035761143263180604 | validation: 0.034016224764617256]
	TIME [epoch: 5.71 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04320884714265739		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.04320884714265739 | validation: 0.03687583284139488]
	TIME [epoch: 5.71 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04900290394258065		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.04900290394258065 | validation: 0.03841807622462995]
	TIME [epoch: 5.72 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04355036352181539		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.04355036352181539 | validation: 0.03520492078697516]
	TIME [epoch: 5.72 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04468803598017663		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.04468803598017663 | validation: 0.02254086026595819]
	TIME [epoch: 5.75 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034120240265756746		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.034120240265756746 | validation: 0.021760298759351652]
	TIME [epoch: 5.74 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03799291050917306		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.03799291050917306 | validation: 0.022857735080011623]
	TIME [epoch: 5.72 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04008640123848066		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.04008640123848066 | validation: 0.02991433152426383]
	TIME [epoch: 5.72 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042184496731541246		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.042184496731541246 | validation: 0.02817757713493263]
	TIME [epoch: 5.72 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037048179200817495		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.037048179200817495 | validation: 0.02950442923973573]
	TIME [epoch: 5.72 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03932256521259937		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.03932256521259937 | validation: 0.0245713508427356]
	TIME [epoch: 5.74 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040373223698800614		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.040373223698800614 | validation: 0.017698196947814583]
	TIME [epoch: 5.74 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03927204421663621		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.03927204421663621 | validation: 0.020543712272766558]
	TIME [epoch: 5.72 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03699820361113638		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.03699820361113638 | validation: 0.02717602991172453]
	TIME [epoch: 5.72 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03571905849395799		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.03571905849395799 | validation: 0.028160321600666026]
	TIME [epoch: 5.72 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037922638923872556		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.037922638923872556 | validation: 0.028329055952031574]
	TIME [epoch: 5.72 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035788437354023026		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.035788437354023026 | validation: 0.03149352201681916]
	TIME [epoch: 5.75 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0409286874631879		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.0409286874631879 | validation: 0.03317428738418288]
	TIME [epoch: 5.74 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04455092696168537		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.04455092696168537 | validation: 0.031200936785910058]
	TIME [epoch: 5.72 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196085354206806		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.04196085354206806 | validation: 0.03477428921863677]
	TIME [epoch: 5.72 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046582737644590144		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.046582737644590144 | validation: 0.02313453509280903]
	TIME [epoch: 5.72 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04167941741335915		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.04167941741335915 | validation: 0.03654002838843568]
	TIME [epoch: 5.72 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04169045748706181		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.04169045748706181 | validation: 0.020893340626763967]
	TIME [epoch: 5.75 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038714222708885526		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.038714222708885526 | validation: 0.022954442536924875]
	TIME [epoch: 5.74 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0378929814844462		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.0378929814844462 | validation: 0.024091498579778704]
	TIME [epoch: 5.72 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03560787405571309		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.03560787405571309 | validation: 0.027672834218301644]
	TIME [epoch: 5.72 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03735731591316552		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.03735731591316552 | validation: 0.027699934242639]
	TIME [epoch: 5.72 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0404987707164244		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.0404987707164244 | validation: 0.03152172856472707]
	TIME [epoch: 5.72 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03478004988103097		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.03478004988103097 | validation: 0.03249170221887613]
	TIME [epoch: 5.75 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738326361115536		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.03738326361115536 | validation: 0.023252654787365278]
	TIME [epoch: 5.73 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03636502926503595		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.03636502926503595 | validation: 0.020477574150388204]
	TIME [epoch: 5.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036503178898977535		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.036503178898977535 | validation: 0.021130675626207348]
	TIME [epoch: 5.72 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040671783475485085		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.040671783475485085 | validation: 0.03395438515170698]
	TIME [epoch: 5.72 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04291482570906614		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.04291482570906614 | validation: 0.027688931677392233]
	TIME [epoch: 5.72 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616920513312726		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.03616920513312726 | validation: 0.022135978101440638]
	TIME [epoch: 5.75 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03597066895336286		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.03597066895336286 | validation: 0.030160289783395914]
	TIME [epoch: 5.73 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03611001170545464		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.03611001170545464 | validation: 0.021169934725111403]
	TIME [epoch: 5.72 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03730076966351706		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.03730076966351706 | validation: 0.018008515847292322]
	TIME [epoch: 5.72 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04213155970752405		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.04213155970752405 | validation: 0.022517160476887902]
	TIME [epoch: 5.72 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0366380250886801		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.0366380250886801 | validation: 0.027642978459366026]
	TIME [epoch: 5.72 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566613568188181		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.03566613568188181 | validation: 0.02674917780532323]
	TIME [epoch: 5.74 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03710614671473318		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.03710614671473318 | validation: 0.030559898306790824]
	TIME [epoch: 5.74 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04272167331874692		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.04272167331874692 | validation: 0.04313856388455646]
	TIME [epoch: 5.72 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04921040512484644		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.04921040512484644 | validation: 0.04660265086389649]
	TIME [epoch: 5.72 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04683157543246186		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.04683157543246186 | validation: 0.03686020172161295]
	TIME [epoch: 5.72 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040472516250122395		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.040472516250122395 | validation: 0.023627321965675976]
	TIME [epoch: 5.73 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0415763864521749		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.0415763864521749 | validation: 0.03138832462128702]
	TIME [epoch: 5.74 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04487678083510778		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.04487678083510778 | validation: 0.021430115113698685]
	TIME [epoch: 5.74 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03850479357801316		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.03850479357801316 | validation: 0.03033849264480061]
	TIME [epoch: 5.72 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03584341741676579		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.03584341741676579 | validation: 0.02704600916932086]
	TIME [epoch: 5.72 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03887840320120487		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.03887840320120487 | validation: 0.026586446183122975]
	TIME [epoch: 5.72 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036749573190601105		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.036749573190601105 | validation: 0.02642448143813475]
	TIME [epoch: 5.72 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0401589052428332		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.0401589052428332 | validation: 0.03083590947773771]
	TIME [epoch: 5.74 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04661537954649717		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.04661537954649717 | validation: 0.02566806717254088]
	TIME [epoch: 5.74 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040665758616135236		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.040665758616135236 | validation: 0.024457852878606034]
	TIME [epoch: 5.72 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0348002689268062		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.0348002689268062 | validation: 0.027063421068075733]
	TIME [epoch: 5.72 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03693651507477246		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.03693651507477246 | validation: 0.025814963870526803]
	TIME [epoch: 5.72 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03842042682839636		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.03842042682839636 | validation: 0.030557272567276392]
	TIME [epoch: 5.72 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038032672716811294		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.038032672716811294 | validation: 0.016594780422142]
	TIME [epoch: 5.74 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03943216116743441		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.03943216116743441 | validation: 0.030820071642110813]
	TIME [epoch: 5.72 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04286083953393448		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.04286083953393448 | validation: 0.02726009078559831]
	TIME [epoch: 5.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03838758001461276		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.03838758001461276 | validation: 0.01939912559578996]
	TIME [epoch: 5.7 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035373564635606536		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.035373564635606536 | validation: 0.028096626688560163]
	TIME [epoch: 5.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04078334357700052		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.04078334357700052 | validation: 0.0245034669707209]
	TIME [epoch: 5.71 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04117027326057701		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.04117027326057701 | validation: 0.028115462666088477]
	TIME [epoch: 5.74 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04418228984195252		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.04418228984195252 | validation: 0.024065441901096937]
	TIME [epoch: 5.74 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041051945745466945		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.041051945745466945 | validation: 0.02453406560460257]
	TIME [epoch: 5.72 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03986010216333487		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.03986010216333487 | validation: 0.02912103933052964]
	TIME [epoch: 5.72 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0350549580954183		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.0350549580954183 | validation: 0.027657871632387306]
	TIME [epoch: 5.71 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0391784541743206		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.0391784541743206 | validation: 0.021369765474882833]
	TIME [epoch: 5.71 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03880006590777538		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.03880006590777538 | validation: 0.021412341603355502]
	TIME [epoch: 5.73 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03829693883854268		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.03829693883854268 | validation: 0.027003819422323796]
	TIME [epoch: 5.73 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039153421597262164		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.039153421597262164 | validation: 0.029526318929862076]
	TIME [epoch: 5.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04173009616398682		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.04173009616398682 | validation: 0.012742707312090333]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_1316.pth
	Model improved!!!
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03922067330015973		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.03922067330015973 | validation: 0.02270249205211053]
	TIME [epoch: 5.7 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03946300984554653		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.03946300984554653 | validation: 0.026352496766568298]
	TIME [epoch: 5.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03782194937437061		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.03782194937437061 | validation: 0.016715779945481516]
	TIME [epoch: 5.72 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04047095811673974		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.04047095811673974 | validation: 0.030816562262284054]
	TIME [epoch: 5.72 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04462163220249684		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.04462163220249684 | validation: 0.03452280249759905]
	TIME [epoch: 5.7 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039114334692891245		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.039114334692891245 | validation: 0.028800805421612573]
	TIME [epoch: 5.7 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041757226432558144		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.041757226432558144 | validation: 0.026637055721976246]
	TIME [epoch: 5.7 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03686277833336049		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.03686277833336049 | validation: 0.03672428946674227]
	TIME [epoch: 5.72 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038183898765375986		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.038183898765375986 | validation: 0.02102468559698308]
	TIME [epoch: 5.74 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03700904112474858		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.03700904112474858 | validation: 0.02555389741806438]
	TIME [epoch: 5.74 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03799131124421325		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.03799131124421325 | validation: 0.026311014635232065]
	TIME [epoch: 5.72 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385388617898897		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.04385388617898897 | validation: 0.031516633366503115]
	TIME [epoch: 5.72 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03702523590506422		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.03702523590506422 | validation: 0.02415264932662769]
	TIME [epoch: 5.7 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04009841190927399		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.04009841190927399 | validation: 0.035633581734175745]
	TIME [epoch: 5.7 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039041688806374486		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.039041688806374486 | validation: 0.025512654857698998]
	TIME [epoch: 5.72 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04081780155277912		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.04081780155277912 | validation: 0.023614615248898456]
	TIME [epoch: 5.72 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860321967256946		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.03860321967256946 | validation: 0.032807544948465474]
	TIME [epoch: 5.7 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043904331206656		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.043904331206656 | validation: 0.012485065880943502]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_1334.pth
	Model improved!!!
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039858214301947165		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.039858214301947165 | validation: 0.025143349411307227]
	TIME [epoch: 5.72 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03968353062721078		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.03968353062721078 | validation: 0.02472309156258983]
	TIME [epoch: 5.72 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03876659173659107		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.03876659173659107 | validation: 0.033280276074037864]
	TIME [epoch: 5.74 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566105140798474		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.03566105140798474 | validation: 0.031061694364099363]
	TIME [epoch: 5.74 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03919504095978573		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.03919504095978573 | validation: 0.02686771923365164]
	TIME [epoch: 5.72 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834956223554666		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.03834956223554666 | validation: 0.028591387520804305]
	TIME [epoch: 5.72 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03634798139437244		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.03634798139437244 | validation: 0.02489885794943203]
	TIME [epoch: 5.72 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0427674635076811		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.0427674635076811 | validation: 0.03304668211710676]
	TIME [epoch: 5.72 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037944181765465754		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.037944181765465754 | validation: 0.025594831869271646]
	TIME [epoch: 5.74 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040118332345292045		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.040118332345292045 | validation: 0.03176323202012597]
	TIME [epoch: 5.74 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03907694560120006		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.03907694560120006 | validation: 0.02126928088598552]
	TIME [epoch: 5.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451162197082474		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.03451162197082474 | validation: 0.0239598873726692]
	TIME [epoch: 5.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041757851389705766		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.041757851389705766 | validation: 0.03293264552937546]
	TIME [epoch: 5.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037009191194159755		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.037009191194159755 | validation: 0.029489824500154728]
	TIME [epoch: 5.7 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04176572751048369		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.04176572751048369 | validation: 0.029307965100332373]
	TIME [epoch: 5.73 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03559958282631073		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.03559958282631073 | validation: 0.030203612207186696]
	TIME [epoch: 5.72 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036453100089353846		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.036453100089353846 | validation: 0.015431265082727788]
	TIME [epoch: 5.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04001395014778296		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.04001395014778296 | validation: 0.02218240814831698]
	TIME [epoch: 5.7 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04108471632932664		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.04108471632932664 | validation: 0.024981936118920103]
	TIME [epoch: 5.72 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03862423393247509		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.03862423393247509 | validation: 0.025259845667826127]
	TIME [epoch: 5.7 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043938688453889006		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.043938688453889006 | validation: 0.01914464746404668]
	TIME [epoch: 5.72 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038705707560962185		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.038705707560962185 | validation: 0.021191942605607292]
	TIME [epoch: 5.72 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03311056731113031		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.03311056731113031 | validation: 0.015398595726739128]
	TIME [epoch: 5.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03861221498770795		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.03861221498770795 | validation: 0.02251586470642222]
	TIME [epoch: 5.7 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03647334134949359		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.03647334134949359 | validation: 0.027727205271993433]
	TIME [epoch: 5.7 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037783813205099805		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.037783813205099805 | validation: 0.02576361527239385]
	TIME [epoch: 5.72 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03306828024744704		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.03306828024744704 | validation: 0.026102143821434765]
	TIME [epoch: 5.74 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04154043224972236		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.04154043224972236 | validation: 0.03596298161355408]
	TIME [epoch: 5.74 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262419975521618		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.04262419975521618 | validation: 0.030580271654811017]
	TIME [epoch: 5.72 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041642655608446245		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.041642655608446245 | validation: 0.031561873554584396]
	TIME [epoch: 5.72 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0387435128922671		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.0387435128922671 | validation: 0.029378860966353875]
	TIME [epoch: 5.72 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038950619952141184		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.038950619952141184 | validation: 0.028413819567086787]
	TIME [epoch: 5.72 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03745447501781341		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.03745447501781341 | validation: 0.025165140509368956]
	TIME [epoch: 5.74 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04504119564621775		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.04504119564621775 | validation: 0.032223417085573546]
	TIME [epoch: 5.74 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03803263249774742		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.03803263249774742 | validation: 0.036510016507851954]
	TIME [epoch: 5.72 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04327250913483184		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.04327250913483184 | validation: 0.025588021302361003]
	TIME [epoch: 5.72 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04307727063666812		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.04307727063666812 | validation: 0.029282934975668487]
	TIME [epoch: 5.72 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03644138220779752		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.03644138220779752 | validation: 0.034441726818519494]
	TIME [epoch: 5.72 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04117382341452278		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.04117382341452278 | validation: 0.028849869385776092]
	TIME [epoch: 5.74 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041518382323440746		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.041518382323440746 | validation: 0.02208368591199454]
	TIME [epoch: 5.74 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038174752797830024		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.038174752797830024 | validation: 0.026954449247179678]
	TIME [epoch: 5.72 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04225970007852525		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.04225970007852525 | validation: 0.02387832151619581]
	TIME [epoch: 5.72 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042619602711842224		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.042619602711842224 | validation: 0.024549586430138996]
	TIME [epoch: 5.72 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036386496146192375		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.036386496146192375 | validation: 0.033927579370356176]
	TIME [epoch: 5.72 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03828639138876151		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.03828639138876151 | validation: 0.02631078729860671]
	TIME [epoch: 5.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03718003790052383		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.03718003790052383 | validation: 0.03183394205564049]
	TIME [epoch: 5.74 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036076687507866065		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.036076687507866065 | validation: 0.03208188564188028]
	TIME [epoch: 5.72 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038412625743948124		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.038412625743948124 | validation: 0.026356621377218423]
	TIME [epoch: 5.72 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04249514150118047		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.04249514150118047 | validation: 0.021284603371334462]
	TIME [epoch: 5.72 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04159539918984173		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.04159539918984173 | validation: 0.03143966234269281]
	TIME [epoch: 5.72 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04041725471673264		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.04041725471673264 | validation: 0.024127786445680376]
	TIME [epoch: 5.74 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0351533626572081		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.0351533626572081 | validation: 0.020875802745460338]
	TIME [epoch: 5.74 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039960205810857984		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.039960205810857984 | validation: 0.02542820906580812]
	TIME [epoch: 5.72 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036406437817038464		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.036406437817038464 | validation: 0.030597962297295896]
	TIME [epoch: 5.72 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041759372424663876		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.041759372424663876 | validation: 0.034004304501667144]
	TIME [epoch: 5.72 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041950128421953545		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.041950128421953545 | validation: 0.02473938321822673]
	TIME [epoch: 5.72 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03940073578312375		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.03940073578312375 | validation: 0.022915598702918975]
	TIME [epoch: 5.74 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03565919705518269		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.03565919705518269 | validation: 0.030009540771199453]
	TIME [epoch: 5.74 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03840816255439596		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.03840816255439596 | validation: 0.018249084887258498]
	TIME [epoch: 5.72 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03526089451541332		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.03526089451541332 | validation: 0.022927891446937895]
	TIME [epoch: 5.72 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03744216919699213		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.03744216919699213 | validation: 0.02860096972707]
	TIME [epoch: 5.72 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03690220222417908		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.03690220222417908 | validation: 0.025261363579958396]
	TIME [epoch: 5.72 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03967646903983493		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.03967646903983493 | validation: 0.021568678943958374]
	TIME [epoch: 5.74 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036755777170149946		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.036755777170149946 | validation: 0.024841303977072137]
	TIME [epoch: 5.73 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04052770793107695		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.04052770793107695 | validation: 0.03377587744013983]
	TIME [epoch: 5.72 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03902985634354244		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.03902985634354244 | validation: 0.024540574254464858]
	TIME [epoch: 5.72 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04095195304074371		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.04095195304074371 | validation: 0.02905589199744589]
	TIME [epoch: 5.72 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039040245508580124		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.039040245508580124 | validation: 0.026328372972005198]
	TIME [epoch: 5.72 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03685359762723318		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.03685359762723318 | validation: 0.022400114114839883]
	TIME [epoch: 5.74 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03898397628851852		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.03898397628851852 | validation: 0.02582359082053775]
	TIME [epoch: 5.74 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03836471782540721		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.03836471782540721 | validation: 0.019980826828725408]
	TIME [epoch: 5.72 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041965138553424666		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.041965138553424666 | validation: 0.02902408030796356]
	TIME [epoch: 5.7 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03808231995982399		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.03808231995982399 | validation: 0.03470535835254536]
	TIME [epoch: 5.72 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03991570521510071		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.03991570521510071 | validation: 0.020540280404298335]
	TIME [epoch: 5.72 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04060591464256853		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.04060591464256853 | validation: 0.026136020967555584]
	TIME [epoch: 5.74 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036061265647597054		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.036061265647597054 | validation: 0.030325711799334392]
	TIME [epoch: 5.74 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037119626133935074		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.037119626133935074 | validation: 0.02474218405802794]
	TIME [epoch: 5.72 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03685919496908721		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.03685919496908721 | validation: 0.027197289594166976]
	TIME [epoch: 5.71 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040554456167136876		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.040554456167136876 | validation: 0.02438435307150637]
	TIME [epoch: 5.72 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038465853737201364		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.038465853737201364 | validation: 0.023370729884141586]
	TIME [epoch: 5.72 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043368278475525074		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.043368278475525074 | validation: 0.03674934837842992]
	TIME [epoch: 5.74 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03879480776080442		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.03879480776080442 | validation: 0.032950499436729126]
	TIME [epoch: 5.74 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041647573397682006		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.041647573397682006 | validation: 0.03187716710961767]
	TIME [epoch: 5.72 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03953463964212313		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.03953463964212313 | validation: 0.028670982805952993]
	TIME [epoch: 5.7 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464814226705015		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.03464814226705015 | validation: 0.01904447807471528]
	TIME [epoch: 5.72 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03739923639272899		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.03739923639272899 | validation: 0.033409939706936335]
	TIME [epoch: 5.72 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03944829954564317		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.03944829954564317 | validation: 0.026722870242138912]
	TIME [epoch: 5.72 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037663554435703864		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.037663554435703864 | validation: 0.027948517213851557]
	TIME [epoch: 5.72 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038883299241048615		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.038883299241048615 | validation: 0.023979061773753207]
	TIME [epoch: 5.7 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03751505863143896		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.03751505863143896 | validation: 0.02329727074280931]
	TIME [epoch: 5.7 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039590808385445445		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.039590808385445445 | validation: 0.028365245089905736]
	TIME [epoch: 5.7 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03882963398478481		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.03882963398478481 | validation: 0.024813239761335874]
	TIME [epoch: 5.72 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035658424961187186		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.035658424961187186 | validation: 0.03373287070565369]
	TIME [epoch: 5.73 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03941612946944324		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.03941612946944324 | validation: 0.021282032939915974]
	TIME [epoch: 5.75 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03572847172179163		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.03572847172179163 | validation: 0.020350041957567826]
	TIME [epoch: 5.72 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03720964609931425		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.03720964609931425 | validation: 0.0246974738098908]
	TIME [epoch: 5.71 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04124334699321545		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.04124334699321545 | validation: 0.03280293927313795]
	TIME [epoch: 5.7 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035420727271273884		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.035420727271273884 | validation: 0.021116079448815783]
	TIME [epoch: 5.72 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03607282985082196		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.03607282985082196 | validation: 0.022302643837448323]
	TIME [epoch: 5.71 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03669765829912372		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.03669765829912372 | validation: 0.023912085262734965]
	TIME [epoch: 5.75 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038083781838342844		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.038083781838342844 | validation: 0.01858636612922896]
	TIME [epoch: 5.72 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04062792726489396		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.04062792726489396 | validation: 0.03469244790390544]
	TIME [epoch: 5.7 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03979960225984554		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.03979960225984554 | validation: 0.028207103243715635]
	TIME [epoch: 5.72 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037460144303534455		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.037460144303534455 | validation: 0.02751413498226775]
	TIME [epoch: 5.72 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0386570747981629		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.0386570747981629 | validation: 0.025804000393242994]
	TIME [epoch: 5.73 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03509348473659492		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.03509348473659492 | validation: 0.023836674978326373]
	TIME [epoch: 5.75 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595825892514569		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03595825892514569 | validation: 0.02053743515630265]
	TIME [epoch: 5.72 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03807725575540517		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.03807725575540517 | validation: 0.024840086930773914]
	TIME [epoch: 5.72 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03803316096402219		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.03803316096402219 | validation: 0.02467507108018327]
	TIME [epoch: 5.72 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03731967136897465		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.03731967136897465 | validation: 0.030614529706614428]
	TIME [epoch: 5.71 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038996026659652405		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.038996026659652405 | validation: 0.02734256431113411]
	TIME [epoch: 5.73 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04071042960569217		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.04071042960569217 | validation: 0.03094204041063707]
	TIME [epoch: 5.74 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03758938159101474		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.03758938159101474 | validation: 0.020239672481874995]
	TIME [epoch: 5.72 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038404353073186306		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.038404353073186306 | validation: 0.024427881507981003]
	TIME [epoch: 5.72 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03807232131826987		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.03807232131826987 | validation: 0.025671347897130596]
	TIME [epoch: 5.72 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04277318242782754		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.04277318242782754 | validation: 0.029004700187416434]
	TIME [epoch: 5.72 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04392476225347603		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.04392476225347603 | validation: 0.04596184224938938]
	TIME [epoch: 5.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05486524854176508		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.05486524854176508 | validation: 0.054211775941081494]
	TIME [epoch: 5.75 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05110273233593398		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.05110273233593398 | validation: 0.035489537717522585]
	TIME [epoch: 5.72 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04475040660431411		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.04475040660431411 | validation: 0.024988309369769354]
	TIME [epoch: 5.72 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0378306781455298		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.0378306781455298 | validation: 0.02464087495433536]
	TIME [epoch: 5.72 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0369900069927999		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.0369900069927999 | validation: 0.023507648805457197]
	TIME [epoch: 5.72 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03612630947548726		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.03612630947548726 | validation: 0.027308720428465313]
	TIME [epoch: 5.73 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03227280420108686		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.03227280420108686 | validation: 0.020110526090624248]
	TIME [epoch: 5.75 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03353495017848005		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.03353495017848005 | validation: 0.02539541859159035]
	TIME [epoch: 5.72 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03819584980878448		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.03819584980878448 | validation: 0.029415869225890196]
	TIME [epoch: 5.72 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03902766765344152		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.03902766765344152 | validation: 0.02516079669148722]
	TIME [epoch: 5.72 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037809855803910955		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.037809855803910955 | validation: 0.026817351556336348]
	TIME [epoch: 5.72 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035539197582657174		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.035539197582657174 | validation: 0.026653324354218726]
	TIME [epoch: 5.73 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03455453923897299		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.03455453923897299 | validation: 0.02615589855050263]
	TIME [epoch: 5.75 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388224890281194		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.03388224890281194 | validation: 0.02016473070990818]
	TIME [epoch: 5.72 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0373421911613124		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.0373421911613124 | validation: 0.02499722595740372]
	TIME [epoch: 5.72 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03937822890747959		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.03937822890747959 | validation: 0.025034747325270237]
	TIME [epoch: 5.72 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037112122434837004		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.037112122434837004 | validation: 0.02632203644633576]
	TIME [epoch: 5.72 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04157869624218398		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.04157869624218398 | validation: 0.031830104433685266]
	TIME [epoch: 5.73 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033837019517612366		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.033837019517612366 | validation: 0.02225826922149941]
	TIME [epoch: 5.75 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039063421445529836		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.039063421445529836 | validation: 0.029652725118938874]
	TIME [epoch: 5.7 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03991718950428874		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.03991718950428874 | validation: 0.036661850403050644]
	TIME [epoch: 5.72 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040474240455823346		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.040474240455823346 | validation: 0.025685190006762167]
	TIME [epoch: 5.72 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04137024897281491		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.04137024897281491 | validation: 0.02825378652770397]
	TIME [epoch: 5.71 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04005320484675274		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.04005320484675274 | validation: 0.029976128785279638]
	TIME [epoch: 5.73 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038146863092453735		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.038146863092453735 | validation: 0.033477412202158566]
	TIME [epoch: 5.73 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043879622294051936		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.043879622294051936 | validation: 0.029633045186591232]
	TIME [epoch: 5.71 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426684961676721		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.0426684961676721 | validation: 0.0355887426567084]
	TIME [epoch: 5.72 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04065597912079302		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.04065597912079302 | validation: 0.023844673319482923]
	TIME [epoch: 5.71 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03574481188850243		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.03574481188850243 | validation: 0.034485111678117505]
	TIME [epoch: 5.71 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03547053174772423		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.03547053174772423 | validation: 0.016345611382544693]
	TIME [epoch: 5.71 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529001762842193		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.03529001762842193 | validation: 0.0268692607900562]
	TIME [epoch: 5.73 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0360271732363182		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.0360271732363182 | validation: 0.023230288012999353]
	TIME [epoch: 5.71 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038339125756144496		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.038339125756144496 | validation: 0.03340197490334955]
	TIME [epoch: 5.7 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03657501512151879		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.03657501512151879 | validation: 0.018454531988904507]
	TIME [epoch: 5.7 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0355795917145824		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.0355795917145824 | validation: 0.025227839095258563]
	TIME [epoch: 5.72 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578322460845358		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.03578322460845358 | validation: 0.026595615058881483]
	TIME [epoch: 5.72 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036010655404434155		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.036010655404434155 | validation: 0.026836224287301817]
	TIME [epoch: 5.75 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039586374548030406		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.039586374548030406 | validation: 0.03588169325411934]
	TIME [epoch: 5.71 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039183931011635635		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.039183931011635635 | validation: 0.036626731199573256]
	TIME [epoch: 5.72 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045450387607323214		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.045450387607323214 | validation: 0.023365626553134424]
	TIME [epoch: 5.72 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04212596412175183		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.04212596412175183 | validation: 0.029276942546741402]
	TIME [epoch: 5.7 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485642101620776		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.03485642101620776 | validation: 0.02306889895189978]
	TIME [epoch: 5.71 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036921691843520135		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.036921691843520135 | validation: 0.02664099483537719]
	TIME [epoch: 5.74 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034893130727360444		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.034893130727360444 | validation: 0.02068223589726376]
	TIME [epoch: 5.72 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03503367353152961		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.03503367353152961 | validation: 0.0195054334419281]
	TIME [epoch: 5.7 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03586246719083257		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.03586246719083257 | validation: 0.02291984390698615]
	TIME [epoch: 5.7 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03883561040028359		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.03883561040028359 | validation: 0.026756654427962313]
	TIME [epoch: 5.72 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036279396414920256		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.036279396414920256 | validation: 0.01944688240341682]
	TIME [epoch: 5.72 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429572403757111		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.03429572403757111 | validation: 0.03125039302979854]
	TIME [epoch: 5.75 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03879003844869934		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.03879003844869934 | validation: 0.0270645040812732]
	TIME [epoch: 5.72 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036560832510849905		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.036560832510849905 | validation: 0.034251485047274544]
	TIME [epoch: 5.72 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040799245885548424		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.040799245885548424 | validation: 0.029975055570729357]
	TIME [epoch: 5.71 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03850323105581849		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.03850323105581849 | validation: 0.025082358293018907]
	TIME [epoch: 5.72 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037278536081953875		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.037278536081953875 | validation: 0.028135403658318705]
	TIME [epoch: 5.71 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568651334741099		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.03568651334741099 | validation: 0.026590993574784776]
	TIME [epoch: 5.74 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03841843906717209		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.03841843906717209 | validation: 0.02214748575858727]
	TIME [epoch: 5.72 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037578358932898445		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.037578358932898445 | validation: 0.027651341404268625]
	TIME [epoch: 5.71 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04118935335981947		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.04118935335981947 | validation: 0.025189657638742778]
	TIME [epoch: 5.71 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036518573250606576		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.036518573250606576 | validation: 0.0255644301682614]
	TIME [epoch: 5.72 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03631046241053393		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.03631046241053393 | validation: 0.032195687396937796]
	TIME [epoch: 5.72 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0372955104610994		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.0372955104610994 | validation: 0.021086407318591172]
	TIME [epoch: 5.74 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357144277699611		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.0357144277699611 | validation: 0.024303008863560106]
	TIME [epoch: 5.72 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909276093995945		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.03909276093995945 | validation: 0.020539292315144845]
	TIME [epoch: 5.71 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03769773562328155		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.03769773562328155 | validation: 0.03056101679953726]
	TIME [epoch: 5.71 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03372914093798764		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.03372914093798764 | validation: 0.02250695632407475]
	TIME [epoch: 5.71 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0366362388218357		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.0366362388218357 | validation: 0.02986954536343376]
	TIME [epoch: 5.72 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03545966753981366		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.03545966753981366 | validation: 0.028431759595634053]
	TIME [epoch: 5.74 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036598428297338406		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.036598428297338406 | validation: 0.026660473879448237]
	TIME [epoch: 5.72 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03846700283415636		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.03846700283415636 | validation: 0.020558344959561083]
	TIME [epoch: 5.71 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038748102521408284		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.038748102521408284 | validation: 0.021774576999540603]
	TIME [epoch: 5.7 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738968483877847		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.03738968483877847 | validation: 0.018401871868699696]
	TIME [epoch: 5.72 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038786695583160204		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.038786695583160204 | validation: 0.021067005632466742]
	TIME [epoch: 5.72 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03777350855744466		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.03777350855744466 | validation: 0.022798763733326278]
	TIME [epoch: 5.74 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834052550248614		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.03834052550248614 | validation: 0.029445375350184124]
	TIME [epoch: 5.7 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03672646505725937		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.03672646505725937 | validation: 0.031870597894598215]
	TIME [epoch: 5.71 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357504919574636		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.0357504919574636 | validation: 0.02777448919963776]
	TIME [epoch: 5.72 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04008965996744184		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.04008965996744184 | validation: 0.027559244287498546]
	TIME [epoch: 5.71 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043678218382647876		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.043678218382647876 | validation: 0.025071836529653786]
	TIME [epoch: 5.72 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03791058543411356		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.03791058543411356 | validation: 0.027359019655859643]
	TIME [epoch: 5.75 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0365281404511809		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.0365281404511809 | validation: 0.023383764497903962]
	TIME [epoch: 5.71 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037213828160312684		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.037213828160312684 | validation: 0.02340609705914224]
	TIME [epoch: 5.71 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036313073923483534		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.036313073923483534 | validation: 0.019053250654608403]
	TIME [epoch: 5.7 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03916589801031789		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.03916589801031789 | validation: 0.024350456841474508]
	TIME [epoch: 5.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0338860814899495		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.0338860814899495 | validation: 0.026171135727279218]
	TIME [epoch: 5.71 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552311500216275		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.03552311500216275 | validation: 0.02689305374008639]
	TIME [epoch: 5.75 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03461429924014571		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.03461429924014571 | validation: 0.017430672340084913]
	TIME [epoch: 5.71 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03929839961275125		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.03929839961275125 | validation: 0.03227880002297293]
	TIME [epoch: 5.72 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03548351076046418		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.03548351076046418 | validation: 0.0191981997828415]
	TIME [epoch: 5.72 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03391602427195146		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.03391602427195146 | validation: 0.030030669121450058]
	TIME [epoch: 5.7 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038510866670061726		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.038510866670061726 | validation: 0.02530794089987515]
	TIME [epoch: 5.71 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03582776141598264		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.03582776141598264 | validation: 0.025575152466356225]
	TIME [epoch: 5.74 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035318567619351295		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.035318567619351295 | validation: 0.030501447641872268]
	TIME [epoch: 5.71 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038720079106164894		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.038720079106164894 | validation: 0.02137728769377086]
	TIME [epoch: 5.72 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03970594850120088		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.03970594850120088 | validation: 0.02846563231525293]
	TIME [epoch: 5.7 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039665931530374315		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.039665931530374315 | validation: 0.03814009322927027]
	TIME [epoch: 5.71 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0418880401336409		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.0418880401336409 | validation: 0.029809388567325144]
	TIME [epoch: 5.73 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035815989107260124		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.035815989107260124 | validation: 0.023257129982569298]
	TIME [epoch: 5.73 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03779729180110851		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.03779729180110851 | validation: 0.02865812914867651]
	TIME [epoch: 5.71 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04229929443251493		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.04229929443251493 | validation: 0.028007763736387303]
	TIME [epoch: 5.7 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041417867537601454		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.041417867537601454 | validation: 0.030935807873498193]
	TIME [epoch: 5.71 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04005989757382882		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.04005989757382882 | validation: 0.032330476733619176]
	TIME [epoch: 5.72 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038381569599570994		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.038381569599570994 | validation: 0.02196535977690182]
	TIME [epoch: 5.72 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03803782412495062		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.03803782412495062 | validation: 0.030634180555967887]
	TIME [epoch: 5.75 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03949425330146711		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.03949425330146711 | validation: 0.026522046868240584]
	TIME [epoch: 5.72 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038281155996481256		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.038281155996481256 | validation: 0.02773406934554932]
	TIME [epoch: 5.71 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038816742220224236		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.038816742220224236 | validation: 0.026267577903322424]
	TIME [epoch: 5.71 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03687075596670142		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.03687075596670142 | validation: 0.020883406194700863]
	TIME [epoch: 5.7 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0347071296330551		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.0347071296330551 | validation: 0.01722700556500975]
	TIME [epoch: 5.71 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037236781241890775		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.037236781241890775 | validation: 0.025112025925136387]
	TIME [epoch: 5.75 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036815925994220025		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.036815925994220025 | validation: 0.019948512150728414]
	TIME [epoch: 5.72 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03970313564959255		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.03970313564959255 | validation: 0.022014255949080488]
	TIME [epoch: 5.7 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03516332220856416		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.03516332220856416 | validation: 0.022579126271756615]
	TIME [epoch: 5.7 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03465680845732142		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.03465680845732142 | validation: 0.027554547355558585]
	TIME [epoch: 5.7 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035341741343529375		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.035341741343529375 | validation: 0.0257650567867993]
	TIME [epoch: 5.71 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0361365595165767		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.0361365595165767 | validation: 0.027360563839101716]
	TIME [epoch: 5.74 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03858945872289132		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.03858945872289132 | validation: 0.016809678424850774]
	TIME [epoch: 5.71 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035550609876416915		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.035550609876416915 | validation: 0.021390314054326735]
	TIME [epoch: 5.7 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034617599139346526		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.034617599139346526 | validation: 0.024221531257767798]
	TIME [epoch: 5.7 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035092242900091185		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.035092242900091185 | validation: 0.025862104652653477]
	TIME [epoch: 5.7 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03355921606017672		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.03355921606017672 | validation: 0.027161971238815728]
	TIME [epoch: 5.7 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03940685421184441		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.03940685421184441 | validation: 0.032147637567159]
	TIME [epoch: 5.75 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04047316694262629		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.04047316694262629 | validation: 0.027566497589771803]
	TIME [epoch: 5.72 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0396630541067616		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.0396630541067616 | validation: 0.03335823611364056]
	TIME [epoch: 5.72 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03711883506294091		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.03711883506294091 | validation: 0.021740770201329883]
	TIME [epoch: 5.71 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03766816103174568		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.03766816103174568 | validation: 0.019624866059812004]
	TIME [epoch: 5.7 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03668171637184945		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.03668171637184945 | validation: 0.02627497914062601]
	TIME [epoch: 5.7 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0345320270268203		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.0345320270268203 | validation: 0.0244397599745135]
	TIME [epoch: 5.74 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036001720668930565		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.036001720668930565 | validation: 0.03296785190882408]
	TIME [epoch: 5.72 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029715804436502288		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.029715804436502288 | validation: 0.0228696076161817]
	TIME [epoch: 5.71 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03246432528648972		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.03246432528648972 | validation: 0.02417123614319456]
	TIME [epoch: 5.71 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03539643314042321		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.03539643314042321 | validation: 0.018046969136527785]
	TIME [epoch: 5.7 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033926476234016414		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.033926476234016414 | validation: 0.026048930775965397]
	TIME [epoch: 5.7 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035885076221319194		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.035885076221319194 | validation: 0.03368982307925149]
	TIME [epoch: 5.74 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03790371767784597		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.03790371767784597 | validation: 0.02455487619338831]
	TIME [epoch: 5.71 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03937758294894048		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.03937758294894048 | validation: 0.027507117156931264]
	TIME [epoch: 5.71 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038633541618192935		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.038633541618192935 | validation: 0.03045427155237965]
	TIME [epoch: 5.7 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036277999050656116		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.036277999050656116 | validation: 0.031446422709946624]
	TIME [epoch: 5.7 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035521458119849095		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.035521458119849095 | validation: 0.022007878222149686]
	TIME [epoch: 5.72 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03599165249354769		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.03599165249354769 | validation: 0.01783723211848419]
	TIME [epoch: 5.74 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03693990869759407		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.03693990869759407 | validation: 0.02330021424429548]
	TIME [epoch: 5.72 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03560786479291492		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.03560786479291492 | validation: 0.018534220686130566]
	TIME [epoch: 5.7 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03547155201485139		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.03547155201485139 | validation: 0.025060941761404054]
	TIME [epoch: 5.71 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033072462474113946		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.033072462474113946 | validation: 0.02255598893822163]
	TIME [epoch: 5.7 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03380752757242908		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.03380752757242908 | validation: 0.025690909098295505]
	TIME [epoch: 5.72 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0361428228176546		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.0361428228176546 | validation: 0.03017964127136827]
	TIME [epoch: 5.74 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034716084846952926		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.034716084846952926 | validation: 0.0231009221998956]
	TIME [epoch: 5.71 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03559752988000989		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.03559752988000989 | validation: 0.03095192774110628]
	TIME [epoch: 5.71 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03656169082453829		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.03656169082453829 | validation: 0.019299317301946464]
	TIME [epoch: 5.71 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034874924161559566		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.034874924161559566 | validation: 0.020681516057290003]
	TIME [epoch: 5.72 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031103179331991023		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.031103179331991023 | validation: 0.01976616023040664]
	TIME [epoch: 5.71 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03608060326114436		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.03608060326114436 | validation: 0.01969494605588449]
	TIME [epoch: 5.74 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036240119631179894		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.036240119631179894 | validation: 0.017431652607884266]
	TIME [epoch: 5.7 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145888090453773		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.03145888090453773 | validation: 0.03317714476508285]
	TIME [epoch: 5.72 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040519022059511946		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.040519022059511946 | validation: 0.02872448838132994]
	TIME [epoch: 5.72 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032828401409740485		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.032828401409740485 | validation: 0.019698667894473925]
	TIME [epoch: 5.71 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03579202617348327		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.03579202617348327 | validation: 0.030409405546786842]
	TIME [epoch: 5.71 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03639176598228826		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.03639176598228826 | validation: 0.022494915148038284]
	TIME [epoch: 5.74 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036361823337566865		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.036361823337566865 | validation: 0.027397987360110784]
	TIME [epoch: 5.72 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035565575953830836		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.035565575953830836 | validation: 0.02231055200784031]
	TIME [epoch: 5.71 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035095791964223536		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.035095791964223536 | validation: 0.02293062484794973]
	TIME [epoch: 5.71 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03668254706963907		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.03668254706963907 | validation: 0.022637100152471917]
	TIME [epoch: 5.71 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03654788936643905		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.03654788936643905 | validation: 0.020255929978986426]
	TIME [epoch: 5.71 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035858714552607016		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.035858714552607016 | validation: 0.03093312755616977]
	TIME [epoch: 5.75 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035128710953361786		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.035128710953361786 | validation: 0.02357209450299109]
	TIME [epoch: 5.71 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03487879548189637		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.03487879548189637 | validation: 0.01886405653594972]
	TIME [epoch: 5.71 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033414531800109344		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.033414531800109344 | validation: 0.021187995579934338]
	TIME [epoch: 5.72 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037679137088228176		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.037679137088228176 | validation: 0.02612981648714864]
	TIME [epoch: 5.71 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03249028973769659		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.03249028973769659 | validation: 0.028325214382991785]
	TIME [epoch: 5.71 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909958579841964		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.03909958579841964 | validation: 0.02254685302973207]
	TIME [epoch: 5.74 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037946425175949205		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.037946425175949205 | validation: 0.02563974808657291]
	TIME [epoch: 5.72 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036434252516845365		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.036434252516845365 | validation: 0.025433688579907496]
	TIME [epoch: 5.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03625991359473981		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.03625991359473981 | validation: 0.02531262674260823]
	TIME [epoch: 5.72 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03907562883835599		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.03907562883835599 | validation: 0.02001057967401376]
	TIME [epoch: 5.7 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441386192369779		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.03441386192369779 | validation: 0.018665076154931074]
	TIME [epoch: 5.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038038700978209966		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.038038700978209966 | validation: 0.024532675289873077]
	TIME [epoch: 5.73 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03645532550975328		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.03645532550975328 | validation: 0.030109196908071664]
	TIME [epoch: 5.7 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03399761091282921		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.03399761091282921 | validation: 0.030488327605385602]
	TIME [epoch: 5.71 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0355833267297259		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.0355833267297259 | validation: 0.018282164401357985]
	TIME [epoch: 5.72 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034490418036845646		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.034490418036845646 | validation: 0.030909468623663675]
	TIME [epoch: 5.71 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03561320323896035		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.03561320323896035 | validation: 0.027440025777564964]
	TIME [epoch: 5.7 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040047508768214266		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.040047508768214266 | validation: 0.026476540362297615]
	TIME [epoch: 5.74 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034602683253477096		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.034602683253477096 | validation: 0.026515429689794145]
	TIME [epoch: 5.71 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03660893891288797		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.03660893891288797 | validation: 0.01817963054712914]
	TIME [epoch: 5.72 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03519803567638598		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.03519803567638598 | validation: 0.02782378473278067]
	TIME [epoch: 5.71 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552408964632943		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.03552408964632943 | validation: 0.024025719338383322]
	TIME [epoch: 5.71 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486126679363238		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.03486126679363238 | validation: 0.023270430463058968]
	TIME [epoch: 5.7 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034391573225517995		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.034391573225517995 | validation: 0.019241154339069953]
	TIME [epoch: 5.75 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033397554462372095		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.033397554462372095 | validation: 0.022435903926137736]
	TIME [epoch: 5.7 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03511697780339087		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.03511697780339087 | validation: 0.030770040604774014]
	TIME [epoch: 5.7 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03611258862525495		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.03611258862525495 | validation: 0.02441895779355671]
	TIME [epoch: 5.7 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037567200738750924		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.037567200738750924 | validation: 0.01845023104080348]
	TIME [epoch: 5.71 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441350189628195		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.03441350189628195 | validation: 0.024448431797329532]
	TIME [epoch: 5.72 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03334261801940486		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.03334261801940486 | validation: 0.019982657221347757]
	TIME [epoch: 5.74 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036708823262544606		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.036708823262544606 | validation: 0.01994722664961461]
	TIME [epoch: 5.71 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03555661607373664		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.03555661607373664 | validation: 0.027159596724437178]
	TIME [epoch: 5.7 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03823669921745603		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.03823669921745603 | validation: 0.02163283881573063]
	TIME [epoch: 5.7 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03517933767055824		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.03517933767055824 | validation: 0.020793632916603254]
	TIME [epoch: 5.71 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03402919346856436		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.03402919346856436 | validation: 0.020284304874582215]
	TIME [epoch: 5.71 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03233595950640729		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.03233595950640729 | validation: 0.02686061644082108]
	TIME [epoch: 5.75 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0363566155653451		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.0363566155653451 | validation: 0.018865937113914214]
	TIME [epoch: 5.7 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03751531790295315		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.03751531790295315 | validation: 0.02826478039755151]
	TIME [epoch: 5.72 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032398543451351375		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.032398543451351375 | validation: 0.0231699141130332]
	TIME [epoch: 5.72 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03775143777483608		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.03775143777483608 | validation: 0.021272211562929275]
	TIME [epoch: 5.72 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03786786819896672		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.03786786819896672 | validation: 0.026184190589957988]
	TIME [epoch: 5.72 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03482582887672825		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.03482582887672825 | validation: 0.02691207511375594]
	TIME [epoch: 5.75 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034977171195861245		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.034977171195861245 | validation: 0.022306311743340003]
	TIME [epoch: 5.72 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03687832204104888		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.03687832204104888 | validation: 0.01606957467346594]
	TIME [epoch: 5.72 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03371341165365367		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.03371341165365367 | validation: 0.014003023451782576]
	TIME [epoch: 5.72 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379775227406075		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.03379775227406075 | validation: 0.0247790796855925]
	TIME [epoch: 5.71 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0365299728618645		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.0365299728618645 | validation: 0.03089409667545806]
	TIME [epoch: 5.72 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03586890140695655		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.03586890140695655 | validation: 0.029936475511150088]
	TIME [epoch: 5.74 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037618507187409646		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.037618507187409646 | validation: 0.019213238776632592]
	TIME [epoch: 5.73 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03590895896927002		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.03590895896927002 | validation: 0.019743515779321773]
	TIME [epoch: 5.71 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03965360870926342		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.03965360870926342 | validation: 0.02315303826967896]
	TIME [epoch: 5.72 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03322553933567366		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.03322553933567366 | validation: 0.021890465981926815]
	TIME [epoch: 5.71 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03230970413746556		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.03230970413746556 | validation: 0.019776571732282793]
	TIME [epoch: 5.7 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03214754226389848		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.03214754226389848 | validation: 0.013836474152061334]
	TIME [epoch: 5.75 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036914175244622524		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.036914175244622524 | validation: 0.015940979992927064]
	TIME [epoch: 5.73 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0348395581708251		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.0348395581708251 | validation: 0.03406536946409093]
	TIME [epoch: 5.71 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368007548513137		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.03368007548513137 | validation: 0.0237431812935767]
	TIME [epoch: 5.71 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03184666919817103		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.03184666919817103 | validation: 0.030226492729654574]
	TIME [epoch: 5.71 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02967256928629864		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.02967256928629864 | validation: 0.026727129172402]
	TIME [epoch: 5.71 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037803464510714216		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.037803464510714216 | validation: 0.02819145801604082]
	TIME [epoch: 5.74 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03274992155722431		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.03274992155722431 | validation: 0.0270017324530043]
	TIME [epoch: 5.72 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03513303957105164		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.03513303957105164 | validation: 0.026970378687216058]
	TIME [epoch: 5.72 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03704031595860477		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.03704031595860477 | validation: 0.023775563522842314]
	TIME [epoch: 5.71 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581089084213269		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.03581089084213269 | validation: 0.01804991022964049]
	TIME [epoch: 5.72 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0347494208605945		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.0347494208605945 | validation: 0.02643003423301098]
	TIME [epoch: 5.71 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03170568193212067		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.03170568193212067 | validation: 0.024135174580261785]
	TIME [epoch: 5.75 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03448494693890867		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.03448494693890867 | validation: 0.026560006254563024]
	TIME [epoch: 5.72 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03506282477809166		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.03506282477809166 | validation: 0.024680713071617896]
	TIME [epoch: 5.7 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03555913237786773		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.03555913237786773 | validation: 0.021056811618893594]
	TIME [epoch: 5.71 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03369301558803209		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.03369301558803209 | validation: 0.020910653177319164]
	TIME [epoch: 5.7 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03380612451096014		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.03380612451096014 | validation: 0.02004242249279631]
	TIME [epoch: 5.71 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03556254146728074		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.03556254146728074 | validation: 0.022373704291605487]
	TIME [epoch: 5.73 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329799116024017		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.03329799116024017 | validation: 0.02650769283988109]
	TIME [epoch: 5.72 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032278136763474456		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.032278136763474456 | validation: 0.022191003178981494]
	TIME [epoch: 5.72 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03560134124189745		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.03560134124189745 | validation: 0.01951215534843367]
	TIME [epoch: 5.71 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033629025254998474		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.033629025254998474 | validation: 0.02239337386864056]
	TIME [epoch: 5.72 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03508789695793703		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.03508789695793703 | validation: 0.025253319525812796]
	TIME [epoch: 5.7 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034833055006407966		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.034833055006407966 | validation: 0.02266924054121059]
	TIME [epoch: 5.75 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03310504345937832		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.03310504345937832 | validation: 0.022416823948301922]
	TIME [epoch: 5.73 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03683229600732101		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.03683229600732101 | validation: 0.02568824075618362]
	TIME [epoch: 5.72 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622194170728395		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.03622194170728395 | validation: 0.024565238170232952]
	TIME [epoch: 5.72 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219256566462942		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.03219256566462942 | validation: 0.02191136850648396]
	TIME [epoch: 5.72 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034456915954786754		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.034456915954786754 | validation: 0.022246963097926172]
	TIME [epoch: 5.7 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03399710284294539		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.03399710284294539 | validation: 0.019267490379254123]
	TIME [epoch: 5.75 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569452883041108		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.03569452883041108 | validation: 0.025096895094213693]
	TIME [epoch: 5.73 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03328036633852716		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.03328036633852716 | validation: 0.017068849789672404]
	TIME [epoch: 5.72 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033162447947950285		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.033162447947950285 | validation: 0.029977311201644836]
	TIME [epoch: 5.7 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03375598924132008		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.03375598924132008 | validation: 0.01949346905502928]
	TIME [epoch: 5.71 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035239265200975596		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.035239265200975596 | validation: 0.025963999758084846]
	TIME [epoch: 5.7 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030486971928895733		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.030486971928895733 | validation: 0.02776811140169656]
	TIME [epoch: 5.75 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0315358687045421		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.0315358687045421 | validation: 0.022979334286961625]
	TIME [epoch: 5.73 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032201230095638134		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.032201230095638134 | validation: 0.030552920447105256]
	TIME [epoch: 5.7 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0354845505185419		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.0354845505185419 | validation: 0.021735755508303978]
	TIME [epoch: 5.7 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031238902019444625		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.031238902019444625 | validation: 0.023118454804631795]
	TIME [epoch: 5.72 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429924919566486		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.03429924919566486 | validation: 0.027850106666013733]
	TIME [epoch: 5.72 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033494143161425065		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.033494143161425065 | validation: 0.02224652758290797]
	TIME [epoch: 5.75 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03389568395221376		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.03389568395221376 | validation: 0.022581168903815674]
	TIME [epoch: 5.73 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030657133886327584		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.030657133886327584 | validation: 0.028250223136399084]
	TIME [epoch: 5.72 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03557166276496391		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.03557166276496391 | validation: 0.0252190992272548]
	TIME [epoch: 5.72 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033906999708883674		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.033906999708883674 | validation: 0.013885718361327338]
	TIME [epoch: 5.71 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485193085928321		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.03485193085928321 | validation: 0.020906119380659175]
	TIME [epoch: 5.72 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03262561464225172		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.03262561464225172 | validation: 0.019418657507495787]
	TIME [epoch: 5.75 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035000892812998174		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.035000892812998174 | validation: 0.02300786179321555]
	TIME [epoch: 5.73 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03207688123507447		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.03207688123507447 | validation: 0.02732353281554806]
	TIME [epoch: 5.71 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033917288044895876		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.033917288044895876 | validation: 0.026020683561836854]
	TIME [epoch: 5.72 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03754071540621016		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.03754071540621016 | validation: 0.02328245921274961]
	TIME [epoch: 5.72 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038063010221068616		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.038063010221068616 | validation: 0.023870209217884134]
	TIME [epoch: 5.71 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03688969125745271		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.03688969125745271 | validation: 0.023321743074361106]
	TIME [epoch: 5.75 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860144539900857		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.03860144539900857 | validation: 0.021036877741006328]
	TIME [epoch: 5.71 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03624637313441146		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.03624637313441146 | validation: 0.01812437223120767]
	TIME [epoch: 5.7 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03542323283930474		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.03542323283930474 | validation: 0.027466918212542935]
	TIME [epoch: 5.72 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037861297280582365		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.037861297280582365 | validation: 0.025903100668975096]
	TIME [epoch: 5.72 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035487049798326016		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.035487049798326016 | validation: 0.01774862909731345]
	TIME [epoch: 5.72 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03666225481983254		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.03666225481983254 | validation: 0.023486682025796363]
	TIME [epoch: 5.75 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03705343600136678		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.03705343600136678 | validation: 0.01597156899862321]
	TIME [epoch: 5.73 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03536875916218039		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.03536875916218039 | validation: 0.016986645918876768]
	TIME [epoch: 5.71 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566768725104916		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.03566768725104916 | validation: 0.026018102254252416]
	TIME [epoch: 5.72 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03790359864066063		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.03790359864066063 | validation: 0.02226761634655737]
	TIME [epoch: 5.71 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03685018655219871		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.03685018655219871 | validation: 0.03015444701129696]
	TIME [epoch: 5.72 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037458040039207385		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.037458040039207385 | validation: 0.03202012267060872]
	TIME [epoch: 5.74 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03867904455806752		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.03867904455806752 | validation: 0.018512371527025995]
	TIME [epoch: 5.72 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429954940482238		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.03429954940482238 | validation: 0.0195276695923495]
	TIME [epoch: 5.72 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035356574189968376		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.035356574189968376 | validation: 0.02459543178826145]
	TIME [epoch: 5.72 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03689186413222481		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.03689186413222481 | validation: 0.024812331740154923]
	TIME [epoch: 5.72 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030324675951856037		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.030324675951856037 | validation: 0.027906049239980614]
	TIME [epoch: 5.72 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03574816624617229		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.03574816624617229 | validation: 0.02844473537316761]
	TIME [epoch: 5.74 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03525356256987097		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.03525356256987097 | validation: 0.018770215985842477]
	TIME [epoch: 5.73 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616312658398868		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.03616312658398868 | validation: 0.03214391913314826]
	TIME [epoch: 5.72 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03402784985727941		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.03402784985727941 | validation: 0.011449706312430032]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_1743.pth
	Model improved!!!
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219575030854792		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.03219575030854792 | validation: 0.03265073784618863]
	TIME [epoch: 5.72 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03931200262289243		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.03931200262289243 | validation: 0.016132396878015792]
	TIME [epoch: 5.72 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037458942419978644		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.037458942419978644 | validation: 0.020532934711730868]
	TIME [epoch: 5.75 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032548626774267064		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.032548626774267064 | validation: 0.01790009865173285]
	TIME [epoch: 5.72 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034701246012623636		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.034701246012623636 | validation: 0.02693223296606738]
	TIME [epoch: 5.72 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03114744840420644		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.03114744840420644 | validation: 0.02587609962676992]
	TIME [epoch: 5.72 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296437741126311		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.03296437741126311 | validation: 0.017457035154442607]
	TIME [epoch: 5.72 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566149382775988		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.03566149382775988 | validation: 0.02637222406059712]
	TIME [epoch: 5.72 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0358728106212507		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.0358728106212507 | validation: 0.020062396574951086]
	TIME [epoch: 5.74 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747978606760739		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.03747978606760739 | validation: 0.02550194733667502]
	TIME [epoch: 5.72 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03530103380600465		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.03530103380600465 | validation: 0.02643125560908417]
	TIME [epoch: 5.7 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03869275532690578		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.03869275532690578 | validation: 0.03204263489530024]
	TIME [epoch: 5.72 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03523852687675044		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.03523852687675044 | validation: 0.024173187248784637]
	TIME [epoch: 5.71 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034352335290515505		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.034352335290515505 | validation: 0.0297725698268086]
	TIME [epoch: 5.72 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0339972244193413		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.0339972244193413 | validation: 0.025465699675759536]
	TIME [epoch: 5.74 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569137458686117		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.03569137458686117 | validation: 0.027974678646652255]
	TIME [epoch: 5.72 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036883699817022636		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.036883699817022636 | validation: 0.028146552290154617]
	TIME [epoch: 5.72 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03654728884981074		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.03654728884981074 | validation: 0.02737252881424972]
	TIME [epoch: 5.72 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03349070574502996		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.03349070574502996 | validation: 0.02925794237615165]
	TIME [epoch: 5.71 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03560009198710858		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.03560009198710858 | validation: 0.025184900559455096]
	TIME [epoch: 5.7 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039054395299218045		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.039054395299218045 | validation: 0.03093650935504626]
	TIME [epoch: 5.74 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033778652023883915		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.033778652023883915 | validation: 0.02199174636252667]
	TIME [epoch: 5.72 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03664452833435684		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.03664452833435684 | validation: 0.02393818545749125]
	TIME [epoch: 5.72 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03551131345050339		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.03551131345050339 | validation: 0.02897282861727308]
	TIME [epoch: 5.72 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03806803819854594		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.03806803819854594 | validation: 0.023442365171334835]
	TIME [epoch: 5.72 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0373970418063639		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.0373970418063639 | validation: 0.026745965342493686]
	TIME [epoch: 5.72 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038167505493139145		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.038167505493139145 | validation: 0.02832058387192932]
	TIME [epoch: 5.75 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03417209308338795		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.03417209308338795 | validation: 0.017553035109744316]
	TIME [epoch: 5.72 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038658973151131225		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.038658973151131225 | validation: 0.021805139050556185]
	TIME [epoch: 5.72 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0343826716962478		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.0343826716962478 | validation: 0.01588592503559489]
	TIME [epoch: 5.72 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03489906770960572		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.03489906770960572 | validation: 0.02820315143209639]
	TIME [epoch: 5.7 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033123565128451014		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.033123565128451014 | validation: 0.01946401586096969]
	TIME [epoch: 5.7 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03507097828012039		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.03507097828012039 | validation: 0.0234611663515767]
	TIME [epoch: 5.74 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03715661035375611		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.03715661035375611 | validation: 0.02927453351022243]
	TIME [epoch: 5.71 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0343626704655224		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.0343626704655224 | validation: 0.02610970883147365]
	TIME [epoch: 5.7 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03757918297957785		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.03757918297957785 | validation: 0.024883947428545394]
	TIME [epoch: 5.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03641959336264795		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.03641959336264795 | validation: 0.02779703788581437]
	TIME [epoch: 5.72 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03593405855533494		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.03593405855533494 | validation: 0.01951300075669461]
	TIME [epoch: 5.7 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03541667853412328		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.03541667853412328 | validation: 0.02275946943382261]
	TIME [epoch: 5.75 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204589277230522		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.03204589277230522 | validation: 0.02607290769726724]
	TIME [epoch: 5.71 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036528023982255214		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.036528023982255214 | validation: 0.027713081448165325]
	TIME [epoch: 5.72 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035180272549195715		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.035180272549195715 | validation: 0.02847028199771531]
	TIME [epoch: 5.72 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03339465273032835		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.03339465273032835 | validation: 0.02896373992600208]
	TIME [epoch: 5.71 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035902316975598016		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.035902316975598016 | validation: 0.02476064107022699]
	TIME [epoch: 5.72 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03361460802571894		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.03361460802571894 | validation: 0.03229395483472209]
	TIME [epoch: 5.74 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034045143263229945		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.034045143263229945 | validation: 0.021343691207389305]
	TIME [epoch: 5.72 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03784723527210712		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.03784723527210712 | validation: 0.018905696506884177]
	TIME [epoch: 5.72 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0360432649364775		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.0360432649364775 | validation: 0.021213939332626736]
	TIME [epoch: 5.72 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03708821315676055		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.03708821315676055 | validation: 0.02048918029265308]
	TIME [epoch: 5.72 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03751973827776449		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.03751973827776449 | validation: 0.027139960351109715]
	TIME [epoch: 5.7 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03494258936065524		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.03494258936065524 | validation: 0.01861837167120394]
	TIME [epoch: 5.75 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035115084072575194		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.035115084072575194 | validation: 0.026890426420108544]
	TIME [epoch: 5.71 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03316285687231173		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.03316285687231173 | validation: 0.02358513212863022]
	TIME [epoch: 5.72 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03338950525172627		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.03338950525172627 | validation: 0.025768761299274336]
	TIME [epoch: 5.71 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032981240953501106		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.032981240953501106 | validation: 0.027341812659714644]
	TIME [epoch: 5.71 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031905167398338465		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.031905167398338465 | validation: 0.02107593147137627]
	TIME [epoch: 5.7 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03387317840832896		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.03387317840832896 | validation: 0.022179095086104505]
	TIME [epoch: 5.75 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03236807352072345		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.03236807352072345 | validation: 0.03182389485965272]
	TIME [epoch: 5.7 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033527215139072586		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.033527215139072586 | validation: 0.03452283156093811]
	TIME [epoch: 5.71 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313161074410957		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.03313161074410957 | validation: 0.024453907606904895]
	TIME [epoch: 5.71 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035572928944197536		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.035572928944197536 | validation: 0.020161242475322107]
	TIME [epoch: 5.71 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034113782441507735		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.034113782441507735 | validation: 0.010367116920014017]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240309_135631/states/model_tr_study2_1805.pth
	Model improved!!!
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03658285433745009		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.03658285433745009 | validation: 0.020644515807168324]
	TIME [epoch: 5.75 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03518028312727261		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.03518028312727261 | validation: 0.021144807490622055]
	TIME [epoch: 5.7 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035391922835624666		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.035391922835624666 | validation: 0.01826626338073466]
	TIME [epoch: 5.77 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03693460960623572		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.03693460960623572 | validation: 0.01895367791006999]
	TIME [epoch: 5.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0350568507004473		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.0350568507004473 | validation: 0.020715518011300955]
	TIME [epoch: 5.7 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03353098567148929		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.03353098567148929 | validation: 0.026049085713657744]
	TIME [epoch: 5.71 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357143798793718		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.0357143798793718 | validation: 0.02649995214088019]
	TIME [epoch: 5.75 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621042988049002		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.03621042988049002 | validation: 0.02671673534959588]
	TIME [epoch: 5.71 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036915865013235474		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.036915865013235474 | validation: 0.02372463409150064]
	TIME [epoch: 5.71 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029380044150794794		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.029380044150794794 | validation: 0.019665072868359976]
	TIME [epoch: 5.71 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03494879942758941		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.03494879942758941 | validation: 0.0280823846558424]
	TIME [epoch: 5.72 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034695161161215		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.034695161161215 | validation: 0.02413803976046566]
	TIME [epoch: 5.72 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037385574005681356		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.037385574005681356 | validation: 0.02699735287896817]
	TIME [epoch: 5.75 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03619319392895299		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.03619319392895299 | validation: 0.026777520309621022]
	TIME [epoch: 5.7 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032836640941315456		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.032836640941315456 | validation: 0.018429903194599]
	TIME [epoch: 5.71 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03487711436278238		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.03487711436278238 | validation: 0.031695338653327416]
	TIME [epoch: 5.7 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03708285391916406		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.03708285391916406 | validation: 0.023965244164834382]
	TIME [epoch: 5.7 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03624528414675658		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.03624528414675658 | validation: 0.02889369894535319]
	TIME [epoch: 5.71 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03431749718086248		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.03431749718086248 | validation: 0.02544657486606975]
	TIME [epoch: 5.74 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033997684155695075		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.033997684155695075 | validation: 0.0151228379563701]
	TIME [epoch: 5.7 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035968207521608314		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.035968207521608314 | validation: 0.023392128296156733]
	TIME [epoch: 5.71 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03135816086036703		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.03135816086036703 | validation: 0.016528006041472067]
	TIME [epoch: 5.7 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034034137073815286		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.034034137073815286 | validation: 0.023756658598640356]
	TIME [epoch: 5.71 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037331028693822516		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.037331028693822516 | validation: 0.016467685936257758]
	TIME [epoch: 5.7 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035871827345993736		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.035871827345993736 | validation: 0.01979084594760286]
	TIME [epoch: 5.74 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414178822202473		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.03414178822202473 | validation: 0.0251647063121969]
	TIME [epoch: 5.72 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03597279477382198		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.03597279477382198 | validation: 0.028100936978783873]
	TIME [epoch: 5.7 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03713471105616771		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.03713471105616771 | validation: 0.03656479256259993]
	TIME [epoch: 5.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03260387671603279		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.03260387671603279 | validation: 0.025839123121998046]
	TIME [epoch: 5.7 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033739063654010304		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.033739063654010304 | validation: 0.014771483493297774]
	TIME [epoch: 5.72 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033739264819127195		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.033739264819127195 | validation: 0.02649816700155787]
	TIME [epoch: 5.74 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031764069032377475		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.031764069032377475 | validation: 0.024984795677451998]
	TIME [epoch: 5.72 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03391649710891804		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.03391649710891804 | validation: 0.0265099360711586]
	TIME [epoch: 5.7 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03440989770331611		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.03440989770331611 | validation: 0.022135968717016504]
	TIME [epoch: 5.72 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0346456143275478		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.0346456143275478 | validation: 0.03026503963208055]
	TIME [epoch: 5.7 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034345654005464576		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.034345654005464576 | validation: 0.02757887913887398]
	TIME [epoch: 5.7 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032697396028225446		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.032697396028225446 | validation: 0.028695572618412865]
	TIME [epoch: 5.74 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03294419869748401		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.03294419869748401 | validation: 0.028334805938138415]
	TIME [epoch: 5.7 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477367184350255		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.03477367184350255 | validation: 0.017342263223093672]
	TIME [epoch: 5.71 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03610389864831903		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.03610389864831903 | validation: 0.033255265358870405]
	TIME [epoch: 5.7 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03396518740174056		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.03396518740174056 | validation: 0.02913533447043776]
	TIME [epoch: 5.7 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03327002007625003		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.03327002007625003 | validation: 0.015320222906644842]
	TIME [epoch: 5.71 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033912182834861096		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.033912182834861096 | validation: 0.033023896073925106]
	TIME [epoch: 5.74 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034893823578365624		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.034893823578365624 | validation: 0.031154192754629734]
	TIME [epoch: 5.71 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528840885755799		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.03528840885755799 | validation: 0.02802084369533012]
	TIME [epoch: 5.7 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035504684289877006		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.035504684289877006 | validation: 0.028167103544044374]
	TIME [epoch: 5.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03524617334331401		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.03524617334331401 | validation: 0.027220473535463467]
	TIME [epoch: 5.71 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03596731597642215		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.03596731597642215 | validation: 0.02544330896039676]
	TIME [epoch: 5.72 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033662098359815845		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.033662098359815845 | validation: 0.026508144838322648]
	TIME [epoch: 5.74 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035707651185940666		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.035707651185940666 | validation: 0.020505068755644517]
	TIME [epoch: 5.72 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414634528483717		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.03414634528483717 | validation: 0.02545308684090597]
	TIME [epoch: 5.71 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566012164098859		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.03566012164098859 | validation: 0.016146168259995004]
	TIME [epoch: 5.72 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03685970977852757		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.03685970977852757 | validation: 0.022701347407501352]
	TIME [epoch: 5.71 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035258476311016834		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.035258476311016834 | validation: 0.022804812125440065]
	TIME [epoch: 5.7 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03596157149648074		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.03596157149648074 | validation: 0.027143891156734438]
	TIME [epoch: 5.75 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03623436573620923		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.03623436573620923 | validation: 0.02832386605412871]
	TIME [epoch: 5.7 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03518005258006873		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.03518005258006873 | validation: 0.031880127955875824]
	TIME [epoch: 5.7 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035558689311352476		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.035558689311352476 | validation: 0.027206430895811998]
	TIME [epoch: 5.7 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034994377799369605		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.034994377799369605 | validation: 0.021532212518231578]
	TIME [epoch: 5.69 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036093109993782825		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.036093109993782825 | validation: 0.029558778847817404]
	TIME [epoch: 5.7 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031829840405759		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.031829840405759 | validation: 0.027806518765432626]
	TIME [epoch: 5.73 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03543360038051909		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.03543360038051909 | validation: 0.03060175517650465]
	TIME [epoch: 5.7 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035418031357366854		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.035418031357366854 | validation: 0.02007444048150158]
	TIME [epoch: 5.7 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03364742609757805		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.03364742609757805 | validation: 0.03024793067576313]
	TIME [epoch: 5.71 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035836371080933856		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.035836371080933856 | validation: 0.02719912451936695]
	TIME [epoch: 5.7 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03948161315662506		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.03948161315662506 | validation: 0.03071177233801352]
	TIME [epoch: 5.7 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037787611022215783		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.037787611022215783 | validation: 0.02475097978184984]
	TIME [epoch: 5.75 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037714436515526584		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.037714436515526584 | validation: 0.024775723266108995]
	TIME [epoch: 5.71 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03614322170048349		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.03614322170048349 | validation: 0.021660994677485345]
	TIME [epoch: 5.7 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03556336825776001		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.03556336825776001 | validation: 0.024281767000930068]
	TIME [epoch: 5.7 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03852642043756317		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.03852642043756317 | validation: 0.020731657789685408]
	TIME [epoch: 5.71 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037486612004935256		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.037486612004935256 | validation: 0.02563071826352027]
	TIME [epoch: 5.7 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03867949716796701		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.03867949716796701 | validation: 0.029765110938814985]
	TIME [epoch: 5.75 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03845520493483398		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.03845520493483398 | validation: 0.02443524023061223]
	TIME [epoch: 5.71 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035931148144082645		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.035931148144082645 | validation: 0.023778530757650376]
	TIME [epoch: 5.71 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03603161605929426		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.03603161605929426 | validation: 0.02305626250505581]
	TIME [epoch: 5.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033175778225266024		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.033175778225266024 | validation: 0.02299535678184792]
	TIME [epoch: 5.71 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03988224076345319		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.03988224076345319 | validation: 0.0202271005848241]
	TIME [epoch: 5.7 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03502136654523648		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.03502136654523648 | validation: 0.02197372975084769]
	TIME [epoch: 5.73 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033208794343885295		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.033208794343885295 | validation: 0.028534156728147755]
	TIME [epoch: 5.71 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03825664469052244		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.03825664469052244 | validation: 0.03221823570772545]
	TIME [epoch: 5.7 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03619752534825944		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.03619752534825944 | validation: 0.0184234022605624]
	TIME [epoch: 5.71 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037631215134265525		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.037631215134265525 | validation: 0.031998366280663826]
	TIME [epoch: 5.71 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035534407453853875		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.035534407453853875 | validation: 0.02120688478277589]
	TIME [epoch: 5.71 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03214221962950587		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.03214221962950587 | validation: 0.013761533279211573]
	TIME [epoch: 5.75 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03716389681220681		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.03716389681220681 | validation: 0.03649097045757496]
	TIME [epoch: 5.73 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03567301542143867		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.03567301542143867 | validation: 0.023161005898760884]
	TIME [epoch: 5.71 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335137248392034		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.0335137248392034 | validation: 0.02447169653309826]
	TIME [epoch: 5.7 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03789979142156577		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.03789979142156577 | validation: 0.03413444294959697]
	TIME [epoch: 5.7 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032005141373052985		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.032005141373052985 | validation: 0.023423132086717063]
	TIME [epoch: 5.7 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03681272484919469		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.03681272484919469 | validation: 0.020412924106785822]
	TIME [epoch: 5.73 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03686743392925399		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.03686743392925399 | validation: 0.03258040770350293]
	TIME [epoch: 5.7 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03605341178270746		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.03605341178270746 | validation: 0.019837153450113103]
	TIME [epoch: 5.72 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03716213632058419		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.03716213632058419 | validation: 0.02523722385754372]
	TIME [epoch: 5.7 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429688715414247		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.03429688715414247 | validation: 0.033188729118750225]
	TIME [epoch: 5.71 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03608795187148695		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.03608795187148695 | validation: 0.02155943574577173]
	TIME [epoch: 5.7 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036399988928709624		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.036399988928709624 | validation: 0.01981142426366547]
	TIME [epoch: 5.75 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03610173305780993		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.03610173305780993 | validation: 0.027785928408994458]
	TIME [epoch: 5.71 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0384399431850698		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.0384399431850698 | validation: 0.01752578656807189]
	TIME [epoch: 5.71 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03351488895587164		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.03351488895587164 | validation: 0.02203698870913465]
	TIME [epoch: 5.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03309034881853079		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.03309034881853079 | validation: 0.023858193156312848]
	TIME [epoch: 5.71 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032652354954568995		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.032652354954568995 | validation: 0.027600187697835735]
	TIME [epoch: 5.7 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03325520731734971		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.03325520731734971 | validation: 0.016070245083206577]
	TIME [epoch: 5.73 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740868293145474		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.03740868293145474 | validation: 0.021339631906146846]
	TIME [epoch: 5.73 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035180985942340315		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.035180985942340315 | validation: 0.03430311054476082]
	TIME [epoch: 5.7 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738261550533429		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.03738261550533429 | validation: 0.025139206937196876]
	TIME [epoch: 5.71 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03260839688567868		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.03260839688567868 | validation: 0.016775100493577454]
	TIME [epoch: 5.71 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03509574591757343		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.03509574591757343 | validation: 0.02644518190695974]
	TIME [epoch: 5.71 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034986093805240995		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.034986093805240995 | validation: 0.019698048795888812]
	TIME [epoch: 5.74 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03525141863768545		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.03525141863768545 | validation: 0.022845307653223245]
	TIME [epoch: 5.72 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035930982875241796		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.035930982875241796 | validation: 0.026357576211434686]
	TIME [epoch: 5.72 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03575624378692931		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.03575624378692931 | validation: 0.03087085381819664]
	TIME [epoch: 5.7 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035248778495774874		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.035248778495774874 | validation: 0.028956909678713887]
	TIME [epoch: 5.7 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02972565936946618		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.02972565936946618 | validation: 0.02936112365424909]
	TIME [epoch: 5.7 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037405125200254345		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.037405125200254345 | validation: 0.026527273668105988]
	TIME [epoch: 5.73 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03494780334719762		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.03494780334719762 | validation: 0.020519602190577954]
	TIME [epoch: 5.72 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03398324170779512		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.03398324170779512 | validation: 0.020595868081205754]
	TIME [epoch: 5.7 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035849446337390393		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.035849446337390393 | validation: 0.02005267114928751]
	TIME [epoch: 5.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032265262183223176		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.032265262183223176 | validation: 0.030729413445419285]
	TIME [epoch: 5.72 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0347716317679181		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.0347716317679181 | validation: 0.02909150811469041]
	TIME [epoch: 5.7 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03594261191895686		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.03594261191895686 | validation: 0.016579650708893345]
	TIME [epoch: 5.73 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036200004110382		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.036200004110382 | validation: 0.02265705779688338]
	TIME [epoch: 5.71 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03519941522920754		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.03519941522920754 | validation: 0.01592253517706819]
	TIME [epoch: 5.71 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03542789416181269		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.03542789416181269 | validation: 0.020316004632275973]
	TIME [epoch: 5.7 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03384527733760839		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.03384527733760839 | validation: 0.02036828905329495]
	TIME [epoch: 5.7 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486584363506332		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.03486584363506332 | validation: 0.02161443536715141]
	TIME [epoch: 5.7 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03349497994921717		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.03349497994921717 | validation: 0.028315880598474275]
	TIME [epoch: 5.73 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032045890756354216		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.032045890756354216 | validation: 0.014722821222222966]
	TIME [epoch: 5.71 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033112848128613044		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.033112848128613044 | validation: 0.02476616384311715]
	TIME [epoch: 5.71 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03311709030468735		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.03311709030468735 | validation: 0.018026326295335276]
	TIME [epoch: 5.71 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03351291417606823		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.03351291417606823 | validation: 0.023272652955721]
	TIME [epoch: 5.71 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033885965053982406		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.033885965053982406 | validation: 0.030805816474428784]
	TIME [epoch: 5.7 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379406581233387		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.03379406581233387 | validation: 0.02471104670413867]
	TIME [epoch: 5.74 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033452868647059916		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.033452868647059916 | validation: 0.021354786375516594]
	TIME [epoch: 5.71 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03492500577471602		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.03492500577471602 | validation: 0.024164310332735348]
	TIME [epoch: 5.71 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03600260995427364		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.03600260995427364 | validation: 0.025091113149899386]
	TIME [epoch: 5.72 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03551080845166431		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.03551080845166431 | validation: 0.026641816801304143]
	TIME [epoch: 5.71 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03371200498843127		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.03371200498843127 | validation: 0.02911477182110321]
	TIME [epoch: 5.71 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034220171484135635		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.034220171484135635 | validation: 0.026914388074636177]
	TIME [epoch: 5.75 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03417694565673525		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.03417694565673525 | validation: 0.028051379257262976]
	TIME [epoch: 5.72 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035339984865300475		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.035339984865300475 | validation: 0.023567948531088918]
	TIME [epoch: 5.7 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03653618359260358		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.03653618359260358 | validation: 0.028397874865251138]
	TIME [epoch: 5.7 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0352891024397439		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.0352891024397439 | validation: 0.0293788501232192]
	TIME [epoch: 5.7 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03422003382772408		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.03422003382772408 | validation: 0.017767826415561405]
	TIME [epoch: 5.7 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03765394567693167		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.03765394567693167 | validation: 0.02253725341208332]
	TIME [epoch: 5.73 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034039703674201546		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.034039703674201546 | validation: 0.028608533674076623]
	TIME [epoch: 5.71 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03916215678508329		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.03916215678508329 | validation: 0.023315793459275605]
	TIME [epoch: 5.7 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03192284257228235		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.03192284257228235 | validation: 0.018845105962313896]
	TIME [epoch: 5.7 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037277645183418015		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.037277645183418015 | validation: 0.023818776943796142]
	TIME [epoch: 5.7 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035358533164129693		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.035358533164129693 | validation: 0.028322366441732014]
	TIME [epoch: 5.71 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03617633906155642		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.03617633906155642 | validation: 0.027366141410208576]
	TIME [epoch: 5.73 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03618780139805348		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.03618780139805348 | validation: 0.021055490506103492]
	TIME [epoch: 5.73 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430694201304799		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.03430694201304799 | validation: 0.015004512039683839]
	TIME [epoch: 5.72 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03377856086139559		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.03377856086139559 | validation: 0.023318124403832238]
	TIME [epoch: 5.7 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0353413063657277		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.0353413063657277 | validation: 0.021202709663009158]
	TIME [epoch: 5.7 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03311545140668574		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.03311545140668574 | validation: 0.021311040428325496]
	TIME [epoch: 5.7 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03406171608945972		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.03406171608945972 | validation: 0.029111313308107834]
	TIME [epoch: 5.73 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035629185108251804		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.035629185108251804 | validation: 0.029595251194329073]
	TIME [epoch: 5.72 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035311565793143		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.035311565793143 | validation: 0.025706864387112446]
	TIME [epoch: 5.7 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03501683006192231		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.03501683006192231 | validation: 0.01412425712346443]
	TIME [epoch: 5.71 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03575636069883498		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.03575636069883498 | validation: 0.02866196136664617]
	TIME [epoch: 5.7 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036781976083279544		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.036781976083279544 | validation: 0.024675728855671385]
	TIME [epoch: 5.7 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03331556027515761		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.03331556027515761 | validation: 0.021519095915341766]
	TIME [epoch: 5.75 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029599509645249163		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.029599509645249163 | validation: 0.023545413514171446]
	TIME [epoch: 5.71 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03231148079570496		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.03231148079570496 | validation: 0.015880817982368574]
	TIME [epoch: 5.72 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03286857840663633		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.03286857840663633 | validation: 0.015124198935109258]
	TIME [epoch: 5.7 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033849877966520635		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.033849877966520635 | validation: 0.021687121932367884]
	TIME [epoch: 5.7 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03295001758238133		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.03295001758238133 | validation: 0.020669561165763597]
	TIME [epoch: 5.7 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031466593494832426		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.031466593494832426 | validation: 0.020159707635999242]
	TIME [epoch: 5.73 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034006525125849174		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.034006525125849174 | validation: 0.027003195316304095]
	TIME [epoch: 5.71 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039222399090354625		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.039222399090354625 | validation: 0.03534493061478836]
	TIME [epoch: 5.7 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03734673155826374		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.03734673155826374 | validation: 0.01829734375267198]
	TIME [epoch: 5.7 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03483356226198038		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.03483356226198038 | validation: 0.023689636998396463]
	TIME [epoch: 5.72 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031179962308362286		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.031179962308362286 | validation: 0.027067050282231192]
	TIME [epoch: 5.72 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035421011772556		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.035421011772556 | validation: 0.020585620853617873]
	TIME [epoch: 5.74 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03380246312463444		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.03380246312463444 | validation: 0.025258851518435276]
	TIME [epoch: 5.71 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429236620642228		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.03429236620642228 | validation: 0.02581325663456053]
	TIME [epoch: 5.71 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036126908739553355		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.036126908739553355 | validation: 0.02765495652426549]
	TIME [epoch: 5.72 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0296487406042604		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.0296487406042604 | validation: 0.028414002911667523]
	TIME [epoch: 5.7 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03521967391966211		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.03521967391966211 | validation: 0.020433662880708463]
	TIME [epoch: 5.7 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03535048477368981		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.03535048477368981 | validation: 0.02435472743382431]
	TIME [epoch: 5.74 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03520978952138678		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.03520978952138678 | validation: 0.01444424645479658]
	TIME [epoch: 5.72 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031067517438316056		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.031067517438316056 | validation: 0.022427182082199477]
	TIME [epoch: 5.71 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03530057585035881		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.03530057585035881 | validation: 0.02320043396365856]
	TIME [epoch: 5.7 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03353890172754058		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.03353890172754058 | validation: 0.02056554986071116]
	TIME [epoch: 5.71 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033877783603924586		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.033877783603924586 | validation: 0.01655668230507827]
	TIME [epoch: 5.71 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03392957691123388		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.03392957691123388 | validation: 0.02752915463103092]
	TIME [epoch: 5.74 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289504026147591		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.03289504026147591 | validation: 0.0298402941281691]
	TIME [epoch: 5.7 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0341100075722214		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.0341100075722214 | validation: 0.028208886792158012]
	TIME [epoch: 5.71 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471473842373536		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.03471473842373536 | validation: 0.02144718981532464]
	TIME [epoch: 5.71 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031331343804400516		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.031331343804400516 | validation: 0.01997581599418779]
	TIME [epoch: 5.71 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03694433775247745		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.03694433775247745 | validation: 0.02566135203469605]
	TIME [epoch: 5.71 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032172027047654504		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.032172027047654504 | validation: 0.016960854406258864]
	TIME [epoch: 5.74 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031975934430217054		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.031975934430217054 | validation: 0.023818066467763077]
	TIME [epoch: 5.72 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03640731750832856		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.03640731750832856 | validation: 0.02318049226783178]
	TIME [epoch: 5.7 sec]
Finished training in 11675.442 seconds.
