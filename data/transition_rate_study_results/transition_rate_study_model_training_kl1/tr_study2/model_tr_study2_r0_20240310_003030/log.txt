Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r0', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2579688782

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.4513973978807035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.4513973978807035 | validation: 6.69205249518659]
	TIME [epoch: 94.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.334522367831746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.334522367831746 | validation: 5.7415086584505755]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.661404108479994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.661404108479994 | validation: 4.905443337791316]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.293645056669434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.293645056669434 | validation: 5.115419286419141]
	TIME [epoch: 5.72 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489307489818738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.489307489818738 | validation: 4.641489735077954]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.730626460402013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.730626460402013 | validation: 3.5148141161475976]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.269547354449129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.269547354449129 | validation: 3.0723279782602764]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.12163268532925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.12163268532925 | validation: 3.0307141470522345]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9189774435039575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9189774435039575 | validation: 3.182107292287461]
	TIME [epoch: 5.74 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2352779089387127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2352779089387127 | validation: 3.2217964263839787]
	TIME [epoch: 5.72 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.773823576066131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.773823576066131 | validation: 2.8324839359687672]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.557025287610668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.557025287610668 | validation: 2.556129456105787]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.529250116043232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.529250116043232 | validation: 2.4215015762405283]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333481327220064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.333481327220064 | validation: 2.283691895804774]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1883056368331886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1883056368331886 | validation: 2.8333521120081278]
	TIME [epoch: 5.74 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3340782235703763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3340782235703763 | validation: 2.251805355270536]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9905775887642014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9905775887642014 | validation: 2.3262510959811]
	TIME [epoch: 5.72 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.102200059077909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.102200059077909 | validation: 2.372612237608161]
	TIME [epoch: 5.72 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.964486114956816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.964486114956816 | validation: 2.0531748869734567]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7390575223233316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7390575223233316 | validation: 1.9300890788925997]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5929227028715176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5929227028715176 | validation: 2.606794128628174]
	TIME [epoch: 5.76 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.940269105070829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.940269105070829 | validation: 1.7413642484756302]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4587238159520937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4587238159520937 | validation: 2.3661762890999403]
	TIME [epoch: 5.72 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7270108899067724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7270108899067724 | validation: 1.8322835910286808]
	TIME [epoch: 5.72 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4837920889009326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4837920889009326 | validation: 1.387012058433284]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.325035433093863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.325035433093863 | validation: 1.339646694517039]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4297258170565468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4297258170565468 | validation: 1.8891649105443538]
	TIME [epoch: 5.74 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.452180246334796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.452180246334796 | validation: 1.286278244011027]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5007647413962415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5007647413962415 | validation: 1.7259407245316232]
	TIME [epoch: 5.72 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2760812279802005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2760812279802005 | validation: 1.8726850365205232]
	TIME [epoch: 5.72 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5012799373531114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5012799373531114 | validation: 1.3001312474311204]
	TIME [epoch: 5.72 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.407677058467966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.407677058467966 | validation: 1.4426153066840004]
	TIME [epoch: 5.71 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1740181205072278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1740181205072278 | validation: 1.3031967256768757]
	TIME [epoch: 5.71 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2329681488449662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2329681488449662 | validation: 1.2120200195687674]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3371918139092567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3371918139092567 | validation: 1.0610592858634713]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228489947073442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.228489947073442 | validation: 1.425362256763479]
	TIME [epoch: 5.73 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2402820152411143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2402820152411143 | validation: 1.0914841376339397]
	TIME [epoch: 5.73 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.069133378491368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.069133378491368 | validation: 1.10069800004139]
	TIME [epoch: 5.72 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3312458980060746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3312458980060746 | validation: 1.561001467160025]
	TIME [epoch: 5.72 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2750621495584313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2750621495584313 | validation: 1.0295639483786103]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8304587917465656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8304587917465656 | validation: 1.2439522698856207]
	TIME [epoch: 5.77 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.396149290389912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.396149290389912 | validation: 1.295860263658019]
	TIME [epoch: 5.73 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2730330823744571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2730330823744571 | validation: 1.3601970126133864]
	TIME [epoch: 5.73 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0967778649349227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0967778649349227 | validation: 3.1712251877042226]
	TIME [epoch: 5.73 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.510313441967832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.510313441967832 | validation: 0.9510804733155552]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9650552436710202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9650552436710202 | validation: 0.6781212030877015]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9282494376750066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9282494376750066 | validation: 1.3211262536605966]
	TIME [epoch: 5.77 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0637450656472067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0637450656472067 | validation: 0.6281921558530318]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1164541528315939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1164541528315939 | validation: 1.4309649348965934]
	TIME [epoch: 5.73 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9257676231881422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9257676231881422 | validation: 1.2256356195099405]
	TIME [epoch: 5.72 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9259366711869857		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.9259366711869857 | validation: 0.5072595988249957]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0193787682928361		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.0193787682928361 | validation: 1.197933999398868]
	TIME [epoch: 5.72 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6774127313804907		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.6774127313804907 | validation: 0.6277860523293642]
	TIME [epoch: 5.74 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9356080084098846		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.9356080084098846 | validation: 1.1691064944642735]
	TIME [epoch: 5.76 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8562826551342384		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.8562826551342384 | validation: 0.6305806344755571]
	TIME [epoch: 5.72 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6533143642874826		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.6533143642874826 | validation: 0.5547511142344544]
	TIME [epoch: 5.72 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271521958007956		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.7271521958007956 | validation: 0.9551162242312502]
	TIME [epoch: 5.71 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.180887265321317		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.180887265321317 | validation: 1.0669269968210353]
	TIME [epoch: 5.72 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.759798292753201		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.759798292753201 | validation: 1.0417652485855704]
	TIME [epoch: 5.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7549824113061897		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.7549824113061897 | validation: 0.42844935249809313]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582400117894466		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.582400117894466 | validation: 1.0101642438574285]
	TIME [epoch: 5.73 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6207585386839068		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.6207585386839068 | validation: 0.7849235739505882]
	TIME [epoch: 5.71 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7756697435456773		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.7756697435456773 | validation: 0.786675331666373]
	TIME [epoch: 5.71 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5620081993759636		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.5620081993759636 | validation: 0.772870571354703]
	TIME [epoch: 5.71 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697499961048131		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.6697499961048131 | validation: 0.5657962723345679]
	TIME [epoch: 5.71 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6756875342149724		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.6756875342149724 | validation: 0.5129099367456502]
	TIME [epoch: 5.72 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236348169087459		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.5236348169087459 | validation: 0.6066127291840178]
	TIME [epoch: 5.75 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7461981940059693		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.7461981940059693 | validation: 0.5923546095730065]
	TIME [epoch: 5.71 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.697031775299253		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.697031775299253 | validation: 0.5993941045064244]
	TIME [epoch: 5.71 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5849861736036305		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.5849861736036305 | validation: 0.9259837656090935]
	TIME [epoch: 5.71 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.825587192543795		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.825587192543795 | validation: 0.5381681444949976]
	TIME [epoch: 5.71 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5870133227019926		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.5870133227019926 | validation: 0.3922781110793252]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6289874729809313		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.6289874729809313 | validation: 0.35686978965369487]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844716150316852		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.3844716150316852 | validation: 0.4757193634361386]
	TIME [epoch: 5.71 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7362657645768329		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.7362657645768329 | validation: 0.38701424773022697]
	TIME [epoch: 5.72 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5400828119354726		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.5400828119354726 | validation: 0.3195126336139507]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6466540976840253		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.6466540976840253 | validation: 0.5843858927316632]
	TIME [epoch: 5.71 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5469359893991389		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.5469359893991389 | validation: 0.8363298083341479]
	TIME [epoch: 5.71 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7072531592940632		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7072531592940632 | validation: 0.40002143296938614]
	TIME [epoch: 5.74 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5413353884460097		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.5413353884460097 | validation: 0.6148812835789907]
	TIME [epoch: 5.73 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5682134142414139		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5682134142414139 | validation: 0.384248251932489]
	TIME [epoch: 5.71 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6521083716032802		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6521083716032802 | validation: 0.3352621066731946]
	TIME [epoch: 5.72 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6505433598267787		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.6505433598267787 | validation: 0.540811992627608]
	TIME [epoch: 5.71 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744890506250251		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.5744890506250251 | validation: 0.5269384488600661]
	TIME [epoch: 5.72 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45342639544680374		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.45342639544680374 | validation: 0.31153522498345093]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49512553913347285		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.49512553913347285 | validation: 1.0177898376559844]
	TIME [epoch: 5.77 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5627000774158692		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.5627000774158692 | validation: 0.5031633175737049]
	TIME [epoch: 5.73 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5794934844982762		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.5794934844982762 | validation: 0.47922843264872184]
	TIME [epoch: 5.73 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047635981558981		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.5047635981558981 | validation: 0.8681452989461486]
	TIME [epoch: 5.73 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4668917780269285		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.4668917780269285 | validation: 0.355125818453419]
	TIME [epoch: 5.73 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42362526795625743		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.42362526795625743 | validation: 0.3695852621419307]
	TIME [epoch: 5.73 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4377095433174212		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.4377095433174212 | validation: 0.5132579591175154]
	TIME [epoch: 5.76 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655776690882481		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.5655776690882481 | validation: 0.8879717076162678]
	TIME [epoch: 5.75 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.650438521545261		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.650438521545261 | validation: 0.42929758784337063]
	TIME [epoch: 5.73 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5895121349973498		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.5895121349973498 | validation: 0.4509832823704878]
	TIME [epoch: 5.73 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4785564410672416		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.4785564410672416 | validation: 0.6251203786536761]
	TIME [epoch: 5.73 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44320416769985216		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.44320416769985216 | validation: 0.4246179198911316]
	TIME [epoch: 5.73 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6681066238814681		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.6681066238814681 | validation: 0.8053559880903433]
	TIME [epoch: 5.73 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5505482462298936		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.5505482462298936 | validation: 0.5539716660990238]
	TIME [epoch: 5.77 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4465064976070503		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.4465064976070503 | validation: 0.30292708722158274]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47803455264856654		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.47803455264856654 | validation: 0.48985196622759264]
	TIME [epoch: 5.73 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509870750086012		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.509870750086012 | validation: 0.4279069120912583]
	TIME [epoch: 5.73 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40784746197037314		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.40784746197037314 | validation: 0.3162786399380821]
	TIME [epoch: 5.73 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5239830921991777		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.5239830921991777 | validation: 0.30738596513379923]
	TIME [epoch: 5.73 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4537113726597812		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.4537113726597812 | validation: 0.41152640963953674]
	TIME [epoch: 5.76 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4452233936623907		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.4452233936623907 | validation: 0.2814499510265664]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4237132521746221		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.4237132521746221 | validation: 0.6032899773647188]
	TIME [epoch: 5.73 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4885068671032929		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.4885068671032929 | validation: 0.34137268399828996]
	TIME [epoch: 5.73 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42214340394342237		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.42214340394342237 | validation: 0.4439033026658378]
	TIME [epoch: 5.72 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4675351449741724		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.4675351449741724 | validation: 0.41595870138810526]
	TIME [epoch: 5.72 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4174946752974762		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.4174946752974762 | validation: 0.3985167014972359]
	TIME [epoch: 5.74 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4589133996424813		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.4589133996424813 | validation: 0.3652474749421565]
	TIME [epoch: 5.76 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4844132863281737		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.4844132863281737 | validation: 0.6281924253805642]
	TIME [epoch: 5.73 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.495803181996812		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.495803181996812 | validation: 0.3889088053350119]
	TIME [epoch: 5.73 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5491447576724777		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5491447576724777 | validation: 0.42073444604196014]
	TIME [epoch: 5.72 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7935291652803145		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.7935291652803145 | validation: 0.4422239151134617]
	TIME [epoch: 5.72 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739984601417938		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.4739984601417938 | validation: 0.422137367418819]
	TIME [epoch: 5.73 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41412505387912735		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.41412505387912735 | validation: 0.32628647904350955]
	TIME [epoch: 5.76 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37606893213974624		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.37606893213974624 | validation: 0.3531504770526007]
	TIME [epoch: 5.73 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45760512556879507		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.45760512556879507 | validation: 0.5560091417843114]
	TIME [epoch: 5.73 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585027317905269		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.5585027317905269 | validation: 0.7380926260602018]
	TIME [epoch: 5.73 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5374530555206634		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.5374530555206634 | validation: 0.42380683613322434]
	TIME [epoch: 5.72 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38732337181822485		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.38732337181822485 | validation: 0.4797024023904008]
	TIME [epoch: 5.73 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375477276305463		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.4375477276305463 | validation: 0.32979490432702796]
	TIME [epoch: 5.74 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783797112529442		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3783797112529442 | validation: 0.33951235370707594]
	TIME [epoch: 5.76 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3668603365522626		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.3668603365522626 | validation: 0.4338421545207518]
	TIME [epoch: 5.73 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.565861203188463		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.565861203188463 | validation: 0.4227036012146148]
	TIME [epoch: 5.72 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4572054709817228		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.4572054709817228 | validation: 0.5466931487312806]
	TIME [epoch: 5.72 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4955047347731091		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.4955047347731091 | validation: 0.3716851551211386]
	TIME [epoch: 5.73 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43424790697649945		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.43424790697649945 | validation: 0.7106219202752146]
	TIME [epoch: 5.73 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4078964563545292		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.4078964563545292 | validation: 0.3567503895030177]
	TIME [epoch: 5.75 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913927816352901		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.3913927816352901 | validation: 0.3128455676302405]
	TIME [epoch: 5.74 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872659088805992		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.3872659088805992 | validation: 0.3449779608154262]
	TIME [epoch: 5.73 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538300018198387		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.3538300018198387 | validation: 0.2906946767335989]
	TIME [epoch: 5.73 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368860358744862		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.368860358744862 | validation: 0.3739498834536728]
	TIME [epoch: 5.72 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3941105833945773		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.3941105833945773 | validation: 0.44717524559153093]
	TIME [epoch: 5.73 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6211681707595853		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.6211681707595853 | validation: 0.3844468594314448]
	TIME [epoch: 5.72 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3642112402497088		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.3642112402497088 | validation: 0.5033889653174703]
	TIME [epoch: 5.77 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44257166823883803		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.44257166823883803 | validation: 0.4667528594953002]
	TIME [epoch: 5.73 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41352223496564644		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.41352223496564644 | validation: 0.3404125936389508]
	TIME [epoch: 5.72 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3927675356324831		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.3927675356324831 | validation: 0.4515923028543061]
	TIME [epoch: 5.72 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34570543328813114		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.34570543328813114 | validation: 0.45947829161465875]
	TIME [epoch: 5.72 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39974051134512834		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.39974051134512834 | validation: 0.39177952283582074]
	TIME [epoch: 5.72 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36646659961576844		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.36646659961576844 | validation: 0.8735098195842238]
	TIME [epoch: 5.75 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.440934400939381		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.440934400939381 | validation: 0.3697137333164204]
	TIME [epoch: 5.74 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5962043691408758		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.5962043691408758 | validation: 0.4025465460097323]
	TIME [epoch: 5.73 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419945919685357		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.4419945919685357 | validation: 0.3706981686879643]
	TIME [epoch: 5.73 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181372871816449		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.5181372871816449 | validation: 0.486335636070408]
	TIME [epoch: 5.72 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46102272319976445		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.46102272319976445 | validation: 0.5414881928819013]
	TIME [epoch: 5.72 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39859399600175854		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.39859399600175854 | validation: 0.7383951002161002]
	TIME [epoch: 5.72 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4393849173126362		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.4393849173126362 | validation: 0.31785772646895105]
	TIME [epoch: 5.77 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4336298931048987		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.4336298931048987 | validation: 0.3339423150641667]
	TIME [epoch: 5.72 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4170317321595973		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.4170317321595973 | validation: 0.688921512474091]
	TIME [epoch: 5.72 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42054174507428327		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.42054174507428327 | validation: 0.5168144505660854]
	TIME [epoch: 5.72 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.428745105140945		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.428745105140945 | validation: 0.6224814944299673]
	TIME [epoch: 5.72 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42810045562910853		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.42810045562910853 | validation: 0.3717640164216286]
	TIME [epoch: 5.72 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316624013500057		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.3316624013500057 | validation: 0.3848427336290051]
	TIME [epoch: 5.75 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4260385298322489		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.4260385298322489 | validation: 0.46822064651013423]
	TIME [epoch: 5.74 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39562932839771914		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.39562932839771914 | validation: 0.3549928158728764]
	TIME [epoch: 5.73 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40578472089217443		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.40578472089217443 | validation: 0.31412096722933697]
	TIME [epoch: 5.72 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35631821906646466		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.35631821906646466 | validation: 0.2832756746367646]
	TIME [epoch: 5.72 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439039895697751		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.3439039895697751 | validation: 0.39526242597408173]
	TIME [epoch: 5.73 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35979867361765194		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.35979867361765194 | validation: 0.3777885083683524]
	TIME [epoch: 5.73 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695846612345947		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.3695846612345947 | validation: 0.3385689922223479]
	TIME [epoch: 5.77 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41133112801512955		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.41133112801512955 | validation: 0.558067977797345]
	TIME [epoch: 5.73 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3773456515939294		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.3773456515939294 | validation: 0.2960798936548925]
	TIME [epoch: 5.72 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5495131650011903		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.5495131650011903 | validation: 0.30025943618586104]
	TIME [epoch: 5.72 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8229259786463242		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.8229259786463242 | validation: 0.575823743666706]
	TIME [epoch: 5.72 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4225404328565429		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.4225404328565429 | validation: 0.31611990907390813]
	TIME [epoch: 5.72 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389371807472636		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.389371807472636 | validation: 0.39702557253305515]
	TIME [epoch: 5.75 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4428205398771334		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.4428205398771334 | validation: 0.3873714171812317]
	TIME [epoch: 5.74 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32583972171217057		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.32583972171217057 | validation: 0.3160389480145018]
	TIME [epoch: 5.73 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333675869064119		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.333675869064119 | validation: 0.8147203406844392]
	TIME [epoch: 5.72 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44026177744849065		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.44026177744849065 | validation: 0.37460298109457496]
	TIME [epoch: 5.72 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876227364456915		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.6876227364456915 | validation: 0.4160324743469166]
	TIME [epoch: 5.72 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585499432066626		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3585499432066626 | validation: 0.36766697760740824]
	TIME [epoch: 5.72 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33889773466967077		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.33889773466967077 | validation: 0.3052600266415046]
	TIME [epoch: 5.76 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435707711025114		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.3435707711025114 | validation: 0.4968058793808781]
	TIME [epoch: 5.73 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41114885806784135		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.41114885806784135 | validation: 0.2924327793695978]
	TIME [epoch: 5.73 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875905341922264		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.2875905341922264 | validation: 0.2896658721794933]
	TIME [epoch: 5.72 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365599038789253		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.365599038789253 | validation: 0.33676927313231647]
	TIME [epoch: 5.73 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072408623724734		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.3072408623724734 | validation: 0.3045695758383279]
	TIME [epoch: 5.73 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46089690599986866		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.46089690599986866 | validation: 0.26742113888929603]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39422167398799557		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.39422167398799557 | validation: 0.3528248579786177]
	TIME [epoch: 5.76 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501713939060287		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.3501713939060287 | validation: 0.24669001353157524]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983070411243159		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.3983070411243159 | validation: 0.37812704833950095]
	TIME [epoch: 5.73 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4090174793747899		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.4090174793747899 | validation: 0.273719584072272]
	TIME [epoch: 5.72 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38576798595016637		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.38576798595016637 | validation: 0.28415513563953243]
	TIME [epoch: 5.73 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44326287773647266		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.44326287773647266 | validation: 0.2699591455933679]
	TIME [epoch: 5.73 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34960517677371816		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.34960517677371816 | validation: 0.30326296022757815]
	TIME [epoch: 5.77 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3273229016881344		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.3273229016881344 | validation: 0.3164020076594416]
	TIME [epoch: 5.73 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074504742851195		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3074504742851195 | validation: 0.24976814801720765]
	TIME [epoch: 5.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30410085835466166		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.30410085835466166 | validation: 0.2774197143542754]
	TIME [epoch: 5.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32830919077034515		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.32830919077034515 | validation: 0.40622688767773235]
	TIME [epoch: 5.72 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4057124543429411		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.4057124543429411 | validation: 0.30646754252851166]
	TIME [epoch: 5.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3146059091435964		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.3146059091435964 | validation: 0.47951492740478807]
	TIME [epoch: 5.74 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34719298030675794		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.34719298030675794 | validation: 0.32697803545429205]
	TIME [epoch: 5.73 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2887612809624426		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.2887612809624426 | validation: 0.30488518039519835]
	TIME [epoch: 5.71 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32781302881843777		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.32781302881843777 | validation: 0.3144759403044501]
	TIME [epoch: 5.72 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336921001426657		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3336921001426657 | validation: 0.24362536986617733]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3712872255951045		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.3712872255951045 | validation: 0.30846131258773674]
	TIME [epoch: 5.72 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31563105183447293		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.31563105183447293 | validation: 0.40660318806549]
	TIME [epoch: 5.72 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34529883193821564		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.34529883193821564 | validation: 0.30490860263094155]
	TIME [epoch: 5.76 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2520679756178799		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.2520679756178799 | validation: 0.2723293424117265]
	TIME [epoch: 5.72 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365494222518451		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.365494222518451 | validation: 0.49767794115638786]
	TIME [epoch: 5.72 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3394536567661931		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3394536567661931 | validation: 0.40945917111664215]
	TIME [epoch: 5.72 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31068501451690755		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.31068501451690755 | validation: 0.25636137090771316]
	TIME [epoch: 5.72 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34437408571243167		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.34437408571243167 | validation: 0.22075761956925682]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3878102848853671		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.3878102848853671 | validation: 0.30174368723388617]
	TIME [epoch: 5.75 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29240580464748334		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.29240580464748334 | validation: 0.2221720513211138]
	TIME [epoch: 5.73 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26342890889013243		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.26342890889013243 | validation: 0.4608788718124238]
	TIME [epoch: 5.73 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40535556512376747		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.40535556512376747 | validation: 0.2681875845731295]
	TIME [epoch: 5.71 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4330669156268466		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.4330669156268466 | validation: 0.2691133536732665]
	TIME [epoch: 5.72 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4090199576421739		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.4090199576421739 | validation: 0.26600925008195675]
	TIME [epoch: 5.72 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903058515469461		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.2903058515469461 | validation: 0.30017789080106394]
	TIME [epoch: 5.72 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26169145858250314		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.26169145858250314 | validation: 0.25458301633108105]
	TIME [epoch: 5.76 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536002487861573		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.2536002487861573 | validation: 0.3267301180118562]
	TIME [epoch: 5.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.299962699668071		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.299962699668071 | validation: 0.3500738013853219]
	TIME [epoch: 5.72 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3059837218749972		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.3059837218749972 | validation: 0.3025177861377598]
	TIME [epoch: 5.73 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32771589271334006		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.32771589271334006 | validation: 0.2784955542547389]
	TIME [epoch: 5.72 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24133694777925074		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.24133694777925074 | validation: 1.4708752540342362]
	TIME [epoch: 5.72 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5564204517380541		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.5564204517380541 | validation: 0.26365117924905507]
	TIME [epoch: 5.74 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447434729946093		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.3447434729946093 | validation: 0.49384473331675166]
	TIME [epoch: 5.74 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45667383980808274		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.45667383980808274 | validation: 0.5146429113676354]
	TIME [epoch: 5.72 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3044046858058288		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.3044046858058288 | validation: 0.21316692244261354]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584527539859971		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.2584527539859971 | validation: 0.3030470273004439]
	TIME [epoch: 5.71 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915124499044823		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.2915124499044823 | validation: 0.2883158562905312]
	TIME [epoch: 5.72 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948390697676403		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.2948390697676403 | validation: 0.2929105121905048]
	TIME [epoch: 5.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33479640625401086		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.33479640625401086 | validation: 0.2412775544697078]
	TIME [epoch: 5.76 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22864162938390137		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.22864162938390137 | validation: 0.2056019494338927]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24727782660713107		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.24727782660713107 | validation: 0.3003494523485074]
	TIME [epoch: 5.71 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39412763679117474		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.39412763679117474 | validation: 0.2776805846821774]
	TIME [epoch: 5.71 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23820334609412383		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.23820334609412383 | validation: 0.2831999652580818]
	TIME [epoch: 5.73 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005130682398779		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.3005130682398779 | validation: 0.23364518820316377]
	TIME [epoch: 5.71 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743159857815672		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.2743159857815672 | validation: 0.35532296815069475]
	TIME [epoch: 5.75 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29935430622045694		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.29935430622045694 | validation: 0.323730009158698]
	TIME [epoch: 5.73 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925961787060586		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.2925961787060586 | validation: 0.28198110468022114]
	TIME [epoch: 5.71 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3994649393450126		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.3994649393450126 | validation: 0.24901611629934195]
	TIME [epoch: 5.72 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3365723121513957		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.3365723121513957 | validation: 0.28332549695914694]
	TIME [epoch: 5.72 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3199179459117477		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.3199179459117477 | validation: 0.2159130822884536]
	TIME [epoch: 5.71 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26326156583177157		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.26326156583177157 | validation: 0.3370538400230964]
	TIME [epoch: 5.71 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2585410742991651		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.2585410742991651 | validation: 0.26243955828389764]
	TIME [epoch: 5.76 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22240652449171533		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.22240652449171533 | validation: 0.3340465703171276]
	TIME [epoch: 5.71 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3064938648385421		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.3064938648385421 | validation: 0.28983636585831]
	TIME [epoch: 5.71 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2847551852712847		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.2847551852712847 | validation: 0.25874448855339444]
	TIME [epoch: 5.71 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254202929638416		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.254202929638416 | validation: 0.5270251495335536]
	TIME [epoch: 5.71 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28440749574229185		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.28440749574229185 | validation: 0.19388300594939317]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912676220312036		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.2912676220312036 | validation: 0.21426860494768377]
	TIME [epoch: 5.76 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3654304783536394		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.3654304783536394 | validation: 0.8870168161793397]
	TIME [epoch: 5.73 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5206239012805672		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.5206239012805672 | validation: 0.24382875866581769]
	TIME [epoch: 5.72 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30123631932180084		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.30123631932180084 | validation: 0.23576140537438542]
	TIME [epoch: 5.71 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26082781558264023		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.26082781558264023 | validation: 0.27837783544172273]
	TIME [epoch: 5.72 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27384126049341756		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.27384126049341756 | validation: 0.24511264040135466]
	TIME [epoch: 5.71 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2378881695383468		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.2378881695383468 | validation: 0.35726173786804977]
	TIME [epoch: 5.72 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27995646714271055		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.27995646714271055 | validation: 0.3275626989384492]
	TIME [epoch: 5.75 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35554796360138013		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.35554796360138013 | validation: 0.24827503054466918]
	TIME [epoch: 5.71 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23012260207349539		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.23012260207349539 | validation: 0.27489305705482464]
	TIME [epoch: 5.72 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23197197151288734		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.23197197151288734 | validation: 0.2270755785229683]
	TIME [epoch: 5.71 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28506469178643445		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.28506469178643445 | validation: 0.23002083810032775]
	TIME [epoch: 5.71 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.257079283015516		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.257079283015516 | validation: 0.4795950299770397]
	TIME [epoch: 5.73 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.313742759870876		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.313742759870876 | validation: 0.22229768993260798]
	TIME [epoch: 5.74 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23914581840871804		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.23914581840871804 | validation: 0.20348909998678155]
	TIME [epoch: 5.74 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25516228623037296		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.25516228623037296 | validation: 0.34510123468761217]
	TIME [epoch: 5.72 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2359591867085549		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.2359591867085549 | validation: 0.5545704269591925]
	TIME [epoch: 5.71 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3975725658924779		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.3975725658924779 | validation: 0.24402009454005538]
	TIME [epoch: 5.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21169017349137043		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.21169017349137043 | validation: 0.3520349634684098]
	TIME [epoch: 5.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783501880520771		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.2783501880520771 | validation: 0.17967094704672257]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2563207705695085		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.2563207705695085 | validation: 0.27955567536892884]
	TIME [epoch: 5.75 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23387881390281934		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.23387881390281934 | validation: 0.20388556392973747]
	TIME [epoch: 5.71 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22059287940413472		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.22059287940413472 | validation: 0.4718370406432031]
	TIME [epoch: 5.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2836604880604292		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.2836604880604292 | validation: 0.37705234396032494]
	TIME [epoch: 5.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31494045505982415		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.31494045505982415 | validation: 0.2045862828588928]
	TIME [epoch: 5.71 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22162668844195899		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.22162668844195899 | validation: 0.272724471547557]
	TIME [epoch: 5.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286727682159154		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.286727682159154 | validation: 0.35753086537762885]
	TIME [epoch: 5.74 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25269596759551116		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.25269596759551116 | validation: 0.2619365342783037]
	TIME [epoch: 5.73 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25969037891098085		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.25969037891098085 | validation: 0.21292707018891108]
	TIME [epoch: 5.72 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28796525181476945		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.28796525181476945 | validation: 0.29860100291533664]
	TIME [epoch: 5.71 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26616980267173584		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.26616980267173584 | validation: 0.33805154735685544]
	TIME [epoch: 5.72 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2954602621056613		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2954602621056613 | validation: 0.3844590084628158]
	TIME [epoch: 5.71 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2900805633576482		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.2900805633576482 | validation: 0.44271870552734]
	TIME [epoch: 5.71 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33221454690892555		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.33221454690892555 | validation: 0.25286510733914347]
	TIME [epoch: 5.76 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695999033927892		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.2695999033927892 | validation: 0.34246779905417685]
	TIME [epoch: 5.72 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23336814986819815		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.23336814986819815 | validation: 0.3005842773998896]
	TIME [epoch: 5.71 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629909938014532		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.2629909938014532 | validation: 0.3525892199383826]
	TIME [epoch: 5.71 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23250040334349786		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.23250040334349786 | validation: 0.21237758038499788]
	TIME [epoch: 5.71 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23711989498126457		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.23711989498126457 | validation: 0.7098198243229824]
	TIME [epoch: 5.71 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49042856281558417		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.49042856281558417 | validation: 0.2636698782001066]
	TIME [epoch: 5.74 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24772838987336165		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.24772838987336165 | validation: 0.2807078286562009]
	TIME [epoch: 5.73 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29444736961192736		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.29444736961192736 | validation: 0.1818150008210094]
	TIME [epoch: 5.72 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29184487092435857		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.29184487092435857 | validation: 0.1933528128723458]
	TIME [epoch: 5.71 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22991562893759288		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.22991562893759288 | validation: 0.19177397614556024]
	TIME [epoch: 5.71 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22653000225098965		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.22653000225098965 | validation: 0.2212508636511888]
	TIME [epoch: 5.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24660289975080052		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.24660289975080052 | validation: 0.26710508137391914]
	TIME [epoch: 5.73 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22565889412049212		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.22565889412049212 | validation: 0.19723187713971524]
	TIME [epoch: 5.76 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20197132219724717		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.20197132219724717 | validation: 0.33988655144981805]
	TIME [epoch: 5.72 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803315070243159		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.2803315070243159 | validation: 0.3135298207236587]
	TIME [epoch: 5.73 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2561015834821074		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.2561015834821074 | validation: 0.3787804244442436]
	TIME [epoch: 5.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2605129839637421		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.2605129839637421 | validation: 0.2473781220958683]
	TIME [epoch: 5.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22089997275478868		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.22089997275478868 | validation: 0.2600670247050717]
	TIME [epoch: 5.72 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2625528156067513		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.2625528156067513 | validation: 0.18493671999586986]
	TIME [epoch: 5.74 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21145758130461673		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.21145758130461673 | validation: 0.32095469227061607]
	TIME [epoch: 5.73 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22857647821144847		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.22857647821144847 | validation: 0.26828936879952664]
	TIME [epoch: 5.71 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2245835157360962		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.2245835157360962 | validation: 0.22773824639287338]
	TIME [epoch: 5.71 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26776616661296093		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.26776616661296093 | validation: 0.1475314042295177]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18095345012708874		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.18095345012708874 | validation: 0.3733147648872243]
	TIME [epoch: 5.71 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31568542577781306		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.31568542577781306 | validation: 0.3010950774504837]
	TIME [epoch: 5.73 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25719409674384086		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.25719409674384086 | validation: 0.670227573073657]
	TIME [epoch: 5.77 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34355948842073825		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.34355948842073825 | validation: 0.32831047533990815]
	TIME [epoch: 5.73 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3325143579747663		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.3325143579747663 | validation: 0.2201044858392391]
	TIME [epoch: 5.73 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20404003694347062		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.20404003694347062 | validation: 0.22179631250575924]
	TIME [epoch: 5.73 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2954470209166483		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.2954470209166483 | validation: 0.31392526517995284]
	TIME [epoch: 5.73 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25829927081557813		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.25829927081557813 | validation: 0.309348193883914]
	TIME [epoch: 5.73 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23406653852837833		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.23406653852837833 | validation: 0.3107667801302159]
	TIME [epoch: 5.77 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726690926110442		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2726690926110442 | validation: 0.23107368506123308]
	TIME [epoch: 5.73 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1947224213230413		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.1947224213230413 | validation: 0.24658298272263657]
	TIME [epoch: 5.73 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2860441297239376		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.2860441297239376 | validation: 0.22324411698030705]
	TIME [epoch: 5.73 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19371022964622636		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.19371022964622636 | validation: 0.18756625991257167]
	TIME [epoch: 5.73 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24048919928457757		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.24048919928457757 | validation: 0.22175273352105135]
	TIME [epoch: 5.73 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20238559591993885		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.20238559591993885 | validation: 0.1945436563195357]
	TIME [epoch: 5.74 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25546044285585345		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.25546044285585345 | validation: 0.23141907510692902]
	TIME [epoch: 5.74 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19114666796360352		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.19114666796360352 | validation: 0.19556288398170182]
	TIME [epoch: 5.72 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18444562192413916		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.18444562192413916 | validation: 0.22171833724809262]
	TIME [epoch: 5.72 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21863531972844005		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.21863531972844005 | validation: 0.21421714611669923]
	TIME [epoch: 5.72 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20926773873912013		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.20926773873912013 | validation: 0.43474417968767803]
	TIME [epoch: 5.72 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2870408537846193		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.2870408537846193 | validation: 0.22061789994314127]
	TIME [epoch: 5.72 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24341350613742913		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.24341350613742913 | validation: 0.1762548708341959]
	TIME [epoch: 5.76 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841748864510261		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.1841748864510261 | validation: 0.21490013907886826]
	TIME [epoch: 5.72 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20363041383608182		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.20363041383608182 | validation: 0.2074674135801451]
	TIME [epoch: 5.72 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20960573473423408		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.20960573473423408 | validation: 0.1660276362787507]
	TIME [epoch: 5.72 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18192098654946404		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.18192098654946404 | validation: 0.33679639245792864]
	TIME [epoch: 5.72 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2404970732538002		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.2404970732538002 | validation: 0.18297359594749452]
	TIME [epoch: 5.72 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24075318555785705		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.24075318555785705 | validation: 0.2516701946742661]
	TIME [epoch: 5.74 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28346518049958025		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.28346518049958025 | validation: 0.38944080122091124]
	TIME [epoch: 5.73 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27745609074931626		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.27745609074931626 | validation: 0.24954333350299288]
	TIME [epoch: 5.72 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21326147484490787		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.21326147484490787 | validation: 0.17919286096089188]
	TIME [epoch: 5.71 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20136538914512958		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.20136538914512958 | validation: 0.155522297794938]
	TIME [epoch: 5.72 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2424924013497412		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.2424924013497412 | validation: 0.17576962680243122]
	TIME [epoch: 5.72 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27673050299900953		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.27673050299900953 | validation: 0.257591003734933]
	TIME [epoch: 5.72 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20183722641422291		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.20183722641422291 | validation: 0.18833690845488577]
	TIME [epoch: 5.76 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17052233323636543		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.17052233323636543 | validation: 0.3199490410770731]
	TIME [epoch: 5.72 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22450237380977028		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.22450237380977028 | validation: 0.21321878211700163]
	TIME [epoch: 5.72 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2326541500027852		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.2326541500027852 | validation: 0.3018261257958115]
	TIME [epoch: 5.71 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22194536614670365		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.22194536614670365 | validation: 0.19019078857753471]
	TIME [epoch: 5.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18199430318840223		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.18199430318840223 | validation: 0.1966044258581508]
	TIME [epoch: 5.71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16950963768321853		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.16950963768321853 | validation: 0.22620038224982408]
	TIME [epoch: 5.73 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24828777968184532		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.24828777968184532 | validation: 0.2442196357787864]
	TIME [epoch: 5.75 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19244446515352764		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.19244446515352764 | validation: 0.25981599304499076]
	TIME [epoch: 5.73 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1823406203031803		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.1823406203031803 | validation: 0.1587143031768503]
	TIME [epoch: 5.71 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695193052732529		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.1695193052732529 | validation: 0.20803929362438964]
	TIME [epoch: 5.72 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.225950698412013		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.225950698412013 | validation: 0.2285106741891965]
	TIME [epoch: 5.71 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28255773375283805		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.28255773375283805 | validation: 0.23409429956574188]
	TIME [epoch: 5.71 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24082761849472561		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.24082761849472561 | validation: 0.17814063801992083]
	TIME [epoch: 5.75 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15530881598782842		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.15530881598782842 | validation: 0.23993411296064068]
	TIME [epoch: 5.72 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16143097632991465		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.16143097632991465 | validation: 0.2641732281336663]
	TIME [epoch: 5.71 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1921032965153574		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1921032965153574 | validation: 0.3019648684039467]
	TIME [epoch: 5.71 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21742840200916266		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.21742840200916266 | validation: 0.22464033740907005]
	TIME [epoch: 5.71 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1771499032174384		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.1771499032174384 | validation: 0.18360348305905447]
	TIME [epoch: 5.71 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30448061600246346		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.30448061600246346 | validation: 0.250951498546843]
	TIME [epoch: 5.72 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27327098058064775		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.27327098058064775 | validation: 0.26377281456693685]
	TIME [epoch: 5.74 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890743060674432		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.1890743060674432 | validation: 0.16829364639718516]
	TIME [epoch: 5.72 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30711704986408894		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.30711704986408894 | validation: 0.23193154209162742]
	TIME [epoch: 5.72 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1869084229550731		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.1869084229550731 | validation: 0.16852596176764856]
	TIME [epoch: 5.72 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17912758863408712		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.17912758863408712 | validation: 0.14078749804731472]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_363.pth
	Model improved!!!
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19085387188498504		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.19085387188498504 | validation: 0.17161104300905475]
	TIME [epoch: 5.71 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17446759337151077		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.17446759337151077 | validation: 0.34793955288359163]
	TIME [epoch: 5.75 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28680692925390044		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.28680692925390044 | validation: 0.17785260202582934]
	TIME [epoch: 5.71 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16310831642250156		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.16310831642250156 | validation: 0.18451740932782087]
	TIME [epoch: 5.71 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17069685074242477		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.17069685074242477 | validation: 0.18411529580965147]
	TIME [epoch: 5.71 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18546025260932614		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.18546025260932614 | validation: 0.20728642879815737]
	TIME [epoch: 5.72 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20355726329352797		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.20355726329352797 | validation: 0.18480235319221777]
	TIME [epoch: 5.72 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17775623816435904		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.17775623816435904 | validation: 0.1454916449248001]
	TIME [epoch: 5.73 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620007191045821		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.1620007191045821 | validation: 0.36487137218550947]
	TIME [epoch: 5.74 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.306013140892344		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.306013140892344 | validation: 0.21342274972644648]
	TIME [epoch: 5.72 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1991809135617585		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.1991809135617585 | validation: 0.1616825252319379]
	TIME [epoch: 5.71 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16968903405592445		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.16968903405592445 | validation: 0.11745110309683407]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_375.pth
	Model improved!!!
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13276490979585875		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.13276490979585875 | validation: 0.2887649614415058]
	TIME [epoch: 5.71 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17922622262930274		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.17922622262930274 | validation: 0.12780054364508409]
	TIME [epoch: 5.71 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308556400719837		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.1308556400719837 | validation: 0.18804382184346044]
	TIME [epoch: 5.75 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16445227273014595		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.16445227273014595 | validation: 0.20048541824793562]
	TIME [epoch: 5.71 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19448985944428704		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.19448985944428704 | validation: 0.2516439623727144]
	TIME [epoch: 5.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20808556560234096		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.20808556560234096 | validation: 0.23944774934375265]
	TIME [epoch: 5.71 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24478630268715845		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.24478630268715845 | validation: 0.20412225113506335]
	TIME [epoch: 5.71 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20041303922374276		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.20041303922374276 | validation: 0.2260865165176329]
	TIME [epoch: 5.72 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19359791204323762		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.19359791204323762 | validation: 0.19747668660917092]
	TIME [epoch: 5.73 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18092754168618919		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.18092754168618919 | validation: 0.1752922349745819]
	TIME [epoch: 5.76 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1672438608905688		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.1672438608905688 | validation: 0.18859446654240494]
	TIME [epoch: 5.73 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1885897946585428		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.1885897946585428 | validation: 0.16302308502303586]
	TIME [epoch: 5.71 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21536786744049202		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.21536786744049202 | validation: 0.228788448776768]
	TIME [epoch: 5.71 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16724614641146757		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.16724614641146757 | validation: 0.12110499852432792]
	TIME [epoch: 5.72 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422850077311238		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.1422850077311238 | validation: 0.16179018261992006]
	TIME [epoch: 5.71 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12597902733385064		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.12597902733385064 | validation: 0.12221035705304693]
	TIME [epoch: 5.76 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17234667442657972		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.17234667442657972 | validation: 0.31062740180648823]
	TIME [epoch: 5.72 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23939579279901646		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.23939579279901646 | validation: 0.10988233917571727]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483317118383168		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.1483317118383168 | validation: 0.22715058715054043]
	TIME [epoch: 5.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16556152799576213		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.16556152799576213 | validation: 0.16425945218587162]
	TIME [epoch: 5.71 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509449766050312		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.1509449766050312 | validation: 0.14023382053659864]
	TIME [epoch: 5.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14837542157014974		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.14837542157014974 | validation: 0.16346426884709467]
	TIME [epoch: 5.72 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16455643848003865		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.16455643848003865 | validation: 0.19988758367589768]
	TIME [epoch: 5.74 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18942765163931705		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.18942765163931705 | validation: 0.2846973067660901]
	TIME [epoch: 5.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17128070615336344		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.17128070615336344 | validation: 0.134533802202797]
	TIME [epoch: 5.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17716485063557108		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.17716485063557108 | validation: 0.10339399496323214]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12978246342803285		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.12978246342803285 | validation: 0.14906309398559484]
	TIME [epoch: 5.71 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328975326754599		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.1328975326754599 | validation: 0.1402607975257499]
	TIME [epoch: 5.71 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15711386629661891		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.15711386629661891 | validation: 0.22947450506581102]
	TIME [epoch: 5.76 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18862078335371044		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.18862078335371044 | validation: 0.2999469764219309]
	TIME [epoch: 5.72 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17537182903668178		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.17537182903668178 | validation: 0.13852378902025592]
	TIME [epoch: 5.71 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1652303904913448		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.1652303904913448 | validation: 0.13858605534155874]
	TIME [epoch: 5.71 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12099716326466013		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.12099716326466013 | validation: 0.1828516670182269]
	TIME [epoch: 5.71 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12867603955175427		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.12867603955175427 | validation: 0.11773152118673967]
	TIME [epoch: 5.71 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323878365240741		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.1323878365240741 | validation: 0.14383782731490719]
	TIME [epoch: 5.73 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899825192682616		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.1899825192682616 | validation: 0.14100217085648725]
	TIME [epoch: 5.75 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19777978477792366		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.19777978477792366 | validation: 0.14161443940006452]
	TIME [epoch: 5.71 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17496031051799937		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.17496031051799937 | validation: 0.2179900885743634]
	TIME [epoch: 5.71 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1419147464213819		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.1419147464213819 | validation: 0.16188554140973288]
	TIME [epoch: 5.71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15463659530179083		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.15463659530179083 | validation: 0.2588203452564682]
	TIME [epoch: 5.71 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23578056226810512		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.23578056226810512 | validation: 0.13875070166084136]
	TIME [epoch: 5.71 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15573873005570094		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.15573873005570094 | validation: 0.19140488638147696]
	TIME [epoch: 5.75 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17155255228114352		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.17155255228114352 | validation: 0.09740933443585022]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10506905710381396		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.10506905710381396 | validation: 0.18003335418146654]
	TIME [epoch: 5.73 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13123956981874024		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.13123956981874024 | validation: 0.14735298427948443]
	TIME [epoch: 5.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1237057868448062		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.1237057868448062 | validation: 0.12360430549986445]
	TIME [epoch: 5.73 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10999848148540411		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.10999848148540411 | validation: 0.10709659067135724]
	TIME [epoch: 5.73 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13485259603781566		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.13485259603781566 | validation: 0.13372964991571287]
	TIME [epoch: 5.74 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10478276710969539		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.10478276710969539 | validation: 0.17590796067242373]
	TIME [epoch: 5.76 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15969776054380747		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.15969776054380747 | validation: 0.149326371697321]
	TIME [epoch: 5.73 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19603355324667482		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.19603355324667482 | validation: 0.16914252941294217]
	TIME [epoch: 5.73 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14581246376463716		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.14581246376463716 | validation: 0.0720746197317633]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_427.pth
	Model improved!!!
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09354763008963549		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.09354763008963549 | validation: 0.13399217431918473]
	TIME [epoch: 5.73 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12152299251159221		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.12152299251159221 | validation: 0.14362784175991128]
	TIME [epoch: 5.72 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17990475461432615		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.17990475461432615 | validation: 0.16445962298583408]
	TIME [epoch: 5.76 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13424998458509652		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.13424998458509652 | validation: 0.2428029829441314]
	TIME [epoch: 5.73 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19530788661341367		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.19530788661341367 | validation: 0.11571785775892636]
	TIME [epoch: 5.72 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1717136751912517		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.1717136751912517 | validation: 0.16962742546636078]
	TIME [epoch: 5.72 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15427068934546168		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.15427068934546168 | validation: 0.27259295137583667]
	TIME [epoch: 5.72 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16041145731342293		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.16041145731342293 | validation: 0.1659664735333694]
	TIME [epoch: 5.73 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178107140875343		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.1178107140875343 | validation: 0.2148922737647404]
	TIME [epoch: 5.75 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14303451088616523		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.14303451088616523 | validation: 0.11189004699962923]
	TIME [epoch: 5.73 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1215642798740138		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.1215642798740138 | validation: 0.14142907492459864]
	TIME [epoch: 5.72 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284700554294355		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.1284700554294355 | validation: 0.11553063453328495]
	TIME [epoch: 5.71 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16214672090355275		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.16214672090355275 | validation: 0.15737193419780712]
	TIME [epoch: 5.71 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13344849535436176		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.13344849535436176 | validation: 0.23906424874541252]
	TIME [epoch: 5.71 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440071703250106		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.1440071703250106 | validation: 0.10049832729697407]
	TIME [epoch: 5.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10394500286489763		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.10394500286489763 | validation: 0.10656457468846178]
	TIME [epoch: 5.75 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1810458962237763		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.1810458962237763 | validation: 0.09068680649704287]
	TIME [epoch: 5.71 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10904359370836397		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.10904359370836397 | validation: 0.1635981205920067]
	TIME [epoch: 5.71 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20736270605961898		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.20736270605961898 | validation: 0.1427313335953452]
	TIME [epoch: 5.71 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12817726935991658		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.12817726935991658 | validation: 0.11886833534926211]
	TIME [epoch: 5.71 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260765986410839		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.1260765986410839 | validation: 0.1270061425685662]
	TIME [epoch: 5.71 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11952411762018117		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.11952411762018117 | validation: 0.1053703385883479]
	TIME [epoch: 5.72 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09411544933744267		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.09411544933744267 | validation: 0.10899488889246753]
	TIME [epoch: 5.75 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09988416947521986		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.09988416947521986 | validation: 0.09272202736504212]
	TIME [epoch: 5.73 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14170466652548983		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.14170466652548983 | validation: 0.1693091658666158]
	TIME [epoch: 5.72 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12892358399007112		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.12892358399007112 | validation: 0.09107433229766883]
	TIME [epoch: 5.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0892392211533209		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.0892392211533209 | validation: 0.17007124153771325]
	TIME [epoch: 5.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1605752015524165		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1605752015524165 | validation: 0.3667501052483377]
	TIME [epoch: 5.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22341853395369257		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.22341853395369257 | validation: 0.13322481103751513]
	TIME [epoch: 5.74 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280763225531385		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.1280763225531385 | validation: 0.12274988419862914]
	TIME [epoch: 5.71 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09610422069036903		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.09610422069036903 | validation: 0.09886838866796087]
	TIME [epoch: 5.72 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13341751281191022		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.13341751281191022 | validation: 0.14741911851252604]
	TIME [epoch: 5.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11819112432676594		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.11819112432676594 | validation: 0.15443264885188426]
	TIME [epoch: 5.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19698633058143455		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.19698633058143455 | validation: 0.13379652864300298]
	TIME [epoch: 5.71 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1299932633055524		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.1299932633055524 | validation: 0.17829139417845474]
	TIME [epoch: 5.72 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0999971326817316		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.0999971326817316 | validation: 0.09295444924820785]
	TIME [epoch: 5.74 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14887616787638522		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.14887616787638522 | validation: 0.21237877307491143]
	TIME [epoch: 5.71 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17865368400557177		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.17865368400557177 | validation: 0.2383275467216221]
	TIME [epoch: 5.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138344106158726		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.138344106158726 | validation: 0.07888190613036335]
	TIME [epoch: 5.71 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293602448589357		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.1293602448589357 | validation: 0.26394193563466667]
	TIME [epoch: 5.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16557276387529538		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.16557276387529538 | validation: 0.1390956964335018]
	TIME [epoch: 5.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.088819655946522		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.088819655946522 | validation: 0.11489991431395691]
	TIME [epoch: 5.74 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11995078296746262		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.11995078296746262 | validation: 0.12336143817722844]
	TIME [epoch: 5.71 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16474942595785558		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.16474942595785558 | validation: 0.0952740993268507]
	TIME [epoch: 5.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11891420531221703		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.11891420531221703 | validation: 0.21158254772053986]
	TIME [epoch: 5.72 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18464390753612012		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.18464390753612012 | validation: 0.20685170681804935]
	TIME [epoch: 5.72 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15961987688951623		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.15961987688951623 | validation: 0.18195061201306736]
	TIME [epoch: 5.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12123538501032094		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.12123538501032094 | validation: 0.1204891627831747]
	TIME [epoch: 5.71 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10451697926778905		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.10451697926778905 | validation: 0.07407014900497443]
	TIME [epoch: 5.74 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09086722612697357		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.09086722612697357 | validation: 0.3406499386425147]
	TIME [epoch: 5.73 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21760539004781637		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.21760539004781637 | validation: 0.27580209109546466]
	TIME [epoch: 5.72 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13668947958725952		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.13668947958725952 | validation: 0.09434776456698755]
	TIME [epoch: 5.72 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13157134722039215		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.13157134722039215 | validation: 0.23014726180751705]
	TIME [epoch: 5.71 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16274159543648795		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.16274159543648795 | validation: 0.11786419683519203]
	TIME [epoch: 5.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1121529261503949		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.1121529261503949 | validation: 0.09837280571599559]
	TIME [epoch: 5.75 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10531165205038504		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.10531165205038504 | validation: 0.10431855177451273]
	TIME [epoch: 5.72 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762564954682303		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.09762564954682303 | validation: 0.11292873358485606]
	TIME [epoch: 5.71 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10094159935409909		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.10094159935409909 | validation: 0.0882926645432163]
	TIME [epoch: 5.72 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09052901907728758		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.09052901907728758 | validation: 0.09720254695736945]
	TIME [epoch: 5.71 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09344394596259112		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.09344394596259112 | validation: 0.10004712749342577]
	TIME [epoch: 5.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20874487777963868		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.20874487777963868 | validation: 0.1587373907994067]
	TIME [epoch: 5.72 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11844204773700913		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.11844204773700913 | validation: 0.13674387571284907]
	TIME [epoch: 5.76 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14551092253259368		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.14551092253259368 | validation: 0.17600729563581016]
	TIME [epoch: 5.73 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14794315816522402		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.14794315816522402 | validation: 0.14609996208289405]
	TIME [epoch: 5.72 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10721782314422884		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.10721782314422884 | validation: 0.10835649831956282]
	TIME [epoch: 5.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10744568383230041		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.10744568383230041 | validation: 0.07266893133284112]
	TIME [epoch: 5.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127660586820393		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.1127660586820393 | validation: 0.13541772611132782]
	TIME [epoch: 5.71 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185491810168029		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.10185491810168029 | validation: 0.09592862396712491]
	TIME [epoch: 5.74 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551295405688928		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.1551295405688928 | validation: 0.15596717939544705]
	TIME [epoch: 5.72 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329723237381634		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.1329723237381634 | validation: 0.13014814912947015]
	TIME [epoch: 5.71 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0985213579309487		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.0985213579309487 | validation: 0.14902200167409513]
	TIME [epoch: 5.71 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1968630208731258		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1968630208731258 | validation: 0.098755626496242]
	TIME [epoch: 5.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07056924785583985		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.07056924785583985 | validation: 0.11019613063599101]
	TIME [epoch: 5.71 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0890039171543341		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.0890039171543341 | validation: 0.12984588638982533]
	TIME [epoch: 5.71 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168766765001782		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.2168766765001782 | validation: 0.12242924807938234]
	TIME [epoch: 5.76 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09279520167328142		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.09279520167328142 | validation: 0.14017881691074305]
	TIME [epoch: 5.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16691316647728696		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.16691316647728696 | validation: 0.16658096402014558]
	TIME [epoch: 5.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14924684907230293		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.14924684907230293 | validation: 0.13595668587421944]
	TIME [epoch: 5.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09478888263207116		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.09478888263207116 | validation: 0.0928247831529746]
	TIME [epoch: 5.72 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11489506619142474		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.11489506619142474 | validation: 0.16239583025116688]
	TIME [epoch: 5.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10360237391472579		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.10360237391472579 | validation: 0.06908953794410992]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09050420720191621		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.09050420720191621 | validation: 0.12613614560587752]
	TIME [epoch: 5.72 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10825575058050757		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.10825575058050757 | validation: 0.1052777326272696]
	TIME [epoch: 5.71 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12498711386264709		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.12498711386264709 | validation: 0.13499779543024168]
	TIME [epoch: 5.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1744888806219647		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.1744888806219647 | validation: 0.09623169009033088]
	TIME [epoch: 5.71 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11649639361781888		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.11649639361781888 | validation: 0.11674175096078736]
	TIME [epoch: 5.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288651029572932		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.1288651029572932 | validation: 0.1839915220823287]
	TIME [epoch: 5.71 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12251287320387233		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.12251287320387233 | validation: 0.12301742356631597]
	TIME [epoch: 5.74 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13078301374695173		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.13078301374695173 | validation: 0.15264760105769637]
	TIME [epoch: 5.71 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11522777396912709		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.11522777396912709 | validation: 0.07900847410671703]
	TIME [epoch: 5.72 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08438441796966958		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.08438441796966958 | validation: 0.11439629128387813]
	TIME [epoch: 5.71 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07486556089097036		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.07486556089097036 | validation: 0.11018612103180118]
	TIME [epoch: 5.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09667083959536213		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.09667083959536213 | validation: 0.11889225709545098]
	TIME [epoch: 5.71 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10060384857675884		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.10060384857675884 | validation: 0.25165128295822065]
	TIME [epoch: 5.73 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551149005425839		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.1551149005425839 | validation: 0.09566192614101354]
	TIME [epoch: 5.71 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0959662315403681		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.0959662315403681 | validation: 0.0884634077262954]
	TIME [epoch: 5.71 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07609120691455944		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.07609120691455944 | validation: 0.10338455592854223]
	TIME [epoch: 5.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09438726391565053		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.09438726391565053 | validation: 0.1279358277950671]
	TIME [epoch: 5.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20361403741899975		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.20361403741899975 | validation: 0.14696252032481116]
	TIME [epoch: 5.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16050399465289983		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.16050399465289983 | validation: 0.0951021845250995]
	TIME [epoch: 5.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07472864655278588		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.07472864655278588 | validation: 0.09792188665328326]
	TIME [epoch: 5.76 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.088070294594621		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.088070294594621 | validation: 0.10551732722447113]
	TIME [epoch: 5.71 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10031715551397623		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.10031715551397623 | validation: 0.13422581407831513]
	TIME [epoch: 5.72 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10714237771730771		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.10714237771730771 | validation: 0.139553960384074]
	TIME [epoch: 5.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09258327799224947		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.09258327799224947 | validation: 0.06439203194904765]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_532.pth
	Model improved!!!
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08069684351049682		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.08069684351049682 | validation: 0.1071029427720537]
	TIME [epoch: 5.72 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09031608169419905		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.09031608169419905 | validation: 0.09519677010109238]
	TIME [epoch: 5.74 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12197596070262079		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.12197596070262079 | validation: 0.15118128060194347]
	TIME [epoch: 5.72 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15920515286746262		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.15920515286746262 | validation: 0.2112950097136462]
	TIME [epoch: 5.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537272805670265		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.1537272805670265 | validation: 0.14094736918253936]
	TIME [epoch: 5.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08090262306943004		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.08090262306943004 | validation: 0.10551511112109564]
	TIME [epoch: 5.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419559087243326		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.12419559087243326 | validation: 0.18763962078742258]
	TIME [epoch: 5.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11153561188621347		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.11153561188621347 | validation: 0.10210765947092867]
	TIME [epoch: 5.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08309564868434628		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.08309564868434628 | validation: 0.11722297292002129]
	TIME [epoch: 5.76 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10423102343150244		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.10423102343150244 | validation: 0.10638679611947235]
	TIME [epoch: 5.73 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08656287227385359		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.08656287227385359 | validation: 0.156882190922673]
	TIME [epoch: 5.72 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12096384503957855		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.12096384503957855 | validation: 0.1207468022919483]
	TIME [epoch: 5.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07886799129116684		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.07886799129116684 | validation: 0.12048797969457635]
	TIME [epoch: 5.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08735911041913169		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.08735911041913169 | validation: 0.060470237307152175]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_546.pth
	Model improved!!!
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06789505222532323		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.06789505222532323 | validation: 0.0703733296763947]
	TIME [epoch: 5.73 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11788113639948432		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.11788113639948432 | validation: 0.09468224804575004]
	TIME [epoch: 5.73 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08285332867371815		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.08285332867371815 | validation: 0.08183963799278378]
	TIME [epoch: 5.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07092104969612073		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.07092104969612073 | validation: 0.09495070880311762]
	TIME [epoch: 5.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07867940493184915		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.07867940493184915 | validation: 0.08543470677955185]
	TIME [epoch: 5.71 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14900288269679327		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.14900288269679327 | validation: 0.2454411858198783]
	TIME [epoch: 5.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13123783017009508		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.13123783017009508 | validation: 0.18155853401924585]
	TIME [epoch: 5.72 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12486663800602216		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.12486663800602216 | validation: 0.10397066410013363]
	TIME [epoch: 5.76 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10681564875573499		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.10681564875573499 | validation: 0.14624101566848632]
	TIME [epoch: 5.72 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07746761258913931		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.07746761258913931 | validation: 0.07207353468876322]
	TIME [epoch: 5.72 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13363212816013198		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.13363212816013198 | validation: 0.07213389034752858]
	TIME [epoch: 5.71 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08449671913711054		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.08449671913711054 | validation: 0.1444175655752891]
	TIME [epoch: 5.72 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12037660865655664		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.12037660865655664 | validation: 0.10957988551862427]
	TIME [epoch: 5.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08007737731743603		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.08007737731743603 | validation: 0.12542012184031168]
	TIME [epoch: 5.72 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09507722759617906		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.09507722759617906 | validation: 0.1829880674753668]
	TIME [epoch: 5.72 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12336940318500215		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.12336940318500215 | validation: 0.14098841615598698]
	TIME [epoch: 5.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11881958945419882		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.11881958945419882 | validation: 0.10996296831850626]
	TIME [epoch: 5.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10415569850341087		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.10415569850341087 | validation: 0.2423216943485698]
	TIME [epoch: 5.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14043285609677045		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.14043285609677045 | validation: 0.07507099412907357]
	TIME [epoch: 5.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07574097074824959		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.07574097074824959 | validation: 0.08775741015024664]
	TIME [epoch: 5.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10413900690031003		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.10413900690031003 | validation: 0.1714958765610256]
	TIME [epoch: 5.74 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12358528582783336		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.12358528582783336 | validation: 0.45930558520997233]
	TIME [epoch: 5.73 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39698876810900613		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.39698876810900613 | validation: 0.09614888992248749]
	TIME [epoch: 5.71 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08905111613238556		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.08905111613238556 | validation: 0.10624326770149459]
	TIME [epoch: 5.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0950603631712724		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.0950603631712724 | validation: 0.06920303740028295]
	TIME [epoch: 5.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08756066435384141		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.08756066435384141 | validation: 0.11112371989136374]
	TIME [epoch: 5.72 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10034771019362801		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.10034771019362801 | validation: 0.0931122116647235]
	TIME [epoch: 5.71 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09142369404864703		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.09142369404864703 | validation: 0.1201502317148976]
	TIME [epoch: 5.73 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08330169607542326		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.08330169607542326 | validation: 0.0768957941329335]
	TIME [epoch: 5.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06730378664256931		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.06730378664256931 | validation: 0.08039764639270701]
	TIME [epoch: 5.72 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07795671046694436		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.07795671046694436 | validation: 0.10422698221003981]
	TIME [epoch: 5.72 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09377646498910497		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.09377646498910497 | validation: 0.10442604497875117]
	TIME [epoch: 5.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07528266646271001		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.07528266646271001 | validation: 0.11656384106872471]
	TIME [epoch: 5.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10665546136582121		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.10665546136582121 | validation: 0.1458495755361337]
	TIME [epoch: 5.76 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10522479495382901		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.10522479495382901 | validation: 0.1258657036754848]
	TIME [epoch: 5.73 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1021514860992416		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.1021514860992416 | validation: 0.09089751186985717]
	TIME [epoch: 5.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10849034323746383		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.10849034323746383 | validation: 0.1838766579954715]
	TIME [epoch: 5.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13722081646973466		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.13722081646973466 | validation: 0.14635704825180829]
	TIME [epoch: 5.72 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0922065400814339		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.0922065400814339 | validation: 0.08817503730974224]
	TIME [epoch: 5.72 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08651976682264685		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.08651976682264685 | validation: 0.08480808376295432]
	TIME [epoch: 5.71 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18023943472315554		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.18023943472315554 | validation: 0.2640462283395163]
	TIME [epoch: 5.73 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15587544878708667		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.15587544878708667 | validation: 0.11981063713971335]
	TIME [epoch: 5.72 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08556907050065887		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.08556907050065887 | validation: 0.1815794577577275]
	TIME [epoch: 5.72 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09550448088122626		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.09550448088122626 | validation: 0.08630723021581851]
	TIME [epoch: 5.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07263421977164233		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.07263421977164233 | validation: 0.11703382042260836]
	TIME [epoch: 5.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07536338388268446		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.07536338388268446 | validation: 0.09962398616613442]
	TIME [epoch: 5.72 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0723492641072587		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.0723492641072587 | validation: 0.11076157045008107]
	TIME [epoch: 5.76 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12435502955280572		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.12435502955280572 | validation: 0.1730772606434761]
	TIME [epoch: 5.71 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1136942406731033		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.1136942406731033 | validation: 0.13080992999059843]
	TIME [epoch: 5.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0935004557492523		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.0935004557492523 | validation: 0.09823599753050238]
	TIME [epoch: 5.72 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07077817158285968		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.07077817158285968 | validation: 0.07217059740118109]
	TIME [epoch: 5.72 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05496763037503549		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.05496763037503549 | validation: 0.07428244478202232]
	TIME [epoch: 5.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10312058058586743		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.10312058058586743 | validation: 0.11467755081152764]
	TIME [epoch: 5.71 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058712811685801565		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.058712811685801565 | validation: 0.1259959556967299]
	TIME [epoch: 5.75 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289867637625583		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.1289867637625583 | validation: 0.17628826028924002]
	TIME [epoch: 5.72 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11278127898476815		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.11278127898476815 | validation: 0.07461696131183077]
	TIME [epoch: 5.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05841465495788968		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.05841465495788968 | validation: 0.09231656371150958]
	TIME [epoch: 5.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14070999019739427		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.14070999019739427 | validation: 0.18483629257526552]
	TIME [epoch: 5.72 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006230798222406		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.1006230798222406 | validation: 0.06643452843806859]
	TIME [epoch: 5.72 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062368508400852146		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.062368508400852146 | validation: 0.08211634871765078]
	TIME [epoch: 5.74 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09900615411133512		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.09900615411133512 | validation: 0.09842070319688982]
	TIME [epoch: 5.71 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07464312938215151		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.07464312938215151 | validation: 0.09018334960639666]
	TIME [epoch: 5.72 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06724282985381151		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.06724282985381151 | validation: 0.10894132181259288]
	TIME [epoch: 5.72 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07508600148187582		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.07508600148187582 | validation: 0.08144830911631003]
	TIME [epoch: 5.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08486962847116905		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.08486962847116905 | validation: 0.07372571148307099]
	TIME [epoch: 5.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06488464693378039		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.06488464693378039 | validation: 0.08073357854079818]
	TIME [epoch: 5.72 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11421272757281786		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.11421272757281786 | validation: 0.1081726135787324]
	TIME [epoch: 5.76 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09586225565081283		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.09586225565081283 | validation: 0.08004291780093874]
	TIME [epoch: 5.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07475700893947239		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.07475700893947239 | validation: 0.09672380768216257]
	TIME [epoch: 5.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08069147766364759		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.08069147766364759 | validation: 0.1254086806364592]
	TIME [epoch: 5.72 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07700210409950553		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.07700210409950553 | validation: 0.08912944501968081]
	TIME [epoch: 5.72 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06506544903696578		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.06506544903696578 | validation: 0.10048226439888282]
	TIME [epoch: 5.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06178917543043497		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.06178917543043497 | validation: 0.10930254720402324]
	TIME [epoch: 5.73 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06898373850897596		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.06898373850897596 | validation: 0.07207299365949849]
	TIME [epoch: 5.73 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07476429036281781		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.07476429036281781 | validation: 0.06453228444513325]
	TIME [epoch: 5.72 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09318874386470073		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.09318874386470073 | validation: 0.11461718456250182]
	TIME [epoch: 5.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10453787852543765		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.10453787852543765 | validation: 0.07060426999103633]
	TIME [epoch: 5.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05707261550147501		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.05707261550147501 | validation: 0.06561895761976459]
	TIME [epoch: 5.72 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0700046338773659		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.0700046338773659 | validation: 0.08896126478320256]
	TIME [epoch: 5.72 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15000900669250616		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.15000900669250616 | validation: 0.11989142779626795]
	TIME [epoch: 5.74 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11044848960477258		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.11044848960477258 | validation: 0.25300961636919117]
	TIME [epoch: 5.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13038262294451675		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.13038262294451675 | validation: 0.06643904463938462]
	TIME [epoch: 5.72 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06143235685751947		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.06143235685751947 | validation: 0.12126848445756405]
	TIME [epoch: 5.72 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10182207342427714		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.10182207342427714 | validation: 0.12924906693601793]
	TIME [epoch: 5.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10726436201852492		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.10726436201852492 | validation: 0.14660509583798959]
	TIME [epoch: 5.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10889383778464806		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.10889383778464806 | validation: 0.0591331292542594]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07430647200242615		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.07430647200242615 | validation: 0.10450028842223962]
	TIME [epoch: 5.73 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09514872287943046		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.09514872287943046 | validation: 0.1535476327325844]
	TIME [epoch: 5.71 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09227510641996542		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.09227510641996542 | validation: 0.09581130567809637]
	TIME [epoch: 5.71 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09761401570254721		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.09761401570254721 | validation: 0.09504247393469563]
	TIME [epoch: 5.71 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279162946268041		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.06279162946268041 | validation: 0.0859789360568571]
	TIME [epoch: 5.71 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07027517556244213		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.07027517556244213 | validation: 0.07368104716697664]
	TIME [epoch: 5.74 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07241661701884987		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.07241661701884987 | validation: 0.0998710740944144]
	TIME [epoch: 5.71 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07178239298236329		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.07178239298236329 | validation: 0.056200691375119675]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06631763279729577		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.06631763279729577 | validation: 0.08562771625908659]
	TIME [epoch: 5.71 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06190457517226265		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.06190457517226265 | validation: 0.07116066980785102]
	TIME [epoch: 5.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057904839077856214		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.057904839077856214 | validation: 0.05139654927403747]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_643.pth
	Model improved!!!
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05436532006838318		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.05436532006838318 | validation: 0.06786552817233732]
	TIME [epoch: 5.71 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044158437547871965		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.044158437547871965 | validation: 0.09309042243111186]
	TIME [epoch: 5.73 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08667341281077412		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.08667341281077412 | validation: 0.23083238323314084]
	TIME [epoch: 5.71 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12594269194518215		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.12594269194518215 | validation: 0.07357463069455919]
	TIME [epoch: 5.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05880851385737139		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.05880851385737139 | validation: 0.07745068184281934]
	TIME [epoch: 5.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07291588543451821		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.07291588543451821 | validation: 0.093612939274498]
	TIME [epoch: 5.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952286403539342		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.05952286403539342 | validation: 0.07275529798097777]
	TIME [epoch: 5.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0586148055698591		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.0586148055698591 | validation: 0.06684766790773665]
	TIME [epoch: 5.74 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06849271606579946		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.06849271606579946 | validation: 0.1118170335292652]
	TIME [epoch: 5.71 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08067553637935226		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.08067553637935226 | validation: 0.07428999123154721]
	TIME [epoch: 5.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0621447056046829		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.0621447056046829 | validation: 0.12018452908124705]
	TIME [epoch: 5.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07276159727478308		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.07276159727478308 | validation: 0.08653062715614965]
	TIME [epoch: 5.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05793391522739662		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.05793391522739662 | validation: 0.09875042971033496]
	TIME [epoch: 5.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07309795755148239		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.07309795755148239 | validation: 0.057044754974417806]
	TIME [epoch: 5.71 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0553896062672391		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.0553896062672391 | validation: 0.053228095403347137]
	TIME [epoch: 5.73 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07257458422253288		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.07257458422253288 | validation: 0.079899645256023]
	TIME [epoch: 5.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08500673722093388		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.08500673722093388 | validation: 0.08652172332437619]
	TIME [epoch: 5.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05545094169539949		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.05545094169539949 | validation: 0.07701255132115037]
	TIME [epoch: 5.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06354738567624732		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.06354738567624732 | validation: 0.054104269897933384]
	TIME [epoch: 5.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06410761444863693		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.06410761444863693 | validation: 0.10973914304293236]
	TIME [epoch: 5.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08003688768569679		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.08003688768569679 | validation: 0.06106735428602875]
	TIME [epoch: 5.74 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517867703993517		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.08517867703993517 | validation: 0.07270719439454727]
	TIME [epoch: 5.71 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08011501212391492		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.08011501212391492 | validation: 0.08743921090439118]
	TIME [epoch: 5.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06763565469749644		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.06763565469749644 | validation: 0.05039270080040055]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04425258217032474		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.04425258217032474 | validation: 0.10082838716824602]
	TIME [epoch: 5.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08113093498583537		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.08113093498583537 | validation: 0.1506417226993459]
	TIME [epoch: 5.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0624852019894334		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.0624852019894334 | validation: 0.0737696428758872]
	TIME [epoch: 5.73 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05445906753377794		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.05445906753377794 | validation: 0.04757943686676939]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_671.pth
	Model improved!!!
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0517158243072312		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.0517158243072312 | validation: 0.05632796087563529]
	TIME [epoch: 5.71 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055614886045737624		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.055614886045737624 | validation: 0.07618467135712319]
	TIME [epoch: 5.71 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06202328862561325		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.06202328862561325 | validation: 0.046387543979213]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_674.pth
	Model improved!!!
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04806789424121012		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.04806789424121012 | validation: 0.06445971616570942]
	TIME [epoch: 5.71 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08812154892821017		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.08812154892821017 | validation: 0.12042063738404797]
	TIME [epoch: 5.71 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06857073480700987		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.06857073480700987 | validation: 0.0672667961559165]
	TIME [epoch: 5.75 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08359792283567741		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.08359792283567741 | validation: 0.11394235738780044]
	TIME [epoch: 5.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757593781701153		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.0757593781701153 | validation: 0.07009715434049106]
	TIME [epoch: 5.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06880686722194423		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.06880686722194423 | validation: 0.07679430336039589]
	TIME [epoch: 5.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316303412776741		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.06316303412776741 | validation: 0.07240337647464692]
	TIME [epoch: 5.71 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0688595837887947		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.0688595837887947 | validation: 0.11209173213216328]
	TIME [epoch: 5.72 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0691442926410538		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.0691442926410538 | validation: 0.06950505035052525]
	TIME [epoch: 5.73 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056453763988571805		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.056453763988571805 | validation: 0.060425417556855175]
	TIME [epoch: 5.71 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06852033515661554		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.06852033515661554 | validation: 0.12523442329943354]
	TIME [epoch: 5.71 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1799970662833923		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.1799970662833923 | validation: 0.14280844634842435]
	TIME [epoch: 5.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11624814053579453		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.11624814053579453 | validation: 0.06736898288462313]
	TIME [epoch: 5.71 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057460167216227015		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.057460167216227015 | validation: 0.06148378044070107]
	TIME [epoch: 5.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04072637660492008		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.04072637660492008 | validation: 0.0719468788823857]
	TIME [epoch: 5.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062122396226099275		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.062122396226099275 | validation: 0.05675555225047448]
	TIME [epoch: 5.74 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05039029350635986		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.05039029350635986 | validation: 0.08703189950164385]
	TIME [epoch: 5.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05973177214330519		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.05973177214330519 | validation: 0.11907665979979283]
	TIME [epoch: 5.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0958539922331323		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.0958539922331323 | validation: 0.04637457528260855]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_693.pth
	Model improved!!!
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0424018434048975		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0424018434048975 | validation: 0.061700507969223044]
	TIME [epoch: 5.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05807578245226081		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.05807578245226081 | validation: 0.08016742087584777]
	TIME [epoch: 5.71 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07873706825299809		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.07873706825299809 | validation: 0.061054789299567494]
	TIME [epoch: 5.73 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651880903505562		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.0651880903505562 | validation: 0.038705180200524957]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_697.pth
	Model improved!!!
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347103300643963		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.04347103300643963 | validation: 0.07765241081935169]
	TIME [epoch: 5.72 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05986402689134275		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.05986402689134275 | validation: 0.06962811911824639]
	TIME [epoch: 5.71 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07366519397741819		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.07366519397741819 | validation: 0.1023369642324277]
	TIME [epoch: 5.71 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10072536631638465		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.10072536631638465 | validation: 0.05229791688367258]
	TIME [epoch: 5.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04958202052697109		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.04958202052697109 | validation: 0.05609247431301042]
	TIME [epoch: 5.71 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056933735277443505		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.056933735277443505 | validation: 0.10258191808168217]
	TIME [epoch: 5.74 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08792377129767173		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.08792377129767173 | validation: 0.05579634289194056]
	TIME [epoch: 5.72 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050763215219537666		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.050763215219537666 | validation: 0.09799566026945479]
	TIME [epoch: 5.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06202766282926067		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.06202766282926067 | validation: 0.055077100358323604]
	TIME [epoch: 5.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057857688462347706		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.057857688462347706 | validation: 0.08012235152966454]
	TIME [epoch: 5.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06872863159287505		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.06872863159287505 | validation: 0.03307139794449901]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_708.pth
	Model improved!!!
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04558553457361092		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.04558553457361092 | validation: 0.058171179112913675]
	TIME [epoch: 5.73 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06343698903544108		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.06343698903544108 | validation: 0.04254681128632889]
	TIME [epoch: 5.71 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056554111110761814		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.056554111110761814 | validation: 0.08283569746878913]
	TIME [epoch: 5.71 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054147370784378195		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.054147370784378195 | validation: 0.05055898250185111]
	TIME [epoch: 5.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04739219527411567		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.04739219527411567 | validation: 0.06825492817505585]
	TIME [epoch: 5.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03981723639592266		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.03981723639592266 | validation: 0.06296272551196927]
	TIME [epoch: 5.71 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042273251930976606		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.042273251930976606 | validation: 0.0608191507334139]
	TIME [epoch: 5.71 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06231983936146353		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.06231983936146353 | validation: 0.07811985175717072]
	TIME [epoch: 5.74 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05116384015674967		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.05116384015674967 | validation: 0.04396799331638811]
	TIME [epoch: 5.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04324014266454243		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.04324014266454243 | validation: 0.07422501810522183]
	TIME [epoch: 5.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050627230892086955		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.050627230892086955 | validation: 0.07278129216473576]
	TIME [epoch: 5.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05850311410307399		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.05850311410307399 | validation: 0.0811702893281255]
	TIME [epoch: 5.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05362712631184402		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.05362712631184402 | validation: 0.08715864631997887]
	TIME [epoch: 5.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05919950994968791		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.05919950994968791 | validation: 0.04936780162578657]
	TIME [epoch: 5.72 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046159252500911435		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.046159252500911435 | validation: 0.04581028817835691]
	TIME [epoch: 5.72 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058492285380498985		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.058492285380498985 | validation: 0.07642341763250259]
	TIME [epoch: 5.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06237562266442018		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.06237562266442018 | validation: 0.0730126358734227]
	TIME [epoch: 5.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05446798755167061		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.05446798755167061 | validation: 0.11300492690516127]
	TIME [epoch: 5.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05285221153661061		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.05285221153661061 | validation: 0.07604966970287425]
	TIME [epoch: 5.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06596519228158516		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.06596519228158516 | validation: 0.07193138791062614]
	TIME [epoch: 5.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07421927923043972		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.07421927923043972 | validation: 0.06153834558874239]
	TIME [epoch: 5.76 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784732397227468		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.05784732397227468 | validation: 0.07597194451544355]
	TIME [epoch: 5.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07438612589018613		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.07438612589018613 | validation: 0.06393447239401248]
	TIME [epoch: 5.72 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.066397553630315		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.066397553630315 | validation: 0.11172062624099488]
	TIME [epoch: 5.72 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06735570638153746		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.06735570638153746 | validation: 0.053822165052285986]
	TIME [epoch: 5.72 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05575763169377386		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.05575763169377386 | validation: 0.06628899874110833]
	TIME [epoch: 5.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060653390112228284		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.060653390112228284 | validation: 0.09044938353493384]
	TIME [epoch: 5.72 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05600997539573189		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.05600997539573189 | validation: 0.05184455840614808]
	TIME [epoch: 5.72 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05432212198427053		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.05432212198427053 | validation: 0.10866724657579756]
	TIME [epoch: 5.72 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06894817695174722		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.06894817695174722 | validation: 0.05742543671717112]
	TIME [epoch: 5.72 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04087616137033544		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.04087616137033544 | validation: 0.0674824576681086]
	TIME [epoch: 5.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487558005178197		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.0487558005178197 | validation: 0.0458556466488978]
	TIME [epoch: 5.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03986318154007907		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.03986318154007907 | validation: 0.06033832233725512]
	TIME [epoch: 5.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047435891510374334		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.047435891510374334 | validation: 0.04961195993708942]
	TIME [epoch: 5.74 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05779929614629185		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.05779929614629185 | validation: 0.10638119552976426]
	TIME [epoch: 5.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06175968032851008		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.06175968032851008 | validation: 0.07441577341423979]
	TIME [epoch: 5.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053816151263581996		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.053816151263581996 | validation: 0.05194124255082841]
	TIME [epoch: 5.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0418922396956246		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0418922396956246 | validation: 0.05186829447448466]
	TIME [epoch: 5.71 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04545632635922064		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.04545632635922064 | validation: 0.059607555409511986]
	TIME [epoch: 5.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04412247417637375		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.04412247417637375 | validation: 0.053366255112888415]
	TIME [epoch: 5.72 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06001344939324414		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.06001344939324414 | validation: 0.04907439357389194]
	TIME [epoch: 5.71 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04870809273985412		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.04870809273985412 | validation: 0.06649524870238033]
	TIME [epoch: 5.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054081109899928925		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.054081109899928925 | validation: 0.0889209661742629]
	TIME [epoch: 5.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06070969550736478		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.06070969550736478 | validation: 0.05360573129972459]
	TIME [epoch: 5.71 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05167263359703049		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.05167263359703049 | validation: 0.07367063630219656]
	TIME [epoch: 5.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04475637985110322		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.04475637985110322 | validation: 0.03611740057414114]
	TIME [epoch: 5.72 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047953670892299544		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.047953670892299544 | validation: 0.1292381970611682]
	TIME [epoch: 5.73 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07713149645764521		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.07713149645764521 | validation: 0.06377941818006719]
	TIME [epoch: 5.71 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04156922887978326		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.04156922887978326 | validation: 0.07475002583428132]
	TIME [epoch: 5.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05648388994874354		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.05648388994874354 | validation: 0.058325802607576936]
	TIME [epoch: 5.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019881233659881		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.08019881233659881 | validation: 0.10821894095376987]
	TIME [epoch: 5.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06974867731130746		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.06974867731130746 | validation: 0.052319030165726005]
	TIME [epoch: 5.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03682336464444169		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.03682336464444169 | validation: 0.07192046441282329]
	TIME [epoch: 5.71 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046414927533786725		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.046414927533786725 | validation: 0.04810587305023157]
	TIME [epoch: 5.73 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0440519154844702		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.0440519154844702 | validation: 0.037407784096475646]
	TIME [epoch: 5.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04468600612176005		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.04468600612176005 | validation: 0.06954630285988615]
	TIME [epoch: 5.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05634068354273415		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.05634068354273415 | validation: 0.08948719023125767]
	TIME [epoch: 5.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06872156002429698		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.06872156002429698 | validation: 0.0774906101012033]
	TIME [epoch: 5.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05094465672264732		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.05094465672264732 | validation: 0.04204856380465456]
	TIME [epoch: 5.72 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03453745121222335		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.03453745121222335 | validation: 0.05561441897720721]
	TIME [epoch: 5.75 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061201049839927954		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.061201049839927954 | validation: 0.06167053803605706]
	TIME [epoch: 5.71 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05717146877432423		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.05717146877432423 | validation: 0.1144994349908032]
	TIME [epoch: 5.71 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08803216960768297		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.08803216960768297 | validation: 0.09075034537159729]
	TIME [epoch: 5.71 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07344204825352793		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.07344204825352793 | validation: 0.050441947347662934]
	TIME [epoch: 5.71 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043177643486595314		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.043177643486595314 | validation: 0.05004526122056253]
	TIME [epoch: 5.69 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04855428428183166		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.04855428428183166 | validation: 0.056781802600783166]
	TIME [epoch: 5.72 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03874946378432122		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.03874946378432122 | validation: 0.0896649291646167]
	TIME [epoch: 5.75 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913469614029067		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.05913469614029067 | validation: 0.09876532562977977]
	TIME [epoch: 5.72 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053796405304135445		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.053796405304135445 | validation: 0.038141981343532985]
	TIME [epoch: 5.71 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03705816335539857		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.03705816335539857 | validation: 0.034131662921844275]
	TIME [epoch: 5.71 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05723469880990608		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.05723469880990608 | validation: 0.08181684644833696]
	TIME [epoch: 5.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05377541063216365		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.05377541063216365 | validation: 0.046878085780376035]
	TIME [epoch: 5.71 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04343679794575978		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.04343679794575978 | validation: 0.05478417432782046]
	TIME [epoch: 5.74 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05267373882772776		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.05267373882772776 | validation: 0.05580420777157528]
	TIME [epoch: 5.75 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042394777200038244		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.042394777200038244 | validation: 0.04216896663785549]
	TIME [epoch: 5.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03682207586123913		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.03682207586123913 | validation: 0.0689609186743743]
	TIME [epoch: 5.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07019252921375914		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.07019252921375914 | validation: 0.05596864135623102]
	TIME [epoch: 5.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04152760792827449		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.04152760792827449 | validation: 0.0374906029083729]
	TIME [epoch: 5.71 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036763130437383676		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.036763130437383676 | validation: 0.06440636421270378]
	TIME [epoch: 5.71 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046872316996090374		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.046872316996090374 | validation: 0.03834096857266785]
	TIME [epoch: 5.74 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03172753511496472		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.03172753511496472 | validation: 0.04532880281487667]
	TIME [epoch: 5.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367859464983883		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.06367859464983883 | validation: 0.0405550444400844]
	TIME [epoch: 5.71 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356666931253588		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.06356666931253588 | validation: 0.07924696166168924]
	TIME [epoch: 5.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04470196381529924		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.04470196381529924 | validation: 0.05813534128033457]
	TIME [epoch: 5.71 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05639787843786686		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.05639787843786686 | validation: 0.030981775885784737]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_793.pth
	Model improved!!!
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06532975345345055		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.06532975345345055 | validation: 0.08686863616868763]
	TIME [epoch: 5.75 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04957865350024802		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.04957865350024802 | validation: 0.03935409445670005]
	TIME [epoch: 5.71 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034735622618950204		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.034735622618950204 | validation: 0.031056949917082577]
	TIME [epoch: 5.71 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03970468880415175		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.03970468880415175 | validation: 0.051159594000063646]
	TIME [epoch: 5.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047366826720819724		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.047366826720819724 | validation: 0.0750207118742363]
	TIME [epoch: 5.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07648790406723273		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.07648790406723273 | validation: 0.12671860184670714]
	TIME [epoch: 5.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07311065447128033		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.07311065447128033 | validation: 0.03811230978592405]
	TIME [epoch: 5.71 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04371384249010321		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.04371384249010321 | validation: 0.04231163216148955]
	TIME [epoch: 5.73 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04824671761772131		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.04824671761772131 | validation: 0.07317436443996479]
	TIME [epoch: 5.71 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060933936966236		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.060933936966236 | validation: 0.08244725699592664]
	TIME [epoch: 5.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0499088965200674		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.0499088965200674 | validation: 0.05426228220986353]
	TIME [epoch: 5.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04394622919402055		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.04394622919402055 | validation: 0.07559085062880957]
	TIME [epoch: 5.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0589172549718356		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.0589172549718356 | validation: 0.0648520946226631]
	TIME [epoch: 5.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06174280764036643		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.06174280764036643 | validation: 0.048676422953282276]
	TIME [epoch: 5.74 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036426405663009455		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.036426405663009455 | validation: 0.07859817720519231]
	TIME [epoch: 5.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06942834829757052		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.06942834829757052 | validation: 0.06009577509472683]
	TIME [epoch: 5.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03898328365168772		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.03898328365168772 | validation: 0.05113320417641946]
	TIME [epoch: 5.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04094600337510817		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.04094600337510817 | validation: 0.0633279941457868]
	TIME [epoch: 5.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04952524478439229		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.04952524478439229 | validation: 0.03548388848290145]
	TIME [epoch: 5.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04280987213621264		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04280987213621264 | validation: 0.11509147529987178]
	TIME [epoch: 5.71 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10606456749618604		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.10606456749618604 | validation: 0.059000275608473415]
	TIME [epoch: 5.73 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05998204992159627		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.05998204992159627 | validation: 0.04854398652467173]
	TIME [epoch: 5.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0448967924288134		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.0448967924288134 | validation: 0.0468921129700256]
	TIME [epoch: 5.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04366157910911715		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.04366157910911715 | validation: 0.049205072320770774]
	TIME [epoch: 5.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04419386207054874		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.04419386207054874 | validation: 0.046903588882145256]
	TIME [epoch: 5.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05879296858345946		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.05879296858345946 | validation: 0.0565614220246046]
	TIME [epoch: 5.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03800043149716375		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.03800043149716375 | validation: 0.04286758677839863]
	TIME [epoch: 5.74 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032343385247956394		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.032343385247956394 | validation: 0.04473409990727808]
	TIME [epoch: 5.71 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0449949747141353		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.0449949747141353 | validation: 0.06263485590040765]
	TIME [epoch: 5.71 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05284488319927967		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.05284488319927967 | validation: 0.0798326979996105]
	TIME [epoch: 5.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060827884266714		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.060827884266714 | validation: 0.04810234990220983]
	TIME [epoch: 5.71 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0369008997385266		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0369008997385266 | validation: 0.050192653513557825]
	TIME [epoch: 5.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045909399862080605		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.045909399862080605 | validation: 0.04468272673721188]
	TIME [epoch: 5.71 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04814134998626914		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.04814134998626914 | validation: 0.059930183685665495]
	TIME [epoch: 5.76 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042849669571280544		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.042849669571280544 | validation: 0.056286158015949946]
	TIME [epoch: 5.71 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07516797850158927		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.07516797850158927 | validation: 0.08384404071936061]
	TIME [epoch: 5.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060675276220636565		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.060675276220636565 | validation: 0.052722991838382034]
	TIME [epoch: 5.71 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046476743330490955		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.046476743330490955 | validation: 0.048301579747551414]
	TIME [epoch: 5.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314210934369034		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.0314210934369034 | validation: 0.0419619782922711]
	TIME [epoch: 5.71 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033374495107601446		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.033374495107601446 | validation: 0.04660255211006103]
	TIME [epoch: 5.72 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042194883511658655		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.042194883511658655 | validation: 0.04419590869748768]
	TIME [epoch: 5.74 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04080226672238294		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.04080226672238294 | validation: 0.053580867558350925]
	TIME [epoch: 5.72 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05848938449116505		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.05848938449116505 | validation: 0.042062571650113484]
	TIME [epoch: 5.71 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040108439702760804		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.040108439702760804 | validation: 0.06843740180648185]
	TIME [epoch: 5.7 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04489213243607321		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.04489213243607321 | validation: 0.03757420888696757]
	TIME [epoch: 5.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027744085510373776		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.027744085510373776 | validation: 0.039318556678646435]
	TIME [epoch: 5.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03022829041236954		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.03022829041236954 | validation: 0.04229243457943582]
	TIME [epoch: 5.74 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06178542744247595		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.06178542744247595 | validation: 0.044191838619584096]
	TIME [epoch: 5.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04042094033048744		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.04042094033048744 | validation: 0.06936913776889174]
	TIME [epoch: 5.71 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05531809811322369		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.05531809811322369 | validation: 0.059094882461065916]
	TIME [epoch: 5.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043025133432850825		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.043025133432850825 | validation: 0.040747323743101214]
	TIME [epoch: 5.71 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040037357548747404		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.040037357548747404 | validation: 0.04838653568334708]
	TIME [epoch: 5.71 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320362035314672		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.03320362035314672 | validation: 0.036748125961563065]
	TIME [epoch: 5.74 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033934630304959586		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.033934630304959586 | validation: 0.0618171612120829]
	TIME [epoch: 5.72 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04343091797365676		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.04343091797365676 | validation: 0.03978281531025466]
	TIME [epoch: 5.72 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03741641275558223		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.03741641275558223 | validation: 0.06680930841126412]
	TIME [epoch: 5.72 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03764811392343649		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.03764811392343649 | validation: 0.04086346889941199]
	TIME [epoch: 5.71 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03396366472217198		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.03396366472217198 | validation: 0.05004065208800249]
	TIME [epoch: 5.71 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030913828561203883		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.030913828561203883 | validation: 0.05244569851510294]
	TIME [epoch: 5.71 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040909849425666736		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.040909849425666736 | validation: 0.043010880166391575]
	TIME [epoch: 5.76 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045437980044273046		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.045437980044273046 | validation: 0.03343493163939035]
	TIME [epoch: 5.71 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02904158533949786		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.02904158533949786 | validation: 0.03406461586818544]
	TIME [epoch: 5.71 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034707199617087424		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.034707199617087424 | validation: 0.06927597991271549]
	TIME [epoch: 5.72 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06255273298039432		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.06255273298039432 | validation: 0.04658263541872598]
	TIME [epoch: 5.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034071307264869725		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.034071307264869725 | validation: 0.05202854945995533]
	TIME [epoch: 5.71 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03183342541852329		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.03183342541852329 | validation: 0.062038298127974886]
	TIME [epoch: 5.72 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038052454715975334		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.038052454715975334 | validation: 0.03660422902167843]
	TIME [epoch: 5.71 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029380191909528546		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.029380191909528546 | validation: 0.05097279818557473]
	TIME [epoch: 5.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040130005433596835		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.040130005433596835 | validation: 0.04151478229708588]
	TIME [epoch: 5.71 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924871941291323		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.03924871941291323 | validation: 0.05658536456612164]
	TIME [epoch: 5.71 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03536926826027262		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.03536926826027262 | validation: 0.042873799825079446]
	TIME [epoch: 5.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04389553560649357		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.04389553560649357 | validation: 0.04410686751880113]
	TIME [epoch: 5.72 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228495928478042		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.12228495928478042 | validation: 0.08941480201199124]
	TIME [epoch: 5.74 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06129631013698945		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.06129631013698945 | validation: 0.03646966870215728]
	TIME [epoch: 5.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04117477620957852		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.04117477620957852 | validation: 0.07005902719026667]
	TIME [epoch: 5.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041159659993922945		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.041159659993922945 | validation: 0.03550296327820129]
	TIME [epoch: 5.72 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033160920920237764		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.033160920920237764 | validation: 0.05101637134363451]
	TIME [epoch: 5.71 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059295252141893455		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.059295252141893455 | validation: 0.045757657327504274]
	TIME [epoch: 5.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05129999688395029		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.05129999688395029 | validation: 0.07113728092506745]
	TIME [epoch: 5.74 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04830343955728224		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.04830343955728224 | validation: 0.05558517267197789]
	TIME [epoch: 5.72 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039832827863794495		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.039832827863794495 | validation: 0.04093013163494355]
	TIME [epoch: 5.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03599903707675982		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.03599903707675982 | validation: 0.04194878004778745]
	TIME [epoch: 5.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042475785757194545		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.042475785757194545 | validation: 0.04759181805463793]
	TIME [epoch: 5.72 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035173790057637655		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.035173790057637655 | validation: 0.04445210233808929]
	TIME [epoch: 5.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03560520402452523		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.03560520402452523 | validation: 0.05903477305737009]
	TIME [epoch: 5.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047548830707753426		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.047548830707753426 | validation: 0.06420047379934232]
	TIME [epoch: 5.74 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04465440690650904		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.04465440690650904 | validation: 0.04810253101885046]
	TIME [epoch: 5.71 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025119779975048127		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.025119779975048127 | validation: 0.03858963718666736]
	TIME [epoch: 5.72 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03628172999854189		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.03628172999854189 | validation: 0.03967683893818067]
	TIME [epoch: 5.71 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026190854771454487		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.026190854771454487 | validation: 0.049174444223813146]
	TIME [epoch: 5.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03821385422748946		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.03821385422748946 | validation: 0.050842785813294336]
	TIME [epoch: 5.71 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0403770413214718		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.0403770413214718 | validation: 0.046268095549394046]
	TIME [epoch: 5.71 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04211508880590521		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.04211508880590521 | validation: 0.08279211730971593]
	TIME [epoch: 5.74 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06895412143694216		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.06895412143694216 | validation: 0.07574061477439772]
	TIME [epoch: 5.72 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05029773449794486		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.05029773449794486 | validation: 0.039603154582403745]
	TIME [epoch: 5.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027941037529653708		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.027941037529653708 | validation: 0.04701935142927077]
	TIME [epoch: 5.72 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029798443850808272		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.029798443850808272 | validation: 0.04729364179065966]
	TIME [epoch: 5.71 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04072150992863295		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.04072150992863295 | validation: 0.045494586119474434]
	TIME [epoch: 5.71 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043842275312211264		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.043842275312211264 | validation: 0.043344407443824465]
	TIME [epoch: 5.75 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030078244767525963		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.030078244767525963 | validation: 0.05426324074437494]
	TIME [epoch: 5.71 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042894203654658396		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.042894203654658396 | validation: 0.051076810121333374]
	TIME [epoch: 5.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034603480881975256		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.034603480881975256 | validation: 0.038698026101604645]
	TIME [epoch: 5.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326248884874753		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.0326248884874753 | validation: 0.044526239535564026]
	TIME [epoch: 5.72 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035636375197415554		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.035636375197415554 | validation: 0.04656986707184823]
	TIME [epoch: 5.71 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08616769975329583		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.08616769975329583 | validation: 0.1123372557547802]
	TIME [epoch: 5.73 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.079221241790187		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.079221241790187 | validation: 0.04874878829444649]
	TIME [epoch: 5.74 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029414759426539705		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.029414759426539705 | validation: 0.032781374975964186]
	TIME [epoch: 5.72 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037101960766495676		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.037101960766495676 | validation: 0.05201770931763173]
	TIME [epoch: 5.71 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03604013202335327		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.03604013202335327 | validation: 0.03928216768092795]
	TIME [epoch: 5.71 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03491442333066602		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.03491442333066602 | validation: 0.05718146266556893]
	TIME [epoch: 5.71 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04338205665684204		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.04338205665684204 | validation: 0.08316023665678855]
	TIME [epoch: 5.72 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08508868080806964		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08508868080806964 | validation: 0.05889181873160271]
	TIME [epoch: 5.75 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740553750708344		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.03740553750708344 | validation: 0.03791059706460927]
	TIME [epoch: 5.72 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03417437072162398		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.03417437072162398 | validation: 0.0628876904222421]
	TIME [epoch: 5.71 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04184861449154882		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.04184861449154882 | validation: 0.035013166056486834]
	TIME [epoch: 5.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0308987499266325		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.0308987499266325 | validation: 0.033323786294745895]
	TIME [epoch: 5.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032457792729996715		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.032457792729996715 | validation: 0.0343573023432877]
	TIME [epoch: 5.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032040734593510964		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.032040734593510964 | validation: 0.03438753432317552]
	TIME [epoch: 5.71 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03693898437167904		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.03693898437167904 | validation: 0.06986858511841933]
	TIME [epoch: 5.74 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04180854403410308		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.04180854403410308 | validation: 0.031093146957803148]
	TIME [epoch: 5.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031114853664334453		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.031114853664334453 | validation: 0.07231317151162422]
	TIME [epoch: 5.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04600945888497248		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.04600945888497248 | validation: 0.04093923023074287]
	TIME [epoch: 5.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036034741788811504		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.036034741788811504 | validation: 0.03370730861623399]
	TIME [epoch: 5.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03988982606929935		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.03988982606929935 | validation: 0.057192341407059394]
	TIME [epoch: 5.71 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0363812079753073		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.0363812079753073 | validation: 0.03298875526448198]
	TIME [epoch: 5.73 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02617619254122027		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.02617619254122027 | validation: 0.04404632170936009]
	TIME [epoch: 5.72 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04433040990974067		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.04433040990974067 | validation: 0.05308321100899476]
	TIME [epoch: 5.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02781758875201714		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.02781758875201714 | validation: 0.03841165937141013]
	TIME [epoch: 5.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023979210570043555		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.023979210570043555 | validation: 0.05351982806869488]
	TIME [epoch: 5.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047385044084677565		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.047385044084677565 | validation: 0.05931518515957327]
	TIME [epoch: 5.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029345566597940596		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.029345566597940596 | validation: 0.03307463320433862]
	TIME [epoch: 5.71 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03435562363328408		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.03435562363328408 | validation: 0.06488001917017092]
	TIME [epoch: 5.73 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04539878771197932		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.04539878771197932 | validation: 0.030083772161370943]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_926.pth
	Model improved!!!
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02676148657027054		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.02676148657027054 | validation: 0.04651588344584637]
	TIME [epoch: 5.72 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036274610221815294		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.036274610221815294 | validation: 0.04684469167469486]
	TIME [epoch: 5.72 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028099915056809397		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.028099915056809397 | validation: 0.036601618247491134]
	TIME [epoch: 5.72 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030143270811193237		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.030143270811193237 | validation: 0.033445067460761486]
	TIME [epoch: 5.72 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04061169255044254		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.04061169255044254 | validation: 0.03701998902862565]
	TIME [epoch: 5.76 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029848368111404594		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.029848368111404594 | validation: 0.029161784457382597]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_932.pth
	Model improved!!!
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025879721167247474		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.025879721167247474 | validation: 0.029981656433082832]
	TIME [epoch: 5.72 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028418648900159455		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.028418648900159455 | validation: 0.04115364727711003]
	TIME [epoch: 5.72 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03169684606791294		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.03169684606791294 | validation: 0.04820802271340172]
	TIME [epoch: 5.72 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04281378755259449		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.04281378755259449 | validation: 0.036191599208551854]
	TIME [epoch: 5.72 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0379179364104603		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.0379179364104603 | validation: 0.0426725157597696]
	TIME [epoch: 5.76 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034471278639604905		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.034471278639604905 | validation: 0.03312174785519727]
	TIME [epoch: 5.72 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040667916431230355		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.040667916431230355 | validation: 0.03515650695614173]
	TIME [epoch: 5.72 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03234602526066445		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.03234602526066445 | validation: 0.07432048358198984]
	TIME [epoch: 5.72 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03580644079985411		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.03580644079985411 | validation: 0.035771133024202366]
	TIME [epoch: 5.72 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04308838571005732		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.04308838571005732 | validation: 0.035294914181210925]
	TIME [epoch: 5.72 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022077240557231308		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.022077240557231308 | validation: 0.03757080397755627]
	TIME [epoch: 5.74 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024419583936331694		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.024419583936331694 | validation: 0.03212396089610705]
	TIME [epoch: 5.73 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02652931509445748		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.02652931509445748 | validation: 0.04301955541916866]
	TIME [epoch: 5.72 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02512177166665263		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.02512177166665263 | validation: 0.038647335304515786]
	TIME [epoch: 5.72 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03106591151438482		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.03106591151438482 | validation: 0.06402457088688648]
	TIME [epoch: 5.72 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056208933210502056		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.056208933210502056 | validation: 0.05809760349721719]
	TIME [epoch: 5.72 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04424507573145049		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.04424507573145049 | validation: 0.05179423754867926]
	TIME [epoch: 5.72 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03380585593682743		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.03380585593682743 | validation: 0.03228567880821131]
	TIME [epoch: 5.76 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03785624344665622		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.03785624344665622 | validation: 0.07149053699165923]
	TIME [epoch: 5.72 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429362667599045		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.05429362667599045 | validation: 0.048880955438024946]
	TIME [epoch: 5.72 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02812115915229471		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.02812115915229471 | validation: 0.037731613195888504]
	TIME [epoch: 5.72 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042009845037220814		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.042009845037220814 | validation: 0.04633456858479519]
	TIME [epoch: 5.72 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029370008078966805		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.029370008078966805 | validation: 0.04629014383008373]
	TIME [epoch: 5.72 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03793149288009691		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.03793149288009691 | validation: 0.05189561635928713]
	TIME [epoch: 5.73 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03859855571172015		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.03859855571172015 | validation: 0.056498185762496975]
	TIME [epoch: 5.74 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03735598541633624		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.03735598541633624 | validation: 0.039614240022367214]
	TIME [epoch: 5.72 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03455644038136661		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.03455644038136661 | validation: 0.05840539376432792]
	TIME [epoch: 5.72 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035783188361143095		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.035783188361143095 | validation: 0.030280974323866033]
	TIME [epoch: 5.72 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023791572727314872		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.023791572727314872 | validation: 0.03549518712428358]
	TIME [epoch: 5.72 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028663872973537747		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.028663872973537747 | validation: 0.03691219266078547]
	TIME [epoch: 5.72 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034810957659248014		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.034810957659248014 | validation: 0.03204357940724077]
	TIME [epoch: 5.75 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042382892462017416		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.042382892462017416 | validation: 0.05791094182975283]
	TIME [epoch: 5.72 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04763347242364663		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.04763347242364663 | validation: 0.0463094351656496]
	TIME [epoch: 5.72 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031071535753471356		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.031071535753471356 | validation: 0.036204618371190905]
	TIME [epoch: 5.72 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03200438234368304		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.03200438234368304 | validation: 0.0437003538172894]
	TIME [epoch: 5.72 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03540324751706423		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.03540324751706423 | validation: 0.07336040669634629]
	TIME [epoch: 5.72 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03938588854493726		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.03938588854493726 | validation: 0.035673111498903724]
	TIME [epoch: 5.73 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024776200416693556		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.024776200416693556 | validation: 0.02559983079541074]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_970.pth
	Model improved!!!
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026520823204709748		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.026520823204709748 | validation: 0.029367455085942098]
	TIME [epoch: 5.72 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590674131647056		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.04590674131647056 | validation: 0.034568172119920665]
	TIME [epoch: 5.72 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02915596183462925		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.02915596183462925 | validation: 0.027683159743042945]
	TIME [epoch: 5.72 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026958315308842278		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.026958315308842278 | validation: 0.0633058451112453]
	TIME [epoch: 5.72 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030140308783015456		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.030140308783015456 | validation: 0.02809610791246748]
	TIME [epoch: 5.72 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02545998995035271		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.02545998995035271 | validation: 0.035201122249949805]
	TIME [epoch: 5.75 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029835049036494178		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.029835049036494178 | validation: 0.05333005340754125]
	TIME [epoch: 5.72 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320927364367327		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.03320927364367327 | validation: 0.033231307561207575]
	TIME [epoch: 5.72 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02233869723489386		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.02233869723489386 | validation: 0.039468637126700824]
	TIME [epoch: 5.72 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158788090368503		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.03158788090368503 | validation: 0.041322683277176725]
	TIME [epoch: 5.72 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02175012488740083		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.02175012488740083 | validation: 0.03188198204841587]
	TIME [epoch: 5.72 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02855208436026349		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.02855208436026349 | validation: 0.030833095668942004]
	TIME [epoch: 5.74 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02882848162345703		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.02882848162345703 | validation: 0.04153204914451277]
	TIME [epoch: 5.73 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024775924214890187		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.024775924214890187 | validation: 0.03148900954522416]
	TIME [epoch: 5.72 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030760066654850326		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.030760066654850326 | validation: 0.041234840015315515]
	TIME [epoch: 5.72 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03340978842424263		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.03340978842424263 | validation: 0.05351706134150641]
	TIME [epoch: 5.72 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03554438241752943		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.03554438241752943 | validation: 0.04220770628410664]
	TIME [epoch: 5.72 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027082101734774544		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.027082101734774544 | validation: 0.04022085835396757]
	TIME [epoch: 5.72 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02841607412580162		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.02841607412580162 | validation: 0.02380466511897639]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029035098734249483		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.029035098734249483 | validation: 0.03214357450013573]
	TIME [epoch: 5.72 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02629228883075727		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.02629228883075727 | validation: 0.04147553132440223]
	TIME [epoch: 5.72 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03052904114724885		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.03052904114724885 | validation: 0.041756044098897716]
	TIME [epoch: 5.72 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025663308929575166		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.025663308929575166 | validation: 0.03655955008717729]
	TIME [epoch: 5.72 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027724463809715032		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.027724463809715032 | validation: 0.027246553219703495]
	TIME [epoch: 5.72 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022982264861324254		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.022982264861324254 | validation: 0.02962111378070853]
	TIME [epoch: 5.74 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03115578347176707		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.03115578347176707 | validation: 0.05090528835337277]
	TIME [epoch: 5.73 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036721017213248504		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.036721017213248504 | validation: 0.029772144554914438]
	TIME [epoch: 5.72 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02743301678240072		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.02743301678240072 | validation: 0.04561258875558084]
	TIME [epoch: 5.72 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054049381083526506		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.054049381083526506 | validation: 0.06444628165824032]
	TIME [epoch: 5.72 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033787802737219895		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.033787802737219895 | validation: 0.02532274874675734]
	TIME [epoch: 5.72 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03111805474848273		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.03111805474848273 | validation: 0.030117803860744793]
	TIME [epoch: 5.72 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022275474957391347		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.022275474957391347 | validation: 0.026355597749101563]
	TIME [epoch: 5.76 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027248777987717097		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.027248777987717097 | validation: 0.029356861349860965]
	TIME [epoch: 5.72 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023302048839155758		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.023302048839155758 | validation: 0.03801966500291882]
	TIME [epoch: 5.72 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04410294329517445		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.04410294329517445 | validation: 0.04519037275984914]
	TIME [epoch: 5.72 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03846322635637972		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.03846322635637972 | validation: 0.048596491886966575]
	TIME [epoch: 5.72 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028309694016644574		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.028309694016644574 | validation: 0.058460072645872094]
	TIME [epoch: 5.72 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02898366245916152		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.02898366245916152 | validation: 0.027561553649265463]
	TIME [epoch: 5.74 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024869720464230284		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.024869720464230284 | validation: 0.054845592670541336]
	TIME [epoch: 5.74 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023543947003395314		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.023543947003395314 | validation: 0.02385978363394707]
	TIME [epoch: 5.72 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0186999518722663		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0186999518722663 | validation: 0.04242569815021081]
	TIME [epoch: 5.72 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02689202279639903		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.02689202279639903 | validation: 0.04318964508700063]
	TIME [epoch: 5.72 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039864852953057195		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.039864852953057195 | validation: 0.05833078366688751]
	TIME [epoch: 5.72 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03518850830574745		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.03518850830574745 | validation: 0.03798965588082471]
	TIME [epoch: 5.72 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0261885618469931		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0261885618469931 | validation: 0.036243196820042164]
	TIME [epoch: 5.76 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028590284036056228		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.028590284036056228 | validation: 0.04436116127891145]
	TIME [epoch: 5.72 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022458018694257818		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.022458018694257818 | validation: 0.04192675113372433]
	TIME [epoch: 5.72 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023682346673205196		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.023682346673205196 | validation: 0.038638320684811676]
	TIME [epoch: 5.72 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03091206890035151		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.03091206890035151 | validation: 0.05237041967890685]
	TIME [epoch: 5.72 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03492652892224363		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.03492652892224363 | validation: 0.03057834000203272]
	TIME [epoch: 5.72 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022371307437973408		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.022371307437973408 | validation: 0.03874383176025306]
	TIME [epoch: 5.74 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027619357222660224		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.027619357222660224 | validation: 0.04102566907411516]
	TIME [epoch: 5.74 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02981127796338188		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.02981127796338188 | validation: 0.04836036627965038]
	TIME [epoch: 5.73 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025130826033685008		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.025130826033685008 | validation: 0.02953736192597091]
	TIME [epoch: 5.72 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02546341249294634		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.02546341249294634 | validation: 0.041674848697627394]
	TIME [epoch: 5.72 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02385593058175135		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.02385593058175135 | validation: 0.04258985349019628]
	TIME [epoch: 5.72 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025980655766649874		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.025980655766649874 | validation: 0.037408004361509664]
	TIME [epoch: 5.72 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020905218156189558		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.020905218156189558 | validation: 0.027741745921122933]
	TIME [epoch: 5.76 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01963209526523485		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.01963209526523485 | validation: 0.02912325619401701]
	TIME [epoch: 5.73 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032470377318311074		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.032470377318311074 | validation: 0.04977127779115812]
	TIME [epoch: 5.72 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05165341881582911		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.05165341881582911 | validation: 0.043594304859109985]
	TIME [epoch: 5.72 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03011565808523046		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.03011565808523046 | validation: 0.02515596011208026]
	TIME [epoch: 5.72 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020336049458079365		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.020336049458079365 | validation: 0.024462405915881266]
	TIME [epoch: 5.72 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237690288599203		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.03237690288599203 | validation: 0.034749076491847546]
	TIME [epoch: 5.75 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030159133750096483		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.030159133750096483 | validation: 0.05120640657467695]
	TIME [epoch: 5.74 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031145467726947623		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.031145467726947623 | validation: 0.04005926689402605]
	TIME [epoch: 5.72 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022335053912311147		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.022335053912311147 | validation: 0.030856054632949305]
	TIME [epoch: 5.72 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024838056552725432		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.024838056552725432 | validation: 0.0377275835107028]
	TIME [epoch: 5.72 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02429360794194746		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.02429360794194746 | validation: 0.04201354779989586]
	TIME [epoch: 5.72 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033556250151061486		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.033556250151061486 | validation: 0.04003798323420297]
	TIME [epoch: 5.72 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021273105872664275		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.021273105872664275 | validation: 0.02855062279309401]
	TIME [epoch: 5.76 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019308555318878155		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.019308555318878155 | validation: 0.03796899989298811]
	TIME [epoch: 5.72 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029978821433949036		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.029978821433949036 | validation: 0.027115619210699316]
	TIME [epoch: 5.72 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02757240280262351		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.02757240280262351 | validation: 0.025728465050134215]
	TIME [epoch: 5.72 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024959281241031396		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.024959281241031396 | validation: 0.03446499584485815]
	TIME [epoch: 5.72 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02434864032689109		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.02434864032689109 | validation: 0.046321583729567205]
	TIME [epoch: 5.72 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02931864531543485		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.02931864531543485 | validation: 0.030020574492043144]
	TIME [epoch: 5.74 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02413484002414853		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.02413484002414853 | validation: 0.030279166924471097]
	TIME [epoch: 5.73 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021560276295821315		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.021560276295821315 | validation: 0.041525901335242595]
	TIME [epoch: 5.72 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025367392473315018		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.025367392473315018 | validation: 0.03915363538736991]
	TIME [epoch: 5.72 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020739801437895534		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.020739801437895534 | validation: 0.027090212215637646]
	TIME [epoch: 5.72 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02486186219576472		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.02486186219576472 | validation: 0.021913973717837577]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_1052.pth
	Model improved!!!
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02884542692339474		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.02884542692339474 | validation: 0.030932148562495307]
	TIME [epoch: 5.72 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026961161975000935		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.026961161975000935 | validation: 0.03335367613501923]
	TIME [epoch: 5.76 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02804462533619856		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.02804462533619856 | validation: 0.03530110076624741]
	TIME [epoch: 5.72 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026502044854368863		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.026502044854368863 | validation: 0.02347827753740651]
	TIME [epoch: 5.72 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01927965933582143		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.01927965933582143 | validation: 0.032915746097614114]
	TIME [epoch: 5.71 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02219134092198508		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.02219134092198508 | validation: 0.030750305702483254]
	TIME [epoch: 5.71 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021417890311385794		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.021417890311385794 | validation: 0.018202666545371324]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_1059.pth
	Model improved!!!
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022759141542320747		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.022759141542320747 | validation: 0.0341563207064339]
	TIME [epoch: 5.75 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02369815423492072		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.02369815423492072 | validation: 0.028363532478485394]
	TIME [epoch: 5.72 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02239164362402871		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.02239164362402871 | validation: 0.029230682811444]
	TIME [epoch: 5.72 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018477379703182854		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.018477379703182854 | validation: 0.02719197919955537]
	TIME [epoch: 5.72 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03460574052368157		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.03460574052368157 | validation: 0.04722760156101065]
	TIME [epoch: 5.72 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033935093714516154		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.033935093714516154 | validation: 0.03918424867620504]
	TIME [epoch: 5.71 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02701192276822546		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.02701192276822546 | validation: 0.03276680873513972]
	TIME [epoch: 5.72 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020841603406409313		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.020841603406409313 | validation: 0.040010545950217156]
	TIME [epoch: 5.75 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021649259672345357		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.021649259672345357 | validation: 0.028782279746050327]
	TIME [epoch: 5.72 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025538823143725235		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.025538823143725235 | validation: 0.04104543932448833]
	TIME [epoch: 5.71 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04061606132696039		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.04061606132696039 | validation: 0.04996035017427957]
	TIME [epoch: 5.71 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041052320742244304		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.041052320742244304 | validation: 0.03867100269752294]
	TIME [epoch: 5.71 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025820953884842023		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.025820953884842023 | validation: 0.03421842413670449]
	TIME [epoch: 5.72 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01967874856626362		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.01967874856626362 | validation: 0.03726771768064355]
	TIME [epoch: 5.74 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024186906705259283		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.024186906705259283 | validation: 0.02542059234733843]
	TIME [epoch: 5.73 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02832163887840173		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.02832163887840173 | validation: 0.03302027908615812]
	TIME [epoch: 5.72 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027184570776207555		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.027184570776207555 | validation: 0.036571969876948496]
	TIME [epoch: 5.71 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01636949431339682		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.01636949431339682 | validation: 0.03118209122533161]
	TIME [epoch: 5.71 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03724683093170774		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03724683093170774 | validation: 0.04430345999845328]
	TIME [epoch: 5.71 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02612927892847259		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.02612927892847259 | validation: 0.026566849971388883]
	TIME [epoch: 5.71 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019841260063104244		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.019841260063104244 | validation: 0.024447908734757464]
	TIME [epoch: 5.75 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020194627732109897		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.020194627732109897 | validation: 0.023345089927200902]
	TIME [epoch: 5.71 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017336928968784023		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.017336928968784023 | validation: 0.015205085994225999]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_1082.pth
	Model improved!!!
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018718540603829933		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.018718540603829933 | validation: 0.03410454871262497]
	TIME [epoch: 5.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021645630778313996		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.021645630778313996 | validation: 0.03399895218738574]
	TIME [epoch: 5.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023962172692237466		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.023962172692237466 | validation: 0.027868694477019524]
	TIME [epoch: 5.71 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025758494166551234		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.025758494166551234 | validation: 0.02798740957091447]
	TIME [epoch: 5.73 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022601555306672932		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.022601555306672932 | validation: 0.03163928652337868]
	TIME [epoch: 5.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02392189939609427		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.02392189939609427 | validation: 0.03672861221342763]
	TIME [epoch: 5.69 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028858622948893322		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.028858622948893322 | validation: 0.03420310818583216]
	TIME [epoch: 5.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03053624124126065		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.03053624124126065 | validation: 0.031891346403905875]
	TIME [epoch: 5.69 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023468317802243753		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.023468317802243753 | validation: 0.029644467964746006]
	TIME [epoch: 5.69 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01859499598839947		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.01859499598839947 | validation: 0.030599512745295775]
	TIME [epoch: 5.72 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018859478386648927		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.018859478386648927 | validation: 0.03220788944537907]
	TIME [epoch: 5.72 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02985617458501165		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.02985617458501165 | validation: 0.047513124178823606]
	TIME [epoch: 5.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02784653809416713		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.02784653809416713 | validation: 0.039726917048601935]
	TIME [epoch: 5.69 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02118218889673283		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.02118218889673283 | validation: 0.0392377530017905]
	TIME [epoch: 5.69 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03321259947717704		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.03321259947717704 | validation: 0.03872156500039335]
	TIME [epoch: 5.69 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021431717104365484		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.021431717104365484 | validation: 0.02176506330413079]
	TIME [epoch: 5.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02232599282860311		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.02232599282860311 | validation: 0.03213918184545704]
	TIME [epoch: 5.72 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0287295203162444		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.0287295203162444 | validation: 0.03513611075678386]
	TIME [epoch: 5.71 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02958796415697077		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.02958796415697077 | validation: 0.03860241931166171]
	TIME [epoch: 5.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031167785603202398		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.031167785603202398 | validation: 0.04129347378555769]
	TIME [epoch: 5.69 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02484885278635088		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.02484885278635088 | validation: 0.03632915773715885]
	TIME [epoch: 5.69 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03016807361741204		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.03016807361741204 | validation: 0.03382024529513639]
	TIME [epoch: 5.69 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02499542136775394		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.02499542136775394 | validation: 0.03063904445706295]
	TIME [epoch: 5.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020059799594904195		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.020059799594904195 | validation: 0.02716461601902112]
	TIME [epoch: 5.75 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022517457169116073		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.022517457169116073 | validation: 0.040478993660453134]
	TIME [epoch: 5.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023953910906538502		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.023953910906538502 | validation: 0.04015218331759468]
	TIME [epoch: 5.69 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025246201984213554		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.025246201984213554 | validation: 0.03996058006632405]
	TIME [epoch: 5.69 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01908458739829217		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.01908458739829217 | validation: 0.028735828087429933]
	TIME [epoch: 5.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020669655924414145		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.020669655924414145 | validation: 0.031253166660542744]
	TIME [epoch: 5.69 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02475762016518958		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.02475762016518958 | validation: 0.03512262022326596]
	TIME [epoch: 5.72 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03012529139533365		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.03012529139533365 | validation: 0.035508055963122453]
	TIME [epoch: 5.71 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028012776862113273		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.028012776862113273 | validation: 0.03391852863195739]
	TIME [epoch: 5.72 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030382716871662056		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.030382716871662056 | validation: 0.04502720634583032]
	TIME [epoch: 5.71 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04735041591126187		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.04735041591126187 | validation: 0.04322941197113904]
	TIME [epoch: 5.71 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03358386081542628		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.03358386081542628 | validation: 0.044055404189423476]
	TIME [epoch: 5.71 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02492766959900561		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.02492766959900561 | validation: 0.03569501935743096]
	TIME [epoch: 5.71 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02398872562578538		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.02398872562578538 | validation: 0.029711552963109258]
	TIME [epoch: 5.75 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021340162656930034		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.021340162656930034 | validation: 0.02760357263664459]
	TIME [epoch: 5.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02151373082279727		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.02151373082279727 | validation: 0.038159243599876574]
	TIME [epoch: 5.69 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02027795208426779		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.02027795208426779 | validation: 0.035474981911792706]
	TIME [epoch: 5.71 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024366210155262122		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.024366210155262122 | validation: 0.04074025520445562]
	TIME [epoch: 5.69 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027473419330098295		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.027473419330098295 | validation: 0.024050912614792575]
	TIME [epoch: 5.69 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02011586281767571		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.02011586281767571 | validation: 0.033928858835609255]
	TIME [epoch: 5.72 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03186037316015334		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.03186037316015334 | validation: 0.029442649238647638]
	TIME [epoch: 5.73 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023576797810139428		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.023576797810139428 | validation: 0.031742866696631504]
	TIME [epoch: 5.72 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026660083248107667		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.026660083248107667 | validation: 0.02456002140712625]
	TIME [epoch: 5.72 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020798546522083898		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.020798546522083898 | validation: 0.028294531192873455]
	TIME [epoch: 5.72 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0229854006978183		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.0229854006978183 | validation: 0.025509340058345997]
	TIME [epoch: 5.71 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0214119248933121		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.0214119248933121 | validation: 0.02703279357063653]
	TIME [epoch: 5.72 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02011946420916167		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.02011946420916167 | validation: 0.02534329593730912]
	TIME [epoch: 5.76 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017845505374048668		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.017845505374048668 | validation: 0.028357467654325827]
	TIME [epoch: 5.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023537810191524202		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.023537810191524202 | validation: 0.020135761579861102]
	TIME [epoch: 5.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020984821672053695		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.020984821672053695 | validation: 0.028864420049127083]
	TIME [epoch: 5.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02487231967994544		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.02487231967994544 | validation: 0.03500885419127496]
	TIME [epoch: 5.71 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029814922673364868		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.029814922673364868 | validation: 0.048724493800451664]
	TIME [epoch: 5.71 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03926453998639787		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.03926453998639787 | validation: 0.04966012106131932]
	TIME [epoch: 5.73 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595833191520136		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.03595833191520136 | validation: 0.03940955535272453]
	TIME [epoch: 5.73 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025802227852693337		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.025802227852693337 | validation: 0.023955077440885476]
	TIME [epoch: 5.72 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02012398926218127		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.02012398926218127 | validation: 0.03325626558173125]
	TIME [epoch: 5.72 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024031428994284443		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.024031428994284443 | validation: 0.029239775448204563]
	TIME [epoch: 5.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02329439131491433		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.02329439131491433 | validation: 0.03349452342776929]
	TIME [epoch: 5.71 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019824988406801802		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.019824988406801802 | validation: 0.03801332920295444]
	TIME [epoch: 5.72 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022610406119916864		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.022610406119916864 | validation: 0.04195391361085688]
	TIME [epoch: 5.76 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03277152477021732		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.03277152477021732 | validation: 0.0457211430155586]
	TIME [epoch: 5.72 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03302064652540276		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.03302064652540276 | validation: 0.0375501942521718]
	TIME [epoch: 5.71 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027236120250775896		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.027236120250775896 | validation: 0.04064792028154367]
	TIME [epoch: 5.71 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03231184307147869		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.03231184307147869 | validation: 0.031398214022331374]
	TIME [epoch: 5.71 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022141356223201798		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.022141356223201798 | validation: 0.0278219713919505]
	TIME [epoch: 5.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017377364942527604		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.017377364942527604 | validation: 0.03133104425189667]
	TIME [epoch: 5.74 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01955901841900727		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.01955901841900727 | validation: 0.02882635762125343]
	TIME [epoch: 5.72 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017516092624430733		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.017516092624430733 | validation: 0.02641639922351574]
	TIME [epoch: 5.72 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01571644643178474		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.01571644643178474 | validation: 0.034773097485741096]
	TIME [epoch: 5.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02254376311523837		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.02254376311523837 | validation: 0.03308459226427028]
	TIME [epoch: 5.71 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029216235618585985		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.029216235618585985 | validation: 0.025994294514835477]
	TIME [epoch: 5.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028852452989158707		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.028852452989158707 | validation: 0.03778889561716997]
	TIME [epoch: 5.72 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02843136554948842		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.02843136554948842 | validation: 0.03143208571275065]
	TIME [epoch: 5.74 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022456844733127576		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.022456844733127576 | validation: 0.02793448683446453]
	TIME [epoch: 5.72 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017402235722347087		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.017402235722347087 | validation: 0.03518507080045383]
	TIME [epoch: 5.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026435443628672665		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.026435443628672665 | validation: 0.03688121165977013]
	TIME [epoch: 5.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022120831833446878		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.022120831833446878 | validation: 0.034582794110201855]
	TIME [epoch: 5.7 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023340968329051037		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.023340968329051037 | validation: 0.029432638138665885]
	TIME [epoch: 5.71 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022803500592909528		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.022803500592909528 | validation: 0.02911848268982186]
	TIME [epoch: 5.74 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014589364400435852		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.014589364400435852 | validation: 0.028174306571416598]
	TIME [epoch: 5.73 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02178020254135133		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.02178020254135133 | validation: 0.03425242522166865]
	TIME [epoch: 5.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02122311491753596		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.02122311491753596 | validation: 0.03416273324671321]
	TIME [epoch: 5.71 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020205900525728102		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.020205900525728102 | validation: 0.03354562715100699]
	TIME [epoch: 5.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02205330528122377		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.02205330528122377 | validation: 0.036422469768879834]
	TIME [epoch: 5.71 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025776675253998894		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.025776675253998894 | validation: 0.02740683373583405]
	TIME [epoch: 5.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02308480497952542		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.02308480497952542 | validation: 0.03934023816411644]
	TIME [epoch: 5.76 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022337735314311255		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.022337735314311255 | validation: 0.038500934332559356]
	TIME [epoch: 5.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02015414901404863		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.02015414901404863 | validation: 0.023210963642823438]
	TIME [epoch: 5.71 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02002330041478942		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.02002330041478942 | validation: 0.04057042272861066]
	TIME [epoch: 5.7 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025188372408311496		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.025188372408311496 | validation: 0.03258216597290494]
	TIME [epoch: 5.71 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02454446452364955		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.02454446452364955 | validation: 0.03957925912241409]
	TIME [epoch: 5.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04222541988309824		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.04222541988309824 | validation: 0.053929046469325226]
	TIME [epoch: 5.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04219963317231568		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.04219963317231568 | validation: 0.043143145733477634]
	TIME [epoch: 5.73 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022358028687183052		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.022358028687183052 | validation: 0.03329303039422913]
	TIME [epoch: 5.72 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02204099246583469		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.02204099246583469 | validation: 0.03695319519595754]
	TIME [epoch: 5.69 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023258500675193867		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.023258500675193867 | validation: 0.038024230025049136]
	TIME [epoch: 5.72 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02138967773841408		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.02138967773841408 | validation: 0.038346417512879746]
	TIME [epoch: 5.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025665133126943924		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.025665133126943924 | validation: 0.033729320313387184]
	TIME [epoch: 5.71 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023921419460013797		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.023921419460013797 | validation: 0.040113831103982214]
	TIME [epoch: 5.74 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025336221216920286		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.025336221216920286 | validation: 0.036278556899851246]
	TIME [epoch: 5.71 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026288559377622388		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.026288559377622388 | validation: 0.03858768436828651]
	TIME [epoch: 5.71 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022975125484244012		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.022975125484244012 | validation: 0.023323782908995144]
	TIME [epoch: 5.7 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018636212588546724		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.018636212588546724 | validation: 0.026749039269020385]
	TIME [epoch: 5.7 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025233549317895898		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.025233549317895898 | validation: 0.033932501079671926]
	TIME [epoch: 5.72 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017059728049510343		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.017059728049510343 | validation: 0.019457178865738375]
	TIME [epoch: 5.71 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015318193238049824		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.015318193238049824 | validation: 0.029308206317698055]
	TIME [epoch: 5.73 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02394944584789619		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.02394944584789619 | validation: 0.034109076772822544]
	TIME [epoch: 5.72 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02399672334015481		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.02399672334015481 | validation: 0.029346606065795013]
	TIME [epoch: 5.72 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01582350336464703		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.01582350336464703 | validation: 0.027403011427755336]
	TIME [epoch: 5.7 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01960206155573687		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.01960206155573687 | validation: 0.03295523017927065]
	TIME [epoch: 5.71 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017152642055925864		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.017152642055925864 | validation: 0.028086565505194203]
	TIME [epoch: 5.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021152051997770975		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.021152051997770975 | validation: 0.039687360426587076]
	TIME [epoch: 5.75 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021915268738900533		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.021915268738900533 | validation: 0.029831329533628187]
	TIME [epoch: 5.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026428794379812066		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.026428794379812066 | validation: 0.030511539005231327]
	TIME [epoch: 5.71 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017880399806957072		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.017880399806957072 | validation: 0.029199601188734176]
	TIME [epoch: 5.71 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015656710403394634		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.015656710403394634 | validation: 0.02508216973190072]
	TIME [epoch: 5.69 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017255077603019923		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.017255077603019923 | validation: 0.038243289513898944]
	TIME [epoch: 5.71 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02001323200757732		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.02001323200757732 | validation: 0.03946360326019819]
	TIME [epoch: 5.72 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020929692061621173		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.020929692061621173 | validation: 0.03920845226350105]
	TIME [epoch: 5.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026095155974867345		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.026095155974867345 | validation: 0.03542774089074168]
	TIME [epoch: 5.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03009522075510843		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.03009522075510843 | validation: 0.03718802982361699]
	TIME [epoch: 5.71 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025771160807697202		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.025771160807697202 | validation: 0.024679719689195193]
	TIME [epoch: 5.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019292919177774263		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.019292919177774263 | validation: 0.031501448925497784]
	TIME [epoch: 5.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016639534902863826		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.016639534902863826 | validation: 0.03030082129021432]
	TIME [epoch: 5.71 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01774240043588707		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.01774240043588707 | validation: 0.023369760949180494]
	TIME [epoch: 5.75 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0221315412062462		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.0221315412062462 | validation: 0.04081445968907807]
	TIME [epoch: 5.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02619052335556732		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.02619052335556732 | validation: 0.04594353820360524]
	TIME [epoch: 5.71 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023458343164129862		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.023458343164129862 | validation: 0.03189909140360378]
	TIME [epoch: 5.7 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022589690404845417		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.022589690404845417 | validation: 0.037427864009045846]
	TIME [epoch: 5.69 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022355958792046625		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.022355958792046625 | validation: 0.04379338029346602]
	TIME [epoch: 5.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020431516122900423		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.020431516122900423 | validation: 0.044155209457255616]
	TIME [epoch: 5.71 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021653817736714223		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.021653817736714223 | validation: 0.03245452977931461]
	TIME [epoch: 5.73 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017112527975715667		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.017112527975715667 | validation: 0.031399797771100524]
	TIME [epoch: 5.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022085068807693453		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.022085068807693453 | validation: 0.041744168039092776]
	TIME [epoch: 5.7 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030937059393452433		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.030937059393452433 | validation: 0.03413669993393636]
	TIME [epoch: 5.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027007847233036834		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.027007847233036834 | validation: 0.03055130357328298]
	TIME [epoch: 5.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020500759220231077		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.020500759220231077 | validation: 0.023065723651901623]
	TIME [epoch: 5.72 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02093184189644194		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.02093184189644194 | validation: 0.025854091117329104]
	TIME [epoch: 5.75 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01916787404782714		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.01916787404782714 | validation: 0.029402724044236744]
	TIME [epoch: 5.72 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01913750919132021		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.01913750919132021 | validation: 0.03215828350592026]
	TIME [epoch: 5.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017574627081709746		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.017574627081709746 | validation: 0.02199191772196623]
	TIME [epoch: 5.71 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016404150763918966		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.016404150763918966 | validation: 0.02672901726107179]
	TIME [epoch: 5.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018721609053052736		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.018721609053052736 | validation: 0.0258519573899225]
	TIME [epoch: 5.7 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020511797132922262		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.020511797132922262 | validation: 0.024728388941357596]
	TIME [epoch: 5.71 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021406733265213362		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.021406733265213362 | validation: 0.030263560516962506]
	TIME [epoch: 5.73 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023174528021642153		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.023174528021642153 | validation: 0.02344649302435298]
	TIME [epoch: 5.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019314738036367764		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.019314738036367764 | validation: 0.01794837143710451]
	TIME [epoch: 5.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01987322849852892		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.01987322849852892 | validation: 0.02403311799295896]
	TIME [epoch: 5.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019058844073943877		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.019058844073943877 | validation: 0.023467486776296256]
	TIME [epoch: 5.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017741172468157228		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.017741172468157228 | validation: 0.01973535543531138]
	TIME [epoch: 5.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01952665615604165		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.01952665615604165 | validation: 0.03010206016678164]
	TIME [epoch: 5.74 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01751899752027467		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.01751899752027467 | validation: 0.027783617079145624]
	TIME [epoch: 5.72 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013372672658058235		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.013372672658058235 | validation: 0.019188512539699037]
	TIME [epoch: 5.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016094935069934445		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.016094935069934445 | validation: 0.026194202363743244]
	TIME [epoch: 5.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018069880398865937		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.018069880398865937 | validation: 0.025080470599733413]
	TIME [epoch: 5.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01988146775574979		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.01988146775574979 | validation: 0.030997839657578987]
	TIME [epoch: 5.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02226990045356419		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.02226990045356419 | validation: 0.025827588995424776]
	TIME [epoch: 5.71 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020078025425894465		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.020078025425894465 | validation: 0.026189675810406113]
	TIME [epoch: 5.73 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022958697023262035		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.022958697023262035 | validation: 0.026856510597669202]
	TIME [epoch: 5.72 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018727125818029277		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.018727125818029277 | validation: 0.025506224669356526]
	TIME [epoch: 5.71 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020736240202403635		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.020736240202403635 | validation: 0.031081996915291486]
	TIME [epoch: 5.69 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023177755958431034		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.023177755958431034 | validation: 0.03445373259528211]
	TIME [epoch: 5.71 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02296933462295478		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.02296933462295478 | validation: 0.03913610788620142]
	TIME [epoch: 5.69 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03128232085362154		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.03128232085362154 | validation: 0.05250977680780973]
	TIME [epoch: 5.74 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023784699945705524		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.023784699945705524 | validation: 0.04615278594098173]
	TIME [epoch: 5.71 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023308551711191956		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.023308551711191956 | validation: 0.025642039059472602]
	TIME [epoch: 5.69 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015862239735024385		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.015862239735024385 | validation: 0.01922518334382703]
	TIME [epoch: 5.69 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01735983849396605		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.01735983849396605 | validation: 0.031243214796584064]
	TIME [epoch: 5.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01408359779175053		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.01408359779175053 | validation: 0.02257536568003264]
	TIME [epoch: 5.71 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020955565127616173		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.020955565127616173 | validation: 0.023859862665472135]
	TIME [epoch: 5.71 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021977188459822727		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.021977188459822727 | validation: 0.031066626817310945]
	TIME [epoch: 5.75 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021184798824567478		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.021184798824567478 | validation: 0.03407537288934913]
	TIME [epoch: 5.7 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01688889632609355		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.01688889632609355 | validation: 0.023523705327741888]
	TIME [epoch: 5.71 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019846562483557775		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.019846562483557775 | validation: 0.01809769671766998]
	TIME [epoch: 5.71 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01818858464524642		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.01818858464524642 | validation: 0.02374480626254686]
	TIME [epoch: 5.71 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01707771240219335		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.01707771240219335 | validation: 0.02600747785480493]
	TIME [epoch: 5.7 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020858557676193094		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.020858557676193094 | validation: 0.04599676434742337]
	TIME [epoch: 5.74 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03275736898034027		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.03275736898034027 | validation: 0.04384835832435183]
	TIME [epoch: 5.71 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02471341410846783		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.02471341410846783 | validation: 0.03619987157536516]
	TIME [epoch: 5.71 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021289765316392824		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.021289765316392824 | validation: 0.028610820944609424]
	TIME [epoch: 5.7 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016886122252481765		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.016886122252481765 | validation: 0.02212758800821571]
	TIME [epoch: 5.71 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01779911755783805		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.01779911755783805 | validation: 0.03107632025958069]
	TIME [epoch: 5.71 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01766434958073882		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.01766434958073882 | validation: 0.0268042791810105]
	TIME [epoch: 5.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01878959818760408		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.01878959818760408 | validation: 0.031195154328601298]
	TIME [epoch: 5.74 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015407180829672183		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.015407180829672183 | validation: 0.027243208513267555]
	TIME [epoch: 5.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017830041573797535		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.017830041573797535 | validation: 0.02691070140574996]
	TIME [epoch: 5.71 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014678741333841502		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.014678741333841502 | validation: 0.028478957695516973]
	TIME [epoch: 5.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016421094733642942		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.016421094733642942 | validation: 0.028620414693494124]
	TIME [epoch: 5.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02167050532095212		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.02167050532095212 | validation: 0.019879609950634317]
	TIME [epoch: 5.71 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01896020370265197		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.01896020370265197 | validation: 0.037007723080580875]
	TIME [epoch: 5.72 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020300391604764094		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.020300391604764094 | validation: 0.025143864987306665]
	TIME [epoch: 5.71 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024691507763020294		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.024691507763020294 | validation: 0.027184369698501847]
	TIME [epoch: 5.7 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017931897862534685		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.017931897862534685 | validation: 0.02760281154746121]
	TIME [epoch: 5.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01986589798178232		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.01986589798178232 | validation: 0.02451736082484258]
	TIME [epoch: 5.71 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021543778106096284		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.021543778106096284 | validation: 0.027003405522259785]
	TIME [epoch: 5.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020059722657473075		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.020059722657473075 | validation: 0.040305954793862196]
	TIME [epoch: 5.69 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025641289849821756		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.025641289849821756 | validation: 0.019324306265616886]
	TIME [epoch: 5.74 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017159611466676623		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.017159611466676623 | validation: 0.02326417428656021]
	TIME [epoch: 5.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020415206912300532		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.020415206912300532 | validation: 0.026797569376599873]
	TIME [epoch: 5.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020548427665456344		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.020548427665456344 | validation: 0.023412613956874585]
	TIME [epoch: 5.7 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022544264658073923		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.022544264658073923 | validation: 0.027792243069009716]
	TIME [epoch: 5.69 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02137969326571649		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.02137969326571649 | validation: 0.0209998524499641]
	TIME [epoch: 5.71 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016298151732593472		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.016298151732593472 | validation: 0.028622149786526423]
	TIME [epoch: 5.74 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018663964359107985		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.018663964359107985 | validation: 0.028458566996102653]
	TIME [epoch: 5.71 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019375496299656934		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.019375496299656934 | validation: 0.022947908334774763]
	TIME [epoch: 5.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018222178157950818		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.018222178157950818 | validation: 0.02566531079109347]
	TIME [epoch: 5.71 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018194854421878945		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.018194854421878945 | validation: 0.03147361219460336]
	TIME [epoch: 5.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01636031399586946		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.01636031399586946 | validation: 0.024840643757950122]
	TIME [epoch: 5.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021994770256128598		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.021994770256128598 | validation: 0.031205843550599386]
	TIME [epoch: 5.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02156055187301896		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.02156055187301896 | validation: 0.022279619148645048]
	TIME [epoch: 5.75 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021796840806403206		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.021796840806403206 | validation: 0.02292585408526826]
	TIME [epoch: 5.71 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365427516702133		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.02365427516702133 | validation: 0.023812749347936518]
	TIME [epoch: 5.71 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02324319398340005		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.02324319398340005 | validation: 0.024425975700217963]
	TIME [epoch: 5.71 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016936843971968728		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.016936843971968728 | validation: 0.02567420173602789]
	TIME [epoch: 5.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01588226418340132		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.01588226418340132 | validation: 0.032983863068280724]
	TIME [epoch: 5.69 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019266403633220682		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.019266403633220682 | validation: 0.03554667663709127]
	TIME [epoch: 5.72 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02293360939041799		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.02293360939041799 | validation: 0.02692112786989885]
	TIME [epoch: 5.71 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01857037611577187		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.01857037611577187 | validation: 0.03922907127929179]
	TIME [epoch: 5.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021728310541990575		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.021728310541990575 | validation: 0.032896893139683255]
	TIME [epoch: 5.69 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02147548899957109		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.02147548899957109 | validation: 0.035545477170507926]
	TIME [epoch: 5.71 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021780954475479196		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.021780954475479196 | validation: 0.027647607467601525]
	TIME [epoch: 5.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021062005046304143		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.021062005046304143 | validation: 0.028479765697434715]
	TIME [epoch: 5.71 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015245865619659345		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.015245865619659345 | validation: 0.029655677272805124]
	TIME [epoch: 5.74 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013740821214151044		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.013740821214151044 | validation: 0.02638137689900773]
	TIME [epoch: 5.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013234408970949175		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.013234408970949175 | validation: 0.022217425913162527]
	TIME [epoch: 5.7 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020835327776210805		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.020835327776210805 | validation: 0.021484464015531616]
	TIME [epoch: 5.71 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020889842170048162		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.020889842170048162 | validation: 0.027198971802434486]
	TIME [epoch: 5.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018626620814669346		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.018626620814669346 | validation: 0.0264769557669566]
	TIME [epoch: 5.71 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012683880195263286		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.012683880195263286 | validation: 0.01891876604194866]
	TIME [epoch: 5.72 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011869249715066255		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.011869249715066255 | validation: 0.021470891299013833]
	TIME [epoch: 5.71 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015992851143952186		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.015992851143952186 | validation: 0.023033699410681906]
	TIME [epoch: 5.7 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01576953631250581		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.01576953631250581 | validation: 0.033237392404339046]
	TIME [epoch: 5.71 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01980837319174982		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.01980837319174982 | validation: 0.023304953927394848]
	TIME [epoch: 5.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01652438017295614		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.01652438017295614 | validation: 0.02548055366857638]
	TIME [epoch: 5.71 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014959491698040839		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.014959491698040839 | validation: 0.02613166391904084]
	TIME [epoch: 5.71 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016149991980319425		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.016149991980319425 | validation: 0.03017577565668213]
	TIME [epoch: 5.74 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016466714601239354		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.016466714601239354 | validation: 0.021722600182566134]
	TIME [epoch: 5.7 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015106852738358082		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.015106852738358082 | validation: 0.03218706595952611]
	TIME [epoch: 5.7 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02043385649210306		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.02043385649210306 | validation: 0.024308943165170467]
	TIME [epoch: 5.71 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015067778489453053		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.015067778489453053 | validation: 0.020569490885946805]
	TIME [epoch: 5.7 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01690223088664264		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.01690223088664264 | validation: 0.021292647479090203]
	TIME [epoch: 5.7 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01687295613647521		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.01687295613647521 | validation: 0.02593801175668685]
	TIME [epoch: 5.72 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015389059252618686		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.015389059252618686 | validation: 0.02861585487962403]
	TIME [epoch: 5.72 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018849290368633406		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.018849290368633406 | validation: 0.02502730112055202]
	TIME [epoch: 5.71 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01665684511646287		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.01665684511646287 | validation: 0.019207953613881716]
	TIME [epoch: 5.7 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015989072934303093		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.015989072934303093 | validation: 0.02355924819228056]
	TIME [epoch: 5.7 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017210566822498944		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.017210566822498944 | validation: 0.024826631743265465]
	TIME [epoch: 5.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01796282322459024		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.01796282322459024 | validation: 0.026606127901007352]
	TIME [epoch: 5.7 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015336752590345289		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.015336752590345289 | validation: 0.028893436025527502]
	TIME [epoch: 5.76 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01519506633787128		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.01519506633787128 | validation: 0.01535994264120255]
	TIME [epoch: 5.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017491846998351		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.017491846998351 | validation: 0.016448700501716162]
	TIME [epoch: 5.71 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016755984033927116		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.016755984033927116 | validation: 0.024165400055859904]
	TIME [epoch: 5.71 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014592660749123592		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.014592660749123592 | validation: 0.026049491469923105]
	TIME [epoch: 5.71 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019891492391740297		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.019891492391740297 | validation: 0.027628768269867078]
	TIME [epoch: 5.7 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020525341212012733		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.020525341212012733 | validation: 0.030896356271499018]
	TIME [epoch: 5.74 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0199865233799651		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.0199865233799651 | validation: 0.02815714808767841]
	TIME [epoch: 5.73 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01857615773381715		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.01857615773381715 | validation: 0.028460503221519523]
	TIME [epoch: 5.72 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020145418780442445		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.020145418780442445 | validation: 0.03770066555778489]
	TIME [epoch: 5.7 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025593873595809693		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.025593873595809693 | validation: 0.03710689066692976]
	TIME [epoch: 5.71 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023585094833233594		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.023585094833233594 | validation: 0.02593720007119143]
	TIME [epoch: 5.71 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018035200084390253		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.018035200084390253 | validation: 0.025054035334397217]
	TIME [epoch: 5.71 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018029835884093428		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.018029835884093428 | validation: 0.03270796858029156]
	TIME [epoch: 5.75 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01719081818141459		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.01719081818141459 | validation: 0.029888719235579543]
	TIME [epoch: 5.71 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02117504247884883		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.02117504247884883 | validation: 0.024715337459346925]
	TIME [epoch: 5.71 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01748526266681482		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.01748526266681482 | validation: 0.028394694229633394]
	TIME [epoch: 5.71 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018083301156333796		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.018083301156333796 | validation: 0.025415613358932873]
	TIME [epoch: 5.71 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014073766623391094		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.014073766623391094 | validation: 0.015289100085661844]
	TIME [epoch: 5.71 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01557903543131874		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.01557903543131874 | validation: 0.028401729210385866]
	TIME [epoch: 5.71 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018428280909587758		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.018428280909587758 | validation: 0.019411994270563445]
	TIME [epoch: 5.74 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021560714635556505		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.021560714635556505 | validation: 0.026318837685600133]
	TIME [epoch: 5.7 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02191320016098092		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.02191320016098092 | validation: 0.031224806992224352]
	TIME [epoch: 5.71 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015547683006275091		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.015547683006275091 | validation: 0.02453989172465891]
	TIME [epoch: 5.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021042073703429538		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.021042073703429538 | validation: 0.030432640774564198]
	TIME [epoch: 5.71 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017378499460866104		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.017378499460866104 | validation: 0.025205106855035884]
	TIME [epoch: 5.72 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01692006963234176		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.01692006963234176 | validation: 0.030749517897694215]
	TIME [epoch: 5.75 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01899904391825072		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.01899904391825072 | validation: 0.030032488619739308]
	TIME [epoch: 5.7 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017867579507062723		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.017867579507062723 | validation: 0.016912045863393513]
	TIME [epoch: 5.71 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015733825236329383		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.015733825236329383 | validation: 0.028289638578898206]
	TIME [epoch: 5.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022816784775785685		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.022816784775785685 | validation: 0.02326366575088932]
	TIME [epoch: 5.71 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017236786980262778		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.017236786980262778 | validation: 0.024638464299151813]
	TIME [epoch: 5.71 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012074519852909476		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.012074519852909476 | validation: 0.029028382553243883]
	TIME [epoch: 5.71 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018881692179903077		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.018881692179903077 | validation: 0.027675398529161274]
	TIME [epoch: 5.73 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0151245020216218		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.0151245020216218 | validation: 0.027666546977162625]
	TIME [epoch: 5.71 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0207301760301682		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.0207301760301682 | validation: 0.03052456330995683]
	TIME [epoch: 5.71 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019079075655262612		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.019079075655262612 | validation: 0.02487825927833585]
	TIME [epoch: 5.71 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014216443663929202		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.014216443663929202 | validation: 0.025430809715413862]
	TIME [epoch: 5.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017712208371523975		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.017712208371523975 | validation: 0.0265683373666663]
	TIME [epoch: 5.7 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015824218258079982		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.015824218258079982 | validation: 0.0171152794726577]
	TIME [epoch: 5.75 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016328975848263417		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.016328975848263417 | validation: 0.017047461820710437]
	TIME [epoch: 5.72 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0124649322382054		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.0124649322382054 | validation: 0.02433160370221177]
	TIME [epoch: 5.71 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014420358503544463		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.014420358503544463 | validation: 0.020429157773039136]
	TIME [epoch: 5.7 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013064607881123205		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.013064607881123205 | validation: 0.01168829010149147]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_1377.pth
	Model improved!!!
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01570742675931577		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.01570742675931577 | validation: 0.027468390440102387]
	TIME [epoch: 5.7 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014819406817508382		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.014819406817508382 | validation: 0.021319896152664906]
	TIME [epoch: 5.73 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020321548563059635		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.020321548563059635 | validation: 0.03943171423826135]
	TIME [epoch: 5.73 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022985863824354996		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.022985863824354996 | validation: 0.032577067928906175]
	TIME [epoch: 5.7 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016593207102184263		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.016593207102184263 | validation: 0.024434289171093675]
	TIME [epoch: 5.7 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021716785933596112		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.021716785933596112 | validation: 0.03380319827807472]
	TIME [epoch: 5.69 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018304465664078295		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.018304465664078295 | validation: 0.030269307743923782]
	TIME [epoch: 5.71 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01671148408948714		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.01671148408948714 | validation: 0.020940668060495986]
	TIME [epoch: 5.69 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0148311581109912		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.0148311581109912 | validation: 0.034922574833603594]
	TIME [epoch: 5.73 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016767516214601354		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.016767516214601354 | validation: 0.021637364891038634]
	TIME [epoch: 5.71 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018667583629638235		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.018667583629638235 | validation: 0.0181804653285314]
	TIME [epoch: 5.71 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01708251296021546		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.01708251296021546 | validation: 0.024540816576164345]
	TIME [epoch: 5.71 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016587268544915774		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.016587268544915774 | validation: 0.02320225443654688]
	TIME [epoch: 5.71 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017150944573161915		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.017150944573161915 | validation: 0.031733504049896596]
	TIME [epoch: 5.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016858676499291316		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.016858676499291316 | validation: 0.02432678470709523]
	TIME [epoch: 5.74 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012978325573157836		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.012978325573157836 | validation: 0.024754448589969176]
	TIME [epoch: 5.71 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016581076424494072		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.016581076424494072 | validation: 0.02283091685962888]
	TIME [epoch: 5.71 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014619265306161935		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.014619265306161935 | validation: 0.02404028670486341]
	TIME [epoch: 5.7 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012847975813863089		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.012847975813863089 | validation: 0.024649642993693616]
	TIME [epoch: 5.71 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015540801163014267		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.015540801163014267 | validation: 0.028632470205989212]
	TIME [epoch: 5.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014721207584986214		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.014721207584986214 | validation: 0.027483779326183764]
	TIME [epoch: 5.71 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014529382500799505		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.014529382500799505 | validation: 0.03156187002359007]
	TIME [epoch: 5.74 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01661336754853422		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.01661336754853422 | validation: 0.021346889166287034]
	TIME [epoch: 5.72 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01628076326202288		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.01628076326202288 | validation: 0.025265658940121668]
	TIME [epoch: 5.71 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01610663155863328		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.01610663155863328 | validation: 0.019802000544438616]
	TIME [epoch: 5.71 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019272980176739427		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.019272980176739427 | validation: 0.02055913802373776]
	TIME [epoch: 5.69 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015343032802922355		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.015343032802922355 | validation: 0.02429511617591082]
	TIME [epoch: 5.71 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018003435561909656		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.018003435561909656 | validation: 0.02191293367497523]
	TIME [epoch: 5.7 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018655228187626813		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.018655228187626813 | validation: 0.026474752565440473]
	TIME [epoch: 5.74 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011892367300355745		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.011892367300355745 | validation: 0.023593386632771395]
	TIME [epoch: 5.71 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017871237484557042		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.017871237484557042 | validation: 0.03133295694242844]
	TIME [epoch: 5.71 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013247767196246128		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.013247767196246128 | validation: 0.026888355316917256]
	TIME [epoch: 5.7 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014550902404343723		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.014550902404343723 | validation: 0.029104840352344646]
	TIME [epoch: 5.71 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01724305665768236		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.01724305665768236 | validation: 0.033482634553671266]
	TIME [epoch: 5.71 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020400042179208384		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.020400042179208384 | validation: 0.020088445234867077]
	TIME [epoch: 5.75 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01543684060672105		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.01543684060672105 | validation: 0.02914456221176675]
	TIME [epoch: 5.71 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014150639948992984		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.014150639948992984 | validation: 0.025094279497570416]
	TIME [epoch: 5.7 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01678867916457581		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.01678867916457581 | validation: 0.024450154516286043]
	TIME [epoch: 5.7 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014291436314615883		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.014291436314615883 | validation: 0.024252742186451518]
	TIME [epoch: 5.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01962034640678831		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.01962034640678831 | validation: 0.03171119063550654]
	TIME [epoch: 5.7 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019657587197972937		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.019657587197972937 | validation: 0.024004039910285397]
	TIME [epoch: 5.71 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019258388033567046		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.019258388033567046 | validation: 0.028178769317376517]
	TIME [epoch: 5.74 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018109517806430206		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.018109517806430206 | validation: 0.021815177189731836]
	TIME [epoch: 5.7 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01487396840698324		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.01487396840698324 | validation: 0.02818963047987349]
	TIME [epoch: 5.7 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015182600621973762		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.015182600621973762 | validation: 0.020952569352688143]
	TIME [epoch: 5.7 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01702297090967518		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.01702297090967518 | validation: 0.022143494086236244]
	TIME [epoch: 5.69 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019631988292789837		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.019631988292789837 | validation: 0.02187246181890545]
	TIME [epoch: 5.7 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017346282120758293		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.017346282120758293 | validation: 0.024915384552108826]
	TIME [epoch: 5.75 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015212370616218477		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.015212370616218477 | validation: 0.020144134980263885]
	TIME [epoch: 5.7 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013331885894163713		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.013331885894163713 | validation: 0.020206681332724727]
	TIME [epoch: 5.71 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018296731416558937		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.018296731416558937 | validation: 0.021650101610579058]
	TIME [epoch: 5.7 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017149209813470713		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.017149209813470713 | validation: 0.016700393636869208]
	TIME [epoch: 5.71 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017442593413500303		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.017442593413500303 | validation: 0.02204074628078542]
	TIME [epoch: 5.7 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015555940120952707		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.015555940120952707 | validation: 0.021328677941828057]
	TIME [epoch: 5.72 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017772813597699846		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.017772813597699846 | validation: 0.031233428697648065]
	TIME [epoch: 5.73 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017037388813849853		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.017037388813849853 | validation: 0.024832103870777417]
	TIME [epoch: 5.7 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02141375982585414		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.02141375982585414 | validation: 0.03040622182625947]
	TIME [epoch: 5.7 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02378922293891811		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.02378922293891811 | validation: 0.025717308805462788]
	TIME [epoch: 5.7 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019119098573643467		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.019119098573643467 | validation: 0.026333687262262272]
	TIME [epoch: 5.71 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013852353480352332		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.013852353480352332 | validation: 0.02272168563074814]
	TIME [epoch: 5.71 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01315399696940087		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.01315399696940087 | validation: 0.022117868449657827]
	TIME [epoch: 5.75 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013527472200803425		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.013527472200803425 | validation: 0.02364120961898967]
	TIME [epoch: 5.7 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015535125220864495		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.015535125220864495 | validation: 0.025786211939586842]
	TIME [epoch: 5.71 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019759508863636553		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.019759508863636553 | validation: 0.02039970393318334]
	TIME [epoch: 5.7 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02333033504696575		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.02333033504696575 | validation: 0.022261297343136827]
	TIME [epoch: 5.7 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01811657109125115		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.01811657109125115 | validation: 0.023854938386309157]
	TIME [epoch: 5.71 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015709657072011676		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.015709657072011676 | validation: 0.021892619358585625]
	TIME [epoch: 5.71 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016085546133600477		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.016085546133600477 | validation: 0.03212436153110255]
	TIME [epoch: 5.73 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013274688785612911		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.013274688785612911 | validation: 0.026576264787955512]
	TIME [epoch: 5.71 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014163630488361221		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.014163630488361221 | validation: 0.02478759578338929]
	TIME [epoch: 5.71 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01543901700976441		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.01543901700976441 | validation: 0.020609941628878924]
	TIME [epoch: 5.71 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010387471773462165		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.010387471773462165 | validation: 0.02764573955249354]
	TIME [epoch: 5.71 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014120868603140772		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.014120868603140772 | validation: 0.018431533676763538]
	TIME [epoch: 5.7 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014883173207529975		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.014883173207529975 | validation: 0.0202924056691329]
	TIME [epoch: 5.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0165927946093326		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.0165927946093326 | validation: 0.025543504717562372]
	TIME [epoch: 5.71 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01754097308007077		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.01754097308007077 | validation: 0.02792645376159034]
	TIME [epoch: 5.71 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02008394442065007		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.02008394442065007 | validation: 0.023995592611186584]
	TIME [epoch: 5.71 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01561119005252387		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.01561119005252387 | validation: 0.019438014189081598]
	TIME [epoch: 5.71 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017578026423753272		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.017578026423753272 | validation: 0.028313700403427573]
	TIME [epoch: 5.71 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012822886382345109		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.012822886382345109 | validation: 0.025878770395723578]
	TIME [epoch: 5.72 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016990540286871764		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.016990540286871764 | validation: 0.02227277751179175]
	TIME [epoch: 5.74 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015070565352417013		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.015070565352417013 | validation: 0.026987862777894178]
	TIME [epoch: 5.71 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013688230042160918		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.013688230042160918 | validation: 0.021534346014996326]
	TIME [epoch: 5.69 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017187437516517863		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.017187437516517863 | validation: 0.024595721536919867]
	TIME [epoch: 5.7 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01958906688923069		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.01958906688923069 | validation: 0.026526219804664408]
	TIME [epoch: 5.69 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015122891257363814		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.015122891257363814 | validation: 0.027556193527706028]
	TIME [epoch: 5.7 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020223078160858228		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.020223078160858228 | validation: 0.025691619487765664]
	TIME [epoch: 5.73 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015055655751565419		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.015055655751565419 | validation: 0.03467564942987814]
	TIME [epoch: 5.7 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01495178749618549		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.01495178749618549 | validation: 0.024113549468195775]
	TIME [epoch: 5.7 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013602193757939387		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.013602193757939387 | validation: 0.02548311700033792]
	TIME [epoch: 5.7 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010162050151756884		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.010162050151756884 | validation: 0.02009032197414222]
	TIME [epoch: 5.69 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01719702426856543		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.01719702426856543 | validation: 0.02628666060063015]
	TIME [epoch: 5.7 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01706837480116019		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.01706837480116019 | validation: 0.030465140540069147]
	TIME [epoch: 5.7 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018933369163741		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.018933369163741 | validation: 0.021551014412687503]
	TIME [epoch: 5.72 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021133676761076955		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.021133676761076955 | validation: 0.024509999633877674]
	TIME [epoch: 5.69 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015110394532495259		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.015110394532495259 | validation: 0.02244049409502603]
	TIME [epoch: 5.69 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015019908702381277		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.015019908702381277 | validation: 0.02521754614232201]
	TIME [epoch: 5.7 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01757231367874132		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.01757231367874132 | validation: 0.01927562122258497]
	TIME [epoch: 5.69 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013627701085432257		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.013627701085432257 | validation: 0.016406399361994763]
	TIME [epoch: 5.69 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014905103383923965		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.014905103383923965 | validation: 0.017724512881355754]
	TIME [epoch: 5.73 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018231452385008878		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.018231452385008878 | validation: 0.02751572159803307]
	TIME [epoch: 5.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01207962150560993		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.01207962150560993 | validation: 0.01929525939511339]
	TIME [epoch: 5.69 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016421479550041286		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.016421479550041286 | validation: 0.03472128911877053]
	TIME [epoch: 5.69 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01865578550281735		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.01865578550281735 | validation: 0.025555355276044828]
	TIME [epoch: 5.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017929110214434402		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.017929110214434402 | validation: 0.026050477726962562]
	TIME [epoch: 5.69 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015604537145765578		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.015604537145765578 | validation: 0.020663406256613056]
	TIME [epoch: 5.71 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014036956461911141		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.014036956461911141 | validation: 0.015846419408826723]
	TIME [epoch: 5.72 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01474150165245142		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.01474150165245142 | validation: 0.027897540143780857]
	TIME [epoch: 5.69 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01706348578185521		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.01706348578185521 | validation: 0.016433804667078715]
	TIME [epoch: 5.69 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016282487426430917		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.016282487426430917 | validation: 0.026354703598251056]
	TIME [epoch: 5.69 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01718393283295572		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.01718393283295572 | validation: 0.020816026688513213]
	TIME [epoch: 5.69 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018576537498810265		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.018576537498810265 | validation: 0.025068931571824465]
	TIME [epoch: 5.69 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016624070904325525		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.016624070904325525 | validation: 0.02384594494942657]
	TIME [epoch: 5.72 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017392417964072916		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.017392417964072916 | validation: 0.018918541422028343]
	TIME [epoch: 5.71 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016106007115527468		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.016106007115527468 | validation: 0.021448868077224358]
	TIME [epoch: 5.71 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016020693069049092		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.016020693069049092 | validation: 0.019231849603665214]
	TIME [epoch: 5.71 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015423164458191186		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.015423164458191186 | validation: 0.024234990868057554]
	TIME [epoch: 5.7 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015889586452012466		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.015889586452012466 | validation: 0.03572445814865571]
	TIME [epoch: 5.71 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019894669830984903		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.019894669830984903 | validation: 0.037310123252719464]
	TIME [epoch: 5.72 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019853291133556078		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.019853291133556078 | validation: 0.02558755858424303]
	TIME [epoch: 5.74 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014538730838450895		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.014538730838450895 | validation: 0.023372888187165222]
	TIME [epoch: 5.72 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014307401195945573		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.014307401195945573 | validation: 0.029838605469928715]
	TIME [epoch: 5.71 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01581975487783165		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.01581975487783165 | validation: 0.023406923465182364]
	TIME [epoch: 5.72 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01859058876707296		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.01859058876707296 | validation: 0.029147731521227342]
	TIME [epoch: 5.71 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018389238297355393		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.018389238297355393 | validation: 0.03235472529541195]
	TIME [epoch: 5.71 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01461030537535734		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.01461030537535734 | validation: 0.032956711565396334]
	TIME [epoch: 5.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014771477171625844		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.014771477171625844 | validation: 0.03223096515495999]
	TIME [epoch: 5.72 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020699662553281845		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.020699662553281845 | validation: 0.027902857228293457]
	TIME [epoch: 5.7 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014745297167232899		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.014745297167232899 | validation: 0.03261601513458782]
	TIME [epoch: 5.7 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01683758333621193		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.01683758333621193 | validation: 0.025165606345697797]
	TIME [epoch: 5.71 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019904647103756924		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.019904647103756924 | validation: 0.024204644456354844]
	TIME [epoch: 5.7 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017475124726264144		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.017475124726264144 | validation: 0.02760822388643188]
	TIME [epoch: 5.72 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01814926587060826		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.01814926587060826 | validation: 0.036484290452317034]
	TIME [epoch: 5.73 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02128256201096946		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.02128256201096946 | validation: 0.025382039270883165]
	TIME [epoch: 5.7 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017186695551273404		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.017186695551273404 | validation: 0.026090291878241252]
	TIME [epoch: 5.69 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017665031028230416		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.017665031028230416 | validation: 0.022934409076999368]
	TIME [epoch: 5.7 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01487583301625707		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.01487583301625707 | validation: 0.028207314816514284]
	TIME [epoch: 5.71 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016540903945178174		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.016540903945178174 | validation: 0.028538264530986766]
	TIME [epoch: 5.71 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01686009528034081		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.01686009528034081 | validation: 0.03207851993290453]
	TIME [epoch: 5.73 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01650297536742899		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.01650297536742899 | validation: 0.02292067660467559]
	TIME [epoch: 5.73 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019558776595322517		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.019558776595322517 | validation: 0.02694856209534341]
	TIME [epoch: 5.71 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017759458476812578		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.017759458476812578 | validation: 0.03470561388891004]
	TIME [epoch: 5.71 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017899466407673745		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.017899466407673745 | validation: 0.020151299576080903]
	TIME [epoch: 5.69 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021043092846571868		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.021043092846571868 | validation: 0.026933210977160567]
	TIME [epoch: 5.69 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01847827327077619		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.01847827327077619 | validation: 0.02426568851354052]
	TIME [epoch: 5.71 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014792926500116422		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.014792926500116422 | validation: 0.03141788441467214]
	TIME [epoch: 5.75 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016535711099874346		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.016535711099874346 | validation: 0.027231852311215547]
	TIME [epoch: 5.71 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01863089647318366		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.01863089647318366 | validation: 0.022592995448447308]
	TIME [epoch: 5.71 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01700561964223589		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.01700561964223589 | validation: 0.029335717088581636]
	TIME [epoch: 5.71 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01653549417383944		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.01653549417383944 | validation: 0.02487321948135387]
	TIME [epoch: 5.69 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021252537645485348		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.021252537645485348 | validation: 0.027942053687412365]
	TIME [epoch: 5.69 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020502655838242703		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.020502655838242703 | validation: 0.03028351087564133]
	TIME [epoch: 5.74 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01519431486334076		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.01519431486334076 | validation: 0.03324402336576314]
	TIME [epoch: 5.73 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013996636790347478		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.013996636790347478 | validation: 0.025709827545112453]
	TIME [epoch: 5.71 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019318878959470688		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.019318878959470688 | validation: 0.02201380179295623]
	TIME [epoch: 5.71 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013729695999148406		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.013729695999148406 | validation: 0.02859278696380566]
	TIME [epoch: 5.71 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014660539663720648		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.014660539663720648 | validation: 0.01815788551900015]
	TIME [epoch: 5.71 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01263080795096956		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.01263080795096956 | validation: 0.01909371007304643]
	TIME [epoch: 5.69 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015373921683550715		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.015373921683550715 | validation: 0.02742492470743252]
	TIME [epoch: 5.73 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014889321701200279		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.014889321701200279 | validation: 0.020395225153739215]
	TIME [epoch: 5.7 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013915552495538192		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.013915552495538192 | validation: 0.02337497469205737]
	TIME [epoch: 5.69 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01359677157748048		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.01359677157748048 | validation: 0.025881375966782194]
	TIME [epoch: 5.69 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013230657813202335		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.013230657813202335 | validation: 0.028193257100855802]
	TIME [epoch: 5.71 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016468033977046933		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.016468033977046933 | validation: 0.019865215680824062]
	TIME [epoch: 5.69 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015207319708815267		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.015207319708815267 | validation: 0.022201409661520895]
	TIME [epoch: 5.72 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01176940438583535		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.01176940438583535 | validation: 0.02521947315635748]
	TIME [epoch: 5.73 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015669521195480332		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.015669521195480332 | validation: 0.016635371129609385]
	TIME [epoch: 5.7 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01613302165047132		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.01613302165047132 | validation: 0.02035788393886405]
	TIME [epoch: 5.69 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01692333742737231		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.01692333742737231 | validation: 0.0240320857500178]
	TIME [epoch: 5.69 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015381746823348839		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.015381746823348839 | validation: 0.03260694578781981]
	TIME [epoch: 5.7 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01619935883192941		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.01619935883192941 | validation: 0.02881639042826536]
	TIME [epoch: 5.69 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01611590702099356		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.01611590702099356 | validation: 0.03068402566084247]
	TIME [epoch: 5.75 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014924098185235882		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.014924098185235882 | validation: 0.02200493013928739]
	TIME [epoch: 5.7 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016140173230944334		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.016140173230944334 | validation: 0.02548766761696226]
	TIME [epoch: 5.69 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018403634103797466		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.018403634103797466 | validation: 0.032470200429423494]
	TIME [epoch: 5.69 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0171946377164662		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.0171946377164662 | validation: 0.023916461596210314]
	TIME [epoch: 5.69 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01683362784100378		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.01683362784100378 | validation: 0.02529052183233601]
	TIME [epoch: 5.69 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017733924207221946		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.017733924207221946 | validation: 0.03186736656268976]
	TIME [epoch: 5.71 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01980483459114366		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.01980483459114366 | validation: 0.02321201606983703]
	TIME [epoch: 5.71 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013391471700573998		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.013391471700573998 | validation: 0.02260161399441865]
	TIME [epoch: 5.71 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008863749489544458		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.008863749489544458 | validation: 0.025767623183195653]
	TIME [epoch: 5.71 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01608235173225943		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.01608235173225943 | validation: 0.01697962451410422]
	TIME [epoch: 5.71 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018619697861178855		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.018619697861178855 | validation: 0.024214328032605897]
	TIME [epoch: 5.71 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014783006671594384		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.014783006671594384 | validation: 0.025217026808520306]
	TIME [epoch: 5.71 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01967842209617257		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.01967842209617257 | validation: 0.01897772058106783]
	TIME [epoch: 5.75 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018284637583958915		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.018284637583958915 | validation: 0.030369904315238228]
	TIME [epoch: 5.71 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016107359330868688		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.016107359330868688 | validation: 0.029630098002070095]
	TIME [epoch: 5.71 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019186199031369783		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.019186199031369783 | validation: 0.02509129036224362]
	TIME [epoch: 5.71 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01786634884511073		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.01786634884511073 | validation: 0.02587638733608063]
	TIME [epoch: 5.71 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015022166398853669		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.015022166398853669 | validation: 0.0181483353785204]
	TIME [epoch: 5.71 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01803149463197		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.01803149463197 | validation: 0.0279426337279282]
	TIME [epoch: 5.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0172356390573643		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.0172356390573643 | validation: 0.023605612551132592]
	TIME [epoch: 5.73 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016552087962425466		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.016552087962425466 | validation: 0.025923877134639367]
	TIME [epoch: 5.71 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010172015537080786		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.010172015537080786 | validation: 0.017753011301393062]
	TIME [epoch: 5.71 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01430687558015472		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.01430687558015472 | validation: 0.024469462258666586]
	TIME [epoch: 5.71 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013378741670917977		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.013378741670917977 | validation: 0.021322166114972615]
	TIME [epoch: 5.71 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022383657205056105		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.022383657205056105 | validation: 0.013934472931178601]
	TIME [epoch: 5.71 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012304217200360613		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.012304217200360613 | validation: 0.0168849174201537]
	TIME [epoch: 5.75 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013404680584453611		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.013404680584453611 | validation: 0.01591473094189282]
	TIME [epoch: 5.71 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014343076560975413		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.014343076560975413 | validation: 0.014026841257868532]
	TIME [epoch: 5.71 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012708800493827799		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.012708800493827799 | validation: 0.02014286786029316]
	TIME [epoch: 5.71 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018536604329340612		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.018536604329340612 | validation: 0.02282607801993673]
	TIME [epoch: 5.71 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014795248443974736		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.014795248443974736 | validation: 0.025380125088805317]
	TIME [epoch: 5.71 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016263997377587602		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.016263997377587602 | validation: 0.02328803021643585]
	TIME [epoch: 5.73 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015299448981195528		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.015299448981195528 | validation: 0.021388472643873318]
	TIME [epoch: 5.71 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014141911297998513		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.014141911297998513 | validation: 0.022783937933362423]
	TIME [epoch: 5.7 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015140811543510727		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.015140811543510727 | validation: 0.029582641263296978]
	TIME [epoch: 5.71 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015084960817145283		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.015084960817145283 | validation: 0.014895961360216321]
	TIME [epoch: 5.69 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017661548537890537		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.017661548537890537 | validation: 0.02624831025515098]
	TIME [epoch: 5.71 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010904691945722834		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.010904691945722834 | validation: 0.023718623207810024]
	TIME [epoch: 5.71 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014456538981477193		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.014456538981477193 | validation: 0.017815652467689017]
	TIME [epoch: 5.75 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015003358657589543		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.015003358657589543 | validation: 0.01941809086406564]
	TIME [epoch: 5.71 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013067559317784288		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.013067559317784288 | validation: 0.008227443839351634]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240310_003030/states/model_tr_study2_1590.pth
	Model improved!!!
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01734567300177398		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.01734567300177398 | validation: 0.0200311878892344]
	TIME [epoch: 5.71 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013850226636708048		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.013850226636708048 | validation: 0.020238695731683635]
	TIME [epoch: 5.71 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012108947904245663		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.012108947904245663 | validation: 0.025465926124078875]
	TIME [epoch: 5.97 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016792053499098923		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.016792053499098923 | validation: 0.015634061425251946]
	TIME [epoch: 5.73 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013391103449649461		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.013391103449649461 | validation: 0.019476506285075346]
	TIME [epoch: 5.7 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016531335439640284		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.016531335439640284 | validation: 0.023502367099023855]
	TIME [epoch: 5.7 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013314671802859113		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.013314671802859113 | validation: 0.020408390086895215]
	TIME [epoch: 5.7 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015999370423564536		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.015999370423564536 | validation: 0.01968380630894784]
	TIME [epoch: 5.7 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01426141083945993		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.01426141083945993 | validation: 0.014918183547286279]
	TIME [epoch: 5.7 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016746336987139735		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.016746336987139735 | validation: 0.02627897997813739]
	TIME [epoch: 5.72 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012674266184419334		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.012674266184419334 | validation: 0.025041177888459904]
	TIME [epoch: 5.71 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014719575602838274		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.014719575602838274 | validation: 0.019781561131842085]
	TIME [epoch: 5.7 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018706644673811546		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.018706644673811546 | validation: 0.027446970842371188]
	TIME [epoch: 5.7 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017795288693420914		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.017795288693420914 | validation: 0.021397558439496724]
	TIME [epoch: 5.7 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019221330934195948		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.019221330934195948 | validation: 0.02028757162567713]
	TIME [epoch: 5.7 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017111301974671353		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.017111301974671353 | validation: 0.027325072697935233]
	TIME [epoch: 5.7 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01488699942563623		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.01488699942563623 | validation: 0.03546980574717752]
	TIME [epoch: 5.74 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013789262880133787		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.013789262880133787 | validation: 0.024737647248039858]
	TIME [epoch: 5.7 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01488185749679049		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.01488185749679049 | validation: 0.028728361035537806]
	TIME [epoch: 5.7 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01688042512172262		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.01688042512172262 | validation: 0.016805325448089783]
	TIME [epoch: 5.7 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01465126834159327		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.01465126834159327 | validation: 0.025132043631154122]
	TIME [epoch: 5.7 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01648380273132335		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.01648380273132335 | validation: 0.026645923978298944]
	TIME [epoch: 5.7 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011513265043421164		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.011513265043421164 | validation: 0.026663686889145517]
	TIME [epoch: 5.72 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015031568476594533		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.015031568476594533 | validation: 0.017910970990257288]
	TIME [epoch: 5.71 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014562605398455313		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.014562605398455313 | validation: 0.02006368035621543]
	TIME [epoch: 5.7 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016458192427876894		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.016458192427876894 | validation: 0.0205262132424709]
	TIME [epoch: 5.7 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014572278590328527		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.014572278590328527 | validation: 0.02632870390438107]
	TIME [epoch: 5.7 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018480699491867328		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.018480699491867328 | validation: 0.023031822044511232]
	TIME [epoch: 5.7 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016160990775232042		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.016160990775232042 | validation: 0.031157027662752253]
	TIME [epoch: 5.7 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018957592638511867		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.018957592638511867 | validation: 0.03216089332557447]
	TIME [epoch: 5.74 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016354053609850407		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.016354053609850407 | validation: 0.02724943541319539]
	TIME [epoch: 5.7 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01623527146065097		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.01623527146065097 | validation: 0.03087891116744429]
	TIME [epoch: 5.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018835069997603367		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.018835069997603367 | validation: 0.018356587120872986]
	TIME [epoch: 5.7 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01701885628289476		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.01701885628289476 | validation: 0.023551174237251553]
	TIME [epoch: 5.7 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015467273966828107		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.015467273966828107 | validation: 0.01717792026150498]
	TIME [epoch: 5.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01358932013966235		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.01358932013966235 | validation: 0.020872609878556006]
	TIME [epoch: 5.72 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0136336570462321		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.0136336570462321 | validation: 0.025788653148832674]
	TIME [epoch: 5.71 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01249502285046828		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.01249502285046828 | validation: 0.02302702370588337]
	TIME [epoch: 5.7 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015330367953375477		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.015330367953375477 | validation: 0.024953066553459698]
	TIME [epoch: 5.7 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015189834291949108		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.015189834291949108 | validation: 0.027060025655744495]
	TIME [epoch: 5.7 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01642620334844373		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.01642620334844373 | validation: 0.02853011134224468]
	TIME [epoch: 5.7 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014569216499508014		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.014569216499508014 | validation: 0.017378534100481197]
	TIME [epoch: 5.7 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01191976215033776		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.01191976215033776 | validation: 0.017432486236564508]
	TIME [epoch: 5.74 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011970768860254926		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.011970768860254926 | validation: 0.02649866210479412]
	TIME [epoch: 5.7 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016183659431077975		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.016183659431077975 | validation: 0.018749211183763596]
	TIME [epoch: 5.7 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012948196435245318		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.012948196435245318 | validation: 0.014997763098657501]
	TIME [epoch: 5.7 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011951642688897535		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.011951642688897535 | validation: 0.02860476698957803]
	TIME [epoch: 5.7 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014375574231261467		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.014375574231261467 | validation: 0.02156188591337289]
	TIME [epoch: 5.7 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011916338959561597		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.011916338959561597 | validation: 0.01880937356977175]
	TIME [epoch: 5.72 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013451211003871647		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.013451211003871647 | validation: 0.02205497081720403]
	TIME [epoch: 5.71 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013201122885470491		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.013201122885470491 | validation: 0.021566337886975467]
	TIME [epoch: 5.7 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012758672026992485		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.012758672026992485 | validation: 0.021535272422426744]
	TIME [epoch: 5.7 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016271582804973535		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.016271582804973535 | validation: 0.02414166813773539]
	TIME [epoch: 5.7 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01253350854552817		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.01253350854552817 | validation: 0.013968223143231952]
	TIME [epoch: 5.7 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015108923163769947		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.015108923163769947 | validation: 0.022248936706402]
	TIME [epoch: 5.7 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01781545082062103		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.01781545082062103 | validation: 0.032574059542877384]
	TIME [epoch: 5.74 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015102846980622225		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.015102846980622225 | validation: 0.021275315475191833]
	TIME [epoch: 5.7 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01601074435430308		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.01601074435430308 | validation: 0.024873957142162402]
	TIME [epoch: 5.7 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013341481455405733		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.013341481455405733 | validation: 0.031352788398419554]
	TIME [epoch: 5.7 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013293770191653387		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.013293770191653387 | validation: 0.03001543786047737]
	TIME [epoch: 5.7 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015654583262543046		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.015654583262543046 | validation: 0.025472203436718823]
	TIME [epoch: 5.7 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010925719384468183		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.010925719384468183 | validation: 0.022652687082972252]
	TIME [epoch: 5.73 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015927281016523902		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.015927281016523902 | validation: 0.014570504478635398]
	TIME [epoch: 5.72 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010804204703813554		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.010804204703813554 | validation: 0.022756562112591975]
	TIME [epoch: 5.71 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014501306199829271		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.014501306199829271 | validation: 0.014376864594448993]
	TIME [epoch: 5.7 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016159846208263877		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.016159846208263877 | validation: 0.026185619160867334]
	TIME [epoch: 5.71 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015227266280702688		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.015227266280702688 | validation: 0.024860614250195843]
	TIME [epoch: 5.7 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016347973284258993		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.016347973284258993 | validation: 0.021462958417587222]
	TIME [epoch: 5.71 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015564637721943185		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.015564637721943185 | validation: 0.017979282893853726]
	TIME [epoch: 5.75 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014205317349472339		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.014205317349472339 | validation: 0.03270310066356068]
	TIME [epoch: 5.71 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013809961979996954		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.013809961979996954 | validation: 0.023825383770175727]
	TIME [epoch: 5.71 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012550695247615411		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.012550695247615411 | validation: 0.02384440128632656]
	TIME [epoch: 5.71 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015585032043194481		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.015585032043194481 | validation: 0.022455684054951432]
	TIME [epoch: 5.71 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011559679309959624		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.011559679309959624 | validation: 0.022457698479824106]
	TIME [epoch: 5.71 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01583025653754671		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.01583025653754671 | validation: 0.02711424845042581]
	TIME [epoch: 5.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015882725532500353		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.015882725532500353 | validation: 0.02153765792300704]
	TIME [epoch: 5.72 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013683672711142644		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.013683672711142644 | validation: 0.026264690241743348]
	TIME [epoch: 5.71 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017002876788818837		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.017002876788818837 | validation: 0.02099270308155716]
	TIME [epoch: 5.71 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017530662331857256		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.017530662331857256 | validation: 0.020469733297440843]
	TIME [epoch: 5.71 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019726902733871825		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.019726902733871825 | validation: 0.02486129692800387]
	TIME [epoch: 5.71 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01590519633902063		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.01590519633902063 | validation: 0.02654508052441322]
	TIME [epoch: 5.71 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01256369426346637		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.01256369426346637 | validation: 0.01835988467739783]
	TIME [epoch: 5.75 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016673077195337314		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.016673077195337314 | validation: 0.023461138309504755]
	TIME [epoch: 5.71 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013582776212180245		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.013582776212180245 | validation: 0.029588743386429365]
	TIME [epoch: 5.71 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01599110732953961		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.01599110732953961 | validation: 0.0208282497858568]
	TIME [epoch: 5.71 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013261181196965524		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.013261181196965524 | validation: 0.021821570985760343]
	TIME [epoch: 5.71 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01612223456848292		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.01612223456848292 | validation: 0.019847901278531133]
	TIME [epoch: 5.71 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013282990960646321		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.013282990960646321 | validation: 0.020305249409594765]
	TIME [epoch: 5.73 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012431844411911109		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.012431844411911109 | validation: 0.022719240512659705]
	TIME [epoch: 5.72 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010087453411878305		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.010087453411878305 | validation: 0.02344389223723085]
	TIME [epoch: 5.71 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016096822317715122		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.016096822317715122 | validation: 0.023939873301691394]
	TIME [epoch: 5.71 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011487491884503237		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.011487491884503237 | validation: 0.019700237506798376]
	TIME [epoch: 5.71 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015370711309205986		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.015370711309205986 | validation: 0.019947178260638902]
	TIME [epoch: 5.71 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013653206229158912		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.013653206229158912 | validation: 0.016676465546917246]
	TIME [epoch: 5.71 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009249730524599892		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.009249730524599892 | validation: 0.01876469674762004]
	TIME [epoch: 5.75 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013620276716474741		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.013620276716474741 | validation: 0.024402195359395334]
	TIME [epoch: 5.71 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018349210349389633		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.018349210349389633 | validation: 0.014349814467407756]
	TIME [epoch: 5.71 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014556541886614632		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.014556541886614632 | validation: 0.023541405166304756]
	TIME [epoch: 5.7 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011573823303438781		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.011573823303438781 | validation: 0.022749205627506527]
	TIME [epoch: 5.7 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017877900200518194		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.017877900200518194 | validation: 0.02031445386250761]
	TIME [epoch: 5.71 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013744206431282192		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.013744206431282192 | validation: 0.024573958078334172]
	TIME [epoch: 5.73 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013159986184718135		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.013159986184718135 | validation: 0.020701581837330573]
	TIME [epoch: 5.72 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014271382248415202		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.014271382248415202 | validation: 0.024831517704868824]
	TIME [epoch: 5.71 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015166162005673724		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.015166162005673724 | validation: 0.010921106735706699]
	TIME [epoch: 5.71 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011316594341842675		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.011316594341842675 | validation: 0.021204595155349254]
	TIME [epoch: 5.71 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015089501607456854		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.015089501607456854 | validation: 0.027235529820409082]
	TIME [epoch: 5.71 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01405735740995603		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.01405735740995603 | validation: 0.028346550161071384]
	TIME [epoch: 5.71 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015694199187038675		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.015694199187038675 | validation: 0.028593422833001602]
	TIME [epoch: 5.74 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01478058051573215		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.01478058051573215 | validation: 0.021175420651250523]
	TIME [epoch: 5.71 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01618052932111881		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.01618052932111881 | validation: 0.023370851166762473]
	TIME [epoch: 5.71 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015113956295039026		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.015113956295039026 | validation: 0.023655716907617787]
	TIME [epoch: 5.71 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01512377347262453		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.01512377347262453 | validation: 0.020847286708825283]
	TIME [epoch: 5.71 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012705324373330761		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.012705324373330761 | validation: 0.022644716222619952]
	TIME [epoch: 5.71 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014608378517327467		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.014608378517327467 | validation: 0.02287567895664268]
	TIME [epoch: 5.73 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017507233319139507		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.017507233319139507 | validation: 0.025492571232385682]
	TIME [epoch: 5.72 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010147281005192566		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.010147281005192566 | validation: 0.023663915845732603]
	TIME [epoch: 5.71 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014659654192985346		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.014659654192985346 | validation: 0.01834531510286153]
	TIME [epoch: 5.7 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012220517262690753		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.012220517262690753 | validation: 0.021889320816477396]
	TIME [epoch: 5.71 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014880568773571946		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.014880568773571946 | validation: 0.024917050561927084]
	TIME [epoch: 5.7 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01588563542618763		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.01588563542618763 | validation: 0.02540019664240143]
	TIME [epoch: 5.71 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014268469509086567		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.014268469509086567 | validation: 0.021920937985479894]
	TIME [epoch: 5.74 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016026219166110446		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.016026219166110446 | validation: 0.021225075474970278]
	TIME [epoch: 5.71 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012074430143306173		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.012074430143306173 | validation: 0.02315669746564363]
	TIME [epoch: 5.71 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014715863592943664		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.014715863592943664 | validation: 0.021709902749935808]
	TIME [epoch: 5.71 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014879422708726893		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.014879422708726893 | validation: 0.02741677447170302]
	TIME [epoch: 5.71 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014127951525199604		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.014127951525199604 | validation: 0.01787109082270594]
	TIME [epoch: 5.71 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013734310527615734		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.013734310527615734 | validation: 0.028229505877736177]
	TIME [epoch: 5.73 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018341474675296725		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.018341474675296725 | validation: 0.026152699662622684]
	TIME [epoch: 5.72 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014340595421312292		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.014340595421312292 | validation: 0.021730214515250843]
	TIME [epoch: 5.71 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014007807382931779		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.014007807382931779 | validation: 0.024495806540273817]
	TIME [epoch: 5.7 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018292740853784677		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.018292740853784677 | validation: 0.021932538847291926]
	TIME [epoch: 5.7 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016742242458244263		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.016742242458244263 | validation: 0.024928154669761168]
	TIME [epoch: 5.71 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019505503621819784		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.019505503621819784 | validation: 0.019982414776736585]
	TIME [epoch: 5.71 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015475331800071695		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.015475331800071695 | validation: 0.02308986745279768]
	TIME [epoch: 5.75 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015679408988264344		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.015679408988264344 | validation: 0.02325914735253192]
	TIME [epoch: 5.71 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016677337008542247		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.016677337008542247 | validation: 0.022513892755876955]
	TIME [epoch: 5.7 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01735097300761781		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.01735097300761781 | validation: 0.028890106830385617]
	TIME [epoch: 5.71 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018177448423140532		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.018177448423140532 | validation: 0.014556368492474644]
	TIME [epoch: 5.7 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01736766049851926		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.01736766049851926 | validation: 0.018177507022224267]
	TIME [epoch: 5.7 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019155054083694383		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.019155054083694383 | validation: 0.01636515701721783]
	TIME [epoch: 5.74 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015236129658303385		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.015236129658303385 | validation: 0.021623608617199214]
	TIME [epoch: 5.72 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01257481982027544		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.01257481982027544 | validation: 0.022162919730422566]
	TIME [epoch: 5.71 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018020039231912033		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.018020039231912033 | validation: 0.014950982290874246]
	TIME [epoch: 5.71 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015587324944212727		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.015587324944212727 | validation: 0.0193783663702331]
	TIME [epoch: 5.71 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01423485570441295		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.01423485570441295 | validation: 0.021651508190480354]
	TIME [epoch: 5.7 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013842108130844471		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.013842108130844471 | validation: 0.01767324212269661]
	TIME [epoch: 5.71 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016457241256194494		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.016457241256194494 | validation: 0.026840227818687667]
	TIME [epoch: 5.74 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01501033307686672		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.01501033307686672 | validation: 0.02917749812169093]
	TIME [epoch: 5.71 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012773068701546222		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.012773068701546222 | validation: 0.021481563854710437]
	TIME [epoch: 5.71 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014292138199634515		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.014292138199634515 | validation: 0.025736852132261918]
	TIME [epoch: 5.7 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012777090354252434		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.012777090354252434 | validation: 0.01661692723198497]
	TIME [epoch: 5.7 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015927916276711255		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.015927916276711255 | validation: 0.018001914041965]
	TIME [epoch: 5.71 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0155047722468129		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.0155047722468129 | validation: 0.023787314400919496]
	TIME [epoch: 5.74 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0136126618936271		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.0136126618936271 | validation: 0.01785713963148512]
	TIME [epoch: 5.72 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018243475314754204		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.018243475314754204 | validation: 0.021386192146263028]
	TIME [epoch: 5.72 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016093493527417735		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.016093493527417735 | validation: 0.021892407096245306]
	TIME [epoch: 5.7 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016072005168758383		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.016072005168758383 | validation: 0.024235567328074283]
	TIME [epoch: 5.71 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014782097356439008		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.014782097356439008 | validation: 0.022603725474806335]
	TIME [epoch: 5.71 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015708389078621966		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.015708389078621966 | validation: 0.02143406661801299]
	TIME [epoch: 5.71 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014526584118347716		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.014526584118347716 | validation: 0.02665204655175826]
	TIME [epoch: 5.74 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013696816765086895		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.013696816765086895 | validation: 0.025668015471277183]
	TIME [epoch: 5.71 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014389605125583892		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.014389605125583892 | validation: 0.024087103712643332]
	TIME [epoch: 5.71 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01742661975951289		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.01742661975951289 | validation: 0.02067948997480578]
	TIME [epoch: 5.71 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01590601690897432		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.01590601690897432 | validation: 0.031043015089877214]
	TIME [epoch: 5.7 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01706934414779091		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.01706934414779091 | validation: 0.03092812513291186]
	TIME [epoch: 5.71 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017358417068100918		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.017358417068100918 | validation: 0.025554969602422636]
	TIME [epoch: 5.73 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015939195277937756		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.015939195277937756 | validation: 0.03489150479379614]
	TIME [epoch: 5.72 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014449412882427591		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.014449412882427591 | validation: 0.031276038451824605]
	TIME [epoch: 5.71 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017784417803664947		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.017784417803664947 | validation: 0.02886652091659971]
	TIME [epoch: 5.7 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01590558515700826		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.01590558515700826 | validation: 0.0280600289877342]
	TIME [epoch: 5.71 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013642475351204823		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.013642475351204823 | validation: 0.015601093843652448]
	TIME [epoch: 5.7 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013184222021446833		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.013184222021446833 | validation: 0.02318574019743713]
	TIME [epoch: 5.71 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011196733061745083		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.011196733061745083 | validation: 0.03250569823634442]
	TIME [epoch: 5.74 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013355725716824262		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.013355725716824262 | validation: 0.02169122041943245]
	TIME [epoch: 5.71 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014514696760212154		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.014514696760212154 | validation: 0.020872468109283098]
	TIME [epoch: 5.71 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01519979067628142		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.01519979067628142 | validation: 0.02399582409943449]
	TIME [epoch: 5.71 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01526475049562279		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.01526475049562279 | validation: 0.01491323651003272]
	TIME [epoch: 5.71 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012906288946525011		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.012906288946525011 | validation: 0.015768209440427047]
	TIME [epoch: 5.71 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015550134801709511		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.015550134801709511 | validation: 0.028460709158966334]
	TIME [epoch: 5.73 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013639896373940162		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.013639896373940162 | validation: 0.023382898860424578]
	TIME [epoch: 5.72 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011555025441197143		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.011555025441197143 | validation: 0.028326693403150333]
	TIME [epoch: 5.71 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013440924954713083		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.013440924954713083 | validation: 0.02453177964617403]
	TIME [epoch: 5.7 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01403162197041035		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.01403162197041035 | validation: 0.027135643648752712]
	TIME [epoch: 5.7 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016491463220044692		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.016491463220044692 | validation: 0.030003791763763596]
	TIME [epoch: 5.71 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011370330279705026		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.011370330279705026 | validation: 0.02853493145520802]
	TIME [epoch: 5.71 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012321702128284163		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.012321702128284163 | validation: 0.024361444550053103]
	TIME [epoch: 5.74 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014398681580925946		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.014398681580925946 | validation: 0.02441522194493212]
	TIME [epoch: 5.71 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013406646056631692		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.013406646056631692 | validation: 0.02203432544133007]
	TIME [epoch: 5.71 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014579120948588629		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.014579120948588629 | validation: 0.019788056667752633]
	TIME [epoch: 5.71 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014485169198875677		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.014485169198875677 | validation: 0.014783701922591748]
	TIME [epoch: 5.7 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014449607792350012		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.014449607792350012 | validation: 0.023054820331054958]
	TIME [epoch: 5.71 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013031163143996383		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.013031163143996383 | validation: 0.026214554896890233]
	TIME [epoch: 5.73 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010303069336409372		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.010303069336409372 | validation: 0.015246523293837213]
	TIME [epoch: 5.72 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013320718766345382		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.013320718766345382 | validation: 0.020633633285160213]
	TIME [epoch: 5.71 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012316602279344216		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.012316602279344216 | validation: 0.025511548039711514]
	TIME [epoch: 5.7 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009944909073541317		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.009944909073541317 | validation: 0.020251345431041727]
	TIME [epoch: 5.71 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016764629574054883		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.016764629574054883 | validation: 0.014365440317415669]
	TIME [epoch: 5.71 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013912206289161535		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.013912206289161535 | validation: 0.021355211630596786]
	TIME [epoch: 5.71 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014070829709279952		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.014070829709279952 | validation: 0.01948360472332192]
	TIME [epoch: 5.75 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010477963773691855		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.010477963773691855 | validation: 0.017776426000986934]
	TIME [epoch: 5.71 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014312675320384285		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.014312675320384285 | validation: 0.020435116874115346]
	TIME [epoch: 5.7 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016177779069880008		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.016177779069880008 | validation: 0.01754355603016321]
	TIME [epoch: 5.71 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01120630096550608		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.01120630096550608 | validation: 0.021106246803032174]
	TIME [epoch: 5.7 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008399252972831358		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.008399252972831358 | validation: 0.032757359200308124]
	TIME [epoch: 5.71 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013602860770056669		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.013602860770056669 | validation: 0.0234833082321045]
	TIME [epoch: 5.73 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011199742090356008		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.011199742090356008 | validation: 0.024342911711196038]
	TIME [epoch: 5.73 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013741620662331696		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.013741620662331696 | validation: 0.025704964194656368]
	TIME [epoch: 5.71 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01528579247023884		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.01528579247023884 | validation: 0.02010503519645777]
	TIME [epoch: 5.71 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018249130529142708		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.018249130529142708 | validation: 0.02436222477114762]
	TIME [epoch: 5.71 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01292701540682483		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.01292701540682483 | validation: 0.020249223632784547]
	TIME [epoch: 5.72 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01708388353279477		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.01708388353279477 | validation: 0.031330870838640064]
	TIME [epoch: 5.71 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011109110067557312		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.011109110067557312 | validation: 0.02897937368231576]
	TIME [epoch: 5.75 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013495378671117608		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.013495378671117608 | validation: 0.03342570040954382]
	TIME [epoch: 5.71 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012834664443414117		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.012834664443414117 | validation: 0.022411763953890402]
	TIME [epoch: 5.71 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017783416010058457		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.017783416010058457 | validation: 0.0191488320992825]
	TIME [epoch: 5.7 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012480392739876793		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.012480392739876793 | validation: 0.030752869432911063]
	TIME [epoch: 5.71 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012118055519826913		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.012118055519826913 | validation: 0.012541907786884006]
	TIME [epoch: 5.71 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014844543259227941		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.014844543259227941 | validation: 0.018677034909522695]
	TIME [epoch: 5.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012285833014208188		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.012285833014208188 | validation: 0.022919520065529646]
	TIME [epoch: 5.73 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017681201365334777		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.017681201365334777 | validation: 0.022888148421832916]
	TIME [epoch: 5.71 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009345707662186528		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.009345707662186528 | validation: 0.02421546606858347]
	TIME [epoch: 5.71 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014106066092830457		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.014106066092830457 | validation: 0.030097218696728944]
	TIME [epoch: 5.71 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011086308582663936		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.011086308582663936 | validation: 0.019966150941573408]
	TIME [epoch: 5.7 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011407428382795341		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.011407428382795341 | validation: 0.025350728767284815]
	TIME [epoch: 5.71 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013175259514210226		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.013175259514210226 | validation: 0.02671374922767247]
	TIME [epoch: 5.75 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014013754357620669		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.014013754357620669 | validation: 0.02663578945809949]
	TIME [epoch: 5.71 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012342917245385743		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.012342917245385743 | validation: 0.02543943184857831]
	TIME [epoch: 5.71 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01377393223346285		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.01377393223346285 | validation: 0.028128791177380773]
	TIME [epoch: 5.71 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012884538856850586		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.012884538856850586 | validation: 0.01831257786260674]
	TIME [epoch: 5.71 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013782273375784866		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.013782273375784866 | validation: 0.028757646570495777]
	TIME [epoch: 5.71 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014959322819404285		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.014959322819404285 | validation: 0.017453787060785673]
	TIME [epoch: 5.73 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013478514782452005		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.013478514782452005 | validation: 0.01351589118057877]
	TIME [epoch: 5.73 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012513363998180288		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.012513363998180288 | validation: 0.017476884252424957]
	TIME [epoch: 5.71 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014736993506168939		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.014736993506168939 | validation: 0.03244912674230668]
	TIME [epoch: 5.7 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016025535855955605		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.016025535855955605 | validation: 0.026872447288402355]
	TIME [epoch: 5.72 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016340986408926804		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.016340986408926804 | validation: 0.015778005955909235]
	TIME [epoch: 5.7 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01605359201343551		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.01605359201343551 | validation: 0.01599430282303159]
	TIME [epoch: 5.72 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0144941144865892		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.0144941144865892 | validation: 0.019304840924578317]
	TIME [epoch: 5.75 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015033383780149059		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.015033383780149059 | validation: 0.020866850129360525]
	TIME [epoch: 5.72 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015958255370027423		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.015958255370027423 | validation: 0.025519144167555893]
	TIME [epoch: 5.7 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01409596371170245		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.01409596371170245 | validation: 0.018635168727211996]
	TIME [epoch: 5.72 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014131092709699115		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.014131092709699115 | validation: 0.02830187313312268]
	TIME [epoch: 5.7 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016729446595392616		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.016729446595392616 | validation: 0.021953486918355268]
	TIME [epoch: 5.72 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013636683195323717		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.013636683195323717 | validation: 0.027910108110791837]
	TIME [epoch: 5.74 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014341240742809805		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.014341240742809805 | validation: 0.02364948758810609]
	TIME [epoch: 5.74 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015525435758359997		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.015525435758359997 | validation: 0.013979482244866859]
	TIME [epoch: 5.71 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01638828859428815		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.01638828859428815 | validation: 0.01962678649795099]
	TIME [epoch: 5.72 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013261686592893287		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.013261686592893287 | validation: 0.021682180042380907]
	TIME [epoch: 5.71 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013807181256774631		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.013807181256774631 | validation: 0.011806976244391268]
	TIME [epoch: 5.7 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016699905160725566		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.016699905160725566 | validation: 0.017933062839222524]
	TIME [epoch: 5.71 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016874384506618698		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.016874384506618698 | validation: 0.027483644613726224]
	TIME [epoch: 5.75 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015470272586525285		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.015470272586525285 | validation: 0.03297425713967632]
	TIME [epoch: 5.71 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01560001789505322		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.01560001789505322 | validation: 0.023525483530450177]
	TIME [epoch: 5.72 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018604660682283683		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.018604660682283683 | validation: 0.014910635812988305]
	TIME [epoch: 5.71 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01704613260977617		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.01704613260977617 | validation: 0.025092250643609832]
	TIME [epoch: 5.71 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013029784626482147		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.013029784626482147 | validation: 0.022464473113467075]
	TIME [epoch: 5.71 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014546043222387381		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.014546043222387381 | validation: 0.02058947656947765]
	TIME [epoch: 5.75 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01450567050254902		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.01450567050254902 | validation: 0.02705883415684075]
	TIME [epoch: 5.72 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01557265345439266		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.01557265345439266 | validation: 0.019783621379722668]
	TIME [epoch: 5.72 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012301596033817464		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.012301596033817464 | validation: 0.021508153900768656]
	TIME [epoch: 5.7 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01545501157166264		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.01545501157166264 | validation: 0.016140716825728246]
	TIME [epoch: 5.71 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01572755998372475		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.01572755998372475 | validation: 0.02535410077090653]
	TIME [epoch: 5.72 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012306750970005824		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.012306750970005824 | validation: 0.019841020055022238]
	TIME [epoch: 5.72 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012259577841687984		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.012259577841687984 | validation: 0.03344916944313829]
	TIME [epoch: 5.76 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013570995756182086		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.013570995756182086 | validation: 0.02582445966612334]
	TIME [epoch: 5.71 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013917015079308277		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.013917015079308277 | validation: 0.02303690944414513]
	TIME [epoch: 5.71 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011297290748926912		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.011297290748926912 | validation: 0.023320973526643116]
	TIME [epoch: 5.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01513213775967732		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.01513213775967732 | validation: 0.022602871816717038]
	TIME [epoch: 5.72 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016085732028316254		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.016085732028316254 | validation: 0.02703893926065735]
	TIME [epoch: 5.72 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014532365062469289		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.014532365062469289 | validation: 0.01941728916398817]
	TIME [epoch: 5.74 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016591288557999614		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.016591288557999614 | validation: 0.02781163652951102]
	TIME [epoch: 5.74 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016795764934442875		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.016795764934442875 | validation: 0.0209066754324577]
	TIME [epoch: 5.72 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013452507060105166		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.013452507060105166 | validation: 0.025371562159348812]
	TIME [epoch: 5.72 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01536322325583089		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.01536322325583089 | validation: 0.01585350341306734]
	TIME [epoch: 5.72 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013217803804947383		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.013217803804947383 | validation: 0.0211613137938401]
	TIME [epoch: 5.72 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012340554038005215		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.012340554038005215 | validation: 0.031788149928568585]
	TIME [epoch: 5.72 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012927119001504948		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.012927119001504948 | validation: 0.009038612070650431]
	TIME [epoch: 5.76 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010203347457578922		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.010203347457578922 | validation: 0.025974910740266068]
	TIME [epoch: 5.71 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014676767168682641		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.014676767168682641 | validation: 0.024639879198425262]
	TIME [epoch: 5.7 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011507565354516712		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.011507565354516712 | validation: 0.021941100814097194]
	TIME [epoch: 5.72 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016487882587790235		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.016487882587790235 | validation: 0.019390865166547356]
	TIME [epoch: 5.71 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01281794407306695		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.01281794407306695 | validation: 0.028261452466221918]
	TIME [epoch: 5.7 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016611766636011823		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.016611766636011823 | validation: 0.021624323973869083]
	TIME [epoch: 5.73 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013175825256479406		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.013175825256479406 | validation: 0.02689961615798853]
	TIME [epoch: 5.72 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012007159243671772		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.012007159243671772 | validation: 0.023187807800063406]
	TIME [epoch: 5.7 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012251552194455017		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.012251552194455017 | validation: 0.019329056925289755]
	TIME [epoch: 5.71 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014432466653450432		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.014432466653450432 | validation: 0.019443875597907584]
	TIME [epoch: 5.7 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014794218125313688		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.014794218125313688 | validation: 0.01902775588109051]
	TIME [epoch: 5.7 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015189886890140286		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.015189886890140286 | validation: 0.02233356121792754]
	TIME [epoch: 5.72 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019075499557137606		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.019075499557137606 | validation: 0.025814731119422656]
	TIME [epoch: 5.74 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017384268768316186		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.017384268768316186 | validation: 0.01749896937854182]
	TIME [epoch: 5.71 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015157546434737948		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.015157546434737948 | validation: 0.021551102705184896]
	TIME [epoch: 5.7 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010743071140694902		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.010743071140694902 | validation: 0.020904741005377484]
	TIME [epoch: 5.7 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015499108592789704		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.015499108592789704 | validation: 0.019247781907937963]
	TIME [epoch: 5.7 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014252940182846877		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.014252940182846877 | validation: 0.022005836167710093]
	TIME [epoch: 5.7 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015166171941810124		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.015166171941810124 | validation: 0.023009609223861607]
	TIME [epoch: 5.73 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012761556939874475		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.012761556939874475 | validation: 0.017419175855055175]
	TIME [epoch: 5.72 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01514143228129242		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.01514143228129242 | validation: 0.020684524519302458]
	TIME [epoch: 5.7 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014972324717701276		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.014972324717701276 | validation: 0.01663288754179651]
	TIME [epoch: 5.7 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016516015898839043		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.016516015898839043 | validation: 0.02311587292540569]
	TIME [epoch: 5.7 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017252779620600026		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.017252779620600026 | validation: 0.012198714672985753]
	TIME [epoch: 5.7 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01465745249265474		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.01465745249265474 | validation: 0.015551233993328802]
	TIME [epoch: 5.7 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016171382311449135		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.016171382311449135 | validation: 0.02743677604826175]
	TIME [epoch: 5.75 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01572037143286497		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.01572037143286497 | validation: 0.015683512281827256]
	TIME [epoch: 5.71 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01513659413291417		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.01513659413291417 | validation: 0.023047939317800196]
	TIME [epoch: 5.7 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01532533745177575		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.01532533745177575 | validation: 0.016284536787227074]
	TIME [epoch: 5.71 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013752491894800422		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.013752491894800422 | validation: 0.029601422713793905]
	TIME [epoch: 5.7 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014657711230381027		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.014657711230381027 | validation: 0.01736638739089998]
	TIME [epoch: 5.7 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012801324643587197		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.012801324643587197 | validation: 0.018088029067591348]
	TIME [epoch: 5.73 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014827883195680638		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.014827883195680638 | validation: 0.018877359834433217]
	TIME [epoch: 5.72 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013491340467161269		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.013491340467161269 | validation: 0.028095048167752528]
	TIME [epoch: 5.7 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013784473931768772		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.013784473931768772 | validation: 0.021866061794707736]
	TIME [epoch: 5.71 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013977340371903658		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.013977340371903658 | validation: 0.0195762542087861]
	TIME [epoch: 5.72 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014062897498502796		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.014062897498502796 | validation: 0.015014849377998409]
	TIME [epoch: 5.71 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016886697742267857		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.016886697742267857 | validation: 0.02232742609916258]
	TIME [epoch: 5.71 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013770581044425525		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.013770581044425525 | validation: 0.019733709948600974]
	TIME [epoch: 5.74 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01490356090326621		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.01490356090326621 | validation: 0.01654241678117295]
	TIME [epoch: 5.71 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013696482598336043		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.013696482598336043 | validation: 0.03408790336250978]
	TIME [epoch: 5.72 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012217190892334796		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.012217190892334796 | validation: 0.019761369538341247]
	TIME [epoch: 5.72 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01513323837837674		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.01513323837837674 | validation: 0.022782705657079436]
	TIME [epoch: 5.71 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013150791169859103		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.013150791169859103 | validation: 0.018458466109443558]
	TIME [epoch: 5.71 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012773111454438199		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.012773111454438199 | validation: 0.026022435409440076]
	TIME [epoch: 5.74 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011646009751576829		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.011646009751576829 | validation: 0.023514357499208573]
	TIME [epoch: 5.73 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014255647404508222		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.014255647404508222 | validation: 0.022350957149475513]
	TIME [epoch: 5.7 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012714641116232632		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.012714641116232632 | validation: 0.02663761199674731]
	TIME [epoch: 5.7 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013712604860038252		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.013712604860038252 | validation: 0.028187599826282553]
	TIME [epoch: 5.7 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014522018636086226		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.014522018636086226 | validation: 0.020904452131659684]
	TIME [epoch: 5.7 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01505691029210315		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.01505691029210315 | validation: 0.023981363225471918]
	TIME [epoch: 5.72 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012873779034033448		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.012873779034033448 | validation: 0.018934476790889238]
	TIME [epoch: 5.74 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017764317521360436		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.017764317521360436 | validation: 0.028328090629051856]
	TIME [epoch: 5.72 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013211092674143842		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.013211092674143842 | validation: 0.017064502579195305]
	TIME [epoch: 5.7 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01094575561337591		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.01094575561337591 | validation: 0.023955786960934353]
	TIME [epoch: 5.71 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015252723891609019		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.015252723891609019 | validation: 0.01984287246113736]
	TIME [epoch: 5.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01575087235058593		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.01575087235058593 | validation: 0.021198464523778916]
	TIME [epoch: 5.7 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009215263338994646		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.009215263338994646 | validation: 0.01888166010322306]
	TIME [epoch: 5.74 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010345505202590326		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.010345505202590326 | validation: 0.024764920352124877]
	TIME [epoch: 5.74 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01217255731064508		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.01217255731064508 | validation: 0.025967769647862803]
	TIME [epoch: 5.72 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013479175730212234		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.013479175730212234 | validation: 0.022348087449333778]
	TIME [epoch: 5.72 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011571131777193126		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.011571131777193126 | validation: 0.019977200773957104]
	TIME [epoch: 5.72 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010610191182076286		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.010610191182076286 | validation: 0.021913387675945972]
	TIME [epoch: 5.72 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017632967598623414		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.017632967598623414 | validation: 0.024406278405539307]
	TIME [epoch: 5.72 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015107402678469595		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.015107402678469595 | validation: 0.02054538649772429]
	TIME [epoch: 5.76 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013902268083290457		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.013902268083290457 | validation: 0.020279522982180196]
	TIME [epoch: 5.72 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014351555962383878		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.014351555962383878 | validation: 0.020976689749515217]
	TIME [epoch: 5.72 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010790080773428627		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.010790080773428627 | validation: 0.026193241621210613]
	TIME [epoch: 5.72 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016007333574833943		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.016007333574833943 | validation: 0.024962984092370556]
	TIME [epoch: 5.72 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018491945246837362		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.018491945246837362 | validation: 0.020579295189153936]
	TIME [epoch: 5.72 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015053384856134357		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.015053384856134357 | validation: 0.027070601848610838]
	TIME [epoch: 5.74 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012146637079711657		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.012146637079711657 | validation: 0.028080236134897678]
	TIME [epoch: 5.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015531688555365797		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.015531688555365797 | validation: 0.009633640173296988]
	TIME [epoch: 5.72 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014728693498418832		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.014728693498418832 | validation: 0.01691144428676227]
	TIME [epoch: 5.72 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01368209642392182		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.01368209642392182 | validation: 0.016151343018367213]
	TIME [epoch: 5.72 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010509013107460266		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.010509013107460266 | validation: 0.01863594822198052]
	TIME [epoch: 5.72 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012428555509171928		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.012428555509171928 | validation: 0.019193486902523066]
	TIME [epoch: 5.7 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012383049918480472		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.012383049918480472 | validation: 0.025110639388925986]
	TIME [epoch: 5.74 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012669454339537312		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.012669454339537312 | validation: 0.020898853130002087]
	TIME [epoch: 5.72 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01361493532860877		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.01361493532860877 | validation: 0.025971973492066033]
	TIME [epoch: 5.72 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011744985539163397		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.011744985539163397 | validation: 0.022785264634306027]
	TIME [epoch: 5.72 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014103491074690045		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.014103491074690045 | validation: 0.019288558688034644]
	TIME [epoch: 5.72 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014100764224155894		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.014100764224155894 | validation: 0.02344410591856426]
	TIME [epoch: 5.7 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014030165460768707		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.014030165460768707 | validation: 0.01796203818619738]
	TIME [epoch: 5.72 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01510592471692809		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.01510592471692809 | validation: 0.022749602880472446]
	TIME [epoch: 5.72 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013101390739923746		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.013101390739923746 | validation: 0.0236526485675487]
	TIME [epoch: 5.72 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013491803286102805		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.013491803286102805 | validation: 0.018748007726875782]
	TIME [epoch: 5.72 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017040324866616493		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.017040324866616493 | validation: 0.027526191229431275]
	TIME [epoch: 5.7 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011619894774423338		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.011619894774423338 | validation: 0.023992045220904767]
	TIME [epoch: 5.72 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012536014624274235		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.012536014624274235 | validation: 0.02244274577239859]
	TIME [epoch: 5.7 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015168622485185329		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.015168622485185329 | validation: 0.019644780097917126]
	TIME [epoch: 5.74 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011894916878720893		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.011894916878720893 | validation: 0.022485288973205276]
	TIME [epoch: 5.7 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016891568062585894		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.016891568062585894 | validation: 0.023454404610170322]
	TIME [epoch: 5.7 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012616855631229674		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.012616855631229674 | validation: 0.012950506815254172]
	TIME [epoch: 5.7 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019112293122751835		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.019112293122751835 | validation: 0.021173337621622053]
	TIME [epoch: 5.7 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012758590444290646		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.012758590444290646 | validation: 0.022349208046342165]
	TIME [epoch: 5.72 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013563620986316003		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.013563620986316003 | validation: 0.020421255379116387]
	TIME [epoch: 5.73 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013897714966202625		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.013897714966202625 | validation: 0.016665370509748395]
	TIME [epoch: 5.72 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014563261097287523		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.014563261097287523 | validation: 0.021933886236511473]
	TIME [epoch: 5.7 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01580669962202822		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.01580669962202822 | validation: 0.020136654636522044]
	TIME [epoch: 5.7 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016236878611896845		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.016236878611896845 | validation: 0.022129762378772313]
	TIME [epoch: 5.7 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01040527691455607		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.01040527691455607 | validation: 0.015739795835610984]
	TIME [epoch: 5.7 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012844061791011933		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.012844061791011933 | validation: 0.027162120946852372]
	TIME [epoch: 5.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014511996829856605		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.014511996829856605 | validation: 0.024421593477190626]
	TIME [epoch: 5.76 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015919165928746187		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.015919165928746187 | validation: 0.020519398712358177]
	TIME [epoch: 5.72 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011700309337751496		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.011700309337751496 | validation: 0.0273838065677434]
	TIME [epoch: 5.72 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01347313394675329		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.01347313394675329 | validation: 0.014852058650801237]
	TIME [epoch: 5.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013695187844872276		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.013695187844872276 | validation: 0.024744276221875056]
	TIME [epoch: 5.7 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01255118067395201		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.01255118067395201 | validation: 0.025513105839133292]
	TIME [epoch: 5.7 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014207557199557783		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.014207557199557783 | validation: 0.027240358659520375]
	TIME [epoch: 5.72 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013727424488539478		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.013727424488539478 | validation: 0.02013131777511787]
	TIME [epoch: 5.72 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013375340638177326		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.013375340638177326 | validation: 0.01217203732884641]
	TIME [epoch: 5.7 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015757431831203567		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.015757431831203567 | validation: 0.023403012386992064]
	TIME [epoch: 5.7 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008737028038864883		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.008737028038864883 | validation: 0.02904292002391325]
	TIME [epoch: 5.72 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014412882550110747		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.014412882550110747 | validation: 0.030251721830274747]
	TIME [epoch: 5.72 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010962805581562195		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.010962805581562195 | validation: 0.01872796776315223]
	TIME [epoch: 5.72 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010524180506485188		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.010524180506485188 | validation: 0.02361607280165142]
	TIME [epoch: 5.76 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015595805685175069		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.015595805685175069 | validation: 0.01828045348882783]
	TIME [epoch: 5.72 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009919416564272605		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.009919416564272605 | validation: 0.01812183634778349]
	TIME [epoch: 5.72 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01262225309008295		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.01262225309008295 | validation: 0.01926032107545836]
	TIME [epoch: 5.72 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01132010835211539		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.01132010835211539 | validation: 0.022289961469568454]
	TIME [epoch: 5.7 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014912320104238267		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.014912320104238267 | validation: 0.025109593809045632]
	TIME [epoch: 5.7 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014429400087773884		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.014429400087773884 | validation: 0.0279576022522484]
	TIME [epoch: 5.73 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0116725993349534		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.0116725993349534 | validation: 0.019701997586133654]
	TIME [epoch: 5.72 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01045755189881888		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.01045755189881888 | validation: 0.02819739592193694]
	TIME [epoch: 5.7 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014776933240023778		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.014776933240023778 | validation: 0.019734290838139254]
	TIME [epoch: 5.7 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011677427687275001		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.011677427687275001 | validation: 0.021078849215672636]
	TIME [epoch: 5.7 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012850523783832914		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.012850523783832914 | validation: 0.014041324724556648]
	TIME [epoch: 5.7 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010195634813137757		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.010195634813137757 | validation: 0.027221218065216872]
	TIME [epoch: 5.7 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013024598246971756		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.013024598246971756 | validation: 0.019495452339779045]
	TIME [epoch: 5.74 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011887358889862979		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.011887358889862979 | validation: 0.01617517318232329]
	TIME [epoch: 5.71 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013719626696056844		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.013719626696056844 | validation: 0.020766369588557678]
	TIME [epoch: 5.7 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013219559050561273		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.013219559050561273 | validation: 0.029721957909441005]
	TIME [epoch: 5.7 sec]
Finished training in 11630.659 seconds.
