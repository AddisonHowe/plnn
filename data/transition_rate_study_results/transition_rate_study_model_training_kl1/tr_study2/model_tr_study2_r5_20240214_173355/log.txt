Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r5', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1238811752

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/20] avg loss: 7.619307846310603		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.897284495056871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.758296170683737 | validation: 5.721436431642598]
	TIME [epoch: 48.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/20] avg loss: 5.1174937859795815		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.592795519612506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.855144652796044 | validation: 3.5411519185432017]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/20] avg loss: 3.9845561520718284		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.4002258821206146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6923910170962215 | validation: 2.822355426853009]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/20] avg loss: 2.938066723274572		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.7183542440096042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.828210483642088 | validation: 2.3793598672030623]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/20] avg loss: 2.3940402572441974		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.6441173304867154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5190787938654564 | validation: 2.7470560258811307]
	TIME [epoch: 8.9 sec]
EPOCH 6/500:
	Training over batches...
		[batch 10/20] avg loss: 2.2903767630109444		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.0915676751530867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.190972219082016 | validation: 1.9438642365251289]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/20] avg loss: 2.0388762094328294		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.536861668504585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7878689389687072 | validation: 2.8779529291903616]
	TIME [epoch: 8.88 sec]
EPOCH 8/500:
	Training over batches...
		[batch 10/20] avg loss: 1.9224082936068008		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3603979541852762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6414031238960387 | validation: 2.585998366754345]
	TIME [epoch: 8.92 sec]
EPOCH 9/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3190538815507018		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5394755130980826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.429264697324392 | validation: 0.9966953382343335]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1804299638028646		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.0299546812554898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.105192322529177 | validation: 0.7084385831931146]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0399613549221902		[learning rate: 0.0099789]
		[batch 20/20] avg loss: 0.9744919021363512		[learning rate: 0.0099555]
	Learning Rate: 0.00995546
	LOSS [training: 1.0072266285292706 | validation: 0.5474330535239701]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9222113170967846		[learning rate: 0.0099321]
		[batch 20/20] avg loss: 0.8892216996456375		[learning rate: 0.0099088]
	Learning Rate: 0.00990879
	LOSS [training: 0.9057165083712109 | validation: 1.4053850783654636]
	TIME [epoch: 8.9 sec]
EPOCH 13/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9119057459932641		[learning rate: 0.0098855]
		[batch 20/20] avg loss: 0.8730848685836892		[learning rate: 0.0098623]
	Learning Rate: 0.00986233
	LOSS [training: 0.8924953072884765 | validation: 0.4906339134468537]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/20] avg loss: 0.69769931878172		[learning rate: 0.0098392]
		[batch 20/20] avg loss: 0.7827796900848978		[learning rate: 0.0098161]
	Learning Rate: 0.0098161
	LOSS [training: 0.740239504433309 | validation: 0.48280489710710883]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7610893405268436		[learning rate: 0.0097931]
		[batch 20/20] avg loss: 0.7223932089121587		[learning rate: 0.0097701]
	Learning Rate: 0.00977008
	LOSS [training: 0.7417412747195012 | validation: 0.4580762683897348]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7473049498556724		[learning rate: 0.0097471]
		[batch 20/20] avg loss: 0.6272262990197233		[learning rate: 0.0097243]
	Learning Rate: 0.00972427
	LOSS [training: 0.6872656244376979 | validation: 0.7846970692726267]
	TIME [epoch: 8.88 sec]
EPOCH 17/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9358749912176471		[learning rate: 0.0097015]
		[batch 20/20] avg loss: 0.7256076295091036		[learning rate: 0.0096787]
	Learning Rate: 0.00967868
	LOSS [training: 0.8307413103633753 | validation: 0.40412122559902663]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 10/20] avg loss: 0.707087168426794		[learning rate: 0.009656]
		[batch 20/20] avg loss: 0.7042664599333424		[learning rate: 0.0096333]
	Learning Rate: 0.00963331
	LOSS [training: 0.705676814180068 | validation: 0.614105716068488]
	TIME [epoch: 8.89 sec]
EPOCH 19/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6169396738939485		[learning rate: 0.0096107]
		[batch 20/20] avg loss: 0.7339733699434167		[learning rate: 0.0095881]
	Learning Rate: 0.00958815
	LOSS [training: 0.6754565219186827 | validation: 0.8288676739472398]
	TIME [epoch: 8.88 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7383149090592506		[learning rate: 0.0095656]
		[batch 20/20] avg loss: 0.6332526468652309		[learning rate: 0.0095432]
	Learning Rate: 0.0095432
	LOSS [training: 0.6857837779622408 | validation: 0.7645474981235663]
	TIME [epoch: 8.89 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7151936317329906		[learning rate: 0.0095208]
		[batch 20/20] avg loss: 1.0422093188062493		[learning rate: 0.0094985]
	Learning Rate: 0.00949846
	LOSS [training: 0.87870147526962 | validation: 0.4248650001120343]
	TIME [epoch: 8.9 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5488500028173511		[learning rate: 0.0094762]
		[batch 20/20] avg loss: 0.5941185395143459		[learning rate: 0.0094539]
	Learning Rate: 0.00945393
	LOSS [training: 0.5714842711658484 | validation: 1.006214357036218]
	TIME [epoch: 8.91 sec]
EPOCH 23/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6465820073505358		[learning rate: 0.0094317]
		[batch 20/20] avg loss: 0.731388866667398		[learning rate: 0.0094096]
	Learning Rate: 0.00940961
	LOSS [training: 0.6889854370089669 | validation: 0.6528636054476953]
	TIME [epoch: 8.88 sec]
EPOCH 24/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6160166824046234		[learning rate: 0.0093875]
		[batch 20/20] avg loss: 0.522102127102852		[learning rate: 0.0093655]
	Learning Rate: 0.00936549
	LOSS [training: 0.5690594047537376 | validation: 0.6343964956381307]
	TIME [epoch: 8.88 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6494857067823651		[learning rate: 0.0093435]
		[batch 20/20] avg loss: 0.8026545689121267		[learning rate: 0.0093216]
	Learning Rate: 0.00932159
	LOSS [training: 0.7260701378472458 | validation: 0.4992202136179398]
	TIME [epoch: 8.89 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5656121430155691		[learning rate: 0.0092997]
		[batch 20/20] avg loss: 0.5828667354797513		[learning rate: 0.0092779]
	Learning Rate: 0.00927788
	LOSS [training: 0.5742394392476602 | validation: 0.7438892731228707]
	TIME [epoch: 8.9 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6503000480929881		[learning rate: 0.0092561]
		[batch 20/20] avg loss: 0.4979791678948984		[learning rate: 0.0092344]
	Learning Rate: 0.00923439
	LOSS [training: 0.5741396079939433 | validation: 0.49766839452946166]
	TIME [epoch: 8.89 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5359383035786057		[learning rate: 0.0092127]
		[batch 20/20] avg loss: 0.580818353184028		[learning rate: 0.0091911]
	Learning Rate: 0.0091911
	LOSS [training: 0.5583783283813168 | validation: 0.5526282067528308]
	TIME [epoch: 8.88 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6514055188257499		[learning rate: 0.0091695]
		[batch 20/20] avg loss: 0.646881992755271		[learning rate: 0.009148]
	Learning Rate: 0.00914801
	LOSS [training: 0.6491437557905103 | validation: 0.522744056778343]
	TIME [epoch: 8.88 sec]
EPOCH 30/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5741189007907123		[learning rate: 0.0091265]
		[batch 20/20] avg loss: 0.6019051877990413		[learning rate: 0.0091051]
	Learning Rate: 0.00910512
	LOSS [training: 0.5880120442948769 | validation: 0.5110459840749333]
	TIME [epoch: 8.89 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5678105767621583		[learning rate: 0.0090838]
		[batch 20/20] avg loss: 0.5578877431352481		[learning rate: 0.0090624]
	Learning Rate: 0.00906243
	LOSS [training: 0.5628491599487031 | validation: 0.48467074260947446]
	TIME [epoch: 8.91 sec]
EPOCH 32/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5155888872547365		[learning rate: 0.0090412]
		[batch 20/20] avg loss: 0.6557436570610918		[learning rate: 0.0090199]
	Learning Rate: 0.00901995
	LOSS [training: 0.5856662721579142 | validation: 0.5865365385432524]
	TIME [epoch: 8.89 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5718265561225363		[learning rate: 0.0089988]
		[batch 20/20] avg loss: 0.5560983656726876		[learning rate: 0.0089777]
	Learning Rate: 0.00897766
	LOSS [training: 0.5639624608976118 | validation: 0.7812154999408989]
	TIME [epoch: 8.89 sec]
EPOCH 34/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5782407459813653		[learning rate: 0.0089566]
		[batch 20/20] avg loss: 0.4477887559459128		[learning rate: 0.0089356]
	Learning Rate: 0.00893557
	LOSS [training: 0.513014750963639 | validation: 0.9376383354710398]
	TIME [epoch: 8.88 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4755248275290659		[learning rate: 0.0089146]
		[batch 20/20] avg loss: 0.5163817531040578		[learning rate: 0.0088937]
	Learning Rate: 0.00889368
	LOSS [training: 0.4959532903165618 | validation: 0.5531454410696852]
	TIME [epoch: 8.89 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5502194569220549		[learning rate: 0.0088728]
		[batch 20/20] avg loss: 0.6149864034286543		[learning rate: 0.008852]
	Learning Rate: 0.00885199
	LOSS [training: 0.5826029301753545 | validation: 0.38886542056427076]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 10/20] avg loss: 0.525367028427266		[learning rate: 0.0088312]
		[batch 20/20] avg loss: 0.610760239462494		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.5680636339448799 | validation: 0.46980649600129426]
	TIME [epoch: 8.88 sec]
EPOCH 38/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5131883846780202		[learning rate: 0.0087898]
		[batch 20/20] avg loss: 0.5773035747761779		[learning rate: 0.0087692]
	Learning Rate: 0.00876918
	LOSS [training: 0.545245979727099 | validation: 0.5051509337701052]
	TIME [epoch: 8.87 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5010809221791102		[learning rate: 0.0087486]
		[batch 20/20] avg loss: 0.5364387986087706		[learning rate: 0.0087281]
	Learning Rate: 0.00872807
	LOSS [training: 0.5187598603939404 | validation: 0.3524625926557055]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5102878100405683		[learning rate: 0.0087076]
		[batch 20/20] avg loss: 0.4565330802551344		[learning rate: 0.0086872]
	Learning Rate: 0.00868715
	LOSS [training: 0.4834104451478513 | validation: 0.3895472280761584]
	TIME [epoch: 8.92 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/20] avg loss: 0.46492239977791544		[learning rate: 0.0086668]
		[batch 20/20] avg loss: 0.45080822788684244		[learning rate: 0.0086464]
	Learning Rate: 0.00864643
	LOSS [training: 0.45786531383237905 | validation: 0.49590281530311686]
	TIME [epoch: 8.9 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4608958982381318		[learning rate: 0.0086261]
		[batch 20/20] avg loss: 0.4908790477121334		[learning rate: 0.0086059]
	Learning Rate: 0.00860589
	LOSS [training: 0.4758874729751327 | validation: 1.240216614176314]
	TIME [epoch: 8.9 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6358517556552187		[learning rate: 0.0085857]
		[batch 20/20] avg loss: 0.5719550409800851		[learning rate: 0.0085655]
	Learning Rate: 0.00856555
	LOSS [training: 0.6039033983176518 | validation: 0.5830693302947001]
	TIME [epoch: 8.9 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4349441891651263		[learning rate: 0.0085454]
		[batch 20/20] avg loss: 0.49577890401628916		[learning rate: 0.0085254]
	Learning Rate: 0.00852539
	LOSS [training: 0.46536154659070766 | validation: 0.35871941608819935]
	TIME [epoch: 8.9 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/20] avg loss: 0.553357955179167		[learning rate: 0.0085054]
		[batch 20/20] avg loss: 0.44116112213900394		[learning rate: 0.0084854]
	Learning Rate: 0.00848542
	LOSS [training: 0.49725953865908534 | validation: 0.34872912533164185]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4225816963546893		[learning rate: 0.0084655]
		[batch 20/20] avg loss: 0.44744682755409315		[learning rate: 0.0084456]
	Learning Rate: 0.00844564
	LOSS [training: 0.4350142619543912 | validation: 0.37351739244431825]
	TIME [epoch: 8.9 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5410013581791984		[learning rate: 0.0084258]
		[batch 20/20] avg loss: 0.4339977482988967		[learning rate: 0.008406]
	Learning Rate: 0.00840605
	LOSS [training: 0.4874995532390475 | validation: 0.5539221376654434]
	TIME [epoch: 8.9 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/20] avg loss: 0.43143899159285093		[learning rate: 0.0083863]
		[batch 20/20] avg loss: 0.4702849238970342		[learning rate: 0.0083666]
	Learning Rate: 0.00836664
	LOSS [training: 0.45086195774494264 | validation: 0.758793043029827]
	TIME [epoch: 8.9 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44313879194157024		[learning rate: 0.008347]
		[batch 20/20] avg loss: 0.4476081728814737		[learning rate: 0.0083274]
	Learning Rate: 0.00832742
	LOSS [training: 0.445373482411522 | validation: 0.35243146770714745]
	TIME [epoch: 8.9 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4180478446070645		[learning rate: 0.0083079]
		[batch 20/20] avg loss: 0.45888728545725765		[learning rate: 0.0082884]
	Learning Rate: 0.00828838
	LOSS [training: 0.4384675650321611 | validation: 0.30676009744251315]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_50.pth
	Model improved!!!
EPOCH 51/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3631265582980997		[learning rate: 0.0082689]
		[batch 20/20] avg loss: 0.38363749849141787		[learning rate: 0.0082495]
	Learning Rate: 0.00824952
	LOSS [training: 0.3733820283947589 | validation: 0.34330328395496224]
	TIME [epoch: 8.9 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3712388822609393		[learning rate: 0.0082302]
		[batch 20/20] avg loss: 0.43478154255648455		[learning rate: 0.0082108]
	Learning Rate: 0.00821084
	LOSS [training: 0.40301021240871193 | validation: 0.2818703125987999]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 10/20] avg loss: 0.42319636675860056		[learning rate: 0.0081916]
		[batch 20/20] avg loss: 0.3405323153942357		[learning rate: 0.0081723]
	Learning Rate: 0.00817235
	LOSS [training: 0.3818643410764181 | validation: 0.3516491326504096]
	TIME [epoch: 8.88 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40367935052115167		[learning rate: 0.0081532]
		[batch 20/20] avg loss: 0.3824166809010284		[learning rate: 0.008134]
	Learning Rate: 0.00813404
	LOSS [training: 0.39304801571109005 | validation: 0.46928967151642453]
	TIME [epoch: 8.9 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34991047893212673		[learning rate: 0.0081149]
		[batch 20/20] avg loss: 0.4585317515360144		[learning rate: 0.0080959]
	Learning Rate: 0.0080959
	LOSS [training: 0.40422111523407056 | validation: 0.5514084510650614]
	TIME [epoch: 8.89 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35745766015347086		[learning rate: 0.0080769]
		[batch 20/20] avg loss: 0.4810417989213577		[learning rate: 0.0080579]
	Learning Rate: 0.00805795
	LOSS [training: 0.41924972953741424 | validation: 0.46611611314151946]
	TIME [epoch: 8.88 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/20] avg loss: 0.38371621007095164		[learning rate: 0.008039]
		[batch 20/20] avg loss: 0.3696547610775975		[learning rate: 0.0080202]
	Learning Rate: 0.00802017
	LOSS [training: 0.3766854855742746 | validation: 0.4805105711565053]
	TIME [epoch: 8.88 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3731051217064696		[learning rate: 0.0080013]
		[batch 20/20] avg loss: 0.34515555973598766		[learning rate: 0.0079826]
	Learning Rate: 0.00798257
	LOSS [training: 0.3591303407212286 | validation: 0.7019996199833364]
	TIME [epoch: 8.88 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/20] avg loss: 0.41766090916393245		[learning rate: 0.0079638]
		[batch 20/20] avg loss: 0.43222318503036244		[learning rate: 0.0079451]
	Learning Rate: 0.00794515
	LOSS [training: 0.4249420470971475 | validation: 0.5449782505480404]
	TIME [epoch: 8.91 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3794684458732754		[learning rate: 0.0079265]
		[batch 20/20] avg loss: 0.46135760445023843		[learning rate: 0.0079079]
	Learning Rate: 0.0079079
	LOSS [training: 0.42041302516175694 | validation: 0.3712949571319223]
	TIME [epoch: 8.89 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4039786888497969		[learning rate: 0.0078893]
		[batch 20/20] avg loss: 0.3248338813735874		[learning rate: 0.0078708]
	Learning Rate: 0.00787083
	LOSS [training: 0.36440628511169215 | validation: 0.4749799257768803]
	TIME [epoch: 8.88 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3189420754525554		[learning rate: 0.0078524]
		[batch 20/20] avg loss: 0.2937183440441512		[learning rate: 0.0078339]
	Learning Rate: 0.00783393
	LOSS [training: 0.30633020974835323 | validation: 0.38843339100540886]
	TIME [epoch: 8.88 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4196690672566584		[learning rate: 0.0078155]
		[batch 20/20] avg loss: 0.5256038809270153		[learning rate: 0.0077972]
	Learning Rate: 0.0077972
	LOSS [training: 0.4726364740918367 | validation: 0.6202294951605979]
	TIME [epoch: 8.88 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34063746205756784		[learning rate: 0.0077789]
		[batch 20/20] avg loss: 0.32069132117824384		[learning rate: 0.0077606]
	Learning Rate: 0.00776065
	LOSS [training: 0.3306643916179059 | validation: 0.2544307276377885]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2991983374975598		[learning rate: 0.0077424]
		[batch 20/20] avg loss: 0.39566254389214284		[learning rate: 0.0077243]
	Learning Rate: 0.00772426
	LOSS [training: 0.3474304406948513 | validation: 0.22860132499533714]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2973176902693159		[learning rate: 0.0077061]
		[batch 20/20] avg loss: 0.3042382110717244		[learning rate: 0.0076881]
	Learning Rate: 0.00768805
	LOSS [training: 0.30077795067052016 | validation: 0.22690316707412925]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24986372357093697		[learning rate: 0.00767]
		[batch 20/20] avg loss: 0.22568889771875167		[learning rate: 0.007652]
	Learning Rate: 0.00765201
	LOSS [training: 0.23777631064484428 | validation: 0.3228645525025333]
	TIME [epoch: 8.89 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25832356220924496		[learning rate: 0.0076341]
		[batch 20/20] avg loss: 0.25447615806479995		[learning rate: 0.0076161]
	Learning Rate: 0.00761614
	LOSS [training: 0.25639986013702243 | validation: 0.20618334290291634]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_68.pth
	Model improved!!!
EPOCH 69/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22135212483726852		[learning rate: 0.0075983]
		[batch 20/20] avg loss: 0.2720703340160672		[learning rate: 0.0075804]
	Learning Rate: 0.00758043
	LOSS [training: 0.2467112294266678 | validation: 0.16897945867507702]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_69.pth
	Model improved!!!
EPOCH 70/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5985735060342195		[learning rate: 0.0075626]
		[batch 20/20] avg loss: 0.2910991040581946		[learning rate: 0.0075449]
	Learning Rate: 0.00754489
	LOSS [training: 0.44483630504620697 | validation: 0.15053931636085197]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_70.pth
	Model improved!!!
EPOCH 71/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2355281146620042		[learning rate: 0.0075272]
		[batch 20/20] avg loss: 0.25518050106559376		[learning rate: 0.0075095]
	Learning Rate: 0.00750952
	LOSS [training: 0.24535430786379897 | validation: 0.15527020992686927]
	TIME [epoch: 8.89 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2392183533948514		[learning rate: 0.0074919]
		[batch 20/20] avg loss: 0.22521153427888913		[learning rate: 0.0074743]
	Learning Rate: 0.00747431
	LOSS [training: 0.23221494383687027 | validation: 0.21422263251124557]
	TIME [epoch: 8.88 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25846507652129086		[learning rate: 0.0074568]
		[batch 20/20] avg loss: 0.21299226379373123		[learning rate: 0.0074393]
	Learning Rate: 0.00743927
	LOSS [training: 0.23572867015751103 | validation: 1.1383277149798767]
	TIME [epoch: 8.91 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/20] avg loss: 0.308253006725495		[learning rate: 0.0074218]
		[batch 20/20] avg loss: 0.35261760345413906		[learning rate: 0.0074044]
	Learning Rate: 0.0074044
	LOSS [training: 0.330435305089817 | validation: 0.19361210722719566]
	TIME [epoch: 8.88 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27803587076694203		[learning rate: 0.007387]
		[batch 20/20] avg loss: 0.23210475128396926		[learning rate: 0.0073697]
	Learning Rate: 0.00736969
	LOSS [training: 0.25507031102545563 | validation: 0.1986109766415226]
	TIME [epoch: 8.88 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2626514423024619		[learning rate: 0.0073524]
		[batch 20/20] avg loss: 0.3646854556798337		[learning rate: 0.0073351]
	Learning Rate: 0.00733514
	LOSS [training: 0.31366844899114776 | validation: 0.21173855817699072]
	TIME [epoch: 8.88 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24492194403045775		[learning rate: 0.0073179]
		[batch 20/20] avg loss: 0.23185251703748966		[learning rate: 0.0073007]
	Learning Rate: 0.00730075
	LOSS [training: 0.23838723053397373 | validation: 0.2853078853044828]
	TIME [epoch: 8.9 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23936947990191498		[learning rate: 0.0072836]
		[batch 20/20] avg loss: 0.2012127162392563		[learning rate: 0.0072665]
	Learning Rate: 0.00726652
	LOSS [training: 0.22029109807058567 | validation: 0.155115197761015]
	TIME [epoch: 8.9 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2088953196258673		[learning rate: 0.0072495]
		[batch 20/20] avg loss: 0.26301224374525656		[learning rate: 0.0072325]
	Learning Rate: 0.00723246
	LOSS [training: 0.23595378168556191 | validation: 0.15491694203684142]
	TIME [epoch: 8.88 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2134144391354329		[learning rate: 0.0072155]
		[batch 20/20] avg loss: 0.22398198404641198		[learning rate: 0.0071985]
	Learning Rate: 0.00719855
	LOSS [training: 0.21869821159092245 | validation: 0.16188527513335077]
	TIME [epoch: 8.89 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2003494417738672		[learning rate: 0.0071817]
		[batch 20/20] avg loss: 0.2135742938139249		[learning rate: 0.0071648]
	Learning Rate: 0.0071648
	LOSS [training: 0.20696186779389608 | validation: 0.5057323595921621]
	TIME [epoch: 8.88 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2634209794355024		[learning rate: 0.007148]
		[batch 20/20] avg loss: 0.22645564437183846		[learning rate: 0.0071312]
	Learning Rate: 0.00713121
	LOSS [training: 0.24493831190367046 | validation: 0.17620923243795988]
	TIME [epoch: 8.91 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16814157963535192		[learning rate: 0.0071145]
		[batch 20/20] avg loss: 0.30502485617721947		[learning rate: 0.0070978]
	Learning Rate: 0.00709778
	LOSS [training: 0.23658321790628561 | validation: 0.21795492401738065]
	TIME [epoch: 8.9 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/20] avg loss: 0.197134610562845		[learning rate: 0.0070811]
		[batch 20/20] avg loss: 0.22729518010357994		[learning rate: 0.0070645]
	Learning Rate: 0.0070645
	LOSS [training: 0.2122148953332125 | validation: 0.29085716723845645]
	TIME [epoch: 8.89 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1604761094314544		[learning rate: 0.0070479]
		[batch 20/20] avg loss: 0.23554891203548278		[learning rate: 0.0070314]
	Learning Rate: 0.00703138
	LOSS [training: 0.19801251073346857 | validation: 0.09548549074057056]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17610402333821878		[learning rate: 0.0070149]
		[batch 20/20] avg loss: 0.1684698580312771		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.17228694068474795 | validation: 0.15466348034653266]
	TIME [epoch: 8.88 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17107873131350448		[learning rate: 0.006982]
		[batch 20/20] avg loss: 0.17757339947203737		[learning rate: 0.0069656]
	Learning Rate: 0.00696561
	LOSS [training: 0.1743260653927709 | validation: 0.1981897411755204]
	TIME [epoch: 8.9 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19150263905580517		[learning rate: 0.0069493]
		[batch 20/20] avg loss: 0.24644036348131002		[learning rate: 0.006933]
	Learning Rate: 0.00693295
	LOSS [training: 0.21897150126855763 | validation: 0.3430127567706715]
	TIME [epoch: 8.89 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20057316575906975		[learning rate: 0.0069167]
		[batch 20/20] avg loss: 0.14665038530911598		[learning rate: 0.0069005]
	Learning Rate: 0.00690045
	LOSS [training: 0.17361177553409285 | validation: 0.2137283011309701]
	TIME [epoch: 8.89 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24374647496296636		[learning rate: 0.0068843]
		[batch 20/20] avg loss: 0.17604358285692104		[learning rate: 0.0068681]
	Learning Rate: 0.0068681
	LOSS [training: 0.20989502890994366 | validation: 0.13524200959941685]
	TIME [epoch: 8.88 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20139881989878505		[learning rate: 0.006852]
		[batch 20/20] avg loss: 0.22472359623323448		[learning rate: 0.0068359]
	Learning Rate: 0.0068359
	LOSS [training: 0.21306120806600976 | validation: 0.17122327648771596]
	TIME [epoch: 8.89 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2008665796141877		[learning rate: 0.0068199]
		[batch 20/20] avg loss: 0.1703347016852197		[learning rate: 0.0068039]
	Learning Rate: 0.00680386
	LOSS [training: 0.18560064064970375 | validation: 0.10575406105347632]
	TIME [epoch: 8.91 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18331815833096776		[learning rate: 0.0067879]
		[batch 20/20] avg loss: 0.1948698289039869		[learning rate: 0.006772]
	Learning Rate: 0.00677196
	LOSS [training: 0.18909399361747736 | validation: 0.3348037791777065]
	TIME [epoch: 8.89 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17908766512098587		[learning rate: 0.0067561]
		[batch 20/20] avg loss: 0.15520230614141234		[learning rate: 0.0067402]
	Learning Rate: 0.00674021
	LOSS [training: 0.1671449856311991 | validation: 0.11536258005364865]
	TIME [epoch: 8.88 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1927807725643433		[learning rate: 0.0067244]
		[batch 20/20] avg loss: 0.1815195264521549		[learning rate: 0.0067086]
	Learning Rate: 0.00670861
	LOSS [training: 0.18715014950824913 | validation: 0.12513784577210668]
	TIME [epoch: 8.89 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1392573678377316		[learning rate: 0.0066929]
		[batch 20/20] avg loss: 0.10761975368790247		[learning rate: 0.0066772]
	Learning Rate: 0.00667716
	LOSS [training: 0.123438560762817 | validation: 0.16252819696381346]
	TIME [epoch: 8.91 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32517705501789546		[learning rate: 0.0066615]
		[batch 20/20] avg loss: 0.218172111419286		[learning rate: 0.0066459]
	Learning Rate: 0.00664586
	LOSS [training: 0.2716745832185906 | validation: 0.11622259117664377]
	TIME [epoch: 8.9 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17390674112564447		[learning rate: 0.0066303]
		[batch 20/20] avg loss: 0.1652732514623873		[learning rate: 0.0066147]
	Learning Rate: 0.0066147
	LOSS [training: 0.1695899962940159 | validation: 0.11798008139127955]
	TIME [epoch: 8.88 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19486327085300145		[learning rate: 0.0065992]
		[batch 20/20] avg loss: 0.15613005076019287		[learning rate: 0.0065837]
	Learning Rate: 0.00658369
	LOSS [training: 0.17549666080659715 | validation: 0.08056037700290952]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_99.pth
	Model improved!!!
EPOCH 100/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14654762734921986		[learning rate: 0.0065682]
		[batch 20/20] avg loss: 0.1252176068643968		[learning rate: 0.0065528]
	Learning Rate: 0.00655282
	LOSS [training: 0.13588261710680832 | validation: 0.08821406315536315]
	TIME [epoch: 8.88 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13498577723392302		[learning rate: 0.0065374]
		[batch 20/20] avg loss: 0.16284055850786658		[learning rate: 0.0065221]
	Learning Rate: 0.0065221
	LOSS [training: 0.14891316787089484 | validation: 0.110975347990619]
	TIME [epoch: 8.91 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18175659528563912		[learning rate: 0.0065068]
		[batch 20/20] avg loss: 0.1931162029871901		[learning rate: 0.0064915]
	Learning Rate: 0.00649153
	LOSS [training: 0.18743639913641458 | validation: 0.11551593189270738]
	TIME [epoch: 8.89 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12431839750163176		[learning rate: 0.0064763]
		[batch 20/20] avg loss: 0.11396302750365402		[learning rate: 0.0064611]
	Learning Rate: 0.0064611
	LOSS [training: 0.11914071250264288 | validation: 0.11952510729408615]
	TIME [epoch: 8.88 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13061659781654197		[learning rate: 0.0064459]
		[batch 20/20] avg loss: 0.12045825004625783		[learning rate: 0.0064308]
	Learning Rate: 0.0064308
	LOSS [training: 0.12553742393139988 | validation: 0.0879089648724696]
	TIME [epoch: 8.88 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11587403983300806		[learning rate: 0.0064157]
		[batch 20/20] avg loss: 0.12177489384251505		[learning rate: 0.0064007]
	Learning Rate: 0.00640066
	LOSS [training: 0.11882446683776157 | validation: 0.11579261645824157]
	TIME [epoch: 8.88 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11397112129889823		[learning rate: 0.0063856]
		[batch 20/20] avg loss: 0.13398100286312004		[learning rate: 0.0063706]
	Learning Rate: 0.00637065
	LOSS [training: 0.12397606208100917 | validation: 0.4030652538811165]
	TIME [epoch: 8.91 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1674490661328908		[learning rate: 0.0063557]
		[batch 20/20] avg loss: 0.18728127561182548		[learning rate: 0.0063408]
	Learning Rate: 0.00634078
	LOSS [training: 0.17736517087235812 | validation: 0.2532655951733195]
	TIME [epoch: 8.88 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13971696825777205		[learning rate: 0.0063259]
		[batch 20/20] avg loss: 0.12540930128594582		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.13256313477185894 | validation: 0.13088822130806188]
	TIME [epoch: 8.88 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11766037448754556		[learning rate: 0.0062962]
		[batch 20/20] avg loss: 0.2681411960984294		[learning rate: 0.0062815]
	Learning Rate: 0.00628147
	LOSS [training: 0.1929007852929875 | validation: 0.2627511095999289]
	TIME [epoch: 8.89 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21153137763748892		[learning rate: 0.0062667]
		[batch 20/20] avg loss: 0.24543167415917927		[learning rate: 0.006252]
	Learning Rate: 0.00625202
	LOSS [training: 0.2284815258983341 | validation: 0.15952583468673384]
	TIME [epoch: 8.9 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18976681006914572		[learning rate: 0.0062373]
		[batch 20/20] avg loss: 0.17393057925348956		[learning rate: 0.0062227]
	Learning Rate: 0.00622271
	LOSS [training: 0.18184869466131767 | validation: 0.1726837538032494]
	TIME [epoch: 8.89 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13321315036817247		[learning rate: 0.0062081]
		[batch 20/20] avg loss: 0.12132177190972368		[learning rate: 0.0061935]
	Learning Rate: 0.00619354
	LOSS [training: 0.1272674611389481 | validation: 0.1568330849308344]
	TIME [epoch: 8.89 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/20] avg loss: 0.127914898828529		[learning rate: 0.006179]
		[batch 20/20] avg loss: 0.14861677519875882		[learning rate: 0.0061645]
	Learning Rate: 0.0061645
	LOSS [training: 0.13826583701364392 | validation: 0.1046385064714113]
	TIME [epoch: 8.88 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16653169195477271		[learning rate: 0.00615]
		[batch 20/20] avg loss: 0.164957523212802		[learning rate: 0.0061356]
	Learning Rate: 0.0061356
	LOSS [training: 0.16574460758378734 | validation: 0.14247245893560176]
	TIME [epoch: 8.88 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09280684229088629		[learning rate: 0.0061212]
		[batch 20/20] avg loss: 0.09265367568846039		[learning rate: 0.0061068]
	Learning Rate: 0.00610684
	LOSS [training: 0.09273025898967335 | validation: 0.06370083214853692]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_115.pth
	Model improved!!!
EPOCH 116/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14778026640295638		[learning rate: 0.0060925]
		[batch 20/20] avg loss: 0.12783020448300914		[learning rate: 0.0060782]
	Learning Rate: 0.00607821
	LOSS [training: 0.13780523544298276 | validation: 0.06451817661816109]
	TIME [epoch: 8.88 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07466046324382546		[learning rate: 0.0060639]
		[batch 20/20] avg loss: 0.16253171319710819		[learning rate: 0.0060497]
	Learning Rate: 0.00604971
	LOSS [training: 0.11859608822046681 | validation: 0.15521192012548946]
	TIME [epoch: 8.87 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12136678624244432		[learning rate: 0.0060355]
		[batch 20/20] avg loss: 0.23737893046782252		[learning rate: 0.0060213]
	Learning Rate: 0.00602135
	LOSS [training: 0.17937285835513345 | validation: 0.2823268777516717]
	TIME [epoch: 8.87 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20820471516617664		[learning rate: 0.0060072]
		[batch 20/20] avg loss: 0.09976604202301248		[learning rate: 0.0059931]
	Learning Rate: 0.00599312
	LOSS [training: 0.15398537859459457 | validation: 0.1027364584239247]
	TIME [epoch: 8.88 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11966829377750447		[learning rate: 0.0059791]
		[batch 20/20] avg loss: 0.15529308835370564		[learning rate: 0.005965]
	Learning Rate: 0.00596502
	LOSS [training: 0.13748069106560507 | validation: 0.2041273249054572]
	TIME [epoch: 8.9 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15289387396696905		[learning rate: 0.005951]
		[batch 20/20] avg loss: 0.13993766588592926		[learning rate: 0.0059371]
	Learning Rate: 0.00593706
	LOSS [training: 0.14641576992644917 | validation: 0.5730422690425795]
	TIME [epoch: 8.88 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18328873284964564		[learning rate: 0.0059231]
		[batch 20/20] avg loss: 0.23096870894480034		[learning rate: 0.0059092]
	Learning Rate: 0.00590923
	LOSS [training: 0.207128720897223 | validation: 0.35834166737772677]
	TIME [epoch: 8.87 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15338838023326978		[learning rate: 0.0058954]
		[batch 20/20] avg loss: 0.13208266241707872		[learning rate: 0.0058815]
	Learning Rate: 0.00588152
	LOSS [training: 0.14273552132517425 | validation: 0.07473757661773642]
	TIME [epoch: 8.87 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18097468262072217		[learning rate: 0.0058677]
		[batch 20/20] avg loss: 0.18979102597206854		[learning rate: 0.0058539]
	Learning Rate: 0.00585395
	LOSS [training: 0.1853828542963954 | validation: 0.17462892144039655]
	TIME [epoch: 8.9 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07284303492919367		[learning rate: 0.0058402]
		[batch 20/20] avg loss: 0.10811130465935004		[learning rate: 0.0058265]
	Learning Rate: 0.00582651
	LOSS [training: 0.09047716979427187 | validation: 0.23841663370437405]
	TIME [epoch: 8.88 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/20] avg loss: 0.121274470198979		[learning rate: 0.0058128]
		[batch 20/20] avg loss: 0.10450091889026805		[learning rate: 0.0057992]
	Learning Rate: 0.00579919
	LOSS [training: 0.11288769454462348 | validation: 0.08236388036001434]
	TIME [epoch: 8.87 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12473744096717618		[learning rate: 0.0057856]
		[batch 20/20] avg loss: 0.20416000156580488		[learning rate: 0.005772]
	Learning Rate: 0.005772
	LOSS [training: 0.16444872126649052 | validation: 0.08250758661074961]
	TIME [epoch: 8.88 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1039646258922716		[learning rate: 0.0057585]
		[batch 20/20] avg loss: 0.09897141853855367		[learning rate: 0.0057449]
	Learning Rate: 0.00574494
	LOSS [training: 0.10146802221541265 | validation: 0.09112111842266189]
	TIME [epoch: 8.88 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10816362210740434		[learning rate: 0.0057315]
		[batch 20/20] avg loss: 0.11284821746069058		[learning rate: 0.005718]
	Learning Rate: 0.00571801
	LOSS [training: 0.11050591978404745 | validation: 0.08544739919012471]
	TIME [epoch: 8.9 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09692274882947073		[learning rate: 0.0057046]
		[batch 20/20] avg loss: 0.12003349833476265		[learning rate: 0.0056912]
	Learning Rate: 0.0056912
	LOSS [training: 0.10847812358211668 | validation: 0.20311577587209564]
	TIME [epoch: 8.88 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16346308168669893		[learning rate: 0.0056778]
		[batch 20/20] avg loss: 0.1234789965451815		[learning rate: 0.0056645]
	Learning Rate: 0.00566452
	LOSS [training: 0.14347103911594022 | validation: 0.11294416867156684]
	TIME [epoch: 8.87 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11394178650415343		[learning rate: 0.0056512]
		[batch 20/20] avg loss: 0.08058485751344721		[learning rate: 0.005638]
	Learning Rate: 0.00563797
	LOSS [training: 0.09726332200880032 | validation: 0.08491843632932695]
	TIME [epoch: 8.87 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09669826577877423		[learning rate: 0.0056247]
		[batch 20/20] avg loss: 0.08135119457331255		[learning rate: 0.0056115]
	Learning Rate: 0.00561153
	LOSS [training: 0.08902473017604338 | validation: 0.2318601840547873]
	TIME [epoch: 8.87 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13112971617462815		[learning rate: 0.0055984]
		[batch 20/20] avg loss: 0.10860884083765229		[learning rate: 0.0055852]
	Learning Rate: 0.00558523
	LOSS [training: 0.11986927850614024 | validation: 0.1308718415146218]
	TIME [epoch: 8.9 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11455812321229215		[learning rate: 0.0055721]
		[batch 20/20] avg loss: 0.12414234490571634		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.11935023405900425 | validation: 0.06939380335481202]
	TIME [epoch: 8.88 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14670601676450035		[learning rate: 0.005546]
		[batch 20/20] avg loss: 0.16209483184267498		[learning rate: 0.005533]
	Learning Rate: 0.00553298
	LOSS [training: 0.1544004243035877 | validation: 0.10117650072957204]
	TIME [epoch: 8.88 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09293905530940391		[learning rate: 0.00552]
		[batch 20/20] avg loss: 0.17063935357412757		[learning rate: 0.005507]
	Learning Rate: 0.00550704
	LOSS [training: 0.13178920444176573 | validation: 0.15326257361208515]
	TIME [epoch: 8.87 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10129907089534193		[learning rate: 0.0054941]
		[batch 20/20] avg loss: 0.0931878727106711		[learning rate: 0.0054812]
	Learning Rate: 0.00548122
	LOSS [training: 0.0972434718030065 | validation: 0.057813315463167564]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_138.pth
	Model improved!!!
EPOCH 139/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08299695300343747		[learning rate: 0.0054684]
		[batch 20/20] avg loss: 0.10549763799895764		[learning rate: 0.0054555]
	Learning Rate: 0.00545553
	LOSS [training: 0.09424729550119756 | validation: 0.10696726063161674]
	TIME [epoch: 8.89 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11874569247075395		[learning rate: 0.0054427]
		[batch 20/20] avg loss: 0.08465008638305074		[learning rate: 0.00543]
	Learning Rate: 0.00542995
	LOSS [training: 0.10169788942690232 | validation: 0.0969040032199111]
	TIME [epoch: 8.87 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09190266733980954		[learning rate: 0.0054172]
		[batch 20/20] avg loss: 0.08758540556477791		[learning rate: 0.0054045]
	Learning Rate: 0.00540449
	LOSS [training: 0.08974403645229373 | validation: 0.04849245776179807]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_141.pth
	Model improved!!!
EPOCH 142/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11153165519189648		[learning rate: 0.0053918]
		[batch 20/20] avg loss: 0.08289798698015058		[learning rate: 0.0053792]
	Learning Rate: 0.00537916
	LOSS [training: 0.09721482108602351 | validation: 0.05740717523864258]
	TIME [epoch: 8.87 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10664217370029797		[learning rate: 0.0053665]
		[batch 20/20] avg loss: 0.09915110028357424		[learning rate: 0.0053539]
	Learning Rate: 0.00535394
	LOSS [training: 0.1028966369919361 | validation: 0.2008574220120028]
	TIME [epoch: 8.9 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09081782128434748		[learning rate: 0.0053414]
		[batch 20/20] avg loss: 0.08709989693948768		[learning rate: 0.0053288]
	Learning Rate: 0.00532884
	LOSS [training: 0.08895885911191759 | validation: 0.10934418525822467]
	TIME [epoch: 8.88 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16218981977693012		[learning rate: 0.0053163]
		[batch 20/20] avg loss: 0.09289375972591402		[learning rate: 0.0053039]
	Learning Rate: 0.00530386
	LOSS [training: 0.12754178975142205 | validation: 0.10600258469001182]
	TIME [epoch: 8.88 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13095016551768018		[learning rate: 0.0052914]
		[batch 20/20] avg loss: 0.07843757372684601		[learning rate: 0.005279]
	Learning Rate: 0.00527899
	LOSS [training: 0.1046938696222631 | validation: 0.11621444054482971]
	TIME [epoch: 8.88 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13752485962601868		[learning rate: 0.0052666]
		[batch 20/20] avg loss: 0.13758429052031404		[learning rate: 0.0052542]
	Learning Rate: 0.00525424
	LOSS [training: 0.13755457507316637 | validation: 0.062334249962672526]
	TIME [epoch: 8.88 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10807170666462598		[learning rate: 0.0052419]
		[batch 20/20] avg loss: 0.08821352637924137		[learning rate: 0.0052296]
	Learning Rate: 0.00522961
	LOSS [training: 0.09814261652193369 | validation: 0.08878707467699751]
	TIME [epoch: 8.91 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22398656981865553		[learning rate: 0.0052173]
		[batch 20/20] avg loss: 0.10813228090877502		[learning rate: 0.0052051]
	Learning Rate: 0.00520509
	LOSS [training: 0.1660594253637153 | validation: 0.059386449280076914]
	TIME [epoch: 8.88 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06838811185479823		[learning rate: 0.0051929]
		[batch 20/20] avg loss: 0.08975336580225605		[learning rate: 0.0051807]
	Learning Rate: 0.00518069
	LOSS [training: 0.07907073882852715 | validation: 0.11350229124867459]
	TIME [epoch: 8.91 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1525416716282442		[learning rate: 0.0051685]
		[batch 20/20] avg loss: 0.12584993669931346		[learning rate: 0.0051564]
	Learning Rate: 0.0051564
	LOSS [training: 0.13919580416377883 | validation: 0.1405555712596413]
	TIME [epoch: 8.88 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10428981169000702		[learning rate: 0.0051443]
		[batch 20/20] avg loss: 0.1516632988974915		[learning rate: 0.0051322]
	Learning Rate: 0.00513223
	LOSS [training: 0.12797655529374924 | validation: 0.14706876791432574]
	TIME [epoch: 8.87 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11712548823312825		[learning rate: 0.0051202]
		[batch 20/20] avg loss: 0.08295058531905611		[learning rate: 0.0051082]
	Learning Rate: 0.00510817
	LOSS [training: 0.10003803677609217 | validation: 0.08182499088171485]
	TIME [epoch: 8.9 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07924373054958214		[learning rate: 0.0050962]
		[batch 20/20] avg loss: 0.111590719395896		[learning rate: 0.0050842]
	Learning Rate: 0.00508422
	LOSS [training: 0.09541722497273908 | validation: 0.10849472993197859]
	TIME [epoch: 8.88 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12184226320940852		[learning rate: 0.0050723]
		[batch 20/20] avg loss: 0.10680332529730534		[learning rate: 0.0050604]
	Learning Rate: 0.00506039
	LOSS [training: 0.11432279425335694 | validation: 0.11873750265398875]
	TIME [epoch: 8.87 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10091407388664886		[learning rate: 0.0050485]
		[batch 20/20] avg loss: 0.13296829889271605		[learning rate: 0.0050367]
	Learning Rate: 0.00503666
	LOSS [training: 0.11694118638968247 | validation: 0.14678570157293303]
	TIME [epoch: 8.88 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11345806091469761		[learning rate: 0.0050248]
		[batch 20/20] avg loss: 0.07198365917589986		[learning rate: 0.005013]
	Learning Rate: 0.00501305
	LOSS [training: 0.09272086004529874 | validation: 0.1109912031252703]
	TIME [epoch: 8.9 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14251732955988877		[learning rate: 0.0050013]
		[batch 20/20] avg loss: 0.10457796269283832		[learning rate: 0.0049895]
	Learning Rate: 0.00498955
	LOSS [training: 0.12354764612636353 | validation: 0.19192745429833696]
	TIME [epoch: 8.89 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08828286392803644		[learning rate: 0.0049778]
		[batch 20/20] avg loss: 0.13627180447168283		[learning rate: 0.0049662]
	Learning Rate: 0.00496616
	LOSS [training: 0.11227733419985964 | validation: 0.1009653602537556]
	TIME [epoch: 8.87 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09874718182584435		[learning rate: 0.0049545]
		[batch 20/20] avg loss: 0.09455535428310397		[learning rate: 0.0049429]
	Learning Rate: 0.00494287
	LOSS [training: 0.09665126805447416 | validation: 0.0518426140685214]
	TIME [epoch: 8.88 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09108088411496272		[learning rate: 0.0049313]
		[batch 20/20] avg loss: 0.09476333320428275		[learning rate: 0.0049197]
	Learning Rate: 0.0049197
	LOSS [training: 0.09292210865962275 | validation: 0.3020626746845517]
	TIME [epoch: 8.88 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2320142496092492		[learning rate: 0.0049082]
		[batch 20/20] avg loss: 0.08965375026382058		[learning rate: 0.0048966]
	Learning Rate: 0.00489664
	LOSS [training: 0.16083399993653488 | validation: 0.14257900094859385]
	TIME [epoch: 8.9 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19681496848548527		[learning rate: 0.0048851]
		[batch 20/20] avg loss: 0.1019360876854554		[learning rate: 0.0048737]
	Learning Rate: 0.00487368
	LOSS [training: 0.14937552808547033 | validation: 0.054703910257599325]
	TIME [epoch: 8.88 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08096296261892079		[learning rate: 0.0048622]
		[batch 20/20] avg loss: 0.08061956526623269		[learning rate: 0.0048508]
	Learning Rate: 0.00485083
	LOSS [training: 0.08079126394257673 | validation: 0.052179620933613]
	TIME [epoch: 8.88 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10288447890071024		[learning rate: 0.0048394]
		[batch 20/20] avg loss: 0.08804424907661643		[learning rate: 0.0048281]
	Learning Rate: 0.00482809
	LOSS [training: 0.09546436398866334 | validation: 0.10485578837387252]
	TIME [epoch: 8.88 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09550609420611518		[learning rate: 0.0048168]
		[batch 20/20] avg loss: 0.13889710646053327		[learning rate: 0.0048055]
	Learning Rate: 0.00480546
	LOSS [training: 0.11720160033332423 | validation: 0.11643811179769344]
	TIME [epoch: 8.88 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10130151737711601		[learning rate: 0.0047942]
		[batch 20/20] avg loss: 0.08883156890355863		[learning rate: 0.0047829]
	Learning Rate: 0.00478293
	LOSS [training: 0.09506654314033733 | validation: 0.14209782217667863]
	TIME [epoch: 8.9 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09464427310953122		[learning rate: 0.0047717]
		[batch 20/20] avg loss: 0.08938746448492979		[learning rate: 0.0047605]
	Learning Rate: 0.00476051
	LOSS [training: 0.0920158687972305 | validation: 0.04218226693959776]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_168.pth
	Model improved!!!
EPOCH 169/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1122569704984225		[learning rate: 0.0047493]
		[batch 20/20] avg loss: 0.10285727788084036		[learning rate: 0.0047382]
	Learning Rate: 0.00473819
	LOSS [training: 0.10755712418963141 | validation: 0.06538754562180257]
	TIME [epoch: 8.87 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07519499523651578		[learning rate: 0.0047271]
		[batch 20/20] avg loss: 0.06085684028945811		[learning rate: 0.004716]
	Learning Rate: 0.00471597
	LOSS [training: 0.06802591776298696 | validation: 0.04913156494768144]
	TIME [epoch: 8.87 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07102019610942441		[learning rate: 0.0047049]
		[batch 20/20] avg loss: 0.0753415277841593		[learning rate: 0.0046939]
	Learning Rate: 0.00469386
	LOSS [training: 0.07318086194679187 | validation: 0.0788419789806187]
	TIME [epoch: 8.89 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09363112086103516		[learning rate: 0.0046828]
		[batch 20/20] avg loss: 0.07717511391092831		[learning rate: 0.0046719]
	Learning Rate: 0.00467186
	LOSS [training: 0.08540311738598175 | validation: 0.040612924441664665]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_172.pth
	Model improved!!!
EPOCH 173/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07890987774027317		[learning rate: 0.0046609]
		[batch 20/20] avg loss: 0.1045884669549773		[learning rate: 0.00465]
	Learning Rate: 0.00464996
	LOSS [training: 0.09174917234762522 | validation: 0.12192087070734525]
	TIME [epoch: 8.87 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/20] avg loss: 0.080761269010851		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.09966953901586666		[learning rate: 0.0046282]
	Learning Rate: 0.00462816
	LOSS [training: 0.09021540401335884 | validation: 0.048311662704677835]
	TIME [epoch: 8.86 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/20] avg loss: 0.047694618963431634		[learning rate: 0.0046173]
		[batch 20/20] avg loss: 0.06226437079635274		[learning rate: 0.0046065]
	Learning Rate: 0.00460646
	LOSS [training: 0.0549794948798922 | validation: 0.03041926556360601]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_175.pth
	Model improved!!!
EPOCH 176/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1074519723344018		[learning rate: 0.0045956]
		[batch 20/20] avg loss: 0.13199679592014313		[learning rate: 0.0045849]
	Learning Rate: 0.00458486
	LOSS [training: 0.11972438412727249 | validation: 0.16618649595260193]
	TIME [epoch: 8.9 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12165224524969634		[learning rate: 0.0045741]
		[batch 20/20] avg loss: 0.07497943574754765		[learning rate: 0.0045634]
	Learning Rate: 0.00456337
	LOSS [training: 0.09831584049862199 | validation: 0.0521729060028272]
	TIME [epoch: 8.87 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06438954647258438		[learning rate: 0.0045527]
		[batch 20/20] avg loss: 0.15437047619828548		[learning rate: 0.004542]
	Learning Rate: 0.00454198
	LOSS [training: 0.10938001133543493 | validation: 0.13290155165223952]
	TIME [epoch: 8.87 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12337515719751298		[learning rate: 0.0045313]
		[batch 20/20] avg loss: 0.09803246104942417		[learning rate: 0.0045207]
	Learning Rate: 0.00452068
	LOSS [training: 0.11070380912346856 | validation: 0.09224341576832554]
	TIME [epoch: 8.87 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07937926594578108		[learning rate: 0.0045101]
		[batch 20/20] avg loss: 0.05519564893446949		[learning rate: 0.0044995]
	Learning Rate: 0.00449949
	LOSS [training: 0.06728745744012529 | validation: 0.08633510270333966]
	TIME [epoch: 8.87 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07344875873509463		[learning rate: 0.0044889]
		[batch 20/20] avg loss: 0.07411609655830173		[learning rate: 0.0044784]
	Learning Rate: 0.0044784
	LOSS [training: 0.07378242764669818 | validation: 0.058263229970173074]
	TIME [epoch: 8.89 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04914260507325436		[learning rate: 0.0044679]
		[batch 20/20] avg loss: 0.08311363987451367		[learning rate: 0.0044574]
	Learning Rate: 0.0044574
	LOSS [training: 0.06612812247388401 | validation: 0.07836140585587276]
	TIME [epoch: 8.87 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07750503884526314		[learning rate: 0.0044469]
		[batch 20/20] avg loss: 0.07597509921584007		[learning rate: 0.0044365]
	Learning Rate: 0.0044365
	LOSS [training: 0.07674006903055162 | validation: 0.06275503742496837]
	TIME [epoch: 8.87 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06722232960244319		[learning rate: 0.0044261]
		[batch 20/20] avg loss: 0.06316749564841041		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.06519491262542679 | validation: 0.08712185729005033]
	TIME [epoch: 8.87 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07024194994033837		[learning rate: 0.0044053]
		[batch 20/20] avg loss: 0.0650488445201928		[learning rate: 0.004395]
	Learning Rate: 0.004395
	LOSS [training: 0.06764539723026555 | validation: 0.057375317036544776]
	TIME [epoch: 8.89 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07856560919885273		[learning rate: 0.0043847]
		[batch 20/20] avg loss: 0.05887379949426776		[learning rate: 0.0043744]
	Learning Rate: 0.0043744
	LOSS [training: 0.06871970434656025 | validation: 0.06926984210216786]
	TIME [epoch: 8.87 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07246672548824692		[learning rate: 0.0043641]
		[batch 20/20] avg loss: 0.128998460010828		[learning rate: 0.0043539]
	Learning Rate: 0.00435389
	LOSS [training: 0.10073259274953747 | validation: 0.3845486927786229]
	TIME [epoch: 8.87 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16534944263880794		[learning rate: 0.0043437]
		[batch 20/20] avg loss: 0.11391674618186098		[learning rate: 0.0043335]
	Learning Rate: 0.00433348
	LOSS [training: 0.13963309441033447 | validation: 0.06727171503996202]
	TIME [epoch: 8.86 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08908381720368903		[learning rate: 0.0043233]
		[batch 20/20] avg loss: 0.05784540437824913		[learning rate: 0.0043132]
	Learning Rate: 0.00431316
	LOSS [training: 0.07346461079096908 | validation: 0.05773373835411235]
	TIME [epoch: 8.86 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06241988635463045		[learning rate: 0.004303]
		[batch 20/20] avg loss: 0.11068950032448477		[learning rate: 0.0042929]
	Learning Rate: 0.00429294
	LOSS [training: 0.08655469333955759 | validation: 0.08965211346888019]
	TIME [epoch: 8.89 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12997151612447494		[learning rate: 0.0042829]
		[batch 20/20] avg loss: 0.14130313443003192		[learning rate: 0.0042728]
	Learning Rate: 0.00427282
	LOSS [training: 0.13563732527725345 | validation: 0.11704452690017293]
	TIME [epoch: 8.88 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09414189573107332		[learning rate: 0.0042628]
		[batch 20/20] avg loss: 0.09522652145946411		[learning rate: 0.0042528]
	Learning Rate: 0.00425279
	LOSS [training: 0.09468420859526874 | validation: 0.0972207559026981]
	TIME [epoch: 8.86 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07298628572399565		[learning rate: 0.0042428]
		[batch 20/20] avg loss: 0.08982506125078502		[learning rate: 0.0042328]
	Learning Rate: 0.00423285
	LOSS [training: 0.08140567348739032 | validation: 0.14805102991651972]
	TIME [epoch: 8.87 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08103753483006336		[learning rate: 0.0042229]
		[batch 20/20] avg loss: 0.07467174500425135		[learning rate: 0.004213]
	Learning Rate: 0.004213
	LOSS [training: 0.07785463991715735 | validation: 0.062067617877468825]
	TIME [epoch: 8.87 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05529984968875925		[learning rate: 0.0042031]
		[batch 20/20] avg loss: 0.08023944688501425		[learning rate: 0.0041933]
	Learning Rate: 0.00419325
	LOSS [training: 0.06776964828688677 | validation: 0.04518926517094591]
	TIME [epoch: 8.89 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06797817849056872		[learning rate: 0.0041834]
		[batch 20/20] avg loss: 0.06563846417854487		[learning rate: 0.0041736]
	Learning Rate: 0.00417359
	LOSS [training: 0.06680832133455682 | validation: 0.0615107792890377]
	TIME [epoch: 8.87 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07034081889504931		[learning rate: 0.0041638]
		[batch 20/20] avg loss: 0.07687362751139026		[learning rate: 0.004154]
	Learning Rate: 0.00415403
	LOSS [training: 0.0736072232032198 | validation: 0.06981549772818765]
	TIME [epoch: 8.86 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09273415083289778		[learning rate: 0.0041443]
		[batch 20/20] avg loss: 0.07390080937997502		[learning rate: 0.0041346]
	Learning Rate: 0.00413455
	LOSS [training: 0.0833174801064364 | validation: 0.04232604885569143]
	TIME [epoch: 8.87 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05838690439553257		[learning rate: 0.0041249]
		[batch 20/20] avg loss: 0.09031495911282851		[learning rate: 0.0041152]
	Learning Rate: 0.00411517
	LOSS [training: 0.07435093175418053 | validation: 0.06015001337748519]
	TIME [epoch: 8.86 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14792101672721353		[learning rate: 0.0041055]
		[batch 20/20] avg loss: 0.06747186105595643		[learning rate: 0.0040959]
	Learning Rate: 0.00409588
	LOSS [training: 0.10769643889158498 | validation: 0.05259392677480866]
	TIME [epoch: 8.89 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07691331510913071		[learning rate: 0.0040863]
		[batch 20/20] avg loss: 0.13331206172082505		[learning rate: 0.0040767]
	Learning Rate: 0.00407667
	LOSS [training: 0.1051126884149779 | validation: 0.1472687897422563]
	TIME [epoch: 8.86 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08443534455100968		[learning rate: 0.0040671]
		[batch 20/20] avg loss: 0.08041838032580446		[learning rate: 0.0040576]
	Learning Rate: 0.00405756
	LOSS [training: 0.08242686243840708 | validation: 0.04460001926447382]
	TIME [epoch: 8.86 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07129751155874557		[learning rate: 0.004048]
		[batch 20/20] avg loss: 0.07192961947507888		[learning rate: 0.0040385]
	Learning Rate: 0.00403854
	LOSS [training: 0.07161356551691221 | validation: 0.09090122182181787]
	TIME [epoch: 8.86 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06333557825755425		[learning rate: 0.0040291]
		[batch 20/20] avg loss: 0.0594402583993926		[learning rate: 0.0040196]
	Learning Rate: 0.00401961
	LOSS [training: 0.061387918328473415 | validation: 0.16940663295896652]
	TIME [epoch: 8.88 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1774057816643004		[learning rate: 0.0040102]
		[batch 20/20] avg loss: 0.10908025546426683		[learning rate: 0.0040008]
	Learning Rate: 0.00400076
	LOSS [training: 0.14324301856428362 | validation: 0.12148632385933514]
	TIME [epoch: 8.87 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17475690083267675		[learning rate: 0.0039914]
		[batch 20/20] avg loss: 0.14636915891479563		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.16056302987373616 | validation: 0.08105657409855377]
	TIME [epoch: 8.87 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09164493783192601		[learning rate: 0.0039727]
		[batch 20/20] avg loss: 0.07140482229962047		[learning rate: 0.0039633]
	Learning Rate: 0.00396334
	LOSS [training: 0.08152488006577323 | validation: 0.06285996818555746]
	TIME [epoch: 8.87 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06373150188002874		[learning rate: 0.003954]
		[batch 20/20] avg loss: 0.06429426940600783		[learning rate: 0.0039448]
	Learning Rate: 0.00394476
	LOSS [training: 0.06401288564301828 | validation: 0.08668818206826188]
	TIME [epoch: 8.86 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1103115760678535		[learning rate: 0.0039355]
		[batch 20/20] avg loss: 0.06801341794165908		[learning rate: 0.0039263]
	Learning Rate: 0.00392627
	LOSS [training: 0.08916249700475629 | validation: 0.12236552570860905]
	TIME [epoch: 8.89 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0599776914152214		[learning rate: 0.0039171]
		[batch 20/20] avg loss: 0.06578122875565592		[learning rate: 0.0039079]
	Learning Rate: 0.00390786
	LOSS [training: 0.06287946008543865 | validation: 0.08512954305286685]
	TIME [epoch: 8.87 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07977707863542796		[learning rate: 0.0038987]
		[batch 20/20] avg loss: 0.0726739264024175		[learning rate: 0.0038895]
	Learning Rate: 0.00388954
	LOSS [training: 0.07622550251892272 | validation: 0.07568023662133244]
	TIME [epoch: 8.86 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10070590841506824		[learning rate: 0.0038804]
		[batch 20/20] avg loss: 0.1544465274489144		[learning rate: 0.0038713]
	Learning Rate: 0.0038713
	LOSS [training: 0.1275762179319913 | validation: 0.14002171700422392]
	TIME [epoch: 8.86 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1253862599783279		[learning rate: 0.0038622]
		[batch 20/20] avg loss: 0.11439919432031684		[learning rate: 0.0038532]
	Learning Rate: 0.00385315
	LOSS [training: 0.11989272714932238 | validation: 0.06445936774597191]
	TIME [epoch: 8.87 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07827443568526184		[learning rate: 0.0038441]
		[batch 20/20] avg loss: 0.09665954491787808		[learning rate: 0.0038351]
	Learning Rate: 0.00383509
	LOSS [training: 0.08746699030156996 | validation: 0.1393440405221821]
	TIME [epoch: 8.88 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10481459361679371		[learning rate: 0.0038261]
		[batch 20/20] avg loss: 0.10412987806841176		[learning rate: 0.0038171]
	Learning Rate: 0.00381711
	LOSS [training: 0.10447223584260272 | validation: 0.06664230695120474]
	TIME [epoch: 8.87 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07185998172749082		[learning rate: 0.0038082]
		[batch 20/20] avg loss: 0.06280236880601583		[learning rate: 0.0037992]
	Learning Rate: 0.00379921
	LOSS [training: 0.06733117526675333 | validation: 0.039556877422941616]
	TIME [epoch: 8.86 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07570958575555277		[learning rate: 0.0037903]
		[batch 20/20] avg loss: 0.06928600003819044		[learning rate: 0.0037814]
	Learning Rate: 0.0037814
	LOSS [training: 0.07249779289687161 | validation: 0.06396946513098373]
	TIME [epoch: 8.86 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07862590353700519		[learning rate: 0.0037725]
		[batch 20/20] avg loss: 0.10299855991184552		[learning rate: 0.0037637]
	Learning Rate: 0.00376368
	LOSS [training: 0.09081223172442535 | validation: 0.13155335171844124]
	TIME [epoch: 8.89 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14962149959926654		[learning rate: 0.0037548]
		[batch 20/20] avg loss: 0.07811963133660874		[learning rate: 0.003746]
	Learning Rate: 0.00374603
	LOSS [training: 0.11387056546793768 | validation: 0.051391910267804555]
	TIME [epoch: 8.87 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0729111737651412		[learning rate: 0.0037372]
		[batch 20/20] avg loss: 0.10698023581723086		[learning rate: 0.0037285]
	Learning Rate: 0.00372847
	LOSS [training: 0.08994570479118602 | validation: 0.0740198929139195]
	TIME [epoch: 8.86 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05605816940114795		[learning rate: 0.0037197]
		[batch 20/20] avg loss: 0.05671167747021808		[learning rate: 0.003711]
	Learning Rate: 0.00371099
	LOSS [training: 0.05638492343568301 | validation: 0.03325554358436832]
	TIME [epoch: 8.86 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03787485710651103		[learning rate: 0.0037023]
		[batch 20/20] avg loss: 0.0561694592804962		[learning rate: 0.0036936]
	Learning Rate: 0.00369359
	LOSS [training: 0.04702215819350361 | validation: 0.07001132306843966]
	TIME [epoch: 8.86 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/20] avg loss: 0.059379977241118174		[learning rate: 0.0036849]
		[batch 20/20] avg loss: 0.07111244830916584		[learning rate: 0.0036763]
	Learning Rate: 0.00367628
	LOSS [training: 0.065246212775142 | validation: 0.20564672764946337]
	TIME [epoch: 8.88 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08298168420415368		[learning rate: 0.0036676]
		[batch 20/20] avg loss: 0.09313258175054848		[learning rate: 0.003659]
	Learning Rate: 0.00365904
	LOSS [training: 0.0880571329773511 | validation: 0.04677931132726071]
	TIME [epoch: 8.87 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0642106539184147		[learning rate: 0.0036505]
		[batch 20/20] avg loss: 0.06055379803288584		[learning rate: 0.0036419]
	Learning Rate: 0.00364189
	LOSS [training: 0.062382225975650255 | validation: 0.05973374846757562]
	TIME [epoch: 8.86 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06739680297498157		[learning rate: 0.0036333]
		[batch 20/20] avg loss: 0.0721019259703651		[learning rate: 0.0036248]
	Learning Rate: 0.00362481
	LOSS [training: 0.06974936447267334 | validation: 0.05378868316168154]
	TIME [epoch: 8.86 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0530743424731301		[learning rate: 0.0036163]
		[batch 20/20] avg loss: 0.06661045579563021		[learning rate: 0.0036078]
	Learning Rate: 0.00360782
	LOSS [training: 0.05984239913438014 | validation: 0.10067975091376516]
	TIME [epoch: 8.86 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06597421627020926		[learning rate: 0.0035994]
		[batch 20/20] avg loss: 0.06094821550002542		[learning rate: 0.0035909]
	Learning Rate: 0.00359091
	LOSS [training: 0.06346121588511734 | validation: 0.0589948168604274]
	TIME [epoch: 8.89 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06492609548815995		[learning rate: 0.0035825]
		[batch 20/20] avg loss: 0.07906016597870603		[learning rate: 0.0035741]
	Learning Rate: 0.00357407
	LOSS [training: 0.071993130733433 | validation: 0.11671141354305126]
	TIME [epoch: 8.86 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14490339885708087		[learning rate: 0.0035657]
		[batch 20/20] avg loss: 0.09614747629915865		[learning rate: 0.0035573]
	Learning Rate: 0.00355732
	LOSS [training: 0.12052543757811976 | validation: 0.14326437927382019]
	TIME [epoch: 8.87 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10074710079198616		[learning rate: 0.003549]
		[batch 20/20] avg loss: 0.06786161560249093		[learning rate: 0.0035406]
	Learning Rate: 0.00354064
	LOSS [training: 0.08430435819723855 | validation: 0.0709454852596911]
	TIME [epoch: 8.86 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/20] avg loss: 0.060268176071309076		[learning rate: 0.0035323]
		[batch 20/20] avg loss: 0.10136750721462184		[learning rate: 0.003524]
	Learning Rate: 0.00352404
	LOSS [training: 0.08081784164296546 | validation: 0.0888512973855829]
	TIME [epoch: 8.87 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09803892176006866		[learning rate: 0.0035158]
		[batch 20/20] avg loss: 0.12603548684279414		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.11203720430143142 | validation: 0.04968813593631744]
	TIME [epoch: 8.89 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06408906090850244		[learning rate: 0.0034993]
		[batch 20/20] avg loss: 0.056280691513224		[learning rate: 0.0034911]
	Learning Rate: 0.00349107
	LOSS [training: 0.06018487621086323 | validation: 0.030143897227319305]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_234.pth
	Model improved!!!
EPOCH 235/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0537545932399481		[learning rate: 0.0034829]
		[batch 20/20] avg loss: 0.05724539957932886		[learning rate: 0.0034747]
	Learning Rate: 0.00347471
	LOSS [training: 0.055499996409638486 | validation: 0.06088023203519242]
	TIME [epoch: 8.86 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0461109610448042		[learning rate: 0.0034666]
		[batch 20/20] avg loss: 0.07409538891283418		[learning rate: 0.0034584]
	Learning Rate: 0.00345842
	LOSS [training: 0.060103174978819195 | validation: 0.09774350279476052]
	TIME [epoch: 8.86 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06148044010387558		[learning rate: 0.0034503]
		[batch 20/20] avg loss: 0.10375798573055524		[learning rate: 0.0034422]
	Learning Rate: 0.00344221
	LOSS [training: 0.08261921291721538 | validation: 0.07557155990880776]
	TIME [epoch: 8.88 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10310217033471869		[learning rate: 0.0034341]
		[batch 20/20] avg loss: 0.06952301933633835		[learning rate: 0.0034261]
	Learning Rate: 0.00342607
	LOSS [training: 0.08631259483552853 | validation: 0.06958271337745339]
	TIME [epoch: 8.87 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07934668889806193		[learning rate: 0.003418]
		[batch 20/20] avg loss: 0.05791191409699311		[learning rate: 0.00341]
	Learning Rate: 0.00341001
	LOSS [training: 0.06862930149752752 | validation: 0.11709508118213398]
	TIME [epoch: 8.86 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0720226914811878		[learning rate: 0.003402]
		[batch 20/20] avg loss: 0.09278519403659242		[learning rate: 0.003394]
	Learning Rate: 0.00339402
	LOSS [training: 0.08240394275889011 | validation: 0.11891786034111818]
	TIME [epoch: 8.86 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04038342664889832		[learning rate: 0.0033861]
		[batch 20/20] avg loss: 0.127782403014498		[learning rate: 0.0033781]
	Learning Rate: 0.00337811
	LOSS [training: 0.08408291483169818 | validation: 0.10282393940263007]
	TIME [epoch: 8.86 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05453914497451447		[learning rate: 0.0033702]
		[batch 20/20] avg loss: 0.06102924478541601		[learning rate: 0.0033623]
	Learning Rate: 0.00336227
	LOSS [training: 0.05778419487996522 | validation: 0.03695264460771943]
	TIME [epoch: 8.89 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04820374064548447		[learning rate: 0.0033544]
		[batch 20/20] avg loss: 0.13748800059795074		[learning rate: 0.0033465]
	Learning Rate: 0.00334651
	LOSS [training: 0.09284587062171759 | validation: 0.08867971960507294]
	TIME [epoch: 8.86 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0921191060745279		[learning rate: 0.0033387]
		[batch 20/20] avg loss: 0.06385637747617218		[learning rate: 0.0033308]
	Learning Rate: 0.00333082
	LOSS [training: 0.07798774177535003 | validation: 0.06439071455008752]
	TIME [epoch: 8.86 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/20] avg loss: 0.054197261993901014		[learning rate: 0.003323]
		[batch 20/20] avg loss: 0.07017883719544502		[learning rate: 0.0033152]
	Learning Rate: 0.0033152
	LOSS [training: 0.06218804959467302 | validation: 0.05830489958014848]
	TIME [epoch: 8.86 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24834741388438347		[learning rate: 0.0033074]
		[batch 20/20] avg loss: 0.11346031858297394		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.1809038662336787 | validation: 0.05636863209978546]
	TIME [epoch: 8.86 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0713621399281158		[learning rate: 0.0032919]
		[batch 20/20] avg loss: 0.10243390097732341		[learning rate: 0.0032842]
	Learning Rate: 0.00328419
	LOSS [training: 0.0868980204527196 | validation: 0.057200197185395325]
	TIME [epoch: 8.89 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/20] avg loss: 0.036544574677853124		[learning rate: 0.0032765]
		[batch 20/20] avg loss: 0.038285022596163266		[learning rate: 0.0032688]
	Learning Rate: 0.0032688
	LOSS [training: 0.037414798637008195 | validation: 0.032408174849348846]
	TIME [epoch: 8.86 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06023478057484445		[learning rate: 0.0032611]
		[batch 20/20] avg loss: 0.07222582542371621		[learning rate: 0.0032535]
	Learning Rate: 0.00325347
	LOSS [training: 0.06623030299928032 | validation: 0.05904240712632369]
	TIME [epoch: 8.86 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06449791885869921		[learning rate: 0.0032458]
		[batch 20/20] avg loss: 0.04770903328659259		[learning rate: 0.0032382]
	Learning Rate: 0.00323822
	LOSS [training: 0.05610347607264591 | validation: 0.04090819257179665]
	TIME [epoch: 8.86 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0377913075438151		[learning rate: 0.0032306]
		[batch 20/20] avg loss: 0.10683090820321355		[learning rate: 0.003223]
	Learning Rate: 0.00322304
	LOSS [training: 0.07231110787351433 | validation: 0.10483463893146402]
	TIME [epoch: 8.88 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05567980000098884		[learning rate: 0.0032155]
		[batch 20/20] avg loss: 0.053951177551449306		[learning rate: 0.0032079]
	Learning Rate: 0.00320793
	LOSS [training: 0.05481548877621907 | validation: 0.045594809794197305]
	TIME [epoch: 8.87 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04420227505759335		[learning rate: 0.0032004]
		[batch 20/20] avg loss: 0.05888719967098786		[learning rate: 0.0031929]
	Learning Rate: 0.00319289
	LOSS [training: 0.051544737364290605 | validation: 0.05484927788710235]
	TIME [epoch: 8.86 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06763220294549148		[learning rate: 0.0031854]
		[batch 20/20] avg loss: 0.0500380252852138		[learning rate: 0.0031779]
	Learning Rate: 0.00317792
	LOSS [training: 0.05883511411535265 | validation: 0.05249836852795339]
	TIME [epoch: 8.87 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/20] avg loss: 0.039225029590812914		[learning rate: 0.0031705]
		[batch 20/20] avg loss: 0.05275752014745892		[learning rate: 0.003163]
	Learning Rate: 0.00316302
	LOSS [training: 0.045991274869135915 | validation: 0.024941287029325958]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_255.pth
	Model improved!!!
EPOCH 256/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05941639835436565		[learning rate: 0.0031556]
		[batch 20/20] avg loss: 0.04973049898043643		[learning rate: 0.0031482]
	Learning Rate: 0.00314819
	LOSS [training: 0.054573448667401034 | validation: 0.03406842213596874]
	TIME [epoch: 8.92 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06749830244609627		[learning rate: 0.0031408]
		[batch 20/20] avg loss: 0.06905820479048527		[learning rate: 0.0031334]
	Learning Rate: 0.00313343
	LOSS [training: 0.06827825361829079 | validation: 0.03108376670573703]
	TIME [epoch: 8.89 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/20] avg loss: 0.049375206233365894		[learning rate: 0.0031261]
		[batch 20/20] avg loss: 0.054475485135238276		[learning rate: 0.0031187]
	Learning Rate: 0.00311874
	LOSS [training: 0.05192534568430209 | validation: 0.06995454599598067]
	TIME [epoch: 8.89 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07355527868875593		[learning rate: 0.0031114]
		[batch 20/20] avg loss: 0.03799293626690551		[learning rate: 0.0031041]
	Learning Rate: 0.00310412
	LOSS [training: 0.055774107477830716 | validation: 0.0465701697747876]
	TIME [epoch: 8.89 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0575304860080326		[learning rate: 0.0030968]
		[batch 20/20] avg loss: 0.042360229173753136		[learning rate: 0.0030896]
	Learning Rate: 0.00308957
	LOSS [training: 0.04994535759089287 | validation: 0.03998709997813232]
	TIME [epoch: 8.89 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03675451256628889		[learning rate: 0.0030823]
		[batch 20/20] avg loss: 0.07573973124565446		[learning rate: 0.0030751]
	Learning Rate: 0.00307509
	LOSS [training: 0.05624712190597168 | validation: 0.1056391536345522]
	TIME [epoch: 8.91 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05610725957268703		[learning rate: 0.0030679]
		[batch 20/20] avg loss: 0.05322642594529402		[learning rate: 0.0030607]
	Learning Rate: 0.00306067
	LOSS [training: 0.054666842758990516 | validation: 0.06735665458192891]
	TIME [epoch: 8.89 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07133395964997782		[learning rate: 0.0030535]
		[batch 20/20] avg loss: 0.05959520815888053		[learning rate: 0.0030463]
	Learning Rate: 0.00304632
	LOSS [training: 0.06546458390442916 | validation: 0.07310463080208493]
	TIME [epoch: 8.89 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06182878250489428		[learning rate: 0.0030392]
		[batch 20/20] avg loss: 0.08654822181101043		[learning rate: 0.003032]
	Learning Rate: 0.00303204
	LOSS [training: 0.07418850215795235 | validation: 0.07667394866608569]
	TIME [epoch: 8.89 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06292617569260198		[learning rate: 0.0030249]
		[batch 20/20] avg loss: 0.04787919554204716		[learning rate: 0.0030178]
	Learning Rate: 0.00301782
	LOSS [training: 0.05540268561732457 | validation: 0.0365728488571112]
	TIME [epoch: 8.91 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05611106983176719		[learning rate: 0.0030107]
		[batch 20/20] avg loss: 0.07564259022532646		[learning rate: 0.0030037]
	Learning Rate: 0.00300368
	LOSS [training: 0.06587683002854682 | validation: 0.06950219287116095]
	TIME [epoch: 8.89 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04831447350682977		[learning rate: 0.0029966]
		[batch 20/20] avg loss: 0.05260012224010292		[learning rate: 0.0029896]
	Learning Rate: 0.00298959
	LOSS [training: 0.050457297873466346 | validation: 0.07413628364784812]
	TIME [epoch: 8.89 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05539461743156725		[learning rate: 0.0029826]
		[batch 20/20] avg loss: 0.06172941810903447		[learning rate: 0.0029756]
	Learning Rate: 0.00297558
	LOSS [training: 0.05856201777030088 | validation: 0.052420959556524226]
	TIME [epoch: 8.89 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0573101633138685		[learning rate: 0.0029686]
		[batch 20/20] avg loss: 0.044740311026217255		[learning rate: 0.0029616]
	Learning Rate: 0.00296163
	LOSS [training: 0.05102523717004287 | validation: 0.04969512555561931]
	TIME [epoch: 8.88 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05344167302397283		[learning rate: 0.0029547]
		[batch 20/20] avg loss: 0.04894853595361908		[learning rate: 0.0029477]
	Learning Rate: 0.00294774
	LOSS [training: 0.05119510448879596 | validation: 0.08506110951300148]
	TIME [epoch: 8.91 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0858593003811872		[learning rate: 0.0029408]
		[batch 20/20] avg loss: 0.054017745612202704		[learning rate: 0.0029339]
	Learning Rate: 0.00293393
	LOSS [training: 0.06993852299669497 | validation: 0.035036859104894305]
	TIME [epoch: 8.89 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05984476988442635		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.05687184471612246		[learning rate: 0.0029202]
	Learning Rate: 0.00292017
	LOSS [training: 0.058358307300274415 | validation: 0.025427412586201653]
	TIME [epoch: 8.89 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/20] avg loss: 0.050668937460847586		[learning rate: 0.0029133]
		[batch 20/20] avg loss: 0.04065078040885266		[learning rate: 0.0029065]
	Learning Rate: 0.00290648
	LOSS [training: 0.045659858934850125 | validation: 0.08529379037368381]
	TIME [epoch: 8.89 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04683837480413486		[learning rate: 0.0028997]
		[batch 20/20] avg loss: 0.07571585127876215		[learning rate: 0.0028929]
	Learning Rate: 0.00289285
	LOSS [training: 0.061277113041448505 | validation: 0.06959983826720817]
	TIME [epoch: 8.89 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04161950940747231		[learning rate: 0.0028861]
		[batch 20/20] avg loss: 0.04021030392359755		[learning rate: 0.0028793]
	Learning Rate: 0.00287929
	LOSS [training: 0.040914906665534934 | validation: 0.022850785257917422]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_275.pth
	Model improved!!!
EPOCH 276/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0346723714806273		[learning rate: 0.0028725]
		[batch 20/20] avg loss: 0.06788362671716049		[learning rate: 0.0028658]
	Learning Rate: 0.00286579
	LOSS [training: 0.0512779990988939 | validation: 0.11311399593512765]
	TIME [epoch: 8.89 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/20] avg loss: 0.054569834403960904		[learning rate: 0.0028591]
		[batch 20/20] avg loss: 0.047666369223473434		[learning rate: 0.0028524]
	Learning Rate: 0.00285236
	LOSS [training: 0.051118101813717155 | validation: 0.03883889039811752]
	TIME [epoch: 8.89 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05275769739632641		[learning rate: 0.0028457]
		[batch 20/20] avg loss: 0.0642235511455901		[learning rate: 0.002839]
	Learning Rate: 0.00283899
	LOSS [training: 0.05849062427095827 | validation: 0.04342014538286895]
	TIME [epoch: 8.88 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06327809882972321		[learning rate: 0.0028323]
		[batch 20/20] avg loss: 0.038538816739220716		[learning rate: 0.0028257]
	Learning Rate: 0.00282568
	LOSS [training: 0.05090845778447197 | validation: 0.05291377599741567]
	TIME [epoch: 8.9 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/20] avg loss: 0.060517390504780555		[learning rate: 0.002819]
		[batch 20/20] avg loss: 0.0523398357459965		[learning rate: 0.0028124]
	Learning Rate: 0.00281243
	LOSS [training: 0.05642861312538853 | validation: 0.09140428843077478]
	TIME [epoch: 8.9 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05548052069434115		[learning rate: 0.0028058]
		[batch 20/20] avg loss: 0.05768194119909361		[learning rate: 0.0027992]
	Learning Rate: 0.00279924
	LOSS [training: 0.05658123094671739 | validation: 0.09843094217560107]
	TIME [epoch: 8.89 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0833941112521449		[learning rate: 0.0027927]
		[batch 20/20] avg loss: 0.057593586143773134		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.07049384869795902 | validation: 0.08281007423335916]
	TIME [epoch: 8.89 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06649109063927382		[learning rate: 0.0027796]
		[batch 20/20] avg loss: 0.0467396310657448		[learning rate: 0.0027731]
	Learning Rate: 0.00277306
	LOSS [training: 0.05661536085250931 | validation: 0.03504844657061437]
	TIME [epoch: 8.88 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04331159211281157		[learning rate: 0.0027666]
		[batch 20/20] avg loss: 0.05040513270424842		[learning rate: 0.0027601]
	Learning Rate: 0.00276006
	LOSS [training: 0.04685836240852999 | validation: 0.05501638632515991]
	TIME [epoch: 8.91 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/20] avg loss: 0.034401004017718166		[learning rate: 0.0027536]
		[batch 20/20] avg loss: 0.03996922629821099		[learning rate: 0.0027471]
	Learning Rate: 0.00274712
	LOSS [training: 0.03718511515796456 | validation: 0.028937160085358567]
	TIME [epoch: 8.89 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/20] avg loss: 0.059593845317786956		[learning rate: 0.0027407]
		[batch 20/20] avg loss: 0.0614378493323451		[learning rate: 0.0027342]
	Learning Rate: 0.00273424
	LOSS [training: 0.06051584732506603 | validation: 0.06110413483714064]
	TIME [epoch: 8.88 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05530762156894468		[learning rate: 0.0027278]
		[batch 20/20] avg loss: 0.045224214695064324		[learning rate: 0.0027214]
	Learning Rate: 0.00272142
	LOSS [training: 0.0502659181320045 | validation: 0.050883113741416484]
	TIME [epoch: 8.89 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05427975643667051		[learning rate: 0.002715]
		[batch 20/20] avg loss: 0.04022934398034255		[learning rate: 0.0027087]
	Learning Rate: 0.00270866
	LOSS [training: 0.04725455020850654 | validation: 0.038725457513456164]
	TIME [epoch: 8.88 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/20] avg loss: 0.046806499749968714		[learning rate: 0.0027023]
		[batch 20/20] avg loss: 0.06994410346564624		[learning rate: 0.002696]
	Learning Rate: 0.00269597
	LOSS [training: 0.058375301607807475 | validation: 0.08312663167156024]
	TIME [epoch: 8.91 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08877719415634108		[learning rate: 0.0026896]
		[batch 20/20] avg loss: 0.03824564094705629		[learning rate: 0.0026833]
	Learning Rate: 0.00268333
	LOSS [training: 0.06351141755169867 | validation: 0.03878776677373455]
	TIME [epoch: 8.89 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0249573738735633		[learning rate: 0.002677]
		[batch 20/20] avg loss: 0.032479267004335795		[learning rate: 0.0026707]
	Learning Rate: 0.00267075
	LOSS [training: 0.028718320438949545 | validation: 0.03153507082633473]
	TIME [epoch: 8.89 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/20] avg loss: 0.037430444737567084		[learning rate: 0.0026645]
		[batch 20/20] avg loss: 0.060706851212435464		[learning rate: 0.0026582]
	Learning Rate: 0.00265823
	LOSS [training: 0.04906864797500127 | validation: 0.046481664276026374]
	TIME [epoch: 8.89 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/20] avg loss: 0.033135050395585654		[learning rate: 0.002652]
		[batch 20/20] avg loss: 0.04561817686351264		[learning rate: 0.0026458]
	Learning Rate: 0.00264576
	LOSS [training: 0.039376613629549154 | validation: 0.08117552139837561]
	TIME [epoch: 8.89 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06204170919116986		[learning rate: 0.0026396]
		[batch 20/20] avg loss: 0.05427664556032793		[learning rate: 0.0026334]
	Learning Rate: 0.00263336
	LOSS [training: 0.0581591773757489 | validation: 0.05373764392307866]
	TIME [epoch: 8.92 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05407885360090018		[learning rate: 0.0026272]
		[batch 20/20] avg loss: 0.04240630538407426		[learning rate: 0.002621]
	Learning Rate: 0.00262101
	LOSS [training: 0.04824257949248722 | validation: 0.01934303633375203]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_295.pth
	Model improved!!!
EPOCH 296/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03241085890687897		[learning rate: 0.0026149]
		[batch 20/20] avg loss: 0.042994764487655796		[learning rate: 0.0026087]
	Learning Rate: 0.00260873
	LOSS [training: 0.03770281169726737 | validation: 0.021405544891496986]
	TIME [epoch: 8.9 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02817645748001928		[learning rate: 0.0026026]
		[batch 20/20] avg loss: 0.04801408076975306		[learning rate: 0.0025965]
	Learning Rate: 0.0025965
	LOSS [training: 0.038095269124886165 | validation: 0.06627735035634938]
	TIME [epoch: 8.88 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03854449406754649		[learning rate: 0.0025904]
		[batch 20/20] avg loss: 0.06573662503564698		[learning rate: 0.0025843]
	Learning Rate: 0.00258432
	LOSS [training: 0.052140559551596743 | validation: 0.0430844109645267]
	TIME [epoch: 8.91 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05296410567058971		[learning rate: 0.0025783]
		[batch 20/20] avg loss: 0.0575608847314664		[learning rate: 0.0025722]
	Learning Rate: 0.00257221
	LOSS [training: 0.05526249520102805 | validation: 0.06963089025091151]
	TIME [epoch: 8.9 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06960410371102717		[learning rate: 0.0025662]
		[batch 20/20] avg loss: 0.07334428539724488		[learning rate: 0.0025601]
	Learning Rate: 0.00256015
	LOSS [training: 0.07147419455413603 | validation: 0.08525821867027046]
	TIME [epoch: 8.89 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05602264454411945		[learning rate: 0.0025541]
		[batch 20/20] avg loss: 0.06192513081825209		[learning rate: 0.0025481]
	Learning Rate: 0.00254815
	LOSS [training: 0.05897388768118576 | validation: 0.08407543791144406]
	TIME [epoch: 8.89 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05838216827611618		[learning rate: 0.0025422]
		[batch 20/20] avg loss: 0.04964027749685993		[learning rate: 0.0025362]
	Learning Rate: 0.0025362
	LOSS [training: 0.05401122288648804 | validation: 0.04891084541419899]
	TIME [epoch: 8.89 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/20] avg loss: 0.038255655984660124		[learning rate: 0.0025302]
		[batch 20/20] avg loss: 0.037326791921976465		[learning rate: 0.0025243]
	Learning Rate: 0.00252431
	LOSS [training: 0.0377912239533183 | validation: 0.04934217528393441]
	TIME [epoch: 8.91 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/20] avg loss: 0.042382778284015044		[learning rate: 0.0025184]
		[batch 20/20] avg loss: 0.048263174059300654		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.04532297617165784 | validation: 0.09120041220040029]
	TIME [epoch: 8.89 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06255881548208889		[learning rate: 0.0025066]
		[batch 20/20] avg loss: 0.029277144017060237		[learning rate: 0.0025007]
	Learning Rate: 0.0025007
	LOSS [training: 0.04591797974957456 | validation: 0.038178220174162905]
	TIME [epoch: 8.88 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05224193698885808		[learning rate: 0.0024948]
		[batch 20/20] avg loss: 0.040399153722780724		[learning rate: 0.002489]
	Learning Rate: 0.00248897
	LOSS [training: 0.046320545355819406 | validation: 0.04212897048898308]
	TIME [epoch: 8.89 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030273456021363505		[learning rate: 0.0024831]
		[batch 20/20] avg loss: 0.030596153762182464		[learning rate: 0.0024773]
	Learning Rate: 0.00247731
	LOSS [training: 0.03043480489177298 | validation: 0.04462208795855689]
	TIME [epoch: 8.88 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05196596832377073		[learning rate: 0.0024715]
		[batch 20/20] avg loss: 0.03239544451735512		[learning rate: 0.0024657]
	Learning Rate: 0.00246569
	LOSS [training: 0.04218070642056293 | validation: 0.01739842758498504]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_308.pth
	Model improved!!!
EPOCH 309/500:
	Training over batches...
		[batch 10/20] avg loss: 0.048898342814696086		[learning rate: 0.0024599]
		[batch 20/20] avg loss: 0.051312875575190355		[learning rate: 0.0024541]
	Learning Rate: 0.00245413
	LOSS [training: 0.050105609194943224 | validation: 0.04719582914934082]
	TIME [epoch: 8.88 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/20] avg loss: 0.048279021674874315		[learning rate: 0.0024484]
		[batch 20/20] avg loss: 0.032586493132862035		[learning rate: 0.0024426]
	Learning Rate: 0.00244263
	LOSS [training: 0.04043275740386816 | validation: 0.046748894634457284]
	TIME [epoch: 8.89 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/20] avg loss: 0.047061149389731105		[learning rate: 0.0024369]
		[batch 20/20] avg loss: 0.03139866524543408		[learning rate: 0.0024312]
	Learning Rate: 0.00243118
	LOSS [training: 0.039229907317582594 | validation: 0.04396101418657353]
	TIME [epoch: 8.88 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/20] avg loss: 0.059886029300282195		[learning rate: 0.0024255]
		[batch 20/20] avg loss: 0.0481260597726238		[learning rate: 0.0024198]
	Learning Rate: 0.00241978
	LOSS [training: 0.05400604453645299 | validation: 0.0691746787778576]
	TIME [epoch: 8.9 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06161145015968422		[learning rate: 0.0024141]
		[batch 20/20] avg loss: 0.05387307156932715		[learning rate: 0.0024084]
	Learning Rate: 0.00240843
	LOSS [training: 0.0577422608645057 | validation: 0.04798286058733732]
	TIME [epoch: 8.88 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026908843887325524		[learning rate: 0.0024028]
		[batch 20/20] avg loss: 0.03933793151534355		[learning rate: 0.0023971]
	Learning Rate: 0.00239714
	LOSS [training: 0.033123387701334536 | validation: 0.04435884759085562]
	TIME [epoch: 8.88 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06063043215973331		[learning rate: 0.0023915]
		[batch 20/20] avg loss: 0.03161552654405547		[learning rate: 0.0023859]
	Learning Rate: 0.0023859
	LOSS [training: 0.0461229793518944 | validation: 0.032727136964989356]
	TIME [epoch: 8.88 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02771467635556174		[learning rate: 0.0023803]
		[batch 20/20] avg loss: 0.04040742027462295		[learning rate: 0.0023747]
	Learning Rate: 0.00237472
	LOSS [training: 0.034061048315092345 | validation: 0.03295822011110445]
	TIME [epoch: 8.88 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03861821154143723		[learning rate: 0.0023691]
		[batch 20/20] avg loss: 0.03807075549035198		[learning rate: 0.0023636]
	Learning Rate: 0.00236359
	LOSS [training: 0.0383444835158946 | validation: 0.09398301899362434]
	TIME [epoch: 8.9 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04212228163846756		[learning rate: 0.002358]
		[batch 20/20] avg loss: 0.029163545397127753		[learning rate: 0.0023525]
	Learning Rate: 0.00235251
	LOSS [training: 0.03564291351779766 | validation: 0.040025594365510196]
	TIME [epoch: 8.88 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03933866509479857		[learning rate: 0.002347]
		[batch 20/20] avg loss: 0.05059350508109499		[learning rate: 0.0023415]
	Learning Rate: 0.00234148
	LOSS [training: 0.044966085087946785 | validation: 0.03026322879450524]
	TIME [epoch: 8.88 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028346442759111752		[learning rate: 0.002336]
		[batch 20/20] avg loss: 0.041893854360004715		[learning rate: 0.0023305]
	Learning Rate: 0.0023305
	LOSS [training: 0.03512014855955823 | validation: 0.06162966458785931]
	TIME [epoch: 8.88 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04071365393028868		[learning rate: 0.002325]
		[batch 20/20] avg loss: 0.02189928204067333		[learning rate: 0.0023196]
	Learning Rate: 0.00231957
	LOSS [training: 0.031306467985481 | validation: 0.019774146393143885]
	TIME [epoch: 8.89 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030150607972918436		[learning rate: 0.0023141]
		[batch 20/20] avg loss: 0.030416731636976696		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.030283669804947566 | validation: 0.05256833395048571]
	TIME [epoch: 8.9 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03297037533578957		[learning rate: 0.0023033]
		[batch 20/20] avg loss: 0.021873295088154738		[learning rate: 0.0022979]
	Learning Rate: 0.00229788
	LOSS [training: 0.027421835211972157 | validation: 0.012196402144818666]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_323.pth
	Model improved!!!
EPOCH 324/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03496437605161155		[learning rate: 0.0022925]
		[batch 20/20] avg loss: 0.030576336091284222		[learning rate: 0.0022871]
	Learning Rate: 0.0022871
	LOSS [training: 0.03277035607144788 | validation: 0.1134746428422948]
	TIME [epoch: 8.88 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/20] avg loss: 0.060615309953834996		[learning rate: 0.0022817]
		[batch 20/20] avg loss: 0.03970865398935678		[learning rate: 0.0022764]
	Learning Rate: 0.00227638
	LOSS [training: 0.05016198197159588 | validation: 0.03797768513970392]
	TIME [epoch: 8.88 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030090753723041895		[learning rate: 0.002271]
		[batch 20/20] avg loss: 0.04205774265610065		[learning rate: 0.0022657]
	Learning Rate: 0.00226571
	LOSS [training: 0.03607424818957128 | validation: 0.024065969515015252]
	TIME [epoch: 8.9 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02880229118731046		[learning rate: 0.0022604]
		[batch 20/20] avg loss: 0.02388651938190214		[learning rate: 0.0022551]
	Learning Rate: 0.00225509
	LOSS [training: 0.026344405284606298 | validation: 0.01815570334271535]
	TIME [epoch: 8.88 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05514760186874039		[learning rate: 0.0022498]
		[batch 20/20] avg loss: 0.03185293233157552		[learning rate: 0.0022445]
	Learning Rate: 0.00224451
	LOSS [training: 0.04350026710015796 | validation: 0.03775660377778886]
	TIME [epoch: 8.88 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03926926155405279		[learning rate: 0.0022392]
		[batch 20/20] avg loss: 0.03595748360527011		[learning rate: 0.002234]
	Learning Rate: 0.00223399
	LOSS [training: 0.03761337257966146 | validation: 0.021570049064503785]
	TIME [epoch: 8.88 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021925421882854075		[learning rate: 0.0022287]
		[batch 20/20] avg loss: 0.029631999808172417		[learning rate: 0.0022235]
	Learning Rate: 0.00222352
	LOSS [training: 0.025778710845513246 | validation: 0.05719551150269466]
	TIME [epoch: 8.88 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03589460954338948		[learning rate: 0.0022183]
		[batch 20/20] avg loss: 0.025705568290947327		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.030800088917168407 | validation: 0.03062832337172566]
	TIME [epoch: 8.91 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/20] avg loss: 0.033037192847057945		[learning rate: 0.0022079]
		[batch 20/20] avg loss: 0.0259429252429155		[learning rate: 0.0022027]
	Learning Rate: 0.00220272
	LOSS [training: 0.02949005904498673 | validation: 0.04866992041604037]
	TIME [epoch: 8.88 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/20] avg loss: 0.047428478489578804		[learning rate: 0.0021976]
		[batch 20/20] avg loss: 0.034915071660744104		[learning rate: 0.0021924]
	Learning Rate: 0.00219239
	LOSS [training: 0.04117177507516145 | validation: 0.034353665588765375]
	TIME [epoch: 8.88 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/20] avg loss: 0.042016002935924786		[learning rate: 0.0021872]
		[batch 20/20] avg loss: 0.048380082161856755		[learning rate: 0.0021821]
	Learning Rate: 0.00218211
	LOSS [training: 0.04519804254889077 | validation: 0.05269834085111309]
	TIME [epoch: 8.88 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05591260547621146		[learning rate: 0.002177]
		[batch 20/20] avg loss: 0.05727986127852992		[learning rate: 0.0021719]
	Learning Rate: 0.00217188
	LOSS [training: 0.05659623337737067 | validation: 0.07567906175179445]
	TIME [epoch: 8.88 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04670046077609132		[learning rate: 0.0021668]
		[batch 20/20] avg loss: 0.06705257661166128		[learning rate: 0.0021617]
	Learning Rate: 0.0021617
	LOSS [training: 0.05687651869387629 | validation: 0.07154718056337392]
	TIME [epoch: 8.9 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04086614929300649		[learning rate: 0.0021566]
		[batch 20/20] avg loss: 0.05769576803205982		[learning rate: 0.0021516]
	Learning Rate: 0.00215157
	LOSS [training: 0.04928095866253317 | validation: 0.056065654519114515]
	TIME [epoch: 8.88 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04070877446879105		[learning rate: 0.0021465]
		[batch 20/20] avg loss: 0.02224215883707846		[learning rate: 0.0021415]
	Learning Rate: 0.00214148
	LOSS [training: 0.031475466652934755 | validation: 0.023678596605607255]
	TIME [epoch: 8.88 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030179124241144644		[learning rate: 0.0021365]
		[batch 20/20] avg loss: 0.0323644965289519		[learning rate: 0.0021314]
	Learning Rate: 0.00213144
	LOSS [training: 0.03127181038504827 | validation: 0.019633764308427615]
	TIME [epoch: 8.87 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/20] avg loss: 0.038771914918385164		[learning rate: 0.0021264]
		[batch 20/20] avg loss: 0.03780749581980493		[learning rate: 0.0021214]
	Learning Rate: 0.00212145
	LOSS [training: 0.038289705369095046 | validation: 0.06503093602242993]
	TIME [epoch: 8.89 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03674260624307062		[learning rate: 0.0021165]
		[batch 20/20] avg loss: 0.031388594751627454		[learning rate: 0.0021115]
	Learning Rate: 0.0021115
	LOSS [training: 0.03406560049734904 | validation: 0.02743115254330578]
	TIME [epoch: 8.89 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02202360772737066		[learning rate: 0.0021065]
		[batch 20/20] avg loss: 0.03969479021271695		[learning rate: 0.0021016]
	Learning Rate: 0.0021016
	LOSS [training: 0.030859198970043807 | validation: 0.030968367173720448]
	TIME [epoch: 8.87 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03152901338942571		[learning rate: 0.0020967]
		[batch 20/20] avg loss: 0.044222413519520956		[learning rate: 0.0020918]
	Learning Rate: 0.00209175
	LOSS [training: 0.03787571345447334 | validation: 0.04007943790576436]
	TIME [epoch: 8.88 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0346029112107707		[learning rate: 0.0020868]
		[batch 20/20] avg loss: 0.07213313592413181		[learning rate: 0.0020819]
	Learning Rate: 0.00208195
	LOSS [training: 0.05336802356745125 | validation: 0.06725093809206084]
	TIME [epoch: 8.91 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/20] avg loss: 0.059170053137061904		[learning rate: 0.0020771]
		[batch 20/20] avg loss: 0.020051208719866105		[learning rate: 0.0020722]
	Learning Rate: 0.00207219
	LOSS [training: 0.039610630928464 | validation: 0.03964974237692712]
	TIME [epoch: 8.9 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05221428029596785		[learning rate: 0.0020673]
		[batch 20/20] avg loss: 0.019261845455224014		[learning rate: 0.0020625]
	Learning Rate: 0.00206247
	LOSS [training: 0.03573806287559592 | validation: 0.013170277126706107]
	TIME [epoch: 8.88 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/20] avg loss: 0.016866384234903862		[learning rate: 0.0020576]
		[batch 20/20] avg loss: 0.03007316995062852		[learning rate: 0.0020528]
	Learning Rate: 0.0020528
	LOSS [training: 0.02346977709276619 | validation: 0.03720375699199462]
	TIME [epoch: 8.88 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02071220343383152		[learning rate: 0.002048]
		[batch 20/20] avg loss: 0.028892396234554685		[learning rate: 0.0020432]
	Learning Rate: 0.00204318
	LOSS [training: 0.024802299834193107 | validation: 0.0355186210545628]
	TIME [epoch: 8.88 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02921517842282938		[learning rate: 0.0020384]
		[batch 20/20] avg loss: 0.028231009102600502		[learning rate: 0.0020336]
	Learning Rate: 0.0020336
	LOSS [training: 0.02872309376271494 | validation: 0.05057106910938857]
	TIME [epoch: 8.87 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028785404753532907		[learning rate: 0.0020288]
		[batch 20/20] avg loss: 0.033390832569927247		[learning rate: 0.0020241]
	Learning Rate: 0.00202407
	LOSS [training: 0.03108811866173008 | validation: 0.08325900564237612]
	TIME [epoch: 8.9 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/20] avg loss: 0.046928016094595626		[learning rate: 0.0020193]
		[batch 20/20] avg loss: 0.03339733072592958		[learning rate: 0.0020146]
	Learning Rate: 0.00201458
	LOSS [training: 0.0401626734102626 | validation: 0.03225055273351207]
	TIME [epoch: 8.88 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/20] avg loss: 0.034520313721107074		[learning rate: 0.0020098]
		[batch 20/20] avg loss: 0.02821379017633665		[learning rate: 0.0020051]
	Learning Rate: 0.00200513
	LOSS [training: 0.03136705194872186 | validation: 0.016086885699300998]
	TIME [epoch: 8.87 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03197942854854451		[learning rate: 0.0020004]
		[batch 20/20] avg loss: 0.03406689636166024		[learning rate: 0.0019957]
	Learning Rate: 0.00199573
	LOSS [training: 0.03302316245510238 | validation: 0.05539375804845889]
	TIME [epoch: 8.88 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04029590690321446		[learning rate: 0.001991]
		[batch 20/20] avg loss: 0.021416081733687115		[learning rate: 0.0019864]
	Learning Rate: 0.00198637
	LOSS [training: 0.030855994318450784 | validation: 0.015554808413122134]
	TIME [epoch: 8.88 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04155711700802655		[learning rate: 0.0019817]
		[batch 20/20] avg loss: 0.02939963756051303		[learning rate: 0.0019771]
	Learning Rate: 0.00197706
	LOSS [training: 0.035478377284269794 | validation: 0.02123438569474516]
	TIME [epoch: 8.9 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021482903123590885		[learning rate: 0.0019724]
		[batch 20/20] avg loss: 0.025744894200406987		[learning rate: 0.0019678]
	Learning Rate: 0.00196779
	LOSS [training: 0.023613898661998943 | validation: 0.03468893804100224]
	TIME [epoch: 8.87 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/20] avg loss: 0.039488369214868334		[learning rate: 0.0019632]
		[batch 20/20] avg loss: 0.043424453315308295		[learning rate: 0.0019586]
	Learning Rate: 0.00195857
	LOSS [training: 0.04145641126508832 | validation: 0.02237082087728507]
	TIME [epoch: 8.87 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/20] avg loss: 0.031247708800138756		[learning rate: 0.001954]
		[batch 20/20] avg loss: 0.03642677862229291		[learning rate: 0.0019494]
	Learning Rate: 0.00194939
	LOSS [training: 0.03383724371121584 | validation: 0.027896712436241047]
	TIME [epoch: 8.88 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03546603158556063		[learning rate: 0.0019448]
		[batch 20/20] avg loss: 0.021627891993930053		[learning rate: 0.0019402]
	Learning Rate: 0.00194025
	LOSS [training: 0.028546961789745345 | validation: 0.04002767473917128]
	TIME [epoch: 8.89 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04396527597053052		[learning rate: 0.0019357]
		[batch 20/20] avg loss: 0.02768136212339705		[learning rate: 0.0019312]
	Learning Rate: 0.00193115
	LOSS [training: 0.03582331904696378 | validation: 0.019142081961370953]
	TIME [epoch: 8.87 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01744857337769925		[learning rate: 0.0019266]
		[batch 20/20] avg loss: 0.032477509521975804		[learning rate: 0.0019221]
	Learning Rate: 0.0019221
	LOSS [training: 0.024963041449837527 | validation: 0.04482666398142162]
	TIME [epoch: 8.87 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05444897823925567		[learning rate: 0.0019176]
		[batch 20/20] avg loss: 0.03148425615781435		[learning rate: 0.0019131]
	Learning Rate: 0.00191309
	LOSS [training: 0.042966617198535 | validation: 0.044427699618826165]
	TIME [epoch: 8.87 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/20] avg loss: 0.050941918925907104		[learning rate: 0.0019086]
		[batch 20/20] avg loss: 0.0658074824773373		[learning rate: 0.0019041]
	Learning Rate: 0.00190412
	LOSS [training: 0.058374700701622206 | validation: 0.03753314620752861]
	TIME [epoch: 8.87 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04274744307896118		[learning rate: 0.0018996]
		[batch 20/20] avg loss: 0.05245934681878054		[learning rate: 0.0018952]
	Learning Rate: 0.00189519
	LOSS [training: 0.04760339494887085 | validation: 0.025171444549245865]
	TIME [epoch: 8.9 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0405346875065067		[learning rate: 0.0018907]
		[batch 20/20] avg loss: 0.05283491063470299		[learning rate: 0.0018863]
	Learning Rate: 0.00188631
	LOSS [training: 0.04668479907060484 | validation: 0.08390722416286342]
	TIME [epoch: 8.87 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03622900347803363		[learning rate: 0.0018819]
		[batch 20/20] avg loss: 0.06922984276718078		[learning rate: 0.0018775]
	Learning Rate: 0.00187746
	LOSS [training: 0.0527294231226072 | validation: 0.10820044656661135]
	TIME [epoch: 8.87 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07578075246176266		[learning rate: 0.0018731]
		[batch 20/20] avg loss: 0.07204149562758791		[learning rate: 0.0018687]
	Learning Rate: 0.00186866
	LOSS [training: 0.07391112404467531 | validation: 0.05840715159468711]
	TIME [epoch: 8.87 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0333589421023786		[learning rate: 0.0018643]
		[batch 20/20] avg loss: 0.026915366366638847		[learning rate: 0.0018599]
	Learning Rate: 0.0018599
	LOSS [training: 0.030137154234508724 | validation: 0.01916548923555382]
	TIME [epoch: 8.87 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/20] avg loss: 0.033510925119520064		[learning rate: 0.0018555]
		[batch 20/20] avg loss: 0.017776678381191475		[learning rate: 0.0018512]
	Learning Rate: 0.00185118
	LOSS [training: 0.02564380175035577 | validation: 0.03424927814359553]
	TIME [epoch: 8.89 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029510811148057564		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.029828468897327237		[learning rate: 0.0018425]
	Learning Rate: 0.0018425
	LOSS [training: 0.029669640022692394 | validation: 0.016919318580135786]
	TIME [epoch: 8.87 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01997598926127501		[learning rate: 0.0018382]
		[batch 20/20] avg loss: 0.024099774479292665		[learning rate: 0.0018339]
	Learning Rate: 0.00183386
	LOSS [training: 0.02203788187028384 | validation: 0.03059653271880968]
	TIME [epoch: 8.87 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03804614024597351		[learning rate: 0.0018296]
		[batch 20/20] avg loss: 0.022713916738083356		[learning rate: 0.0018253]
	Learning Rate: 0.00182527
	LOSS [training: 0.03038002849202844 | validation: 0.020666374265973522]
	TIME [epoch: 8.87 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027637386615356363		[learning rate: 0.001821]
		[batch 20/20] avg loss: 0.03908760562972087		[learning rate: 0.0018167]
	Learning Rate: 0.00181671
	LOSS [training: 0.03336249612253862 | validation: 0.03753167057677699]
	TIME [epoch: 8.89 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03374373989900793		[learning rate: 0.0018124]
		[batch 20/20] avg loss: 0.04171270257363957		[learning rate: 0.0018082]
	Learning Rate: 0.00180819
	LOSS [training: 0.037728221236323765 | validation: 0.04167616596932161]
	TIME [epoch: 8.87 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04690893791105419		[learning rate: 0.001804]
		[batch 20/20] avg loss: 0.037538442779319635		[learning rate: 0.0017997]
	Learning Rate: 0.00179972
	LOSS [training: 0.042223690345186915 | validation: 0.049218008728853915]
	TIME [epoch: 8.87 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04588883608406126		[learning rate: 0.0017955]
		[batch 20/20] avg loss: 0.03984896119886605		[learning rate: 0.0017913]
	Learning Rate: 0.00179128
	LOSS [training: 0.04286889864146365 | validation: 0.045311131062721874]
	TIME [epoch: 8.87 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04636926925509153		[learning rate: 0.0017871]
		[batch 20/20] avg loss: 0.036860150659247595		[learning rate: 0.0017829]
	Learning Rate: 0.00178288
	LOSS [training: 0.04161470995716956 | validation: 0.025189570703848883]
	TIME [epoch: 8.87 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027570888241206064		[learning rate: 0.0017787]
		[batch 20/20] avg loss: 0.02943921239755389		[learning rate: 0.0017745]
	Learning Rate: 0.00177452
	LOSS [training: 0.028505050319379978 | validation: 0.03517513383982412]
	TIME [epoch: 8.89 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023324835999112524		[learning rate: 0.0017704]
		[batch 20/20] avg loss: 0.028027972227582958		[learning rate: 0.0017662]
	Learning Rate: 0.0017662
	LOSS [training: 0.025676404113347744 | validation: 0.03770286568828653]
	TIME [epoch: 8.87 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/20] avg loss: 0.042013206779515505		[learning rate: 0.0017621]
		[batch 20/20] avg loss: 0.031478882554574775		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.03674604466704514 | validation: 0.03295855440052273]
	TIME [epoch: 8.87 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02563617126298725		[learning rate: 0.0017538]
		[batch 20/20] avg loss: 0.0337787462218521		[learning rate: 0.0017497]
	Learning Rate: 0.00174968
	LOSS [training: 0.029707458742419673 | validation: 0.020856812051559467]
	TIME [epoch: 8.9 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025618586741223037		[learning rate: 0.0017456]
		[batch 20/20] avg loss: 0.023391004884251547		[learning rate: 0.0017415]
	Learning Rate: 0.00174148
	LOSS [training: 0.024504795812737297 | validation: 0.059178332203372305]
	TIME [epoch: 8.9 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05199341645488966		[learning rate: 0.0017374]
		[batch 20/20] avg loss: 0.06322349410532602		[learning rate: 0.0017333]
	Learning Rate: 0.00173331
	LOSS [training: 0.05760845528010785 | validation: 0.049597284942458165]
	TIME [epoch: 8.93 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/20] avg loss: 0.052450787309558086		[learning rate: 0.0017292]
		[batch 20/20] avg loss: 0.03182860431561485		[learning rate: 0.0017252]
	Learning Rate: 0.00172519
	LOSS [training: 0.04213969581258646 | validation: 0.02644152485038922]
	TIME [epoch: 8.9 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022953152406791806		[learning rate: 0.0017211]
		[batch 20/20] avg loss: 0.03041098732140273		[learning rate: 0.0017171]
	Learning Rate: 0.0017171
	LOSS [training: 0.02668206986409727 | validation: 0.06966040982937453]
	TIME [epoch: 8.89 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027312668076295888		[learning rate: 0.0017131]
		[batch 20/20] avg loss: 0.026793761272127743		[learning rate: 0.0017091]
	Learning Rate: 0.00170905
	LOSS [training: 0.027053214674211817 | validation: 0.07634426793073035]
	TIME [epoch: 8.9 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029585072107493764		[learning rate: 0.001705]
		[batch 20/20] avg loss: 0.030320510620648396		[learning rate: 0.001701]
	Learning Rate: 0.00170104
	LOSS [training: 0.029952791364071075 | validation: 0.04968601040691251]
	TIME [epoch: 8.94 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03535705198408709		[learning rate: 0.001697]
		[batch 20/20] avg loss: 0.02872536250684355		[learning rate: 0.0016931]
	Learning Rate: 0.00169306
	LOSS [training: 0.03204120724546531 | validation: 0.03279821469796666]
	TIME [epoch: 8.92 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02381734127273196		[learning rate: 0.0016891]
		[batch 20/20] avg loss: 0.00849511764140078		[learning rate: 0.0016851]
	Learning Rate: 0.00168513
	LOSS [training: 0.01615622945706637 | validation: 0.021357119429399336]
	TIME [epoch: 8.9 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04318777173975813		[learning rate: 0.0016812]
		[batch 20/20] avg loss: 0.03180946432942138		[learning rate: 0.0016772]
	Learning Rate: 0.00167723
	LOSS [training: 0.03749861803458975 | validation: 0.03362748729039382]
	TIME [epoch: 8.9 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04205180734369161		[learning rate: 0.0016733]
		[batch 20/20] avg loss: 0.033490545625712055		[learning rate: 0.0016694]
	Learning Rate: 0.00166936
	LOSS [training: 0.03777117648470184 | validation: 0.035964446492470235]
	TIME [epoch: 8.9 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0344101388098854		[learning rate: 0.0016654]
		[batch 20/20] avg loss: 0.033309816338392764		[learning rate: 0.0016615]
	Learning Rate: 0.00166154
	LOSS [training: 0.033859977574139076 | validation: 0.030825327842952624]
	TIME [epoch: 8.94 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01887942633689507		[learning rate: 0.0016576]
		[batch 20/20] avg loss: 0.020034750468922544		[learning rate: 0.0016537]
	Learning Rate: 0.00165375
	LOSS [training: 0.019457088402908804 | validation: 0.020370394785223813]
	TIME [epoch: 8.91 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/20] avg loss: 0.038208375825479424		[learning rate: 0.0016499]
		[batch 20/20] avg loss: 0.03298989930760572		[learning rate: 0.001646]
	Learning Rate: 0.001646
	LOSS [training: 0.03559913756654258 | validation: 0.019833225192996035]
	TIME [epoch: 8.89 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018272103374956678		[learning rate: 0.0016421]
		[batch 20/20] avg loss: 0.019247277278238488		[learning rate: 0.0016383]
	Learning Rate: 0.00163828
	LOSS [training: 0.01875969032659758 | validation: 0.03526019172576624]
	TIME [epoch: 8.86 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030768275589876982		[learning rate: 0.0016344]
		[batch 20/20] avg loss: 0.014028954759737186		[learning rate: 0.0016306]
	Learning Rate: 0.0016306
	LOSS [training: 0.022398615174807075 | validation: 0.008706242956000988]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_396.pth
	Model improved!!!
EPOCH 397/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014048748031132355		[learning rate: 0.0016268]
		[batch 20/20] avg loss: 0.03316230604430342		[learning rate: 0.001623]
	Learning Rate: 0.00162295
	LOSS [training: 0.023605527037717882 | validation: 0.051388132103144094]
	TIME [epoch: 8.92 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025988940470709793		[learning rate: 0.0016191]
		[batch 20/20] avg loss: 0.04605277941447167		[learning rate: 0.0016153]
	Learning Rate: 0.00161535
	LOSS [training: 0.03602085994259072 | validation: 0.04337164214010003]
	TIME [epoch: 8.86 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/20] avg loss: 0.016672132398660326		[learning rate: 0.0016116]
		[batch 20/20] avg loss: 0.05106222265238981		[learning rate: 0.0016078]
	Learning Rate: 0.00160777
	LOSS [training: 0.03386717752552507 | validation: 0.04644428066684762]
	TIME [epoch: 8.85 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03216503635788663		[learning rate: 0.001604]
		[batch 20/20] avg loss: 0.020240051309195792		[learning rate: 0.0016002]
	Learning Rate: 0.00160023
	LOSS [training: 0.02620254383354121 | validation: 0.029430293518809332]
	TIME [epoch: 8.86 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02780858334503436		[learning rate: 0.0015965]
		[batch 20/20] avg loss: 0.034933053529817945		[learning rate: 0.0015927]
	Learning Rate: 0.00159273
	LOSS [training: 0.03137081843742616 | validation: 0.02386242544045596]
	TIME [epoch: 8.85 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027240921969447756		[learning rate: 0.001589]
		[batch 20/20] avg loss: 0.035996492822013136		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.031618707395730444 | validation: 0.04725870871284717]
	TIME [epoch: 8.88 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/20] avg loss: 0.042922209431908484		[learning rate: 0.0015815]
		[batch 20/20] avg loss: 0.042594952996380574		[learning rate: 0.0015778]
	Learning Rate: 0.00157783
	LOSS [training: 0.042758581214144525 | validation: 0.03635803529581982]
	TIME [epoch: 8.85 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04262796339151294		[learning rate: 0.0015741]
		[batch 20/20] avg loss: 0.02309638557402536		[learning rate: 0.0015704]
	Learning Rate: 0.00157044
	LOSS [training: 0.03286217448276914 | validation: 0.02159880088520203]
	TIME [epoch: 8.86 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03510232068843293		[learning rate: 0.0015668]
		[batch 20/20] avg loss: 0.032155722504352016		[learning rate: 0.0015631]
	Learning Rate: 0.00156307
	LOSS [training: 0.033629021596392465 | validation: 0.03700531773380243]
	TIME [epoch: 8.85 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/20] avg loss: 0.048972214252593835		[learning rate: 0.0015594]
		[batch 20/20] avg loss: 0.09440766267836898		[learning rate: 0.0015557]
	Learning Rate: 0.00155575
	LOSS [training: 0.07168993846548141 | validation: 0.03412570551496667]
	TIME [epoch: 8.88 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/20] avg loss: 0.031980594021444333		[learning rate: 0.0015521]
		[batch 20/20] avg loss: 0.052922710448538524		[learning rate: 0.0015485]
	Learning Rate: 0.00154845
	LOSS [training: 0.042451652234991435 | validation: 0.034647204125672876]
	TIME [epoch: 8.86 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/20] avg loss: 0.034804000823308104		[learning rate: 0.0015448]
		[batch 20/20] avg loss: 0.025024376273399724		[learning rate: 0.0015412]
	Learning Rate: 0.00154119
	LOSS [training: 0.02991418854835391 | validation: 0.007229119803880193]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240214_173355/states/model_tr_study2_408.pth
	Model improved!!!
EPOCH 409/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021904025212555724		[learning rate: 0.0015376]
		[batch 20/20] avg loss: 0.026659338584140074		[learning rate: 0.001534]
	Learning Rate: 0.00153397
	LOSS [training: 0.0242816818983479 | validation: 0.022877831604883162]
	TIME [epoch: 8.86 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02451391254476283		[learning rate: 0.0015304]
		[batch 20/20] avg loss: 0.031097215287949266		[learning rate: 0.0015268]
	Learning Rate: 0.00152678
	LOSS [training: 0.027805563916356045 | validation: 0.029353140578940534]
	TIME [epoch: 8.86 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01809997328596536		[learning rate: 0.0015232]
		[batch 20/20] avg loss: 0.03002440142499988		[learning rate: 0.0015196]
	Learning Rate: 0.00151962
	LOSS [training: 0.024062187355482618 | validation: 0.013100859029047025]
	TIME [epoch: 8.88 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013994701876484666		[learning rate: 0.0015161]
		[batch 20/20] avg loss: 0.023794211133629107		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.018894456505056882 | validation: 0.024458381037357577]
	TIME [epoch: 8.86 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01790541929582519		[learning rate: 0.0015089]
		[batch 20/20] avg loss: 0.04774819092819017		[learning rate: 0.0015054]
	Learning Rate: 0.0015054
	LOSS [training: 0.03282680511200768 | validation: 0.0529727700088059]
	TIME [epoch: 8.85 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/20] avg loss: 0.039065815681216906		[learning rate: 0.0015019]
		[batch 20/20] avg loss: 0.0377146353997871		[learning rate: 0.0014983]
	Learning Rate: 0.00149835
	LOSS [training: 0.038390225540502004 | validation: 0.03366285823450895]
	TIME [epoch: 8.85 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015583014533276391		[learning rate: 0.0014948]
		[batch 20/20] avg loss: 0.02613333795743427		[learning rate: 0.0014913]
	Learning Rate: 0.00149132
	LOSS [training: 0.020858176245355332 | validation: 0.02865993556230765]
	TIME [epoch: 8.85 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026314767199586336		[learning rate: 0.0014878]
		[batch 20/20] avg loss: 0.03208087152116494		[learning rate: 0.0014843]
	Learning Rate: 0.00148433
	LOSS [training: 0.029197819360375642 | validation: 0.031610925155680716]
	TIME [epoch: 8.88 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03041920776856123		[learning rate: 0.0014808]
		[batch 20/20] avg loss: 0.01952301117460271		[learning rate: 0.0014774]
	Learning Rate: 0.00147737
	LOSS [training: 0.02497110947158197 | validation: 0.014761501786633227]
	TIME [epoch: 8.86 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/20] avg loss: 0.025808560758785504		[learning rate: 0.0014739]
		[batch 20/20] avg loss: 0.016942118960224926		[learning rate: 0.0014704]
	Learning Rate: 0.00147045
	LOSS [training: 0.021375339859505214 | validation: 0.0238834834571933]
	TIME [epoch: 8.85 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02036408121711559		[learning rate: 0.001467]
		[batch 20/20] avg loss: 0.0373505870772768		[learning rate: 0.0014636]
	Learning Rate: 0.00146355
	LOSS [training: 0.0288573341471962 | validation: 0.03560206224298942]
	TIME [epoch: 8.85 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03327711450275321		[learning rate: 0.0014601]
		[batch 20/20] avg loss: 0.01872736629664349		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.026002240399698347 | validation: 0.027554491197811375]
	TIME [epoch: 8.87 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03243784181174239		[learning rate: 0.0014533]
		[batch 20/20] avg loss: 0.02913159997384025		[learning rate: 0.0014499]
	Learning Rate: 0.00144986
	LOSS [training: 0.030784720892791318 | validation: 0.0291940397758136]
	TIME [epoch: 8.86 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021069164977565148		[learning rate: 0.0014465]
		[batch 20/20] avg loss: 0.03526172085752151		[learning rate: 0.0014431]
	Learning Rate: 0.00144306
	LOSS [training: 0.028165442917543325 | validation: 0.05809443915837581]
	TIME [epoch: 8.86 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/20] avg loss: 0.041206271240510836		[learning rate: 0.0014397]
		[batch 20/20] avg loss: 0.01099418995132107		[learning rate: 0.0014363]
	Learning Rate: 0.0014363
	LOSS [training: 0.026100230595915958 | validation: 0.012124280535197828]
	TIME [epoch: 8.85 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02253267997015988		[learning rate: 0.0014329]
		[batch 20/20] avg loss: 0.021313487271149182		[learning rate: 0.0014296]
	Learning Rate: 0.00142957
	LOSS [training: 0.02192308362065453 | validation: 0.018073555698301012]
	TIME [epoch: 8.85 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03238889615405356		[learning rate: 0.0014262]
		[batch 20/20] avg loss: 0.023875279245453233		[learning rate: 0.0014229]
	Learning Rate: 0.00142286
	LOSS [training: 0.0281320876997534 | validation: 0.026562778799785136]
	TIME [epoch: 8.87 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030417182590097302		[learning rate: 0.0014195]
		[batch 20/20] avg loss: 0.021301458732901894		[learning rate: 0.0014162]
	Learning Rate: 0.00141619
	LOSS [training: 0.025859320661499596 | validation: 0.01971173581837767]
	TIME [epoch: 8.85 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011821050207467938		[learning rate: 0.0014129]
		[batch 20/20] avg loss: 0.034477539229982444		[learning rate: 0.0014096]
	Learning Rate: 0.00140955
	LOSS [training: 0.023149294718725195 | validation: 0.020013141836407497]
	TIME [epoch: 8.85 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/20] avg loss: 0.042755054987400246		[learning rate: 0.0014062]
		[batch 20/20] avg loss: 0.017998372452074717		[learning rate: 0.0014029]
	Learning Rate: 0.00140295
	LOSS [training: 0.030376713719737474 | validation: 0.01345092929967074]
	TIME [epoch: 8.85 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/20] avg loss: 0.021124405598974907		[learning rate: 0.0013997]
		[batch 20/20] avg loss: 0.05462166617050037		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.03787303588473764 | validation: 0.06544920379665473]
	TIME [epoch: 8.86 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05385773793939963		[learning rate: 0.0013931]
		[batch 20/20] avg loss: 0.03589150058562422		[learning rate: 0.0013898]
	Learning Rate: 0.00138982
	LOSS [training: 0.04487461926251193 | validation: 0.03315254039056219]
	TIME [epoch: 8.88 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/20] avg loss: 0.019187111186290202		[learning rate: 0.0013866]
		[batch 20/20] avg loss: 0.01996437378532612		[learning rate: 0.0013833]
	Learning Rate: 0.00138331
	LOSS [training: 0.019575742485808158 | validation: 0.04042426986304795]
	TIME [epoch: 8.86 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029158415488358097		[learning rate: 0.0013801]
		[batch 20/20] avg loss: 0.015193940338683936		[learning rate: 0.0013768]
	Learning Rate: 0.00137682
	LOSS [training: 0.022176177913521018 | validation: 0.039195597020843576]
	TIME [epoch: 8.85 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/20] avg loss: 0.022550450003532698		[learning rate: 0.0013736]
		[batch 20/20] avg loss: 0.013036080434069921		[learning rate: 0.0013704]
	Learning Rate: 0.00137037
	LOSS [training: 0.01779326521880131 | validation: 0.009123109657714741]
	TIME [epoch: 8.85 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012690098312093067		[learning rate: 0.0013672]
		[batch 20/20] avg loss: 0.019118736877450433		[learning rate: 0.0013639]
	Learning Rate: 0.00136394
	LOSS [training: 0.015904417594771753 | validation: 0.0239358952059408]
	TIME [epoch: 8.86 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01618827811014286		[learning rate: 0.0013607]
		[batch 20/20] avg loss: 0.020392900286422804		[learning rate: 0.0013575]
	Learning Rate: 0.00135755
	LOSS [training: 0.018290589198282838 | validation: 0.017807665119640208]
	TIME [epoch: 8.88 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01674670694712141		[learning rate: 0.0013544]
		[batch 20/20] avg loss: 0.02936299913558637		[learning rate: 0.0013512]
	Learning Rate: 0.00135118
	LOSS [training: 0.023054853041353886 | validation: 0.01995749141085599]
	TIME [epoch: 8.86 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02828659315173162		[learning rate: 0.001348]
		[batch 20/20] avg loss: 0.021361849888665744		[learning rate: 0.0013448]
	Learning Rate: 0.00134485
	LOSS [training: 0.024824221520198687 | validation: 0.018008747000717366]
	TIME [epoch: 8.86 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028554294540991565		[learning rate: 0.0013417]
		[batch 20/20] avg loss: 0.023984900126252102		[learning rate: 0.0013385]
	Learning Rate: 0.00133854
	LOSS [training: 0.026269597333621837 | validation: 0.03922497971462532]
	TIME [epoch: 8.85 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020946987564313825		[learning rate: 0.0013354]
		[batch 20/20] avg loss: 0.03377222269643005		[learning rate: 0.0013323]
	Learning Rate: 0.00133227
	LOSS [training: 0.027359605130371938 | validation: 0.01776189522199027]
	TIME [epoch: 8.88 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018887362444321855		[learning rate: 0.0013291]
		[batch 20/20] avg loss: 0.018254683256272202		[learning rate: 0.001326]
	Learning Rate: 0.00132602
	LOSS [training: 0.018571022850297027 | validation: 0.02093131861585118]
	TIME [epoch: 8.86 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017739556073027248		[learning rate: 0.0013229]
		[batch 20/20] avg loss: 0.019351453486941624		[learning rate: 0.0013198]
	Learning Rate: 0.00131981
	LOSS [training: 0.018545504779984436 | validation: 0.021252901613530228]
	TIME [epoch: 8.86 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01663546219463796		[learning rate: 0.0013167]
		[batch 20/20] avg loss: 0.02641063773781701		[learning rate: 0.0013136]
	Learning Rate: 0.00131362
	LOSS [training: 0.021523049966227482 | validation: 0.020653101151729355]
	TIME [epoch: 8.85 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017960245980762662		[learning rate: 0.0013105]
		[batch 20/20] avg loss: 0.023020220160616528		[learning rate: 0.0013075]
	Learning Rate: 0.00130746
	LOSS [training: 0.020490233070689597 | validation: 0.019670461473092232]
	TIME [epoch: 8.86 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017739006546689324		[learning rate: 0.0013044]
		[batch 20/20] avg loss: 0.011089829123943382		[learning rate: 0.0013013]
	Learning Rate: 0.00130133
	LOSS [training: 0.014414417835316353 | validation: 0.019535656305479314]
	TIME [epoch: 8.88 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018039869557976356		[learning rate: 0.0012983]
		[batch 20/20] avg loss: 0.028201344507836117		[learning rate: 0.0012952]
	Learning Rate: 0.00129523
	LOSS [training: 0.023120607032906235 | validation: 0.024468270764682477]
	TIME [epoch: 8.86 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015441338762919999		[learning rate: 0.0012922]
		[batch 20/20] avg loss: 0.010490989662116822		[learning rate: 0.0012892]
	Learning Rate: 0.00128916
	LOSS [training: 0.012966164212518411 | validation: 0.021344520822883014]
	TIME [epoch: 8.86 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029981156468601482		[learning rate: 0.0012861]
		[batch 20/20] avg loss: 0.03807119759513884		[learning rate: 0.0012831]
	Learning Rate: 0.00128311
	LOSS [training: 0.034026177031870164 | validation: 0.08476905315170688]
	TIME [epoch: 8.86 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03234244159668777		[learning rate: 0.0012801]
		[batch 20/20] avg loss: 0.01574846760388695		[learning rate: 0.0012771]
	Learning Rate: 0.0012771
	LOSS [training: 0.02404545460028736 | validation: 0.03932998896462369]
	TIME [epoch: 8.86 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023414540351484894		[learning rate: 0.0012741]
		[batch 20/20] avg loss: 0.008471139596229135		[learning rate: 0.0012711]
	Learning Rate: 0.00127111
	LOSS [training: 0.015942839973857013 | validation: 0.016581587725727383]
	TIME [epoch: 8.89 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0156552585202965		[learning rate: 0.0012681]
		[batch 20/20] avg loss: 0.016748663569934905		[learning rate: 0.0012652]
	Learning Rate: 0.00126515
	LOSS [training: 0.0162019610451157 | validation: 0.01701944545989144]
	TIME [epoch: 8.86 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018889938259994073		[learning rate: 0.0012622]
		[batch 20/20] avg loss: 0.011265981128753513		[learning rate: 0.0012592]
	Learning Rate: 0.00125922
	LOSS [training: 0.015077959694373791 | validation: 0.029655859912339263]
	TIME [epoch: 8.87 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02863342005985789		[learning rate: 0.0012563]
		[batch 20/20] avg loss: 0.04161864539328486		[learning rate: 0.0012533]
	Learning Rate: 0.00125332
	LOSS [training: 0.035126032726571374 | validation: 0.04912531810703722]
	TIME [epoch: 8.86 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01681101266918738		[learning rate: 0.0012504]
		[batch 20/20] avg loss: 0.023022165760081127		[learning rate: 0.0012474]
	Learning Rate: 0.00124744
	LOSS [training: 0.019916589214634253 | validation: 0.020703732326744592]
	TIME [epoch: 8.89 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/20] avg loss: 0.00905852522585874		[learning rate: 0.0012445]
		[batch 20/20] avg loss: 0.015287276686075085		[learning rate: 0.0012416]
	Learning Rate: 0.00124159
	LOSS [training: 0.012172900955966907 | validation: 0.03373768512308519]
	TIME [epoch: 8.87 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/20] avg loss: 0.026609531940492988		[learning rate: 0.0012387]
		[batch 20/20] avg loss: 0.014405678057086199		[learning rate: 0.0012358]
	Learning Rate: 0.00123577
	LOSS [training: 0.02050760499878959 | validation: 0.014429256709288664]
	TIME [epoch: 8.87 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/20] avg loss: 0.014552452390127823		[learning rate: 0.0012329]
		[batch 20/20] avg loss: 0.017958162845800013		[learning rate: 0.00123]
	Learning Rate: 0.00122998
	LOSS [training: 0.016255307617963916 | validation: 0.03160024855590095]
	TIME [epoch: 8.87 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018792583339635047		[learning rate: 0.0012271]
		[batch 20/20] avg loss: 0.012438255949082709		[learning rate: 0.0012242]
	Learning Rate: 0.00122421
	LOSS [training: 0.015615419644358874 | validation: 0.024453351770832195]
	TIME [epoch: 8.86 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0198662382555848		[learning rate: 0.0012213]
		[batch 20/20] avg loss: 0.02422840865561282		[learning rate: 0.0012185]
	Learning Rate: 0.00121847
	LOSS [training: 0.022047323455598816 | validation: 0.0342438209712256]
	TIME [epoch: 8.89 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017895805813946015		[learning rate: 0.0012156]
		[batch 20/20] avg loss: 0.024062064350406812		[learning rate: 0.0012128]
	Learning Rate: 0.00121276
	LOSS [training: 0.020978935082176416 | validation: 0.04167092458144296]
	TIME [epoch: 8.87 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03096283298516391		[learning rate: 0.0012099]
		[batch 20/20] avg loss: 0.02370736129731921		[learning rate: 0.0012071]
	Learning Rate: 0.00120708
	LOSS [training: 0.027335097141241556 | validation: 0.028544333708317108]
	TIME [epoch: 8.87 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017819272395565126		[learning rate: 0.0012042]
		[batch 20/20] avg loss: 0.01442954297973834		[learning rate: 0.0012014]
	Learning Rate: 0.00120142
	LOSS [training: 0.016124407687651734 | validation: 0.014899996509666712]
	TIME [epoch: 8.87 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/20] avg loss: 0.016575712382952426		[learning rate: 0.0011986]
		[batch 20/20] avg loss: 0.010724538278383346		[learning rate: 0.0011958]
	Learning Rate: 0.00119578
	LOSS [training: 0.013650125330667886 | validation: 0.020553582513402578]
	TIME [epoch: 8.87 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010413126161627932		[learning rate: 0.001193]
		[batch 20/20] avg loss: 0.007412740693280831		[learning rate: 0.0011902]
	Learning Rate: 0.00119018
	LOSS [training: 0.008912933427454379 | validation: 0.013411038942954003]
	TIME [epoch: 8.89 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01843211194999719		[learning rate: 0.0011874]
		[batch 20/20] avg loss: 0.009651581033147586		[learning rate: 0.0011846]
	Learning Rate: 0.0011846
	LOSS [training: 0.014041846491572387 | validation: 0.022780652244003115]
	TIME [epoch: 8.87 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/20] avg loss: 0.019117217697179244		[learning rate: 0.0011818]
		[batch 20/20] avg loss: 0.019656049233133778		[learning rate: 0.001179]
	Learning Rate: 0.00117905
	LOSS [training: 0.01938663346515651 | validation: 0.01991892122282305]
	TIME [epoch: 8.87 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017710750335690688		[learning rate: 0.0011763]
		[batch 20/20] avg loss: 0.018924018938129804		[learning rate: 0.0011735]
	Learning Rate: 0.00117352
	LOSS [training: 0.018317384636910246 | validation: 0.0263860089921061]
	TIME [epoch: 8.87 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028756591258715415		[learning rate: 0.0011708]
		[batch 20/20] avg loss: 0.03258294764172017		[learning rate: 0.001168]
	Learning Rate: 0.00116802
	LOSS [training: 0.030669769450217786 | validation: 0.03802483673342786]
	TIME [epoch: 8.88 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/20] avg loss: 0.028521356642331595		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.045791200370412295		[learning rate: 0.0011625]
	Learning Rate: 0.00116254
	LOSS [training: 0.037156278506371945 | validation: 0.019750417059318005]
	TIME [epoch: 8.88 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/20] avg loss: 0.016177404544719005		[learning rate: 0.0011598]
		[batch 20/20] avg loss: 0.023890541839683543		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.020033973192201272 | validation: 0.02674694081716348]
	TIME [epoch: 8.86 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/20] avg loss: 0.029444760554272066		[learning rate: 0.0011544]
		[batch 20/20] avg loss: 0.04723753132911823		[learning rate: 0.0011517]
	Learning Rate: 0.00115167
	LOSS [training: 0.038341145941695146 | validation: 0.027106218151314504]
	TIME [epoch: 8.87 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018038188777294843		[learning rate: 0.001149]
		[batch 20/20] avg loss: 0.022948858020439097		[learning rate: 0.0011463]
	Learning Rate: 0.00114627
	LOSS [training: 0.02049352339886697 | validation: 0.04407656284901425]
	TIME [epoch: 8.86 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02337504985471185		[learning rate: 0.0011436]
		[batch 20/20] avg loss: 0.017941147708895787		[learning rate: 0.0011409]
	Learning Rate: 0.00114089
	LOSS [training: 0.02065809878180382 | validation: 0.0347535501217783]
	TIME [epoch: 8.88 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/20] avg loss: 0.018406946811684158		[learning rate: 0.0011382]
		[batch 20/20] avg loss: 0.01842771955056597		[learning rate: 0.0011355]
	Learning Rate: 0.00113554
	LOSS [training: 0.018417333181125064 | validation: 0.01455339912355689]
	TIME [epoch: 8.87 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/20] avg loss: 0.009940786875361544		[learning rate: 0.0011329]
		[batch 20/20] avg loss: 0.010941762889058026		[learning rate: 0.0011302]
	Learning Rate: 0.00113022
	LOSS [training: 0.010441274882209785 | validation: 0.013357013602716185]
	TIME [epoch: 8.86 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023318715608183754		[learning rate: 0.0011276]
		[batch 20/20] avg loss: 0.02177395181563109		[learning rate: 0.0011249]
	Learning Rate: 0.00112492
	LOSS [training: 0.022546333711907417 | validation: 0.029947682718186555]
	TIME [epoch: 8.86 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020899053542509385		[learning rate: 0.0011223]
		[batch 20/20] avg loss: 0.02339921309393216		[learning rate: 0.0011196]
	Learning Rate: 0.00111965
	LOSS [training: 0.02214913331822077 | validation: 0.01338860306210897]
	TIME [epoch: 8.86 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015549359499902705		[learning rate: 0.001117]
		[batch 20/20] avg loss: 0.013978164108753804		[learning rate: 0.0011144]
	Learning Rate: 0.0011144
	LOSS [training: 0.014763761804328257 | validation: 0.012082877894170223]
	TIME [epoch: 8.88 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/20] avg loss: 0.017922167784517135		[learning rate: 0.0011118]
		[batch 20/20] avg loss: 0.021574795978880422		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.019748481881698778 | validation: 0.0215062405077193]
	TIME [epoch: 8.87 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02184897523493145		[learning rate: 0.0011066]
		[batch 20/20] avg loss: 0.011493651553481796		[learning rate: 0.001104]
	Learning Rate: 0.00110397
	LOSS [training: 0.016671313394206626 | validation: 0.01521280398995336]
	TIME [epoch: 8.86 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/20] avg loss: 0.01179640051589019		[learning rate: 0.0011014]
		[batch 20/20] avg loss: 0.0173632169461573		[learning rate: 0.0010988]
	Learning Rate: 0.0010988
	LOSS [training: 0.014579808731023745 | validation: 0.026408015263360417]
	TIME [epoch: 8.87 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02045520377816976		[learning rate: 0.0010962]
		[batch 20/20] avg loss: 0.010755663224483045		[learning rate: 0.0010936]
	Learning Rate: 0.00109365
	LOSS [training: 0.015605433501326402 | validation: 0.010140767108437228]
	TIME [epoch: 8.87 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013265787992797543		[learning rate: 0.0010911]
		[batch 20/20] avg loss: 0.015495725720499842		[learning rate: 0.0010885]
	Learning Rate: 0.00108852
	LOSS [training: 0.014380756856648691 | validation: 0.020717069756232536]
	TIME [epoch: 8.89 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/20] avg loss: 0.009877432037548385		[learning rate: 0.001086]
		[batch 20/20] avg loss: 0.018965028513497923		[learning rate: 0.0010834]
	Learning Rate: 0.00108342
	LOSS [training: 0.014421230275523153 | validation: 0.016818492831963707]
	TIME [epoch: 8.87 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/20] avg loss: 0.023226675783116074		[learning rate: 0.0010809]
		[batch 20/20] avg loss: 0.02937050769698473		[learning rate: 0.0010783]
	Learning Rate: 0.00107834
	LOSS [training: 0.026298591740050403 | validation: 0.026065053702971644]
	TIME [epoch: 8.86 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/20] avg loss: 0.02230686346429355		[learning rate: 0.0010758]
		[batch 20/20] avg loss: 0.028198697968635937		[learning rate: 0.0010733]
	Learning Rate: 0.00107328
	LOSS [training: 0.02525278071646475 | validation: 0.03733856298985929]
	TIME [epoch: 8.87 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/20] avg loss: 0.030654042258938703		[learning rate: 0.0010708]
		[batch 20/20] avg loss: 0.015462596145707969		[learning rate: 0.0010683]
	Learning Rate: 0.00106825
	LOSS [training: 0.023058319202323336 | validation: 0.01807273162763744]
	TIME [epoch: 8.88 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013888273719160913		[learning rate: 0.0010657]
		[batch 20/20] avg loss: 0.010092125083065544		[learning rate: 0.0010632]
	Learning Rate: 0.00106324
	LOSS [training: 0.011990199401113231 | validation: 0.01119728605847399]
	TIME [epoch: 8.86 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010296899650825902		[learning rate: 0.0010607]
		[batch 20/20] avg loss: 0.01294691454763389		[learning rate: 0.0010583]
	Learning Rate: 0.00105826
	LOSS [training: 0.011621907099229894 | validation: 0.011991053712870946]
	TIME [epoch: 8.86 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/20] avg loss: 0.013831640563519312		[learning rate: 0.0010558]
		[batch 20/20] avg loss: 0.015956092279926965		[learning rate: 0.0010533]
	Learning Rate: 0.0010533
	LOSS [training: 0.014893866421723138 | validation: 0.03572147885002683]
	TIME [epoch: 8.86 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010554853226912879		[learning rate: 0.0010508]
		[batch 20/20] avg loss: 0.026800335889241626		[learning rate: 0.0010484]
	Learning Rate: 0.00104836
	LOSS [training: 0.018677594558077253 | validation: 0.02055109053141832]
	TIME [epoch: 8.86 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/20] avg loss: 0.004831494643081757		[learning rate: 0.0010459]
		[batch 20/20] avg loss: 0.017287094453799758		[learning rate: 0.0010434]
	Learning Rate: 0.00104344
	LOSS [training: 0.011059294548440757 | validation: 0.014302777218173975]
	TIME [epoch: 8.88 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015752641021699466		[learning rate: 0.001041]
		[batch 20/20] avg loss: 0.01947650955699683		[learning rate: 0.0010386]
	Learning Rate: 0.00103855
	LOSS [training: 0.017614575289348153 | validation: 0.023072716400996205]
	TIME [epoch: 8.86 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/20] avg loss: 0.027872899082680213		[learning rate: 0.0010361]
		[batch 20/20] avg loss: 0.01292111840416354		[learning rate: 0.0010337]
	Learning Rate: 0.00103368
	LOSS [training: 0.020397008743421877 | validation: 0.022991387918024977]
	TIME [epoch: 8.85 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/20] avg loss: 0.012931838171262694		[learning rate: 0.0010313]
		[batch 20/20] avg loss: 0.030678903813996416		[learning rate: 0.0010288]
	Learning Rate: 0.00102884
	LOSS [training: 0.021805370992629552 | validation: 0.025250687876391308]
	TIME [epoch: 8.85 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/20] avg loss: 0.03137693724435593		[learning rate: 0.0010264]
		[batch 20/20] avg loss: 0.014856069510757635		[learning rate: 0.001024]
	Learning Rate: 0.00102401
	LOSS [training: 0.02311650337755678 | validation: 0.024143635103194155]
	TIME [epoch: 8.85 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015501762976376477		[learning rate: 0.0010216]
		[batch 20/20] avg loss: 0.03704048747264281		[learning rate: 0.0010192]
	Learning Rate: 0.00101921
	LOSS [training: 0.026271125224509646 | validation: 0.009912397447061794]
	TIME [epoch: 8.87 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/20] avg loss: 0.015807554296480893		[learning rate: 0.0010168]
		[batch 20/20] avg loss: 0.013956040638854358		[learning rate: 0.0010144]
	Learning Rate: 0.00101444
	LOSS [training: 0.014881797467667626 | validation: 0.01911379761509592]
	TIME [epoch: 8.85 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/20] avg loss: 0.020055438762534333		[learning rate: 0.0010121]
		[batch 20/20] avg loss: 0.021320643698703505		[learning rate: 0.0010097]
	Learning Rate: 0.00100968
	LOSS [training: 0.02068804123061892 | validation: 0.016265791109132975]
	TIME [epoch: 8.85 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/20] avg loss: 0.010123611145510476		[learning rate: 0.0010073]
		[batch 20/20] avg loss: 0.018944861113575885		[learning rate: 0.0010049]
	Learning Rate: 0.00100495
	LOSS [training: 0.014534236129543182 | validation: 0.020833661339212585]
	TIME [epoch: 8.85 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/20] avg loss: 0.011290656447989182		[learning rate: 0.0010026]
		[batch 20/20] avg loss: 0.028421565717947194		[learning rate: 0.0010002]
	Learning Rate: 0.00100023
	LOSS [training: 0.01985611108296819 | validation: 0.02564654770530906]
	TIME [epoch: 8.86 sec]
Finished training in 4500.104 seconds.
