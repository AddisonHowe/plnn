Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r5', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3507471147

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.851726049423411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.851726049423411 | validation: 6.290708371500216]
	TIME [epoch: 95 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.57507667830527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.57507667830527 | validation: 4.879253584517421]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.07571119048101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.07571119048101 | validation: 3.2362137091731507]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2959494507721416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2959494507721416 | validation: 3.7664972318607957]
	TIME [epoch: 5.73 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1156760140290194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1156760140290194 | validation: 2.5651406172148596]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0208754706521104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0208754706521104 | validation: 2.4718594260801514]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8401635774605936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8401635774605936 | validation: 2.451164968916694]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.714314857308343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.714314857308343 | validation: 2.6790367765520124]
	TIME [epoch: 5.77 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1634012688761994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1634012688761994 | validation: 2.599182984500499]
	TIME [epoch: 5.72 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.436930206087651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.436930206087651 | validation: 1.906408441646559]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.378009078874002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.378009078874002 | validation: 2.5239965167475273]
	TIME [epoch: 5.73 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.50375106115913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.50375106115913 | validation: 2.164982302037789]
	TIME [epoch: 5.71 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1891234581611263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1891234581611263 | validation: 1.7191616973340178]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1752150639507315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1752150639507315 | validation: 2.1820521965251944]
	TIME [epoch: 5.73 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292610474231893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.292610474231893 | validation: 2.6950773107398613]
	TIME [epoch: 5.77 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2128685700838093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2128685700838093 | validation: 1.397663752187878]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7659344971167812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7659344971167812 | validation: 1.5294710535851388]
	TIME [epoch: 5.72 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.818632797433984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.818632797433984 | validation: 1.685389936623681]
	TIME [epoch: 5.72 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.865550101630555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.865550101630555 | validation: 2.163929554914886]
	TIME [epoch: 5.72 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8444211027855482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8444211027855482 | validation: 5.7664544050147155]
	TIME [epoch: 5.71 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6978436177719614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6978436177719614 | validation: 1.5749904216956139]
	TIME [epoch: 5.73 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6995679708741513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6995679708741513 | validation: 2.4279827863367105]
	TIME [epoch: 5.76 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.720465086631697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.720465086631697 | validation: 1.2776529676652275]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6432642800050523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6432642800050523 | validation: 1.1184072278421568]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.586126807931791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.586126807931791 | validation: 1.0346360723984478]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4935093089553586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4935093089553586 | validation: 1.094536353195449]
	TIME [epoch: 5.71 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.612049835461116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.612049835461116 | validation: 1.437460320444783]
	TIME [epoch: 5.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9877510835569427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9877510835569427 | validation: 1.3330454692930374]
	TIME [epoch: 5.75 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6046645045739771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6046645045739771 | validation: 1.0180123401108734]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.423448222365756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.423448222365756 | validation: 1.0418855780455638]
	TIME [epoch: 5.71 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4061185581323599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4061185581323599 | validation: 0.8892121493845332]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2956442662339993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2956442662339993 | validation: 0.8735621103683368]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1249640046526603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1249640046526603 | validation: 1.217845666009007]
	TIME [epoch: 5.71 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3143884760001878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3143884760001878 | validation: 0.8908848568588298]
	TIME [epoch: 5.74 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9911848962197698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9911848962197698 | validation: 1.873408020268264]
	TIME [epoch: 5.75 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9336613746877211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9336613746877211 | validation: 1.3615502922004834]
	TIME [epoch: 5.71 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4878800346515941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4878800346515941 | validation: 2.4202431524163415]
	TIME [epoch: 5.71 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.444028220855156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.444028220855156 | validation: 0.8900115705911287]
	TIME [epoch: 5.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2526711666943031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2526711666943031 | validation: 0.8449769126242009]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028150180847193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.028150180847193 | validation: 0.7170852686427308]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0385920904789596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0385920904789596 | validation: 0.7405058569529291]
	TIME [epoch: 5.74 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0732096106645637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0732096106645637 | validation: 0.7840400141944724]
	TIME [epoch: 5.74 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9470592223515995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9470592223515995 | validation: 0.9183189915413251]
	TIME [epoch: 5.72 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.636531193382725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.636531193382725 | validation: 2.2140401863705934]
	TIME [epoch: 5.71 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358454045422734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.358454045422734 | validation: 1.600267573923501]
	TIME [epoch: 5.71 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.151571275467615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.151571275467615 | validation: 1.2941689082749046]
	TIME [epoch: 5.71 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0439307109632827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0439307109632827 | validation: 0.6951056751125992]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8671530943422168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8671530943422168 | validation: 0.5684674021393553]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8469032719939769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8469032719939769 | validation: 1.3539277248510848]
	TIME [epoch: 5.72 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9364712550429635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9364712550429635 | validation: 0.5706822498910085]
	TIME [epoch: 5.73 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.308803912723967		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.308803912723967 | validation: 1.9271896854474342]
	TIME [epoch: 5.73 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1162531179867594		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.1162531179867594 | validation: 0.7081672849865117]
	TIME [epoch: 5.73 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7740142603290279		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.7740142603290279 | validation: 0.6497742249054318]
	TIME [epoch: 5.73 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7959704570832977		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.7959704570832977 | validation: 0.7700503285529857]
	TIME [epoch: 5.72 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7335464413641343		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.7335464413641343 | validation: 0.6411394646189157]
	TIME [epoch: 5.77 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8355893246532353		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.8355893246532353 | validation: 0.5143382252839589]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175586178802702		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.7175586178802702 | validation: 0.5327340535654406]
	TIME [epoch: 5.73 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9696310885733582		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.9696310885733582 | validation: 0.6163618569411251]
	TIME [epoch: 5.73 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7730432639870823		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.7730432639870823 | validation: 0.48335463736132567]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7496166463329037		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.7496166463329037 | validation: 0.48626548378748935]
	TIME [epoch: 5.73 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647329733448875		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.5647329733448875 | validation: 0.4318014935930898]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.77724702573052		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.77724702573052 | validation: 0.6032164850037828]
	TIME [epoch: 5.74 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5878596732692505		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.5878596732692505 | validation: 1.0650828019428797]
	TIME [epoch: 5.71 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69784715554457		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.69784715554457 | validation: 0.4448137945784095]
	TIME [epoch: 5.71 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5556183520760365		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.5556183520760365 | validation: 0.473865951596263]
	TIME [epoch: 5.72 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6175799899725509		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.6175799899725509 | validation: 0.38603409403834194]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555428424813314		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.555428424813314 | validation: 0.45904630900433857]
	TIME [epoch: 5.73 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6025359266049899		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.6025359266049899 | validation: 0.9157198056014277]
	TIME [epoch: 5.75 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7714359598756593		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.7714359598756593 | validation: 0.63332694468313]
	TIME [epoch: 5.72 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6714942637150226		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.6714942637150226 | validation: 0.45837718061884886]
	TIME [epoch: 5.72 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5630426295083223		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.5630426295083223 | validation: 0.5825649364563887]
	TIME [epoch: 5.71 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5332507186280072		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.5332507186280072 | validation: 0.6844069009760255]
	TIME [epoch: 5.71 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7584757197264363		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.7584757197264363 | validation: 0.4308769038250073]
	TIME [epoch: 5.72 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5779875941031004		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.5779875941031004 | validation: 0.510555690213654]
	TIME [epoch: 5.75 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5380469426346677		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.5380469426346677 | validation: 0.7566784761747483]
	TIME [epoch: 5.73 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686156663283735		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.686156663283735 | validation: 0.41071196313167163]
	TIME [epoch: 5.72 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6077925411815353		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.6077925411815353 | validation: 0.5254616335958875]
	TIME [epoch: 5.71 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5716855251960835		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.5716855251960835 | validation: 0.6599402080050782]
	TIME [epoch: 5.71 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8140672442616368		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.8140672442616368 | validation: 0.5917046471656485]
	TIME [epoch: 5.71 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6928053563649769		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.6928053563649769 | validation: 0.5028250620831176]
	TIME [epoch: 5.71 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5373124401370153		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5373124401370153 | validation: 0.556010733821784]
	TIME [epoch: 5.76 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6121940933139032		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6121940933139032 | validation: 0.5574204750311277]
	TIME [epoch: 5.72 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5380739409858337		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.5380739409858337 | validation: 0.5601441683976667]
	TIME [epoch: 5.72 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49583808474944585		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.49583808474944585 | validation: 0.6061221713402698]
	TIME [epoch: 5.71 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5935283753859526		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.5935283753859526 | validation: 0.418312933844162]
	TIME [epoch: 5.72 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5306189307335929		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.5306189307335929 | validation: 0.5481842017949603]
	TIME [epoch: 5.71 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.631245650291262		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.631245650291262 | validation: 0.5042880788832644]
	TIME [epoch: 5.74 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5116695938248789		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.5116695938248789 | validation: 0.5813807330124986]
	TIME [epoch: 5.73 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148887951690099		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.7148887951690099 | validation: 0.6268600644392985]
	TIME [epoch: 5.71 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5064308374071692		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.5064308374071692 | validation: 0.5971947711547618]
	TIME [epoch: 5.72 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088986859381169		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.5088986859381169 | validation: 0.7290607687563424]
	TIME [epoch: 5.72 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4322062680352916		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.4322062680352916 | validation: 0.5243250184354048]
	TIME [epoch: 5.72 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4491163165556614		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.4491163165556614 | validation: 0.7324143545526846]
	TIME [epoch: 5.72 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6123125109509227		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.6123125109509227 | validation: 0.6604981128404083]
	TIME [epoch: 5.76 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5622364175159413		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.5622364175159413 | validation: 0.4328587921771052]
	TIME [epoch: 5.72 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41042906995240136		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.41042906995240136 | validation: 0.4460994555867916]
	TIME [epoch: 5.71 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4956856360493414		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.4956856360493414 | validation: 0.3278190588801742]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4428353143559194		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.4428353143559194 | validation: 0.6006158185155808]
	TIME [epoch: 5.73 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7162131628884749		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.7162131628884749 | validation: 1.037106284631091]
	TIME [epoch: 5.73 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158243183742578		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.5158243183742578 | validation: 0.5570591716569532]
	TIME [epoch: 5.75 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43516011231515483		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.43516011231515483 | validation: 0.5411316903360214]
	TIME [epoch: 5.74 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7523774026196173		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.7523774026196173 | validation: 0.5691210944913284]
	TIME [epoch: 5.72 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.60370462075827		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.60370462075827 | validation: 0.8553136090277418]
	TIME [epoch: 5.72 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42191236159653656		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.42191236159653656 | validation: 0.519460140457778]
	TIME [epoch: 5.71 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5262403821258348		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.5262403821258348 | validation: 0.7636699319103277]
	TIME [epoch: 5.72 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5632290248319072		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.5632290248319072 | validation: 0.5080037122523817]
	TIME [epoch: 5.73 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43760067483597453		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.43760067483597453 | validation: 0.4528975382451876]
	TIME [epoch: 5.77 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4252870172687346		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.4252870172687346 | validation: 1.14548535251301]
	TIME [epoch: 5.72 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5489003778776361		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.5489003778776361 | validation: 0.4581146329451281]
	TIME [epoch: 5.71 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5183104562022838		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.5183104562022838 | validation: 0.4515120522292042]
	TIME [epoch: 5.72 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5152237540743543		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.5152237540743543 | validation: 0.4306428215885056]
	TIME [epoch: 5.71 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39967699598891526		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.39967699598891526 | validation: 0.6559119614929989]
	TIME [epoch: 5.71 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6577497969583307		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.6577497969583307 | validation: 0.3761790136792593]
	TIME [epoch: 5.75 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40912348983186025		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.40912348983186025 | validation: 0.3895353448858009]
	TIME [epoch: 5.73 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151222660880135		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.4151222660880135 | validation: 0.6167517600131646]
	TIME [epoch: 5.72 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4846206077083032		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.4846206077083032 | validation: 0.43941123854147035]
	TIME [epoch: 5.72 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46940016050608996		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.46940016050608996 | validation: 0.5108645446302472]
	TIME [epoch: 5.72 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42655192984757184		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.42655192984757184 | validation: 0.4301090748029456]
	TIME [epoch: 5.72 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40138285393329093		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.40138285393329093 | validation: 0.39533366995150054]
	TIME [epoch: 5.73 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4391720766326688		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.4391720766326688 | validation: 0.3509057114402506]
	TIME [epoch: 5.77 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4334406954712757		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.4334406954712757 | validation: 0.5079771743936315]
	TIME [epoch: 5.71 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48132415771998793		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.48132415771998793 | validation: 0.3915388677883037]
	TIME [epoch: 5.71 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239895929126946		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.6239895929126946 | validation: 0.4333015359339054]
	TIME [epoch: 5.72 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40384452542417815		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.40384452542417815 | validation: 0.3593551588141068]
	TIME [epoch: 5.72 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46698412539793854		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.46698412539793854 | validation: 0.5586661095777464]
	TIME [epoch: 5.72 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43324088501039215		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.43324088501039215 | validation: 0.3679254924349036]
	TIME [epoch: 5.74 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35673741409280857		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.35673741409280857 | validation: 0.30766966548959984]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36861478390394053		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.36861478390394053 | validation: 0.3883765895348348]
	TIME [epoch: 5.72 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9332571317128182		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.9332571317128182 | validation: 0.5677362871972979]
	TIME [epoch: 5.72 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6213053441389986		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.6213053441389986 | validation: 0.4038003511519919]
	TIME [epoch: 5.71 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47389852546197314		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.47389852546197314 | validation: 0.43782598325781635]
	TIME [epoch: 5.73 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4565502782449885		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.4565502782449885 | validation: 0.42298421219828564]
	TIME [epoch: 5.72 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570122264192056		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.3570122264192056 | validation: 0.46825982538370214]
	TIME [epoch: 5.77 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528568812688412		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.4528568812688412 | validation: 0.30902855371000576]
	TIME [epoch: 5.72 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35868044082445516		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.35868044082445516 | validation: 0.37518611648396616]
	TIME [epoch: 5.71 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3567386253983688		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.3567386253983688 | validation: 0.4882219003285683]
	TIME [epoch: 5.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.370372312832267		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.370372312832267 | validation: 0.41465403869536815]
	TIME [epoch: 5.71 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3643411797080515		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.3643411797080515 | validation: 0.3651434598888271]
	TIME [epoch: 5.72 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42171309561557574		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.42171309561557574 | validation: 0.37758224415673947]
	TIME [epoch: 5.74 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36937553153333225		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.36937553153333225 | validation: 0.5015135104092598]
	TIME [epoch: 5.74 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4217223716767333		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.4217223716767333 | validation: 0.3785813698948673]
	TIME [epoch: 5.73 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333465389519948		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.333465389519948 | validation: 0.3865954107250799]
	TIME [epoch: 5.71 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41314909176480746		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.41314909176480746 | validation: 0.34094735026031386]
	TIME [epoch: 5.72 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33049950611715		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.33049950611715 | validation: 0.42070636643250725]
	TIME [epoch: 5.72 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3846853780094056		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.3846853780094056 | validation: 0.3481454923148675]
	TIME [epoch: 5.71 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475086803497954		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.3475086803497954 | validation: 0.34748761873869854]
	TIME [epoch: 5.76 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5518516150756148		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.5518516150756148 | validation: 0.4043677471300967]
	TIME [epoch: 5.71 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40109145758270554		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.40109145758270554 | validation: 0.4355283559021051]
	TIME [epoch: 5.71 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367076307723698		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.4367076307723698 | validation: 0.4034813384637435]
	TIME [epoch: 5.72 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112484468440581		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.5112484468440581 | validation: 0.3115116655886563]
	TIME [epoch: 5.72 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31948145801638295		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.31948145801638295 | validation: 0.5532907908273957]
	TIME [epoch: 5.71 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336466154570492		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.5336466154570492 | validation: 0.401602732824386]
	TIME [epoch: 5.74 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3291687723746422		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.3291687723746422 | validation: 0.39013882313915055]
	TIME [epoch: 5.73 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30718464003421664		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.30718464003421664 | validation: 0.32282484538580447]
	TIME [epoch: 5.72 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43120434197926005		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.43120434197926005 | validation: 0.6368914366305655]
	TIME [epoch: 5.71 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3772975877264081		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.3772975877264081 | validation: 0.5830401606719657]
	TIME [epoch: 5.71 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6248162080702583		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.6248162080702583 | validation: 0.3661187078942146]
	TIME [epoch: 5.71 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318237761096214		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.3318237761096214 | validation: 0.33662725997427617]
	TIME [epoch: 5.72 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29988373233354115		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.29988373233354115 | validation: 0.4065549055208101]
	TIME [epoch: 5.76 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3020151302355178		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.3020151302355178 | validation: 0.33583174626903145]
	TIME [epoch: 5.73 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3209006768578514		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3209006768578514 | validation: 0.3865102964418403]
	TIME [epoch: 5.72 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35069192878215416		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.35069192878215416 | validation: 0.30843352037786687]
	TIME [epoch: 5.72 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3161814656542309		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.3161814656542309 | validation: 0.27492160813612415]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30074629171706035		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.30074629171706035 | validation: 0.31658012258178864]
	TIME [epoch: 5.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32520630091336655		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.32520630091336655 | validation: 0.3157000931248091]
	TIME [epoch: 5.73 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47777907102035727		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.47777907102035727 | validation: 0.3758114863842269]
	TIME [epoch: 5.73 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096681041113307		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.4096681041113307 | validation: 0.39335982170843564]
	TIME [epoch: 5.72 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3603476298697434		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.3603476298697434 | validation: 0.354633959087687]
	TIME [epoch: 5.72 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3577811187493183		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.3577811187493183 | validation: 0.4000763949724741]
	TIME [epoch: 5.71 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974379412255895		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3974379412255895 | validation: 0.2427470162431378]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28797100124151		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.28797100124151 | validation: 0.2761530060294783]
	TIME [epoch: 5.72 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3186608575593096		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.3186608575593096 | validation: 0.24893095483015296]
	TIME [epoch: 5.75 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2438390062247457		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.2438390062247457 | validation: 0.3784988134954903]
	TIME [epoch: 5.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30791561602872763		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.30791561602872763 | validation: 0.29166799294085927]
	TIME [epoch: 5.71 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30862584257027503		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.30862584257027503 | validation: 0.3427815203115801]
	TIME [epoch: 5.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609929244347861		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3609929244347861 | validation: 0.23655325827558557]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3130520349190621		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.3130520349190621 | validation: 0.3669254222864251]
	TIME [epoch: 5.72 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32215563004331565		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.32215563004331565 | validation: 0.2752360945537406]
	TIME [epoch: 5.73 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2611557740374968		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2611557740374968 | validation: 0.26549421271728807]
	TIME [epoch: 5.74 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425290758020944		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.3425290758020944 | validation: 0.34469986105768174]
	TIME [epoch: 5.71 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34746438055205175		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.34746438055205175 | validation: 0.29649766964260876]
	TIME [epoch: 5.72 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3194166952919441		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.3194166952919441 | validation: 0.3136750207437045]
	TIME [epoch: 5.71 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32742251555764135		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.32742251555764135 | validation: 0.3110290296487225]
	TIME [epoch: 5.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32094692247488965		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.32094692247488965 | validation: 0.29485265693855395]
	TIME [epoch: 5.71 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280047326253333		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.280047326253333 | validation: 0.2512197947799729]
	TIME [epoch: 5.77 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2702183565971897		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.2702183565971897 | validation: 0.28603799651680567]
	TIME [epoch: 5.72 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36549802033699913		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.36549802033699913 | validation: 0.242062218392026]
	TIME [epoch: 5.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3238456391898005		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.3238456391898005 | validation: 0.2526931455358422]
	TIME [epoch: 5.71 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2973095407447833		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.2973095407447833 | validation: 0.20122488854297602]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22472470778083314		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.22472470778083314 | validation: 0.2240315130120852]
	TIME [epoch: 5.71 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22860107807068017		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.22860107807068017 | validation: 0.21198363721443905]
	TIME [epoch: 5.77 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3449493591342622		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3449493591342622 | validation: 0.19672442172968715]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25033085015533574		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.25033085015533574 | validation: 0.2302299258451415]
	TIME [epoch: 5.71 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2900753166273853		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.2900753166273853 | validation: 0.22159037747459945]
	TIME [epoch: 5.7 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3036532842313957		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.3036532842313957 | validation: 0.23367716836972258]
	TIME [epoch: 5.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3250395427231196		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.3250395427231196 | validation: 0.3155516221514224]
	TIME [epoch: 5.72 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2521863612015299		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.2521863612015299 | validation: 0.2458908081924968]
	TIME [epoch: 5.73 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658780841427687		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.2658780841427687 | validation: 0.24307011835785858]
	TIME [epoch: 5.75 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27080818596101663		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.27080818596101663 | validation: 0.26027121414280385]
	TIME [epoch: 5.73 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3517331240551739		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3517331240551739 | validation: 0.28508299650125296]
	TIME [epoch: 5.71 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.283350081893461		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.283350081893461 | validation: 0.26114115554728146]
	TIME [epoch: 5.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2944324211267544		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.2944324211267544 | validation: 0.3566324380180671]
	TIME [epoch: 5.72 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32077188427869385		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.32077188427869385 | validation: 0.35861266474440145]
	TIME [epoch: 5.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30434434457741727		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.30434434457741727 | validation: 0.18866433809560867]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2360755358293123		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.2360755358293123 | validation: 0.16827142619621355]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3037374436569744		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3037374436569744 | validation: 0.22046387984326618]
	TIME [epoch: 5.71 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28101474502094465		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.28101474502094465 | validation: 0.20451997778736733]
	TIME [epoch: 5.71 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.709980637439417		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.709980637439417 | validation: 1.1623722833838925]
	TIME [epoch: 5.72 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.656398976703827		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.656398976703827 | validation: 0.27521328022284025]
	TIME [epoch: 5.71 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827104916003099		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.2827104916003099 | validation: 0.3029097834747699]
	TIME [epoch: 5.74 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2643871245039278		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.2643871245039278 | validation: 0.42730878487975277]
	TIME [epoch: 5.74 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3080129953245111		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.3080129953245111 | validation: 0.3101414538571952]
	TIME [epoch: 5.71 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952430252323768		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.2952430252323768 | validation: 0.25043622897513423]
	TIME [epoch: 5.72 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2677933262744124		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.2677933262744124 | validation: 0.24589286233887606]
	TIME [epoch: 5.73 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31887917121254117		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.31887917121254117 | validation: 0.3311143238368222]
	TIME [epoch: 5.72 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24800455261031595		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.24800455261031595 | validation: 0.25112471772720013]
	TIME [epoch: 5.71 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2947717608557739		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.2947717608557739 | validation: 0.2643492898164856]
	TIME [epoch: 5.75 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31220456986300427		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.31220456986300427 | validation: 0.37439324677352454]
	TIME [epoch: 5.72 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489529076527254		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.3489529076527254 | validation: 0.1873639385399959]
	TIME [epoch: 5.73 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22545135071217715		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.22545135071217715 | validation: 0.2157061144399353]
	TIME [epoch: 5.72 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3189544159925022		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.3189544159925022 | validation: 0.19480358112199148]
	TIME [epoch: 5.72 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18800731695860068		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.18800731695860068 | validation: 0.2216825650974667]
	TIME [epoch: 5.72 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23230718679742912		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.23230718679742912 | validation: 0.3451083382324822]
	TIME [epoch: 5.74 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627399006835429		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.2627399006835429 | validation: 0.21314111090119475]
	TIME [epoch: 5.76 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24290085458366426		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.24290085458366426 | validation: 0.2562711983512487]
	TIME [epoch: 5.71 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28864727701293647		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.28864727701293647 | validation: 0.24602861303719428]
	TIME [epoch: 5.73 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20640808175762684		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.20640808175762684 | validation: 0.18295901410218102]
	TIME [epoch: 5.73 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2274592672783194		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.2274592672783194 | validation: 0.24032235082160083]
	TIME [epoch: 5.72 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2736308178895844		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.2736308178895844 | validation: 0.16423770976474203]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1891867639632467		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.1891867639632467 | validation: 0.2099809584557084]
	TIME [epoch: 5.77 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18848766542107873		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.18848766542107873 | validation: 0.15300281001632318]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20732125246194125		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.20732125246194125 | validation: 0.25374300567996594]
	TIME [epoch: 5.71 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26200180912222937		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.26200180912222937 | validation: 0.14660963617886222]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22753483102991884		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.22753483102991884 | validation: 0.19007098003237974]
	TIME [epoch: 5.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22457475707860688		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.22457475707860688 | validation: 0.5340613076956453]
	TIME [epoch: 5.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48821569766343464		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.48821569766343464 | validation: 0.42381360486422054]
	TIME [epoch: 5.75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35781659053299375		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.35781659053299375 | validation: 0.16517320709900954]
	TIME [epoch: 5.74 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.199119948196472		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.199119948196472 | validation: 0.37295860836286715]
	TIME [epoch: 5.72 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252401200542812		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.252401200542812 | validation: 0.2991481104824551]
	TIME [epoch: 5.72 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039903085511718		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.3039903085511718 | validation: 0.2704342566703075]
	TIME [epoch: 5.73 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681931629342055		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.2681931629342055 | validation: 0.1907840095256184]
	TIME [epoch: 5.71 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20375377869066455		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.20375377869066455 | validation: 0.20562210057618335]
	TIME [epoch: 5.72 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23353686340660765		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.23353686340660765 | validation: 0.1811494934578265]
	TIME [epoch: 5.78 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19831448251711647		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.19831448251711647 | validation: 0.16093938615068246]
	TIME [epoch: 5.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18841189224571864		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.18841189224571864 | validation: 0.7516000297647727]
	TIME [epoch: 5.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3462961774703533		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.3462961774703533 | validation: 0.176959539083094]
	TIME [epoch: 5.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3469791549534388		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.3469791549534388 | validation: 0.23863276763423727]
	TIME [epoch: 5.71 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19409763023070684		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.19409763023070684 | validation: 0.2554808361114679]
	TIME [epoch: 5.71 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2083042872686885		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.2083042872686885 | validation: 0.24084237957195392]
	TIME [epoch: 5.74 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22813160226870155		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.22813160226870155 | validation: 0.21469186695925932]
	TIME [epoch: 5.72 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18845804514579922		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.18845804514579922 | validation: 0.16655660280349466]
	TIME [epoch: 5.71 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865285607052416		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.1865285607052416 | validation: 0.1578345155282199]
	TIME [epoch: 5.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16879659659410884		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.16879659659410884 | validation: 0.1686118271207293]
	TIME [epoch: 5.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19912541492682315		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.19912541492682315 | validation: 0.16553925188880642]
	TIME [epoch: 5.71 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21342195568194636		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.21342195568194636 | validation: 0.22482190793567275]
	TIME [epoch: 5.71 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19612839990308367		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.19612839990308367 | validation: 0.11817064192418496]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912484556375045		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.1912484556375045 | validation: 0.1274781319342773]
	TIME [epoch: 5.72 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15307211831216064		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.15307211831216064 | validation: 0.14208892484609748]
	TIME [epoch: 5.71 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24686558575251405		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.24686558575251405 | validation: 0.5863282680453218]
	TIME [epoch: 5.71 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42780597996009645		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.42780597996009645 | validation: 0.3549357768762506]
	TIME [epoch: 5.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909375900949557		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.1909375900949557 | validation: 0.21954067042779923]
	TIME [epoch: 5.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30775576959941936		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.30775576959941936 | validation: 0.2956101682377337]
	TIME [epoch: 5.73 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536538654441918		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.2536538654441918 | validation: 0.2135116891568835]
	TIME [epoch: 5.73 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23408321414651959		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.23408321414651959 | validation: 0.23432265113031311]
	TIME [epoch: 5.71 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1903567423400083		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.1903567423400083 | validation: 0.11635531864354158]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14527050136276212		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.14527050136276212 | validation: 0.24792326508136892]
	TIME [epoch: 5.71 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21714282805620327		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.21714282805620327 | validation: 0.18626963020526127]
	TIME [epoch: 5.71 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17154672245669456		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.17154672245669456 | validation: 0.25068383963581803]
	TIME [epoch: 5.71 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17872749293457263		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.17872749293457263 | validation: 0.2501050347212614]
	TIME [epoch: 5.77 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1990760154621805		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.1990760154621805 | validation: 0.18814287914014444]
	TIME [epoch: 5.71 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785720636196488		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.2785720636196488 | validation: 0.1936386791838521]
	TIME [epoch: 5.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2172350741416623		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.2172350741416623 | validation: 0.19964292216380627]
	TIME [epoch: 5.71 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.183912933196427		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.183912933196427 | validation: 0.11040751227760691]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17737175680941597		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.17737175680941597 | validation: 0.1479827469970626]
	TIME [epoch: 5.71 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16607352800163974		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.16607352800163974 | validation: 0.1064661711184478]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2462699638420348		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.2462699638420348 | validation: 0.2557786945360128]
	TIME [epoch: 5.72 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18680661120222147		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.18680661120222147 | validation: 0.26838087396740096]
	TIME [epoch: 5.72 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2137362594209269		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.2137362594209269 | validation: 0.169733023832303]
	TIME [epoch: 5.71 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19607160941000992		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.19607160941000992 | validation: 0.22968292900961204]
	TIME [epoch: 5.73 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1914637154979991		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.1914637154979991 | validation: 0.14996837238584393]
	TIME [epoch: 5.71 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21809668300230983		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.21809668300230983 | validation: 0.1859388754458809]
	TIME [epoch: 5.73 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17794496191418557		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.17794496191418557 | validation: 0.15684312530454364]
	TIME [epoch: 5.75 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21211291601538063		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.21211291601538063 | validation: 0.2552532158678521]
	TIME [epoch: 5.72 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19862947850624832		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.19862947850624832 | validation: 0.2794384654242489]
	TIME [epoch: 5.72 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23013797602850575		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.23013797602850575 | validation: 0.1101821014396863]
	TIME [epoch: 5.73 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14007300316176452		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.14007300316176452 | validation: 0.1446989024926632]
	TIME [epoch: 5.72 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14895876992780202		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.14895876992780202 | validation: 0.4978970680400085]
	TIME [epoch: 5.72 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24646163718292685		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.24646163718292685 | validation: 0.17980883670839248]
	TIME [epoch: 5.76 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29475462398976626		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.29475462398976626 | validation: 0.22765741647815815]
	TIME [epoch: 5.71 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20870675329645388		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.20870675329645388 | validation: 0.16159812378187383]
	TIME [epoch: 5.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1888244939300344		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.1888244939300344 | validation: 0.23983285341747018]
	TIME [epoch: 5.71 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22411605233156373		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.22411605233156373 | validation: 0.18821687860872355]
	TIME [epoch: 5.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21258958897677682		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.21258958897677682 | validation: 0.18924576370817625]
	TIME [epoch: 5.71 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20345467784559418		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.20345467784559418 | validation: 0.3397499192705516]
	TIME [epoch: 5.72 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2702674413892887		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.2702674413892887 | validation: 0.16210708162029655]
	TIME [epoch: 5.75 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21131513290304182		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.21131513290304182 | validation: 0.3099877819597663]
	TIME [epoch: 5.73 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2373668722465301		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.2373668722465301 | validation: 0.16247657104707913]
	TIME [epoch: 5.72 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1904372540636939		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.1904372540636939 | validation: 0.1465742755608758]
	TIME [epoch: 5.72 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13953215541519193		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.13953215541519193 | validation: 0.12340034874350042]
	TIME [epoch: 5.71 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15209894177520447		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.15209894177520447 | validation: 0.17661822113879386]
	TIME [epoch: 5.72 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17071120795877404		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.17071120795877404 | validation: 0.1425936919960881]
	TIME [epoch: 5.76 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20021672168577587		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.20021672168577587 | validation: 0.14344967857899057]
	TIME [epoch: 5.73 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559597517443924		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.1559597517443924 | validation: 0.16004311311731975]
	TIME [epoch: 5.72 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19968145738006282		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.19968145738006282 | validation: 0.1593025179566905]
	TIME [epoch: 5.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13453818328886888		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.13453818328886888 | validation: 0.1496616369550638]
	TIME [epoch: 5.71 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17674253106322727		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.17674253106322727 | validation: 0.12795132842512186]
	TIME [epoch: 5.73 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17230855284836488		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.17230855284836488 | validation: 0.1672664962047004]
	TIME [epoch: 5.74 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18096310871786087		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.18096310871786087 | validation: 0.19061333767083355]
	TIME [epoch: 5.75 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19436134678965786		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.19436134678965786 | validation: 0.22411961569727765]
	TIME [epoch: 5.72 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18897001472786584		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.18897001472786584 | validation: 0.1650888999974064]
	TIME [epoch: 5.71 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15103378138957563		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.15103378138957563 | validation: 0.16618285894455156]
	TIME [epoch: 5.72 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18624056764809357		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.18624056764809357 | validation: 0.17454178669744566]
	TIME [epoch: 5.73 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447820575402686		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.1447820575402686 | validation: 0.1415948612874127]
	TIME [epoch: 5.72 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20438462100068158		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.20438462100068158 | validation: 0.2393150318064682]
	TIME [epoch: 5.74 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18655116949866146		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.18655116949866146 | validation: 0.3223809890977829]
	TIME [epoch: 5.74 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708249898532193		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.1708249898532193 | validation: 0.14287094572919512]
	TIME [epoch: 5.71 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16099543509123676		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.16099543509123676 | validation: 0.1551776637350196]
	TIME [epoch: 5.72 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1817229856827583		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.1817229856827583 | validation: 0.17940066765622134]
	TIME [epoch: 5.72 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18882785908270622		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.18882785908270622 | validation: 0.17475197327541941]
	TIME [epoch: 5.73 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16605831432149898		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.16605831432149898 | validation: 0.18655555721014477]
	TIME [epoch: 5.71 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17221860374365378		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.17221860374365378 | validation: 0.1476206730742968]
	TIME [epoch: 5.77 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17932551288789406		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.17932551288789406 | validation: 0.15989877201387867]
	TIME [epoch: 5.71 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13701125513871734		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.13701125513871734 | validation: 0.2664771465155004]
	TIME [epoch: 5.71 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18540290272083973		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.18540290272083973 | validation: 0.1815451543901709]
	TIME [epoch: 5.73 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16902192508655078		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.16902192508655078 | validation: 0.24369745885927685]
	TIME [epoch: 5.72 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18091212824800315		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.18091212824800315 | validation: 0.24171073046240668]
	TIME [epoch: 5.72 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1723180352208803		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.1723180352208803 | validation: 0.1536776525862257]
	TIME [epoch: 5.74 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14629558844306165		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.14629558844306165 | validation: 0.20252116844348386]
	TIME [epoch: 5.75 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20036343387043581		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.20036343387043581 | validation: 0.28760531138876777]
	TIME [epoch: 5.71 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24771919548545263		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.24771919548545263 | validation: 0.48939662111400933]
	TIME [epoch: 5.73 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20980055926670693		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.20980055926670693 | validation: 0.15230592480859195]
	TIME [epoch: 5.71 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14454955608119585		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.14454955608119585 | validation: 0.1557424690085896]
	TIME [epoch: 5.72 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20341751909637537		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.20341751909637537 | validation: 0.16181456407670097]
	TIME [epoch: 5.72 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485764154516086		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.1485764154516086 | validation: 0.15502411022281326]
	TIME [epoch: 5.77 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17389514134854822		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.17389514134854822 | validation: 0.17384279268160124]
	TIME [epoch: 5.73 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16813592841967742		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.16813592841967742 | validation: 0.2324183404015515]
	TIME [epoch: 5.72 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15563799835238173		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.15563799835238173 | validation: 0.21105390010417374]
	TIME [epoch: 5.71 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21584401932601438		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.21584401932601438 | validation: 0.18346243686499297]
	TIME [epoch: 5.72 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19027472630730746		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.19027472630730746 | validation: 0.2812042318384666]
	TIME [epoch: 5.71 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2205330491809799		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.2205330491809799 | validation: 0.17340304176246552]
	TIME [epoch: 5.76 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2049994556208528		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.2049994556208528 | validation: 0.34779767029809333]
	TIME [epoch: 5.75 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18751624168908806		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.18751624168908806 | validation: 0.23242160837326664]
	TIME [epoch: 5.71 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16127685739372577		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.16127685739372577 | validation: 0.5073718980480917]
	TIME [epoch: 5.71 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2338475652379262		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.2338475652379262 | validation: 0.14060609656705308]
	TIME [epoch: 5.71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19209772019777885		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.19209772019777885 | validation: 0.17675132116671063]
	TIME [epoch: 5.73 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514824107306328		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.2514824107306328 | validation: 0.11610542093343426]
	TIME [epoch: 5.72 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333593481334598		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.1333593481334598 | validation: 0.13549579622245794]
	TIME [epoch: 5.77 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138001822692011		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.138001822692011 | validation: 0.18340088203566848]
	TIME [epoch: 5.72 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1684951938830584		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.1684951938830584 | validation: 0.2180060012344503]
	TIME [epoch: 5.72 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21446700772117805		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.21446700772117805 | validation: 0.19464175855122343]
	TIME [epoch: 5.73 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16335531269677697		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.16335531269677697 | validation: 0.15632700816008235]
	TIME [epoch: 5.72 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.181742446530943		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.181742446530943 | validation: 0.2738967165414448]
	TIME [epoch: 5.71 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1839298854661906		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.1839298854661906 | validation: 0.2520590835150021]
	TIME [epoch: 5.74 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1686345086626756		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.1686345086626756 | validation: 0.2538582638828826]
	TIME [epoch: 5.73 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17943329399868033		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.17943329399868033 | validation: 0.2064841277127548]
	TIME [epoch: 5.73 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13968834466451827		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.13968834466451827 | validation: 0.14505467233212344]
	TIME [epoch: 5.72 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15736426209575122		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.15736426209575122 | validation: 0.18651220535300575]
	TIME [epoch: 5.71 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13901208401431958		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.13901208401431958 | validation: 0.13419184219874478]
	TIME [epoch: 5.72 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26362788775397805		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.26362788775397805 | validation: 0.15708391068386932]
	TIME [epoch: 5.71 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15817877281553377		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.15817877281553377 | validation: 0.14569574549518272]
	TIME [epoch: 5.77 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409741826042813		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.1409741826042813 | validation: 0.13835421713970628]
	TIME [epoch: 5.73 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15375657279055904		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.15375657279055904 | validation: 0.16787351602892717]
	TIME [epoch: 5.72 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15637684945352606		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.15637684945352606 | validation: 0.12492661604115317]
	TIME [epoch: 5.71 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15509991644321372		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.15509991644321372 | validation: 0.12421349920534876]
	TIME [epoch: 5.71 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14141924535389802		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.14141924535389802 | validation: 0.24877625492813488]
	TIME [epoch: 5.71 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876020456057969		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2876020456057969 | validation: 0.17644407057865935]
	TIME [epoch: 5.75 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17906970748091816		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.17906970748091816 | validation: 0.14089999859614558]
	TIME [epoch: 5.74 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17007340597699147		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.17007340597699147 | validation: 0.13319103986792882]
	TIME [epoch: 5.72 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13682949426050142		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.13682949426050142 | validation: 0.16911373104108948]
	TIME [epoch: 5.72 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12426904619335843		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.12426904619335843 | validation: 0.20345835861522824]
	TIME [epoch: 5.71 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15498529950125783		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.15498529950125783 | validation: 0.1648062440780565]
	TIME [epoch: 5.72 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16051726046343376		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.16051726046343376 | validation: 0.24392266327387202]
	TIME [epoch: 5.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16695083541924616		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.16695083541924616 | validation: 0.2075226918986184]
	TIME [epoch: 5.77 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20344711051326922		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.20344711051326922 | validation: 0.1437289566749332]
	TIME [epoch: 5.72 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14145506937985036		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.14145506937985036 | validation: 0.13377489150306493]
	TIME [epoch: 5.71 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14560565629743427		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.14560565629743427 | validation: 0.23749837818030478]
	TIME [epoch: 5.73 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1445112965019432		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.1445112965019432 | validation: 0.3472681506389834]
	TIME [epoch: 5.71 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1771675632819976		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.1771675632819976 | validation: 0.3073880042218141]
	TIME [epoch: 5.72 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16224264649381917		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.16224264649381917 | validation: 0.3110897311962462]
	TIME [epoch: 5.75 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2365290612700821		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.2365290612700821 | validation: 0.20636717614065223]
	TIME [epoch: 5.72 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18406680653967394		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.18406680653967394 | validation: 0.1919231249514307]
	TIME [epoch: 5.71 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411195262563836		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.1411195262563836 | validation: 0.16790959684690798]
	TIME [epoch: 5.71 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16051353094126813		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.16051353094126813 | validation: 0.14629641334304377]
	TIME [epoch: 5.72 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15200269471766978		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.15200269471766978 | validation: 0.11980421809633623]
	TIME [epoch: 5.72 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374787960103772		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.1374787960103772 | validation: 0.11875354625911318]
	TIME [epoch: 5.73 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13788664704364548		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.13788664704364548 | validation: 0.11879349821244548]
	TIME [epoch: 5.77 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14170326596541516		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.14170326596541516 | validation: 0.14361044067414494]
	TIME [epoch: 5.73 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152121755814842		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.152121755814842 | validation: 0.12947020771280418]
	TIME [epoch: 5.73 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853687753915914		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.13853687753915914 | validation: 0.15915114648074297]
	TIME [epoch: 5.71 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15133309715050916		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.15133309715050916 | validation: 0.1262310170179977]
	TIME [epoch: 5.71 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16923248340236388		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.16923248340236388 | validation: 0.24308648762584345]
	TIME [epoch: 5.71 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1813087674897832		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.1813087674897832 | validation: 0.13093658630893246]
	TIME [epoch: 5.73 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1224529443629		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.1224529443629 | validation: 0.11977154934988413]
	TIME [epoch: 5.75 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14131688560005742		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.14131688560005742 | validation: 0.18042587795259607]
	TIME [epoch: 5.71 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14830711538772554		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.14830711538772554 | validation: 0.12707949713329916]
	TIME [epoch: 5.72 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13996708370058308		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.13996708370058308 | validation: 0.15114507495097548]
	TIME [epoch: 5.71 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14632148737993836		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.14632148737993836 | validation: 0.15998256812445383]
	TIME [epoch: 5.72 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131204481052118		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.131204481052118 | validation: 0.10333744187905711]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13600436300224186		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.13600436300224186 | validation: 0.12095094072856725]
	TIME [epoch: 5.77 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12910760462856308		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.12910760462856308 | validation: 0.11411633560510247]
	TIME [epoch: 5.71 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14251899397879841		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.14251899397879841 | validation: 0.14607299960909614]
	TIME [epoch: 5.72 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2404913539844198		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.2404913539844198 | validation: 0.13034187373296685]
	TIME [epoch: 5.71 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389321784473011		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.1389321784473011 | validation: 0.11995867523684162]
	TIME [epoch: 5.72 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11653025505026202		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.11653025505026202 | validation: 0.10490367815085559]
	TIME [epoch: 5.72 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12183357513702248		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.12183357513702248 | validation: 0.15108198644245976]
	TIME [epoch: 5.74 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460065062927352		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.1460065062927352 | validation: 0.13911674334347696]
	TIME [epoch: 5.74 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13127631801280476		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.13127631801280476 | validation: 0.15469964873679135]
	TIME [epoch: 5.72 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11809623128142643		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.11809623128142643 | validation: 0.11958488107188833]
	TIME [epoch: 5.71 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2194000460323689		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.2194000460323689 | validation: 0.12558019364385495]
	TIME [epoch: 5.72 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16676567401961018		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.16676567401961018 | validation: 0.12259398753714754]
	TIME [epoch: 5.73 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11526667571784081		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.11526667571784081 | validation: 0.1184293158353767]
	TIME [epoch: 5.73 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16254388127660518		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.16254388127660518 | validation: 0.12947393519122494]
	TIME [epoch: 5.76 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14304116848770426		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.14304116848770426 | validation: 0.1227374336495128]
	TIME [epoch: 5.72 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11826780775909294		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.11826780775909294 | validation: 0.1208675660751969]
	TIME [epoch: 5.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14058037633846615		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.14058037633846615 | validation: 0.27251422217314836]
	TIME [epoch: 5.72 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114321834408049		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.2114321834408049 | validation: 0.13629372601664663]
	TIME [epoch: 5.73 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20991206829343342		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.20991206829343342 | validation: 0.16378634852057]
	TIME [epoch: 5.72 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12322616400115227		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.12322616400115227 | validation: 0.11818537162680917]
	TIME [epoch: 5.71 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18008810145071083		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.18008810145071083 | validation: 0.10842502960689732]
	TIME [epoch: 5.75 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11192124044071472		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.11192124044071472 | validation: 0.12431569210621074]
	TIME [epoch: 5.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14349822532908216		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.14349822532908216 | validation: 0.19407629542095606]
	TIME [epoch: 5.71 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253428248750979		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.1253428248750979 | validation: 0.10648000400608286]
	TIME [epoch: 5.72 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13325380726344954		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.13325380726344954 | validation: 0.12505915895327718]
	TIME [epoch: 5.72 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12804928954245196		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.12804928954245196 | validation: 0.11061779682633467]
	TIME [epoch: 5.72 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11085331121356656		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.11085331121356656 | validation: 0.10104026945532696]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14493570806651768		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.14493570806651768 | validation: 0.15077264022082518]
	TIME [epoch: 5.72 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286353677012047		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.1286353677012047 | validation: 0.07334923103311777]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_427.pth
	Model improved!!!
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12383250013399284		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.12383250013399284 | validation: 0.1183920686901907]
	TIME [epoch: 5.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1180228972852195		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.1180228972852195 | validation: 0.10199825526936167]
	TIME [epoch: 5.71 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10042680945957139		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.10042680945957139 | validation: 0.08471378391417346]
	TIME [epoch: 5.71 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108157438954274		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.108157438954274 | validation: 0.08908886999331365]
	TIME [epoch: 5.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09160364982644799		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.09160364982644799 | validation: 0.07549107796510705]
	TIME [epoch: 5.73 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08320611651233156		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.08320611651233156 | validation: 0.1319786966397035]
	TIME [epoch: 5.71 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13198694199188662		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.13198694199188662 | validation: 0.10715556881879348]
	TIME [epoch: 5.71 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10014624991892251		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.10014624991892251 | validation: 0.12449021693455149]
	TIME [epoch: 5.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15322382717780222		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.15322382717780222 | validation: 0.20120436891530055]
	TIME [epoch: 5.71 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20765921515202168		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.20765921515202168 | validation: 0.1462862605617343]
	TIME [epoch: 5.72 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11042068355118378		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.11042068355118378 | validation: 0.11611962290385204]
	TIME [epoch: 5.76 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11688864278238763		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.11688864278238763 | validation: 0.08294771706682445]
	TIME [epoch: 5.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12916178320583813		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.12916178320583813 | validation: 0.11574349841159631]
	TIME [epoch: 5.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11522615622799089		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.11522615622799089 | validation: 0.13478832680822542]
	TIME [epoch: 5.71 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11611457632924155		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.11611457632924155 | validation: 0.08724878887363433]
	TIME [epoch: 5.72 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09656649768066275		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.09656649768066275 | validation: 0.07865330876967931]
	TIME [epoch: 5.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13657032522803456		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.13657032522803456 | validation: 0.0725140551061235]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_444.pth
	Model improved!!!
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11786059550495337		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.11786059550495337 | validation: 0.1142262791441457]
	TIME [epoch: 5.72 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12726361336347308		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.12726361336347308 | validation: 0.08124493964862921]
	TIME [epoch: 5.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1080285973663951		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.1080285973663951 | validation: 0.052408103112982135]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_447.pth
	Model improved!!!
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12109633549667981		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.12109633549667981 | validation: 0.07545383803878984]
	TIME [epoch: 5.71 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11700632920294417		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.11700632920294417 | validation: 0.07361278163376049]
	TIME [epoch: 5.71 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11374729812831821		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.11374729812831821 | validation: 0.07344814394813357]
	TIME [epoch: 5.72 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679251383234456		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.09679251383234456 | validation: 0.10168931323601259]
	TIME [epoch: 5.74 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11266480388218506		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.11266480388218506 | validation: 0.06576213791370009]
	TIME [epoch: 5.71 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09044819768303769		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.09044819768303769 | validation: 0.05900438719191526]
	TIME [epoch: 5.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07845684655875092		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.07845684655875092 | validation: 0.08099157144857692]
	TIME [epoch: 5.71 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12097738972171299		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.12097738972171299 | validation: 0.0659311550930022]
	TIME [epoch: 5.71 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10363169983318521		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.10363169983318521 | validation: 0.09047192796824825]
	TIME [epoch: 5.71 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701994062936385		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.1701994062936385 | validation: 0.16610381125729887]
	TIME [epoch: 5.74 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11249292964031198		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.11249292964031198 | validation: 0.06668130880515882]
	TIME [epoch: 5.71 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11690117751534247		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.11690117751534247 | validation: 0.16407054264080287]
	TIME [epoch: 5.71 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22144804523180284		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.22144804523180284 | validation: 0.20189675722522069]
	TIME [epoch: 5.71 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385646324370626		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.1385646324370626 | validation: 0.11688684874767717]
	TIME [epoch: 5.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1152351073684275		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.1152351073684275 | validation: 0.08693381392355175]
	TIME [epoch: 5.71 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14539451027130626		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.14539451027130626 | validation: 0.0810638939799389]
	TIME [epoch: 5.71 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11942604734753455		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.11942604734753455 | validation: 0.07592428772970304]
	TIME [epoch: 5.75 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11772579025515262		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.11772579025515262 | validation: 0.09785710135634648]
	TIME [epoch: 5.71 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13467857429036728		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.13467857429036728 | validation: 0.1438633994845295]
	TIME [epoch: 5.71 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13888594434979265		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.13888594434979265 | validation: 0.1080860529764971]
	TIME [epoch: 5.71 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09519238671833617		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.09519238671833617 | validation: 0.0883827731320713]
	TIME [epoch: 5.71 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991554018131069		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.08991554018131069 | validation: 0.06642583875518807]
	TIME [epoch: 5.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07837745129701573		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.07837745129701573 | validation: 0.09404275381054873]
	TIME [epoch: 5.74 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08539728210376281		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.08539728210376281 | validation: 0.08870205589087896]
	TIME [epoch: 5.73 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558011155268012		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.12558011155268012 | validation: 0.11529013001950243]
	TIME [epoch: 5.71 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09631887758576477		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.09631887758576477 | validation: 0.07855896874412997]
	TIME [epoch: 5.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1189985172568337		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.1189985172568337 | validation: 0.0604351912824785]
	TIME [epoch: 5.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08198416890645285		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.08198416890645285 | validation: 0.0793804281320405]
	TIME [epoch: 5.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07497252284378889		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.07497252284378889 | validation: 0.05822508920823779]
	TIME [epoch: 5.71 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017661623779574		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.07017661623779574 | validation: 0.22717629817382687]
	TIME [epoch: 5.76 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18861759247740048		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.18861759247740048 | validation: 0.07917955871503034]
	TIME [epoch: 5.71 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1511241085926373		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.1511241085926373 | validation: 0.1433441599332164]
	TIME [epoch: 5.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796465213896702		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.1796465213896702 | validation: 0.10203627705192993]
	TIME [epoch: 5.71 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11736727045812914		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.11736727045812914 | validation: 0.05740646996103663]
	TIME [epoch: 5.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07352811264644554		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.07352811264644554 | validation: 0.05342799993094904]
	TIME [epoch: 5.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10165870575572206		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.10165870575572206 | validation: 0.06890100280272135]
	TIME [epoch: 5.73 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0816431960773702		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.0816431960773702 | validation: 0.14123679676392079]
	TIME [epoch: 5.73 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10676195842381675		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.10676195842381675 | validation: 0.06811944932753043]
	TIME [epoch: 5.71 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10433932107095235		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.10433932107095235 | validation: 0.10186669252714076]
	TIME [epoch: 5.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08877280345775466		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.08877280345775466 | validation: 0.0719134827776222]
	TIME [epoch: 5.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12540375914445023		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.12540375914445023 | validation: 0.07505521767337585]
	TIME [epoch: 5.71 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07715062424106126		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.07715062424106126 | validation: 0.07690994239412378]
	TIME [epoch: 5.71 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07565006450423331		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.07565006450423331 | validation: 0.08479920425050712]
	TIME [epoch: 5.75 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989772462390843		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.07989772462390843 | validation: 0.061319245741200734]
	TIME [epoch: 5.71 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06521881498730558		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.06521881498730558 | validation: 0.08919633712137845]
	TIME [epoch: 5.71 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08321772717289963		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.08321772717289963 | validation: 0.06505013532205842]
	TIME [epoch: 5.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08540552803805006		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.08540552803805006 | validation: 0.18404238187746874]
	TIME [epoch: 5.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11304340214797742		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.11304340214797742 | validation: 0.06563918867917078]
	TIME [epoch: 5.71 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08963587069923305		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.08963587069923305 | validation: 0.0742663634749339]
	TIME [epoch: 5.73 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08658418634897688		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.08658418634897688 | validation: 0.07162521762301932]
	TIME [epoch: 5.72 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0628706646783164		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.0628706646783164 | validation: 0.06234374016200883]
	TIME [epoch: 5.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06538685188208931		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.06538685188208931 | validation: 0.08374558259690443]
	TIME [epoch: 5.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08251234907404768		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.08251234907404768 | validation: 0.06004791282989103]
	TIME [epoch: 5.71 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1679469748494333		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.1679469748494333 | validation: 0.07115116906693014]
	TIME [epoch: 5.71 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11295144997502116		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.11295144997502116 | validation: 0.06994461777846722]
	TIME [epoch: 5.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07626410954992237		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.07626410954992237 | validation: 0.10444764753659583]
	TIME [epoch: 5.74 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10510782635641637		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.10510782635641637 | validation: 0.08490270152648184]
	TIME [epoch: 5.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908086948901373		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.08908086948901373 | validation: 0.08020763698690862]
	TIME [epoch: 5.71 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12028513010079224		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.12028513010079224 | validation: 0.08742869273447738]
	TIME [epoch: 5.71 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14402701125982592		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.14402701125982592 | validation: 0.1793678373702619]
	TIME [epoch: 5.71 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16547756058487684		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.16547756058487684 | validation: 0.10456551646233692]
	TIME [epoch: 5.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08390339787240628		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.08390339787240628 | validation: 0.11203817204517634]
	TIME [epoch: 5.72 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1023098160336452		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.1023098160336452 | validation: 0.1077041705724704]
	TIME [epoch: 5.72 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09109329367731087		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.09109329367731087 | validation: 0.14386873507500877]
	TIME [epoch: 5.71 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0921575283383298		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.0921575283383298 | validation: 0.06822925715257512]
	TIME [epoch: 5.71 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09748290297239232		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.09748290297239232 | validation: 0.11462725872500124]
	TIME [epoch: 5.71 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08658016437622516		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.08658016437622516 | validation: 0.05801354593036157]
	TIME [epoch: 5.71 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060873333376858914		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.060873333376858914 | validation: 0.06296676270733398]
	TIME [epoch: 5.71 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07553702387094935		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.07553702387094935 | validation: 0.07568351523166854]
	TIME [epoch: 5.74 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376091301699885		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.1376091301699885 | validation: 0.08637015441898183]
	TIME [epoch: 5.71 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264230277054722		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.1264230277054722 | validation: 0.1343557331242135]
	TIME [epoch: 5.71 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343936760734728		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.1343936760734728 | validation: 0.11711160964191099]
	TIME [epoch: 5.71 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11400600418929199		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.11400600418929199 | validation: 0.060957509507507356]
	TIME [epoch: 5.71 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07413187512339989		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.07413187512339989 | validation: 0.06498361770321999]
	TIME [epoch: 5.71 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07295701959072359		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.07295701959072359 | validation: 0.0810388023951247]
	TIME [epoch: 5.72 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856756253343817		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.06856756253343817 | validation: 0.08239805413010305]
	TIME [epoch: 5.74 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06916084921816072		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.06916084921816072 | validation: 0.08921086104871039]
	TIME [epoch: 5.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09827309117336874		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.09827309117336874 | validation: 0.07156900806039045]
	TIME [epoch: 5.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08430548603650023		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.08430548603650023 | validation: 0.07135367538016059]
	TIME [epoch: 5.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07037698749686791		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.07037698749686791 | validation: 0.04541803481457878]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11328422121376558		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.11328422121376558 | validation: 0.20993777999791166]
	TIME [epoch: 5.71 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19797434395506178		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.19797434395506178 | validation: 0.10010343532727568]
	TIME [epoch: 5.75 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09351599759270032		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.09351599759270032 | validation: 0.07156579013335349]
	TIME [epoch: 5.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07720879006459683		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.07720879006459683 | validation: 0.04857785695742387]
	TIME [epoch: 5.71 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07628803320548391		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.07628803320548391 | validation: 0.0796096151498174]
	TIME [epoch: 5.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11320017710788528		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.11320017710788528 | validation: 0.12634810523475395]
	TIME [epoch: 5.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1696601277049627		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.1696601277049627 | validation: 0.21300979965997813]
	TIME [epoch: 5.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12819606071945477		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.12819606071945477 | validation: 0.061387529486465135]
	TIME [epoch: 5.71 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11815803002197957		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.11815803002197957 | validation: 0.16064133872344372]
	TIME [epoch: 5.74 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0849893665558228		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.0849893665558228 | validation: 0.06659106355513746]
	TIME [epoch: 5.71 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07704043356131743		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.07704043356131743 | validation: 0.05916709841535275]
	TIME [epoch: 5.71 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06274147399090746		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.06274147399090746 | validation: 0.06686862419788601]
	TIME [epoch: 5.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0612329208808082		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.0612329208808082 | validation: 0.11391438270757853]
	TIME [epoch: 5.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11609658298619474		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.11609658298619474 | validation: 0.11864221781947087]
	TIME [epoch: 5.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08662810859818039		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.08662810859818039 | validation: 0.049757566811016764]
	TIME [epoch: 5.75 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05056410993560037		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.05056410993560037 | validation: 0.07929734344540156]
	TIME [epoch: 5.72 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060481232297275145		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.060481232297275145 | validation: 0.08460095463940807]
	TIME [epoch: 5.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08895010373640008		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.08895010373640008 | validation: 0.07485728249286241]
	TIME [epoch: 5.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0687863928095305		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.0687863928095305 | validation: 0.07082988332577854]
	TIME [epoch: 5.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06339819230424469		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.06339819230424469 | validation: 0.04601082244553041]
	TIME [epoch: 5.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10459859583443482		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.10459859583443482 | validation: 0.0763208263173437]
	TIME [epoch: 5.72 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07356717788624939		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.07356717788624939 | validation: 0.09257463872289907]
	TIME [epoch: 5.74 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11352202120212357		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.11352202120212357 | validation: 0.11194702864238586]
	TIME [epoch: 5.71 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08251378790439698		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.08251378790439698 | validation: 0.08097300739953477]
	TIME [epoch: 5.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07085599175733157		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.07085599175733157 | validation: 0.10606587760439146]
	TIME [epoch: 5.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08996591962626613		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.08996591962626613 | validation: 0.10389894100159901]
	TIME [epoch: 5.71 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09364692027518282		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.09364692027518282 | validation: 0.091908848910171]
	TIME [epoch: 5.71 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1017062238967723		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1017062238967723 | validation: 0.09096487376156417]
	TIME [epoch: 5.74 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014535789931911		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.1014535789931911 | validation: 0.08749670392294977]
	TIME [epoch: 5.71 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07869845616127184		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.07869845616127184 | validation: 0.11167561669884869]
	TIME [epoch: 5.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09905292846057875		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.09905292846057875 | validation: 0.12146999022748073]
	TIME [epoch: 5.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11028168371043129		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.11028168371043129 | validation: 0.06827198277825504]
	TIME [epoch: 5.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07876530421161526		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.07876530421161526 | validation: 0.056165640681877176]
	TIME [epoch: 5.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07030983433820813		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.07030983433820813 | validation: 0.05513072476626477]
	TIME [epoch: 5.72 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07104151729300381		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.07104151729300381 | validation: 0.04663162631648492]
	TIME [epoch: 5.74 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07891163208984656		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.07891163208984656 | validation: 0.07515256044597926]
	TIME [epoch: 5.71 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09571716328620009		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.09571716328620009 | validation: 0.06346936363465676]
	TIME [epoch: 5.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07703368241532388		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.07703368241532388 | validation: 0.09117520316337824]
	TIME [epoch: 5.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08685875615449531		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.08685875615449531 | validation: 0.06018453266209063]
	TIME [epoch: 5.71 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09084359388363195		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.09084359388363195 | validation: 0.0743012378749667]
	TIME [epoch: 5.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08709602426640392		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.08709602426640392 | validation: 0.06686199136282978]
	TIME [epoch: 5.75 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08847593594230296		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.08847593594230296 | validation: 0.13425669759723982]
	TIME [epoch: 5.71 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08225348920540948		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.08225348920540948 | validation: 0.12301057802836113]
	TIME [epoch: 5.71 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10556030070557107		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.10556030070557107 | validation: 0.07401167755650788]
	TIME [epoch: 5.71 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06949532920371317		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.06949532920371317 | validation: 0.05887134720040366]
	TIME [epoch: 5.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259764635021067		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.06259764635021067 | validation: 0.05471902227646719]
	TIME [epoch: 5.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061279595988045235		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.061279595988045235 | validation: 0.039818173257111296]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_574.pth
	Model improved!!!
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0550978523859135		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.0550978523859135 | validation: 0.050493664166929283]
	TIME [epoch: 5.75 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05420215038399213		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.05420215038399213 | validation: 0.08763391348949696]
	TIME [epoch: 5.71 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09514225830795113		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.09514225830795113 | validation: 0.12555220297118613]
	TIME [epoch: 5.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09174404817290197		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.09174404817290197 | validation: 0.05360198334035182]
	TIME [epoch: 5.72 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06977135272058821		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.06977135272058821 | validation: 0.12063068624076864]
	TIME [epoch: 5.71 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11415035556575034		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.11415035556575034 | validation: 0.0588500109019369]
	TIME [epoch: 5.72 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06725941607674632		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.06725941607674632 | validation: 0.043331555122280686]
	TIME [epoch: 5.75 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054998041620098845		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.054998041620098845 | validation: 0.06162746389717898]
	TIME [epoch: 5.72 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06386954975127576		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.06386954975127576 | validation: 0.04384192629278415]
	TIME [epoch: 5.72 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07261636669110881		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.07261636669110881 | validation: 0.09400342872495764]
	TIME [epoch: 5.71 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06875694814919928		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.06875694814919928 | validation: 0.07277377106075718]
	TIME [epoch: 5.71 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07555793432884894		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.07555793432884894 | validation: 0.08738897058296724]
	TIME [epoch: 5.72 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10101933159075363		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.10101933159075363 | validation: 0.0694198900037376]
	TIME [epoch: 5.73 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111077037882447		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.10111077037882447 | validation: 0.05728456415093664]
	TIME [epoch: 5.75 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05771956318378998		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.05771956318378998 | validation: 0.04232360154696329]
	TIME [epoch: 5.72 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11092769556752187		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.11092769556752187 | validation: 0.06925488721234299]
	TIME [epoch: 5.72 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05906621645005443		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.05906621645005443 | validation: 0.04744409387309972]
	TIME [epoch: 5.71 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048600249497823905		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.048600249497823905 | validation: 0.051029615488042246]
	TIME [epoch: 5.73 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053587709165570346		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.053587709165570346 | validation: 0.06375981969007379]
	TIME [epoch: 5.71 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07118321461451002		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.07118321461451002 | validation: 0.0885603694011553]
	TIME [epoch: 5.76 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947657208125605		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.0947657208125605 | validation: 0.060265900605438995]
	TIME [epoch: 5.72 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07954397176265081		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.07954397176265081 | validation: 0.039396492434085974]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057094144777422404		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.057094144777422404 | validation: 0.06271784094322522]
	TIME [epoch: 5.72 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06732791898599581		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.06732791898599581 | validation: 0.03663473868667221]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07832479342776771		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.07832479342776771 | validation: 0.08364093827355312]
	TIME [epoch: 5.71 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07343741881098431		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.07343741881098431 | validation: 0.09152314465935779]
	TIME [epoch: 5.75 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05884645915743715		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.05884645915743715 | validation: 0.054825934675694035]
	TIME [epoch: 5.74 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05983126663201791		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.05983126663201791 | validation: 0.03847362919183122]
	TIME [epoch: 5.73 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05584391603711677		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.05584391603711677 | validation: 0.06498275203980718]
	TIME [epoch: 5.71 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353786034328462		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.06353786034328462 | validation: 0.05234584924884732]
	TIME [epoch: 5.72 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059300848603783804		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.059300848603783804 | validation: 0.0695394099490826]
	TIME [epoch: 5.72 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06694941198554354		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.06694941198554354 | validation: 0.05013435364804224]
	TIME [epoch: 5.71 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058150933078451136		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.058150933078451136 | validation: 0.08114394650779644]
	TIME [epoch: 5.77 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06980410109430835		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.06980410109430835 | validation: 0.05856301112434022]
	TIME [epoch: 5.73 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07223728016478058		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.07223728016478058 | validation: 0.08043737669952204]
	TIME [epoch: 5.72 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119730869965004		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.08119730869965004 | validation: 0.09374662064324589]
	TIME [epoch: 5.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08694565527877865		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.08694565527877865 | validation: 0.07601867584224015]
	TIME [epoch: 5.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06927665037583047		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.06927665037583047 | validation: 0.04953619654341525]
	TIME [epoch: 5.71 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0620538507004627		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.0620538507004627 | validation: 0.05188234018832416]
	TIME [epoch: 5.72 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053812169822687037		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.053812169822687037 | validation: 0.037425187330247946]
	TIME [epoch: 5.75 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05050963462525051		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.05050963462525051 | validation: 0.04807787958017077]
	TIME [epoch: 5.72 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07852197949701406		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.07852197949701406 | validation: 0.05308085777416238]
	TIME [epoch: 5.73 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07606913725426195		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.07606913725426195 | validation: 0.07467708489028027]
	TIME [epoch: 5.73 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08370174587018224		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.08370174587018224 | validation: 0.04126005042367417]
	TIME [epoch: 5.72 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590291389171332		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.04590291389171332 | validation: 0.04736045596935504]
	TIME [epoch: 5.72 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04534962875991589		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.04534962875991589 | validation: 0.048860241116126545]
	TIME [epoch: 5.76 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0520422949198159		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.0520422949198159 | validation: 0.07383124087866186]
	TIME [epoch: 5.73 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.090301949056441		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.090301949056441 | validation: 0.10022494291306347]
	TIME [epoch: 5.71 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08389119226405903		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.08389119226405903 | validation: 0.07844923107379743]
	TIME [epoch: 5.72 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06700308353702801		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.06700308353702801 | validation: 0.05436169543021613]
	TIME [epoch: 5.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05845170350298177		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.05845170350298177 | validation: 0.06256680513347386]
	TIME [epoch: 5.71 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09889104648603217		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.09889104648603217 | validation: 0.051061128840718534]
	TIME [epoch: 5.72 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06800340352982612		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.06800340352982612 | validation: 0.06866031018096658]
	TIME [epoch: 5.75 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061136382473133286		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.061136382473133286 | validation: 0.06632018867326878]
	TIME [epoch: 5.71 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05501001070244799		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.05501001070244799 | validation: 0.03513067394572821]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06007140378206907		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.06007140378206907 | validation: 0.09543122688141915]
	TIME [epoch: 5.72 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0669644096134974		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.0669644096134974 | validation: 0.042887844811544173]
	TIME [epoch: 5.72 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05344733234226906		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.05344733234226906 | validation: 0.038883363438379115]
	TIME [epoch: 5.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055284892135606445		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.055284892135606445 | validation: 0.04896652914161518]
	TIME [epoch: 5.75 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08380286172991844		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.08380286172991844 | validation: 0.07455940114839649]
	TIME [epoch: 5.71 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0919550104723186		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.0919550104723186 | validation: 0.04950810318580357]
	TIME [epoch: 5.71 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06902557414321449		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.06902557414321449 | validation: 0.08237705625584459]
	TIME [epoch: 5.71 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0853987925355073		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.0853987925355073 | validation: 0.05709258797993338]
	TIME [epoch: 5.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0661172404269017		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.0661172404269017 | validation: 0.07982008817530045]
	TIME [epoch: 5.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09701462411692666		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.09701462411692666 | validation: 0.13563170265499888]
	TIME [epoch: 5.73 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458752648948367		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.12458752648948367 | validation: 0.10383351703074467]
	TIME [epoch: 5.74 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08819249646937316		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.08819249646937316 | validation: 0.09638426906698705]
	TIME [epoch: 5.73 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07691157990390972		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.07691157990390972 | validation: 0.08596456839377167]
	TIME [epoch: 5.71 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07375124889514051		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.07375124889514051 | validation: 0.060330458902521825]
	TIME [epoch: 5.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06119731931738234		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.06119731931738234 | validation: 0.09602611238808136]
	TIME [epoch: 5.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0923109119745739		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.0923109119745739 | validation: 0.07212930166434439]
	TIME [epoch: 5.72 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06302675500090166		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.06302675500090166 | validation: 0.07063540883188915]
	TIME [epoch: 5.75 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07745578757461138		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.07745578757461138 | validation: 0.06474958415610392]
	TIME [epoch: 5.71 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07672774951717251		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.07672774951717251 | validation: 0.057813525372497045]
	TIME [epoch: 5.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06711806969430426		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.06711806969430426 | validation: 0.10442847220536183]
	TIME [epoch: 5.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09824159477459474		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.09824159477459474 | validation: 0.046944300115870925]
	TIME [epoch: 5.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04860256350908822		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.04860256350908822 | validation: 0.05475187746645605]
	TIME [epoch: 5.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08280553430578776		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.08280553430578776 | validation: 0.07459324719554891]
	TIME [epoch: 5.73 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07246290649684167		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.07246290649684167 | validation: 0.11105185669345033]
	TIME [epoch: 5.74 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0838377650349547		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.0838377650349547 | validation: 0.05782937883184808]
	TIME [epoch: 5.71 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06691744613404721		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.06691744613404721 | validation: 0.07733440679520939]
	TIME [epoch: 5.72 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07612081191798573		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.07612081191798573 | validation: 0.0805225415184313]
	TIME [epoch: 5.71 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08203651167719672		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.08203651167719672 | validation: 0.07958638750877141]
	TIME [epoch: 5.71 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06996541386992029		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.06996541386992029 | validation: 0.07247555744078932]
	TIME [epoch: 5.71 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060121062367832684		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.060121062367832684 | validation: 0.04431450379864887]
	TIME [epoch: 5.76 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05550638608284847		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.05550638608284847 | validation: 0.04917230419679101]
	TIME [epoch: 5.71 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141364525549305		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.05141364525549305 | validation: 0.05537556336621836]
	TIME [epoch: 5.72 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061485838819840294		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.061485838819840294 | validation: 0.04521815688980978]
	TIME [epoch: 5.71 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07400329429678447		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.07400329429678447 | validation: 0.0441310768590315]
	TIME [epoch: 5.71 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05659191697289355		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.05659191697289355 | validation: 0.031088408803444746]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_664.pth
	Model improved!!!
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040803176619483926		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.040803176619483926 | validation: 0.041929674048121354]
	TIME [epoch: 5.73 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04424061754508891		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.04424061754508891 | validation: 0.03618329051197864]
	TIME [epoch: 5.73 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05033490465660237		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.05033490465660237 | validation: 0.031055462168675822]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0526846025691455		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.0526846025691455 | validation: 0.08525080218191455]
	TIME [epoch: 5.73 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08938328500589406		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.08938328500589406 | validation: 0.0995758882509545]
	TIME [epoch: 5.73 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11112162360408441		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.11112162360408441 | validation: 0.09706556493042992]
	TIME [epoch: 5.73 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08616638353776561		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.08616638353776561 | validation: 0.07847087955122177]
	TIME [epoch: 5.73 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08043353153182571		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.08043353153182571 | validation: 0.05611351786387877]
	TIME [epoch: 5.77 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08328091895326942		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.08328091895326942 | validation: 0.04891702782981161]
	TIME [epoch: 5.72 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07300732028676152		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.07300732028676152 | validation: 0.03182279288168014]
	TIME [epoch: 5.73 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05959098536811282		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.05959098536811282 | validation: 0.10162602327348093]
	TIME [epoch: 5.73 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0864595145149987		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.0864595145149987 | validation: 0.03904444425696083]
	TIME [epoch: 5.73 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058561904654358524		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.058561904654358524 | validation: 0.04658768858994778]
	TIME [epoch: 5.72 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05329817273492969		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.05329817273492969 | validation: 0.04546385880206165]
	TIME [epoch: 5.75 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049399750402965514		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.049399750402965514 | validation: 0.029516235961615806]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_679.pth
	Model improved!!!
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04439912129226248		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.04439912129226248 | validation: 0.04880982005184164]
	TIME [epoch: 5.73 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05991281296596163		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.05991281296596163 | validation: 0.04358300580360123]
	TIME [epoch: 5.72 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04658757327400553		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.04658757327400553 | validation: 0.030138641134634395]
	TIME [epoch: 5.73 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04289794549958018		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.04289794549958018 | validation: 0.04805325047730507]
	TIME [epoch: 5.74 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06441466135604496		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.06441466135604496 | validation: 0.07146971172524731]
	TIME [epoch: 5.73 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05187355327011121		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.05187355327011121 | validation: 0.05246722835423487]
	TIME [epoch: 5.77 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057462512824574895		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.057462512824574895 | validation: 0.047259454555880924]
	TIME [epoch: 5.73 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050461122025269034		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.050461122025269034 | validation: 0.03927533441243403]
	TIME [epoch: 5.73 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04689219363066664		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.04689219363066664 | validation: 0.03616737912936961]
	TIME [epoch: 5.73 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.064692846956314		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.064692846956314 | validation: 0.07391453217279968]
	TIME [epoch: 5.72 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05748437124947032		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.05748437124947032 | validation: 0.06457413590724607]
	TIME [epoch: 5.72 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08049013485569438		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.08049013485569438 | validation: 0.04630591366907554]
	TIME [epoch: 5.75 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062303626527039926		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.062303626527039926 | validation: 0.056841676244152824]
	TIME [epoch: 5.74 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055656925610791295		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.055656925610791295 | validation: 0.053964207041766396]
	TIME [epoch: 5.74 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058111847596270846		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.058111847596270846 | validation: 0.04555009152596602]
	TIME [epoch: 5.73 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057919365142615135		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.057919365142615135 | validation: 0.10135247094666419]
	TIME [epoch: 5.73 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09122392304520748		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.09122392304520748 | validation: 0.07554722144609005]
	TIME [epoch: 5.73 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06843729276810896		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.06843729276810896 | validation: 0.04212231137465255]
	TIME [epoch: 5.74 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04723733197769987		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.04723733197769987 | validation: 0.040905277830146226]
	TIME [epoch: 5.77 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045353795277741235		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.045353795277741235 | validation: 0.04001407425166962]
	TIME [epoch: 5.73 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049196751412025515		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.049196751412025515 | validation: 0.03250878423311039]
	TIME [epoch: 5.73 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04969533772663127		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.04969533772663127 | validation: 0.031190391648466934]
	TIME [epoch: 5.73 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04900015784860952		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.04900015784860952 | validation: 0.04162758295233848]
	TIME [epoch: 5.73 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07546259760497925		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.07546259760497925 | validation: 0.1156110121430466]
	TIME [epoch: 5.72 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08548944664068102		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.08548944664068102 | validation: 0.062237188543337735]
	TIME [epoch: 5.75 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05422255927029744		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.05422255927029744 | validation: 0.042731461508054396]
	TIME [epoch: 5.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04025746334941006		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.04025746334941006 | validation: 0.03322790925915839]
	TIME [epoch: 5.73 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04278472305214348		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.04278472305214348 | validation: 0.06340337520541471]
	TIME [epoch: 5.73 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05163413254758634		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.05163413254758634 | validation: 0.038013393717080506]
	TIME [epoch: 5.72 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04611773439810054		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.04611773439810054 | validation: 0.04261334371390017]
	TIME [epoch: 5.73 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06375625026054782		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.06375625026054782 | validation: 0.06793608310020523]
	TIME [epoch: 5.73 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07014946566396095		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.07014946566396095 | validation: 0.05841623268833821]
	TIME [epoch: 5.77 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038092285629416786		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.038092285629416786 | validation: 0.03626719317190637]
	TIME [epoch: 5.72 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04104141712295396		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.04104141712295396 | validation: 0.028445274294727315]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_713.pth
	Model improved!!!
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05512338609958583		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.05512338609958583 | validation: 0.04305580660894117]
	TIME [epoch: 5.72 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04781631348615789		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.04781631348615789 | validation: 0.03113029904164588]
	TIME [epoch: 5.73 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04137388875490171		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.04137388875490171 | validation: 0.048275920083318234]
	TIME [epoch: 5.73 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044359923457030354		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.044359923457030354 | validation: 0.05004997188946002]
	TIME [epoch: 5.76 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06668190850110961		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.06668190850110961 | validation: 0.08289846999328938]
	TIME [epoch: 5.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08244894900194802		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.08244894900194802 | validation: 0.048673031306706645]
	TIME [epoch: 5.72 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06389745090420741		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.06389745090420741 | validation: 0.03666379277008436]
	TIME [epoch: 5.72 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0556035933430995		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.0556035933430995 | validation: 0.06120889803070908]
	TIME [epoch: 5.72 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08731482554586392		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.08731482554586392 | validation: 0.04792424027771634]
	TIME [epoch: 5.73 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055086241651734286		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.055086241651734286 | validation: 0.048413418976558764]
	TIME [epoch: 5.74 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07158528648020372		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.07158528648020372 | validation: 0.05472068370977898]
	TIME [epoch: 5.75 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07782930547727435		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.07782930547727435 | validation: 0.04678762874258007]
	TIME [epoch: 5.72 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08701322319137554		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.08701322319137554 | validation: 0.07046023646880868]
	TIME [epoch: 5.72 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10330385914949945		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.10330385914949945 | validation: 0.04676684978361206]
	TIME [epoch: 5.72 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056326216359683226		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.056326216359683226 | validation: 0.030857418840546897]
	TIME [epoch: 5.72 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06674041830167958		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.06674041830167958 | validation: 0.03644154270574779]
	TIME [epoch: 5.73 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05537341703165678		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.05537341703165678 | validation: 0.0479213069028438]
	TIME [epoch: 5.77 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057584949509355894		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.057584949509355894 | validation: 0.056312035836609785]
	TIME [epoch: 5.73 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05579713635014166		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.05579713635014166 | validation: 0.0495947059573254]
	TIME [epoch: 5.73 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07509971136742456		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.07509971136742456 | validation: 0.08495642324708096]
	TIME [epoch: 5.73 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06469762903022008		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.06469762903022008 | validation: 0.056123558570575736]
	TIME [epoch: 5.72 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06006983277340982		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.06006983277340982 | validation: 0.03656536764044386]
	TIME [epoch: 5.72 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053560410410261314		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.053560410410261314 | validation: 0.031135537803891663]
	TIME [epoch: 5.73 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05349954270619332		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.05349954270619332 | validation: 0.05055805759376151]
	TIME [epoch: 5.76 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04481925514062554		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.04481925514062554 | validation: 0.04382195411437641]
	TIME [epoch: 5.73 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07412598441971938		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.07412598441971938 | validation: 0.04832179102171796]
	TIME [epoch: 5.72 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05201676745739059		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.05201676745739059 | validation: 0.05451224351276831]
	TIME [epoch: 5.72 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08583657026574254		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.08583657026574254 | validation: 0.03511286937065782]
	TIME [epoch: 5.72 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05225592230159893		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.05225592230159893 | validation: 0.03904645167812002]
	TIME [epoch: 5.72 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04362745682380968		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.04362745682380968 | validation: 0.039863274086070856]
	TIME [epoch: 5.77 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049746773881605366		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.049746773881605366 | validation: 0.03514750138889608]
	TIME [epoch: 5.73 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278507391477126		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.06278507391477126 | validation: 0.05307682332003529]
	TIME [epoch: 5.72 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06949040201461752		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.06949040201461752 | validation: 0.05372082882464138]
	TIME [epoch: 5.73 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039833958420880784		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.039833958420880784 | validation: 0.04022544116509596]
	TIME [epoch: 5.72 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04381092716142233		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.04381092716142233 | validation: 0.03751755449055384]
	TIME [epoch: 5.72 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04616302973910289		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.04616302973910289 | validation: 0.034062814269141976]
	TIME [epoch: 5.74 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051459604555792404		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.051459604555792404 | validation: 0.022945325790451793]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_750.pth
	Model improved!!!
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03935443073405853		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.03935443073405853 | validation: 0.03204436183968052]
	TIME [epoch: 5.73 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05043677010511084		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.05043677010511084 | validation: 0.04785656293519422]
	TIME [epoch: 5.72 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06812024596502253		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.06812024596502253 | validation: 0.05687753416950045]
	TIME [epoch: 5.72 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052513172611285415		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.052513172611285415 | validation: 0.03514427282254589]
	TIME [epoch: 5.72 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03780313377975354		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.03780313377975354 | validation: 0.03267052814347236]
	TIME [epoch: 5.72 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04368222353652614		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.04368222353652614 | validation: 0.02941017824704681]
	TIME [epoch: 5.76 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0430154326415447		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.0430154326415447 | validation: 0.03933665875766334]
	TIME [epoch: 5.74 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03955762531315875		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.03955762531315875 | validation: 0.032201484670557376]
	TIME [epoch: 5.72 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731118687435669		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.04731118687435669 | validation: 0.038305270494875886]
	TIME [epoch: 5.72 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04157079008475306		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.04157079008475306 | validation: 0.03340499781297433]
	TIME [epoch: 5.72 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04717693939673809		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.04717693939673809 | validation: 0.06842835734643032]
	TIME [epoch: 5.72 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05279317027817809		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.05279317027817809 | validation: 0.03711368100862014]
	TIME [epoch: 5.74 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045948035931708146		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.045948035931708146 | validation: 0.046427749762065346]
	TIME [epoch: 5.76 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0517969571997976		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0517969571997976 | validation: 0.03971033220689323]
	TIME [epoch: 5.72 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056173132259625475		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.056173132259625475 | validation: 0.041476318222872045]
	TIME [epoch: 5.73 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08576260833743637		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.08576260833743637 | validation: 0.053602246024375945]
	TIME [epoch: 5.72 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056140500110786376		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.056140500110786376 | validation: 0.025669667544246124]
	TIME [epoch: 5.72 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05405062334682138		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.05405062334682138 | validation: 0.05037243789750976]
	TIME [epoch: 5.72 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05101674395232633		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.05101674395232633 | validation: 0.02946934258200237]
	TIME [epoch: 5.76 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038231051859697184		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.038231051859697184 | validation: 0.040342896526237515]
	TIME [epoch: 5.73 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045691597259866046		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.045691597259866046 | validation: 0.04750197276915618]
	TIME [epoch: 5.73 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06968778232697548		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.06968778232697548 | validation: 0.05442074850079672]
	TIME [epoch: 5.72 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0688307333257053		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.0688307333257053 | validation: 0.061266068400736486]
	TIME [epoch: 5.72 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07493341546679266		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.07493341546679266 | validation: 0.042341619578162265]
	TIME [epoch: 5.72 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051669288612198994		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.051669288612198994 | validation: 0.05451979782449191]
	TIME [epoch: 5.74 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039559689048801555		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.039559689048801555 | validation: 0.036026626451141824]
	TIME [epoch: 5.75 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04384476897882751		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.04384476897882751 | validation: 0.034690481850604464]
	TIME [epoch: 5.72 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05334627666766274		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.05334627666766274 | validation: 0.04042757036590832]
	TIME [epoch: 5.72 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047612157012053784		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.047612157012053784 | validation: 0.046764116788542]
	TIME [epoch: 5.72 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057529318214753586		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.057529318214753586 | validation: 0.049492870425126546]
	TIME [epoch: 5.72 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06910287483686958		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.06910287483686958 | validation: 0.05085687378447444]
	TIME [epoch: 5.72 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04704663252214027		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.04704663252214027 | validation: 0.06005208724301129]
	TIME [epoch: 5.76 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647271061451037		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.0647271061451037 | validation: 0.04407358301363674]
	TIME [epoch: 5.73 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04701863814198067		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.04701863814198067 | validation: 0.05169683692721442]
	TIME [epoch: 5.72 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06534511567746701		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.06534511567746701 | validation: 0.06234315739382812]
	TIME [epoch: 5.72 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845080711860406		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.06845080711860406 | validation: 0.0441582542241834]
	TIME [epoch: 5.72 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04127898306293054		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.04127898306293054 | validation: 0.02578925977466046]
	TIME [epoch: 5.72 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050430321533898606		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.050430321533898606 | validation: 0.03445806181341481]
	TIME [epoch: 5.73 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05176067998499598		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.05176067998499598 | validation: 0.06686969314312523]
	TIME [epoch: 5.76 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04734450882477809		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.04734450882477809 | validation: 0.04214899208435565]
	TIME [epoch: 5.73 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04459684528345103		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.04459684528345103 | validation: 0.033518490133251276]
	TIME [epoch: 5.72 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03355646805087784		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.03355646805087784 | validation: 0.02946385842381275]
	TIME [epoch: 5.72 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04470625401918712		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.04470625401918712 | validation: 0.03900997778782957]
	TIME [epoch: 5.72 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04646928934980732		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.04646928934980732 | validation: 0.05539030435522644]
	TIME [epoch: 5.72 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04386685569527598		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.04386685569527598 | validation: 0.028422609474269077]
	TIME [epoch: 5.76 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03398962410533567		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.03398962410533567 | validation: 0.031729349566488416]
	TIME [epoch: 5.73 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06295551251066664		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.06295551251066664 | validation: 0.04766156392429185]
	TIME [epoch: 5.72 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07557828692444876		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.07557828692444876 | validation: 0.07685592323635713]
	TIME [epoch: 5.72 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09041132116568229		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.09041132116568229 | validation: 0.05632011331043479]
	TIME [epoch: 5.72 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0675679629667705		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.0675679629667705 | validation: 0.056042376496965536]
	TIME [epoch: 5.72 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05707991207316804		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.05707991207316804 | validation: 0.03419666166491119]
	TIME [epoch: 5.73 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04654870526135445		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.04654870526135445 | validation: 0.034022637600958076]
	TIME [epoch: 5.76 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04849611860836259		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.04849611860836259 | validation: 0.03675814373199428]
	TIME [epoch: 5.73 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06852776450831584		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.06852776450831584 | validation: 0.05287222939449894]
	TIME [epoch: 5.72 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06135251762704931		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.06135251762704931 | validation: 0.04964982311524585]
	TIME [epoch: 5.71 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838799299507911		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.08838799299507911 | validation: 0.08240630637665024]
	TIME [epoch: 5.72 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08646072405551536		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.08646072405551536 | validation: 0.10741678489439718]
	TIME [epoch: 5.72 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10841198747678235		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.10841198747678235 | validation: 0.10150603773068138]
	TIME [epoch: 5.76 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08802234523947419		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.08802234523947419 | validation: 0.04108509413405897]
	TIME [epoch: 5.73 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05151975573960764		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.05151975573960764 | validation: 0.0483153848345094]
	TIME [epoch: 5.72 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06497606408200882		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.06497606408200882 | validation: 0.05434820064843155]
	TIME [epoch: 5.72 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0895092604856984		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.0895092604856984 | validation: 0.05592737836667142]
	TIME [epoch: 5.72 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08151430230154391		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.08151430230154391 | validation: 0.04517111866888922]
	TIME [epoch: 5.72 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05616061444477575		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.05616061444477575 | validation: 0.033574549964548506]
	TIME [epoch: 5.73 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045107704822007544		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.045107704822007544 | validation: 0.03459338760428792]
	TIME [epoch: 5.75 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04349009826949754		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.04349009826949754 | validation: 0.03481117183383007]
	TIME [epoch: 5.73 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045674800111016545		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.045674800111016545 | validation: 0.04428483837845204]
	TIME [epoch: 5.72 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047725707983613044		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.047725707983613044 | validation: 0.06443026080169903]
	TIME [epoch: 5.72 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07621633707265503		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.07621633707265503 | validation: 0.053179383439888074]
	TIME [epoch: 5.72 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05879958304218892		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.05879958304218892 | validation: 0.030207639528168084]
	TIME [epoch: 5.72 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03466773138864202		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.03466773138864202 | validation: 0.029691343210134512]
	TIME [epoch: 5.76 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05147045429610846		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.05147045429610846 | validation: 0.03193118103570462]
	TIME [epoch: 5.73 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568530256509458		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.03568530256509458 | validation: 0.029693117059922197]
	TIME [epoch: 5.73 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03681905886682286		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.03681905886682286 | validation: 0.03224855852574295]
	TIME [epoch: 5.72 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04041251685993427		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.04041251685993427 | validation: 0.02595022372261716]
	TIME [epoch: 5.73 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04371782248391608		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.04371782248391608 | validation: 0.032112896088151106]
	TIME [epoch: 5.73 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03689065141217418		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.03689065141217418 | validation: 0.022869185212520453]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_827.pth
	Model improved!!!
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04373595262575215		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.04373595262575215 | validation: 0.043843983254194294]
	TIME [epoch: 5.75 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04604752877563835		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.04604752877563835 | validation: 0.06287376066015699]
	TIME [epoch: 5.71 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07582609121747266		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.07582609121747266 | validation: 0.06289004409400914]
	TIME [epoch: 5.71 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494390426223773		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.06494390426223773 | validation: 0.03789199010068664]
	TIME [epoch: 5.72 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04190234138914892		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.04190234138914892 | validation: 0.025679660866888172]
	TIME [epoch: 5.72 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04770057072977832		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.04770057072977832 | validation: 0.04864677598303953]
	TIME [epoch: 5.71 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07580679140185856		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.07580679140185856 | validation: 0.05060601141340163]
	TIME [epoch: 5.75 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06311245125415639		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.06311245125415639 | validation: 0.044516480191755636]
	TIME [epoch: 5.72 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05427978051173562		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.05427978051173562 | validation: 0.04611366917005217]
	TIME [epoch: 5.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05837563711856089		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.05837563711856089 | validation: 0.023228045433170315]
	TIME [epoch: 5.72 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04473937026033973		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.04473937026033973 | validation: 0.029265626458660078]
	TIME [epoch: 5.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04009776863121625		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.04009776863121625 | validation: 0.028697051083737924]
	TIME [epoch: 5.73 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03806283264889299		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.03806283264889299 | validation: 0.03286179569433746]
	TIME [epoch: 5.73 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034616898879734924		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.034616898879734924 | validation: 0.030687816291954877]
	TIME [epoch: 5.76 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048664902998383955		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.048664902998383955 | validation: 0.034254186779819826]
	TIME [epoch: 5.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041757801121545354		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.041757801121545354 | validation: 0.039840140427522715]
	TIME [epoch: 5.72 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0418001218039677		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.0418001218039677 | validation: 0.026088828725954877]
	TIME [epoch: 5.71 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04148757938305101		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.04148757938305101 | validation: 0.048712446354482464]
	TIME [epoch: 5.73 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0742776499762232		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.0742776499762232 | validation: 0.10652786034730122]
	TIME [epoch: 5.71 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07884235564146794		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.07884235564146794 | validation: 0.030478864710388135]
	TIME [epoch: 5.75 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04428123697230094		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.04428123697230094 | validation: 0.046482488654557945]
	TIME [epoch: 5.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051676251346437115		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.051676251346437115 | validation: 0.0342654449984306]
	TIME [epoch: 5.72 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733051278192009		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.04733051278192009 | validation: 0.04052294719002543]
	TIME [epoch: 5.71 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042100858953399885		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.042100858953399885 | validation: 0.027547186233542388]
	TIME [epoch: 5.72 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040483639191154254		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.040483639191154254 | validation: 0.027620820010038023]
	TIME [epoch: 5.71 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030625676957103394		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.030625676957103394 | validation: 0.02300023646499047]
	TIME [epoch: 5.72 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03577054115192317		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.03577054115192317 | validation: 0.028388751002807987]
	TIME [epoch: 5.74 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03303498826818086		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.03303498826818086 | validation: 0.033452203087288905]
	TIME [epoch: 5.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036771699981131084		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.036771699981131084 | validation: 0.029302161267968422]
	TIME [epoch: 5.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04036926208706189		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.04036926208706189 | validation: 0.022994416716503166]
	TIME [epoch: 5.71 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044482368775114765		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.044482368775114765 | validation: 0.04971889743354543]
	TIME [epoch: 5.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05352641700937261		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.05352641700937261 | validation: 0.02622106216813532]
	TIME [epoch: 5.71 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04587020458912887		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.04587020458912887 | validation: 0.02856802039165948]
	TIME [epoch: 5.75 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414359379317573		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.03414359379317573 | validation: 0.030635029576735962]
	TIME [epoch: 5.71 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030340707601140212		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.030340707601140212 | validation: 0.023737010958899258]
	TIME [epoch: 5.71 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03677703414875591		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.03677703414875591 | validation: 0.03274176775334748]
	TIME [epoch: 5.71 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04081392070158678		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.04081392070158678 | validation: 0.040353106845851555]
	TIME [epoch: 5.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06155338214656665		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.06155338214656665 | validation: 0.031032693954558807]
	TIME [epoch: 5.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03932644564372923		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.03932644564372923 | validation: 0.028147313913130773]
	TIME [epoch: 5.71 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036758201536150566		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.036758201536150566 | validation: 0.05589016490055653]
	TIME [epoch: 5.74 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051500003839934874		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.051500003839934874 | validation: 0.038419927193729095]
	TIME [epoch: 5.73 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04740226061508959		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.04740226061508959 | validation: 0.0316933016831765]
	TIME [epoch: 5.71 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03548344190966012		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.03548344190966012 | validation: 0.02242462563160273]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_870.pth
	Model improved!!!
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043597446975033496		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.043597446975033496 | validation: 0.05389475485455968]
	TIME [epoch: 5.71 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05531484969390607		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.05531484969390607 | validation: 0.029942074898255316]
	TIME [epoch: 5.73 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03281371679022334		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.03281371679022334 | validation: 0.045206428857722705]
	TIME [epoch: 5.74 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05805712404964366		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.05805712404964366 | validation: 0.029495096037854555]
	TIME [epoch: 5.71 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03695102583090168		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.03695102583090168 | validation: 0.02675938080225201]
	TIME [epoch: 5.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04397731685535595		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.04397731685535595 | validation: 0.03310435199341176]
	TIME [epoch: 5.71 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05494340104423579		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.05494340104423579 | validation: 0.035126676552398976]
	TIME [epoch: 5.71 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043464821212026675		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.043464821212026675 | validation: 0.02183247193508234]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_878.pth
	Model improved!!!
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03944324419795463		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.03944324419795463 | validation: 0.030083083999826555]
	TIME [epoch: 5.74 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033532912154386106		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.033532912154386106 | validation: 0.02706004912064267]
	TIME [epoch: 5.74 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033619536533734694		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.033619536533734694 | validation: 0.022588207697997856]
	TIME [epoch: 5.72 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038315744594878465		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.038315744594878465 | validation: 0.038420978007280775]
	TIME [epoch: 5.71 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04056892930455409		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.04056892930455409 | validation: 0.041906824943493605]
	TIME [epoch: 5.72 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05025492226177179		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.05025492226177179 | validation: 0.058813813886998786]
	TIME [epoch: 5.72 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05947389951858474		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.05947389951858474 | validation: 0.040640855911034904]
	TIME [epoch: 5.72 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07020977091321853		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.07020977091321853 | validation: 0.0384751048821116]
	TIME [epoch: 5.77 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07195641733516606		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.07195641733516606 | validation: 0.048816115769272084]
	TIME [epoch: 5.71 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05243796635291275		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.05243796635291275 | validation: 0.04323241674739407]
	TIME [epoch: 5.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05092684052556794		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.05092684052556794 | validation: 0.03217415500485852]
	TIME [epoch: 5.72 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040085232456042494		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.040085232456042494 | validation: 0.03247233055370732]
	TIME [epoch: 5.69 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03931542034284854		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.03931542034284854 | validation: 0.03652288303203024]
	TIME [epoch: 5.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038850146139571703		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.038850146139571703 | validation: 0.03506568695765041]
	TIME [epoch: 5.75 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0497721942980444		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.0497721942980444 | validation: 0.04286911665928311]
	TIME [epoch: 5.74 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038693391471576605		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.038693391471576605 | validation: 0.016984676654012435]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_894.pth
	Model improved!!!
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036783714495286585		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.036783714495286585 | validation: 0.02717124470164272]
	TIME [epoch: 5.72 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568227588065445		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.03568227588065445 | validation: 0.03348800757967013]
	TIME [epoch: 5.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04227939476194045		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.04227939476194045 | validation: 0.031010221461328067]
	TIME [epoch: 5.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03380442966297964		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.03380442966297964 | validation: 0.028637542419099653]
	TIME [epoch: 5.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033932244378583123		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.033932244378583123 | validation: 0.034688099875806774]
	TIME [epoch: 5.77 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335228317298243		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.0335228317298243 | validation: 0.03903637388690918]
	TIME [epoch: 5.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034639562305940286		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.034639562305940286 | validation: 0.03951183034691184]
	TIME [epoch: 5.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039100019926713254		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.039100019926713254 | validation: 0.03097568957584237]
	TIME [epoch: 5.71 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033147653616964534		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.033147653616964534 | validation: 0.031233973125891927]
	TIME [epoch: 5.72 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03061760361306093		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.03061760361306093 | validation: 0.028866476351262407]
	TIME [epoch: 5.71 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04254621754272279		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.04254621754272279 | validation: 0.022290892520214413]
	TIME [epoch: 5.73 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053448500778723956		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.053448500778723956 | validation: 0.05589548515337551]
	TIME [epoch: 5.72 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06413621139028675		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.06413621139028675 | validation: 0.06460306405098619]
	TIME [epoch: 5.71 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0652883501297698		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.0652883501297698 | validation: 0.08087464361758506]
	TIME [epoch: 5.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05924448218518249		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.05924448218518249 | validation: 0.06828541243921475]
	TIME [epoch: 5.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05256427917354205		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.05256427917354205 | validation: 0.050634170405880176]
	TIME [epoch: 5.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041964994885817876		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.041964994885817876 | validation: 0.03657769852456339]
	TIME [epoch: 5.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044397409087700894		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.044397409087700894 | validation: 0.055201710397465166]
	TIME [epoch: 5.75 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047061697803720895		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.047061697803720895 | validation: 0.038772988076321166]
	TIME [epoch: 5.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04083522524721658		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.04083522524721658 | validation: 0.04670555823622713]
	TIME [epoch: 5.72 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05404640567485505		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.05404640567485505 | validation: 0.03957584918217043]
	TIME [epoch: 5.72 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050708499173250474		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.050708499173250474 | validation: 0.035021311394791976]
	TIME [epoch: 5.72 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262981221803832		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.04262981221803832 | validation: 0.03282822543933732]
	TIME [epoch: 5.72 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04003653249598718		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.04003653249598718 | validation: 0.031209269298102128]
	TIME [epoch: 5.75 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033718586840635716		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.033718586840635716 | validation: 0.024482866673818417]
	TIME [epoch: 5.74 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558365000558681		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.03558365000558681 | validation: 0.02903083985047708]
	TIME [epoch: 5.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03573185019980996		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.03573185019980996 | validation: 0.02126447167227056]
	TIME [epoch: 5.72 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031888932095877266		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.031888932095877266 | validation: 0.026292932741081965]
	TIME [epoch: 5.72 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03448367780182731		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.03448367780182731 | validation: 0.038446242326968486]
	TIME [epoch: 5.72 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042867955204908555		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.042867955204908555 | validation: 0.047498703079694664]
	TIME [epoch: 5.72 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032036630233933217		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.032036630233933217 | validation: 0.03552592717226792]
	TIME [epoch: 5.78 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03246740726855614		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.03246740726855614 | validation: 0.02702200752409295]
	TIME [epoch: 5.72 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032194165530578404		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.032194165530578404 | validation: 0.030620344007986054]
	TIME [epoch: 5.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052608347228338605		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.052608347228338605 | validation: 0.0435369079328118]
	TIME [epoch: 5.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05725373877926933		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.05725373877926933 | validation: 0.05063881465205773]
	TIME [epoch: 5.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044984424456704974		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.044984424456704974 | validation: 0.031319112456868255]
	TIME [epoch: 5.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033291252566258964		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.033291252566258964 | validation: 0.03321137518799373]
	TIME [epoch: 5.72 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04010318365568222		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.04010318365568222 | validation: 0.06923878337616966]
	TIME [epoch: 5.72 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04702492875570369		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.04702492875570369 | validation: 0.05525501627894649]
	TIME [epoch: 5.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050048696634381155		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.050048696634381155 | validation: 0.046378209574284235]
	TIME [epoch: 5.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040965872606840675		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.040965872606840675 | validation: 0.03443303509236787]
	TIME [epoch: 5.69 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028368265942399676		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.028368265942399676 | validation: 0.04132067705159009]
	TIME [epoch: 5.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0358242207105802		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.0358242207105802 | validation: 0.04075163581684762]
	TIME [epoch: 5.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04451382824244437		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.04451382824244437 | validation: 0.04349505005231089]
	TIME [epoch: 5.74 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033915657709717384		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.033915657709717384 | validation: 0.03629848768595655]
	TIME [epoch: 5.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044005427168416544		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.044005427168416544 | validation: 0.034193746275903374]
	TIME [epoch: 5.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040065215515831344		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.040065215515831344 | validation: 0.037022413328312305]
	TIME [epoch: 5.69 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03515448395057396		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.03515448395057396 | validation: 0.033678354172407436]
	TIME [epoch: 5.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03813171129630852		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.03813171129630852 | validation: 0.02299180023337208]
	TIME [epoch: 5.71 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0327981398577067		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.0327981398577067 | validation: 0.038798392266658925]
	TIME [epoch: 5.72 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050480674503620905		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.050480674503620905 | validation: 0.04524333046845917]
	TIME [epoch: 5.73 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0598975907981246		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0598975907981246 | validation: 0.05319775998379198]
	TIME [epoch: 5.71 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367511605311466		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.06367511605311466 | validation: 0.06624035894623076]
	TIME [epoch: 5.72 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06241192608072518		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.06241192608072518 | validation: 0.04475628905166941]
	TIME [epoch: 5.71 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05154837380667139		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.05154837380667139 | validation: 0.04227462685116381]
	TIME [epoch: 5.71 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038442951078331004		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.038442951078331004 | validation: 0.026742619980628622]
	TIME [epoch: 5.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03321199417072366		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.03321199417072366 | validation: 0.034255497812409094]
	TIME [epoch: 5.74 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045337560587987394		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.045337560587987394 | validation: 0.03186515040062196]
	TIME [epoch: 5.71 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04835528302146204		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.04835528302146204 | validation: 0.03666494122346269]
	TIME [epoch: 5.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04049144920919624		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.04049144920919624 | validation: 0.029117180773013843]
	TIME [epoch: 5.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03286604342158734		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.03286604342158734 | validation: 0.018906645010759896]
	TIME [epoch: 5.71 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034246567515780736		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.034246567515780736 | validation: 0.03273330709058134]
	TIME [epoch: 5.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036083332290064885		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.036083332290064885 | validation: 0.0343445903891307]
	TIME [epoch: 5.71 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0403618696990599		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.0403618696990599 | validation: 0.0259152541597064]
	TIME [epoch: 5.73 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03453277202735182		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.03453277202735182 | validation: 0.03636261694102164]
	TIME [epoch: 5.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738783319442274		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.03738783319442274 | validation: 0.022497575747521648]
	TIME [epoch: 5.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033511618056676344		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.033511618056676344 | validation: 0.018857834986651875]
	TIME [epoch: 5.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581464808555723		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.03581464808555723 | validation: 0.024514316483678904]
	TIME [epoch: 5.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04171099539658688		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.04171099539658688 | validation: 0.042178449537975206]
	TIME [epoch: 5.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03583362012071052		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.03583362012071052 | validation: 0.015151625193207435]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_964.pth
	Model improved!!!
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03468050721223684		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.03468050721223684 | validation: 0.03401106552921809]
	TIME [epoch: 5.72 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048183337934549764		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.048183337934549764 | validation: 0.03414136162738022]
	TIME [epoch: 5.71 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033804841688117315		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.033804841688117315 | validation: 0.04048079470854402]
	TIME [epoch: 5.72 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03567152483183688		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.03567152483183688 | validation: 0.03511284784243864]
	TIME [epoch: 5.72 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04547983400770894		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.04547983400770894 | validation: 0.04375618280692733]
	TIME [epoch: 5.71 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05751154136605491		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.05751154136605491 | validation: 0.04391483561476135]
	TIME [epoch: 5.74 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04423017411526537		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.04423017411526537 | validation: 0.03598938196833342]
	TIME [epoch: 5.73 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04028830387683637		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.04028830387683637 | validation: 0.028118797203876413]
	TIME [epoch: 5.71 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04228272041371958		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.04228272041371958 | validation: 0.03366327606636744]
	TIME [epoch: 5.71 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0387781599713343		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0387781599713343 | validation: 0.038068580988801684]
	TIME [epoch: 5.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046112674220798525		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.046112674220798525 | validation: 0.03247579613043646]
	TIME [epoch: 5.71 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04282209180344001		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.04282209180344001 | validation: 0.026019894747521994]
	TIME [epoch: 5.71 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03224109465380053		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.03224109465380053 | validation: 0.022263628174767947]
	TIME [epoch: 5.75 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025027573129468145		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.025027573129468145 | validation: 0.026193274861723365]
	TIME [epoch: 5.71 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032426795656825866		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.032426795656825866 | validation: 0.020827974169046956]
	TIME [epoch: 5.71 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029740005816637508		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.029740005816637508 | validation: 0.03679841198460089]
	TIME [epoch: 5.72 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032991763151535305		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.032991763151535305 | validation: 0.031950272560190916]
	TIME [epoch: 5.72 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03857907411393165		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.03857907411393165 | validation: 0.04303776387998555]
	TIME [epoch: 5.71 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03410163177715377		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.03410163177715377 | validation: 0.02475403171053478]
	TIME [epoch: 5.71 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02797820601523278		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.02797820601523278 | validation: 0.026863184626602563]
	TIME [epoch: 5.73 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02682758009941666		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.02682758009941666 | validation: 0.011388594981456097]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_985.pth
	Model improved!!!
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0352420991939504		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.0352420991939504 | validation: 0.02699961946239201]
	TIME [epoch: 5.71 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533198530531943		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.03533198530531943 | validation: 0.02757782802367653]
	TIME [epoch: 5.72 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033105906474305447		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.033105906474305447 | validation: 0.020747135542891284]
	TIME [epoch: 5.71 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127838187231127		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.03127838187231127 | validation: 0.023377051487321464]
	TIME [epoch: 5.71 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026313787013329874		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.026313787013329874 | validation: 0.02763516816710903]
	TIME [epoch: 5.74 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03556043024037115		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.03556043024037115 | validation: 0.03807923821284103]
	TIME [epoch: 5.72 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040427265142453074		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.040427265142453074 | validation: 0.03211274657790424]
	TIME [epoch: 5.72 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0390787619680299		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.0390787619680299 | validation: 0.02371921425462206]
	TIME [epoch: 5.71 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414171649462124		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.03414171649462124 | validation: 0.026879565608621887]
	TIME [epoch: 5.71 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03493004842484702		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.03493004842484702 | validation: 0.03027698091598179]
	TIME [epoch: 5.71 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035515062729567955		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.035515062729567955 | validation: 0.04233487872182298]
	TIME [epoch: 5.73 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04302708020146085		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.04302708020146085 | validation: 0.027550012966817094]
	TIME [epoch: 5.72 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052629684404163844		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.052629684404163844 | validation: 0.03309734232019446]
	TIME [epoch: 5.71 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038046621737424374		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.038046621737424374 | validation: 0.037825089377001755]
	TIME [epoch: 5.71 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03953994013529429		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.03953994013529429 | validation: 0.03191905752145486]
	TIME [epoch: 5.71 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03883457320406317		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.03883457320406317 | validation: 0.02711571626010806]
	TIME [epoch: 5.71 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030165140399704856		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.030165140399704856 | validation: 0.026682286372230257]
	TIME [epoch: 5.71 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029572926147424735		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.029572926147424735 | validation: 0.022566886173464855]
	TIME [epoch: 5.76 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02885026115866849		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.02885026115866849 | validation: 0.031094305010312146]
	TIME [epoch: 5.71 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029705140779110295		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.029705140779110295 | validation: 0.03350395699527646]
	TIME [epoch: 5.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0341894818851563		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.0341894818851563 | validation: 0.025227096707928283]
	TIME [epoch: 5.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04041795114982351		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.04041795114982351 | validation: 0.02048147736641716]
	TIME [epoch: 5.71 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03021139200229357		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.03021139200229357 | validation: 0.017468233851376146]
	TIME [epoch: 5.71 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03453232050264793		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.03453232050264793 | validation: 0.02319559050582124]
	TIME [epoch: 5.75 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03281376098545397		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.03281376098545397 | validation: 0.033020906855261795]
	TIME [epoch: 5.73 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031698830844866285		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.031698830844866285 | validation: 0.026869981602250598]
	TIME [epoch: 5.72 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03718146285814664		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.03718146285814664 | validation: 0.02795484732190716]
	TIME [epoch: 5.72 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03376660998786761		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.03376660998786761 | validation: 0.027565060109031293]
	TIME [epoch: 5.71 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03192169251788486		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.03192169251788486 | validation: 0.022354736254808768]
	TIME [epoch: 5.72 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02870694173477023		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.02870694173477023 | validation: 0.03680892020553482]
	TIME [epoch: 5.71 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150611037327261		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.03150611037327261 | validation: 0.024278931296400838]
	TIME [epoch: 5.75 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03939557289328377		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.03939557289328377 | validation: 0.034295793865209964]
	TIME [epoch: 5.72 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04819067621262111		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.04819067621262111 | validation: 0.04721394374103464]
	TIME [epoch: 5.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04937368193845213		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.04937368193845213 | validation: 0.03727594587522149]
	TIME [epoch: 5.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035480841705712016		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.035480841705712016 | validation: 0.025105425632425606]
	TIME [epoch: 5.72 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03519832601229404		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.03519832601229404 | validation: 0.02662212953858716]
	TIME [epoch: 5.72 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03518951314813956		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.03518951314813956 | validation: 0.03561456408856055]
	TIME [epoch: 5.75 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038099348117871114		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.038099348117871114 | validation: 0.03847614052226965]
	TIME [epoch: 5.74 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038408329426039584		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.038408329426039584 | validation: 0.04032057614255374]
	TIME [epoch: 5.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04442913745319501		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.04442913745319501 | validation: 0.04718691531322753]
	TIME [epoch: 5.72 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04116208939794133		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.04116208939794133 | validation: 0.050248668407465724]
	TIME [epoch: 5.71 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041396815521003		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.041396815521003 | validation: 0.027194746651199572]
	TIME [epoch: 5.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03540655833412719		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.03540655833412719 | validation: 0.02247642471311008]
	TIME [epoch: 5.71 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02804538908890364		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.02804538908890364 | validation: 0.029264149188492662]
	TIME [epoch: 5.76 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03236727125077146		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.03236727125077146 | validation: 0.04037813963993783]
	TIME [epoch: 5.71 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03940050514581675		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.03940050514581675 | validation: 0.03830306465311507]
	TIME [epoch: 5.72 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03199806533803454		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.03199806533803454 | validation: 0.03406197751866977]
	TIME [epoch: 5.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031324830893303096		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.031324830893303096 | validation: 0.029142859115474685]
	TIME [epoch: 5.71 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028296335465610795		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.028296335465610795 | validation: 0.0234877256155186]
	TIME [epoch: 5.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030207201220509114		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.030207201220509114 | validation: 0.024981395333271105]
	TIME [epoch: 5.73 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02760717662042043		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.02760717662042043 | validation: 0.029432434311308705]
	TIME [epoch: 5.75 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027546759119208702		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.027546759119208702 | validation: 0.029556365798192492]
	TIME [epoch: 5.71 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026822608614192528		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.026822608614192528 | validation: 0.02886200657769013]
	TIME [epoch: 5.71 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028210753322927128		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.028210753322927128 | validation: 0.01978319242725545]
	TIME [epoch: 5.72 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03247207867016263		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.03247207867016263 | validation: 0.027826194811217363]
	TIME [epoch: 5.71 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041731617889484145		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.041731617889484145 | validation: 0.025523233901971882]
	TIME [epoch: 5.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032117714716281394		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.032117714716281394 | validation: 0.023293339094228958]
	TIME [epoch: 5.75 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127275468513449		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.03127275468513449 | validation: 0.027854785855681748]
	TIME [epoch: 5.71 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02661117233005187		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.02661117233005187 | validation: 0.02587348317734828]
	TIME [epoch: 5.71 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02677342715378831		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.02677342715378831 | validation: 0.02972704535855107]
	TIME [epoch: 5.71 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032591650604847575		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.032591650604847575 | validation: 0.02357920024188471]
	TIME [epoch: 5.71 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029536268061306957		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.029536268061306957 | validation: 0.023041016790462]
	TIME [epoch: 5.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02954354521039748		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.02954354521039748 | validation: 0.030402619657734]
	TIME [epoch: 5.72 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02959827681126049		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.02959827681126049 | validation: 0.01898114723242427]
	TIME [epoch: 5.75 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029844475501026407		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.029844475501026407 | validation: 0.026267380261449032]
	TIME [epoch: 5.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028230765204115542		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.028230765204115542 | validation: 0.03273463695793393]
	TIME [epoch: 5.72 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035929520096462136		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.035929520096462136 | validation: 0.02958480427443334]
	TIME [epoch: 5.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030866941615014534		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.030866941615014534 | validation: 0.03558459846830385]
	TIME [epoch: 5.71 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03686184348207483		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.03686184348207483 | validation: 0.036559012080604844]
	TIME [epoch: 5.71 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027276077625139786		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.027276077625139786 | validation: 0.0223156289215414]
	TIME [epoch: 5.75 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030765219847016592		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.030765219847016592 | validation: 0.035439524069904124]
	TIME [epoch: 5.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034218708732627015		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.034218708732627015 | validation: 0.03243336809693252]
	TIME [epoch: 5.71 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03639565102272472		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.03639565102272472 | validation: 0.025944750405648087]
	TIME [epoch: 5.71 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028960714083314968		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.028960714083314968 | validation: 0.027738311959156194]
	TIME [epoch: 5.72 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041271766095427875		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.041271766095427875 | validation: 0.02270264872993352]
	TIME [epoch: 5.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03647066191796468		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.03647066191796468 | validation: 0.025369899787358804]
	TIME [epoch: 5.72 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03183244185182165		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.03183244185182165 | validation: 0.025340888856233174]
	TIME [epoch: 5.75 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0342731468722418		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.0342731468722418 | validation: 0.03170957020600025]
	TIME [epoch: 5.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043429255977421734		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.043429255977421734 | validation: 0.048087272621562045]
	TIME [epoch: 5.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0517346071553904		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.0517346071553904 | validation: 0.044038119169688486]
	TIME [epoch: 5.72 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05449618755460602		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.05449618755460602 | validation: 0.03626677939249465]
	TIME [epoch: 5.71 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04639869571448043		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.04639869571448043 | validation: 0.030039224863587774]
	TIME [epoch: 5.72 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035801880574302905		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.035801880574302905 | validation: 0.028404100300474387]
	TIME [epoch: 5.75 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03291731827963313		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.03291731827963313 | validation: 0.03076772899942908]
	TIME [epoch: 5.72 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033241395648439205		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.033241395648439205 | validation: 0.022791436633237582]
	TIME [epoch: 5.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031142791326816306		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.031142791326816306 | validation: 0.03406294089233419]
	TIME [epoch: 5.72 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145338078069218		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.03145338078069218 | validation: 0.020668526327315088]
	TIME [epoch: 5.72 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02862675986549339		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.02862675986549339 | validation: 0.02750765986976677]
	TIME [epoch: 5.72 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028900741253450518		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.028900741253450518 | validation: 0.01836478340982633]
	TIME [epoch: 5.73 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02781640856252171		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.02781640856252171 | validation: 0.02356096467146153]
	TIME [epoch: 5.75 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02827413447248448		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.02827413447248448 | validation: 0.021261732131580394]
	TIME [epoch: 5.71 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026247686142447012		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.026247686142447012 | validation: 0.024538831210734982]
	TIME [epoch: 5.71 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02740914869668965		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.02740914869668965 | validation: 0.018546474770168277]
	TIME [epoch: 5.71 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02585619220086703		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.02585619220086703 | validation: 0.01871748909365921]
	TIME [epoch: 5.72 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024048879584020428		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.024048879584020428 | validation: 0.024803135910363556]
	TIME [epoch: 5.72 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029510178300901295		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.029510178300901295 | validation: 0.025617874749354997]
	TIME [epoch: 5.77 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030374099814372182		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.030374099814372182 | validation: 0.030154984677093436]
	TIME [epoch: 5.73 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02924156874404068		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.02924156874404068 | validation: 0.03541209585821479]
	TIME [epoch: 5.71 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030504177753519438		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.030504177753519438 | validation: 0.036221797581441555]
	TIME [epoch: 5.71 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03385652724361884		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.03385652724361884 | validation: 0.03642576653995579]
	TIME [epoch: 5.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029103615675987127		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.029103615675987127 | validation: 0.026366633732359306]
	TIME [epoch: 5.71 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028487455190744644		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.028487455190744644 | validation: 0.03824270211084357]
	TIME [epoch: 5.72 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032327331082574885		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.032327331082574885 | validation: 0.02948629008870242]
	TIME [epoch: 5.76 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030993697891765235		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.030993697891765235 | validation: 0.03192132644308179]
	TIME [epoch: 5.72 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03246677822987859		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.03246677822987859 | validation: 0.02758491779807247]
	TIME [epoch: 5.72 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032898534428868004		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.032898534428868004 | validation: 0.021516539638405698]
	TIME [epoch: 5.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028999406856637457		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.028999406856637457 | validation: 0.01879986832712085]
	TIME [epoch: 5.72 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02721183990732729		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.02721183990732729 | validation: 0.01592839391530187]
	TIME [epoch: 5.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02490182821005427		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.02490182821005427 | validation: 0.03019790539390916]
	TIME [epoch: 5.76 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027696242349159773		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.027696242349159773 | validation: 0.029917342813856076]
	TIME [epoch: 5.72 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204071431156102		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.03204071431156102 | validation: 0.038090056108158354]
	TIME [epoch: 5.72 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029271131714038952		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.029271131714038952 | validation: 0.02820678538019319]
	TIME [epoch: 5.72 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02573482864870299		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.02573482864870299 | validation: 0.017739069950453674]
	TIME [epoch: 5.72 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02642749274887971		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.02642749274887971 | validation: 0.024013973298841425]
	TIME [epoch: 5.71 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028516049011482907		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.028516049011482907 | validation: 0.029125680195466658]
	TIME [epoch: 5.73 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03159085274121682		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.03159085274121682 | validation: 0.026833686281471227]
	TIME [epoch: 5.75 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031456334819097		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.031456334819097 | validation: 0.028511462420220374]
	TIME [epoch: 5.72 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027997909125741145		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.027997909125741145 | validation: 0.026804724303146826]
	TIME [epoch: 5.71 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204077750837911		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.03204077750837911 | validation: 0.030731796529511676]
	TIME [epoch: 5.72 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03036276937101026		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.03036276937101026 | validation: 0.027678325065672495]
	TIME [epoch: 5.72 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024989002812583865		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.024989002812583865 | validation: 0.015560958384933783]
	TIME [epoch: 5.71 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02490445821236282		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.02490445821236282 | validation: 0.01957751372594341]
	TIME [epoch: 5.74 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029599382934448304		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.029599382934448304 | validation: 0.027299805351433497]
	TIME [epoch: 5.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03269450246893124		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.03269450246893124 | validation: 0.02680942861345592]
	TIME [epoch: 5.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02776327110081281		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.02776327110081281 | validation: 0.021676987381367294]
	TIME [epoch: 5.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03022262135979675		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.03022262135979675 | validation: 0.0323594633395365]
	TIME [epoch: 5.72 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028308327480928087		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.028308327480928087 | validation: 0.03346947015066284]
	TIME [epoch: 5.71 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028214364584493095		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.028214364584493095 | validation: 0.01911676151384326]
	TIME [epoch: 5.72 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027404962752813084		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.027404962752813084 | validation: 0.024101089993429196]
	TIME [epoch: 5.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028169430683730505		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.028169430683730505 | validation: 0.02618560940112021]
	TIME [epoch: 5.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027732765549939607		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.027732765549939607 | validation: 0.020214129232702584]
	TIME [epoch: 5.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02793037392251238		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.02793037392251238 | validation: 0.03128088599133434]
	TIME [epoch: 5.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03641149140166621		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.03641149140166621 | validation: 0.027057789512471668]
	TIME [epoch: 5.71 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03223994580902389		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.03223994580902389 | validation: 0.023632586790104146]
	TIME [epoch: 5.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03092430224695234		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.03092430224695234 | validation: 0.02638205647398998]
	TIME [epoch: 5.76 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030886368828893757		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.030886368828893757 | validation: 0.029938666941044002]
	TIME [epoch: 5.73 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035337903861835794		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.035337903861835794 | validation: 0.02903014712139747]
	TIME [epoch: 5.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03089172117028196		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.03089172117028196 | validation: 0.02919303675926216]
	TIME [epoch: 5.71 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02890268183070871		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.02890268183070871 | validation: 0.020189456693102015]
	TIME [epoch: 5.72 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218942775676859		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.03218942775676859 | validation: 0.041011160629405706]
	TIME [epoch: 5.71 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04476649399679631		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.04476649399679631 | validation: 0.044421076058039376]
	TIME [epoch: 5.71 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036041864973875674		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.036041864973875674 | validation: 0.029180496122927828]
	TIME [epoch: 5.75 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0332584148541271		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0332584148541271 | validation: 0.03411291277845032]
	TIME [epoch: 5.71 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028667680671248863		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.028667680671248863 | validation: 0.02914856038907497]
	TIME [epoch: 5.71 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032864732761239496		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.032864732761239496 | validation: 0.028938380111812087]
	TIME [epoch: 5.71 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027862479270300992		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.027862479270300992 | validation: 0.020688674770481263]
	TIME [epoch: 5.71 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029760441857759664		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.029760441857759664 | validation: 0.028875533570114555]
	TIME [epoch: 5.71 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02764045440200752		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.02764045440200752 | validation: 0.03006442204697955]
	TIME [epoch: 5.75 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02799356350533152		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.02799356350533152 | validation: 0.0284660716851943]
	TIME [epoch: 5.71 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025582162921236724		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.025582162921236724 | validation: 0.02499997061988756]
	TIME [epoch: 5.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259266476198688		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.03259266476198688 | validation: 0.02298983947228843]
	TIME [epoch: 5.71 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025044377096578162		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.025044377096578162 | validation: 0.028895160176485888]
	TIME [epoch: 5.71 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025382964133268265		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.025382964133268265 | validation: 0.018319724718214633]
	TIME [epoch: 5.72 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02634891715269095		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.02634891715269095 | validation: 0.024857700683263304]
	TIME [epoch: 5.72 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030237842112125116		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.030237842112125116 | validation: 0.02906535875562277]
	TIME [epoch: 5.74 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029897212071910977		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.029897212071910977 | validation: 0.0277356271429293]
	TIME [epoch: 5.72 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028397469013484312		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.028397469013484312 | validation: 0.023815992308056626]
	TIME [epoch: 5.71 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026183582091979515		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.026183582091979515 | validation: 0.022597048548498647]
	TIME [epoch: 5.72 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02763783230950581		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.02763783230950581 | validation: 0.020078100340597392]
	TIME [epoch: 5.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030086632608764603		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.030086632608764603 | validation: 0.025673353268441588]
	TIME [epoch: 5.71 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02208029340644767		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.02208029340644767 | validation: 0.02267307746847272]
	TIME [epoch: 5.76 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026682880184760935		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.026682880184760935 | validation: 0.02641296235576787]
	TIME [epoch: 5.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195831304082285		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.03195831304082285 | validation: 0.032044160688843984]
	TIME [epoch: 5.71 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04619641516294466		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.04619641516294466 | validation: 0.032429392280056875]
	TIME [epoch: 5.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03811193079884022		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.03811193079884022 | validation: 0.019718818589342324]
	TIME [epoch: 5.72 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027514867942197763		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.027514867942197763 | validation: 0.028029740260090145]
	TIME [epoch: 5.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026784479871977393		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.026784479871977393 | validation: 0.026413061451270325]
	TIME [epoch: 5.73 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027460865421684556		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.027460865421684556 | validation: 0.023380140046319334]
	TIME [epoch: 5.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027618256834792194		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.027618256834792194 | validation: 0.01306001075234435]
	TIME [epoch: 5.72 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0238167624112474		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.0238167624112474 | validation: 0.020677461505830007]
	TIME [epoch: 5.72 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023852109004476322		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.023852109004476322 | validation: 0.026123626393076155]
	TIME [epoch: 5.71 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0278197705060332		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.0278197705060332 | validation: 0.02174766816556491]
	TIME [epoch: 5.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03360454753035247		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.03360454753035247 | validation: 0.031948628055143875]
	TIME [epoch: 5.71 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03345181757260315		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.03345181757260315 | validation: 0.029899624924501628]
	TIME [epoch: 5.75 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027827698316022175		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.027827698316022175 | validation: 0.022321811688827485]
	TIME [epoch: 5.72 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02818427422696795		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.02818427422696795 | validation: 0.028541956911248646]
	TIME [epoch: 5.71 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038016485526553956		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.038016485526553956 | validation: 0.031096657925934003]
	TIME [epoch: 5.71 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034292252901367164		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.034292252901367164 | validation: 0.030169051434111662]
	TIME [epoch: 5.72 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03794090638409554		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.03794090638409554 | validation: 0.031145136684984483]
	TIME [epoch: 5.72 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568332361533152		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.03568332361533152 | validation: 0.02014601099237577]
	TIME [epoch: 5.73 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027746761825169587		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.027746761825169587 | validation: 0.02586956186880494]
	TIME [epoch: 5.75 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0254758150027862		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.0254758150027862 | validation: 0.0283277202275012]
	TIME [epoch: 5.72 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03401968026290324		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.03401968026290324 | validation: 0.0246090537381217]
	TIME [epoch: 5.72 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0270820259331552		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.0270820259331552 | validation: 0.02681533102387747]
	TIME [epoch: 5.72 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0236397414227347		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.0236397414227347 | validation: 0.021142530591713227]
	TIME [epoch: 5.71 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0234896136054533		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.0234896136054533 | validation: 0.022025773641193843]
	TIME [epoch: 5.71 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028548575421048415		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.028548575421048415 | validation: 0.02684637516657076]
	TIME [epoch: 5.75 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029659083756381877		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.029659083756381877 | validation: 0.027791599321056567]
	TIME [epoch: 5.72 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03264652723558582		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.03264652723558582 | validation: 0.0256514307468086]
	TIME [epoch: 5.71 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030265395398404876		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.030265395398404876 | validation: 0.026974308604600605]
	TIME [epoch: 5.72 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03309999055034435		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.03309999055034435 | validation: 0.024654705733765568]
	TIME [epoch: 5.72 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0319730810886626		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.0319730810886626 | validation: 0.029540987591944692]
	TIME [epoch: 5.71 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030631181796518824		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.030631181796518824 | validation: 0.030106547939995894]
	TIME [epoch: 5.72 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029291108163713386		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.029291108163713386 | validation: 0.017313352972048963]
	TIME [epoch: 5.75 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030722495282115913		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.030722495282115913 | validation: 0.035430475807003606]
	TIME [epoch: 5.72 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03247918550666866		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.03247918550666866 | validation: 0.029896897811461813]
	TIME [epoch: 5.72 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028215736220287366		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.028215736220287366 | validation: 0.032252156717136535]
	TIME [epoch: 5.72 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03480174122007903		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.03480174122007903 | validation: 0.027219554370643308]
	TIME [epoch: 5.72 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02743450191306908		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.02743450191306908 | validation: 0.02496248891875101]
	TIME [epoch: 5.69 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030582468301665784		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.030582468301665784 | validation: 0.03261101445370055]
	TIME [epoch: 5.76 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03084786874581759		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.03084786874581759 | validation: 0.0353147492782298]
	TIME [epoch: 5.72 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026365582952307287		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.026365582952307287 | validation: 0.02753623208616909]
	TIME [epoch: 5.72 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023642847344379127		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.023642847344379127 | validation: 0.023517443068988522]
	TIME [epoch: 5.72 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027665890561812123		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.027665890561812123 | validation: 0.020218520150623923]
	TIME [epoch: 5.72 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026322685434496722		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.026322685434496722 | validation: 0.017846501908444196]
	TIME [epoch: 5.71 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027362510599022265		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.027362510599022265 | validation: 0.023632934875891083]
	TIME [epoch: 5.73 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031503671307324024		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.031503671307324024 | validation: 0.019481439049413886]
	TIME [epoch: 5.75 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03420041778074006		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.03420041778074006 | validation: 0.02944582894670192]
	TIME [epoch: 5.72 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03768849471050771		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.03768849471050771 | validation: 0.028532174010905118]
	TIME [epoch: 5.72 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036641789711240234		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.036641789711240234 | validation: 0.02685284504738892]
	TIME [epoch: 5.71 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029192419595759453		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.029192419595759453 | validation: 0.024420045501357856]
	TIME [epoch: 5.71 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03067880720727481		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.03067880720727481 | validation: 0.02811483123897997]
	TIME [epoch: 5.71 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027640171147063252		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.027640171147063252 | validation: 0.02316070925899649]
	TIME [epoch: 5.77 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02380301190750555		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.02380301190750555 | validation: 0.021887164382880856]
	TIME [epoch: 5.72 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02651852009119062		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.02651852009119062 | validation: 0.028754568706052943]
	TIME [epoch: 5.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029094440487848795		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.029094440487848795 | validation: 0.02625187439127335]
	TIME [epoch: 5.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027769294516140026		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.027769294516140026 | validation: 0.016304468563843447]
	TIME [epoch: 5.71 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026710120386896106		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.026710120386896106 | validation: 0.022537498767502887]
	TIME [epoch: 5.71 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028748373770000286		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.028748373770000286 | validation: 0.024317039646940528]
	TIME [epoch: 5.73 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314804910977479		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.0314804910977479 | validation: 0.023425823300702114]
	TIME [epoch: 5.75 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028440954382843636		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.028440954382843636 | validation: 0.027667789551297572]
	TIME [epoch: 5.72 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025156968079535498		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.025156968079535498 | validation: 0.02473780508389434]
	TIME [epoch: 5.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022965409999671168		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.022965409999671168 | validation: 0.016750397332681237]
	TIME [epoch: 5.72 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024923259479117225		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.024923259479117225 | validation: 0.023307575625538424]
	TIME [epoch: 5.72 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02486249014252041		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.02486249014252041 | validation: 0.019499246547920995]
	TIME [epoch: 5.71 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02917858202751392		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.02917858202751392 | validation: 0.026940578101661537]
	TIME [epoch: 5.76 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025173118376565808		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.025173118376565808 | validation: 0.01574953183990556]
	TIME [epoch: 5.72 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03097001247484993		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.03097001247484993 | validation: 0.028335584108913136]
	TIME [epoch: 5.72 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0311506676721758		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.0311506676721758 | validation: 0.019608315320925523]
	TIME [epoch: 5.72 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026931398618753224		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.026931398618753224 | validation: 0.02656723393571891]
	TIME [epoch: 5.71 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02498236611343338		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.02498236611343338 | validation: 0.027181636010362116]
	TIME [epoch: 5.71 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02491216832710072		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.02491216832710072 | validation: 0.023192887060385067]
	TIME [epoch: 5.73 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02896780950206474		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.02896780950206474 | validation: 0.021890689399679177]
	TIME [epoch: 5.75 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02857329889497414		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.02857329889497414 | validation: 0.023016357321180295]
	TIME [epoch: 5.72 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03445581016322613		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.03445581016322613 | validation: 0.02742820177828891]
	TIME [epoch: 5.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031396312202739814		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.031396312202739814 | validation: 0.027396657761328217]
	TIME [epoch: 5.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027793549415579207		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.027793549415579207 | validation: 0.022377257762957983]
	TIME [epoch: 5.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028668888694858882		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.028668888694858882 | validation: 0.02128032749032217]
	TIME [epoch: 5.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02829136558970933		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.02829136558970933 | validation: 0.028578988767196122]
	TIME [epoch: 5.75 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02909535466961996		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.02909535466961996 | validation: 0.026900833057425456]
	TIME [epoch: 5.73 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024811911984455166		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.024811911984455166 | validation: 0.021735486395697636]
	TIME [epoch: 5.7 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030784499969773376		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.030784499969773376 | validation: 0.023030298694648465]
	TIME [epoch: 5.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026979865040377245		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.026979865040377245 | validation: 0.03081811458625675]
	TIME [epoch: 5.7 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030570765281495802		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.030570765281495802 | validation: 0.027994657852249773]
	TIME [epoch: 5.69 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03048147229175719		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.03048147229175719 | validation: 0.02727192665397208]
	TIME [epoch: 5.71 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02835565850517798		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.02835565850517798 | validation: 0.028831799809525036]
	TIME [epoch: 5.73 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03032223139173992		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.03032223139173992 | validation: 0.02648872822411622]
	TIME [epoch: 5.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851371621901605		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.02851371621901605 | validation: 0.020376926342891084]
	TIME [epoch: 5.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02739627873041924		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.02739627873041924 | validation: 0.017219001995533455]
	TIME [epoch: 5.72 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024010157846003594		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.024010157846003594 | validation: 0.02215137791361009]
	TIME [epoch: 5.72 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023480315894775505		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.023480315894775505 | validation: 0.022839048839990907]
	TIME [epoch: 5.72 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028773793364788965		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.028773793364788965 | validation: 0.022389554135540682]
	TIME [epoch: 5.77 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029627279891450132		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.029627279891450132 | validation: 0.025452782364296024]
	TIME [epoch: 5.72 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03311506630391647		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03311506630391647 | validation: 0.020355454593685107]
	TIME [epoch: 5.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031065307075813536		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.031065307075813536 | validation: 0.025260226158541843]
	TIME [epoch: 5.71 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034520087345935924		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.034520087345935924 | validation: 0.03001959778466267]
	TIME [epoch: 5.71 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042118368670903995		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.042118368670903995 | validation: 0.03726944775156197]
	TIME [epoch: 5.72 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046724331580430156		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.046724331580430156 | validation: 0.031191392695996006]
	TIME [epoch: 5.72 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04102777865450406		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.04102777865450406 | validation: 0.029940100018168093]
	TIME [epoch: 5.75 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032697660286626413		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.032697660286626413 | validation: 0.03418699125279364]
	TIME [epoch: 5.72 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03373414940130179		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.03373414940130179 | validation: 0.03416677507435581]
	TIME [epoch: 5.72 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03770680052608742		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.03770680052608742 | validation: 0.02756243458170553]
	TIME [epoch: 5.71 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02923160677696838		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.02923160677696838 | validation: 0.028263301252695553]
	TIME [epoch: 5.71 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02889642727502787		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.02889642727502787 | validation: 0.015704576413673267]
	TIME [epoch: 5.71 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02590396278070932		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.02590396278070932 | validation: 0.022635275068074074]
	TIME [epoch: 5.76 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030875303957241963		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.030875303957241963 | validation: 0.02571216333389083]
	TIME [epoch: 5.73 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030496273067633747		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.030496273067633747 | validation: 0.02828175513632428]
	TIME [epoch: 5.72 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028388754049691833		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.028388754049691833 | validation: 0.02251871940048903]
	TIME [epoch: 5.71 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029787304719571448		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.029787304719571448 | validation: 0.022872041697045885]
	TIME [epoch: 5.72 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0309679998475351		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.0309679998475351 | validation: 0.029522992460017657]
	TIME [epoch: 5.72 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029807270832338903		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.029807270832338903 | validation: 0.025270665487535312]
	TIME [epoch: 5.73 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03658385058955244		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.03658385058955244 | validation: 0.02347065182849594]
	TIME [epoch: 5.75 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028435810623271773		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.028435810623271773 | validation: 0.023182948540120003]
	TIME [epoch: 5.72 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02326769836068616		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.02326769836068616 | validation: 0.029635856845043246]
	TIME [epoch: 5.72 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142707655202268		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.03142707655202268 | validation: 0.02530747530015363]
	TIME [epoch: 5.72 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025560502195589217		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.025560502195589217 | validation: 0.02397228968620011]
	TIME [epoch: 5.72 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022762824432755756		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.022762824432755756 | validation: 0.03334490011108187]
	TIME [epoch: 5.72 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026954382727564456		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.026954382727564456 | validation: 0.024284054182375885]
	TIME [epoch: 5.76 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026390424452586943		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.026390424452586943 | validation: 0.014692687794847297]
	TIME [epoch: 5.72 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027255391541113158		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.027255391541113158 | validation: 0.02794847302726634]
	TIME [epoch: 5.71 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030411576743967845		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.030411576743967845 | validation: 0.02502238366321741]
	TIME [epoch: 5.71 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02962645411246541		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.02962645411246541 | validation: 0.02515027072215183]
	TIME [epoch: 5.71 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02749457805591295		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.02749457805591295 | validation: 0.02203904445667737]
	TIME [epoch: 5.72 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023962585941790418		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.023962585941790418 | validation: 0.030001008862923565]
	TIME [epoch: 5.74 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03060949689849305		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.03060949689849305 | validation: 0.02594952179526158]
	TIME [epoch: 5.73 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028942605952432816		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.028942605952432816 | validation: 0.019879291123125]
	TIME [epoch: 5.71 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031132749289924565		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.031132749289924565 | validation: 0.027628305499087142]
	TIME [epoch: 5.71 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028034242550199824		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.028034242550199824 | validation: 0.030961740398872412]
	TIME [epoch: 5.72 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02569987776673366		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.02569987776673366 | validation: 0.016219844007571028]
	TIME [epoch: 5.7 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027301545035264274		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.027301545035264274 | validation: 0.015423209917546437]
	TIME [epoch: 5.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02753198098711341		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.02753198098711341 | validation: 0.022823041905591857]
	TIME [epoch: 5.74 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025712723547302675		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.025712723547302675 | validation: 0.024565892793067312]
	TIME [epoch: 5.73 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027718582093021395		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.027718582093021395 | validation: 0.026386189935217085]
	TIME [epoch: 5.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026910959400412125		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.026910959400412125 | validation: 0.019692094365189414]
	TIME [epoch: 5.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03025179370897345		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.03025179370897345 | validation: 0.04100603269325606]
	TIME [epoch: 5.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02580002012873845		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.02580002012873845 | validation: 0.023432014531664113]
	TIME [epoch: 5.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026877354483639634		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.026877354483639634 | validation: 0.02627525434352807]
	TIME [epoch: 5.72 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02587191324416159		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.02587191324416159 | validation: 0.021446738146471026]
	TIME [epoch: 5.75 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023753494441449672		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.023753494441449672 | validation: 0.026341637667198946]
	TIME [epoch: 5.72 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023436342764296708		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.023436342764296708 | validation: 0.014727516782066128]
	TIME [epoch: 5.71 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02645642379616798		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.02645642379616798 | validation: 0.014274052001262597]
	TIME [epoch: 5.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026891440279633187		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.026891440279633187 | validation: 0.020777470060089877]
	TIME [epoch: 5.71 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024494513883424253		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.024494513883424253 | validation: 0.02084330711084081]
	TIME [epoch: 5.72 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02629288542186444		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.02629288542186444 | validation: 0.021627536835766296]
	TIME [epoch: 5.76 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02812614413003687		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.02812614413003687 | validation: 0.03375363001801431]
	TIME [epoch: 5.72 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02758643753037781		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.02758643753037781 | validation: 0.029504827073327196]
	TIME [epoch: 5.71 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029909616146716635		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.029909616146716635 | validation: 0.027787314785417162]
	TIME [epoch: 5.71 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0288798162510328		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.0288798162510328 | validation: 0.023195108959480105]
	TIME [epoch: 5.71 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025046850006088403		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.025046850006088403 | validation: 0.021431336009479468]
	TIME [epoch: 5.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032868330488990634		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.032868330488990634 | validation: 0.015630501650539]
	TIME [epoch: 5.72 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024250194186277305		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.024250194186277305 | validation: 0.024628695432273195]
	TIME [epoch: 5.74 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021647995342905624		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.021647995342905624 | validation: 0.022516729450916963]
	TIME [epoch: 5.71 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024032552271028317		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.024032552271028317 | validation: 0.026065626283564833]
	TIME [epoch: 5.71 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02840532286627234		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.02840532286627234 | validation: 0.020772325002005064]
	TIME [epoch: 5.72 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02558737614507814		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.02558737614507814 | validation: 0.0328253637151148]
	TIME [epoch: 5.72 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02762357136100802		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.02762357136100802 | validation: 0.023715751658446284]
	TIME [epoch: 5.72 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03144478091482216		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.03144478091482216 | validation: 0.027055719642570066]
	TIME [epoch: 5.74 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028942466149312215		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.028942466149312215 | validation: 0.03459003394016927]
	TIME [epoch: 5.72 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578911704617335		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.03578911704617335 | validation: 0.033439040222700674]
	TIME [epoch: 5.72 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03275765769674197		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.03275765769674197 | validation: 0.030077284915121485]
	TIME [epoch: 5.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03366409374652482		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.03366409374652482 | validation: 0.0330352387425093]
	TIME [epoch: 5.71 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03415119353417789		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.03415119353417789 | validation: 0.037899548099591326]
	TIME [epoch: 5.72 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02855800825538965		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.02855800825538965 | validation: 0.022442542609126283]
	TIME [epoch: 5.73 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02843417510558264		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.02843417510558264 | validation: 0.03603701038232169]
	TIME [epoch: 5.75 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030292832746783932		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.030292832746783932 | validation: 0.03203733566387538]
	TIME [epoch: 5.71 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03083276759709595		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.03083276759709595 | validation: 0.027237854113398824]
	TIME [epoch: 5.71 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02833833881714696		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.02833833881714696 | validation: 0.03265193165474266]
	TIME [epoch: 5.72 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03409129655196043		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.03409129655196043 | validation: 0.031927000855899425]
	TIME [epoch: 5.72 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140511304562061		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.03140511304562061 | validation: 0.029573794152668826]
	TIME [epoch: 5.72 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03113923378215722		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.03113923378215722 | validation: 0.034623897754761976]
	TIME [epoch: 5.76 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030791560815135927		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.030791560815135927 | validation: 0.03107264803782594]
	TIME [epoch: 5.72 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030489936500871194		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.030489936500871194 | validation: 0.031654870885882466]
	TIME [epoch: 5.72 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03003306206741816		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.03003306206741816 | validation: 0.03588216339216049]
	TIME [epoch: 5.72 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03186857488503698		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.03186857488503698 | validation: 0.02706307854199129]
	TIME [epoch: 5.7 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0288564438168368		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.0288564438168368 | validation: 0.03608678572413219]
	TIME [epoch: 5.71 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027565905659489933		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.027565905659489933 | validation: 0.034445715764880286]
	TIME [epoch: 5.73 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0308125347231587		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.0308125347231587 | validation: 0.019810619295285856]
	TIME [epoch: 5.76 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02916137821685921		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.02916137821685921 | validation: 0.030221863086317944]
	TIME [epoch: 5.72 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02777553765229257		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.02777553765229257 | validation: 0.024602350544402178]
	TIME [epoch: 5.72 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02578979093884144		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.02578979093884144 | validation: 0.024783350314950985]
	TIME [epoch: 5.71 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02941024888322796		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.02941024888322796 | validation: 0.03979249140911652]
	TIME [epoch: 5.71 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02523018815029527		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.02523018815029527 | validation: 0.033025436348434675]
	TIME [epoch: 5.72 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025034559372888336		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.025034559372888336 | validation: 0.018922909024034654]
	TIME [epoch: 5.76 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02246793897422121		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.02246793897422121 | validation: 0.024326230524417198]
	TIME [epoch: 5.72 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02805812963924372		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.02805812963924372 | validation: 0.022598607292886208]
	TIME [epoch: 5.72 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026867639096070782		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.026867639096070782 | validation: 0.01904685557262704]
	TIME [epoch: 5.72 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025595183578883754		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.025595183578883754 | validation: 0.018204447548591]
	TIME [epoch: 5.72 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02823339864968753		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.02823339864968753 | validation: 0.02637661035855361]
	TIME [epoch: 5.72 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027450617202577608		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.027450617202577608 | validation: 0.029322322095721668]
	TIME [epoch: 5.73 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027412316559763297		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.027412316559763297 | validation: 0.033246071925936795]
	TIME [epoch: 5.75 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028689713468650596		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.028689713468650596 | validation: 0.025257228930761055]
	TIME [epoch: 5.71 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034350600516216204		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.034350600516216204 | validation: 0.02979183782120559]
	TIME [epoch: 5.72 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030611925112982375		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.030611925112982375 | validation: 0.025550670061976654]
	TIME [epoch: 5.72 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027954009227506793		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.027954009227506793 | validation: 0.0259691311458368]
	TIME [epoch: 5.72 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02711507765734848		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.02711507765734848 | validation: 0.027549799610563936]
	TIME [epoch: 5.71 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0282304275218445		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.0282304275218445 | validation: 0.024538530292592797]
	TIME [epoch: 5.75 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02621037597978238		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.02621037597978238 | validation: 0.02269381262619953]
	TIME [epoch: 5.72 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02304241368139672		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.02304241368139672 | validation: 0.014521079512424649]
	TIME [epoch: 5.72 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02658240648382275		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.02658240648382275 | validation: 0.022174787749420288]
	TIME [epoch: 5.7 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024306303714041015		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.024306303714041015 | validation: 0.024289339775761493]
	TIME [epoch: 5.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02590102355254155		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.02590102355254155 | validation: 0.023091000738161577]
	TIME [epoch: 5.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02709422458952754		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.02709422458952754 | validation: 0.02456829208748345]
	TIME [epoch: 5.71 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027337383768587086		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.027337383768587086 | validation: 0.022367965762031795]
	TIME [epoch: 5.73 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027915549718489766		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.027915549718489766 | validation: 0.02405659753295378]
	TIME [epoch: 5.7 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0274316982299894		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.0274316982299894 | validation: 0.02481139511816739]
	TIME [epoch: 5.7 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024703426016874093		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.024703426016874093 | validation: 0.026838042949890586]
	TIME [epoch: 5.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023581898028981085		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.023581898028981085 | validation: 0.02203961748631414]
	TIME [epoch: 5.7 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025410475209907663		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.025410475209907663 | validation: 0.029171897965535615]
	TIME [epoch: 5.71 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027446430434222863		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.027446430434222863 | validation: 0.02106834158672744]
	TIME [epoch: 5.74 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027983438135048163		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.027983438135048163 | validation: 0.026752217329585406]
	TIME [epoch: 5.71 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025285660726040545		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.025285660726040545 | validation: 0.017635084048787896]
	TIME [epoch: 5.7 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025940598770787488		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.025940598770787488 | validation: 0.01598157937651634]
	TIME [epoch: 5.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027295359169300384		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.027295359169300384 | validation: 0.019811293424325953]
	TIME [epoch: 5.72 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02801191632729625		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.02801191632729625 | validation: 0.02044261669225999]
	TIME [epoch: 5.7 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022052771226518303		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.022052771226518303 | validation: 0.02200045907280095]
	TIME [epoch: 5.71 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027510702876284023		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.027510702876284023 | validation: 0.031170362722926385]
	TIME [epoch: 5.74 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023333107209006325		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.023333107209006325 | validation: 0.017851647493966054]
	TIME [epoch: 5.7 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02562016313412145		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.02562016313412145 | validation: 0.015684890307998436]
	TIME [epoch: 5.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02864170107980743		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.02864170107980743 | validation: 0.025419779368410528]
	TIME [epoch: 5.7 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029616162322829036		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.029616162322829036 | validation: 0.02518987621622129]
	TIME [epoch: 5.71 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029651241455731475		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.029651241455731475 | validation: 0.00982379111063898]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_1366.pth
	Model improved!!!
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029264534994357307		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.029264534994357307 | validation: 0.024652805475374562]
	TIME [epoch: 5.76 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02387969200598135		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.02387969200598135 | validation: 0.025574241753263872]
	TIME [epoch: 5.72 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022906839593478785		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.022906839593478785 | validation: 0.024247814868206322]
	TIME [epoch: 5.71 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02394676049430479		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.02394676049430479 | validation: 0.021622045195526084]
	TIME [epoch: 5.71 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02865826565335486		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.02865826565335486 | validation: 0.01767986940428323]
	TIME [epoch: 5.72 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024683161862598085		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.024683161862598085 | validation: 0.02874565471789286]
	TIME [epoch: 5.71 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02624117771846883		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.02624117771846883 | validation: 0.01896022777486528]
	TIME [epoch: 5.72 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026992060931568043		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.026992060931568043 | validation: 0.022703130608981985]
	TIME [epoch: 5.75 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028366397068833767		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.028366397068833767 | validation: 0.024971361610763045]
	TIME [epoch: 5.72 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02468106451599867		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.02468106451599867 | validation: 0.029776634145631756]
	TIME [epoch: 5.71 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023019476774262974		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.023019476774262974 | validation: 0.021249777329858707]
	TIME [epoch: 5.71 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02436935370332482		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.02436935370332482 | validation: 0.017267509946381848]
	TIME [epoch: 5.71 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023970766239241343		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.023970766239241343 | validation: 0.01871096398027552]
	TIME [epoch: 5.71 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02639061531794528		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.02639061531794528 | validation: 0.020390406246210732]
	TIME [epoch: 5.75 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028611909057460905		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.028611909057460905 | validation: 0.02037429742078653]
	TIME [epoch: 5.71 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028407699671714255		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.028407699671714255 | validation: 0.022907682297502473]
	TIME [epoch: 5.71 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0287854663117212		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.0287854663117212 | validation: 0.025659070588143734]
	TIME [epoch: 5.72 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02946333217471754		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.02946333217471754 | validation: 0.02785464190472313]
	TIME [epoch: 5.71 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02494396883660828		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.02494396883660828 | validation: 0.0241914723137025]
	TIME [epoch: 5.71 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023583478733942374		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.023583478733942374 | validation: 0.02313491726207639]
	TIME [epoch: 5.72 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025870870980512203		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.025870870980512203 | validation: 0.021680916883625344]
	TIME [epoch: 5.74 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029806948694132192		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.029806948694132192 | validation: 0.02334804762990859]
	TIME [epoch: 5.72 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029279077501327015		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.029279077501327015 | validation: 0.018868114353134336]
	TIME [epoch: 5.72 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024487250591639885		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.024487250591639885 | validation: 0.015966680747759344]
	TIME [epoch: 5.71 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024922100390333494		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.024922100390333494 | validation: 0.015887886344773634]
	TIME [epoch: 5.71 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024515110155222307		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.024515110155222307 | validation: 0.02953854433530922]
	TIME [epoch: 5.71 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02832683044540943		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.02832683044540943 | validation: 0.022711672258830622]
	TIME [epoch: 5.76 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027357461102382723		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.027357461102382723 | validation: 0.018461244772217552]
	TIME [epoch: 5.72 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995449513637608		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.02995449513637608 | validation: 0.010020772645788663]
	TIME [epoch: 5.71 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03119361802202211		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.03119361802202211 | validation: 0.030140183720339556]
	TIME [epoch: 5.72 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02972396782529057		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.02972396782529057 | validation: 0.0288175863723005]
	TIME [epoch: 5.72 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027929983798678597		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.027929983798678597 | validation: 0.02442067497871369]
	TIME [epoch: 5.72 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028540755905955298		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.028540755905955298 | validation: 0.022668404051524225]
	TIME [epoch: 5.73 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02946311443075013		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.02946311443075013 | validation: 0.02219804289988079]
	TIME [epoch: 5.75 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024802769833729074		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.024802769833729074 | validation: 0.022100855506822326]
	TIME [epoch: 5.72 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026608215108210855		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.026608215108210855 | validation: 0.021105057872076234]
	TIME [epoch: 5.72 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027594040665852512		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.027594040665852512 | validation: 0.01787224822807646]
	TIME [epoch: 5.72 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027076261715640138		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.027076261715640138 | validation: 0.026865407018981564]
	TIME [epoch: 5.72 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02411255184485685		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.02411255184485685 | validation: 0.02420464371443266]
	TIME [epoch: 5.72 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024818940398358982		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.024818940398358982 | validation: 0.021219427406894385]
	TIME [epoch: 5.76 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02800591271503446		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.02800591271503446 | validation: 0.026589723552345186]
	TIME [epoch: 5.72 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030255727200985322		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.030255727200985322 | validation: 0.03244977412762143]
	TIME [epoch: 5.71 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029232536627897564		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.029232536627897564 | validation: 0.02862951296061367]
	TIME [epoch: 5.72 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026257491189055383		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.026257491189055383 | validation: 0.02507454257025686]
	TIME [epoch: 5.72 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02523523924613627		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.02523523924613627 | validation: 0.015075861198084626]
	TIME [epoch: 5.72 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030618639787305623		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.030618639787305623 | validation: 0.024438375210149257]
	TIME [epoch: 5.73 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031989332546657555		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.031989332546657555 | validation: 0.025592298551552563]
	TIME [epoch: 5.75 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030854872717095153		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.030854872717095153 | validation: 0.026763834485513928]
	TIME [epoch: 5.71 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032486132942635984		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.032486132942635984 | validation: 0.029639110402258584]
	TIME [epoch: 5.71 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03109199997077334		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.03109199997077334 | validation: 0.022871105729214962]
	TIME [epoch: 5.72 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029508941506743304		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.029508941506743304 | validation: 0.02212137335552847]
	TIME [epoch: 5.72 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02818395845443706		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.02818395845443706 | validation: 0.021748263336276046]
	TIME [epoch: 5.71 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027576089771615218		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.027576089771615218 | validation: 0.013468788160014195]
	TIME [epoch: 5.76 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02743014764564878		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.02743014764564878 | validation: 0.01975476572334457]
	TIME [epoch: 5.72 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02645862397051241		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.02645862397051241 | validation: 0.026252411347193236]
	TIME [epoch: 5.71 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028113814992624133		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.028113814992624133 | validation: 0.023327070550449944]
	TIME [epoch: 5.71 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028929638597010372		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.028929638597010372 | validation: 0.023671137255022904]
	TIME [epoch: 5.72 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02712147994185625		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.02712147994185625 | validation: 0.021815993647559734]
	TIME [epoch: 5.72 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026646432631147715		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.026646432631147715 | validation: 0.02027590534389815]
	TIME [epoch: 5.74 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026689077936198794		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.026689077936198794 | validation: 0.01903278082830073]
	TIME [epoch: 5.75 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029843041047208183		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.029843041047208183 | validation: 0.01625508992340585]
	TIME [epoch: 5.72 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02512673819149945		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.02512673819149945 | validation: 0.019200265900647683]
	TIME [epoch: 5.72 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02741472660709446		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.02741472660709446 | validation: 0.024969481902458485]
	TIME [epoch: 5.71 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026431549410285873		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.026431549410285873 | validation: 0.02703593890730435]
	TIME [epoch: 5.72 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026970551039470464		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.026970551039470464 | validation: 0.01307065527609983]
	TIME [epoch: 5.72 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0252256344948562		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.0252256344948562 | validation: 0.014129620143943087]
	TIME [epoch: 5.76 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02508965671542096		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.02508965671542096 | validation: 0.019660857391374197]
	TIME [epoch: 5.72 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023446351751415455		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.023446351751415455 | validation: 0.02039529453397685]
	TIME [epoch: 5.71 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026370378541707054		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.026370378541707054 | validation: 0.021717338953311485]
	TIME [epoch: 5.71 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024547313626464024		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.024547313626464024 | validation: 0.02919774943636501]
	TIME [epoch: 5.71 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02438601755851109		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.02438601755851109 | validation: 0.026574163661970074]
	TIME [epoch: 5.72 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02781910736083812		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.02781910736083812 | validation: 0.0317850868857759]
	TIME [epoch: 5.74 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027080030847789732		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.027080030847789732 | validation: 0.01704398319605589]
	TIME [epoch: 5.74 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02575039181303663		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.02575039181303663 | validation: 0.027385882355766115]
	TIME [epoch: 5.72 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030949337530307784		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.030949337530307784 | validation: 0.026609738069489026]
	TIME [epoch: 5.72 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02614419306702705		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.02614419306702705 | validation: 0.0246715800398393]
	TIME [epoch: 5.71 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03129009942675659		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.03129009942675659 | validation: 0.03239414439234937]
	TIME [epoch: 5.71 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027864089316220687		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.027864089316220687 | validation: 0.02110845456509491]
	TIME [epoch: 5.72 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028805286270201326		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.028805286270201326 | validation: 0.01489185704167049]
	TIME [epoch: 5.77 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02709156770068161		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.02709156770068161 | validation: 0.020662189782277948]
	TIME [epoch: 5.72 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025827534817919356		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.025827534817919356 | validation: 0.022524830666448673]
	TIME [epoch: 5.71 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024443688785024967		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.024443688785024967 | validation: 0.02458398313608264]
	TIME [epoch: 5.71 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025997351873209992		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.025997351873209992 | validation: 0.011643795088561105]
	TIME [epoch: 5.71 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027936143714209084		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.027936143714209084 | validation: 0.016753732552758575]
	TIME [epoch: 5.72 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025807929292812237		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.025807929292812237 | validation: 0.025428694932579585]
	TIME [epoch: 5.75 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029030314411986093		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.029030314411986093 | validation: 0.02734998752425205]
	TIME [epoch: 5.73 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026377302341506224		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.026377302341506224 | validation: 0.025769527562692844]
	TIME [epoch: 5.72 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028251045674364112		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.028251045674364112 | validation: 0.0258294984429094]
	TIME [epoch: 5.71 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029965734770786383		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.029965734770786383 | validation: 0.03173191560371603]
	TIME [epoch: 5.71 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026308618285440784		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.026308618285440784 | validation: 0.01819227340428965]
	TIME [epoch: 5.71 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028163286846458406		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.028163286846458406 | validation: 0.02267019134629428]
	TIME [epoch: 5.72 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02748877074370723		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.02748877074370723 | validation: 0.02353169683737445]
	TIME [epoch: 5.75 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026160825637319342		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.026160825637319342 | validation: 0.022116417392737647]
	TIME [epoch: 5.72 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02930847880530207		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.02930847880530207 | validation: 0.01623960130395437]
	TIME [epoch: 5.71 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0252532115795514		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.0252532115795514 | validation: 0.026918951150591924]
	TIME [epoch: 5.72 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029533515710682953		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.029533515710682953 | validation: 0.018032744248903027]
	TIME [epoch: 5.71 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02687649985250132		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.02687649985250132 | validation: 0.020334480669012507]
	TIME [epoch: 5.71 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024870763712828495		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.024870763712828495 | validation: 0.02373851433200686]
	TIME [epoch: 5.73 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02765620763098062		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.02765620763098062 | validation: 0.02025462735831781]
	TIME [epoch: 5.73 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02955026231859558		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.02955026231859558 | validation: 0.02554635207742576]
	TIME [epoch: 5.72 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027758507526666927		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.027758507526666927 | validation: 0.026851625602276732]
	TIME [epoch: 5.72 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028520363817973158		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.028520363817973158 | validation: 0.019694819766328517]
	TIME [epoch: 5.71 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02677304144728115		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.02677304144728115 | validation: 0.018127138612511598]
	TIME [epoch: 5.72 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029203709521201895		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.029203709521201895 | validation: 0.031660135887713714]
	TIME [epoch: 5.71 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029332018262085154		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.029332018262085154 | validation: 0.024412829103135907]
	TIME [epoch: 5.75 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026877135151510564		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.026877135151510564 | validation: 0.01926377254156553]
	TIME [epoch: 5.71 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027973880071510013		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.027973880071510013 | validation: 0.029212183808046084]
	TIME [epoch: 5.71 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028406285057382238		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.028406285057382238 | validation: 0.025117056446100704]
	TIME [epoch: 5.71 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02486965891898654		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.02486965891898654 | validation: 0.022969518366677707]
	TIME [epoch: 5.72 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028580430675882052		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.028580430675882052 | validation: 0.021945684340035135]
	TIME [epoch: 5.72 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026305408549515866		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.026305408549515866 | validation: 0.01822616767099856]
	TIME [epoch: 5.74 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02731765983157179		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.02731765983157179 | validation: 0.020798459957793093]
	TIME [epoch: 5.74 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024606941913761598		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.024606941913761598 | validation: 0.018015454187750076]
	TIME [epoch: 5.72 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024288869598926163		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.024288869598926163 | validation: 0.017422484550900078]
	TIME [epoch: 5.71 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026130132894044714		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.026130132894044714 | validation: 0.027003421299422705]
	TIME [epoch: 5.71 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026487079470590966		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.026487079470590966 | validation: 0.018386034468545226]
	TIME [epoch: 5.71 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025214878715066006		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.025214878715066006 | validation: 0.025312452409797317]
	TIME [epoch: 5.72 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027862780289098943		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.027862780289098943 | validation: 0.012684209061067393]
	TIME [epoch: 5.76 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024970013957422037		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.024970013957422037 | validation: 0.022642268407526665]
	TIME [epoch: 5.71 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025682715290439147		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.025682715290439147 | validation: 0.01750074226389915]
	TIME [epoch: 5.71 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023681431015605672		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.023681431015605672 | validation: 0.012759100645004887]
	TIME [epoch: 5.72 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026308491603873246		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.026308491603873246 | validation: 0.021031628706219482]
	TIME [epoch: 5.71 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024300103158288747		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.024300103158288747 | validation: 0.0191348928843693]
	TIME [epoch: 5.72 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02637403226197721		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.02637403226197721 | validation: 0.027443280992293727]
	TIME [epoch: 5.74 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026228625422191232		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.026228625422191232 | validation: 0.021067247846482173]
	TIME [epoch: 5.73 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028062888890480447		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.028062888890480447 | validation: 0.021774222140235607]
	TIME [epoch: 5.72 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02644624114922626		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.02644624114922626 | validation: 0.025134174215823216]
	TIME [epoch: 5.72 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02156676614512801		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.02156676614512801 | validation: 0.016194854673060876]
	TIME [epoch: 5.71 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025741785315000064		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.025741785315000064 | validation: 0.025337245308258857]
	TIME [epoch: 5.71 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024907088825094344		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.024907088825094344 | validation: 0.018759192034382796]
	TIME [epoch: 5.71 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022153971811614603		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.022153971811614603 | validation: 0.024694540528898034]
	TIME [epoch: 5.76 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027233065709494818		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.027233065709494818 | validation: 0.018593671464093495]
	TIME [epoch: 5.72 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024326462873935403		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.024326462873935403 | validation: 0.023622124207962933]
	TIME [epoch: 5.72 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027745233199577186		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.027745233199577186 | validation: 0.022284963673075992]
	TIME [epoch: 5.71 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024645648660138374		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.024645648660138374 | validation: 0.016965478955045143]
	TIME [epoch: 5.71 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023389600730666635		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.023389600730666635 | validation: 0.019623217339294497]
	TIME [epoch: 5.71 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02656241051394538		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.02656241051394538 | validation: 0.010765675503610269]
	TIME [epoch: 5.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022617178247476083		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.022617178247476083 | validation: 0.0210618710486377]
	TIME [epoch: 5.73 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02948050236960573		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.02948050236960573 | validation: 0.021934913633539686]
	TIME [epoch: 5.72 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028710755012326297		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.028710755012326297 | validation: 0.01699646832412631]
	TIME [epoch: 5.72 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025406596674238665		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.025406596674238665 | validation: 0.02072369911100632]
	TIME [epoch: 5.71 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026291146078832046		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.026291146078832046 | validation: 0.02347796495779436]
	TIME [epoch: 5.71 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02839948355986453		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.02839948355986453 | validation: 0.016587565124975463]
	TIME [epoch: 5.71 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02656279458209207		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.02656279458209207 | validation: 0.014486676922744066]
	TIME [epoch: 5.75 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02840233148903304		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.02840233148903304 | validation: 0.024175138518960724]
	TIME [epoch: 5.72 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02378598601556847		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.02378598601556847 | validation: 0.020137611337412164]
	TIME [epoch: 5.71 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022251295898902117		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.022251295898902117 | validation: 0.017799840409616956]
	TIME [epoch: 5.72 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023371575691103992		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.023371575691103992 | validation: 0.01437743193593294]
	TIME [epoch: 5.72 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023492621904081364		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.023492621904081364 | validation: 0.021979870302954733]
	TIME [epoch: 5.71 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02617451003891536		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.02617451003891536 | validation: 0.01707021271647266]
	TIME [epoch: 5.74 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024976068381310963		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.024976068381310963 | validation: 0.01513696301328328]
	TIME [epoch: 5.73 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022497851904838072		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.022497851904838072 | validation: 0.01865992814864093]
	TIME [epoch: 5.72 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02402129286259068		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.02402129286259068 | validation: 0.019870978714721314]
	TIME [epoch: 5.72 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02434608994291349		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.02434608994291349 | validation: 0.023940123029415564]
	TIME [epoch: 5.72 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02644453027227086		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.02644453027227086 | validation: 0.017251780537351363]
	TIME [epoch: 5.71 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02460935208967194		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.02460935208967194 | validation: 0.019655748303921704]
	TIME [epoch: 5.72 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02668292173231588		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.02668292173231588 | validation: 0.023949459954666616]
	TIME [epoch: 5.76 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027051413965305478		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.027051413965305478 | validation: 0.02121798192852518]
	TIME [epoch: 5.72 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02203144908558064		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.02203144908558064 | validation: 0.017613574741152875]
	TIME [epoch: 5.71 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022810720782119147		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.022810720782119147 | validation: 0.020904580751594234]
	TIME [epoch: 5.71 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022538219553454315		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.022538219553454315 | validation: 0.019505360953895417]
	TIME [epoch: 5.71 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02479369642756951		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.02479369642756951 | validation: 0.01995196389464617]
	TIME [epoch: 5.71 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025195150318517084		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.025195150318517084 | validation: 0.016727457120001694]
	TIME [epoch: 5.74 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027630855266991605		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.027630855266991605 | validation: 0.02507975774542741]
	TIME [epoch: 5.73 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0263108619157803		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.0263108619157803 | validation: 0.02179548316555797]
	TIME [epoch: 5.71 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024886579180088474		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.024886579180088474 | validation: 0.01675630556335786]
	TIME [epoch: 5.72 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02430090057491948		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.02430090057491948 | validation: 0.021669245540475824]
	TIME [epoch: 5.71 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024427105267948775		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.024427105267948775 | validation: 0.021012701541995]
	TIME [epoch: 5.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02806548043222218		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.02806548043222218 | validation: 0.012899072948306962]
	TIME [epoch: 5.71 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024579363906542345		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.024579363906542345 | validation: 0.019330115628832176]
	TIME [epoch: 5.76 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022987180573238297		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.022987180573238297 | validation: 0.02312291507481951]
	TIME [epoch: 5.72 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02623302447540843		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.02623302447540843 | validation: 0.02468581785625098]
	TIME [epoch: 5.71 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022061152358287706		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.022061152358287706 | validation: 0.02531100673819481]
	TIME [epoch: 5.71 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025170719892858805		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.025170719892858805 | validation: 0.02753706235689809]
	TIME [epoch: 5.71 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023351148734670812		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.023351148734670812 | validation: 0.028639656401029594]
	TIME [epoch: 5.71 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02478724623860021		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.02478724623860021 | validation: 0.019617461369282926]
	TIME [epoch: 5.74 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02454596314273163		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.02454596314273163 | validation: 0.02715270152359123]
	TIME [epoch: 5.74 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027944677430325467		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.027944677430325467 | validation: 0.029399723466897124]
	TIME [epoch: 5.72 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331139583419525		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.02331139583419525 | validation: 0.02762916917692168]
	TIME [epoch: 5.71 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331363213865481		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.02331363213865481 | validation: 0.020522783386760515]
	TIME [epoch: 5.72 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0254182556678664		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.0254182556678664 | validation: 0.02893156095967657]
	TIME [epoch: 5.72 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028169734060094435		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.028169734060094435 | validation: 0.02627634255643045]
	TIME [epoch: 5.71 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025657386556145353		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.025657386556145353 | validation: 0.015125828970992381]
	TIME [epoch: 5.76 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025391221628338324		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.025391221628338324 | validation: 0.019767991729579687]
	TIME [epoch: 5.72 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025113326992357878		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.025113326992357878 | validation: 0.024152967678866415]
	TIME [epoch: 5.71 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022614539879683065		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.022614539879683065 | validation: 0.02800258568967796]
	TIME [epoch: 5.72 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025286163402364576		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.025286163402364576 | validation: 0.02079137015880458]
	TIME [epoch: 5.71 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023724332869788617		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.023724332869788617 | validation: 0.02478856540831101]
	TIME [epoch: 5.71 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024889022134317318		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.024889022134317318 | validation: 0.01700614324364592]
	TIME [epoch: 5.74 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0250717253021147		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.0250717253021147 | validation: 0.024250342707097285]
	TIME [epoch: 5.74 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024615432326652517		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.024615432326652517 | validation: 0.02945577203722159]
	TIME [epoch: 5.71 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024451327872607124		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.024451327872607124 | validation: 0.02170919127919398]
	TIME [epoch: 5.72 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023998406197411518		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.023998406197411518 | validation: 0.023191924801722292]
	TIME [epoch: 5.71 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028990806796242028		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.028990806796242028 | validation: 0.02027011049488679]
	TIME [epoch: 5.71 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02700415169250223		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.02700415169250223 | validation: 0.020923221589509162]
	TIME [epoch: 5.71 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020128549872738398		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.020128549872738398 | validation: 0.01965889838784042]
	TIME [epoch: 5.75 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025623662245365175		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.025623662245365175 | validation: 0.020851551221217006]
	TIME [epoch: 5.73 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026925624120599335		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.026925624120599335 | validation: 0.01999955405224126]
	TIME [epoch: 5.71 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020824434304236923		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.020824434304236923 | validation: 0.013437872280419642]
	TIME [epoch: 5.71 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02256901055161422		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.02256901055161422 | validation: 0.01658171840744346]
	TIME [epoch: 5.72 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027166191355993685		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.027166191355993685 | validation: 0.016644837470162308]
	TIME [epoch: 5.72 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0259615543524645		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.0259615543524645 | validation: 0.01823340731095464]
	TIME [epoch: 5.74 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026952953797391026		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.026952953797391026 | validation: 0.025706702547790124]
	TIME [epoch: 5.73 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02464809556698582		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.02464809556698582 | validation: 0.02432600977352479]
	TIME [epoch: 5.71 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021333732592572437		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.021333732592572437 | validation: 0.019902558172865566]
	TIME [epoch: 5.71 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022766217152073095		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.022766217152073095 | validation: 0.01856346000190604]
	TIME [epoch: 5.71 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021481589832199922		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.021481589832199922 | validation: 0.02013881060837985]
	TIME [epoch: 5.72 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331760374215019		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.02331760374215019 | validation: 0.021252980040303168]
	TIME [epoch: 5.71 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023789976638558363		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.023789976638558363 | validation: 0.019729054933271897]
	TIME [epoch: 5.77 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024736976317143756		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.024736976317143756 | validation: 0.019931538650585775]
	TIME [epoch: 5.73 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022229789363614746		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.022229789363614746 | validation: 0.017607519208830955]
	TIME [epoch: 5.72 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028546638152394787		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.028546638152394787 | validation: 0.02381522323585733]
	TIME [epoch: 5.72 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026731195897820463		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.026731195897820463 | validation: 0.020935780323301185]
	TIME [epoch: 5.72 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028065860969579165		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.028065860969579165 | validation: 0.024632866812452393]
	TIME [epoch: 5.71 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026081262555328		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.026081262555328 | validation: 0.02545652551241036]
	TIME [epoch: 5.74 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0277193136324972		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.0277193136324972 | validation: 0.02231808040873335]
	TIME [epoch: 5.74 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025053144912055587		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.025053144912055587 | validation: 0.025950246165301727]
	TIME [epoch: 5.72 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026313659852935954		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.026313659852935954 | validation: 0.027949389356648348]
	TIME [epoch: 5.72 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026108672682971137		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.026108672682971137 | validation: 0.01470382518330749]
	TIME [epoch: 5.72 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027763958584449064		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.027763958584449064 | validation: 0.009702880603810134]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_1586.pth
	Model improved!!!
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029090590420822977		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.029090590420822977 | validation: 0.019803671237839805]
	TIME [epoch: 5.72 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03141559459232634		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.03141559459232634 | validation: 0.02465956868000836]
	TIME [epoch: 5.74 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026341762346300795		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.026341762346300795 | validation: 0.029147198691900456]
	TIME [epoch: 5.71 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127133460623406		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.03127133460623406 | validation: 0.020025608831916314]
	TIME [epoch: 5.72 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02581753361479218		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.02581753361479218 | validation: 0.02624883590504417]
	TIME [epoch: 5.71 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024492546178476703		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.024492546178476703 | validation: 0.01655121846527306]
	TIME [epoch: 5.72 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023107374283578397		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.023107374283578397 | validation: 0.018801816127917013]
	TIME [epoch: 5.71 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02249227647699093		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.02249227647699093 | validation: 0.025745184622912313]
	TIME [epoch: 5.74 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025483289454589178		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.025483289454589178 | validation: 0.018576806075251407]
	TIME [epoch: 5.72 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023710916791955205		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.023710916791955205 | validation: 0.016561209830236494]
	TIME [epoch: 5.72 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02668005098445949		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.02668005098445949 | validation: 0.020538826301237708]
	TIME [epoch: 5.7 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023169042289992163		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.023169042289992163 | validation: 0.016804009552352405]
	TIME [epoch: 5.7 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023090985139840238		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.023090985139840238 | validation: 0.023034802501856712]
	TIME [epoch: 5.71 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021366601062792038		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.021366601062792038 | validation: 0.022230159862858662]
	TIME [epoch: 5.73 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024349640965643078		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.024349640965643078 | validation: 0.02174380625756825]
	TIME [epoch: 5.75 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025268850119297623		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.025268850119297623 | validation: 0.021312100222110428]
	TIME [epoch: 5.72 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02485454029437102		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.02485454029437102 | validation: 0.011376258555149992]
	TIME [epoch: 5.71 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02451266006060386		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.02451266006060386 | validation: 0.024521928302358182]
	TIME [epoch: 5.72 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020412156731478143		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.020412156731478143 | validation: 0.023611780303993447]
	TIME [epoch: 5.71 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02178069315902841		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.02178069315902841 | validation: 0.02709390532808647]
	TIME [epoch: 5.69 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023592088429617627		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.023592088429617627 | validation: 0.019160797847617733]
	TIME [epoch: 5.75 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028414241359387263		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.028414241359387263 | validation: 0.020920406122086534]
	TIME [epoch: 5.71 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026783021252400653		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.026783021252400653 | validation: 0.021848576095979035]
	TIME [epoch: 5.7 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021792903683499915		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.021792903683499915 | validation: 0.020856045843145925]
	TIME [epoch: 5.7 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02359619427641868		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.02359619427641868 | validation: 0.017093175248791]
	TIME [epoch: 5.71 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023093790158858603		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.023093790158858603 | validation: 0.019101427780445983]
	TIME [epoch: 5.7 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025297353940634287		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.025297353940634287 | validation: 0.019766828505896165]
	TIME [epoch: 5.72 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022093408552898316		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.022093408552898316 | validation: 0.021030541898071978]
	TIME [epoch: 5.74 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02255622029976679		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.02255622029976679 | validation: 0.015411348798542392]
	TIME [epoch: 5.71 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025183283751672128		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.025183283751672128 | validation: 0.016272651338904688]
	TIME [epoch: 5.72 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02296768495395614		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.02296768495395614 | validation: 0.015970756732798068]
	TIME [epoch: 5.71 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02497345019371213		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.02497345019371213 | validation: 0.015479055133691839]
	TIME [epoch: 5.72 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024468885199306522		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.024468885199306522 | validation: 0.019690923864280493]
	TIME [epoch: 5.71 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026005767470838523		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.026005767470838523 | validation: 0.023849155295269236]
	TIME [epoch: 5.75 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02517622960594042		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.02517622960594042 | validation: 0.02075685592203232]
	TIME [epoch: 5.73 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027945464795076022		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.027945464795076022 | validation: 0.016814890433774394]
	TIME [epoch: 5.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027597573473265077		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.027597573473265077 | validation: 0.013998256227299761]
	TIME [epoch: 5.7 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025604966231097186		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.025604966231097186 | validation: 0.02374530212070206]
	TIME [epoch: 5.69 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022531161764710296		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.022531161764710296 | validation: 0.01774725478088733]
	TIME [epoch: 5.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025468606124312464		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.025468606124312464 | validation: 0.01712750716034837]
	TIME [epoch: 5.72 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02545785606073476		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.02545785606073476 | validation: 0.02174531783076393]
	TIME [epoch: 5.76 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02269571585946087		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.02269571585946087 | validation: 0.031182673144196316]
	TIME [epoch: 5.72 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023758355406484737		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.023758355406484737 | validation: 0.02902831762276094]
	TIME [epoch: 5.72 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024051116916476364		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.024051116916476364 | validation: 0.020753442126766886]
	TIME [epoch: 5.72 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024158839793666943		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.024158839793666943 | validation: 0.023967280212166885]
	TIME [epoch: 5.72 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024670745070620885		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.024670745070620885 | validation: 0.024073043638707436]
	TIME [epoch: 5.71 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02712087829198811		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.02712087829198811 | validation: 0.01902059059333867]
	TIME [epoch: 5.76 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023235304770621842		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.023235304770621842 | validation: 0.021355598052379507]
	TIME [epoch: 5.72 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023383015476674596		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.023383015476674596 | validation: 0.021911283900149067]
	TIME [epoch: 5.72 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024870246801333963		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.024870246801333963 | validation: 0.021095727857272067]
	TIME [epoch: 5.72 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02306121867530566		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.02306121867530566 | validation: 0.024000444097666804]
	TIME [epoch: 5.72 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025464696357640433		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.025464696357640433 | validation: 0.027442771860294236]
	TIME [epoch: 5.72 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02757237074721381		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.02757237074721381 | validation: 0.016988961869270527]
	TIME [epoch: 5.74 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024142919167481715		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.024142919167481715 | validation: 0.016280255071347737]
	TIME [epoch: 5.75 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02468977800518499		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.02468977800518499 | validation: 0.012667584994994737]
	TIME [epoch: 5.72 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022992314093596863		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.022992314093596863 | validation: 0.02390271941985922]
	TIME [epoch: 5.71 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025794093249801312		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.025794093249801312 | validation: 0.01533975561729761]
	TIME [epoch: 5.72 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022702504073312944		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.022702504073312944 | validation: 0.015508520483145674]
	TIME [epoch: 5.72 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028049709999156028		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.028049709999156028 | validation: 0.024033233876529503]
	TIME [epoch: 5.72 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023937798117651433		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.023937798117651433 | validation: 0.01325537711859205]
	TIME [epoch: 5.77 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021431302388469933		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.021431302388469933 | validation: 0.022531629566976547]
	TIME [epoch: 5.72 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02359201979319349		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.02359201979319349 | validation: 0.02731928742578518]
	TIME [epoch: 5.72 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02261417605848309		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.02261417605848309 | validation: 0.026047126631669144]
	TIME [epoch: 5.72 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02641971097638144		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.02641971097638144 | validation: 0.017714122747662178]
	TIME [epoch: 5.72 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02293416947185525		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.02293416947185525 | validation: 0.027685233129898856]
	TIME [epoch: 5.72 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025682235500203918		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.025682235500203918 | validation: 0.02303012626455386]
	TIME [epoch: 5.72 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023271899661947378		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.023271899661947378 | validation: 0.021181321465380567]
	TIME [epoch: 5.75 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026569264627764082		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.026569264627764082 | validation: 0.02006549801566837]
	TIME [epoch: 5.72 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024514632394572834		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.024514632394572834 | validation: 0.024713815932583358]
	TIME [epoch: 5.71 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023136970643044062		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.023136970643044062 | validation: 0.020124118539266506]
	TIME [epoch: 5.72 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025845413752914208		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.025845413752914208 | validation: 0.021408967348484628]
	TIME [epoch: 5.72 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02137080799490223		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.02137080799490223 | validation: 0.02303189972179152]
	TIME [epoch: 5.72 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027939137915671042		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.027939137915671042 | validation: 0.023041222415579418]
	TIME [epoch: 5.77 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022189923984672212		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.022189923984672212 | validation: 0.023544043163866]
	TIME [epoch: 5.71 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026367150144483792		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.026367150144483792 | validation: 0.0210593702866725]
	TIME [epoch: 5.69 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023795718658093542		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.023795718658093542 | validation: 0.02544371187881322]
	TIME [epoch: 5.71 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021614673946130175		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.021614673946130175 | validation: 0.021547032555493076]
	TIME [epoch: 5.71 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02325374766342879		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.02325374766342879 | validation: 0.0244592582687244]
	TIME [epoch: 5.71 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023033896342435786		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.023033896342435786 | validation: 0.019534275685361906]
	TIME [epoch: 5.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027284598735235872		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.027284598735235872 | validation: 0.027327548634636795]
	TIME [epoch: 5.75 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020874097781221776		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.020874097781221776 | validation: 0.020802074307487112]
	TIME [epoch: 5.72 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02290506727294066		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.02290506727294066 | validation: 0.018472666679432894]
	TIME [epoch: 5.72 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0193308302285145		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.0193308302285145 | validation: 0.018446444992916165]
	TIME [epoch: 5.72 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025189463848528		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.025189463848528 | validation: 0.022644485611382166]
	TIME [epoch: 5.72 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023817837662456032		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.023817837662456032 | validation: 0.022985127588173008]
	TIME [epoch: 5.71 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02542377286304567		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.02542377286304567 | validation: 0.0248890846227622]
	TIME [epoch: 5.76 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026629045353169047		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.026629045353169047 | validation: 0.02640380774103039]
	TIME [epoch: 5.71 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024253541469634696		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.024253541469634696 | validation: 0.02156347164118284]
	TIME [epoch: 5.72 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022321831776828074		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.022321831776828074 | validation: 0.02345813703408238]
	TIME [epoch: 5.7 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026947953117260653		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.026947953117260653 | validation: 0.024182270907553063]
	TIME [epoch: 5.72 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02720598142390073		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.02720598142390073 | validation: 0.03013887922068684]
	TIME [epoch: 5.71 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023850355550159075		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.023850355550159075 | validation: 0.013223641247662876]
	TIME [epoch: 5.73 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023995078948211793		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.023995078948211793 | validation: 0.018765857950429215]
	TIME [epoch: 5.74 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024459676063488908		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.024459676063488908 | validation: 0.02299079852740423]
	TIME [epoch: 5.72 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023980365119443195		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.023980365119443195 | validation: 0.018982662475534488]
	TIME [epoch: 5.7 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022461571842169563		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.022461571842169563 | validation: 0.027569438711748412]
	TIME [epoch: 5.72 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025893860148954957		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.025893860148954957 | validation: 0.022391246972733318]
	TIME [epoch: 5.71 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026068269667597246		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.026068269667597246 | validation: 0.015751819572195843]
	TIME [epoch: 5.72 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02628437745643858		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.02628437745643858 | validation: 0.019946966238860168]
	TIME [epoch: 5.76 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021796763736504146		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.021796763736504146 | validation: 0.024363959210583416]
	TIME [epoch: 5.72 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024889887756283112		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.024889887756283112 | validation: 0.02764612721632715]
	TIME [epoch: 5.72 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02888733043180703		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.02888733043180703 | validation: 0.023135407840567127]
	TIME [epoch: 5.72 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023525993410140104		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.023525993410140104 | validation: 0.017085286767610133]
	TIME [epoch: 5.7 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029284222980393584		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.029284222980393584 | validation: 0.01855250432534172]
	TIME [epoch: 5.71 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02763974724224067		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.02763974724224067 | validation: 0.0238273731605314]
	TIME [epoch: 5.73 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02625112128898698		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.02625112128898698 | validation: 0.023903965409593064]
	TIME [epoch: 5.76 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024797982559082193		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.024797982559082193 | validation: 0.022549840701972232]
	TIME [epoch: 5.72 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026901705925237048		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.026901705925237048 | validation: 0.019222318004687735]
	TIME [epoch: 5.72 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02334131166635822		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.02334131166635822 | validation: 0.02190056200887125]
	TIME [epoch: 5.71 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02314055941072622		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.02314055941072622 | validation: 0.016579964166334168]
	TIME [epoch: 5.72 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02314578486229867		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.02314578486229867 | validation: 0.028061797349181728]
	TIME [epoch: 5.71 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024646020413568323		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.024646020413568323 | validation: 0.018133596062871273]
	TIME [epoch: 5.76 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023950563756499094		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.023950563756499094 | validation: 0.0257258769922013]
	TIME [epoch: 5.71 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023461675381255556		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.023461675381255556 | validation: 0.017595066139526435]
	TIME [epoch: 5.72 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02395973324563105		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.02395973324563105 | validation: 0.007880872202032412]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240310_003030/states/model_tr_study2_1701.pth
	Model improved!!!
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02333801357923758		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.02333801357923758 | validation: 0.02285274355759858]
	TIME [epoch: 5.73 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02289261548606822		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.02289261548606822 | validation: 0.015644816270352722]
	TIME [epoch: 5.72 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022579629530560672		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.022579629530560672 | validation: 0.01700375623205261]
	TIME [epoch: 5.75 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025147828650364242		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.025147828650364242 | validation: 0.01989925152387726]
	TIME [epoch: 5.72 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023614303002884134		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.023614303002884134 | validation: 0.02197787666024353]
	TIME [epoch: 5.72 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027459695170268847		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.027459695170268847 | validation: 0.024802991147434252]
	TIME [epoch: 5.71 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02674067875759638		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.02674067875759638 | validation: 0.014763620628898796]
	TIME [epoch: 5.73 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024707893127719503		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.024707893127719503 | validation: 0.022767294435787202]
	TIME [epoch: 5.71 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013441752980208		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.02013441752980208 | validation: 0.026944725800048558]
	TIME [epoch: 5.73 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0196824860761996		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.0196824860761996 | validation: 0.016339598518810027]
	TIME [epoch: 5.77 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019100410479777175		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.019100410479777175 | validation: 0.022000291902116262]
	TIME [epoch: 5.72 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02573995785275883		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.02573995785275883 | validation: 0.017579795370124638]
	TIME [epoch: 5.7 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021720491995377494		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.021720491995377494 | validation: 0.01923004624035814]
	TIME [epoch: 5.72 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02530696877908474		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.02530696877908474 | validation: 0.019784791935348395]
	TIME [epoch: 5.72 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02430878139520189		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.02430878139520189 | validation: 0.02460617574927066]
	TIME [epoch: 5.72 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02419948121837362		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.02419948121837362 | validation: 0.021962821581590842]
	TIME [epoch: 5.75 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022691287705162346		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.022691287705162346 | validation: 0.020050872455384613]
	TIME [epoch: 5.74 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024760379021149623		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.024760379021149623 | validation: 0.01390776333686265]
	TIME [epoch: 5.72 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024920123455502576		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.024920123455502576 | validation: 0.023873679080098565]
	TIME [epoch: 5.72 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02514187096172449		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.02514187096172449 | validation: 0.008635470554863158]
	TIME [epoch: 5.72 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026455763599786915		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.026455763599786915 | validation: 0.02386519279205097]
	TIME [epoch: 5.72 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023244784334115545		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.023244784334115545 | validation: 0.027315386339219233]
	TIME [epoch: 5.73 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024149537220197595		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.024149537220197595 | validation: 0.020601593332789464]
	TIME [epoch: 5.78 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028544878928826546		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.028544878928826546 | validation: 0.015568196655646824]
	TIME [epoch: 5.72 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02103710189310635		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.02103710189310635 | validation: 0.019756867512042833]
	TIME [epoch: 5.73 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02439955089156243		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.02439955089156243 | validation: 0.016231548033660507]
	TIME [epoch: 5.7 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022739855571072273		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.022739855571072273 | validation: 0.027927410425923217]
	TIME [epoch: 5.73 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025057922142956233		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.025057922142956233 | validation: 0.021084488747405032]
	TIME [epoch: 5.71 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02246876241474142		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.02246876241474142 | validation: 0.025341483054570926]
	TIME [epoch: 5.73 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02273955444372257		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.02273955444372257 | validation: 0.01854737231176642]
	TIME [epoch: 5.73 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023946293395001268		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.023946293395001268 | validation: 0.02005325611876269]
	TIME [epoch: 5.7 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025941568525469902		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.025941568525469902 | validation: 0.018080019456714398]
	TIME [epoch: 5.71 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025705355457298636		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.025705355457298636 | validation: 0.017793214109123025]
	TIME [epoch: 5.7 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02376162118222098		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.02376162118222098 | validation: 0.022886663981120145]
	TIME [epoch: 5.71 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024572031345863367		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.024572031345863367 | validation: 0.022266588907340117]
	TIME [epoch: 5.7 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020627248890422226		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.020627248890422226 | validation: 0.025563578129801586]
	TIME [epoch: 5.76 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023081144481807453		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.023081144481807453 | validation: 0.01746601720313918]
	TIME [epoch: 5.7 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024875758526330047		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.024875758526330047 | validation: 0.020488295518618832]
	TIME [epoch: 5.72 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024578772850018568		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.024578772850018568 | validation: 0.019626500830289967]
	TIME [epoch: 5.72 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021665175413671266		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.021665175413671266 | validation: 0.017227756731126004]
	TIME [epoch: 5.72 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027612146112056316		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.027612146112056316 | validation: 0.018948190211097952]
	TIME [epoch: 5.71 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024864446332100387		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.024864446332100387 | validation: 0.015190048007580845]
	TIME [epoch: 5.73 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020495823537902386		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.020495823537902386 | validation: 0.022156857153145186]
	TIME [epoch: 5.72 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0249831093475446		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.0249831093475446 | validation: 0.020917908059464255]
	TIME [epoch: 5.71 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019806436852092046		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.019806436852092046 | validation: 0.01599443950717585]
	TIME [epoch: 5.7 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024340366511642564		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.024340366511642564 | validation: 0.018284795764227663]
	TIME [epoch: 5.72 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021759131883933528		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.021759131883933528 | validation: 0.026712408547164012]
	TIME [epoch: 5.71 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02403430666788		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.02403430666788 | validation: 0.021418974680108525]
	TIME [epoch: 5.71 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028054050271047105		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.028054050271047105 | validation: 0.02673685642047656]
	TIME [epoch: 5.76 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02432508939693535		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.02432508939693535 | validation: 0.020011728915701008]
	TIME [epoch: 5.71 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02501779910002932		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.02501779910002932 | validation: 0.024719777598303284]
	TIME [epoch: 5.71 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021900719744291038		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.021900719744291038 | validation: 0.02508374853874062]
	TIME [epoch: 5.7 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02116934884528982		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.02116934884528982 | validation: 0.026829676248049234]
	TIME [epoch: 5.72 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022895621252913424		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.022895621252913424 | validation: 0.031032801428971198]
	TIME [epoch: 5.7 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02556897101724259		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.02556897101724259 | validation: 0.02361182527155519]
	TIME [epoch: 5.74 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022690987195616234		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.022690987195616234 | validation: 0.013075290535053626]
	TIME [epoch: 5.74 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021279641049033453		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.021279641049033453 | validation: 0.024798654571850244]
	TIME [epoch: 5.71 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028226883596215578		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.028226883596215578 | validation: 0.01684985053599246]
	TIME [epoch: 5.71 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026178373431910304		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.026178373431910304 | validation: 0.0197113481577708]
	TIME [epoch: 5.71 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025186302425015142		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.025186302425015142 | validation: 0.026414451937574964]
	TIME [epoch: 5.71 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026511299351674424		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.026511299351674424 | validation: 0.023220151451956196]
	TIME [epoch: 5.71 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022209067516671475		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.022209067516671475 | validation: 0.022222170880618907]
	TIME [epoch: 5.77 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023082742806957067		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.023082742806957067 | validation: 0.02109887116299279]
	TIME [epoch: 5.71 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02595594908254511		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.02595594908254511 | validation: 0.020529077076781786]
	TIME [epoch: 5.72 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023975634629642036		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.023975634629642036 | validation: 0.020573800532061128]
	TIME [epoch: 5.72 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022641288804350516		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.022641288804350516 | validation: 0.02029714272589879]
	TIME [epoch: 5.72 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02826155652879335		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.02826155652879335 | validation: 0.019729005215912948]
	TIME [epoch: 5.7 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021122596468628314		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.021122596468628314 | validation: 0.020954491446547516]
	TIME [epoch: 5.73 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025868729549450888		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.025868729549450888 | validation: 0.01811338814169435]
	TIME [epoch: 5.73 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02406813431177648		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.02406813431177648 | validation: 0.02341850940994488]
	TIME [epoch: 5.71 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026130291511615233		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.026130291511615233 | validation: 0.01959774142426817]
	TIME [epoch: 5.7 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02421061440906602		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.02421061440906602 | validation: 0.02267018302378662]
	TIME [epoch: 5.71 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023368110163247382		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.023368110163247382 | validation: 0.024031618264509298]
	TIME [epoch: 5.7 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0243132016493557		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.0243132016493557 | validation: 0.025566740153056104]
	TIME [epoch: 5.71 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025598077946733893		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.025598077946733893 | validation: 0.01657116833764108]
	TIME [epoch: 5.75 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022363053088229765		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.022363053088229765 | validation: 0.026043057072180187]
	TIME [epoch: 5.71 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02686426497113619		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.02686426497113619 | validation: 0.017579280517019596]
	TIME [epoch: 5.71 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025158587975127746		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.025158587975127746 | validation: 0.01586749305526476]
	TIME [epoch: 5.71 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02041992963670535		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.02041992963670535 | validation: 0.02226533326179668]
	TIME [epoch: 5.71 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025257132968382535		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.025257132968382535 | validation: 0.022003934754513628]
	TIME [epoch: 5.72 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02293836094095819		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.02293836094095819 | validation: 0.021138593531503293]
	TIME [epoch: 5.73 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02606640530574243		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.02606640530574243 | validation: 0.018912972512827565]
	TIME [epoch: 5.72 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02599758639684771		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.02599758639684771 | validation: 0.02148448661504708]
	TIME [epoch: 5.7 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02785021713425201		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.02785021713425201 | validation: 0.015225892673554276]
	TIME [epoch: 5.71 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024983384410307386		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.024983384410307386 | validation: 0.021069740184854618]
	TIME [epoch: 5.71 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0255587470300492		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.0255587470300492 | validation: 0.013490525418354394]
	TIME [epoch: 5.7 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02253309277543635		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.02253309277543635 | validation: 0.024389047241487195]
	TIME [epoch: 5.71 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02500167294091029		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.02500167294091029 | validation: 0.026326654699558007]
	TIME [epoch: 5.75 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026484450351790787		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.026484450351790787 | validation: 0.022267741114234654]
	TIME [epoch: 5.7 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02290451494376965		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.02290451494376965 | validation: 0.02376186815586503]
	TIME [epoch: 5.72 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021689882336229316		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.021689882336229316 | validation: 0.021816853843217524]
	TIME [epoch: 5.7 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025242670090474872		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.025242670090474872 | validation: 0.021633785817046728]
	TIME [epoch: 5.71 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02196218903329971		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.02196218903329971 | validation: 0.020108458996510353]
	TIME [epoch: 5.7 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026089955134306182		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.026089955134306182 | validation: 0.028975460331139735]
	TIME [epoch: 5.74 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0236522445400108		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.0236522445400108 | validation: 0.022648720212731465]
	TIME [epoch: 5.74 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02269705403870127		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.02269705403870127 | validation: 0.019455036991527855]
	TIME [epoch: 5.71 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023560202127298095		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.023560202127298095 | validation: 0.023413302799713938]
	TIME [epoch: 5.71 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024139026952775484		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.024139026952775484 | validation: 0.024477310546112577]
	TIME [epoch: 5.7 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02020704420119334		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.02020704420119334 | validation: 0.022363753831846106]
	TIME [epoch: 5.71 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026234514832042442		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.026234514832042442 | validation: 0.020787020200913057]
	TIME [epoch: 5.73 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025382563636448786		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.025382563636448786 | validation: 0.021415361683923575]
	TIME [epoch: 5.75 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023362002014092012		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.023362002014092012 | validation: 0.02706352989141821]
	TIME [epoch: 5.71 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023184281192563442		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.023184281192563442 | validation: 0.017218160181371327]
	TIME [epoch: 5.71 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022794093879183887		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.022794093879183887 | validation: 0.023464887202147348]
	TIME [epoch: 5.72 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025439825148381945		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.025439825148381945 | validation: 0.022337341005517583]
	TIME [epoch: 5.7 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02381638197846548		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.02381638197846548 | validation: 0.021032902007188038]
	TIME [epoch: 5.7 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022567231726289074		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.022567231726289074 | validation: 0.021235005573445917]
	TIME [epoch: 5.79 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018215635374818743		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.018215635374818743 | validation: 0.023233280110762245]
	TIME [epoch: 5.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020931838667331698		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.020931838667331698 | validation: 0.02199733125987017]
	TIME [epoch: 5.7 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024567570649675137		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.024567570649675137 | validation: 0.019615316903226657]
	TIME [epoch: 5.71 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024042149231738363		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.024042149231738363 | validation: 0.028199427281919945]
	TIME [epoch: 5.7 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022363249662822778		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.022363249662822778 | validation: 0.02635748030506682]
	TIME [epoch: 5.71 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023049093993595997		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.023049093993595997 | validation: 0.020293311905008184]
	TIME [epoch: 5.72 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02535542272447592		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.02535542272447592 | validation: 0.0200590567769532]
	TIME [epoch: 5.73 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02436656726641445		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.02436656726641445 | validation: 0.009875761962354979]
	TIME [epoch: 5.71 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024340198340299282		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.024340198340299282 | validation: 0.022594291584891048]
	TIME [epoch: 5.7 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02328017036180632		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.02328017036180632 | validation: 0.02529321045472824]
	TIME [epoch: 5.69 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026121558752102047		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.026121558752102047 | validation: 0.02048961680996974]
	TIME [epoch: 5.71 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026834900060838954		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.026834900060838954 | validation: 0.024493644367574507]
	TIME [epoch: 5.71 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02480388991761917		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.02480388991761917 | validation: 0.0170690597991267]
	TIME [epoch: 5.76 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024193237137910543		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.024193237137910543 | validation: 0.025745529004608258]
	TIME [epoch: 5.73 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02002327424197218		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.02002327424197218 | validation: 0.024406888534514674]
	TIME [epoch: 5.71 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023262443304015702		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.023262443304015702 | validation: 0.019446862643146382]
	TIME [epoch: 5.7 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022794985787151834		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.022794985787151834 | validation: 0.02130618697836279]
	TIME [epoch: 5.7 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020785859603491108		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.020785859603491108 | validation: 0.017398655289615286]
	TIME [epoch: 5.7 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02357291079935934		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.02357291079935934 | validation: 0.022492178223618004]
	TIME [epoch: 5.73 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019450595716234417		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.019450595716234417 | validation: 0.020323333963198735]
	TIME [epoch: 5.74 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02079257738722001		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.02079257738722001 | validation: 0.02772060715378715]
	TIME [epoch: 5.71 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023800849211879256		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.023800849211879256 | validation: 0.02359839070070911]
	TIME [epoch: 5.71 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02336733053408549		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.02336733053408549 | validation: 0.022103166114162395]
	TIME [epoch: 5.7 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021472798172862947		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.021472798172862947 | validation: 0.014227082173313197]
	TIME [epoch: 5.71 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022541411406292285		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.022541411406292285 | validation: 0.020849795937742468]
	TIME [epoch: 5.72 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022072375719119606		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.022072375719119606 | validation: 0.02083213754121302]
	TIME [epoch: 5.76 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02520119253734828		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.02520119253734828 | validation: 0.023711957753086696]
	TIME [epoch: 5.71 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026751847826343482		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.026751847826343482 | validation: 0.02836797225299769]
	TIME [epoch: 5.7 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024012760579418178		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.024012760579418178 | validation: 0.015344689284941322]
	TIME [epoch: 5.7 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020606278745638022		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.020606278745638022 | validation: 0.019408325467711547]
	TIME [epoch: 5.7 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025796769540059716		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.025796769540059716 | validation: 0.025278077551303967]
	TIME [epoch: 5.7 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025176827506586497		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.025176827506586497 | validation: 0.027799729210345514]
	TIME [epoch: 5.71 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02564593454399563		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.02564593454399563 | validation: 0.022349915385619725]
	TIME [epoch: 5.74 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023183825736352665		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.023183825736352665 | validation: 0.023979819438482923]
	TIME [epoch: 5.7 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024145771313991052		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.024145771313991052 | validation: 0.010950975083539783]
	TIME [epoch: 5.71 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02258583580417719		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.02258583580417719 | validation: 0.024589504776239432]
	TIME [epoch: 5.7 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02269385195912151		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.02269385195912151 | validation: 0.021336418525566815]
	TIME [epoch: 5.71 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023346940507554252		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.023346940507554252 | validation: 0.018489653548051203]
	TIME [epoch: 5.71 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02487751509644712		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.02487751509644712 | validation: 0.024280933221810547]
	TIME [epoch: 5.77 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02734916569028176		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.02734916569028176 | validation: 0.017899425422075125]
	TIME [epoch: 5.7 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02317811906609239		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.02317811906609239 | validation: 0.01591004648592238]
	TIME [epoch: 5.7 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023385617270527466		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.023385617270527466 | validation: 0.021782920022513166]
	TIME [epoch: 5.7 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02632929398002567		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.02632929398002567 | validation: 0.017167012015053544]
	TIME [epoch: 5.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0236551734559842		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.0236551734559842 | validation: 0.028258038700026123]
	TIME [epoch: 5.7 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027597994707041808		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.027597994707041808 | validation: 0.019119880201396437]
	TIME [epoch: 5.72 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023340468905787167		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.023340468905787167 | validation: 0.021180029823837165]
	TIME [epoch: 5.75 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022778516508587015		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.022778516508587015 | validation: 0.023939548315903735]
	TIME [epoch: 5.72 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02605769709869226		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.02605769709869226 | validation: 0.020397757138045865]
	TIME [epoch: 5.72 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024977083470714218		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.024977083470714218 | validation: 0.018938497878899764]
	TIME [epoch: 5.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02393784965398439		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.02393784965398439 | validation: 0.022793686390760525]
	TIME [epoch: 5.73 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02241859351203093		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.02241859351203093 | validation: 0.017221674740119007]
	TIME [epoch: 5.7 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026362291743830476		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.026362291743830476 | validation: 0.01704758871613784]
	TIME [epoch: 5.76 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02534599797880927		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.02534599797880927 | validation: 0.012397016314343454]
	TIME [epoch: 5.71 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021247996664338763		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.021247996664338763 | validation: 0.018671802903719184]
	TIME [epoch: 5.72 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02095010978814985		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.02095010978814985 | validation: 0.02540362540754575]
	TIME [epoch: 5.72 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020839045125609808		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.020839045125609808 | validation: 0.025963193150213355]
	TIME [epoch: 5.72 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023531229344781603		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.023531229344781603 | validation: 0.024143237380834626]
	TIME [epoch: 5.71 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02046041813982288		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.02046041813982288 | validation: 0.021021154460062287]
	TIME [epoch: 5.73 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025091290263848764		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.025091290263848764 | validation: 0.021583585042531203]
	TIME [epoch: 5.74 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024705308916589418		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.024705308916589418 | validation: 0.024150459677614308]
	TIME [epoch: 5.72 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022148657119108038		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.022148657119108038 | validation: 0.021287457966427534]
	TIME [epoch: 5.7 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020812865080994402		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.020812865080994402 | validation: 0.022738240904641334]
	TIME [epoch: 5.71 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02211515693855965		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.02211515693855965 | validation: 0.01571520382737225]
	TIME [epoch: 5.7 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02369932638723343		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.02369932638723343 | validation: 0.018253993620581457]
	TIME [epoch: 5.72 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02134986412831313		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.02134986412831313 | validation: 0.019427104243567764]
	TIME [epoch: 5.76 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027827501639187548		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.027827501639187548 | validation: 0.018820526507521557]
	TIME [epoch: 5.72 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02474177252691414		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.02474177252691414 | validation: 0.02459608048951567]
	TIME [epoch: 5.7 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024190658959340004		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.024190658959340004 | validation: 0.02436879327011279]
	TIME [epoch: 5.7 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024048569043052515		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.024048569043052515 | validation: 0.014038610419105266]
	TIME [epoch: 5.71 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020487610727388198		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.020487610727388198 | validation: 0.013661004210953526]
	TIME [epoch: 5.72 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02325935083283119		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.02325935083283119 | validation: 0.017635189527192858]
	TIME [epoch: 5.72 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02503769074683302		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.02503769074683302 | validation: 0.018475547148053714]
	TIME [epoch: 5.74 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026260162041550336		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.026260162041550336 | validation: 0.026503235446043105]
	TIME [epoch: 5.71 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026867743524415212		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.026867743524415212 | validation: 0.020258869818855697]
	TIME [epoch: 5.7 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02219769254802225		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.02219769254802225 | validation: 0.030248748306101258]
	TIME [epoch: 5.7 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02397449293135969		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.02397449293135969 | validation: 0.017675592920130292]
	TIME [epoch: 5.7 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0253984188977099		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.0253984188977099 | validation: 0.019214578766036307]
	TIME [epoch: 5.71 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02348827991813882		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.02348827991813882 | validation: 0.02451436361878074]
	TIME [epoch: 5.76 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026642651475698532		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.026642651475698532 | validation: 0.023457226488315986]
	TIME [epoch: 5.72 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02509399345806612		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.02509399345806612 | validation: 0.02508354733744791]
	TIME [epoch: 5.72 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020701152356991864		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.020701152356991864 | validation: 0.020217182915155917]
	TIME [epoch: 5.7 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02616058155547481		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.02616058155547481 | validation: 0.018896021997438978]
	TIME [epoch: 5.7 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024392688668916293		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.024392688668916293 | validation: 0.019263711885307698]
	TIME [epoch: 5.7 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02132672130722052		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.02132672130722052 | validation: 0.019595690370443033]
	TIME [epoch: 5.71 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018944591538776825		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.018944591538776825 | validation: 0.028128322784218947]
	TIME [epoch: 5.74 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022481914353924423		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.022481914353924423 | validation: 0.015960469206772604]
	TIME [epoch: 5.7 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021638530531563945		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.021638530531563945 | validation: 0.019719703802857102]
	TIME [epoch: 5.71 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020145370798882917		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.020145370798882917 | validation: 0.021407387732926414]
	TIME [epoch: 5.72 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023332892218073536		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.023332892218073536 | validation: 0.019970949209604853]
	TIME [epoch: 5.71 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025610234315524068		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.025610234315524068 | validation: 0.015659975260834784]
	TIME [epoch: 5.72 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021604948314318355		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.021604948314318355 | validation: 0.02004419897572026]
	TIME [epoch: 5.76 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021080161149365655		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.021080161149365655 | validation: 0.02307767780847552]
	TIME [epoch: 5.72 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022910767444180843		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.022910767444180843 | validation: 0.01215755121320067]
	TIME [epoch: 5.71 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02651161989288894		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.02651161989288894 | validation: 0.018657144012857462]
	TIME [epoch: 5.71 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024594167700748296		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.024594167700748296 | validation: 0.02262750496717457]
	TIME [epoch: 5.71 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022934211282159448		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.022934211282159448 | validation: 0.023541880534097885]
	TIME [epoch: 5.7 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021813856705803825		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.021813856705803825 | validation: 0.02294579445103811]
	TIME [epoch: 5.73 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02466293005536889		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.02466293005536889 | validation: 0.022271299437785844]
	TIME [epoch: 5.75 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023446546498314815		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.023446546498314815 | validation: 0.01993229422803192]
	TIME [epoch: 5.72 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024735963110094735		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.024735963110094735 | validation: 0.03304706175499713]
	TIME [epoch: 5.72 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022561176708817778		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.022561176708817778 | validation: 0.021237520929136226]
	TIME [epoch: 5.71 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025246389954183084		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.025246389954183084 | validation: 0.02489649217693406]
	TIME [epoch: 5.72 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022148174836567155		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.022148174836567155 | validation: 0.019855234323406485]
	TIME [epoch: 5.71 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02484006243520738		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.02484006243520738 | validation: 0.023108332470416867]
	TIME [epoch: 5.76 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02508832207507028		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.02508832207507028 | validation: 0.013721720705842771]
	TIME [epoch: 5.71 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025784311071659672		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.025784311071659672 | validation: 0.01940770021606626]
	TIME [epoch: 5.71 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021612260641119343		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.021612260641119343 | validation: 0.022823590252059774]
	TIME [epoch: 5.71 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024605383081373822		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.024605383081373822 | validation: 0.01893996936787409]
	TIME [epoch: 5.72 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026825377195547853		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.026825377195547853 | validation: 0.022347573463069894]
	TIME [epoch: 5.71 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023467396761552038		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.023467396761552038 | validation: 0.02264498359341251]
	TIME [epoch: 5.73 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028369866700374887		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.028369866700374887 | validation: 0.01828126009946332]
	TIME [epoch: 5.72 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021869982211224468		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.021869982211224468 | validation: 0.01568642270283122]
	TIME [epoch: 5.71 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02442355389041093		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.02442355389041093 | validation: 0.020637660012430406]
	TIME [epoch: 5.7 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021794031082011424		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.021794031082011424 | validation: 0.01629850336836452]
	TIME [epoch: 5.71 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025969937653320396		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.025969937653320396 | validation: 0.02527332647276641]
	TIME [epoch: 5.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02071415378341538		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.02071415378341538 | validation: 0.021590293263466225]
	TIME [epoch: 5.72 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027766957595529353		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.027766957595529353 | validation: 0.017746154012153185]
	TIME [epoch: 5.75 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024609448484595245		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.024609448484595245 | validation: 0.026196707144296703]
	TIME [epoch: 5.72 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028561193106908224		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.028561193106908224 | validation: 0.02414631182272826]
	TIME [epoch: 5.7 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023139649279727385		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.023139649279727385 | validation: 0.023135780521732156]
	TIME [epoch: 5.71 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02579133287364812		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.02579133287364812 | validation: 0.01947513195514239]
	TIME [epoch: 5.72 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022684756208382086		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.022684756208382086 | validation: 0.017452550508686004]
	TIME [epoch: 5.71 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02213417355044262		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.02213417355044262 | validation: 0.018433319455178496]
	TIME [epoch: 5.74 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025171428348452034		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.025171428348452034 | validation: 0.022434716277185664]
	TIME [epoch: 5.74 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02418252800695315		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.02418252800695315 | validation: 0.021946177288484085]
	TIME [epoch: 5.71 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024316584241355278		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.024316584241355278 | validation: 0.013694638120164937]
	TIME [epoch: 5.7 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02254730787020266		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.02254730787020266 | validation: 0.016002807694620515]
	TIME [epoch: 5.71 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024034936670200735		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.024034936670200735 | validation: 0.020018017064187075]
	TIME [epoch: 5.72 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02318202579690276		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.02318202579690276 | validation: 0.026862220928536358]
	TIME [epoch: 5.7 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023456609393257274		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.023456609393257274 | validation: 0.026090436660089776]
	TIME [epoch: 5.75 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021732608262023462		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.021732608262023462 | validation: 0.027103955743534518]
	TIME [epoch: 5.7 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024225285553870504		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.024225285553870504 | validation: 0.014787911738731912]
	TIME [epoch: 5.7 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024840881334088075		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.024840881334088075 | validation: 0.0255388823093972]
	TIME [epoch: 5.71 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024655720568095223		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.024655720568095223 | validation: 0.017520275868693726]
	TIME [epoch: 5.71 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023025523188271373		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.023025523188271373 | validation: 0.022221596609098608]
	TIME [epoch: 5.71 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024159111204391667		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.024159111204391667 | validation: 0.01863604794855905]
	TIME [epoch: 5.72 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021044313538738486		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.021044313538738486 | validation: 0.023723949034488757]
	TIME [epoch: 5.72 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025726857231407347		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.025726857231407347 | validation: 0.021056155314777197]
	TIME [epoch: 5.71 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01983052018301468		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.01983052018301468 | validation: 0.025140163343220587]
	TIME [epoch: 5.69 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02235412498199893		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.02235412498199893 | validation: 0.026578588374928033]
	TIME [epoch: 5.69 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02343472862962789		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.02343472862962789 | validation: 0.0217904193956944]
	TIME [epoch: 5.71 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026964885301501297		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.026964885301501297 | validation: 0.022257542913432026]
	TIME [epoch: 5.7 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02273481620539853		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.02273481620539853 | validation: 0.023438873896743543]
	TIME [epoch: 5.77 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02081658172830519		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.02081658172830519 | validation: 0.03008331182140347]
	TIME [epoch: 5.72 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023909158588233573		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.023909158588233573 | validation: 0.023223059481342664]
	TIME [epoch: 5.72 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022955239866380046		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.022955239866380046 | validation: 0.011412949579621766]
	TIME [epoch: 5.72 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02503673090971763		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.02503673090971763 | validation: 0.02195792075237197]
	TIME [epoch: 5.71 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025202488752179685		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.025202488752179685 | validation: 0.027120128384442364]
	TIME [epoch: 5.71 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025803536096291053		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.025803536096291053 | validation: 0.02512548513049715]
	TIME [epoch: 5.75 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02179457318634603		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.02179457318634603 | validation: 0.020070180472587188]
	TIME [epoch: 5.74 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026936419237733083		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.026936419237733083 | validation: 0.023242214744385432]
	TIME [epoch: 5.71 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025552588769777874		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.025552588769777874 | validation: 0.023955572070168258]
	TIME [epoch: 5.7 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02085804508209667		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.02085804508209667 | validation: 0.02803964086356988]
	TIME [epoch: 5.71 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025598272595903554		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.025598272595903554 | validation: 0.017357821874449265]
	TIME [epoch: 5.7 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028212937864590476		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.028212937864590476 | validation: 0.01899900280385789]
	TIME [epoch: 5.72 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025810548790246378		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.025810548790246378 | validation: 0.027541364203371554]
	TIME [epoch: 5.75 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020770838139938984		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.020770838139938984 | validation: 0.022768007069372584]
	TIME [epoch: 5.71 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02300794836206024		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.02300794836206024 | validation: 0.030879502107656318]
	TIME [epoch: 5.7 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018948343158936735		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.018948343158936735 | validation: 0.023743982975114687]
	TIME [epoch: 5.71 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025574866816443925		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.025574866816443925 | validation: 0.0283760942351695]
	TIME [epoch: 5.7 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023808180633347862		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.023808180633347862 | validation: 0.01580665037753521]
	TIME [epoch: 5.7 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02455777104196174		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.02455777104196174 | validation: 0.012798056486436327]
	TIME [epoch: 5.73 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02265833344397518		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.02265833344397518 | validation: 0.017605550130698155]
	TIME [epoch: 5.72 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02423164231630906		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.02423164231630906 | validation: 0.02716433853489738]
	TIME [epoch: 5.71 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024622407847319883		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.024622407847319883 | validation: 0.026859714869196083]
	TIME [epoch: 5.71 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025394610142242747		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.025394610142242747 | validation: 0.015179160807392131]
	TIME [epoch: 5.69 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019745825135038732		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.019745825135038732 | validation: 0.02665914929735039]
	TIME [epoch: 5.69 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02007268003179882		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.02007268003179882 | validation: 0.015640958894882137]
	TIME [epoch: 5.7 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02346230235289842		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.02346230235289842 | validation: 0.0253064242250748]
	TIME [epoch: 5.75 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022611712903559053		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.022611712903559053 | validation: 0.02130442225032336]
	TIME [epoch: 5.7 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021726855068208994		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.021726855068208994 | validation: 0.020933455784636904]
	TIME [epoch: 5.7 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022977296178626525		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.022977296178626525 | validation: 0.023064003201547015]
	TIME [epoch: 5.7 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024496678108945645		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.024496678108945645 | validation: 0.022248941038741924]
	TIME [epoch: 5.69 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02537818848570126		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.02537818848570126 | validation: 0.02152516609449198]
	TIME [epoch: 5.69 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02396664719940691		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.02396664719940691 | validation: 0.022570483585925238]
	TIME [epoch: 5.72 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02429845683332943		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.02429845683332943 | validation: 0.02029969587520389]
	TIME [epoch: 5.72 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022813073593253373		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.022813073593253373 | validation: 0.020793500541407103]
	TIME [epoch: 5.7 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023240818987699464		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.023240818987699464 | validation: 0.02861464502749081]
	TIME [epoch: 5.7 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02509868870950482		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.02509868870950482 | validation: 0.02597241124766132]
	TIME [epoch: 5.7 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02481524984254653		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.02481524984254653 | validation: 0.028877543275607893]
	TIME [epoch: 5.7 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02346194856467141		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.02346194856467141 | validation: 0.020224368886355207]
	TIME [epoch: 5.71 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02397133901575799		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.02397133901575799 | validation: 0.01942699242176328]
	TIME [epoch: 5.75 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022665697831992168		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.022665697831992168 | validation: 0.023394984287343462]
	TIME [epoch: 5.72 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025569755444408548		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.025569755444408548 | validation: 0.028473471948384628]
	TIME [epoch: 5.71 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025807291519846995		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.025807291519846995 | validation: 0.02156406586313132]
	TIME [epoch: 5.71 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02222817220659053		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.02222817220659053 | validation: 0.028497233514709397]
	TIME [epoch: 5.69 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026141023645788512		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.026141023645788512 | validation: 0.01803247344167424]
	TIME [epoch: 5.7 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02505150198908951		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.02505150198908951 | validation: 0.024510984359345196]
	TIME [epoch: 5.73 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023094953710297086		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.023094953710297086 | validation: 0.028692408552325015]
	TIME [epoch: 5.73 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029125473536469323		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.029125473536469323 | validation: 0.023582604644073066]
	TIME [epoch: 5.7 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02264356312297452		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.02264356312297452 | validation: 0.021874214925725482]
	TIME [epoch: 5.71 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02420770052165902		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.02420770052165902 | validation: 0.020301373126031596]
	TIME [epoch: 5.7 sec]
Finished training in 11638.274 seconds.
