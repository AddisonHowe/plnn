Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r3', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3287779939

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.326869180069815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.326869180069815 | validation: 9.488738134564555]
	TIME [epoch: 93.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.095287093159309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.095287093159309 | validation: 6.468813289850195]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.282469240646794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.282469240646794 | validation: 4.7504431539731575]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.303919943512479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.303919943512479 | validation: 5.0450679424677265]
	TIME [epoch: 5.76 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.089301113904618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.089301113904618 | validation: 4.460768996158594]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5042201958864165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5042201958864165 | validation: 4.079708652282306]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.096930791667312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.096930791667312 | validation: 3.5550278817861884]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6260730327468123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6260730327468123 | validation: 3.304438316239572]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.35143632645109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.35143632645109 | validation: 3.244136965188243]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0401752449706523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0401752449706523 | validation: 3.78316841199845]
	TIME [epoch: 5.76 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.477045726727615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.477045726727615 | validation: 3.164017252047581]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22457424795553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.22457424795553 | validation: 2.6309209875117534]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.030735522768769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.030735522768769 | validation: 2.487668299757362]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6792126424153206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6792126424153206 | validation: 2.3222005699057933]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.667065504428758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.667065504428758 | validation: 2.3148938221490485]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2290854328922167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2290854328922167 | validation: 2.311456308171584]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313425751182507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.313425751182507 | validation: 2.134040017490708]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0732533045631327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0732533045631327 | validation: 2.982144785740951]
	TIME [epoch: 5.81 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.558830237220289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.558830237220289 | validation: 2.0519275854282313]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.04916659319183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.04916659319183 | validation: 1.8039698779311846]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8799678739733618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8799678739733618 | validation: 1.683672561065963]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8460136199695782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8460136199695782 | validation: 1.5335275788268434]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.731680491574606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.731680491574606 | validation: 2.2687308278156184]
	TIME [epoch: 5.78 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9847197387444924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9847197387444924 | validation: 1.7197895297040375]
	TIME [epoch: 5.78 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7187727631303942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7187727631303942 | validation: 1.3515082457928949]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.714260211597329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.714260211597329 | validation: 1.294533772014335]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5082229841858381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5082229841858381 | validation: 1.2949127594567327]
	TIME [epoch: 5.75 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6109545452779013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6109545452779013 | validation: 1.3921700624290148]
	TIME [epoch: 5.74 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6246167548785624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6246167548785624 | validation: 1.4896520027298419]
	TIME [epoch: 5.74 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3310722913353024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3310722913353024 | validation: 2.769306118012886]
	TIME [epoch: 5.74 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.408250413023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.408250413023 | validation: 1.8968654822134905]
	TIME [epoch: 5.78 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6088662352625933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6088662352625933 | validation: 1.393346960117274]
	TIME [epoch: 5.76 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.439071371354311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.439071371354311 | validation: 1.2571433732494357]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.321908285415873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.321908285415873 | validation: 1.527959723063163]
	TIME [epoch: 5.74 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.492378217331618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.492378217331618 | validation: 1.4988238341413558]
	TIME [epoch: 5.75 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5073973214609497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5073973214609497 | validation: 1.0390667974581715]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3156897131075236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3156897131075236 | validation: 1.0013287212170439]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.337309006084976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.337309006084976 | validation: 1.466154309518106]
	TIME [epoch: 5.76 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2453732068330585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2453732068330585 | validation: 1.2903370664610125]
	TIME [epoch: 5.74 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1552935911094333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1552935911094333 | validation: 0.8548091804666794]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146145992885715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.146145992885715 | validation: 1.4863941552031128]
	TIME [epoch: 5.75 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2054973070122514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2054973070122514 | validation: 1.0899934136022091]
	TIME [epoch: 5.76 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0092320358278386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0092320358278386 | validation: 0.7789691606342125]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1590605200754767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1590605200754767 | validation: 0.8105599748901824]
	TIME [epoch: 5.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9888346618542152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9888346618542152 | validation: 1.1422486034177246]
	TIME [epoch: 5.76 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9489098129868103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9489098129868103 | validation: 2.29337337532835]
	TIME [epoch: 5.76 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2210919752101452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2210919752101452 | validation: 1.1265061332224189]
	TIME [epoch: 5.75 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0443549641314203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0443549641314203 | validation: 0.6018632209123908]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9128819873208002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9128819873208002 | validation: 0.5462672339614683]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2557894885034027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2557894885034027 | validation: 0.6055647736866301]
	TIME [epoch: 5.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8295313428247442		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.8295313428247442 | validation: 0.5253618716769377]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294992844402672		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.7294992844402672 | validation: 0.7504947290433713]
	TIME [epoch: 5.78 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8733431588696183		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.8733431588696183 | validation: 0.9293384426258964]
	TIME [epoch: 5.77 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8177858304584094		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.8177858304584094 | validation: 0.435939955718157]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2336204242449795		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.2336204242449795 | validation: 0.5244411027346044]
	TIME [epoch: 5.77 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8445240952185871		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.8445240952185871 | validation: 0.5012008685759699]
	TIME [epoch: 5.81 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8098899458814413		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.8098899458814413 | validation: 0.7293743616861649]
	TIME [epoch: 5.77 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9174868524974054		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.9174868524974054 | validation: 0.5935440430366505]
	TIME [epoch: 5.77 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941440722233162		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.6941440722233162 | validation: 0.7172472577670448]
	TIME [epoch: 5.76 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8301874103220062		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.8301874103220062 | validation: 0.529566661030662]
	TIME [epoch: 5.76 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.823430825666232		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.823430825666232 | validation: 0.4001278276141161]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7610706434556845		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.7610706434556845 | validation: 0.6157797748828111]
	TIME [epoch: 5.78 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6237217364732216		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.6237217364732216 | validation: 0.7895852175728407]
	TIME [epoch: 5.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6153079568178157		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.6153079568178157 | validation: 0.4988312933341895]
	TIME [epoch: 5.77 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8509501876749993		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.8509501876749993 | validation: 0.5868433599671723]
	TIME [epoch: 5.77 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.739257783745963		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.739257783745963 | validation: 0.8900155408148211]
	TIME [epoch: 5.76 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6121485091095512		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.6121485091095512 | validation: 0.9730783847982784]
	TIME [epoch: 5.76 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755503581051567		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.6755503581051567 | validation: 1.4819235205949315]
	TIME [epoch: 5.76 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9526371648665003		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.9526371648665003 | validation: 0.8535947058930438]
	TIME [epoch: 5.81 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6513479344236048		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.6513479344236048 | validation: 0.4906117865018681]
	TIME [epoch: 5.77 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8666545321608254		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.8666545321608254 | validation: 0.9158528992324985]
	TIME [epoch: 5.76 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8059217011863777		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.8059217011863777 | validation: 0.4350321288160594]
	TIME [epoch: 5.77 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585778092600188		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.5585778092600188 | validation: 0.43500062100791254]
	TIME [epoch: 5.77 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6705044758453094		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.6705044758453094 | validation: 0.5967746571433536]
	TIME [epoch: 5.76 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918289054152189		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.6918289054152189 | validation: 0.45317921870804045]
	TIME [epoch: 5.77 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7342756706044293		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.7342756706044293 | validation: 0.3572241106332206]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616311448586788		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.616311448586788 | validation: 0.7465150738050085]
	TIME [epoch: 5.78 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5687784004211031		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.5687784004211031 | validation: 0.3076995713510704]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7637748402839211		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7637748402839211 | validation: 0.6292175590293481]
	TIME [epoch: 5.77 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4898296036455743		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.4898296036455743 | validation: 0.9746851548407185]
	TIME [epoch: 5.76 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7694019491113666		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.7694019491113666 | validation: 0.42347194698050367]
	TIME [epoch: 5.76 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5307446917213366		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.5307446917213366 | validation: 0.7422451205113287]
	TIME [epoch: 5.81 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6135917881395906		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.6135917881395906 | validation: 0.8787218155938795]
	TIME [epoch: 5.77 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9713717802465229		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.9713717802465229 | validation: 0.8817325887360982]
	TIME [epoch: 5.76 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9060131034792073		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.9060131034792073 | validation: 0.35565123570937607]
	TIME [epoch: 5.77 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484565432407918		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.5484565432407918 | validation: 0.5970929119531411]
	TIME [epoch: 5.77 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.573804817036256		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.573804817036256 | validation: 0.7267997729054687]
	TIME [epoch: 5.76 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7449113430138772		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.7449113430138772 | validation: 0.6968958167470715]
	TIME [epoch: 5.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013044356341227		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.5013044356341227 | validation: 0.5737863668958448]
	TIME [epoch: 5.78 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6154213856439356		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.6154213856439356 | validation: 0.3967969004110366]
	TIME [epoch: 5.76 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44475239666218164		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.44475239666218164 | validation: 0.47559081953842675]
	TIME [epoch: 5.76 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416879338008895		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.5416879338008895 | validation: 1.0120047654400273]
	TIME [epoch: 5.76 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6769310976384498		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.6769310976384498 | validation: 1.1390160980680089]
	TIME [epoch: 5.76 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493889687849258		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.6493889687849258 | validation: 0.9102159369515687]
	TIME [epoch: 5.77 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6352457544881681		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.6352457544881681 | validation: 0.2796734994889462]
	TIME [epoch: 5.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4929070828791462		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.4929070828791462 | validation: 0.44868124273491183]
	TIME [epoch: 5.77 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4658900282641202		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.4658900282641202 | validation: 0.5093894118539614]
	TIME [epoch: 5.77 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4982078478008803		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.4982078478008803 | validation: 0.7676096002867945]
	TIME [epoch: 5.77 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5708560526702625		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.5708560526702625 | validation: 0.3519289686375335]
	TIME [epoch: 5.76 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43413796591973025		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.43413796591973025 | validation: 0.65980009641609]
	TIME [epoch: 5.76 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5981822415501286		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.5981822415501286 | validation: 0.6147799448505532]
	TIME [epoch: 5.81 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5147756381329153		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.5147756381329153 | validation: 0.316516992205903]
	TIME [epoch: 5.77 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744041091538403		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.5744041091538403 | validation: 0.3993963153218424]
	TIME [epoch: 5.77 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6011673605243919		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.6011673605243919 | validation: 0.3177036978841353]
	TIME [epoch: 5.76 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6094886584015549		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.6094886584015549 | validation: 0.673791197348146]
	TIME [epoch: 5.77 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226016457409984		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.7226016457409984 | validation: 0.4952821796559003]
	TIME [epoch: 5.77 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.627993887145323		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.627993887145323 | validation: 0.5395205409653725]
	TIME [epoch: 5.77 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883286741066669		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.6883286741066669 | validation: 0.4798720518691616]
	TIME [epoch: 5.79 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.488395002128285		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.488395002128285 | validation: 0.428839490015141]
	TIME [epoch: 5.76 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5178073413777364		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.5178073413777364 | validation: 0.987322640024027]
	TIME [epoch: 5.76 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6076058955577562		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.6076058955577562 | validation: 0.48944480448283517]
	TIME [epoch: 5.76 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679692948705832		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.4679692948705832 | validation: 0.9821643131474077]
	TIME [epoch: 5.77 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965567246196784		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.6965567246196784 | validation: 0.5951234766711003]
	TIME [epoch: 5.77 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4935657629337665		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.4935657629337665 | validation: 0.3088303817983517]
	TIME [epoch: 5.81 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7744533207413596		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.7744533207413596 | validation: 0.423089090472932]
	TIME [epoch: 5.78 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5610336622101335		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.5610336622101335 | validation: 0.510314244963419]
	TIME [epoch: 5.77 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5535732449474073		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.5535732449474073 | validation: 0.34670351586823756]
	TIME [epoch: 5.76 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5624824320517218		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.5624824320517218 | validation: 0.34719188303593]
	TIME [epoch: 5.76 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38482528610476735		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.38482528610476735 | validation: 0.5730178180016418]
	TIME [epoch: 5.76 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44978924597084713		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.44978924597084713 | validation: 0.5247145535183466]
	TIME [epoch: 5.78 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48698379503490624		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.48698379503490624 | validation: 0.4012535057536421]
	TIME [epoch: 5.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4546498693156774		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.4546498693156774 | validation: 0.6463819023291814]
	TIME [epoch: 5.77 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0612504213982366		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.0612504213982366 | validation: 0.6630634640227026]
	TIME [epoch: 5.77 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6177771416580774		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.6177771416580774 | validation: 0.4402376273062512]
	TIME [epoch: 5.76 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45290464814699166		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.45290464814699166 | validation: 0.3431803807271287]
	TIME [epoch: 5.76 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4000913974538269		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.4000913974538269 | validation: 0.43498269409665197]
	TIME [epoch: 5.76 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43447679755124097		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.43447679755124097 | validation: 0.526541855644824]
	TIME [epoch: 5.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6171156394753917		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.6171156394753917 | validation: 0.29811017024625713]
	TIME [epoch: 5.78 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4106624202953954		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.4106624202953954 | validation: 0.5514136589125824]
	TIME [epoch: 5.77 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722535459476994		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.4722535459476994 | validation: 0.518495420953832]
	TIME [epoch: 5.77 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47917193420847465		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.47917193420847465 | validation: 1.1423709595645222]
	TIME [epoch: 5.78 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7534995571775497		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.7534995571775497 | validation: 0.541053033588887]
	TIME [epoch: 5.77 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48748757456136943		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.48748757456136943 | validation: 0.36674489170809027]
	TIME [epoch: 5.78 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498685238882679		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.4498685238882679 | validation: 0.4926732533109291]
	TIME [epoch: 5.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47006340834498606		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.47006340834498606 | validation: 0.304582318318864]
	TIME [epoch: 5.76 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35824369218088936		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.35824369218088936 | validation: 0.2947562953066821]
	TIME [epoch: 5.76 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441491824720945		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.5441491824720945 | validation: 0.47347942161257]
	TIME [epoch: 5.77 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874879200779825		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.5874879200779825 | validation: 0.30471594947071307]
	TIME [epoch: 5.77 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3993242573780123		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3993242573780123 | validation: 0.7406573049583883]
	TIME [epoch: 5.77 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5183237331962556		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.5183237331962556 | validation: 0.5376172569366543]
	TIME [epoch: 5.81 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46120154150397447		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.46120154150397447 | validation: 0.47468170609098237]
	TIME [epoch: 5.78 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4711270450861885		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.4711270450861885 | validation: 0.4949032072322943]
	TIME [epoch: 5.76 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5580691094883602		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.5580691094883602 | validation: 0.3679844959778544]
	TIME [epoch: 5.76 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3875973580984052		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.3875973580984052 | validation: 0.3831508064256877]
	TIME [epoch: 5.76 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44995513100743445		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.44995513100743445 | validation: 0.3501816715953103]
	TIME [epoch: 5.76 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4530515794266919		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.4530515794266919 | validation: 0.39468388449980857]
	TIME [epoch: 5.78 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7296799301997671		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.7296799301997671 | validation: 0.3542458088765727]
	TIME [epoch: 5.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51480757302075		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.51480757302075 | validation: 0.40484709014497955]
	TIME [epoch: 5.77 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5689939888254262		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.5689939888254262 | validation: 0.4324670012329274]
	TIME [epoch: 5.77 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4388212549782578		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.4388212549782578 | validation: 0.3167375622214604]
	TIME [epoch: 5.77 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4290458354079003		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.4290458354079003 | validation: 0.4234196738405066]
	TIME [epoch: 5.76 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40495735561169516		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.40495735561169516 | validation: 0.5316388029895299]
	TIME [epoch: 5.76 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072002014586617		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.5072002014586617 | validation: 0.5412934941246976]
	TIME [epoch: 5.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47748149640901727		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.47748149640901727 | validation: 0.29293965517304005]
	TIME [epoch: 5.77 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5456434045167067		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.5456434045167067 | validation: 0.31499467532438424]
	TIME [epoch: 5.77 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46807461689174246		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.46807461689174246 | validation: 0.2991386706911249]
	TIME [epoch: 5.77 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4683764774278037		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.4683764774278037 | validation: 0.6553552821132769]
	TIME [epoch: 5.77 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49190534816412435		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.49190534816412435 | validation: 0.27187182175055014]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40652371131495174		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.40652371131495174 | validation: 0.34863108618956035]
	TIME [epoch: 5.79 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702821533976892		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.3702821533976892 | validation: 0.38439166342866343]
	TIME [epoch: 5.78 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47095986883784713		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.47095986883784713 | validation: 0.394266094293129]
	TIME [epoch: 5.76 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3895791360572038		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.3895791360572038 | validation: 0.2630392148684104]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501571855530555		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.3501571855530555 | validation: 0.9745530104983664]
	TIME [epoch: 5.76 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536821342635714		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.6536821342635714 | validation: 0.31847309864438994]
	TIME [epoch: 5.77 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.513847144740283		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.513847144740283 | validation: 0.3047453842268854]
	TIME [epoch: 5.77 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3891881696045784		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.3891881696045784 | validation: 0.35885038757140814]
	TIME [epoch: 5.81 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576117047597851		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.3576117047597851 | validation: 0.4710989776158697]
	TIME [epoch: 5.77 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4883255472493497		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.4883255472493497 | validation: 0.3610947108295575]
	TIME [epoch: 5.77 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44793061683984703		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.44793061683984703 | validation: 0.4101138761000882]
	TIME [epoch: 5.77 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39902547371316416		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.39902547371316416 | validation: 0.3324598626757369]
	TIME [epoch: 5.76 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778952721140648		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.3778952721140648 | validation: 0.4057806786937864]
	TIME [epoch: 5.76 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46884054837324446		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.46884054837324446 | validation: 0.3301385506314553]
	TIME [epoch: 5.79 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371994483895374		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.4371994483895374 | validation: 0.52894813679848]
	TIME [epoch: 5.78 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43930688363413845		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.43930688363413845 | validation: 0.34260315379382134]
	TIME [epoch: 5.77 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4165129985236795		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.4165129985236795 | validation: 0.3051658585612476]
	TIME [epoch: 5.77 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4018129856329287		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.4018129856329287 | validation: 0.5957797465478815]
	TIME [epoch: 5.77 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4830780955594195		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.4830780955594195 | validation: 0.32800060272561526]
	TIME [epoch: 5.77 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4114367211330904		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.4114367211330904 | validation: 0.4331416978400916]
	TIME [epoch: 5.77 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45043754333626634		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.45043754333626634 | validation: 0.3185508700635724]
	TIME [epoch: 5.81 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.404955408944509		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.404955408944509 | validation: 0.39129657672493395]
	TIME [epoch: 5.76 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45050902583152175		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.45050902583152175 | validation: 0.27429118828796806]
	TIME [epoch: 5.76 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39057074156278393		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.39057074156278393 | validation: 0.37609723197272443]
	TIME [epoch: 5.76 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4055002129585984		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.4055002129585984 | validation: 0.3219850014769712]
	TIME [epoch: 5.75 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41268958899942476		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.41268958899942476 | validation: 0.38769732101144627]
	TIME [epoch: 5.77 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40059845136738226		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.40059845136738226 | validation: 0.36085620284940645]
	TIME [epoch: 5.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44930316323662167		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.44930316323662167 | validation: 0.3393322297298473]
	TIME [epoch: 5.79 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38590917416537995		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.38590917416537995 | validation: 0.23935743035624282]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42432462179093156		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.42432462179093156 | validation: 0.37548735204008926]
	TIME [epoch: 5.77 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39292385013181724		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.39292385013181724 | validation: 0.3240839884053353]
	TIME [epoch: 5.76 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4034915827207397		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.4034915827207397 | validation: 0.2608105612536778]
	TIME [epoch: 5.73 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706112435724097		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.3706112435724097 | validation: 0.2826416117746539]
	TIME [epoch: 5.76 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3320245064032502		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3320245064032502 | validation: 0.3360187160575516]
	TIME [epoch: 5.78 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34653987800284736		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.34653987800284736 | validation: 0.2923840471463369]
	TIME [epoch: 5.75 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5007585154761677		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.5007585154761677 | validation: 0.4355852433259818]
	TIME [epoch: 5.76 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.614229112125884		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.614229112125884 | validation: 0.41919169451302124]
	TIME [epoch: 5.77 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4750873082338045		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.4750873082338045 | validation: 0.27795746823909734]
	TIME [epoch: 5.76 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40836684770878867		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.40836684770878867 | validation: 0.2873156585044234]
	TIME [epoch: 5.77 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35841660558330585		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.35841660558330585 | validation: 0.26157150523645173]
	TIME [epoch: 5.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074707371468426		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.3074707371468426 | validation: 0.3196913296961567]
	TIME [epoch: 5.76 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3211011080671867		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3211011080671867 | validation: 0.2887746179415588]
	TIME [epoch: 5.75 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261534696848751		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.3261534696848751 | validation: 0.44472050116854517]
	TIME [epoch: 5.75 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4414663643978008		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.4414663643978008 | validation: 0.32329760606406654]
	TIME [epoch: 5.75 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43985146971036904		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.43985146971036904 | validation: 0.24434541384244704]
	TIME [epoch: 5.76 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32457127672634745		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.32457127672634745 | validation: 0.3233376363920425]
	TIME [epoch: 5.78 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38093742309082335		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.38093742309082335 | validation: 0.31881265705474965]
	TIME [epoch: 5.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34813848551386284		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.34813848551386284 | validation: 0.5988465122378779]
	TIME [epoch: 5.75 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44713561079348296		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.44713561079348296 | validation: 0.29286296040425114]
	TIME [epoch: 5.77 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34026993341515555		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.34026993341515555 | validation: 0.5145893926634166]
	TIME [epoch: 5.75 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019279741920392		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.4019279741920392 | validation: 0.2249635692322539]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45816161434201746		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.45816161434201746 | validation: 0.22476678723364266]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43842120567766474		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.43842120567766474 | validation: 0.37095046861128866]
	TIME [epoch: 5.82 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.383861122908592		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.383861122908592 | validation: 0.34457550675852405]
	TIME [epoch: 5.77 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3817558314526138		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.3817558314526138 | validation: 0.2644949698659705]
	TIME [epoch: 5.77 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3639100925191942		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.3639100925191942 | validation: 0.5139731057140048]
	TIME [epoch: 5.77 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4047940721459119		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.4047940721459119 | validation: 0.2498489245536959]
	TIME [epoch: 5.77 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3366954076215433		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.3366954076215433 | validation: 0.23913338580841179]
	TIME [epoch: 5.77 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3837509516234139		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.3837509516234139 | validation: 0.4710724636247062]
	TIME [epoch: 5.79 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44623461984621976		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.44623461984621976 | validation: 0.3215344119550305]
	TIME [epoch: 5.78 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33841207018447605		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.33841207018447605 | validation: 0.24191134311081208]
	TIME [epoch: 5.76 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3152116105301339		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.3152116105301339 | validation: 0.2497195428575261]
	TIME [epoch: 5.77 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4760123402735097		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.4760123402735097 | validation: 0.4161105663702278]
	TIME [epoch: 5.77 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34735038293357473		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.34735038293357473 | validation: 0.23527006073430226]
	TIME [epoch: 5.77 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3473254658671957		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.3473254658671957 | validation: 0.2798991888033116]
	TIME [epoch: 5.77 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3105024872354675		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.3105024872354675 | validation: 0.4110511327412533]
	TIME [epoch: 5.83 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4229042070366068		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.4229042070366068 | validation: 0.6133071312816748]
	TIME [epoch: 5.77 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.416443505587276		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.416443505587276 | validation: 0.4281111368834658]
	TIME [epoch: 5.76 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33515804630642104		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.33515804630642104 | validation: 0.2800643117553386]
	TIME [epoch: 5.76 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43757578855285545		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.43757578855285545 | validation: 0.28800896443279206]
	TIME [epoch: 5.76 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3790084220605054		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.3790084220605054 | validation: 0.321735689503628]
	TIME [epoch: 5.77 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470779465350024		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.3470779465350024 | validation: 0.2662022433580997]
	TIME [epoch: 5.81 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3320757075545092		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.3320757075545092 | validation: 0.2640658676597744]
	TIME [epoch: 5.78 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34834456799703206		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.34834456799703206 | validation: 0.2718958481879789]
	TIME [epoch: 5.78 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33265928758775193		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.33265928758775193 | validation: 0.25665079788091455]
	TIME [epoch: 5.78 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3054428311197055		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.3054428311197055 | validation: 0.34680625046892205]
	TIME [epoch: 5.77 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38405432505164155		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.38405432505164155 | validation: 0.4743728746560199]
	TIME [epoch: 5.77 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3956754993853477		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.3956754993853477 | validation: 0.2889529836513037]
	TIME [epoch: 5.76 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32117303223090615		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.32117303223090615 | validation: 0.2734619922701521]
	TIME [epoch: 5.81 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30669504924021096		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.30669504924021096 | validation: 0.39392603395212633]
	TIME [epoch: 5.77 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4407327181137537		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.4407327181137537 | validation: 0.5171154053162467]
	TIME [epoch: 5.78 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3923267822198938		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.3923267822198938 | validation: 0.28309766489186833]
	TIME [epoch: 5.78 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29384511106417405		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.29384511106417405 | validation: 0.20540287384202455]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3015553570760044		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.3015553570760044 | validation: 0.4334931431998264]
	TIME [epoch: 5.77 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44169886667744396		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.44169886667744396 | validation: 0.23184691141703254]
	TIME [epoch: 5.81 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4336131566345162		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.4336131566345162 | validation: 0.7006103854929663]
	TIME [epoch: 5.77 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45454518676112343		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.45454518676112343 | validation: 0.24621186758873553]
	TIME [epoch: 5.76 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935037333008703		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.2935037333008703 | validation: 0.21114213573986831]
	TIME [epoch: 5.76 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30342973568359566		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.30342973568359566 | validation: 0.3157150345497696]
	TIME [epoch: 5.76 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33595537229074746		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.33595537229074746 | validation: 0.19168441074610854]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352531632250868		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.352531632250868 | validation: 0.2722668428590128]
	TIME [epoch: 5.78 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43011025133513686		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.43011025133513686 | validation: 0.2458084867060159]
	TIME [epoch: 5.81 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25882524195561774		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.25882524195561774 | validation: 0.22389516049461824]
	TIME [epoch: 5.76 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2946425532567566		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.2946425532567566 | validation: 0.24535639900991407]
	TIME [epoch: 5.77 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37738851167583926		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.37738851167583926 | validation: 0.23400923441362725]
	TIME [epoch: 5.77 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28610060397067		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.28610060397067 | validation: 0.1800572048562846]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26188876123069293		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.26188876123069293 | validation: 0.20083665260610864]
	TIME [epoch: 5.76 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3481935542688936		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.3481935542688936 | validation: 0.19743006440475724]
	TIME [epoch: 5.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49254784188664824		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.49254784188664824 | validation: 0.23966853423779128]
	TIME [epoch: 5.76 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30913717711954325		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.30913717711954325 | validation: 0.17842697456077664]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4037377319395873		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.4037377319395873 | validation: 0.21056805477308843]
	TIME [epoch: 5.77 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31182769488770773		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.31182769488770773 | validation: 0.22318636538816164]
	TIME [epoch: 5.76 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2882301949064611		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.2882301949064611 | validation: 0.3239779224130715]
	TIME [epoch: 5.77 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4116746328370279		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.4116746328370279 | validation: 0.258480415555659]
	TIME [epoch: 5.79 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33827691014325434		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.33827691014325434 | validation: 0.21506863686643848]
	TIME [epoch: 5.77 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32069543039991766		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.32069543039991766 | validation: 0.19362274094955567]
	TIME [epoch: 5.76 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524295337196384		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.2524295337196384 | validation: 0.332794768827623]
	TIME [epoch: 5.76 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3401102508262698		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.3401102508262698 | validation: 0.3097048562875438]
	TIME [epoch: 5.76 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37714998524386345		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.37714998524386345 | validation: 0.19715785734666483]
	TIME [epoch: 5.77 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103098242932994		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.3103098242932994 | validation: 0.451596006427843]
	TIME [epoch: 5.77 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3709099249932224		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.3709099249932224 | validation: 0.4074134592447629]
	TIME [epoch: 5.81 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3486782689461151		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.3486782689461151 | validation: 0.2858322516443284]
	TIME [epoch: 5.77 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3075106274314323		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.3075106274314323 | validation: 0.5439440317012716]
	TIME [epoch: 5.76 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35323931329303027		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.35323931329303027 | validation: 0.8122882442280757]
	TIME [epoch: 5.76 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44208068663025274		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.44208068663025274 | validation: 0.24872194087223995]
	TIME [epoch: 5.76 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28246280882707353		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.28246280882707353 | validation: 0.2637398960438593]
	TIME [epoch: 5.76 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35673419606320533		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.35673419606320533 | validation: 0.21045541793033518]
	TIME [epoch: 5.79 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296839264164834		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.296839264164834 | validation: 0.2272554282836863]
	TIME [epoch: 5.79 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27812598254075543		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.27812598254075543 | validation: 0.24262914077295428]
	TIME [epoch: 5.76 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33684839385546417		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.33684839385546417 | validation: 0.30956772912855296]
	TIME [epoch: 5.77 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30052199612858743		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.30052199612858743 | validation: 0.19157756527444092]
	TIME [epoch: 5.76 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28912755185837635		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.28912755185837635 | validation: 0.21143518730406283]
	TIME [epoch: 5.76 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659163196503424		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.3659163196503424 | validation: 0.2120490774277941]
	TIME [epoch: 5.76 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.320766432618045		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.320766432618045 | validation: 0.20203814912314194]
	TIME [epoch: 5.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.273052507327378		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.273052507327378 | validation: 0.2333984855643648]
	TIME [epoch: 5.76 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3151115463979408		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.3151115463979408 | validation: 0.28271145683645194]
	TIME [epoch: 5.77 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36282899366026894		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.36282899366026894 | validation: 0.34651102242485704]
	TIME [epoch: 5.77 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673688954483856		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.3673688954483856 | validation: 0.24263892418478017]
	TIME [epoch: 5.76 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36657889904145174		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.36657889904145174 | validation: 0.2415418277876258]
	TIME [epoch: 5.77 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30630335678802734		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.30630335678802734 | validation: 0.21691770135690852]
	TIME [epoch: 5.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29458733373218243		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.29458733373218243 | validation: 0.24696481725736547]
	TIME [epoch: 5.78 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842751881536752		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.2842751881536752 | validation: 0.20025319202058117]
	TIME [epoch: 5.76 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32047374464458206		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.32047374464458206 | validation: 0.21511816890878194]
	TIME [epoch: 5.76 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34507694170912473		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.34507694170912473 | validation: 0.48462728389713583]
	TIME [epoch: 5.76 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3415791827185566		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.3415791827185566 | validation: 0.22156108216262405]
	TIME [epoch: 5.76 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26338943971968465		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.26338943971968465 | validation: 0.3226779292329509]
	TIME [epoch: 5.77 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31705615241058566		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.31705615241058566 | validation: 0.21469535082282845]
	TIME [epoch: 5.82 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34381650089593463		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.34381650089593463 | validation: 0.34883758602684256]
	TIME [epoch: 5.76 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3237182752731782		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.3237182752731782 | validation: 0.21404659167610354]
	TIME [epoch: 5.77 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25773046712406206		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.25773046712406206 | validation: 0.2310982631482078]
	TIME [epoch: 5.77 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2585008922115335		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.2585008922115335 | validation: 0.1828783044631359]
	TIME [epoch: 5.76 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532661727823634		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.2532661727823634 | validation: 0.21041628753263936]
	TIME [epoch: 5.76 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24770997861653465		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.24770997861653465 | validation: 0.24524863976067146]
	TIME [epoch: 5.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3091798971926245		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.3091798971926245 | validation: 0.22226477884355408]
	TIME [epoch: 5.77 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24107419591267912		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.24107419591267912 | validation: 0.4413654454017971]
	TIME [epoch: 5.77 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3776463804026911		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.3776463804026911 | validation: 0.2268838803507013]
	TIME [epoch: 5.77 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23280218090925064		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.23280218090925064 | validation: 0.5026056861477458]
	TIME [epoch: 5.77 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356108078210791		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.3356108078210791 | validation: 0.23931368665735825]
	TIME [epoch: 5.76 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29827463588814895		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.29827463588814895 | validation: 0.3539052359022665]
	TIME [epoch: 5.79 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3252509643850265		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.3252509643850265 | validation: 0.23374161045611197]
	TIME [epoch: 5.82 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36984630141497965		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.36984630141497965 | validation: 0.40755545919021513]
	TIME [epoch: 5.77 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28654029494324573		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.28654029494324573 | validation: 0.20822030542576778]
	TIME [epoch: 5.76 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26756927985345846		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.26756927985345846 | validation: 0.4941481120102944]
	TIME [epoch: 5.76 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3876744513201146		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.3876744513201146 | validation: 0.24228279050326984]
	TIME [epoch: 5.77 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4225903155612446		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.4225903155612446 | validation: 0.2240830157020227]
	TIME [epoch: 5.77 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2475259197293652		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2475259197293652 | validation: 0.16355256567644816]
	TIME [epoch: 5.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24379079184405342		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.24379079184405342 | validation: 0.169168728460567]
	TIME [epoch: 5.78 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3179412840987417		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.3179412840987417 | validation: 0.22789731306130137]
	TIME [epoch: 5.77 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30090041917359794		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.30090041917359794 | validation: 0.1910270675830016]
	TIME [epoch: 5.77 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25495142539439747		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.25495142539439747 | validation: 0.38685919651451656]
	TIME [epoch: 5.76 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33074541104441824		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.33074541104441824 | validation: 0.16845158606407928]
	TIME [epoch: 5.76 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3037147295397014		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.3037147295397014 | validation: 0.2164960805828743]
	TIME [epoch: 5.78 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26711287119799487		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.26711287119799487 | validation: 0.18699333859013656]
	TIME [epoch: 5.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2394656881036754		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.2394656881036754 | validation: 0.18963255745046348]
	TIME [epoch: 5.77 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30552771807850493		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.30552771807850493 | validation: 0.2221838478172804]
	TIME [epoch: 5.77 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22637209197958952		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.22637209197958952 | validation: 0.16316531053704691]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2368298550567475		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.2368298550567475 | validation: 0.17042198719852417]
	TIME [epoch: 5.77 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35311816202100593		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.35311816202100593 | validation: 0.2560590002791235]
	TIME [epoch: 5.78 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3269829686070104		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.3269829686070104 | validation: 0.26450328305066007]
	TIME [epoch: 5.82 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2600426849094607		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.2600426849094607 | validation: 0.2437294312285912]
	TIME [epoch: 5.78 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2687483716892334		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.2687483716892334 | validation: 0.2803026509983596]
	TIME [epoch: 5.77 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2691773885415325		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.2691773885415325 | validation: 0.22230595388388988]
	TIME [epoch: 5.77 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2605289287757528		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.2605289287757528 | validation: 0.35986365617183763]
	TIME [epoch: 5.77 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3152952840047981		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.3152952840047981 | validation: 0.25318230363637745]
	TIME [epoch: 5.77 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21921981114947764		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.21921981114947764 | validation: 0.18314399659415642]
	TIME [epoch: 5.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502696823059555		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.2502696823059555 | validation: 0.5299889201279899]
	TIME [epoch: 5.79 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5463490284557341		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5463490284557341 | validation: 0.19899983345222938]
	TIME [epoch: 5.77 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24677877319353608		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.24677877319353608 | validation: 0.18810365599033424]
	TIME [epoch: 5.77 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35411816566327203		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.35411816566327203 | validation: 0.2570132222661912]
	TIME [epoch: 5.77 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25708727731313163		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.25708727731313163 | validation: 0.31717940053255783]
	TIME [epoch: 5.76 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29339966740384044		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.29339966740384044 | validation: 0.18848241388952477]
	TIME [epoch: 5.77 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23474162583605285		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.23474162583605285 | validation: 0.18877409431395303]
	TIME [epoch: 5.82 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2760602175654541		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.2760602175654541 | validation: 0.24638258968757926]
	TIME [epoch: 5.77 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003118669109363		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.3003118669109363 | validation: 0.15141882220765443]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23033707741642084		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.23033707741642084 | validation: 0.2507083634014023]
	TIME [epoch: 5.77 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27674491577106225		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.27674491577106225 | validation: 0.137970448462579]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.230035653536511		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.230035653536511 | validation: 0.19569754828130392]
	TIME [epoch: 5.77 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23961851740119725		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.23961851740119725 | validation: 0.17999196458668956]
	TIME [epoch: 5.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739985321709151		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.2739985321709151 | validation: 0.1461187141224939]
	TIME [epoch: 5.77 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24495173284761587		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.24495173284761587 | validation: 0.23924142880253002]
	TIME [epoch: 5.77 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20987354052821172		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.20987354052821172 | validation: 0.1409799679510096]
	TIME [epoch: 5.76 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2320757643246124		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.2320757643246124 | validation: 0.198226241629828]
	TIME [epoch: 5.76 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22960989294702833		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.22960989294702833 | validation: 0.231041724858174]
	TIME [epoch: 5.76 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27926355071566983		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.27926355071566983 | validation: 0.13259041870238175]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19552871584705597		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.19552871584705597 | validation: 0.1921164910654276]
	TIME [epoch: 5.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23370742945389883		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.23370742945389883 | validation: 0.2609581679891015]
	TIME [epoch: 5.77 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2606423514187334		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.2606423514187334 | validation: 0.16029823465621718]
	TIME [epoch: 5.76 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23448310496458563		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.23448310496458563 | validation: 0.18733746861524836]
	TIME [epoch: 5.76 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40350621185694957		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.40350621185694957 | validation: 0.23046273537280038]
	TIME [epoch: 5.76 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.229742052073935		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.229742052073935 | validation: 0.1989033738267375]
	TIME [epoch: 5.77 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24999821868874378		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.24999821868874378 | validation: 0.2050448846169021]
	TIME [epoch: 5.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535604143284287		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.2535604143284287 | validation: 0.2092942473607593]
	TIME [epoch: 5.77 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2891977085433359		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.2891977085433359 | validation: 0.18001347305301316]
	TIME [epoch: 5.76 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22510928364657412		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.22510928364657412 | validation: 0.25165161982731676]
	TIME [epoch: 5.76 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23748484179822177		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.23748484179822177 | validation: 0.3159814747232912]
	TIME [epoch: 5.76 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25650481733902875		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.25650481733902875 | validation: 0.13538132499279434]
	TIME [epoch: 5.76 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22571753001817738		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.22571753001817738 | validation: 0.20826403841166105]
	TIME [epoch: 5.79 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23351148438664102		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.23351148438664102 | validation: 0.19631369540425808]
	TIME [epoch: 5.78 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23904873718403552		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.23904873718403552 | validation: 0.14668644418937862]
	TIME [epoch: 5.77 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1940667664724755		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.1940667664724755 | validation: 0.20016198250133702]
	TIME [epoch: 5.76 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.226533609808551		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.226533609808551 | validation: 0.15283401124381044]
	TIME [epoch: 5.76 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949623811247667		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.2949623811247667 | validation: 0.23004757265258563]
	TIME [epoch: 5.76 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24337660569008207		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.24337660569008207 | validation: 0.14414746983092894]
	TIME [epoch: 5.76 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2264564504908267		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.2264564504908267 | validation: 0.16033158564724062]
	TIME [epoch: 5.81 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2534219075585294		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.2534219075585294 | validation: 0.1523864919011579]
	TIME [epoch: 5.77 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2269919770858816		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.2269919770858816 | validation: 0.1985751077076531]
	TIME [epoch: 5.76 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20094639564584788		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.20094639564584788 | validation: 0.22718359742769179]
	TIME [epoch: 5.76 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2382471543410297		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.2382471543410297 | validation: 0.19741723206606154]
	TIME [epoch: 5.76 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21400146912580675		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.21400146912580675 | validation: 0.2859011085349632]
	TIME [epoch: 5.76 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24506757176535357		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.24506757176535357 | validation: 0.2793989536437801]
	TIME [epoch: 5.79 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27017707785549666		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.27017707785549666 | validation: 0.1407727776091549]
	TIME [epoch: 5.78 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1770739537328786		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.1770739537328786 | validation: 0.15634484727133852]
	TIME [epoch: 5.77 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19881606571870014		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.19881606571870014 | validation: 0.16104832501340224]
	TIME [epoch: 5.76 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23615789276086666		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.23615789276086666 | validation: 0.1550578679690228]
	TIME [epoch: 5.76 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19968863607291443		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.19968863607291443 | validation: 0.16476810283602297]
	TIME [epoch: 5.76 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25328682835182603		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.25328682835182603 | validation: 0.17028287816986765]
	TIME [epoch: 5.76 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1963785352309899		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.1963785352309899 | validation: 0.25025444648795625]
	TIME [epoch: 5.81 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629230171595829		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2629230171595829 | validation: 0.15291065865076486]
	TIME [epoch: 5.77 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1940694095922547		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.1940694095922547 | validation: 0.1919424164691145]
	TIME [epoch: 5.76 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607899995381043		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.2607899995381043 | validation: 0.29819758383960054]
	TIME [epoch: 5.76 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24574940959621863		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.24574940959621863 | validation: 0.15971526701928482]
	TIME [epoch: 5.76 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22984837044966383		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.22984837044966383 | validation: 0.18018562713140995]
	TIME [epoch: 5.76 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2818347130777855		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.2818347130777855 | validation: 0.19157420527016342]
	TIME [epoch: 5.79 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24540738314553384		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.24540738314553384 | validation: 0.14442792566423923]
	TIME [epoch: 5.78 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20766476830469735		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.20766476830469735 | validation: 0.1997939441491001]
	TIME [epoch: 5.77 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23196026406334438		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.23196026406334438 | validation: 0.22808914912410472]
	TIME [epoch: 5.76 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21137901975067813		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.21137901975067813 | validation: 0.16193372791009383]
	TIME [epoch: 5.76 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19962217365956875		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.19962217365956875 | validation: 0.3369878439982607]
	TIME [epoch: 5.76 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3156856640535349		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.3156856640535349 | validation: 0.23851368097679665]
	TIME [epoch: 5.77 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27740674866215115		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.27740674866215115 | validation: 0.22210351410058546]
	TIME [epoch: 5.81 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29418898031657914		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.29418898031657914 | validation: 0.1572136957277451]
	TIME [epoch: 5.77 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003473896125697		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.3003473896125697 | validation: 0.19970222753412398]
	TIME [epoch: 5.76 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20706775419241863		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.20706775419241863 | validation: 0.1816169372462497]
	TIME [epoch: 5.76 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19144120830263384		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.19144120830263384 | validation: 0.19898635779188248]
	TIME [epoch: 5.77 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24203837499020117		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.24203837499020117 | validation: 0.1496098446826439]
	TIME [epoch: 5.77 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23478620174432158		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.23478620174432158 | validation: 0.1537190784907624]
	TIME [epoch: 5.79 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20044059753492477		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.20044059753492477 | validation: 0.13168611611570807]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21273668256665929		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.21273668256665929 | validation: 0.17245643511302675]
	TIME [epoch: 5.76 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614270224563705		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.2614270224563705 | validation: 0.16343280892925743]
	TIME [epoch: 5.76 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22527368868125944		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.22527368868125944 | validation: 0.24116574408010646]
	TIME [epoch: 5.76 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22638790114981772		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.22638790114981772 | validation: 0.17665444798214297]
	TIME [epoch: 5.75 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22581761483785023		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.22581761483785023 | validation: 0.1635371754203689]
	TIME [epoch: 5.75 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17992357102155127		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.17992357102155127 | validation: 0.21264107230348306]
	TIME [epoch: 5.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24835034606958456		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.24835034606958456 | validation: 0.1359969755519235]
	TIME [epoch: 5.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2325195519374078		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.2325195519374078 | validation: 0.1982532295127571]
	TIME [epoch: 5.75 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2055922866383123		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.2055922866383123 | validation: 0.12482662220908781]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16774960360638058		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.16774960360638058 | validation: 0.11686484219077478]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18264937208466223		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.18264937208466223 | validation: 0.2433698427252269]
	TIME [epoch: 5.77 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112809198614352		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.2112809198614352 | validation: 0.30022064303950524]
	TIME [epoch: 5.81 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23675788519989277		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.23675788519989277 | validation: 0.1445538692649414]
	TIME [epoch: 5.75 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17999652243151418		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.17999652243151418 | validation: 0.1910138793703254]
	TIME [epoch: 5.77 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20659368237844727		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.20659368237844727 | validation: 0.18515632621229533]
	TIME [epoch: 5.75 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1855511831285155		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.1855511831285155 | validation: 0.1455904861851786]
	TIME [epoch: 5.77 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18052406254381276		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.18052406254381276 | validation: 0.1298968300099832]
	TIME [epoch: 5.77 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19854267943615478		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.19854267943615478 | validation: 0.15280089035753477]
	TIME [epoch: 5.77 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19132154453203704		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.19132154453203704 | validation: 0.13125257050650244]
	TIME [epoch: 5.79 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24263057504455848		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.24263057504455848 | validation: 0.16195626738696114]
	TIME [epoch: 5.76 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21715798127758468		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.21715798127758468 | validation: 0.1123986339402228]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15516052016338513		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.15516052016338513 | validation: 0.14356977171435462]
	TIME [epoch: 5.76 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18703638533934597		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.18703638533934597 | validation: 0.12281800673142318]
	TIME [epoch: 5.75 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20552198187926018		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.20552198187926018 | validation: 0.13403760997225309]
	TIME [epoch: 5.76 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23511222821759753		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.23511222821759753 | validation: 0.18005147871281219]
	TIME [epoch: 5.81 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2266619548901286		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.2266619548901286 | validation: 0.21323494741856866]
	TIME [epoch: 5.76 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20237103075847485		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.20237103075847485 | validation: 0.2393993032781899]
	TIME [epoch: 5.76 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3057591687715191		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.3057591687715191 | validation: 0.13330731839530416]
	TIME [epoch: 5.76 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256183440648375		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.256183440648375 | validation: 0.13332151525898195]
	TIME [epoch: 5.76 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18539789100214993		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.18539789100214993 | validation: 0.18997935179503675]
	TIME [epoch: 5.76 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20726691746738368		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.20726691746738368 | validation: 0.23119345302978045]
	TIME [epoch: 5.79 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18766203869284773		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.18766203869284773 | validation: 0.11313591136384968]
	TIME [epoch: 5.78 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18026966244249096		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.18026966244249096 | validation: 0.18329686078787127]
	TIME [epoch: 5.77 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27065030518437805		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.27065030518437805 | validation: 0.16507996353713594]
	TIME [epoch: 5.76 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22493352228489208		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.22493352228489208 | validation: 0.16251827413448755]
	TIME [epoch: 5.76 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18360890011577558		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.18360890011577558 | validation: 0.13581446101832653]
	TIME [epoch: 5.76 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1881031212101456		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.1881031212101456 | validation: 0.14065559259105562]
	TIME [epoch: 5.76 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1918163099582015		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.1918163099582015 | validation: 0.16583911489513228]
	TIME [epoch: 5.81 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19165733768062043		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.19165733768062043 | validation: 0.28340858169267125]
	TIME [epoch: 5.77 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2453474577391671		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.2453474577391671 | validation: 0.14203318536854626]
	TIME [epoch: 5.76 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17292311146260314		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.17292311146260314 | validation: 0.15464401479798393]
	TIME [epoch: 5.77 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20036337874820842		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.20036337874820842 | validation: 0.13908697288969077]
	TIME [epoch: 5.75 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21190158771800074		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.21190158771800074 | validation: 0.12618566489780678]
	TIME [epoch: 5.76 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1767969450519109		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.1767969450519109 | validation: 0.11075452885006083]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21990111334098963		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.21990111334098963 | validation: 0.11410388925246803]
	TIME [epoch: 5.77 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17938719534282058		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.17938719534282058 | validation: 0.12292569512045468]
	TIME [epoch: 5.76 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20434233448714484		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.20434233448714484 | validation: 0.15182856052012436]
	TIME [epoch: 5.76 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2030379548337595		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.2030379548337595 | validation: 0.21964341543394525]
	TIME [epoch: 5.75 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18544361988765418		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.18544361988765418 | validation: 0.1388748437845663]
	TIME [epoch: 5.74 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20709116307905479		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.20709116307905479 | validation: 0.18003276203800878]
	TIME [epoch: 5.77 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23830596879617558		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.23830596879617558 | validation: 0.13156080823242053]
	TIME [epoch: 5.78 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18436408029468104		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.18436408029468104 | validation: 0.11246077507558497]
	TIME [epoch: 5.76 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1881995789053177		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.1881995789053177 | validation: 0.14184447214617246]
	TIME [epoch: 5.74 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819758492896995		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.1819758492896995 | validation: 0.17292990789517718]
	TIME [epoch: 5.76 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23106690309817848		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.23106690309817848 | validation: 0.13191884349572885]
	TIME [epoch: 5.75 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19512409836899824		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.19512409836899824 | validation: 0.13185217633007176]
	TIME [epoch: 5.75 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22048684709718103		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.22048684709718103 | validation: 0.1383806627369278]
	TIME [epoch: 5.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17445235975321424		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.17445235975321424 | validation: 0.18836304095252548]
	TIME [epoch: 5.77 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16479047251582934		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.16479047251582934 | validation: 0.13662635357087216]
	TIME [epoch: 5.75 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22204689950652695		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.22204689950652695 | validation: 0.1367334064014841]
	TIME [epoch: 5.75 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1608892384762464		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.1608892384762464 | validation: 0.2533718968279477]
	TIME [epoch: 5.74 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23382000942205258		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.23382000942205258 | validation: 0.13671255524312503]
	TIME [epoch: 5.76 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16651464686876066		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.16651464686876066 | validation: 0.1787572350891705]
	TIME [epoch: 5.76 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1688235257817922		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.1688235257817922 | validation: 0.16434889568304445]
	TIME [epoch: 5.79 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1892353103255008		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.1892353103255008 | validation: 0.12207540698223009]
	TIME [epoch: 5.75 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16971675511230472		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.16971675511230472 | validation: 0.16424165883193986]
	TIME [epoch: 5.76 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17876850379136838		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.17876850379136838 | validation: 0.14540170742473862]
	TIME [epoch: 5.75 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17021925526438175		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.17021925526438175 | validation: 0.11935482585324574]
	TIME [epoch: 5.76 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18241870413091632		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.18241870413091632 | validation: 0.14916368188524137]
	TIME [epoch: 5.74 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3230983774734762		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.3230983774734762 | validation: 0.18903538203298756]
	TIME [epoch: 5.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19332826211799392		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.19332826211799392 | validation: 0.19910299364559464]
	TIME [epoch: 5.76 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18969262280944155		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.18969262280944155 | validation: 0.13178476986653972]
	TIME [epoch: 5.76 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1724099716022334		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.1724099716022334 | validation: 0.12267910069455404]
	TIME [epoch: 5.74 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15513622490788512		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.15513622490788512 | validation: 0.11298443063646882]
	TIME [epoch: 5.75 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21369709953939126		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.21369709953939126 | validation: 0.22133174810987777]
	TIME [epoch: 5.76 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25576203611331766		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.25576203611331766 | validation: 0.21945310909058563]
	TIME [epoch: 5.78 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19990871146983868		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.19990871146983868 | validation: 0.21131796807934752]
	TIME [epoch: 5.78 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24347111270561733		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.24347111270561733 | validation: 0.1762486216011855]
	TIME [epoch: 5.75 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18467554849828788		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.18467554849828788 | validation: 0.11668620357377182]
	TIME [epoch: 5.75 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588579580103041		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1588579580103041 | validation: 0.10514259561885661]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18447397357029519		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.18447397357029519 | validation: 0.09867929793575086]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_486.pth
	Model improved!!!
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17683732255319132		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.17683732255319132 | validation: 0.10566044338322896]
	TIME [epoch: 5.76 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15371547782497857		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.15371547782497857 | validation: 0.27698664345564916]
	TIME [epoch: 5.81 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21746240275164774		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.21746240275164774 | validation: 0.09018952357449248]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2186039622745201		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.2186039622745201 | validation: 0.14924992500670864]
	TIME [epoch: 5.75 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1745319405192084		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.1745319405192084 | validation: 0.1289642756379706]
	TIME [epoch: 5.75 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2126153684347621		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.2126153684347621 | validation: 0.18128111629905738]
	TIME [epoch: 5.75 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138366334163043		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.2138366334163043 | validation: 0.1476564611790846]
	TIME [epoch: 5.75 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15962564630024317		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.15962564630024317 | validation: 0.21769621484624652]
	TIME [epoch: 5.79 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19224473489406207		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.19224473489406207 | validation: 0.15513999325639946]
	TIME [epoch: 5.78 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16977290643913237		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.16977290643913237 | validation: 0.18803237755908314]
	TIME [epoch: 5.75 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20781971031517868		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.20781971031517868 | validation: 0.13686572638711833]
	TIME [epoch: 5.75 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20734631506440976		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.20734631506440976 | validation: 0.28585714606173035]
	TIME [epoch: 5.76 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25699398637648646		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.25699398637648646 | validation: 0.15833735403207216]
	TIME [epoch: 5.76 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.173328025898623		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.173328025898623 | validation: 0.11223063029680845]
	TIME [epoch: 5.77 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15690115577885355		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.15690115577885355 | validation: 0.12141888578728458]
	TIME [epoch: 5.79 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14609787411254688		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.14609787411254688 | validation: 0.14594438903703896]
	TIME [epoch: 5.76 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15728646415816994		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.15728646415816994 | validation: 0.1292662500685266]
	TIME [epoch: 5.75 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15069181856343225		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.15069181856343225 | validation: 0.13460557019044792]
	TIME [epoch: 5.76 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16419563901013196		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16419563901013196 | validation: 0.18707319954660542]
	TIME [epoch: 5.76 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17575364043220792		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.17575364043220792 | validation: 0.1375883405208348]
	TIME [epoch: 5.76 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18522985033029266		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.18522985033029266 | validation: 0.18940083897531715]
	TIME [epoch: 5.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1981913685139141		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.1981913685139141 | validation: 0.15311531488317673]
	TIME [epoch: 5.76 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20167911686056722		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.20167911686056722 | validation: 0.5771944508305675]
	TIME [epoch: 5.75 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4342728303941391		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.4342728303941391 | validation: 0.2320252886339984]
	TIME [epoch: 5.75 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146251007032149		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.2146251007032149 | validation: 0.1381806376704964]
	TIME [epoch: 5.75 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22474364774886318		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.22474364774886318 | validation: 0.13982788171418187]
	TIME [epoch: 5.76 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168371506584146		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.168371506584146 | validation: 0.11320789609009861]
	TIME [epoch: 5.77 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19615992828806195		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.19615992828806195 | validation: 0.13293526339461237]
	TIME [epoch: 5.78 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16347583972447582		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.16347583972447582 | validation: 0.12411644845690496]
	TIME [epoch: 5.75 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478257576221586		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.1478257576221586 | validation: 0.22421550994276665]
	TIME [epoch: 5.75 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18995442458260237		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.18995442458260237 | validation: 0.120723807079029]
	TIME [epoch: 5.75 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549660926616572		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.1549660926616572 | validation: 0.14143297342168779]
	TIME [epoch: 5.75 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2063486223887292		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.2063486223887292 | validation: 0.3574355432072773]
	TIME [epoch: 5.75 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30170386561560525		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.30170386561560525 | validation: 0.08761782312603256]
	TIME [epoch: 5.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15857269474102723		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.15857269474102723 | validation: 0.1334940305014753]
	TIME [epoch: 5.76 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.161587019388037		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.161587019388037 | validation: 0.1697433397041882]
	TIME [epoch: 5.76 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16716237422393015		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.16716237422393015 | validation: 0.2620007433362334]
	TIME [epoch: 5.76 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22310832421819762		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.22310832421819762 | validation: 0.13557591490206608]
	TIME [epoch: 5.75 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14118177082581118		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.14118177082581118 | validation: 0.09341018089231685]
	TIME [epoch: 5.75 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16286423614812348		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.16286423614812348 | validation: 0.09181400696537509]
	TIME [epoch: 5.76 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16650353752742397		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.16650353752742397 | validation: 0.29586863561980153]
	TIME [epoch: 5.79 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21586458142097678		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.21586458142097678 | validation: 0.15683211740874975]
	TIME [epoch: 5.76 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19764537629019682		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.19764537629019682 | validation: 0.2884130527659557]
	TIME [epoch: 5.75 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1852990346730921		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.1852990346730921 | validation: 0.10152749982188494]
	TIME [epoch: 5.75 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13266885361245975		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.13266885361245975 | validation: 0.15166294348038648]
	TIME [epoch: 5.75 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2015375991057926		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.2015375991057926 | validation: 0.30822944655986373]
	TIME [epoch: 5.75 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22752610945522517		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.22752610945522517 | validation: 0.23563829353774285]
	TIME [epoch: 5.79 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18852748230777544		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.18852748230777544 | validation: 0.20014151498218521]
	TIME [epoch: 5.76 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17414453151611095		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.17414453151611095 | validation: 0.22478666358511995]
	TIME [epoch: 5.76 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1861400205939216		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.1861400205939216 | validation: 0.10611049299952402]
	TIME [epoch: 5.75 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15302989219290897		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.15302989219290897 | validation: 0.10772001232741049]
	TIME [epoch: 5.75 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18879363340158223		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.18879363340158223 | validation: 0.18618672045080614]
	TIME [epoch: 5.76 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15999697976039542		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.15999697976039542 | validation: 0.12380354129791118]
	TIME [epoch: 5.77 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15779832065579324		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.15779832065579324 | validation: 0.14202786986652904]
	TIME [epoch: 5.79 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601545836812363		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.1601545836812363 | validation: 0.1573009990159764]
	TIME [epoch: 5.75 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22129158533156496		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.22129158533156496 | validation: 0.1255310805905774]
	TIME [epoch: 5.76 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14514494597388433		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.14514494597388433 | validation: 0.1307804613605985]
	TIME [epoch: 5.76 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393798713241055		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.1393798713241055 | validation: 0.12133326838440024]
	TIME [epoch: 5.75 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15672843088524574		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.15672843088524574 | validation: 0.08410846897327005]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_545.pth
	Model improved!!!
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17286236039577843		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.17286236039577843 | validation: 0.15431265632141103]
	TIME [epoch: 5.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18495842927485123		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.18495842927485123 | validation: 0.11654758104194142]
	TIME [epoch: 5.75 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16062644236026974		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.16062644236026974 | validation: 0.11570072330222553]
	TIME [epoch: 5.75 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477893270988031		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.1477893270988031 | validation: 0.13473778569286482]
	TIME [epoch: 5.75 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16681077428868302		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.16681077428868302 | validation: 0.12921505120571306]
	TIME [epoch: 5.75 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16334886831478274		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.16334886831478274 | validation: 0.0910784256815365]
	TIME [epoch: 5.75 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1651131263917433		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.1651131263917433 | validation: 0.15639158954766]
	TIME [epoch: 5.77 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1719797238266067		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.1719797238266067 | validation: 0.11622444181062261]
	TIME [epoch: 5.77 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15849591141093317		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.15849591141093317 | validation: 0.11110386722737342]
	TIME [epoch: 5.75 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15458245612835544		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.15458245612835544 | validation: 0.11863602172075538]
	TIME [epoch: 5.74 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15062179134262768		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.15062179134262768 | validation: 0.10805212090974699]
	TIME [epoch: 5.75 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14712051454927927		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.14712051454927927 | validation: 0.10363200417605663]
	TIME [epoch: 5.76 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13708809562708957		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.13708809562708957 | validation: 0.12715865200336002]
	TIME [epoch: 5.75 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14903698336149085		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.14903698336149085 | validation: 0.09162219064549114]
	TIME [epoch: 5.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14497685728283938		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.14497685728283938 | validation: 0.1292081128193736]
	TIME [epoch: 5.75 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17378780983303438		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.17378780983303438 | validation: 0.16039576558339882]
	TIME [epoch: 5.75 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15287068187827196		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.15287068187827196 | validation: 0.13279195047668454]
	TIME [epoch: 5.75 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14557349599239527		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.14557349599239527 | validation: 0.13563203208751742]
	TIME [epoch: 5.75 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15535694624634577		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.15535694624634577 | validation: 0.12655416871727915]
	TIME [epoch: 5.74 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12702831847308385		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.12702831847308385 | validation: 0.1355768446568939]
	TIME [epoch: 5.77 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18394611485996903		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.18394611485996903 | validation: 0.2931470147098536]
	TIME [epoch: 5.76 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19880418702753344		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.19880418702753344 | validation: 0.12152937108426304]
	TIME [epoch: 5.75 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1763311654926965		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.1763311654926965 | validation: 0.2907157889641721]
	TIME [epoch: 5.74 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22205102161015858		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.22205102161015858 | validation: 0.12008913462420402]
	TIME [epoch: 5.74 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13656299060094423		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.13656299060094423 | validation: 0.18881003769602842]
	TIME [epoch: 5.74 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1662757862863626		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.1662757862863626 | validation: 0.1299818281489666]
	TIME [epoch: 5.75 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19937130230906833		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.19937130230906833 | validation: 0.18057474655426808]
	TIME [epoch: 5.79 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1697522878377114		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.1697522878377114 | validation: 0.11205268743219662]
	TIME [epoch: 5.75 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12993799271952594		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.12993799271952594 | validation: 0.13295110936555374]
	TIME [epoch: 5.75 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1704285953842363		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.1704285953842363 | validation: 0.08592035241334305]
	TIME [epoch: 5.75 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16979052620080565		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.16979052620080565 | validation: 0.1482882033811502]
	TIME [epoch: 5.74 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15105042082439074		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.15105042082439074 | validation: 0.1344051018376112]
	TIME [epoch: 5.74 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16365718466874085		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.16365718466874085 | validation: 0.1108930242524202]
	TIME [epoch: 5.77 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13609181808299953		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.13609181808299953 | validation: 0.09887045002123326]
	TIME [epoch: 5.76 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17750737692450722		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.17750737692450722 | validation: 0.12496823556533546]
	TIME [epoch: 5.75 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1743059748390263		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.1743059748390263 | validation: 0.14318127776207928]
	TIME [epoch: 5.74 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18012314592562578		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.18012314592562578 | validation: 0.09929569742320919]
	TIME [epoch: 5.75 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541319977871995		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.1541319977871995 | validation: 0.14501678321492853]
	TIME [epoch: 5.75 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18014334739056326		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.18014334739056326 | validation: 0.1305057138789046]
	TIME [epoch: 5.75 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15557555388655006		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.15557555388655006 | validation: 0.10961862566737875]
	TIME [epoch: 5.79 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17380191296598935		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.17380191296598935 | validation: 0.08194194322855104]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_586.pth
	Model improved!!!
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15513431702158992		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.15513431702158992 | validation: 0.13865965592445012]
	TIME [epoch: 5.76 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14681286005094787		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.14681286005094787 | validation: 0.08642992242138506]
	TIME [epoch: 5.75 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16218640728488184		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.16218640728488184 | validation: 0.09092619446228643]
	TIME [epoch: 5.75 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18626088977047264		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.18626088977047264 | validation: 0.11959302038828817]
	TIME [epoch: 5.76 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14223005753196372		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.14223005753196372 | validation: 0.12706845130132852]
	TIME [epoch: 5.78 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1775826477720706		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.1775826477720706 | validation: 0.08269035722450253]
	TIME [epoch: 5.77 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13287775120946824		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.13287775120946824 | validation: 0.11852439435546214]
	TIME [epoch: 5.75 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15142562207377847		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.15142562207377847 | validation: 0.10618826388736156]
	TIME [epoch: 5.75 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13611102962002344		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.13611102962002344 | validation: 0.14297342361687918]
	TIME [epoch: 5.76 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17017062367232316		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.17017062367232316 | validation: 0.10573413279617289]
	TIME [epoch: 5.75 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408909037150113		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.1408909037150113 | validation: 0.11955404692785548]
	TIME [epoch: 5.77 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13664297809526707		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.13664297809526707 | validation: 0.24593837639633742]
	TIME [epoch: 5.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19358259876013492		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.19358259876013492 | validation: 0.10398932167717735]
	TIME [epoch: 5.76 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13239066880088407		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.13239066880088407 | validation: 0.09024088504391761]
	TIME [epoch: 5.75 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15053039741856852		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.15053039741856852 | validation: 0.14322554200961066]
	TIME [epoch: 5.75 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14446467392368123		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.14446467392368123 | validation: 0.09585142726790821]
	TIME [epoch: 5.75 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12528495772912646		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.12528495772912646 | validation: 0.0738503547107359]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_603.pth
	Model improved!!!
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357266043134095		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.1357266043134095 | validation: 0.10794780921507696]
	TIME [epoch: 5.79 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14052129982469552		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.14052129982469552 | validation: 0.0917891900586281]
	TIME [epoch: 5.76 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12723514792744406		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.12723514792744406 | validation: 0.14236081389677263]
	TIME [epoch: 5.76 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1423477320318282		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.1423477320318282 | validation: 0.09670600733494629]
	TIME [epoch: 5.75 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15310472467937092		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.15310472467937092 | validation: 0.17802645435107983]
	TIME [epoch: 5.75 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14109484692858557		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.14109484692858557 | validation: 0.0877179824077987]
	TIME [epoch: 5.76 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1150167340657702		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.1150167340657702 | validation: 0.10017295068642679]
	TIME [epoch: 5.76 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1892756386515758		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.1892756386515758 | validation: 0.1317227468864854]
	TIME [epoch: 5.79 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20240593133142626		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.20240593133142626 | validation: 0.12899389371758196]
	TIME [epoch: 5.75 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13956246128038435		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.13956246128038435 | validation: 0.09052924188339381]
	TIME [epoch: 5.75 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15106618826957974		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.15106618826957974 | validation: 0.10008731471713939]
	TIME [epoch: 5.75 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14060360096775057		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.14060360096775057 | validation: 0.09741776711820727]
	TIME [epoch: 5.75 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1529534198204741		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.1529534198204741 | validation: 0.08857247525247082]
	TIME [epoch: 5.76 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205909218531366		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.1205909218531366 | validation: 0.1173605151366729]
	TIME [epoch: 5.79 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517610320035172		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.1517610320035172 | validation: 0.15805114391521705]
	TIME [epoch: 5.77 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15207796891673095		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.15207796891673095 | validation: 0.16593298433788434]
	TIME [epoch: 5.75 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461194308829669		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1461194308829669 | validation: 0.11584752544932014]
	TIME [epoch: 5.75 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380717497667806		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.1380717497667806 | validation: 0.16762455245029131]
	TIME [epoch: 5.75 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17661991342221814		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.17661991342221814 | validation: 0.1221390626807511]
	TIME [epoch: 5.75 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14233956946905055		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.14233956946905055 | validation: 0.08475355881788532]
	TIME [epoch: 5.77 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14892172773041978		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.14892172773041978 | validation: 0.13048281649961566]
	TIME [epoch: 5.79 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13947322422554573		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.13947322422554573 | validation: 0.0827628235264772]
	TIME [epoch: 5.76 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13432857533216225		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.13432857533216225 | validation: 0.09494363584625333]
	TIME [epoch: 5.76 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12729363589636455		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.12729363589636455 | validation: 0.1832198137729418]
	TIME [epoch: 5.75 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507398809552618		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.1507398809552618 | validation: 0.11990854375865234]
	TIME [epoch: 5.75 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14006174272399596		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.14006174272399596 | validation: 0.10861406771710072]
	TIME [epoch: 5.75 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13199288483631777		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.13199288483631777 | validation: 0.0809931063162514]
	TIME [epoch: 5.79 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12359714511750682		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.12359714511750682 | validation: 0.09605771402135294]
	TIME [epoch: 5.75 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16001990592249757		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.16001990592249757 | validation: 0.09589349703914789]
	TIME [epoch: 5.76 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16434966277912552		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.16434966277912552 | validation: 0.14561620001181236]
	TIME [epoch: 5.76 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16062526770920418		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.16062526770920418 | validation: 0.0895989809008918]
	TIME [epoch: 5.76 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12411137783628556		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.12411137783628556 | validation: 0.08261989416733327]
	TIME [epoch: 5.75 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13013936510390825		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.13013936510390825 | validation: 0.23500013422072716]
	TIME [epoch: 5.77 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16890624837904844		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.16890624837904844 | validation: 0.10136086927135506]
	TIME [epoch: 5.78 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12943500424336157		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.12943500424336157 | validation: 0.14091339485234453]
	TIME [epoch: 5.75 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156793479931673		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.156793479931673 | validation: 0.17743080532166963]
	TIME [epoch: 5.75 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16721709233712653		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.16721709233712653 | validation: 0.07676971528411915]
	TIME [epoch: 5.75 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13079503526883904		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.13079503526883904 | validation: 0.09302007219408803]
	TIME [epoch: 5.75 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.160531648150463		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.160531648150463 | validation: 0.23501126070847542]
	TIME [epoch: 5.75 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16841099316872707		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.16841099316872707 | validation: 0.08039510168467404]
	TIME [epoch: 5.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13872771905391307		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.13872771905391307 | validation: 0.11297808149977819]
	TIME [epoch: 5.76 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737392561318953		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.12737392561318953 | validation: 0.11604935386388132]
	TIME [epoch: 5.76 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579949666353524		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.1579949666353524 | validation: 0.0969300330257849]
	TIME [epoch: 5.75 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12582076618270097		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.12582076618270097 | validation: 0.09652348483916705]
	TIME [epoch: 5.75 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1186823642275536		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.1186823642275536 | validation: 0.08813553981194627]
	TIME [epoch: 5.75 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12267641035609339		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.12267641035609339 | validation: 0.16928872122122118]
	TIME [epoch: 5.78 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15769652899247597		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15769652899247597 | validation: 0.09691928808421736]
	TIME [epoch: 5.77 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12571915958825142		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.12571915958825142 | validation: 0.10535484554950948]
	TIME [epoch: 5.75 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262507440621175		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.14262507440621175 | validation: 0.14797919639655954]
	TIME [epoch: 5.76 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13074227228973231		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.13074227228973231 | validation: 0.10792856471408768]
	TIME [epoch: 5.75 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12134349542565404		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.12134349542565404 | validation: 0.10316137733030598]
	TIME [epoch: 5.75 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13242421925707007		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.13242421925707007 | validation: 0.11774724994565436]
	TIME [epoch: 5.75 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16814348368109663		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.16814348368109663 | validation: 0.09522575077936896]
	TIME [epoch: 5.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549033949746754		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.1549033949746754 | validation: 0.11145638491098545]
	TIME [epoch: 5.76 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13956472005327822		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.13956472005327822 | validation: 0.08710354197019946]
	TIME [epoch: 5.76 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536697141461013		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.1536697141461013 | validation: 0.08269668671207484]
	TIME [epoch: 5.75 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.178113518976074		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.178113518976074 | validation: 0.09942340310802891]
	TIME [epoch: 5.75 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12600429872238333		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.12600429872238333 | validation: 0.14314001160290338]
	TIME [epoch: 5.75 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15574101017823078		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.15574101017823078 | validation: 0.10358628089386689]
	TIME [epoch: 5.77 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368794376143998		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.1368794376143998 | validation: 0.13382982599036394]
	TIME [epoch: 5.77 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13558698635410177		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.13558698635410177 | validation: 0.11966113147031832]
	TIME [epoch: 5.77 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1552417451300983		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.1552417451300983 | validation: 0.13865833900707078]
	TIME [epoch: 5.75 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712654573320608		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.1712654573320608 | validation: 0.0699670992506093]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12094929337271769		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.12094929337271769 | validation: 0.18815885150670075]
	TIME [epoch: 5.76 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537945610617684		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.1537945610617684 | validation: 0.08703137627160887]
	TIME [epoch: 5.76 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11570827229297019		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.11570827229297019 | validation: 0.0948666622467475]
	TIME [epoch: 5.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13414529079682375		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.13414529079682375 | validation: 0.11702954850166027]
	TIME [epoch: 5.76 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16029467337784015		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.16029467337784015 | validation: 0.11822437744655312]
	TIME [epoch: 5.76 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13558357914565525		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.13558357914565525 | validation: 0.07897421242193049]
	TIME [epoch: 5.76 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13986615513549028		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.13986615513549028 | validation: 0.18400011812294112]
	TIME [epoch: 5.76 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16218040959308114		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.16218040959308114 | validation: 0.08883450808413305]
	TIME [epoch: 5.77 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16465122218399406		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.16465122218399406 | validation: 0.1564772933756365]
	TIME [epoch: 5.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705857468110684		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.1705857468110684 | validation: 0.08815513543901307]
	TIME [epoch: 5.76 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11663675698235618		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.11663675698235618 | validation: 0.11752282281703408]
	TIME [epoch: 5.76 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12380435621272023		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.12380435621272023 | validation: 0.07920615859632468]
	TIME [epoch: 5.76 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392881217874929		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.12392881217874929 | validation: 0.09748159665880984]
	TIME [epoch: 5.77 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13510870980809303		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.13510870980809303 | validation: 0.09766595824735667]
	TIME [epoch: 5.76 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15130941384154709		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.15130941384154709 | validation: 0.15377430120496072]
	TIME [epoch: 5.77 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14008073851749347		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.14008073851749347 | validation: 0.1811153140934791]
	TIME [epoch: 5.81 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15467907118757607		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.15467907118757607 | validation: 0.10825265049181841]
	TIME [epoch: 5.76 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12521778877690223		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.12521778877690223 | validation: 0.10228510097159202]
	TIME [epoch: 5.76 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11578184596151594		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.11578184596151594 | validation: 0.0904287233515212]
	TIME [epoch: 5.74 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12385394978663561		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.12385394978663561 | validation: 0.10042219257995476]
	TIME [epoch: 5.74 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11705916568222668		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.11705916568222668 | validation: 0.09607849593912614]
	TIME [epoch: 5.75 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17439352577279438		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.17439352577279438 | validation: 0.08084846085369626]
	TIME [epoch: 5.78 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818912749025532		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.12818912749025532 | validation: 0.10103345537127709]
	TIME [epoch: 5.76 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11381768556314902		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.11381768556314902 | validation: 0.09857529237603262]
	TIME [epoch: 5.75 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12545033368383707		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.12545033368383707 | validation: 0.10244562084522063]
	TIME [epoch: 5.75 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13430991327603717		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.13430991327603717 | validation: 0.1535094371244097]
	TIME [epoch: 5.76 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13513753321875976		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.13513753321875976 | validation: 0.0995579941929886]
	TIME [epoch: 5.74 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13259670415474115		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.13259670415474115 | validation: 0.1108463204304085]
	TIME [epoch: 5.78 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20707254342734005		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.20707254342734005 | validation: 0.09000896687053471]
	TIME [epoch: 5.78 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11137430525570718		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.11137430525570718 | validation: 0.097301845568254]
	TIME [epoch: 5.76 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14064916855648346		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.14064916855648346 | validation: 0.10468208228389682]
	TIME [epoch: 5.74 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324717502210844		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.1324717502210844 | validation: 0.07791970175838939]
	TIME [epoch: 5.75 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11511682795950115		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.11511682795950115 | validation: 0.10990262791331246]
	TIME [epoch: 5.75 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13152285607605152		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.13152285607605152 | validation: 0.08583769530905486]
	TIME [epoch: 5.76 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1122267215760189		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1122267215760189 | validation: 0.1122724384378941]
	TIME [epoch: 5.78 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12624730066346565		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.12624730066346565 | validation: 0.12453771580077952]
	TIME [epoch: 5.77 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129108457026936		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.129108457026936 | validation: 0.12220302372452181]
	TIME [epoch: 5.76 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14831787693563053		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.14831787693563053 | validation: 0.09336380404774336]
	TIME [epoch: 5.76 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11169737857807341		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.11169737857807341 | validation: 0.08664230919686076]
	TIME [epoch: 5.76 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13172259083508853		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.13172259083508853 | validation: 0.10122078398037535]
	TIME [epoch: 5.74 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12121034528306238		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.12121034528306238 | validation: 0.1260635408593831]
	TIME [epoch: 5.75 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12799280642695782		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.12799280642695782 | validation: 0.08739311845563076]
	TIME [epoch: 5.78 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13669324981371248		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.13669324981371248 | validation: 0.11477899785402666]
	TIME [epoch: 5.74 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307726310311862		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1307726310311862 | validation: 0.09916973791874173]
	TIME [epoch: 5.77 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1869457210078934		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.1869457210078934 | validation: 0.11767586704081887]
	TIME [epoch: 5.75 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14245794118489483		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.14245794118489483 | validation: 0.1521374762772572]
	TIME [epoch: 5.74 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13712757237229903		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.13712757237229903 | validation: 0.10342331734626098]
	TIME [epoch: 5.76 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11231210222138467		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.11231210222138467 | validation: 0.10673329060324077]
	TIME [epoch: 5.79 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12862158937378457		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.12862158937378457 | validation: 0.09149608916002183]
	TIME [epoch: 5.75 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10835508590379825		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.10835508590379825 | validation: 0.12447170711750785]
	TIME [epoch: 5.75 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13262582561750078		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.13262582561750078 | validation: 0.12650120078649515]
	TIME [epoch: 5.76 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13029048467149731		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.13029048467149731 | validation: 0.10056628982231396]
	TIME [epoch: 5.77 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483343285090127		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1483343285090127 | validation: 0.1569387817545995]
	TIME [epoch: 5.77 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14061284915830424		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.14061284915830424 | validation: 0.10951795395746378]
	TIME [epoch: 5.78 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263219485752044		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.1263219485752044 | validation: 0.09626760618872712]
	TIME [epoch: 5.79 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12940198358036997		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.12940198358036997 | validation: 0.08891851245439959]
	TIME [epoch: 5.76 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13852961365920308		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.13852961365920308 | validation: 0.08798393842062653]
	TIME [epoch: 5.76 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1100753532519773		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.1100753532519773 | validation: 0.0842655823827597]
	TIME [epoch: 5.76 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10993147615650288		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.10993147615650288 | validation: 0.08897328106066214]
	TIME [epoch: 5.77 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13717783443907386		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.13717783443907386 | validation: 0.09141751052710234]
	TIME [epoch: 5.77 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11454810002828432		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.11454810002828432 | validation: 0.09304979230730695]
	TIME [epoch: 5.81 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11199751207000075		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.11199751207000075 | validation: 0.07059256466260594]
	TIME [epoch: 5.77 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11801313736840895		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.11801313736840895 | validation: 0.07816191686020173]
	TIME [epoch: 5.77 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11753146147624585		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.11753146147624585 | validation: 0.0947816970814276]
	TIME [epoch: 5.75 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11256566142076169		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.11256566142076169 | validation: 0.0659695337185098]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_731.pth
	Model improved!!!
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13417014709503647		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.13417014709503647 | validation: 0.11279330894215854]
	TIME [epoch: 5.74 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12628083729388526		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.12628083729388526 | validation: 0.08839069586615772]
	TIME [epoch: 5.76 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11691539619626365		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.11691539619626365 | validation: 0.08348479889580354]
	TIME [epoch: 5.78 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11663722574531502		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.11663722574531502 | validation: 0.14750397419840472]
	TIME [epoch: 5.74 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14923793158534723		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.14923793158534723 | validation: 0.07743199892999207]
	TIME [epoch: 5.76 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212987472642773		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.1212987472642773 | validation: 0.09483049257975243]
	TIME [epoch: 5.77 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15500795090686825		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.15500795090686825 | validation: 0.16988109932126247]
	TIME [epoch: 5.76 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13625362483670386		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.13625362483670386 | validation: 0.0971159846761939]
	TIME [epoch: 5.75 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11655080856709514		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.11655080856709514 | validation: 0.08959820121360469]
	TIME [epoch: 5.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1209037923769457		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.1209037923769457 | validation: 0.08745307500909989]
	TIME [epoch: 5.75 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12617564233177608		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.12617564233177608 | validation: 0.1029970810812078]
	TIME [epoch: 5.75 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267789028557456		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.1267789028557456 | validation: 0.12751753262686422]
	TIME [epoch: 5.74 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13887457937014128		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.13887457937014128 | validation: 0.09572907265508968]
	TIME [epoch: 5.75 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13101876860845962		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.13101876860845962 | validation: 0.08847722804583633]
	TIME [epoch: 5.76 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11934428481978293		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.11934428481978293 | validation: 0.0728870837498131]
	TIME [epoch: 5.78 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11708219329778147		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.11708219329778147 | validation: 0.10693461704009152]
	TIME [epoch: 5.76 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11432857616071483		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.11432857616071483 | validation: 0.07760536435761584]
	TIME [epoch: 5.77 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09955370149646793		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.09955370149646793 | validation: 0.07278721396756292]
	TIME [epoch: 5.77 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11921301873023377		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.11921301873023377 | validation: 0.08615375508680118]
	TIME [epoch: 5.76 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10800550610749636		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.10800550610749636 | validation: 0.09108670381401396]
	TIME [epoch: 5.74 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11103551102787526		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.11103551102787526 | validation: 0.08081002068246021]
	TIME [epoch: 5.76 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10557096095851985		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.10557096095851985 | validation: 0.08650967622292877]
	TIME [epoch: 5.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13578766823863578		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.13578766823863578 | validation: 0.0820426437537736]
	TIME [epoch: 5.76 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13833902715205898		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.13833902715205898 | validation: 0.07691076387578603]
	TIME [epoch: 5.76 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079718144466077		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1079718144466077 | validation: 0.1138787681892196]
	TIME [epoch: 5.76 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11988017054418565		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.11988017054418565 | validation: 0.06721903260094393]
	TIME [epoch: 5.77 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11363398850475796		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.11363398850475796 | validation: 0.06814754240335726]
	TIME [epoch: 5.76 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09928836678067467		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.09928836678067467 | validation: 0.08912231103382291]
	TIME [epoch: 5.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11288602812496878		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.11288602812496878 | validation: 0.08964531762563187]
	TIME [epoch: 5.79 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16802277710776525		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.16802277710776525 | validation: 0.11527032421208652]
	TIME [epoch: 5.76 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12899341676935971		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.12899341676935971 | validation: 0.07482735739255153]
	TIME [epoch: 5.76 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1170270627106225		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.1170270627106225 | validation: 0.10565114442770622]
	TIME [epoch: 5.74 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10432530170511614		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.10432530170511614 | validation: 0.10221025637653312]
	TIME [epoch: 5.76 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13840183903596848		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.13840183903596848 | validation: 0.07873124655073242]
	TIME [epoch: 5.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10579974570871634		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.10579974570871634 | validation: 0.08201351462780633]
	TIME [epoch: 5.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12836977190862536		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.12836977190862536 | validation: 0.09157763277966986]
	TIME [epoch: 5.75 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13496369996868007		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.13496369996868007 | validation: 0.08855476610511591]
	TIME [epoch: 5.75 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11801402940668745		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.11801402940668745 | validation: 0.06823634380329764]
	TIME [epoch: 5.75 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890713177477718		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.09890713177477718 | validation: 0.09898450099881975]
	TIME [epoch: 5.75 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13699367636037146		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.13699367636037146 | validation: 0.08830021514300912]
	TIME [epoch: 5.75 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304283591248579		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.1304283591248579 | validation: 0.08561183117376187]
	TIME [epoch: 5.77 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11831832406347315		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.11831832406347315 | validation: 0.08141714606219207]
	TIME [epoch: 5.78 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1157112143620891		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.1157112143620891 | validation: 0.12575337033053743]
	TIME [epoch: 5.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289941936311126		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1289941936311126 | validation: 0.0790752875171338]
	TIME [epoch: 5.76 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11278850429354897		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.11278850429354897 | validation: 0.08730135431337109]
	TIME [epoch: 5.77 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11816957219254857		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.11816957219254857 | validation: 0.07961792448299558]
	TIME [epoch: 5.77 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11624288130760181		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.11624288130760181 | validation: 0.068378078239087]
	TIME [epoch: 5.76 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10314694138035023		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.10314694138035023 | validation: 0.11690389649413063]
	TIME [epoch: 5.81 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13674872467836166		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.13674872467836166 | validation: 0.10013675096565741]
	TIME [epoch: 5.76 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12192592918935385		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.12192592918935385 | validation: 0.08449402028508836]
	TIME [epoch: 5.76 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12288263471677087		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.12288263471677087 | validation: 0.11564792828574723]
	TIME [epoch: 5.77 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14089358997079054		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.14089358997079054 | validation: 0.11345568372650036]
	TIME [epoch: 5.77 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12786717659974392		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.12786717659974392 | validation: 0.09627833782282619]
	TIME [epoch: 5.76 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12344029621673352		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.12344029621673352 | validation: 0.11451298344804225]
	TIME [epoch: 5.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364677301052588		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.1364677301052588 | validation: 0.08291626490227713]
	TIME [epoch: 5.79 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10932588454744428		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.10932588454744428 | validation: 0.07394917434859409]
	TIME [epoch: 5.76 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1202423746770217		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1202423746770217 | validation: 0.0781098073823883]
	TIME [epoch: 5.76 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10666788314836964		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.10666788314836964 | validation: 0.07928623873950363]
	TIME [epoch: 5.76 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578327349212287		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.10578327349212287 | validation: 0.07244274466994875]
	TIME [epoch: 5.76 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11058026807605133		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.11058026807605133 | validation: 0.07212202326407821]
	TIME [epoch: 5.77 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11357101586404117		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.11357101586404117 | validation: 0.08992672864769218]
	TIME [epoch: 5.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11586621499264316		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.11586621499264316 | validation: 0.08366909478974285]
	TIME [epoch: 5.77 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11628984280328106		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.11628984280328106 | validation: 0.11283457699842388]
	TIME [epoch: 5.75 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11300631062774766		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.11300631062774766 | validation: 0.08127665455242675]
	TIME [epoch: 5.77 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11152897417762264		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.11152897417762264 | validation: 0.084372796889415]
	TIME [epoch: 5.75 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10932647140300032		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.10932647140300032 | validation: 0.1132972594968838]
	TIME [epoch: 5.76 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11248895660032618		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.11248895660032618 | validation: 0.11865525610069945]
	TIME [epoch: 5.78 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13075969447421276		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.13075969447421276 | validation: 0.08618470951836223]
	TIME [epoch: 5.76 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10419568994647004		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.10419568994647004 | validation: 0.07191562348106835]
	TIME [epoch: 5.77 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10268495000937737		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.10268495000937737 | validation: 0.07864675500895522]
	TIME [epoch: 5.75 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11078921426789684		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.11078921426789684 | validation: 0.0924714145450708]
	TIME [epoch: 5.75 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09985606323989435		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.09985606323989435 | validation: 0.09748003356750036]
	TIME [epoch: 5.76 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13590165381425784		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.13590165381425784 | validation: 0.08207674283144537]
	TIME [epoch: 5.77 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10447298353319967		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.10447298353319967 | validation: 0.07211788518690539]
	TIME [epoch: 5.78 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09415750704637471		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.09415750704637471 | validation: 0.0716624345019163]
	TIME [epoch: 5.76 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11299196536320097		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.11299196536320097 | validation: 0.10388527520844404]
	TIME [epoch: 5.76 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12141987529718834		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.12141987529718834 | validation: 0.06638770708423049]
	TIME [epoch: 5.76 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09734411700843719		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.09734411700843719 | validation: 0.09130038974510013]
	TIME [epoch: 5.74 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11538561755011689		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.11538561755011689 | validation: 0.10409168566976922]
	TIME [epoch: 5.77 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12875304963145462		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.12875304963145462 | validation: 0.07599157053408347]
	TIME [epoch: 5.81 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11698684827224186		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.11698684827224186 | validation: 0.08462881274182109]
	TIME [epoch: 5.77 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10209615144130833		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.10209615144130833 | validation: 0.07137664892759853]
	TIME [epoch: 5.76 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178200511322097		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.1178200511322097 | validation: 0.0970489555674481]
	TIME [epoch: 5.76 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12154470142312558		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.12154470142312558 | validation: 0.12240547362857784]
	TIME [epoch: 5.75 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12083604900270901		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.12083604900270901 | validation: 0.07332510289617059]
	TIME [epoch: 5.76 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10029075611594439		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.10029075611594439 | validation: 0.054027196638762036]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_817.pth
	Model improved!!!
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10312747830693346		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.10312747830693346 | validation: 0.08360126383432881]
	TIME [epoch: 5.79 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1122414488753247		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.1122414488753247 | validation: 0.19870193345777842]
	TIME [epoch: 5.75 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16077058032507638		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.16077058032507638 | validation: 0.06221748057051768]
	TIME [epoch: 5.76 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09530765351251191		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.09530765351251191 | validation: 0.1277634940118772]
	TIME [epoch: 5.74 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13897574903757415		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.13897574903757415 | validation: 0.06378292045403434]
	TIME [epoch: 5.74 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11209385048317531		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.11209385048317531 | validation: 0.07719842650255221]
	TIME [epoch: 5.74 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11531050306028656		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.11531050306028656 | validation: 0.09715132667072471]
	TIME [epoch: 5.79 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10540153090779296		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.10540153090779296 | validation: 0.06141131446595516]
	TIME [epoch: 5.76 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11000594757116888		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.11000594757116888 | validation: 0.07631934790736838]
	TIME [epoch: 5.75 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11306734443526009		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.11306734443526009 | validation: 0.081208291518481]
	TIME [epoch: 5.76 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890659591390452		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.09890659591390452 | validation: 0.07976974355512653]
	TIME [epoch: 5.74 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12836424685281692		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.12836424685281692 | validation: 0.11098906270921866]
	TIME [epoch: 5.76 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12440769906771665		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.12440769906771665 | validation: 0.08647400169184379]
	TIME [epoch: 5.76 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11499883908333543		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.11499883908333543 | validation: 0.07580640711224713]
	TIME [epoch: 5.78 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578259333511364		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.10578259333511364 | validation: 0.06988349132908372]
	TIME [epoch: 5.75 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12126845919738993		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.12126845919738993 | validation: 0.11020880627701264]
	TIME [epoch: 5.75 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11589495298649607		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.11589495298649607 | validation: 0.08732351707702289]
	TIME [epoch: 5.75 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12750602079883064		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.12750602079883064 | validation: 0.0846437830991063]
	TIME [epoch: 5.75 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1068245577993602		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.1068245577993602 | validation: 0.09704865784830766]
	TIME [epoch: 5.74 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10729878238124588		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.10729878238124588 | validation: 0.07023383993383167]
	TIME [epoch: 5.79 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10351375783740606		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.10351375783740606 | validation: 0.09069725937810706]
	TIME [epoch: 5.75 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232304009105356		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.10232304009105356 | validation: 0.06960307076957266]
	TIME [epoch: 5.76 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1234641558970781		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.1234641558970781 | validation: 0.10452279005858933]
	TIME [epoch: 5.74 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10958509318036343		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.10958509318036343 | validation: 0.06802555374510139]
	TIME [epoch: 5.75 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10059283112206334		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.10059283112206334 | validation: 0.0826338326727164]
	TIME [epoch: 5.75 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099867679990016		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.099867679990016 | validation: 0.0666014431787867]
	TIME [epoch: 5.77 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09639446239181933		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.09639446239181933 | validation: 0.10395515573064469]
	TIME [epoch: 5.77 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14531239575136642		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.14531239575136642 | validation: 0.13044783727289413]
	TIME [epoch: 5.77 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14496593218998585		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.14496593218998585 | validation: 0.11287964372133275]
	TIME [epoch: 5.76 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11370814262055404		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.11370814262055404 | validation: 0.07024312385338924]
	TIME [epoch: 5.76 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993894506375522		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.09993894506375522 | validation: 0.06398421599950536]
	TIME [epoch: 5.76 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12181139739026633		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.12181139739026633 | validation: 0.0973731714077603]
	TIME [epoch: 5.76 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11828427438993269		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.11828427438993269 | validation: 0.0998472572296612]
	TIME [epoch: 5.81 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13390816732729027		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.13390816732729027 | validation: 0.07754910336858375]
	TIME [epoch: 5.77 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10549075217156881		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.10549075217156881 | validation: 0.07489749517519317]
	TIME [epoch: 5.74 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09711738004679564		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.09711738004679564 | validation: 0.0687234363218422]
	TIME [epoch: 5.74 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10835171441723614		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.10835171441723614 | validation: 0.0709873264809792]
	TIME [epoch: 5.75 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10170182866007624		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.10170182866007624 | validation: 0.0724878426294365]
	TIME [epoch: 5.74 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10295466973507063		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.10295466973507063 | validation: 0.07666727249493908]
	TIME [epoch: 5.77 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10677219071186451		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.10677219071186451 | validation: 0.0709492262327292]
	TIME [epoch: 5.76 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995116591828042		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.0995116591828042 | validation: 0.10829413618960032]
	TIME [epoch: 5.75 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10587111505815104		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.10587111505815104 | validation: 0.06861824141803265]
	TIME [epoch: 5.75 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10087963608310489		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.10087963608310489 | validation: 0.09330343159324665]
	TIME [epoch: 5.76 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108340307683462		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.1108340307683462 | validation: 0.07597910847959415]
	TIME [epoch: 5.74 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1200992407556416		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.1200992407556416 | validation: 0.09325920598448116]
	TIME [epoch: 5.75 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1111325042141719		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.1111325042141719 | validation: 0.08111024627781033]
	TIME [epoch: 5.79 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11156577378238203		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.11156577378238203 | validation: 0.07715760519424807]
	TIME [epoch: 5.74 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09889677349518754		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.09889677349518754 | validation: 0.08208569725224713]
	TIME [epoch: 5.74 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11822526822032847		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.11822526822032847 | validation: 0.07613727276649279]
	TIME [epoch: 5.75 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09326966024034102		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.09326966024034102 | validation: 0.07539536259814039]
	TIME [epoch: 5.74 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09463701321195746		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.09463701321195746 | validation: 0.08018355839389499]
	TIME [epoch: 5.74 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11131542485121976		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.11131542485121976 | validation: 0.07301339391967056]
	TIME [epoch: 5.77 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09554352945826519		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.09554352945826519 | validation: 0.06390573318577028]
	TIME [epoch: 5.76 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247686382632631		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.10247686382632631 | validation: 0.08416954643971858]
	TIME [epoch: 5.74 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10514065578096335		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.10514065578096335 | validation: 0.0859154094021363]
	TIME [epoch: 5.74 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1085517313095001		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.1085517313095001 | validation: 0.10786876207884866]
	TIME [epoch: 5.74 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11179608709961078		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.11179608709961078 | validation: 0.06921665315057733]
	TIME [epoch: 5.75 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071651303195485		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.1071651303195485 | validation: 0.08551487962840333]
	TIME [epoch: 5.74 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762483345495011		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.09762483345495011 | validation: 0.06336107791212366]
	TIME [epoch: 5.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0988574636692165		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.0988574636692165 | validation: 0.07247755573070033]
	TIME [epoch: 5.74 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10465399182063805		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.10465399182063805 | validation: 0.07355645400851443]
	TIME [epoch: 5.75 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10807316850680664		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.10807316850680664 | validation: 0.09063013505939566]
	TIME [epoch: 5.75 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10915416323179727		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.10915416323179727 | validation: 0.07411550799091449]
	TIME [epoch: 5.75 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10198512069190187		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.10198512069190187 | validation: 0.060879397607126275]
	TIME [epoch: 5.74 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10175121321654275		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.10175121321654275 | validation: 0.07415943308254122]
	TIME [epoch: 5.79 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11510547728860877		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.11510547728860877 | validation: 0.09611524484126356]
	TIME [epoch: 5.76 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11101737156211541		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.11101737156211541 | validation: 0.09230125910332483]
	TIME [epoch: 5.74 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10820245701328254		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.10820245701328254 | validation: 0.07680527531522957]
	TIME [epoch: 5.75 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11711175865164761		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.11711175865164761 | validation: 0.08725414157351669]
	TIME [epoch: 5.74 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10211865044495227		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.10211865044495227 | validation: 0.07714721289500648]
	TIME [epoch: 5.76 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1018842780637739		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.1018842780637739 | validation: 0.06538354116762704]
	TIME [epoch: 5.75 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0892578128793158		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0892578128793158 | validation: 0.07958618047885666]
	TIME [epoch: 5.81 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13161267661886933		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.13161267661886933 | validation: 0.10935537182733035]
	TIME [epoch: 5.75 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11236925649939918		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.11236925649939918 | validation: 0.06323990606721694]
	TIME [epoch: 5.75 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09158296442206214		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.09158296442206214 | validation: 0.06176207223147393]
	TIME [epoch: 5.75 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09441398483555509		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.09441398483555509 | validation: 0.06314423110536156]
	TIME [epoch: 5.76 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09454863266653243		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.09454863266653243 | validation: 0.05858326764697155]
	TIME [epoch: 5.74 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0972560726629082		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.0972560726629082 | validation: 0.09028123553733433]
	TIME [epoch: 5.79 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10179976289989286		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.10179976289989286 | validation: 0.05516663020642106]
	TIME [epoch: 5.77 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09290540534038218		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.09290540534038218 | validation: 0.07090351480654784]
	TIME [epoch: 5.75 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290898753843646		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.10290898753843646 | validation: 0.07240879935856291]
	TIME [epoch: 5.75 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09915858241766373		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.09915858241766373 | validation: 0.09366528486674076]
	TIME [epoch: 5.75 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11706571371386193		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.11706571371386193 | validation: 0.10141205988566622]
	TIME [epoch: 5.75 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126699024771239		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.126699024771239 | validation: 0.1060377730121068]
	TIME [epoch: 5.75 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1092081325978192		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.1092081325978192 | validation: 0.07054027886010038]
	TIME [epoch: 5.79 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001625203323167		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.1001625203323167 | validation: 0.07813571873499156]
	TIME [epoch: 5.75 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09639381712147388		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.09639381712147388 | validation: 0.07316952395470618]
	TIME [epoch: 5.75 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173135475302861		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.10173135475302861 | validation: 0.07725536452642554]
	TIME [epoch: 5.75 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10141683843540182		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.10141683843540182 | validation: 0.09793596619804731]
	TIME [epoch: 5.76 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10350067639950439		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.10350067639950439 | validation: 0.06413145485258234]
	TIME [epoch: 5.75 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09104069492242568		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.09104069492242568 | validation: 0.07776376893331408]
	TIME [epoch: 5.79 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11011033080419866		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.11011033080419866 | validation: 0.08826683172916173]
	TIME [epoch: 5.77 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11287778973932279		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.11287778973932279 | validation: 0.06853397090417244]
	TIME [epoch: 5.75 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499746266148205		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.09499746266148205 | validation: 0.06562402453641594]
	TIME [epoch: 5.77 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09479192362791754		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.09479192362791754 | validation: 0.07277725309894936]
	TIME [epoch: 5.75 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10033624598845511		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.10033624598845511 | validation: 0.08355965923614336]
	TIME [epoch: 5.75 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10355966756556657		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.10355966756556657 | validation: 0.061989029610208066]
	TIME [epoch: 5.76 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10482876470641647		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.10482876470641647 | validation: 0.0777910167703188]
	TIME [epoch: 5.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11282193871305794		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.11282193871305794 | validation: 0.0629101726462242]
	TIME [epoch: 5.77 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09144126273234082		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.09144126273234082 | validation: 0.060874265393388624]
	TIME [epoch: 5.74 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0964178598466176		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.0964178598466176 | validation: 0.07694405283559436]
	TIME [epoch: 5.76 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12383019030745679		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.12383019030745679 | validation: 0.0726417187634473]
	TIME [epoch: 5.76 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10438930687676655		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.10438930687676655 | validation: 0.09565148838861447]
	TIME [epoch: 5.76 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11566874695520603		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.11566874695520603 | validation: 0.08603271415452719]
	TIME [epoch: 5.78 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11837388471578461		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.11837388471578461 | validation: 0.07776338086547017]
	TIME [epoch: 5.78 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1005948791511941		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.1005948791511941 | validation: 0.06504633741750432]
	TIME [epoch: 5.76 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09720877963951263		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.09720877963951263 | validation: 0.06930056668253502]
	TIME [epoch: 5.76 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09408357287176718		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.09408357287176718 | validation: 0.056522824548702034]
	TIME [epoch: 5.75 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11325821943070022		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.11325821943070022 | validation: 0.0940372485398961]
	TIME [epoch: 5.76 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11963792431397363		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.11963792431397363 | validation: 0.07403921375954801]
	TIME [epoch: 5.76 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09912556382417187		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.09912556382417187 | validation: 0.0760050019888518]
	TIME [epoch: 5.79 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10089958303148779		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.10089958303148779 | validation: 0.06359325647587774]
	TIME [epoch: 5.75 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0936963681881437		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.0936963681881437 | validation: 0.06245421702340709]
	TIME [epoch: 5.75 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10239334071419169		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.10239334071419169 | validation: 0.0686191853812558]
	TIME [epoch: 5.75 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10133580099622319		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.10133580099622319 | validation: 0.09140283520871606]
	TIME [epoch: 5.75 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124559640996312		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.124559640996312 | validation: 0.12387717025349186]
	TIME [epoch: 5.75 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12097596444915998		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.12097596444915998 | validation: 0.06657864629835647]
	TIME [epoch: 5.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08738133592623448		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.08738133592623448 | validation: 0.06364438952138889]
	TIME [epoch: 5.75 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09448052427483064		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.09448052427483064 | validation: 0.07782925757770676]
	TIME [epoch: 5.75 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11041630473090655		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.11041630473090655 | validation: 0.08807214309757329]
	TIME [epoch: 5.75 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0972410544265089		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0972410544265089 | validation: 0.07922854851655652]
	TIME [epoch: 5.76 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10224594306294271		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.10224594306294271 | validation: 0.053686428214344266]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_939.pth
	Model improved!!!
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09259586580556925		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.09259586580556925 | validation: 0.07854607078966869]
	TIME [epoch: 5.76 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09681376159654101		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.09681376159654101 | validation: 0.07163598216871483]
	TIME [epoch: 5.77 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10549475030983647		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.10549475030983647 | validation: 0.06447353170421398]
	TIME [epoch: 5.74 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0894325078929445		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.0894325078929445 | validation: 0.07506042393157246]
	TIME [epoch: 5.75 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09936928310846305		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.09936928310846305 | validation: 0.0706390165239817]
	TIME [epoch: 5.74 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10165615254289596		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.10165615254289596 | validation: 0.07797695240009203]
	TIME [epoch: 5.76 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10262733747784257		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.10262733747784257 | validation: 0.059387882547359425]
	TIME [epoch: 5.74 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09374127697536437		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.09374127697536437 | validation: 0.0831354254696599]
	TIME [epoch: 5.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09671861246768836		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.09671861246768836 | validation: 0.08258164496124089]
	TIME [epoch: 5.76 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09650647556336883		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.09650647556336883 | validation: 0.06324356742311063]
	TIME [epoch: 5.76 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09262238972615		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.09262238972615 | validation: 0.08341475293129344]
	TIME [epoch: 5.76 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11539915055648808		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.11539915055648808 | validation: 0.11709682169327028]
	TIME [epoch: 5.75 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12367331476786651		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.12367331476786651 | validation: 0.07644283761565916]
	TIME [epoch: 5.76 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002794105637407		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.1002794105637407 | validation: 0.06578671828225512]
	TIME [epoch: 5.76 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10134016802066617		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.10134016802066617 | validation: 0.05851164331622116]
	TIME [epoch: 5.78 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09733085103108657		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.09733085103108657 | validation: 0.06689580855626256]
	TIME [epoch: 5.77 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09644967602386915		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.09644967602386915 | validation: 0.06991115285744275]
	TIME [epoch: 5.75 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10284462183061141		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.10284462183061141 | validation: 0.0964241737576873]
	TIME [epoch: 5.77 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10851929586862698		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.10851929586862698 | validation: 0.06596346244707793]
	TIME [epoch: 5.74 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09543152633880064		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.09543152633880064 | validation: 0.06588178436428482]
	TIME [epoch: 5.76 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0904013985318582		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.0904013985318582 | validation: 0.07329998539379844]
	TIME [epoch: 5.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10120719820428882		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.10120719820428882 | validation: 0.07867162762210034]
	TIME [epoch: 5.75 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11749981754378028		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.11749981754378028 | validation: 0.09506979580741497]
	TIME [epoch: 5.74 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12644401498815072		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.12644401498815072 | validation: 0.07895943073896781]
	TIME [epoch: 5.74 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10219367440261848		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.10219367440261848 | validation: 0.08462129367141617]
	TIME [epoch: 5.74 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11143365873484654		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.11143365873484654 | validation: 0.06567884773334141]
	TIME [epoch: 5.75 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09341856018163838		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.09341856018163838 | validation: 0.07549448845972792]
	TIME [epoch: 5.79 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09325296750303895		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.09325296750303895 | validation: 0.06652922102748317]
	TIME [epoch: 5.78 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08948421364200243		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.08948421364200243 | validation: 0.0745172128669535]
	TIME [epoch: 5.77 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10819954923765035		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.10819954923765035 | validation: 0.08031696152610301]
	TIME [epoch: 5.75 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10426483008358493		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.10426483008358493 | validation: 0.07275090909371609]
	TIME [epoch: 5.76 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09761963029970194		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.09761963029970194 | validation: 0.06385945313612446]
	TIME [epoch: 5.74 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09400273939685955		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.09400273939685955 | validation: 0.0690812218293063]
	TIME [epoch: 5.75 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09917468979126721		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.09917468979126721 | validation: 0.05564963139050885]
	TIME [epoch: 5.82 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0918050529451175		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0918050529451175 | validation: 0.07904582714351908]
	TIME [epoch: 5.75 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0985375636504022		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.0985375636504022 | validation: 0.06900696364444722]
	TIME [epoch: 5.76 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10264751001378593		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.10264751001378593 | validation: 0.08967557091880901]
	TIME [epoch: 5.75 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09778458302440457		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.09778458302440457 | validation: 0.06940990052936863]
	TIME [epoch: 5.76 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317260140359032		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.10317260140359032 | validation: 0.0795777016133567]
	TIME [epoch: 5.76 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0945336519678215		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.0945336519678215 | validation: 0.06664476865736177]
	TIME [epoch: 5.79 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08972370192161569		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.08972370192161569 | validation: 0.08749325119433986]
	TIME [epoch: 5.77 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10045518308309273		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.10045518308309273 | validation: 0.07343413376401314]
	TIME [epoch: 5.76 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0912042715759315		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.0912042715759315 | validation: 0.05958908040706259]
	TIME [epoch: 5.75 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0969362815224755		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.0969362815224755 | validation: 0.0799966569298004]
	TIME [epoch: 5.74 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0998830144966167		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.0998830144966167 | validation: 0.060531110136257275]
	TIME [epoch: 5.75 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09704238977316532		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.09704238977316532 | validation: 0.0692330699416449]
	TIME [epoch: 5.74 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09512825216959361		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.09512825216959361 | validation: 0.06562368224779273]
	TIME [epoch: 5.81 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09305672835731822		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.09305672835731822 | validation: 0.07628505242514899]
	TIME [epoch: 5.75 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09031686742642234		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.09031686742642234 | validation: 0.05980397146445683]
	TIME [epoch: 5.75 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09324646276981143		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.09324646276981143 | validation: 0.08134791608081844]
	TIME [epoch: 5.74 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10249654556656834		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.10249654556656834 | validation: 0.05831201953731133]
	TIME [epoch: 5.74 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08989633520643128		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.08989633520643128 | validation: 0.06622964748220284]
	TIME [epoch: 5.74 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0917175527719107		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.0917175527719107 | validation: 0.06061455502768265]
	TIME [epoch: 5.78 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10020330621492364		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.10020330621492364 | validation: 0.08314022139726719]
	TIME [epoch: 5.77 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11470180307266478		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.11470180307266478 | validation: 0.07100012469009175]
	TIME [epoch: 5.76 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09064381888163679		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.09064381888163679 | validation: 0.0620631811726827]
	TIME [epoch: 5.76 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08654022380579292		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.08654022380579292 | validation: 0.07162371106102387]
	TIME [epoch: 5.75 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114552130331655		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.10114552130331655 | validation: 0.0960887723174508]
	TIME [epoch: 5.74 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1105441253174569		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.1105441253174569 | validation: 0.07769481262605156]
	TIME [epoch: 5.76 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0886693875374647		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.0886693875374647 | validation: 0.0603351620507229]
	TIME [epoch: 5.79 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08922308556534236		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.08922308556534236 | validation: 0.058012456648741245]
	TIME [epoch: 5.75 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09126177565552004		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.09126177565552004 | validation: 0.07187029104354563]
	TIME [epoch: 5.74 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09060703730012543		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.09060703730012543 | validation: 0.06398390553904455]
	TIME [epoch: 5.75 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09300180855100235		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.09300180855100235 | validation: 0.0839611325784544]
	TIME [epoch: 5.74 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09831776329499493		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.09831776329499493 | validation: 0.05976687071787024]
	TIME [epoch: 5.76 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09004794476789607		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.09004794476789607 | validation: 0.08648326093307007]
	TIME [epoch: 5.79 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926604151420294		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.09926604151420294 | validation: 0.06354151559602136]
	TIME [epoch: 5.77 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0957366920224468		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.0957366920224468 | validation: 0.08799593392882882]
	TIME [epoch: 5.77 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10465359983706451		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.10465359983706451 | validation: 0.06266292779152711]
	TIME [epoch: 5.75 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09600873414723926		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.09600873414723926 | validation: 0.07631521187687797]
	TIME [epoch: 5.74 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09960810970438279		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.09960810970438279 | validation: 0.06588954968560745]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909820801863749		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.08909820801863749 | validation: 0.0749764903175245]
	TIME [epoch: 5.75 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10770707101522317		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.10770707101522317 | validation: 0.09222970974623261]
	TIME [epoch: 5.81 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10933593582805996		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.10933593582805996 | validation: 0.06674150423423472]
	TIME [epoch: 5.75 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880683362820423		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.0880683362820423 | validation: 0.06292273232185928]
	TIME [epoch: 5.75 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08559574262126676		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.08559574262126676 | validation: 0.05763053084079939]
	TIME [epoch: 5.77 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09073661917890599		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.09073661917890599 | validation: 0.0635276819933477]
	TIME [epoch: 5.76 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10345102046094765		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.10345102046094765 | validation: 0.0906492856474021]
	TIME [epoch: 5.74 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185297600394405		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.10185297600394405 | validation: 0.07539562206503415]
	TIME [epoch: 5.78 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09678319187620905		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.09678319187620905 | validation: 0.07056236473301397]
	TIME [epoch: 5.78 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09181568419321451		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.09181568419321451 | validation: 0.06441815681790039]
	TIME [epoch: 5.75 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09013676594917343		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.09013676594917343 | validation: 0.07609401873167382]
	TIME [epoch: 5.77 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0940071355066523		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.0940071355066523 | validation: 0.06551884228120494]
	TIME [epoch: 5.75 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09652650248932011		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.09652650248932011 | validation: 0.05551046741580194]
	TIME [epoch: 5.75 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0910778007148661		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.0910778007148661 | validation: 0.06701998384240301]
	TIME [epoch: 5.78 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08858791844247463		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.08858791844247463 | validation: 0.07905509817055587]
	TIME [epoch: 5.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09190151390528455		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.09190151390528455 | validation: 0.06185742069370028]
	TIME [epoch: 5.74 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08882242455775086		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.08882242455775086 | validation: 0.057336410047083924]
	TIME [epoch: 5.74 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08425898861885933		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.08425898861885933 | validation: 0.06034163721156066]
	TIME [epoch: 5.74 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09032328792849317		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.09032328792849317 | validation: 0.06202121969868854]
	TIME [epoch: 5.76 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09307191269973403		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.09307191269973403 | validation: 0.0645723422434954]
	TIME [epoch: 5.74 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09099874960790678		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.09099874960790678 | validation: 0.08700527049518261]
	TIME [epoch: 5.79 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10104002825277715		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.10104002825277715 | validation: 0.059037838602983006]
	TIME [epoch: 5.75 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09168758000555516		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.09168758000555516 | validation: 0.07070346930772418]
	TIME [epoch: 5.75 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09238277160337921		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.09238277160337921 | validation: 0.0628162952889981]
	TIME [epoch: 5.74 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08985180980209918		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.08985180980209918 | validation: 0.05866010381851823]
	TIME [epoch: 5.75 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09832769122866435		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.09832769122866435 | validation: 0.07000064692667302]
	TIME [epoch: 5.75 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883375596206839		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.0883375596206839 | validation: 0.06102277318775592]
	TIME [epoch: 5.77 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08571007325428687		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.08571007325428687 | validation: 0.06630017890614945]
	TIME [epoch: 5.77 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0903006294063948		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.0903006294063948 | validation: 0.05859356340404224]
	TIME [epoch: 5.75 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0873929013397709		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.0873929013397709 | validation: 0.0663010277519548]
	TIME [epoch: 5.76 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909137541001348		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0909137541001348 | validation: 0.08691461456244486]
	TIME [epoch: 5.76 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10410131304934042		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.10410131304934042 | validation: 0.0834718012897395]
	TIME [epoch: 5.76 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09667978822182394		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.09667978822182394 | validation: 0.06698871374357433]
	TIME [epoch: 5.76 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09096343703994939		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.09096343703994939 | validation: 0.05570292978934837]
	TIME [epoch: 5.79 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08476409300451679		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.08476409300451679 | validation: 0.057572471282382305]
	TIME [epoch: 5.76 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848689967819257		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.09848689967819257 | validation: 0.06889836426616563]
	TIME [epoch: 5.76 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09126582332325116		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.09126582332325116 | validation: 0.08254120691082871]
	TIME [epoch: 5.76 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0999258101643349		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.0999258101643349 | validation: 0.0631802338270443]
	TIME [epoch: 5.75 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0881706441361938		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.0881706441361938 | validation: 0.060549010275294184]
	TIME [epoch: 5.76 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11216293519947307		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.11216293519947307 | validation: 0.09016674067534548]
	TIME [epoch: 5.76 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09647983331214151		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.09647983331214151 | validation: 0.07033605993524315]
	TIME [epoch: 5.78 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0859659549468256		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.0859659549468256 | validation: 0.05332040823464557]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1052.pth
	Model improved!!!
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08421695097447215		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.08421695097447215 | validation: 0.06000379033260003]
	TIME [epoch: 5.75 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08985207679184459		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.08985207679184459 | validation: 0.06376404435230476]
	TIME [epoch: 5.74 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08888454997282041		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.08888454997282041 | validation: 0.0702699046909451]
	TIME [epoch: 5.74 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09578092128400342		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.09578092128400342 | validation: 0.08168452069756954]
	TIME [epoch: 5.76 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10034258978172		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.10034258978172 | validation: 0.06225632264912172]
	TIME [epoch: 5.81 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09143943600868548		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.09143943600868548 | validation: 0.07262513514731372]
	TIME [epoch: 5.74 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08893959618918532		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.08893959618918532 | validation: 0.06694229330717374]
	TIME [epoch: 5.74 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11672592875859256		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.11672592875859256 | validation: 0.08392248282183591]
	TIME [epoch: 5.74 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10773742385878894		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.10773742385878894 | validation: 0.07168399512648212]
	TIME [epoch: 5.76 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09583954443494408		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.09583954443494408 | validation: 0.06092534816051238]
	TIME [epoch: 5.74 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924208998333821		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.08924208998333821 | validation: 0.06687374972857221]
	TIME [epoch: 5.78 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0957132051442065		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.0957132051442065 | validation: 0.0818841598983423]
	TIME [epoch: 5.78 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09504288470248404		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.09504288470248404 | validation: 0.06438318595405164]
	TIME [epoch: 5.76 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08726210742504818		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.08726210742504818 | validation: 0.06317327378731237]
	TIME [epoch: 5.75 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08855179956423745		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.08855179956423745 | validation: 0.06408650287531092]
	TIME [epoch: 5.75 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09078504474563089		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.09078504474563089 | validation: 0.0705705976187031]
	TIME [epoch: 5.75 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09786304560968229		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.09786304560968229 | validation: 0.058785325474840444]
	TIME [epoch: 5.75 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09692260465817873		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.09692260465817873 | validation: 0.09702100715214933]
	TIME [epoch: 5.78 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900005557735362		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.10900005557735362 | validation: 0.0715998290901782]
	TIME [epoch: 5.75 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09217132629382675		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.09217132629382675 | validation: 0.06442025736723622]
	TIME [epoch: 5.74 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08751233142020497		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.08751233142020497 | validation: 0.07026065143475259]
	TIME [epoch: 5.75 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09583262832204006		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.09583262832204006 | validation: 0.07795821009497671]
	TIME [epoch: 5.75 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09793434659419825		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.09793434659419825 | validation: 0.05925829338875571]
	TIME [epoch: 5.75 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09656010917566242		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.09656010917566242 | validation: 0.07736522242084831]
	TIME [epoch: 5.78 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10944246212139441		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.10944246212139441 | validation: 0.09492208993752196]
	TIME [epoch: 5.77 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10887089872232958		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.10887089872232958 | validation: 0.06865091842895901]
	TIME [epoch: 5.75 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08770186403814151		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.08770186403814151 | validation: 0.06600457699497572]
	TIME [epoch: 5.74 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847371080474222		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.0847371080474222 | validation: 0.06391869268553345]
	TIME [epoch: 5.74 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09159991112315831		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.09159991112315831 | validation: 0.09070391268033355]
	TIME [epoch: 5.75 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10795270629471802		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.10795270629471802 | validation: 0.06150813521230759]
	TIME [epoch: 5.75 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08514637409372505		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.08514637409372505 | validation: 0.06313047676302003]
	TIME [epoch: 5.79 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08936105580086964		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.08936105580086964 | validation: 0.06544048689876053]
	TIME [epoch: 5.75 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08964111965881437		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.08964111965881437 | validation: 0.060324554896142524]
	TIME [epoch: 5.75 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08811865552452892		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.08811865552452892 | validation: 0.06764903684901417]
	TIME [epoch: 5.76 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09078284922697628		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.09078284922697628 | validation: 0.06503658910573966]
	TIME [epoch: 5.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0935578994998838		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.0935578994998838 | validation: 0.07667861866577497]
	TIME [epoch: 5.74 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10395259697593273		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.10395259697593273 | validation: 0.058978994387650786]
	TIME [epoch: 5.78 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09211925295788623		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.09211925295788623 | validation: 0.06886747706922879]
	TIME [epoch: 5.77 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993280567741961		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.0993280567741961 | validation: 0.06332908187147755]
	TIME [epoch: 5.75 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09071922690974092		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.09071922690974092 | validation: 0.05927102359213865]
	TIME [epoch: 5.75 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09112221862450853		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.09112221862450853 | validation: 0.07664745546151286]
	TIME [epoch: 5.75 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09104414605322253		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.09104414605322253 | validation: 0.061094361416139116]
	TIME [epoch: 5.75 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08359476845524487		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.08359476845524487 | validation: 0.07345700767747129]
	TIME [epoch: 5.75 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0999685958318398		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.0999685958318398 | validation: 0.05940799293547685]
	TIME [epoch: 5.79 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0865061777539448		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.0865061777539448 | validation: 0.07179295262475438]
	TIME [epoch: 5.75 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08339268343542972		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.08339268343542972 | validation: 0.0494680354147237]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1098.pth
	Model improved!!!
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09530718638902486		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.09530718638902486 | validation: 0.06404666318575317]
	TIME [epoch: 5.76 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08813602555659883		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.08813602555659883 | validation: 0.05011838262232952]
	TIME [epoch: 5.75 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08854158187480338		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.08854158187480338 | validation: 0.06739573930983013]
	TIME [epoch: 5.75 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08556985697099803		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.08556985697099803 | validation: 0.04927398293816432]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1102.pth
	Model improved!!!
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0890780559901295		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0890780559901295 | validation: 0.058142386788894475]
	TIME [epoch: 5.76 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08914537843789186		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.08914537843789186 | validation: 0.07587521484300186]
	TIME [epoch: 5.74 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10304661507519129		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.10304661507519129 | validation: 0.09483260358182338]
	TIME [epoch: 5.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11949337711153724		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.11949337711153724 | validation: 0.07973418397644887]
	TIME [epoch: 5.74 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11033202076784555		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.11033202076784555 | validation: 0.07057617616035106]
	TIME [epoch: 5.75 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09472689143454398		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.09472689143454398 | validation: 0.07053149584467887]
	TIME [epoch: 5.75 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08341025027134967		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.08341025027134967 | validation: 0.059690251864661745]
	TIME [epoch: 5.78 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08394403322306203		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.08394403322306203 | validation: 0.058382419761104434]
	TIME [epoch: 5.75 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08311720580429133		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.08311720580429133 | validation: 0.058476476750747006]
	TIME [epoch: 5.74 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08537543532148395		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.08537543532148395 | validation: 0.06767638061243067]
	TIME [epoch: 5.74 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09425869626574768		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.09425869626574768 | validation: 0.06007174517737766]
	TIME [epoch: 5.74 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09012030618744774		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.09012030618744774 | validation: 0.07399012584402447]
	TIME [epoch: 5.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08799271159683594		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.08799271159683594 | validation: 0.05321137239169908]
	TIME [epoch: 5.78 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09283080790039402		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.09283080790039402 | validation: 0.05768629544782729]
	TIME [epoch: 5.75 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09063884280991209		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.09063884280991209 | validation: 0.05297170264996506]
	TIME [epoch: 5.75 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09784958998711861		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.09784958998711861 | validation: 0.06759790687451882]
	TIME [epoch: 5.74 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09386965222006771		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.09386965222006771 | validation: 0.06315668819245586]
	TIME [epoch: 5.74 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09097575243790867		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.09097575243790867 | validation: 0.059377640128430914]
	TIME [epoch: 5.75 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07865480340279328		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.07865480340279328 | validation: 0.056929438506426004]
	TIME [epoch: 5.75 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08714124415324484		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.08714124415324484 | validation: 0.06004592734886743]
	TIME [epoch: 5.78 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08585623075910925		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.08585623075910925 | validation: 0.05397808458913337]
	TIME [epoch: 5.74 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533199800907265		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.08533199800907265 | validation: 0.059764012384898424]
	TIME [epoch: 5.74 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08085699048003718		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.08085699048003718 | validation: 0.05577650723704637]
	TIME [epoch: 5.75 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09189614170136773		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.09189614170136773 | validation: 0.053692062739138305]
	TIME [epoch: 5.75 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08854011679431405		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.08854011679431405 | validation: 0.05867832366250938]
	TIME [epoch: 5.74 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09169430750150272		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.09169430750150272 | validation: 0.05671742000219939]
	TIME [epoch: 5.79 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08873140044589947		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.08873140044589947 | validation: 0.05820494784122898]
	TIME [epoch: 5.75 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10294952325702181		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.10294952325702181 | validation: 0.08913399945935638]
	TIME [epoch: 5.74 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0982236836539414		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.0982236836539414 | validation: 0.058078359624249336]
	TIME [epoch: 5.74 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08414269653929239		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.08414269653929239 | validation: 0.05873491456336652]
	TIME [epoch: 5.74 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08695379425911984		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.08695379425911984 | validation: 0.061686958590219804]
	TIME [epoch: 5.74 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08665675935879652		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.08665675935879652 | validation: 0.05732642820927618]
	TIME [epoch: 5.76 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0845276774338141		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.0845276774338141 | validation: 0.06561663498832435]
	TIME [epoch: 5.78 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08406449985081843		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.08406449985081843 | validation: 0.06210063805041134]
	TIME [epoch: 5.75 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023928451788561		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.09023928451788561 | validation: 0.05930504735600625]
	TIME [epoch: 5.75 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08981726513786928		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.08981726513786928 | validation: 0.06845212128955759]
	TIME [epoch: 5.75 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08606846661877571		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.08606846661877571 | validation: 0.05332144572930439]
	TIME [epoch: 5.74 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09121778848542089		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.09121778848542089 | validation: 0.06947390677389745]
	TIME [epoch: 5.74 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09134089748438373		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.09134089748438373 | validation: 0.07624922119428905]
	TIME [epoch: 5.78 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10778746895425276		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.10778746895425276 | validation: 0.06808638489526382]
	TIME [epoch: 5.75 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09213300725009996		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.09213300725009996 | validation: 0.06578714342430718]
	TIME [epoch: 5.75 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08655683896690175		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.08655683896690175 | validation: 0.04599029195385961]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1144.pth
	Model improved!!!
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856344304502713		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.0856344304502713 | validation: 0.06136397088100637]
	TIME [epoch: 5.75 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08521412755059538		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.08521412755059538 | validation: 0.04655687747344149]
	TIME [epoch: 5.75 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0879447964527982		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.0879447964527982 | validation: 0.05632786471045142]
	TIME [epoch: 5.78 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08832687899546925		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.08832687899546925 | validation: 0.05482139501462908]
	TIME [epoch: 5.77 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0875413226914216		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.0875413226914216 | validation: 0.06700649495016724]
	TIME [epoch: 5.75 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0946246786007374		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.0946246786007374 | validation: 0.06925171458542495]
	TIME [epoch: 5.75 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09172727764533713		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.09172727764533713 | validation: 0.04896301966292347]
	TIME [epoch: 5.75 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401037711446138		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.08401037711446138 | validation: 0.0544622486441825]
	TIME [epoch: 5.75 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08377182525145008		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.08377182525145008 | validation: 0.054813514650342815]
	TIME [epoch: 5.75 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821020672384725		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.08821020672384725 | validation: 0.062255347984502704]
	TIME [epoch: 5.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09143582113241433		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.09143582113241433 | validation: 0.07294986604017273]
	TIME [epoch: 5.76 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0994122732594297		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.0994122732594297 | validation: 0.06075945798811852]
	TIME [epoch: 5.75 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08996414835013518		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.08996414835013518 | validation: 0.06106674547842617]
	TIME [epoch: 5.75 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08409416775287079		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.08409416775287079 | validation: 0.05392702326329391]
	TIME [epoch: 5.75 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08228091757009948		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.08228091757009948 | validation: 0.06269587296500227]
	TIME [epoch: 5.75 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07912902284361428		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.07912902284361428 | validation: 0.06314964159972433]
	TIME [epoch: 5.78 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642937759699743		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.08642937759699743 | validation: 0.06344392882811929]
	TIME [epoch: 5.77 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08204933627079047		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.08204933627079047 | validation: 0.053996710170526895]
	TIME [epoch: 5.75 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08730447472018499		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.08730447472018499 | validation: 0.05360929336830325]
	TIME [epoch: 5.76 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08606541748531941		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.08606541748531941 | validation: 0.061094746452489565]
	TIME [epoch: 5.75 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08513646819995431		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.08513646819995431 | validation: 0.06257057692275045]
	TIME [epoch: 5.75 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08481212831021057		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.08481212831021057 | validation: 0.054884798693603035]
	TIME [epoch: 5.77 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08856974508424857		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.08856974508424857 | validation: 0.0641528372145594]
	TIME [epoch: 5.78 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08465730052369093		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.08465730052369093 | validation: 0.05931728041574113]
	TIME [epoch: 5.75 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08708414626533897		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.08708414626533897 | validation: 0.07218819011926211]
	TIME [epoch: 5.75 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08993547571691576		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.08993547571691576 | validation: 0.06372189551680137]
	TIME [epoch: 5.75 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09016449531465638		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.09016449531465638 | validation: 0.06556412598055869]
	TIME [epoch: 5.75 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09055601810635647		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.09055601810635647 | validation: 0.07162396565445482]
	TIME [epoch: 5.75 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09116514551480315		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.09116514551480315 | validation: 0.052949835946111606]
	TIME [epoch: 5.79 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08607605146701514		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.08607605146701514 | validation: 0.05794993343610482]
	TIME [epoch: 5.76 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09062658257670372		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.09062658257670372 | validation: 0.06972259077853472]
	TIME [epoch: 5.76 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0846469734605123		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.0846469734605123 | validation: 0.06713339714582865]
	TIME [epoch: 5.76 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0871334502705878		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.0871334502705878 | validation: 0.06380756223210422]
	TIME [epoch: 5.75 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09063144378739386		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.09063144378739386 | validation: 0.07841993625893129]
	TIME [epoch: 5.75 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09112420457754503		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.09112420457754503 | validation: 0.07367511381418057]
	TIME [epoch: 5.76 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09018006261132078		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.09018006261132078 | validation: 0.07049368729842809]
	TIME [epoch: 5.78 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0934281188266347		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.0934281188266347 | validation: 0.05553164994006998]
	TIME [epoch: 5.76 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0843581361422243		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.0843581361422243 | validation: 0.06762417012973995]
	TIME [epoch: 5.76 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08664507563754663		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.08664507563754663 | validation: 0.06746363039444467]
	TIME [epoch: 5.75 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08872684824231203		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.08872684824231203 | validation: 0.0639193688618412]
	TIME [epoch: 5.75 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08779198103265594		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.08779198103265594 | validation: 0.06836527458862243]
	TIME [epoch: 5.76 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096090886086706		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.096090886086706 | validation: 0.08070052670763746]
	TIME [epoch: 5.79 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09475253154378926		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.09475253154378926 | validation: 0.0844503241784027]
	TIME [epoch: 5.75 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09223613149639084		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.09223613149639084 | validation: 0.04554671489683295]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1188.pth
	Model improved!!!
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09598240254253568		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.09598240254253568 | validation: 0.07282315777108864]
	TIME [epoch: 5.75 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09546540393776028		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.09546540393776028 | validation: 0.0645944818181935]
	TIME [epoch: 5.75 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08452332236336245		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.08452332236336245 | validation: 0.056648982922342286]
	TIME [epoch: 5.75 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08393232710698835		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.08393232710698835 | validation: 0.05027076671640913]
	TIME [epoch: 5.78 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973345027364406		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.08973345027364406 | validation: 0.06465646808226846]
	TIME [epoch: 5.78 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09201021893206066		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.09201021893206066 | validation: 0.05923550687156662]
	TIME [epoch: 5.75 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09071278337908131		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.09071278337908131 | validation: 0.061993058944101516]
	TIME [epoch: 5.76 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07973209606477931		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.07973209606477931 | validation: 0.0632279715790579]
	TIME [epoch: 5.76 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0871057850503742		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.0871057850503742 | validation: 0.06003586031617722]
	TIME [epoch: 5.75 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08321888684084582		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.08321888684084582 | validation: 0.054469105137711485]
	TIME [epoch: 5.75 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111282496655399		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.08111282496655399 | validation: 0.06233273941735435]
	TIME [epoch: 5.79 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09137918566938144		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.09137918566938144 | validation: 0.055186282923939206]
	TIME [epoch: 5.75 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823518424381876		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.0823518424381876 | validation: 0.05494711950907835]
	TIME [epoch: 5.76 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08006603549398596		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.08006603549398596 | validation: 0.056694786495640324]
	TIME [epoch: 5.76 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872736001245847		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.07872736001245847 | validation: 0.051597462986126205]
	TIME [epoch: 5.75 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08397156576571141		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.08397156576571141 | validation: 0.06764613976956808]
	TIME [epoch: 5.75 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09239152098111789		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.09239152098111789 | validation: 0.05186788536933389]
	TIME [epoch: 5.78 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08588681608175085		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.08588681608175085 | validation: 0.06333394844576558]
	TIME [epoch: 5.77 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08038731241840677		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.08038731241840677 | validation: 0.06360902005981325]
	TIME [epoch: 5.75 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821818204329099		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.08821818204329099 | validation: 0.05248036774793558]
	TIME [epoch: 5.75 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08468502733724145		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.08468502733724145 | validation: 0.0657185994748145]
	TIME [epoch: 5.75 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08978544326001121		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.08978544326001121 | validation: 0.061835461829183175]
	TIME [epoch: 5.75 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08915640740680757		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.08915640740680757 | validation: 0.060773683982809516]
	TIME [epoch: 5.75 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0938253157998835		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.0938253157998835 | validation: 0.058088093204577716]
	TIME [epoch: 5.8 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323955349155085		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.08323955349155085 | validation: 0.06486660679492137]
	TIME [epoch: 5.75 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08421875583661326		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.08421875583661326 | validation: 0.06268488826821765]
	TIME [epoch: 5.76 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08742553608100591		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.08742553608100591 | validation: 0.0645700596580746]
	TIME [epoch: 5.75 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0850825608892836		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.0850825608892836 | validation: 0.05688344761719511]
	TIME [epoch: 5.75 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08916864828097708		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.08916864828097708 | validation: 0.07601420905118192]
	TIME [epoch: 5.75 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09801764712387506		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.09801764712387506 | validation: 0.059383772597460284]
	TIME [epoch: 5.78 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08737073242369163		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.08737073242369163 | validation: 0.06753686126121666]
	TIME [epoch: 5.77 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09519335614214289		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.09519335614214289 | validation: 0.06056097773165903]
	TIME [epoch: 5.76 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028677200082396		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.08028677200082396 | validation: 0.05651505768451582]
	TIME [epoch: 5.76 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08241286199066071		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.08241286199066071 | validation: 0.05491529786236849]
	TIME [epoch: 5.75 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08388716366260365		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.08388716366260365 | validation: 0.0537884176759097]
	TIME [epoch: 5.75 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08274303231998782		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.08274303231998782 | validation: 0.05701821117192494]
	TIME [epoch: 5.75 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08644771599019788		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.08644771599019788 | validation: 0.05885108624152418]
	TIME [epoch: 5.79 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08732589514729616		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.08732589514729616 | validation: 0.06208009792906452]
	TIME [epoch: 5.75 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0852790565816611		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.0852790565816611 | validation: 0.053406328686237056]
	TIME [epoch: 5.75 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08741605654665496		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.08741605654665496 | validation: 0.06952222102155982]
	TIME [epoch: 5.75 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09083071196400967		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.09083071196400967 | validation: 0.06081896615919208]
	TIME [epoch: 5.76 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08383158428253157		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.08383158428253157 | validation: 0.06236755640299174]
	TIME [epoch: 5.75 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08168042096748965		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.08168042096748965 | validation: 0.05934397022918818]
	TIME [epoch: 5.78 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08591489944791904		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.08591489944791904 | validation: 0.062274766344511095]
	TIME [epoch: 5.78 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08604786016772922		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.08604786016772922 | validation: 0.07649922191013407]
	TIME [epoch: 5.75 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09388733822191345		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.09388733822191345 | validation: 0.07174260240780982]
	TIME [epoch: 5.75 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0879309926611891		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.0879309926611891 | validation: 0.06855982801450139]
	TIME [epoch: 5.75 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08303136666180456		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.08303136666180456 | validation: 0.057532625512825064]
	TIME [epoch: 5.75 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824897466303924		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.0824897466303924 | validation: 0.05990975488170805]
	TIME [epoch: 5.75 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08812771429268901		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.08812771429268901 | validation: 0.06371198543045742]
	TIME [epoch: 5.79 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08992428655307728		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.08992428655307728 | validation: 0.05777137980275402]
	TIME [epoch: 5.75 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08379486442185483		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.08379486442185483 | validation: 0.05775449069369387]
	TIME [epoch: 5.75 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08516419719306116		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.08516419719306116 | validation: 0.06326348168876134]
	TIME [epoch: 5.75 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09269743422167022		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.09269743422167022 | validation: 0.0623040999148858]
	TIME [epoch: 5.75 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0794435710314038		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.0794435710314038 | validation: 0.0574430625768945]
	TIME [epoch: 5.75 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08354221521403354		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.08354221521403354 | validation: 0.057491542868536645]
	TIME [epoch: 5.79 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08518130676187945		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.08518130676187945 | validation: 0.05186839789505928]
	TIME [epoch: 5.75 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08197142737704811		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.08197142737704811 | validation: 0.06362843826501693]
	TIME [epoch: 5.75 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09028522225798649		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.09028522225798649 | validation: 0.06036882011877889]
	TIME [epoch: 5.75 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08379641151844568		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.08379641151844568 | validation: 0.050898649012989426]
	TIME [epoch: 5.75 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08039837972988567		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.08039837972988567 | validation: 0.06506367285656298]
	TIME [epoch: 5.75 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0925807094168782		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.0925807094168782 | validation: 0.06280881564003145]
	TIME [epoch: 5.76 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08812937034605593		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.08812937034605593 | validation: 0.05596486391107584]
	TIME [epoch: 5.78 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08417453864136827		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.08417453864136827 | validation: 0.059595234936185404]
	TIME [epoch: 5.75 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0904419416487415		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.0904419416487415 | validation: 0.06701414130802007]
	TIME [epoch: 5.75 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08602178854276427		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.08602178854276427 | validation: 0.06163826660145999]
	TIME [epoch: 5.75 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09171657522604743		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.09171657522604743 | validation: 0.08534730915425975]
	TIME [epoch: 5.75 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09292496004381536		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.09292496004381536 | validation: 0.05496026366179776]
	TIME [epoch: 5.75 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08666605739309169		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.08666605739309169 | validation: 0.05418593243642391]
	TIME [epoch: 5.79 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086285638524779		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.08086285638524779 | validation: 0.06080810050996447]
	TIME [epoch: 5.76 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07973361144843724		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.07973361144843724 | validation: 0.06478085604971526]
	TIME [epoch: 5.75 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09020412140637846		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.09020412140637846 | validation: 0.059472711364278064]
	TIME [epoch: 5.75 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385565004276042		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.08385565004276042 | validation: 0.055506424198994896]
	TIME [epoch: 5.75 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08835425851369273		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.08835425851369273 | validation: 0.06058153704019707]
	TIME [epoch: 5.75 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0854487522876222		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.0854487522876222 | validation: 0.05309543078415174]
	TIME [epoch: 5.76 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08233080487554381		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.08233080487554381 | validation: 0.05803164001051282]
	TIME [epoch: 5.78 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08174422840161419		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.08174422840161419 | validation: 0.055177550447969126]
	TIME [epoch: 5.75 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08433039659152085		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.08433039659152085 | validation: 0.054644549305977605]
	TIME [epoch: 5.75 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08726422397933473		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.08726422397933473 | validation: 0.07434832403278804]
	TIME [epoch: 5.75 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08749035342922426		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.08749035342922426 | validation: 0.05500537529402163]
	TIME [epoch: 5.75 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08610158126784308		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.08610158126784308 | validation: 0.061792424361203836]
	TIME [epoch: 5.75 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09111357896892569		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.09111357896892569 | validation: 0.06723185132717446]
	TIME [epoch: 5.79 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153554926241262		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.08153554926241262 | validation: 0.05316516409567015]
	TIME [epoch: 5.76 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08155881109157608		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.08155881109157608 | validation: 0.06647416715439664]
	TIME [epoch: 5.75 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08871378070262773		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.08871378070262773 | validation: 0.06095647237637802]
	TIME [epoch: 5.75 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823328752279783		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.0823328752279783 | validation: 0.05482093897512897]
	TIME [epoch: 5.75 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880167868455958		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.0880167868455958 | validation: 0.05891199634287391]
	TIME [epoch: 5.75 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08200058415248253		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.08200058415248253 | validation: 0.06090573953111342]
	TIME [epoch: 5.76 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08406284438619259		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.08406284438619259 | validation: 0.047174086292252275]
	TIME [epoch: 5.78 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08083286717000433		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.08083286717000433 | validation: 0.06613102401309943]
	TIME [epoch: 5.76 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08430079105437441		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.08430079105437441 | validation: 0.05868208873454878]
	TIME [epoch: 5.75 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07911124606051		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.07911124606051 | validation: 0.04826428246698619]
	TIME [epoch: 5.75 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08032774097625464		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.08032774097625464 | validation: 0.05835439750685472]
	TIME [epoch: 5.75 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08384310523478257		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.08384310523478257 | validation: 0.059263806993264084]
	TIME [epoch: 5.76 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08236316266029381		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.08236316266029381 | validation: 0.05309771763620095]
	TIME [epoch: 5.79 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08161525908570838		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.08161525908570838 | validation: 0.05522619257812474]
	TIME [epoch: 5.75 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08330085528898219		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.08330085528898219 | validation: 0.06268533631432323]
	TIME [epoch: 5.75 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08051982078350978		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.08051982078350978 | validation: 0.0645205321475184]
	TIME [epoch: 5.75 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09114837320569467		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.09114837320569467 | validation: 0.05728412840853299]
	TIME [epoch: 5.75 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08643997446780287		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.08643997446780287 | validation: 0.06224733802797649]
	TIME [epoch: 5.75 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08386133773884197		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.08386133773884197 | validation: 0.055519176768916365]
	TIME [epoch: 5.78 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08129856633833021		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.08129856633833021 | validation: 0.05777309533408378]
	TIME [epoch: 5.77 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08253955234463081		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.08253955234463081 | validation: 0.05834932107936402]
	TIME [epoch: 5.76 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0846551720934762		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.0846551720934762 | validation: 0.05657532866707589]
	TIME [epoch: 5.75 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08239786277364616		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.08239786277364616 | validation: 0.05717611544308451]
	TIME [epoch: 5.75 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08762780358132465		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.08762780358132465 | validation: 0.05917447238117307]
	TIME [epoch: 5.75 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054467020811368		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.08054467020811368 | validation: 0.057866199484165215]
	TIME [epoch: 5.75 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0845796920575244		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.0845796920575244 | validation: 0.045373884097361046]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1296.pth
	Model improved!!!
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08283424425636787		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.08283424425636787 | validation: 0.06248784833004844]
	TIME [epoch: 5.75 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08355562235822127		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.08355562235822127 | validation: 0.06670756926086012]
	TIME [epoch: 5.75 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09721673776123368		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.09721673776123368 | validation: 0.07309449309945329]
	TIME [epoch: 5.75 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09209974061090166		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.09209974061090166 | validation: 0.048527807607228135]
	TIME [epoch: 5.75 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104438411366927		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.08104438411366927 | validation: 0.06893273325019823]
	TIME [epoch: 5.75 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08664931101728282		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.08664931101728282 | validation: 0.05579937242789872]
	TIME [epoch: 5.77 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08510950880654067		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.08510950880654067 | validation: 0.06933892287868705]
	TIME [epoch: 5.76 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09168668663521037		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.09168668663521037 | validation: 0.07159798697521078]
	TIME [epoch: 5.75 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971527091739759		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.08971527091739759 | validation: 0.05563513908977799]
	TIME [epoch: 5.74 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154967173106385		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.08154967173106385 | validation: 0.07344329034179457]
	TIME [epoch: 5.75 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09128749951313027		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.09128749951313027 | validation: 0.06365264271491089]
	TIME [epoch: 5.75 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401795431730005		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.08401795431730005 | validation: 0.05641117460948038]
	TIME [epoch: 5.75 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08383597044679908		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.08383597044679908 | validation: 0.0626765823635776]
	TIME [epoch: 5.79 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0891025604445635		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.0891025604445635 | validation: 0.06504480063041014]
	TIME [epoch: 5.75 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08285818734673808		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.08285818734673808 | validation: 0.06554744469517143]
	TIME [epoch: 5.75 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08408066005741408		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.08408066005741408 | validation: 0.05518346569479199]
	TIME [epoch: 5.74 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08235616308538082		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.08235616308538082 | validation: 0.0534253329166826]
	TIME [epoch: 5.75 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08904513188726344		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.08904513188726344 | validation: 0.05959321892437159]
	TIME [epoch: 5.74 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08525054183490509		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.08525054183490509 | validation: 0.06429964049699433]
	TIME [epoch: 5.77 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08500867744907657		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.08500867744907657 | validation: 0.0551014833604116]
	TIME [epoch: 5.76 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973229538282836		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.08973229538282836 | validation: 0.0786284686560415]
	TIME [epoch: 5.75 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09809784411679054		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.09809784411679054 | validation: 0.08063192423014308]
	TIME [epoch: 5.75 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481916624965234		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.09481916624965234 | validation: 0.05881212556890601]
	TIME [epoch: 5.75 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08297829711585213		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.08297829711585213 | validation: 0.06008007963944307]
	TIME [epoch: 5.75 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08577723498785327		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.08577723498785327 | validation: 0.060887104934255094]
	TIME [epoch: 5.75 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08256105959373965		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.08256105959373965 | validation: 0.061853103215257124]
	TIME [epoch: 5.78 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08590847481456157		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.08590847481456157 | validation: 0.04587386536714952]
	TIME [epoch: 5.75 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0858268075509832		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.0858268075509832 | validation: 0.06253376052798514]
	TIME [epoch: 5.74 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09189708099929764		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.09189708099929764 | validation: 0.05513534098963566]
	TIME [epoch: 5.75 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08253230254972228		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.08253230254972228 | validation: 0.057323655726627315]
	TIME [epoch: 5.74 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08342593048268818		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.08342593048268818 | validation: 0.05615400487952202]
	TIME [epoch: 5.75 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08213443008659385		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.08213443008659385 | validation: 0.05757092984942629]
	TIME [epoch: 5.79 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08609913833491449		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.08609913833491449 | validation: 0.05931651093602221]
	TIME [epoch: 5.75 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0830604641644151		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.0830604641644151 | validation: 0.059154801587606956]
	TIME [epoch: 5.74 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837394981785749		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.0837394981785749 | validation: 0.046588546387426294]
	TIME [epoch: 5.74 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083898657263272		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.083898657263272 | validation: 0.055503303903475416]
	TIME [epoch: 5.74 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385754119686308		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.08385754119686308 | validation: 0.05847895427298778]
	TIME [epoch: 5.75 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08348434906543709		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.08348434906543709 | validation: 0.050228115516026545]
	TIME [epoch: 5.76 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08488674434601917		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.08488674434601917 | validation: 0.0650979886004202]
	TIME [epoch: 5.78 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08172880787986354		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.08172880787986354 | validation: 0.058116793750678325]
	TIME [epoch: 5.75 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0843634379285228		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.0843634379285228 | validation: 0.05745527046283876]
	TIME [epoch: 5.75 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08751921788442675		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.08751921788442675 | validation: 0.060668674014168485]
	TIME [epoch: 5.74 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08325872143588364		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.08325872143588364 | validation: 0.05956033410075958]
	TIME [epoch: 5.74 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08396417765718557		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.08396417765718557 | validation: 0.05714790161089933]
	TIME [epoch: 5.74 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08500665206677742		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.08500665206677742 | validation: 0.06268518176319199]
	TIME [epoch: 5.79 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08223593509935226		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.08223593509935226 | validation: 0.06286828691906518]
	TIME [epoch: 5.75 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08507161271856019		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.08507161271856019 | validation: 0.06144063590497067]
	TIME [epoch: 5.74 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08420973459149642		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.08420973459149642 | validation: 0.059806576543934044]
	TIME [epoch: 5.75 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08089350299699606		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.08089350299699606 | validation: 0.06177961523104438]
	TIME [epoch: 5.75 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08061511610247238		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.08061511610247238 | validation: 0.059359912995866126]
	TIME [epoch: 5.74 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137002845250595		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.08137002845250595 | validation: 0.05308858322541177]
	TIME [epoch: 5.75 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08233293423846574		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.08233293423846574 | validation: 0.06363090605116077]
	TIME [epoch: 5.78 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08573292093306335		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.08573292093306335 | validation: 0.05836071819022281]
	TIME [epoch: 5.75 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08431603478474717		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.08431603478474717 | validation: 0.06252163269235464]
	TIME [epoch: 5.74 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0855868017766357		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.0855868017766357 | validation: 0.06006063598699472]
	TIME [epoch: 5.75 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07799159172626419		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.07799159172626419 | validation: 0.06421320659858022]
	TIME [epoch: 5.75 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837882932212434		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.0837882932212434 | validation: 0.052489415135601424]
	TIME [epoch: 5.75 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08612152039670196		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.08612152039670196 | validation: 0.05679389083507882]
	TIME [epoch: 5.79 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957661068102667		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.07957661068102667 | validation: 0.054115188582628884]
	TIME [epoch: 5.75 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791932774172074		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.0791932774172074 | validation: 0.06389463805886333]
	TIME [epoch: 5.75 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127794042509182		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.08127794042509182 | validation: 0.055404101450328785]
	TIME [epoch: 5.74 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0851537264186325		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.0851537264186325 | validation: 0.0668045658118534]
	TIME [epoch: 5.74 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346519958428239		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.08346519958428239 | validation: 0.051071187051998236]
	TIME [epoch: 5.74 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08170441464089466		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.08170441464089466 | validation: 0.053269164062046806]
	TIME [epoch: 5.75 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07913912284900514		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.07913912284900514 | validation: 0.05249681447947549]
	TIME [epoch: 5.78 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08003845604749742		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.08003845604749742 | validation: 0.05281522293568805]
	TIME [epoch: 5.75 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07911698486997698		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.07911698486997698 | validation: 0.060230652831238844]
	TIME [epoch: 5.75 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0852245923062248		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.0852245923062248 | validation: 0.05032780079562971]
	TIME [epoch: 5.75 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08126198133406394		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.08126198133406394 | validation: 0.057826279679814865]
	TIME [epoch: 5.75 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196244525313252		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.08196244525313252 | validation: 0.04919478198723409]
	TIME [epoch: 5.75 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08557680422662114		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.08557680422662114 | validation: 0.06562142803698677]
	TIME [epoch: 5.79 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.085815937973897		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.085815937973897 | validation: 0.060737053691446906]
	TIME [epoch: 5.75 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104391863531636		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.08104391863531636 | validation: 0.06272500464321962]
	TIME [epoch: 5.74 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08237790055650417		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.08237790055650417 | validation: 0.06075265759943042]
	TIME [epoch: 5.74 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08546240566031588		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.08546240566031588 | validation: 0.061442219315961]
	TIME [epoch: 5.75 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08593921726651119		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.08593921726651119 | validation: 0.06658409445656029]
	TIME [epoch: 5.75 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08694990758587927		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.08694990758587927 | validation: 0.05737911618986956]
	TIME [epoch: 5.76 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08052535897089937		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.08052535897089937 | validation: 0.05711825562798466]
	TIME [epoch: 5.78 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08115539850492018		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.08115539850492018 | validation: 0.053063073321596925]
	TIME [epoch: 5.75 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157269505261017		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.08157269505261017 | validation: 0.06687260026817532]
	TIME [epoch: 5.75 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802506957643859		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.0802506957643859 | validation: 0.06064528517271795]
	TIME [epoch: 5.74 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08038626183571351		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.08038626183571351 | validation: 0.05503297775025054]
	TIME [epoch: 5.74 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718567014190558		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.07718567014190558 | validation: 0.056361865665024755]
	TIME [epoch: 5.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07786152166455987		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.07786152166455987 | validation: 0.050092973295984236]
	TIME [epoch: 5.79 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08310995241079833		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.08310995241079833 | validation: 0.06492307185242244]
	TIME [epoch: 5.75 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08969705847442959		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.08969705847442959 | validation: 0.05603285794062808]
	TIME [epoch: 5.74 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08543941425235325		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.08543941425235325 | validation: 0.04820286501246363]
	TIME [epoch: 5.75 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07933367812074801		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.07933367812074801 | validation: 0.057648771527313056]
	TIME [epoch: 5.75 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09011449129319767		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.09011449129319767 | validation: 0.0632006675908794]
	TIME [epoch: 5.74 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08656956548065554		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.08656956548065554 | validation: 0.052283583750738424]
	TIME [epoch: 5.77 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08017174102092696		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.08017174102092696 | validation: 0.054042774326964624]
	TIME [epoch: 5.76 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086506152060934		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.08086506152060934 | validation: 0.05571127302989838]
	TIME [epoch: 5.75 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08042666393816769		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.08042666393816769 | validation: 0.05679904720014523]
	TIME [epoch: 5.75 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0777721838759546		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.0777721838759546 | validation: 0.052892413154484785]
	TIME [epoch: 5.75 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07670316096042708		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.07670316096042708 | validation: 0.060801089128677197]
	TIME [epoch: 5.75 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313734147583593		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.08313734147583593 | validation: 0.05442208716281006]
	TIME [epoch: 5.75 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368616703500116		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.08368616703500116 | validation: 0.05943105830948477]
	TIME [epoch: 5.79 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07880265107784312		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.07880265107784312 | validation: 0.058407651001792314]
	TIME [epoch: 5.75 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08283153457726122		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.08283153457726122 | validation: 0.05254855733787245]
	TIME [epoch: 5.75 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08754772664331341		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.08754772664331341 | validation: 0.06261688322820583]
	TIME [epoch: 5.74 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832515350036103		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.0832515350036103 | validation: 0.06240711431288661]
	TIME [epoch: 5.74 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07676002994741797		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.07676002994741797 | validation: 0.05383667827382141]
	TIME [epoch: 5.74 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0810787682010172		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.0810787682010172 | validation: 0.05108552058968343]
	TIME [epoch: 5.77 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08135376669968465		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.08135376669968465 | validation: 0.05148071890577196]
	TIME [epoch: 5.77 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07905116824253254		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.07905116824253254 | validation: 0.05588513133145782]
	TIME [epoch: 5.75 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0828012667160588		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.0828012667160588 | validation: 0.06455452357372131]
	TIME [epoch: 5.75 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08744269340738223		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.08744269340738223 | validation: 0.05658140045844871]
	TIME [epoch: 5.75 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08178193035855523		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.08178193035855523 | validation: 0.06653668533230206]
	TIME [epoch: 5.75 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517385522057921		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.08517385522057921 | validation: 0.05852333768728362]
	TIME [epoch: 5.75 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08228047725145086		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.08228047725145086 | validation: 0.061061505088121776]
	TIME [epoch: 5.79 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08815037321216723		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.08815037321216723 | validation: 0.05972309372761046]
	TIME [epoch: 5.75 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07977434551256003		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.07977434551256003 | validation: 0.053741124717635154]
	TIME [epoch: 5.74 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08008413751141508		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.08008413751141508 | validation: 0.058010297574578776]
	TIME [epoch: 5.74 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08428209678793105		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.08428209678793105 | validation: 0.05957377315404819]
	TIME [epoch: 5.75 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08231861622994233		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.08231861622994233 | validation: 0.05502248047901153]
	TIME [epoch: 5.75 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08272637607959175		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.08272637607959175 | validation: 0.05942920292508541]
	TIME [epoch: 5.78 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08715294538345528		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.08715294538345528 | validation: 0.0600598986508213]
	TIME [epoch: 5.76 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08591015578637998		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.08591015578637998 | validation: 0.05415253039907667]
	TIME [epoch: 5.75 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08418214126119856		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.08418214126119856 | validation: 0.05603452344164934]
	TIME [epoch: 5.75 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0827910883303043		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.0827910883303043 | validation: 0.050399379089167744]
	TIME [epoch: 5.74 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07742928668053484		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.07742928668053484 | validation: 0.04852510664126248]
	TIME [epoch: 5.74 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08159344431964688		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.08159344431964688 | validation: 0.060415937014955325]
	TIME [epoch: 5.75 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07769338414738307		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.07769338414738307 | validation: 0.05489592211714912]
	TIME [epoch: 5.79 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08156883319286434		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.08156883319286434 | validation: 0.05924878712725178]
	TIME [epoch: 5.75 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08381651594867372		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.08381651594867372 | validation: 0.06186089068301099]
	TIME [epoch: 5.75 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08382507187997233		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.08382507187997233 | validation: 0.06096355640145548]
	TIME [epoch: 5.75 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08626861762883466		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.08626861762883466 | validation: 0.05763123465818097]
	TIME [epoch: 5.74 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08247303406687934		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.08247303406687934 | validation: 0.04406968339852842]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1424.pth
	Model improved!!!
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08163637620906783		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.08163637620906783 | validation: 0.05698582263011939]
	TIME [epoch: 5.79 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08048554358613075		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.08048554358613075 | validation: 0.052246814919012334]
	TIME [epoch: 5.75 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07721222713771844		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.07721222713771844 | validation: 0.059510300034194795]
	TIME [epoch: 5.74 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401317196939571		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.08401317196939571 | validation: 0.05849243598801984]
	TIME [epoch: 5.74 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08182191504268002		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.08182191504268002 | validation: 0.05663959843087006]
	TIME [epoch: 5.74 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08132904937044486		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.08132904937044486 | validation: 0.05406545976899667]
	TIME [epoch: 5.75 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08299840494824709		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.08299840494824709 | validation: 0.05607634596059796]
	TIME [epoch: 5.75 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08342631071310003		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.08342631071310003 | validation: 0.05044548067309397]
	TIME [epoch: 5.78 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07841330970573591		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.07841330970573591 | validation: 0.05524415910614188]
	TIME [epoch: 5.75 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08194272760251675		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.08194272760251675 | validation: 0.05338880677835594]
	TIME [epoch: 5.75 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08191684836887066		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.08191684836887066 | validation: 0.05524589427130427]
	TIME [epoch: 5.74 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08092809463507997		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.08092809463507997 | validation: 0.05217040713936468]
	TIME [epoch: 5.74 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08221406290591889		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.08221406290591889 | validation: 0.05977806786869294]
	TIME [epoch: 5.74 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07883065155564961		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.07883065155564961 | validation: 0.055672729177810035]
	TIME [epoch: 5.78 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07944779061932102		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.07944779061932102 | validation: 0.055350483335053546]
	TIME [epoch: 5.75 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07946681759358509		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.07946681759358509 | validation: 0.0549117042448597]
	TIME [epoch: 5.75 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802004877172039		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.0802004877172039 | validation: 0.06428243929861266]
	TIME [epoch: 5.74 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318113996943749		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.08318113996943749 | validation: 0.05176382719298248]
	TIME [epoch: 5.75 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07968969138986076		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.07968969138986076 | validation: 0.04914610558626741]
	TIME [epoch: 5.75 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08303684374554346		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.08303684374554346 | validation: 0.05212046564775813]
	TIME [epoch: 5.76 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08100206275455277		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.08100206275455277 | validation: 0.05563435066759543]
	TIME [epoch: 5.78 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08093347289647863		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.08093347289647863 | validation: 0.060136960555882996]
	TIME [epoch: 5.75 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07874017392145972		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.07874017392145972 | validation: 0.06130120283162607]
	TIME [epoch: 5.75 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08013951877748947		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.08013951877748947 | validation: 0.05228701263033498]
	TIME [epoch: 5.75 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08105713010064523		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.08105713010064523 | validation: 0.06495047076555062]
	TIME [epoch: 5.75 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08130952555144139		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.08130952555144139 | validation: 0.06242520282949615]
	TIME [epoch: 5.75 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08209661842052013		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.08209661842052013 | validation: 0.05144181572757679]
	TIME [epoch: 5.79 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07660135828509948		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.07660135828509948 | validation: 0.05369568689722327]
	TIME [epoch: 5.75 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08159002184222582		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.08159002184222582 | validation: 0.05292588367518004]
	TIME [epoch: 5.75 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0881337043899365		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.0881337043899365 | validation: 0.05590753251667623]
	TIME [epoch: 5.75 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08627183206574497		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.08627183206574497 | validation: 0.054588508179904925]
	TIME [epoch: 5.74 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08202328811407116		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.08202328811407116 | validation: 0.053091274537546765]
	TIME [epoch: 5.74 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08397335906502604		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.08397335906502604 | validation: 0.04901471916150753]
	TIME [epoch: 5.77 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07870069584796441		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.07870069584796441 | validation: 0.055747681155244776]
	TIME [epoch: 5.76 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08144379793385521		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.08144379793385521 | validation: 0.053799507817161175]
	TIME [epoch: 5.75 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08423411478661301		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.08423411478661301 | validation: 0.0516409414579044]
	TIME [epoch: 5.75 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07949281328882614		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.07949281328882614 | validation: 0.05276175994787277]
	TIME [epoch: 5.74 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08566045324449345		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.08566045324449345 | validation: 0.048434796672048204]
	TIME [epoch: 5.75 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08249428052284885		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.08249428052284885 | validation: 0.05437037030136069]
	TIME [epoch: 5.75 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08089129843814279		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.08089129843814279 | validation: 0.05361194870174902]
	TIME [epoch: 5.79 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0790327765028776		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.0790327765028776 | validation: 0.050415318790571866]
	TIME [epoch: 5.75 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063602861032186		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.08063602861032186 | validation: 0.05280675247743231]
	TIME [epoch: 5.74 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127719250862278		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.08127719250862278 | validation: 0.055981810911599615]
	TIME [epoch: 5.75 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08268532249457802		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.08268532249457802 | validation: 0.05192957836845112]
	TIME [epoch: 5.74 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08359565884531897		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.08359565884531897 | validation: 0.05742210248037535]
	TIME [epoch: 5.74 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08198286190383894		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.08198286190383894 | validation: 0.051238491368777374]
	TIME [epoch: 5.77 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07929865400881175		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.07929865400881175 | validation: 0.04868150481084452]
	TIME [epoch: 5.76 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08162141070705874		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.08162141070705874 | validation: 0.06054920578600532]
	TIME [epoch: 5.75 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08175911880787642		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.08175911880787642 | validation: 0.057344352095916325]
	TIME [epoch: 5.74 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08388511268027439		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.08388511268027439 | validation: 0.05408066717046285]
	TIME [epoch: 5.75 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08242095675474664		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.08242095675474664 | validation: 0.05933811699689933]
	TIME [epoch: 5.74 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07992303755817057		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.07992303755817057 | validation: 0.04841559345528096]
	TIME [epoch: 5.75 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08236747025129176		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.08236747025129176 | validation: 0.056499134523623463]
	TIME [epoch: 5.79 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08223414652225947		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.08223414652225947 | validation: 0.054848086396351727]
	TIME [epoch: 5.75 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07905196484891477		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.07905196484891477 | validation: 0.05872226525897263]
	TIME [epoch: 5.75 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791107523887244		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.0791107523887244 | validation: 0.05269985492694023]
	TIME [epoch: 5.74 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07818193632617193		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.07818193632617193 | validation: 0.05370017175554363]
	TIME [epoch: 5.74 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188492167113365		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.08188492167113365 | validation: 0.05838023976690183]
	TIME [epoch: 5.74 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07790192256552114		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.07790192256552114 | validation: 0.06236362626103622]
	TIME [epoch: 5.77 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086571204669124		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.08086571204669124 | validation: 0.047831080429242515]
	TIME [epoch: 5.77 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07824646393348958		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.07824646393348958 | validation: 0.052355632594679735]
	TIME [epoch: 5.75 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0778531011953879		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.0778531011953879 | validation: 0.053801601261536734]
	TIME [epoch: 5.75 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07938000621943275		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.07938000621943275 | validation: 0.04678433618926402]
	TIME [epoch: 5.75 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08029776548038976		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.08029776548038976 | validation: 0.05342671309368823]
	TIME [epoch: 5.75 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0788119313080486		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.0788119313080486 | validation: 0.05464892005273856]
	TIME [epoch: 5.75 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313760357522912		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.08313760357522912 | validation: 0.04920417053037436]
	TIME [epoch: 5.79 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07635496838603514		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.07635496838603514 | validation: 0.05589168009551812]
	TIME [epoch: 5.75 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0780160307616859		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.0780160307616859 | validation: 0.059956373660007445]
	TIME [epoch: 5.75 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08310575899174684		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.08310575899174684 | validation: 0.05537199113877935]
	TIME [epoch: 5.75 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08062983304744945		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.08062983304744945 | validation: 0.05931473846733006]
	TIME [epoch: 5.75 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07952913657144664		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.07952913657144664 | validation: 0.06458271681941663]
	TIME [epoch: 5.75 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08431239399481495		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.08431239399481495 | validation: 0.05648295700794745]
	TIME [epoch: 5.78 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0806113336084713		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.0806113336084713 | validation: 0.05673457631846052]
	TIME [epoch: 5.77 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08444902101435303		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.08444902101435303 | validation: 0.05052897711125515]
	TIME [epoch: 5.75 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0798653129722269		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.0798653129722269 | validation: 0.05609035970855137]
	TIME [epoch: 5.76 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08209229159695978		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.08209229159695978 | validation: 0.0633914267281135]
	TIME [epoch: 5.75 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07906667247281975		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.07906667247281975 | validation: 0.05783138738990291]
	TIME [epoch: 5.75 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08277318883312672		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.08277318883312672 | validation: 0.059002353614189186]
	TIME [epoch: 5.75 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08035291406778831		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.08035291406778831 | validation: 0.0588758865954844]
	TIME [epoch: 5.78 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07720240091885391		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.07720240091885391 | validation: 0.05839336994401238]
	TIME [epoch: 5.76 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834159906176795		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.07834159906176795 | validation: 0.04991408069371884]
	TIME [epoch: 5.75 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07885928466741073		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.07885928466741073 | validation: 0.054726223298972004]
	TIME [epoch: 5.75 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0811031597297548		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.0811031597297548 | validation: 0.05606940317267256]
	TIME [epoch: 5.75 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08241199460842627		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.08241199460842627 | validation: 0.04115760842846063]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1508.pth
	Model improved!!!
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07745545395873503		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.07745545395873503 | validation: 0.057316865077552855]
	TIME [epoch: 5.79 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0754607551868292		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.0754607551868292 | validation: 0.04679996877746575]
	TIME [epoch: 5.75 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07774789404948654		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.07774789404948654 | validation: 0.054229877757640946]
	TIME [epoch: 5.74 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07561935893586094		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.07561935893586094 | validation: 0.04620933094930308]
	TIME [epoch: 5.74 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07798725566914898		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.07798725566914898 | validation: 0.052669441628886454]
	TIME [epoch: 5.74 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950016218345478		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.07950016218345478 | validation: 0.05317283766111713]
	TIME [epoch: 5.74 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08511611270570224		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.08511611270570224 | validation: 0.06500829197108704]
	TIME [epoch: 5.76 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07814286817792104		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.07814286817792104 | validation: 0.04984651218672591]
	TIME [epoch: 5.78 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08373003973376031		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.08373003973376031 | validation: 0.053912400551018556]
	TIME [epoch: 5.74 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07931494389230179		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.07931494389230179 | validation: 0.05798333683586968]
	TIME [epoch: 5.74 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07480871330223554		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.07480871330223554 | validation: 0.04957865481635004]
	TIME [epoch: 5.74 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08209109621253652		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.08209109621253652 | validation: 0.05721961736694681]
	TIME [epoch: 5.75 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07953332098801744		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.07953332098801744 | validation: 0.0597020524159632]
	TIME [epoch: 5.75 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188439217293458		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.08188439217293458 | validation: 0.05347007703315645]
	TIME [epoch: 5.79 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08549810435762331		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.08549810435762331 | validation: 0.04932256152104076]
	TIME [epoch: 5.75 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08152538958296038		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.08152538958296038 | validation: 0.053647285500508]
	TIME [epoch: 5.74 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243333102358774		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.08243333102358774 | validation: 0.04990309398496177]
	TIME [epoch: 5.74 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0811352416918969		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.0811352416918969 | validation: 0.05891042112899605]
	TIME [epoch: 5.74 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083983940071283		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.083983940071283 | validation: 0.05892980712126244]
	TIME [epoch: 5.74 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08324967178758708		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.08324967178758708 | validation: 0.05698772939347885]
	TIME [epoch: 5.77 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08068522811345027		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.08068522811345027 | validation: 0.058295242872038154]
	TIME [epoch: 5.76 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07964812568778161		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.07964812568778161 | validation: 0.055504365617192256]
	TIME [epoch: 5.75 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08174958502258654		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.08174958502258654 | validation: 0.05304373986036846]
	TIME [epoch: 5.74 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346490538739175		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.08346490538739175 | validation: 0.05172601390140929]
	TIME [epoch: 5.74 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820167272480218		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.0820167272480218 | validation: 0.05569012726217004]
	TIME [epoch: 5.75 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0805719348555524		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.0805719348555524 | validation: 0.05994480336227406]
	TIME [epoch: 5.74 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08305728468057505		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.08305728468057505 | validation: 0.05326002566032604]
	TIME [epoch: 5.79 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08007403064448493		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.08007403064448493 | validation: 0.05678704370151895]
	TIME [epoch: 5.75 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08582856535013937		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.08582856535013937 | validation: 0.05113252816254248]
	TIME [epoch: 5.74 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07594169922350022		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.07594169922350022 | validation: 0.05453091545955651]
	TIME [epoch: 5.74 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08236222400028492		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.08236222400028492 | validation: 0.05520344756702123]
	TIME [epoch: 5.74 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08230100089421091		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.08230100089421091 | validation: 0.05003577319542524]
	TIME [epoch: 5.74 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08457692541316263		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.08457692541316263 | validation: 0.055432270884009434]
	TIME [epoch: 5.77 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128547093756815		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.08128547093756815 | validation: 0.051002327838504266]
	TIME [epoch: 5.77 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08049101915080203		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.08049101915080203 | validation: 0.05328281726695756]
	TIME [epoch: 5.75 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143717798591019		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.08143717798591019 | validation: 0.0567460467187486]
	TIME [epoch: 5.74 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07924003613444054		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.07924003613444054 | validation: 0.05175571016890714]
	TIME [epoch: 5.74 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07891245279765935		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.07891245279765935 | validation: 0.04420171216290889]
	TIME [epoch: 5.74 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08009479555996468		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.08009479555996468 | validation: 0.04727268130913826]
	TIME [epoch: 5.75 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08319310816221451		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.08319310816221451 | validation: 0.057416312425709964]
	TIME [epoch: 5.79 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08017946545037824		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.08017946545037824 | validation: 0.059778889866289174]
	TIME [epoch: 5.75 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07924890074197558		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.07924890074197558 | validation: 0.05086066743543622]
	TIME [epoch: 5.74 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08025870068423618		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.08025870068423618 | validation: 0.05299230452969335]
	TIME [epoch: 5.74 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07688715326767573		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.07688715326767573 | validation: 0.04546799145372279]
	TIME [epoch: 5.74 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07753311554115595		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.07753311554115595 | validation: 0.05077663177685812]
	TIME [epoch: 5.74 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802804836991123		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.0802804836991123 | validation: 0.06173843349805745]
	TIME [epoch: 5.77 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484145392203643		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.08484145392203643 | validation: 0.06076866295011206]
	TIME [epoch: 5.76 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.080724584081795		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.080724584081795 | validation: 0.049369738859191145]
	TIME [epoch: 5.75 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08055032819924639		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.08055032819924639 | validation: 0.051726095950067594]
	TIME [epoch: 5.75 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08596470590806428		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.08596470590806428 | validation: 0.058067796341440214]
	TIME [epoch: 5.74 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08087697256229996		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.08087697256229996 | validation: 0.06031381093105532]
	TIME [epoch: 5.75 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07716814281285644		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.07716814281285644 | validation: 0.048190210321872484]
	TIME [epoch: 5.75 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07621451992146558		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.07621451992146558 | validation: 0.055069524861168714]
	TIME [epoch: 5.79 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128879148756336		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.08128879148756336 | validation: 0.05959236222272355]
	TIME [epoch: 5.76 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823185834009566		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.0823185834009566 | validation: 0.0566570310745027]
	TIME [epoch: 5.74 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785223464673685		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.0785223464673685 | validation: 0.04798259085583068]
	TIME [epoch: 5.75 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08120678152021757		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.08120678152021757 | validation: 0.055335339252758756]
	TIME [epoch: 5.74 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07958301707647952		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.07958301707647952 | validation: 0.05484737134736104]
	TIME [epoch: 5.75 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08247772486702264		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.08247772486702264 | validation: 0.04970068094896298]
	TIME [epoch: 5.77 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07630911171507791		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.07630911171507791 | validation: 0.05292031030491199]
	TIME [epoch: 5.76 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08201625383365091		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.08201625383365091 | validation: 0.04996377212272206]
	TIME [epoch: 5.75 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0780362456709112		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.0780362456709112 | validation: 0.05220156342548256]
	TIME [epoch: 5.75 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07847348730249341		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.07847348730249341 | validation: 0.055904333456987094]
	TIME [epoch: 5.75 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07721809382102701		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.07721809382102701 | validation: 0.0509010735382838]
	TIME [epoch: 5.75 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07923544319724357		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.07923544319724357 | validation: 0.059829038764056576]
	TIME [epoch: 5.75 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08056724426609117		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.08056724426609117 | validation: 0.05929261331552386]
	TIME [epoch: 5.78 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08550920363508008		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.08550920363508008 | validation: 0.06633282336155365]
	TIME [epoch: 5.75 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083753518181727		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.083753518181727 | validation: 0.059100645277369336]
	TIME [epoch: 5.75 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08531505133764002		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.08531505133764002 | validation: 0.058914709169828224]
	TIME [epoch: 5.75 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08302137355960151		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.08302137355960151 | validation: 0.05174819517126611]
	TIME [epoch: 5.75 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08009677927594937		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.08009677927594937 | validation: 0.053598586011669946]
	TIME [epoch: 5.75 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773149729254885		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.0773149729254885 | validation: 0.05653853701995207]
	TIME [epoch: 5.79 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08049879877510838		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.08049879877510838 | validation: 0.06047402188527366]
	TIME [epoch: 5.75 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08194155617113216		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.08194155617113216 | validation: 0.054137227546407714]
	TIME [epoch: 5.74 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948159696059234		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.07948159696059234 | validation: 0.049399404591124546]
	TIME [epoch: 5.74 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803370817811957		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.0803370817811957 | validation: 0.06742244871004018]
	TIME [epoch: 5.74 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08327938675676819		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.08327938675676819 | validation: 0.05483145719067617]
	TIME [epoch: 5.75 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08354348992425152		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.08354348992425152 | validation: 0.05747653408059325]
	TIME [epoch: 5.76 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08069946333803107		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.08069946333803107 | validation: 0.06346389778754398]
	TIME [epoch: 5.78 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08195445168257877		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.08195445168257877 | validation: 0.04906364141682817]
	TIME [epoch: 5.75 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789253115693939		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.07789253115693939 | validation: 0.0572958996741755]
	TIME [epoch: 5.74 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08214145353930263		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.08214145353930263 | validation: 0.04880044473215502]
	TIME [epoch: 5.74 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07907637856863393		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.07907637856863393 | validation: 0.05479574475002779]
	TIME [epoch: 5.74 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08049677883139367		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.08049677883139367 | validation: 0.054770373767793805]
	TIME [epoch: 5.75 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0858264926988998		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.0858264926988998 | validation: 0.052304573733287486]
	TIME [epoch: 5.78 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08210121453321426		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.08210121453321426 | validation: 0.0614189355484989]
	TIME [epoch: 5.75 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07768934450844689		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.07768934450844689 | validation: 0.04874377760440774]
	TIME [epoch: 5.75 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08122120660779575		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.08122120660779575 | validation: 0.04831808787128521]
	TIME [epoch: 5.74 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08178615605680505		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.08178615605680505 | validation: 0.05732708661184741]
	TIME [epoch: 5.74 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08292343830408688		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.08292343830408688 | validation: 0.0548136932951091]
	TIME [epoch: 5.74 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07949187575723173		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.07949187575723173 | validation: 0.05767945781703451]
	TIME [epoch: 5.76 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07967914803227745		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.07967914803227745 | validation: 0.06011663251474845]
	TIME [epoch: 5.78 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08116026750007743		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.08116026750007743 | validation: 0.055262537305173734]
	TIME [epoch: 5.75 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07943253378138493		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.07943253378138493 | validation: 0.06408701878931253]
	TIME [epoch: 5.74 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07869755300264555		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.07869755300264555 | validation: 0.058031398507942644]
	TIME [epoch: 5.74 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08163656903763478		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.08163656903763478 | validation: 0.05183732374405045]
	TIME [epoch: 5.74 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07745851110580071		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.07745851110580071 | validation: 0.059907599000873724]
	TIME [epoch: 5.75 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08004383862011724		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.08004383862011724 | validation: 0.0537956812886067]
	TIME [epoch: 5.78 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08288248605669747		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.08288248605669747 | validation: 0.05642368690988786]
	TIME [epoch: 5.75 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809927218726217		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.0809927218726217 | validation: 0.055432368426879694]
	TIME [epoch: 5.74 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07972205532712966		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.07972205532712966 | validation: 0.04851120858082245]
	TIME [epoch: 5.74 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08000607375154455		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.08000607375154455 | validation: 0.05418579807942942]
	TIME [epoch: 5.74 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318392685752511		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.08318392685752511 | validation: 0.04737232818269993]
	TIME [epoch: 5.74 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07972234502646319		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.07972234502646319 | validation: 0.044102921377844426]
	TIME [epoch: 5.75 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0781891620099128		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.0781891620099128 | validation: 0.051522902126945595]
	TIME [epoch: 5.78 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07451632518391063		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.07451632518391063 | validation: 0.05665671528645134]
	TIME [epoch: 5.75 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07691513477178377		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.07691513477178377 | validation: 0.05465217066819422]
	TIME [epoch: 5.75 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0787810878576837		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.0787810878576837 | validation: 0.05066387670153399]
	TIME [epoch: 5.75 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07489378580544485		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.07489378580544485 | validation: 0.05639145420924484]
	TIME [epoch: 5.74 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07779825205670451		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.07779825205670451 | validation: 0.04965861660765466]
	TIME [epoch: 5.74 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07890516169065023		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.07890516169065023 | validation: 0.05488727759255677]
	TIME [epoch: 5.79 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07753878049098159		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.07753878049098159 | validation: 0.05423969248408538]
	TIME [epoch: 5.75 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08488133606353968		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.08488133606353968 | validation: 0.05057331783533345]
	TIME [epoch: 5.75 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07906758023468206		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.07906758023468206 | validation: 0.0536216236880796]
	TIME [epoch: 5.74 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834528072076091		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.07834528072076091 | validation: 0.05154254737271751]
	TIME [epoch: 5.74 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07973036169109626		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.07973036169109626 | validation: 0.04862788093752045]
	TIME [epoch: 5.74 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755253688896643		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.0755253688896643 | validation: 0.051859519666429134]
	TIME [epoch: 5.77 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07741326190485417		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.07741326190485417 | validation: 0.05625978199099965]
	TIME [epoch: 5.76 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07729858407768471		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.07729858407768471 | validation: 0.0650585368406782]
	TIME [epoch: 5.75 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07940441506419915		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.07940441506419915 | validation: 0.05610749520317307]
	TIME [epoch: 5.74 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07915686565259462		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.07915686565259462 | validation: 0.056111111289445015]
	TIME [epoch: 5.74 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08202116853133193		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.08202116853133193 | validation: 0.0520807299315336]
	TIME [epoch: 5.75 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824428964932261		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.0824428964932261 | validation: 0.052661072570705326]
	TIME [epoch: 5.74 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690131110227408		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.07690131110227408 | validation: 0.05760793736605514]
	TIME [epoch: 5.78 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119696176190591		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.08119696176190591 | validation: 0.05328349796557566]
	TIME [epoch: 5.75 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08098112895207432		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.08098112895207432 | validation: 0.053121624964066944]
	TIME [epoch: 5.74 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07994985773341932		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.07994985773341932 | validation: 0.04800901241672946]
	TIME [epoch: 5.74 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08253052747137997		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.08253052747137997 | validation: 0.05509320772388948]
	TIME [epoch: 5.75 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119032687019721		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.08119032687019721 | validation: 0.05540440066286694]
	TIME [epoch: 5.75 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08197333707995735		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.08197333707995735 | validation: 0.05004375447812096]
	TIME [epoch: 5.77 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533455622143019		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.08533455622143019 | validation: 0.058600045129513736]
	TIME [epoch: 5.76 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08374698133451229		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.08374698133451229 | validation: 0.06877123854619178]
	TIME [epoch: 5.75 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08457097200211129		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.08457097200211129 | validation: 0.048763703415562805]
	TIME [epoch: 5.74 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08345623488796189		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.08345623488796189 | validation: 0.05355345750685105]
	TIME [epoch: 5.74 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07779030027023905		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.07779030027023905 | validation: 0.0574393275872967]
	TIME [epoch: 5.74 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07820640700952641		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.07820640700952641 | validation: 0.05192433553458962]
	TIME [epoch: 5.74 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08115314628249763		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.08115314628249763 | validation: 0.04723289729908791]
	TIME [epoch: 5.78 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08053472713436148		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.08053472713436148 | validation: 0.05451391011361958]
	TIME [epoch: 5.75 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0810259595303989		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.0810259595303989 | validation: 0.05758373554801995]
	TIME [epoch: 5.74 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07695079567744269		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.07695079567744269 | validation: 0.05146423782717825]
	TIME [epoch: 5.74 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918023774287603		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.07918023774287603 | validation: 0.05697479806623432]
	TIME [epoch: 5.75 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07986011459424319		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.07986011459424319 | validation: 0.04958412324515818]
	TIME [epoch: 5.74 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07459982806746901		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.07459982806746901 | validation: 0.053002488145079456]
	TIME [epoch: 5.77 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07889078366924213		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.07889078366924213 | validation: 0.058806371035040446]
	TIME [epoch: 5.76 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08444236019627177		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.08444236019627177 | validation: 0.0529635227388606]
	TIME [epoch: 5.74 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08045424063076143		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.08045424063076143 | validation: 0.05130361571895277]
	TIME [epoch: 5.74 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08144553108651632		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.08144553108651632 | validation: 0.05625042213324452]
	TIME [epoch: 5.74 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08152819515980261		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.08152819515980261 | validation: 0.046461807886998115]
	TIME [epoch: 5.75 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07870336243435971		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.07870336243435971 | validation: 0.04906981283299834]
	TIME [epoch: 5.75 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07661746402429662		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.07661746402429662 | validation: 0.05461749509439326]
	TIME [epoch: 5.79 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0790178930568384		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.0790178930568384 | validation: 0.06020433684990964]
	TIME [epoch: 5.75 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07701683913932772		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.07701683913932772 | validation: 0.05073859492816537]
	TIME [epoch: 5.74 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07919247099351007		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.07919247099351007 | validation: 0.05743494286698844]
	TIME [epoch: 5.74 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07900970378674636		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.07900970378674636 | validation: 0.058281348128715216]
	TIME [epoch: 5.74 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918966371193549		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.07918966371193549 | validation: 0.049012305513484976]
	TIME [epoch: 5.75 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07879856376709748		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.07879856376709748 | validation: 0.04795182930011558]
	TIME [epoch: 5.77 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07963702451551244		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.07963702451551244 | validation: 0.0558806872399947]
	TIME [epoch: 5.76 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07969037269883172		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.07969037269883172 | validation: 0.04977100127725555]
	TIME [epoch: 5.75 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07951781271453409		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.07951781271453409 | validation: 0.05890017311411372]
	TIME [epoch: 5.74 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08235938679859037		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.08235938679859037 | validation: 0.0489082424744708]
	TIME [epoch: 5.74 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07942326701091729		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.07942326701091729 | validation: 0.043823680272033115]
	TIME [epoch: 5.74 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.081012739272364		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.081012739272364 | validation: 0.052710555577379345]
	TIME [epoch: 5.75 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07717910189548549		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.07717910189548549 | validation: 0.04894145751002994]
	TIME [epoch: 5.78 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07976939687541021		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.07976939687541021 | validation: 0.044953845917827875]
	TIME [epoch: 5.75 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07662224386859894		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.07662224386859894 | validation: 0.05520314564854939]
	TIME [epoch: 5.74 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08155281210994783		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.08155281210994783 | validation: 0.05108542014010501]
	TIME [epoch: 5.74 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08178840551475704		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.08178840551475704 | validation: 0.0570562722252933]
	TIME [epoch: 5.74 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08056083292568658		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.08056083292568658 | validation: 0.055033684132424016]
	TIME [epoch: 5.74 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791772163622918		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.0791772163622918 | validation: 0.0570994605204453]
	TIME [epoch: 5.79 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792739209755321		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.07792739209755321 | validation: 0.05338754837184289]
	TIME [epoch: 5.75 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0777721390165649		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.0777721390165649 | validation: 0.04391847478849723]
	TIME [epoch: 5.74 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07915257220884754		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.07915257220884754 | validation: 0.05724023651267534]
	TIME [epoch: 5.74 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08030332707316101		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.08030332707316101 | validation: 0.05581236144213687]
	TIME [epoch: 5.74 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07777876233357675		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.07777876233357675 | validation: 0.04691107449856741]
	TIME [epoch: 5.74 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07691064813977448		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.07691064813977448 | validation: 0.0495303820344469]
	TIME [epoch: 5.75 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922804383273369		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.07922804383273369 | validation: 0.046706386840561914]
	TIME [epoch: 5.77 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07896832916446121		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.07896832916446121 | validation: 0.05696981308742815]
	TIME [epoch: 5.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730256334307642		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.07730256334307642 | validation: 0.05328420509982928]
	TIME [epoch: 5.74 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08047408401131331		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.08047408401131331 | validation: 0.0527520426124948]
	TIME [epoch: 5.74 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07825257545716893		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.07825257545716893 | validation: 0.05985722491848889]
	TIME [epoch: 5.75 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813541302614549		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.0813541302614549 | validation: 0.05324268147842387]
	TIME [epoch: 5.74 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08042175727591558		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.08042175727591558 | validation: 0.053671030123738105]
	TIME [epoch: 5.79 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07600069082937107		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.07600069082937107 | validation: 0.05598012230486599]
	TIME [epoch: 5.75 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989321022352172		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.07989321022352172 | validation: 0.053523183874700654]
	TIME [epoch: 5.74 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196265314622626		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.08196265314622626 | validation: 0.05130833569426045]
	TIME [epoch: 5.74 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.080517953458817		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.080517953458817 | validation: 0.05484333406551887]
	TIME [epoch: 5.74 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789934947356821		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.0789934947356821 | validation: 0.05496268008715458]
	TIME [epoch: 5.74 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0795344156705943		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.0795344156705943 | validation: 0.06082816335351092]
	TIME [epoch: 5.76 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07651236791628631		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.07651236791628631 | validation: 0.058517817061043156]
	TIME [epoch: 5.78 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07839995185451752		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.07839995185451752 | validation: 0.05087741458973356]
	TIME [epoch: 5.75 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872626275095042		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.07872626275095042 | validation: 0.04747234423300104]
	TIME [epoch: 5.74 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07600951408567289		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.07600951408567289 | validation: 0.057472532869904995]
	TIME [epoch: 5.74 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07770147811844505		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.07770147811844505 | validation: 0.048663739123101186]
	TIME [epoch: 5.75 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07674165327839452		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.07674165327839452 | validation: 0.04867987965131526]
	TIME [epoch: 5.74 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07823481545481106		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.07823481545481106 | validation: 0.05217824414486724]
	TIME [epoch: 5.78 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07558811287857442		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.07558811287857442 | validation: 0.05305708512431064]
	TIME [epoch: 5.75 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07602933863833883		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.07602933863833883 | validation: 0.0522005597094778]
	TIME [epoch: 5.74 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07921672715317575		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.07921672715317575 | validation: 0.05941669044559401]
	TIME [epoch: 5.75 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08109087439464523		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.08109087439464523 | validation: 0.05140821164403439]
	TIME [epoch: 5.75 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07888165071896899		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.07888165071896899 | validation: 0.05172521625052921]
	TIME [epoch: 5.74 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0795920924194218		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.0795920924194218 | validation: 0.05207070837838016]
	TIME [epoch: 5.76 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0798172580410588		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.0798172580410588 | validation: 0.05518888315546775]
	TIME [epoch: 5.78 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08058966642707596		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.08058966642707596 | validation: 0.05756730043506443]
	TIME [epoch: 5.75 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07944190118117324		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.07944190118117324 | validation: 0.05313003777571844]
	TIME [epoch: 5.74 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07707074796592213		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.07707074796592213 | validation: 0.05871949618090032]
	TIME [epoch: 5.74 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07791968351435188		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.07791968351435188 | validation: 0.05431143242811933]
	TIME [epoch: 5.74 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07698117578820454		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.07698117578820454 | validation: 0.05505929090907101]
	TIME [epoch: 5.75 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07833027985238797		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.07833027985238797 | validation: 0.05790072564696771]
	TIME [epoch: 5.79 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0818702129532706		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.0818702129532706 | validation: 0.04608463279197059]
	TIME [epoch: 5.75 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0787815132814927		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.0787815132814927 | validation: 0.054983369723823595]
	TIME [epoch: 5.74 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08166326871661708		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.08166326871661708 | validation: 0.04763843086976021]
	TIME [epoch: 5.74 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793738150696377		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.0793738150696377 | validation: 0.05562975311016128]
	TIME [epoch: 5.74 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07832075576139895		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.07832075576139895 | validation: 0.060811091803237245]
	TIME [epoch: 5.74 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07813796993350296		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.07813796993350296 | validation: 0.04341410995485211]
	TIME [epoch: 5.77 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757468497186284		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.0757468497186284 | validation: 0.05128833152228081]
	TIME [epoch: 5.76 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823818107960343		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.0823818107960343 | validation: 0.05137489231550417]
	TIME [epoch: 5.75 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07958800813571293		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.07958800813571293 | validation: 0.05856949815946408]
	TIME [epoch: 5.74 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07775070076996596		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.07775070076996596 | validation: 0.04979618350669189]
	TIME [epoch: 5.74 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08031805317044145		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.08031805317044145 | validation: 0.05153100854456946]
	TIME [epoch: 5.74 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08081200437648868		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.08081200437648868 | validation: 0.05082829470574127]
	TIME [epoch: 5.74 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07871890883084474		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.07871890883084474 | validation: 0.05876500970629335]
	TIME [epoch: 5.79 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07844000486042128		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.07844000486042128 | validation: 0.06018322063588636]
	TIME [epoch: 5.75 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07688744753311907		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.07688744753311907 | validation: 0.056440107300896776]
	TIME [epoch: 5.75 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07884699217804081		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.07884699217804081 | validation: 0.05244388507110931]
	TIME [epoch: 5.74 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07804558395277851		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.07804558395277851 | validation: 0.05100514013334694]
	TIME [epoch: 5.74 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07914814375329277		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.07914814375329277 | validation: 0.05628854264808739]
	TIME [epoch: 5.74 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07966235142472294		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.07966235142472294 | validation: 0.056582306583426334]
	TIME [epoch: 5.77 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07713265219860788		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.07713265219860788 | validation: 0.05691925715748124]
	TIME [epoch: 5.76 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08037473329263771		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.08037473329263771 | validation: 0.04668315791365139]
	TIME [epoch: 5.75 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08124390839600736		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.08124390839600736 | validation: 0.05382272981650453]
	TIME [epoch: 5.75 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774245646980511		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.0774245646980511 | validation: 0.053166392341356394]
	TIME [epoch: 5.75 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07993746432368319		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.07993746432368319 | validation: 0.05652065901848555]
	TIME [epoch: 5.75 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07848378435011663		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.07848378435011663 | validation: 0.0533128413844473]
	TIME [epoch: 5.75 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07987470614795822		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.07987470614795822 | validation: 0.05420181815794659]
	TIME [epoch: 5.78 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08001809754627992		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.08001809754627992 | validation: 0.05494783384225452]
	TIME [epoch: 5.74 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07917421748288997		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.07917421748288997 | validation: 0.05588966530671674]
	TIME [epoch: 5.74 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07709999067270232		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.07709999067270232 | validation: 0.05661855196471934]
	TIME [epoch: 5.74 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07841602553746888		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.07841602553746888 | validation: 0.0620049701862756]
	TIME [epoch: 5.75 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08106815059115621		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.08106815059115621 | validation: 0.050363579004697547]
	TIME [epoch: 5.74 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07703562479880977		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.07703562479880977 | validation: 0.05245177449022373]
	TIME [epoch: 5.77 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07667544309276064		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.07667544309276064 | validation: 0.05504627606874566]
	TIME [epoch: 5.76 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07735493507683933		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.07735493507683933 | validation: 0.05654151806223729]
	TIME [epoch: 5.75 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07817249680541223		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.07817249680541223 | validation: 0.054385887944627814]
	TIME [epoch: 5.74 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07860322299543368		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.07860322299543368 | validation: 0.05016365098814106]
	TIME [epoch: 5.74 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08252386748274151		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.08252386748274151 | validation: 0.055960172811209845]
	TIME [epoch: 5.74 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07914067024919844		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.07914067024919844 | validation: 0.05657665956135961]
	TIME [epoch: 5.74 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997769508734323		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.07997769508734323 | validation: 0.05891034267142066]
	TIME [epoch: 5.78 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08004714015965585		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.08004714015965585 | validation: 0.06038644124868582]
	TIME [epoch: 5.75 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07686713274637678		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.07686713274637678 | validation: 0.055799621882008286]
	TIME [epoch: 5.75 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07691845172495469		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.07691845172495469 | validation: 0.0422717026674593]
	TIME [epoch: 5.74 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08010429553145083		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.08010429553145083 | validation: 0.05028419596875718]
	TIME [epoch: 5.75 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776876275387855		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.0776876275387855 | validation: 0.04927807733744887]
	TIME [epoch: 5.75 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07798689953588386		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.07798689953588386 | validation: 0.05288136656080182]
	TIME [epoch: 5.78 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08324427440239399		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.08324427440239399 | validation: 0.0573899218880891]
	TIME [epoch: 5.75 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07976377340810899		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.07976377340810899 | validation: 0.05690667668394406]
	TIME [epoch: 5.74 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07405486508901415		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.07405486508901415 | validation: 0.05427549994668965]
	TIME [epoch: 5.74 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022427661391561		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.08022427661391561 | validation: 0.05567594997010883]
	TIME [epoch: 5.74 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08183421282379164		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.08183421282379164 | validation: 0.05026870816516137]
	TIME [epoch: 5.74 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07907584760004831		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.07907584760004831 | validation: 0.04715189713237759]
	TIME [epoch: 5.76 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07785020403291207		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.07785020403291207 | validation: 0.0524847332588854]
	TIME [epoch: 5.77 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08023334750999192		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.08023334750999192 | validation: 0.05130898467674934]
	TIME [epoch: 5.75 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07509707036848706		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.07509707036848706 | validation: 0.04978373981683089]
	TIME [epoch: 5.75 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08090139971478276		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.08090139971478276 | validation: 0.0550044604006855]
	TIME [epoch: 5.74 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834801290369309		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.07834801290369309 | validation: 0.04997250671512147]
	TIME [epoch: 5.74 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0744599734571135		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.0744599734571135 | validation: 0.044229069446631276]
	TIME [epoch: 5.74 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803213794053472		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.0803213794053472 | validation: 0.05260737683839274]
	TIME [epoch: 5.78 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0796188087552655		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.0796188087552655 | validation: 0.04844978970592475]
	TIME [epoch: 5.75 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07988379862457942		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.07988379862457942 | validation: 0.053276449994020265]
	TIME [epoch: 5.75 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07483961855121288		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.07483961855121288 | validation: 0.05138358596298916]
	TIME [epoch: 5.75 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08033547720101218		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.08033547720101218 | validation: 0.04796879303624837]
	TIME [epoch: 5.75 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08064028847195817		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.08064028847195817 | validation: 0.04636184262435689]
	TIME [epoch: 5.75 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07701000095100835		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.07701000095100835 | validation: 0.05630891380119524]
	TIME [epoch: 5.76 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07712521494830302		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.07712521494830302 | validation: 0.05194903042504207]
	TIME [epoch: 5.78 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737790213353857		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.0737790213353857 | validation: 0.05308192263934414]
	TIME [epoch: 5.74 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0801530944678874		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.0801530944678874 | validation: 0.062041742287134535]
	TIME [epoch: 5.74 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07826460792747324		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.07826460792747324 | validation: 0.0512072026503151]
	TIME [epoch: 5.74 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740370318465391		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.07740370318465391 | validation: 0.05750462175719971]
	TIME [epoch: 5.74 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948398218287575		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.07948398218287575 | validation: 0.05195646051842232]
	TIME [epoch: 5.74 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07764800869949602		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.07764800869949602 | validation: 0.04957018580801426]
	TIME [epoch: 5.78 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08145829327241516		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.08145829327241516 | validation: 0.055163945584354564]
	TIME [epoch: 5.75 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07493986455309447		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.07493986455309447 | validation: 0.048657154624845024]
	TIME [epoch: 5.74 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07746412286345751		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.07746412286345751 | validation: 0.055400769322423445]
	TIME [epoch: 5.74 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08050622047999938		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.08050622047999938 | validation: 0.058418334325672026]
	TIME [epoch: 5.74 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07661187011115987		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.07661187011115987 | validation: 0.0530892824485127]
	TIME [epoch: 5.74 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773848076629305		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.0773848076629305 | validation: 0.049344424723569896]
	TIME [epoch: 5.76 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07640965451011376		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.07640965451011376 | validation: 0.053677370793856406]
	TIME [epoch: 5.78 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770303088504081		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.0770303088504081 | validation: 0.052894824101501405]
	TIME [epoch: 5.75 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07753474970015937		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.07753474970015937 | validation: 0.05620942557290471]
	TIME [epoch: 5.75 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07721878013457523		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.07721878013457523 | validation: 0.05542861925733286]
	TIME [epoch: 5.75 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07866575588555558		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.07866575588555558 | validation: 0.055456942233751104]
	TIME [epoch: 5.75 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768064474877244		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.0768064474877244 | validation: 0.06195101960188819]
	TIME [epoch: 5.74 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07556514099180298		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.07556514099180298 | validation: 0.053236861526046494]
	TIME [epoch: 5.78 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764418238653656		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.0764418238653656 | validation: 0.050405564038721304]
	TIME [epoch: 5.75 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08055427398572516		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.08055427398572516 | validation: 0.04631271568821319]
	TIME [epoch: 5.74 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07970284983667264		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.07970284983667264 | validation: 0.05934016939127288]
	TIME [epoch: 5.75 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07871464066238545		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.07871464066238545 | validation: 0.056216682747306734]
	TIME [epoch: 5.74 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07793655967376299		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.07793655967376299 | validation: 0.05478407383697859]
	TIME [epoch: 5.75 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07650257318613259		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.07650257318613259 | validation: 0.05075277763006941]
	TIME [epoch: 5.77 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07840528317211179		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.07840528317211179 | validation: 0.05056692165000259]
	TIME [epoch: 5.76 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143428553613187		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.08143428553613187 | validation: 0.057264477785496766]
	TIME [epoch: 5.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0807890499245636		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0807890499245636 | validation: 0.054740146940289565]
	TIME [epoch: 5.74 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07369148324345955		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.07369148324345955 | validation: 0.045679782627055056]
	TIME [epoch: 5.74 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07699994505062177		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.07699994505062177 | validation: 0.05553527903691758]
	TIME [epoch: 5.75 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811079472506197		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.07811079472506197 | validation: 0.04382411852977452]
	TIME [epoch: 5.75 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07784748246153242		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.07784748246153242 | validation: 0.04830771087412744]
	TIME [epoch: 5.78 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054200840512665		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.08054200840512665 | validation: 0.05365743153193827]
	TIME [epoch: 5.75 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0812288623665662		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.0812288623665662 | validation: 0.049884367682417975]
	TIME [epoch: 5.75 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922549891243892		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.07922549891243892 | validation: 0.050905644088926144]
	TIME [epoch: 5.74 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765061461988207		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.0765061461988207 | validation: 0.052126044631662205]
	TIME [epoch: 5.74 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07892577245573822		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.07892577245573822 | validation: 0.06105052167479108]
	TIME [epoch: 5.74 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07908692304652669		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.07908692304652669 | validation: 0.04957438012552738]
	TIME [epoch: 5.77 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08330930767739689		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.08330930767739689 | validation: 0.04792201141102456]
	TIME [epoch: 5.76 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154227417119375		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.08154227417119375 | validation: 0.05787229879103687]
	TIME [epoch: 5.75 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07841419765238816		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.07841419765238816 | validation: 0.05192908596502216]
	TIME [epoch: 5.75 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07758390296618341		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.07758390296618341 | validation: 0.05197631622960502]
	TIME [epoch: 5.74 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07954415454087856		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.07954415454087856 | validation: 0.05004004325447883]
	TIME [epoch: 5.74 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07692054043922775		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.07692054043922775 | validation: 0.0567432888491476]
	TIME [epoch: 5.74 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07878622820064772		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.07878622820064772 | validation: 0.05212748442954891]
	TIME [epoch: 5.79 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07712642791552946		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.07712642791552946 | validation: 0.05177478786589314]
	TIME [epoch: 5.75 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07751544387041315		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.07751544387041315 | validation: 0.049154892939471506]
	TIME [epoch: 5.74 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07937340514358596		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.07937340514358596 | validation: 0.05150426499300214]
	TIME [epoch: 5.75 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07622985857092957		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.07622985857092957 | validation: 0.054411069791690796]
	TIME [epoch: 5.74 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776178843018987		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.0776178843018987 | validation: 0.05789277560123074]
	TIME [epoch: 5.74 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07476733074455395		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.07476733074455395 | validation: 0.050309959743271994]
	TIME [epoch: 5.77 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07604906246371465		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.07604906246371465 | validation: 0.05194919570645669]
	TIME [epoch: 5.76 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07870520426370373		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.07870520426370373 | validation: 0.051413886827691935]
	TIME [epoch: 5.74 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08096738394394762		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.08096738394394762 | validation: 0.048948500012667505]
	TIME [epoch: 5.75 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08179205003780343		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.08179205003780343 | validation: 0.05713782494859952]
	TIME [epoch: 5.75 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0828272863214562		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.0828272863214562 | validation: 0.051850550266694814]
	TIME [epoch: 5.75 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07719100795760293		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.07719100795760293 | validation: 0.046908833365860304]
	TIME [epoch: 5.75 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07739583231501615		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.07739583231501615 | validation: 0.05431128281686732]
	TIME [epoch: 5.78 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07896666417644148		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.07896666417644148 | validation: 0.05804061224649249]
	TIME [epoch: 5.75 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782035183625655		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.0782035183625655 | validation: 0.04819289792294976]
	TIME [epoch: 5.74 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0792600159621054		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.0792600159621054 | validation: 0.053520117894465036]
	TIME [epoch: 5.74 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779650233995712		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.0779650233995712 | validation: 0.04975520806022346]
	TIME [epoch: 5.74 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07550623579259252		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.07550623579259252 | validation: 0.05383780687919603]
	TIME [epoch: 5.74 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07747972487856424		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.07747972487856424 | validation: 0.05071920520403133]
	TIME [epoch: 5.78 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07750555539069696		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.07750555539069696 | validation: 0.05539706906657916]
	TIME [epoch: 5.75 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0769540750808732		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.0769540750808732 | validation: 0.04980024818613398]
	TIME [epoch: 5.75 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07880873172431378		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.07880873172431378 | validation: 0.05362703125564404]
	TIME [epoch: 5.74 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07784124492674967		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.07784124492674967 | validation: 0.05450182785563816]
	TIME [epoch: 5.74 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07359723914666585		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.07359723914666585 | validation: 0.05372600981741726]
	TIME [epoch: 5.75 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07758670125731601		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.07758670125731601 | validation: 0.0500595245731391]
	TIME [epoch: 5.75 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07854414330585088		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.07854414330585088 | validation: 0.04619217386295795]
	TIME [epoch: 5.77 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157999597497531		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.08157999597497531 | validation: 0.05324942263740194]
	TIME [epoch: 5.75 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07804910151372424		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.07804910151372424 | validation: 0.05110227123330681]
	TIME [epoch: 5.74 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0819721083720775		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.0819721083720775 | validation: 0.06003351700633504]
	TIME [epoch: 5.75 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07902626271452916		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.07902626271452916 | validation: 0.053324588951050134]
	TIME [epoch: 5.74 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07937912700662077		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.07937912700662077 | validation: 0.054751970131932996]
	TIME [epoch: 5.75 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07929503047192184		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.07929503047192184 | validation: 0.04743696813537454]
	TIME [epoch: 5.78 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07799777035668551		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.07799777035668551 | validation: 0.04406233285136224]
	TIME [epoch: 5.75 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07480198785383174		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.07480198785383174 | validation: 0.05234067611632627]
	TIME [epoch: 5.74 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07881974201133402		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.07881974201133402 | validation: 0.04865832745220191]
	TIME [epoch: 5.74 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07583351462671362		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.07583351462671362 | validation: 0.059391109940133156]
	TIME [epoch: 5.74 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07855683144370093		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.07855683144370093 | validation: 0.0450366103706516]
	TIME [epoch: 5.75 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07687861108617285		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.07687861108617285 | validation: 0.04253034250638647]
	TIME [epoch: 5.76 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07694129742304197		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.07694129742304197 | validation: 0.056385535579973445]
	TIME [epoch: 5.78 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07555557850874395		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.07555557850874395 | validation: 0.05237652241143665]
	TIME [epoch: 5.75 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07906251077255079		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.07906251077255079 | validation: 0.053427420402086895]
	TIME [epoch: 5.75 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802557034350224		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.0802557034350224 | validation: 0.04620004180572911]
	TIME [epoch: 5.74 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07892477093893469		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.07892477093893469 | validation: 0.05550871021298361]
	TIME [epoch: 5.74 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07776405944533518		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.07776405944533518 | validation: 0.05529381231855861]
	TIME [epoch: 5.74 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07627587614610266		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.07627587614610266 | validation: 0.05518252313129185]
	TIME [epoch: 5.78 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07808404611472503		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.07808404611472503 | validation: 0.057383267204355964]
	TIME [epoch: 5.75 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07882021515737551		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.07882021515737551 | validation: 0.04986765505291366]
	TIME [epoch: 5.75 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07801508353333488		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.07801508353333488 | validation: 0.05900393278788878]
	TIME [epoch: 5.75 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07984398565259412		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.07984398565259412 | validation: 0.05831103927646951]
	TIME [epoch: 5.75 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07951842068586093		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.07951842068586093 | validation: 0.052241169231255484]
	TIME [epoch: 5.75 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07925019270739803		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.07925019270739803 | validation: 0.045423100996089955]
	TIME [epoch: 5.77 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07603195171213024		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.07603195171213024 | validation: 0.054674272619886624]
	TIME [epoch: 5.77 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07798412285479257		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.07798412285479257 | validation: 0.05754870231135006]
	TIME [epoch: 5.74 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07553625388580223		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.07553625388580223 | validation: 0.052059145916074724]
	TIME [epoch: 5.74 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793610661019376		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.0793610661019376 | validation: 0.06277911389878088]
	TIME [epoch: 5.74 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07676280170521083		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.07676280170521083 | validation: 0.047132834970341125]
	TIME [epoch: 5.74 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07947266941397105		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.07947266941397105 | validation: 0.05331615222198792]
	TIME [epoch: 5.75 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07733114272515534		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.07733114272515534 | validation: 0.05294270356922201]
	TIME [epoch: 5.79 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07614862718483253		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.07614862718483253 | validation: 0.05031585570930218]
	TIME [epoch: 5.75 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802818007029404		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.07802818007029404 | validation: 0.047316967396324225]
	TIME [epoch: 5.75 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0780192736509344		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.0780192736509344 | validation: 0.05470961120472396]
	TIME [epoch: 5.74 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07637956998082261		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.07637956998082261 | validation: 0.06095140016192653]
	TIME [epoch: 5.74 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022216067459363		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.08022216067459363 | validation: 0.053316586005697976]
	TIME [epoch: 5.74 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07595428330265955		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.07595428330265955 | validation: 0.05218864990232902]
	TIME [epoch: 5.77 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07823188444182921		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.07823188444182921 | validation: 0.04530351846959304]
	TIME [epoch: 5.76 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07979738999224681		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.07979738999224681 | validation: 0.052241979070944855]
	TIME [epoch: 5.75 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771661475943709		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.0771661475943709 | validation: 0.05837207122411755]
	TIME [epoch: 5.75 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07505545274242131		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.07505545274242131 | validation: 0.0439273912288439]
	TIME [epoch: 5.74 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0787839954517012		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.0787839954517012 | validation: 0.06013576161887924]
	TIME [epoch: 5.75 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07695345218033665		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.07695345218033665 | validation: 0.05665244499486574]
	TIME [epoch: 5.75 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07513693472407346		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.07513693472407346 | validation: 0.0519493633793385]
	TIME [epoch: 5.78 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07841431890844601		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.07841431890844601 | validation: 0.05574818185209585]
	TIME [epoch: 5.75 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07839252621856876		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.07839252621856876 | validation: 0.0485220019415792]
	TIME [epoch: 5.74 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08184524989578994		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.08184524989578994 | validation: 0.05284986614131881]
	TIME [epoch: 5.74 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07302934541161848		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.07302934541161848 | validation: 0.05887849679158461]
	TIME [epoch: 5.74 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07696847191948301		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.07696847191948301 | validation: 0.05806862704086358]
	TIME [epoch: 5.74 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07865574648204635		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.07865574648204635 | validation: 0.04324755264579125]
	TIME [epoch: 5.78 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07787601925205533		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.07787601925205533 | validation: 0.06187321090354456]
	TIME [epoch: 5.76 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078049184999759		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.078049184999759 | validation: 0.04944704992294668]
	TIME [epoch: 5.75 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07843998189456255		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.07843998189456255 | validation: 0.05752043251920939]
	TIME [epoch: 5.75 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07949537612015868		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.07949537612015868 | validation: 0.04534681939652923]
	TIME [epoch: 5.74 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07746957646776177		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.07746957646776177 | validation: 0.05173033999334576]
	TIME [epoch: 5.74 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07570132581861258		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.07570132581861258 | validation: 0.05407997485048417]
	TIME [epoch: 5.74 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07964012707562376		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.07964012707562376 | validation: 0.0533642054529143]
	TIME [epoch: 5.78 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755792711689467		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.0755792711689467 | validation: 0.05379019905486214]
	TIME [epoch: 5.75 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08034336906928119		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.08034336906928119 | validation: 0.05887618395501921]
	TIME [epoch: 5.75 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07577520806316074		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.07577520806316074 | validation: 0.054395192557888654]
	TIME [epoch: 5.75 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07484880804460509		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.07484880804460509 | validation: 0.04733215544479473]
	TIME [epoch: 5.75 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08081236317199371		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.08081236317199371 | validation: 0.056462137575985845]
	TIME [epoch: 5.74 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08106042248083753		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.08106042248083753 | validation: 0.05976687265455228]
	TIME [epoch: 5.78 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08072215087074783		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.08072215087074783 | validation: 0.05860921292201947]
	TIME [epoch: 5.75 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08116298970394428		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.08116298970394428 | validation: 0.05970757545867758]
	TIME [epoch: 5.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07831217691378073		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.07831217691378073 | validation: 0.05637527520416791]
	TIME [epoch: 5.74 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07873796071073214		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.07873796071073214 | validation: 0.05120231799160469]
	TIME [epoch: 5.75 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07960747055221164		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.07960747055221164 | validation: 0.054690370613978176]
	TIME [epoch: 5.74 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08275890161212154		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.08275890161212154 | validation: 0.04884705425326576]
	TIME [epoch: 5.76 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802609916160204		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.07802609916160204 | validation: 0.05183130797066939]
	TIME [epoch: 5.78 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07983966818263899		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.07983966818263899 | validation: 0.04674365712871063]
	TIME [epoch: 5.74 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0777689108262855		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.0777689108262855 | validation: 0.05831002166657268]
	TIME [epoch: 5.74 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07955153033328652		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.07955153033328652 | validation: 0.05027101807593967]
	TIME [epoch: 5.74 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07896124937500598		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.07896124937500598 | validation: 0.04542334374892304]
	TIME [epoch: 5.75 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08177919193409962		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.08177919193409962 | validation: 0.055906353695949464]
	TIME [epoch: 5.75 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07917203298375777		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.07917203298375777 | validation: 0.052459959389430794]
	TIME [epoch: 5.78 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07704526174452953		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.07704526174452953 | validation: 0.04988365763833361]
	TIME [epoch: 5.75 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08061759826039229		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.08061759826039229 | validation: 0.05161708412800861]
	TIME [epoch: 5.75 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07852762036730808		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.07852762036730808 | validation: 0.05238322708215104]
	TIME [epoch: 5.74 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07672658435333987		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.07672658435333987 | validation: 0.05004565302314784]
	TIME [epoch: 5.74 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07956415762564972		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.07956415762564972 | validation: 0.047477269319744886]
	TIME [epoch: 5.74 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07758864665699444		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.07758864665699444 | validation: 0.05671458544741959]
	TIME [epoch: 5.75 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765807266840153		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.0765807266840153 | validation: 0.05287367963987512]
	TIME [epoch: 5.78 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07627822581697999		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.07627822581697999 | validation: 0.04667308088774151]
	TIME [epoch: 5.75 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0792918963003739		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.0792918963003739 | validation: 0.06192647223585131]
	TIME [epoch: 5.77 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07859028678960911		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.07859028678960911 | validation: 0.055684647954569434]
	TIME [epoch: 5.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08035652735284866		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.08035652735284866 | validation: 0.053943644932301124]
	TIME [epoch: 5.75 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641282394306004		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.07641282394306004 | validation: 0.05187228293736709]
	TIME [epoch: 5.75 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08150566477323111		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.08150566477323111 | validation: 0.06137609886053749]
	TIME [epoch: 5.78 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07954473561853277		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.07954473561853277 | validation: 0.05507262440141328]
	TIME [epoch: 5.75 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834640311616188		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.07834640311616188 | validation: 0.05207700763441851]
	TIME [epoch: 5.74 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765717869424529		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.0765717869424529 | validation: 0.0542694046712573]
	TIME [epoch: 5.74 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07523704669625218		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.07523704669625218 | validation: 0.05152700147946753]
	TIME [epoch: 5.75 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07627528081741602		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.07627528081741602 | validation: 0.057469669445697695]
	TIME [epoch: 5.75 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07841490889634607		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.07841490889634607 | validation: 0.0628170385472075]
	TIME [epoch: 5.76 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07721549073201382		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.07721549073201382 | validation: 0.0380614846762906]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240310_003040/states/model_tr_study2_1949.pth
	Model improved!!!
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785014728739014		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.0785014728739014 | validation: 0.049318952434147176]
	TIME [epoch: 5.75 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07570390058727328		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.07570390058727328 | validation: 0.04259638323294764]
	TIME [epoch: 5.74 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07777996767641636		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.07777996767641636 | validation: 0.0532022733764614]
	TIME [epoch: 5.74 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07515681016737819		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.07515681016737819 | validation: 0.05735792024797649]
	TIME [epoch: 5.74 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07866938795709344		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.07866938795709344 | validation: 0.05275008518792845]
	TIME [epoch: 5.75 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07917728237581834		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.07917728237581834 | validation: 0.05189966326514118]
	TIME [epoch: 5.79 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07549095982761676		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.07549095982761676 | validation: 0.05579761788436614]
	TIME [epoch: 5.75 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07843062707040119		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.07843062707040119 | validation: 0.05156029470727997]
	TIME [epoch: 5.74 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07644763597136893		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.07644763597136893 | validation: 0.05570488801640098]
	TIME [epoch: 5.74 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07851468974783002		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.07851468974783002 | validation: 0.049018098165430964]
	TIME [epoch: 5.74 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07842668479590993		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.07842668479590993 | validation: 0.04819100605053497]
	TIME [epoch: 5.74 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07654485289432345		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.07654485289432345 | validation: 0.053220408021955365]
	TIME [epoch: 5.77 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07712338062739679		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.07712338062739679 | validation: 0.054315581440899124]
	TIME [epoch: 5.76 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773547141481799		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.0773547141481799 | validation: 0.052073640723509784]
	TIME [epoch: 5.75 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07816343098239928		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.07816343098239928 | validation: 0.05625275022342014]
	TIME [epoch: 5.74 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756085178775828		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.0756085178775828 | validation: 0.0480190622763595]
	TIME [epoch: 5.74 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675007995684686		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.07675007995684686 | validation: 0.053614602788458116]
	TIME [epoch: 5.74 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07855367418194889		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.07855367418194889 | validation: 0.054984116936035464]
	TIME [epoch: 5.75 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950705952632305		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.07950705952632305 | validation: 0.05021464811956029]
	TIME [epoch: 5.78 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07655465756443094		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.07655465756443094 | validation: 0.054156536449058684]
	TIME [epoch: 5.74 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07709896513508654		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.07709896513508654 | validation: 0.056203734427718026]
	TIME [epoch: 5.74 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07890091222738274		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.07890091222738274 | validation: 0.052304337486379054]
	TIME [epoch: 5.74 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0778389884624902		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.0778389884624902 | validation: 0.04732382922172697]
	TIME [epoch: 5.74 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07725981394126834		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.07725981394126834 | validation: 0.045907606573899355]
	TIME [epoch: 5.74 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07943837576012461		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.07943837576012461 | validation: 0.050124140291258626]
	TIME [epoch: 5.78 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07904967124687459		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.07904967124687459 | validation: 0.04821193749486357]
	TIME [epoch: 5.75 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07527284052019634		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.07527284052019634 | validation: 0.0452811091038266]
	TIME [epoch: 5.74 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07937308929469859		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.07937308929469859 | validation: 0.054892325048073606]
	TIME [epoch: 5.74 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07694718809558607		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.07694718809558607 | validation: 0.05616231049660891]
	TIME [epoch: 5.74 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07642609331685447		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.07642609331685447 | validation: 0.04633780978936626]
	TIME [epoch: 5.74 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07867789107344014		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.07867789107344014 | validation: 0.05608203034449757]
	TIME [epoch: 5.75 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07794162809258376		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.07794162809258376 | validation: 0.048682705712527856]
	TIME [epoch: 5.77 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07724184770476106		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.07724184770476106 | validation: 0.04674674057796745]
	TIME [epoch: 5.75 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07719494042527629		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.07719494042527629 | validation: 0.0556745238150445]
	TIME [epoch: 5.74 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153200096247233		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.08153200096247233 | validation: 0.05222096352643118]
	TIME [epoch: 5.74 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771497566546159		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.0771497566546159 | validation: 0.06467742710460751]
	TIME [epoch: 5.74 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07698806356044682		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.07698806356044682 | validation: 0.05620526225440356]
	TIME [epoch: 5.74 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07591259398823645		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.07591259398823645 | validation: 0.0545829060621954]
	TIME [epoch: 5.78 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820916505730658		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.0820916505730658 | validation: 0.052116542136669]
	TIME [epoch: 5.75 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07784059333222135		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.07784059333222135 | validation: 0.05538317244534463]
	TIME [epoch: 5.74 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07816959800947096		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.07816959800947096 | validation: 0.047947639367172785]
	TIME [epoch: 5.75 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0794377313902957		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.0794377313902957 | validation: 0.05197492885928176]
	TIME [epoch: 5.74 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07846006185846362		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.07846006185846362 | validation: 0.051395378442247515]
	TIME [epoch: 5.74 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07870462353928848		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.07870462353928848 | validation: 0.054306971771823545]
	TIME [epoch: 5.76 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965940722925147		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.07965940722925147 | validation: 0.04931702601931421]
	TIME [epoch: 5.78 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07738754836480306		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.07738754836480306 | validation: 0.04960582436018927]
	TIME [epoch: 5.74 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08099255014355174		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.08099255014355174 | validation: 0.05276719926411397]
	TIME [epoch: 5.74 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022308375289136		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.08022308375289136 | validation: 0.052900731461234404]
	TIME [epoch: 5.74 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0799353786386179		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.0799353786386179 | validation: 0.04576920226425866]
	TIME [epoch: 5.76 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07712997575793493		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.07712997575793493 | validation: 0.05677574862316683]
	TIME [epoch: 5.75 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07745973044137926		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.07745973044137926 | validation: 0.05219152277561111]
	TIME [epoch: 5.79 sec]
Finished training in 11727.007 seconds.
