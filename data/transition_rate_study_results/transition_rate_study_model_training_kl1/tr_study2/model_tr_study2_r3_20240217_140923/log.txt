Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r3', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2525695943

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/20] avg loss: 7.1824222008673715		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.199488764243717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.690955482555545 | validation: 6.063536084303755]
	TIME [epoch: 78.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/20] avg loss: 6.000604662754995		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.766417289266762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.383510976010879 | validation: 3.5612535968833403]
	TIME [epoch: 8.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.9199019497139553		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.4672023774873715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.693552163600663 | validation: 2.624496669299124]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.0482089250980415		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.4958686383695046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.272038781733773 | validation: 2.3621248929851957]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.709547825089717		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8837096519064054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.796628738498061 | validation: 2.2875102371747618]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.8416153126897274		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.7257289268066582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7836721197481933 | validation: 2.0560785670757333]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.00668660063634		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.844271244477351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9254789225568456 | validation: 2.060499041226117]
	TIME [epoch: 8.18 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.591061528912359		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.5419979120046508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.566529720458505 | validation: 1.798609032195606]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.7017298881227663		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.6766436513561063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6891867697394365 | validation: 2.4354700717744144]
	TIME [epoch: 8.2 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.3133270189767083		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.0786592849176584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.195993151947184 | validation: 2.490787526665811]
	TIME [epoch: 8.16 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.269784923941433		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.2041889046108247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.236986914276129 | validation: 3.1311255753121383]
	TIME [epoch: 8.17 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.5094607669686795		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.2274238763938308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.368442321681255 | validation: 1.4066362858443047]
	TIME [epoch: 8.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.24445615545035		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.092933640715439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1686948980828946 | validation: 1.6558443222264356]
	TIME [epoch: 8.2 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.9846445361317187		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.94135895901032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9630017475710198 | validation: 2.0610980678667254]
	TIME [epoch: 8.18 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.615731111078785		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.64100963719613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6283703741374578 | validation: 2.1972961022549957]
	TIME [epoch: 8.17 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.0525651898228077		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.934298374076753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9934317819497802 | validation: 1.8346224557867663]
	TIME [epoch: 8.17 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.1800491874951295		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.978049985080773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0790495862879514 | validation: 1.8177311952527906]
	TIME [epoch: 8.19 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.1349641120966014		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.1753215719414127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.155142842019007 | validation: 4.555327514440499]
	TIME [epoch: 8.17 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.2410639565041013		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.2040988339585956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.222581395231348 | validation: 1.8504667339406327]
	TIME [epoch: 8.17 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.9156638624357392		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.8314410087255855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.873552435580662 | validation: 2.883052848523188]
	TIME [epoch: 8.18 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8655583259346589		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7907051558260245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8281317408803417 | validation: 1.2886917579545485]
	TIME [epoch: 8.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6087334710941217		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.83170359080088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7202185309475009 | validation: 1.526306871066833]
	TIME [epoch: 8.17 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.785598828590595		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.855351348183716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8204750883871554 | validation: 1.9997239186223128]
	TIME [epoch: 8.16 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7121345082654187		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.453758115897974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5829463120816962 | validation: 1.3485770079005666]
	TIME [epoch: 8.17 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4785795816525238		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5401981379508167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5093888598016703 | validation: 1.4578234737978517]
	TIME [epoch: 8.19 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.447980897842254		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5233029143947627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4856419061185084 | validation: 1.9084634368816826]
	TIME [epoch: 8.17 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5827611365006775		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6253137726540874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6040374545773823 | validation: 2.4344402703766135]
	TIME [epoch: 8.19 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7505409946194574		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.604759520728523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6776502576739905 | validation: 1.6551367428371764]
	TIME [epoch: 8.15 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8611763479747658		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6616367551492846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7614065515620254 | validation: 1.6633924666833477]
	TIME [epoch: 8.19 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8726815582091958		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4814310127666572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6770562854879265 | validation: 1.748638283032442]
	TIME [epoch: 8.16 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3096617063844957		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5075984984931126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4086301024388042 | validation: 1.0388781436954608]
	TIME [epoch: 8.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_31.pth
	Model improved!!!
EPOCH 32/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3645751502905097		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4657719615070506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4151735558987801 | validation: 1.2575807074204546]
	TIME [epoch: 8.16 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.391979096282069		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5117062506907597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4518426734864145 | validation: 1.627960511846433]
	TIME [epoch: 8.19 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6704208616102343		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3000549794931917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.485237920551713 | validation: 1.2707838338966584]
	TIME [epoch: 8.16 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6956708918482977		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.381736018799101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5387034553236993 | validation: 1.125897947713984]
	TIME [epoch: 8.17 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5171147216181624		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4165547524737363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4668347370459496 | validation: 1.3767766862121604]
	TIME [epoch: 8.16 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.411229929915503		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3930807931944331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.402155361554968 | validation: 1.3812616512818479]
	TIME [epoch: 8.2 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.436345362963397		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3496295981538606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3929874805586286 | validation: 1.1035015485083113]
	TIME [epoch: 8.18 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.459436748477847		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.45733041915831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4583835838180783 | validation: 1.4917869394748957]
	TIME [epoch: 8.17 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4154846240225596		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.403880666629534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.409682645326047 | validation: 1.0998963804400215]
	TIME [epoch: 8.16 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4519529975565297		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5549263778463345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.503439687701432 | validation: 1.2483489355999773]
	TIME [epoch: 8.19 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3947810908855338		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2837057321251621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.339243411505348 | validation: 1.3261165592366124]
	TIME [epoch: 8.18 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.282285239913587		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3384006748692687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3103429573914278 | validation: 1.955808649582372]
	TIME [epoch: 8.17 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5343363962594585		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3162879345983007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4253121654288798 | validation: 0.9993410613571438]
	TIME [epoch: 8.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2566202040058578		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2155041730290619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2360621885174599 | validation: 1.1045188416387814]
	TIME [epoch: 8.18 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2170168602747524		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2503140164071187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2336654383409358 | validation: 1.0115438256242701]
	TIME [epoch: 8.16 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4447419118693179		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3309611176513747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3878515147603463 | validation: 1.3526420620672628]
	TIME [epoch: 8.16 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1969316301393982		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.383019766885074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2899756985122361 | validation: 1.081650249181529]
	TIME [epoch: 8.15 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.266806294935662		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2356725796338428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2512394372847522 | validation: 1.156590804136553]
	TIME [epoch: 8.18 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6259292534220264		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3007417091829667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4633354813024964 | validation: 1.0955109905638376]
	TIME [epoch: 8.16 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1663935235916336		[learning rate: 0.0099782]
		[batch 20/20] avg loss: 1.3289122789947625		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 1.2476529012931978 | validation: 1.0821207466503269]
	TIME [epoch: 8.16 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2237438156658478		[learning rate: 0.00993]
		[batch 20/20] avg loss: 1.2609335093173701		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 1.2423386624916088 | validation: 1.0490683059460209]
	TIME [epoch: 8.15 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3378694152558612		[learning rate: 0.0098819]
		[batch 20/20] avg loss: 1.244294695051104		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 1.2910820551534825 | validation: 1.0952099807503628]
	TIME [epoch: 8.18 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.257839544042809		[learning rate: 0.0098341]
		[batch 20/20] avg loss: 1.2318150684504876		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 1.2448273062466484 | validation: 1.5258041623334249]
	TIME [epoch: 8.18 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3509857452441336		[learning rate: 0.0097866]
		[batch 20/20] avg loss: 1.4698216055346858		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 1.4104036753894096 | validation: 1.695209100953591]
	TIME [epoch: 8.16 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2577574700439054		[learning rate: 0.0097393]
		[batch 20/20] avg loss: 1.2482319906509072		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 1.2529947303474063 | validation: 1.0955816012776243]
	TIME [epoch: 8.17 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2050217876879183		[learning rate: 0.0096922]
		[batch 20/20] avg loss: 1.2943189495425207		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 1.2496703686152195 | validation: 1.4050404954445581]
	TIME [epoch: 8.19 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2135313651988178		[learning rate: 0.0096453]
		[batch 20/20] avg loss: 1.23216957133975		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 1.2228504682692836 | validation: 0.9409605394786774]
	TIME [epoch: 8.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_58.pth
	Model improved!!!
EPOCH 59/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2159819253198425		[learning rate: 0.0095987]
		[batch 20/20] avg loss: 1.4346493072728932		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 1.325315616296368 | validation: 1.2566372362779574]
	TIME [epoch: 8.17 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4205047432955584		[learning rate: 0.0095522]
		[batch 20/20] avg loss: 1.2230683256852797		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 1.321786534490419 | validation: 1.3773526577950705]
	TIME [epoch: 8.17 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3324961564927542		[learning rate: 0.009506]
		[batch 20/20] avg loss: 1.1910146872561307		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 1.2617554218744422 | validation: 1.331177641055894]
	TIME [epoch: 8.19 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3865228416440125		[learning rate: 0.0094601]
		[batch 20/20] avg loss: 1.2202736054579022		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 1.3033982235509576 | validation: 1.060957055337949]
	TIME [epoch: 8.18 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2817857204339669		[learning rate: 0.0094143]
		[batch 20/20] avg loss: 1.2032713832690967		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 1.2425285518515317 | validation: 1.2247053879900904]
	TIME [epoch: 8.17 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0960869143337741		[learning rate: 0.0093688]
		[batch 20/20] avg loss: 1.1387113781567755		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 1.1173991462452746 | validation: 1.0188339591183009]
	TIME [epoch: 8.17 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2533000747814342		[learning rate: 0.0093235]
		[batch 20/20] avg loss: 1.3341879841940696		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 1.2937440294877516 | validation: 1.045158531473513]
	TIME [epoch: 8.18 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1877365432227824		[learning rate: 0.0092784]
		[batch 20/20] avg loss: 1.145452325142315		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 1.166594434182549 | validation: 1.4224396758836015]
	TIME [epoch: 8.19 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1748791655062427		[learning rate: 0.0092335]
		[batch 20/20] avg loss: 1.2384596884505394		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 1.2066694269783906 | validation: 0.9543573930507387]
	TIME [epoch: 8.17 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1120759591344553		[learning rate: 0.0091889]
		[batch 20/20] avg loss: 1.3173585935894248		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 1.2147172763619403 | validation: 0.9648713301136609]
	TIME [epoch: 8.16 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1672104613166803		[learning rate: 0.0091445]
		[batch 20/20] avg loss: 1.1615045136651148		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 1.1643574874908975 | validation: 2.0201058423644147]
	TIME [epoch: 8.17 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2621733879031432		[learning rate: 0.0091002]
		[batch 20/20] avg loss: 1.1207232807453116		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 1.1914483343242277 | validation: 1.8593070107896108]
	TIME [epoch: 8.2 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5299562397867075		[learning rate: 0.0090562]
		[batch 20/20] avg loss: 1.302863216521883		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 1.4164097281542953 | validation: 1.3354098781637835]
	TIME [epoch: 8.18 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2318173837110422		[learning rate: 0.0090124]
		[batch 20/20] avg loss: 1.0714262708959692		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 1.1516218273035057 | validation: 0.8690148549110321]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_72.pth
	Model improved!!!
EPOCH 73/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1699108828696625		[learning rate: 0.0089689]
		[batch 20/20] avg loss: 1.0000578229358292		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 1.084984352902746 | validation: 1.016757408637457]
	TIME [epoch: 8.16 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0534965978213773		[learning rate: 0.0089255]
		[batch 20/20] avg loss: 1.0628771471592184		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 1.0581868724902976 | validation: 1.3689211331536728]
	TIME [epoch: 8.19 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1860033392531173		[learning rate: 0.0088823]
		[batch 20/20] avg loss: 1.07179504151155		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 1.1288991903823338 | validation: 0.8223240922972328]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_75.pth
	Model improved!!!
EPOCH 76/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1398244531282815		[learning rate: 0.0088394]
		[batch 20/20] avg loss: 1.3394236777739192		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 1.2396240654511002 | validation: 1.0210492464854983]
	TIME [epoch: 8.17 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1690097682637544		[learning rate: 0.0087966]
		[batch 20/20] avg loss: 1.196682967426393		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 1.1828463678450736 | validation: 0.9358888113666626]
	TIME [epoch: 8.18 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2747361576286065		[learning rate: 0.0087541]
		[batch 20/20] avg loss: 1.2113612089807582		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 1.2430486833046823 | validation: 0.7987848109222074]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_78.pth
	Model improved!!!
EPOCH 79/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1849652629228564		[learning rate: 0.0087117]
		[batch 20/20] avg loss: 1.046391996196118		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 1.1156786295594874 | validation: 0.9194239816559403]
	TIME [epoch: 8.18 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0539622129362203		[learning rate: 0.0086696]
		[batch 20/20] avg loss: 1.126788236126116		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 1.0903752245311682 | validation: 1.559172959029233]
	TIME [epoch: 8.18 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2895938886139648		[learning rate: 0.0086277]
		[batch 20/20] avg loss: 1.1539749742206054		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 1.221784431417285 | validation: 0.9155959811658045]
	TIME [epoch: 8.18 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1239510389309195		[learning rate: 0.008586]
		[batch 20/20] avg loss: 1.2710094601685993		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 1.1974802495497592 | validation: 0.8538792263767834]
	TIME [epoch: 8.21 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1911496618471362		[learning rate: 0.0085445]
		[batch 20/20] avg loss: 1.1866883395673304		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 1.188919000707233 | validation: 0.9533018910858343]
	TIME [epoch: 8.18 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0441411855640865		[learning rate: 0.0085031]
		[batch 20/20] avg loss: 1.0727037297017215		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 1.0584224576329042 | validation: 1.0181554128611168]
	TIME [epoch: 8.18 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.132922075405044		[learning rate: 0.008462]
		[batch 20/20] avg loss: 1.0947111053107634		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 1.1138165903579036 | validation: 1.2681295256062182]
	TIME [epoch: 8.18 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.966339449523162		[learning rate: 0.0084211]
		[batch 20/20] avg loss: 1.0542229704827955		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 1.0102812100029788 | validation: 1.0738978423681178]
	TIME [epoch: 8.24 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.477436914547344		[learning rate: 0.0083804]
		[batch 20/20] avg loss: 1.1428535424553226		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 1.3101452285013333 | validation: 0.9209585890212459]
	TIME [epoch: 8.18 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0041374235416511		[learning rate: 0.0083398]
		[batch 20/20] avg loss: 0.9864700088138747		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.9953037161777629 | validation: 0.9069331454103158]
	TIME [epoch: 8.18 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2607780487807487		[learning rate: 0.0082995]
		[batch 20/20] avg loss: 1.0147008499978396		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 1.137739449389294 | validation: 2.3572521907516717]
	TIME [epoch: 8.18 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2007697425044612		[learning rate: 0.0082594]
		[batch 20/20] avg loss: 1.204275565482898		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 1.2025226539936795 | validation: 1.3950723706589225]
	TIME [epoch: 8.21 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1502332155270687		[learning rate: 0.0082194]
		[batch 20/20] avg loss: 0.9643788572942309		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 1.0573060364106497 | validation: 1.0487128101412684]
	TIME [epoch: 8.18 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4527750058183424		[learning rate: 0.0081797]
		[batch 20/20] avg loss: 1.0360465018785123		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 1.2444107538484275 | validation: 0.8003555745727149]
	TIME [epoch: 8.17 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0375210505804255		[learning rate: 0.0081401]
		[batch 20/20] avg loss: 1.2125023680672906		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 1.125011709323858 | validation: 0.845933616128361]
	TIME [epoch: 8.18 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0086342572899574		[learning rate: 0.0081008]
		[batch 20/20] avg loss: 1.0055834569561601		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 1.0071088571230586 | validation: 0.852933365874909]
	TIME [epoch: 8.21 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9907315163879176		[learning rate: 0.0080616]
		[batch 20/20] avg loss: 0.8977172388255668		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.9442243776067422 | validation: 0.8317150949036821]
	TIME [epoch: 8.18 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0372975277265448		[learning rate: 0.0080226]
		[batch 20/20] avg loss: 1.20344663124991		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 1.1203720794882275 | validation: 1.366177451996899]
	TIME [epoch: 8.17 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0630272862818742		[learning rate: 0.0079838]
		[batch 20/20] avg loss: 0.9199967908086558		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.9915120385452647 | validation: 1.2313021503814885]
	TIME [epoch: 8.18 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2344002976494626		[learning rate: 0.0079452]
		[batch 20/20] avg loss: 1.1081931224135209		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 1.1712967100314917 | validation: 0.7915412409917844]
	TIME [epoch: 8.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0045055146277264		[learning rate: 0.0079068]
		[batch 20/20] avg loss: 0.8962674862739117		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.9503865004508191 | validation: 2.1559229950429195]
	TIME [epoch: 8.18 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.316134672167521		[learning rate: 0.0078685]
		[batch 20/20] avg loss: 1.3024696616077547		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 1.3093021668876377 | validation: 0.9794102855906882]
	TIME [epoch: 8.17 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2351523907097834		[learning rate: 0.0078305]
		[batch 20/20] avg loss: 1.1895558375140727		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 1.212354114111928 | validation: 1.412474642006218]
	TIME [epoch: 8.17 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0520350980595885		[learning rate: 0.0077926]
		[batch 20/20] avg loss: 1.1526577076027087		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 1.1023464028311487 | validation: 1.5418916814975772]
	TIME [epoch: 8.2 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0933322776671757		[learning rate: 0.0077549]
		[batch 20/20] avg loss: 1.0583603720611636		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 1.0758463248641696 | validation: 1.131456105709514]
	TIME [epoch: 8.17 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0615570097602125		[learning rate: 0.0077174]
		[batch 20/20] avg loss: 1.279560173166279		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 1.1705585914632457 | validation: 0.9687204382530545]
	TIME [epoch: 8.17 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.18133295062797		[learning rate: 0.0076801]
		[batch 20/20] avg loss: 1.0990238446767033		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 1.1401783976523363 | validation: 0.929398459874518]
	TIME [epoch: 8.16 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1815022511777327		[learning rate: 0.007643]
		[batch 20/20] avg loss: 1.0117687541583242		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 1.0966355026680281 | validation: 1.1376492429181035]
	TIME [epoch: 8.2 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9536036677831025		[learning rate: 0.007606]
		[batch 20/20] avg loss: 1.209192566914045		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 1.081398117348574 | validation: 1.1505667205377619]
	TIME [epoch: 8.17 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.149929504946137		[learning rate: 0.0075692]
		[batch 20/20] avg loss: 1.2291453411174955		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 1.189537423031816 | validation: 0.7258195671812568]
	TIME [epoch: 8.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_108.pth
	Model improved!!!
EPOCH 109/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9191488115649097		[learning rate: 0.0075326]
		[batch 20/20] avg loss: 1.0282033325627749		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.9736760720638422 | validation: 1.683591776246073]
	TIME [epoch: 8.17 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2026280508062936		[learning rate: 0.0074962]
		[batch 20/20] avg loss: 0.992342927955702		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 1.0974854893809978 | validation: 0.9741143731406877]
	TIME [epoch: 8.19 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8707188046540397		[learning rate: 0.00746]
		[batch 20/20] avg loss: 1.0822658659377062		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.9764923352958729 | validation: 0.7118165797866974]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_111.pth
	Model improved!!!
EPOCH 112/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9949833263238326		[learning rate: 0.0074239]
		[batch 20/20] avg loss: 0.9426134299941659		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.9687983781589992 | validation: 0.7298571680490812]
	TIME [epoch: 8.16 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0424640474759908		[learning rate: 0.007388]
		[batch 20/20] avg loss: 0.9692937367743161		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 1.0058788921251536 | validation: 0.9203142554060705]
	TIME [epoch: 8.17 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9066812297842379		[learning rate: 0.0073523]
		[batch 20/20] avg loss: 0.8362851707167644		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.8714832002505013 | validation: 1.1517075329561028]
	TIME [epoch: 8.19 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1134868833958094		[learning rate: 0.0073167]
		[batch 20/20] avg loss: 0.8774414151927393		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.9954641492942746 | validation: 1.2902040024132688]
	TIME [epoch: 8.17 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2533795649301818		[learning rate: 0.0072813]
		[batch 20/20] avg loss: 1.2015126629191808		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 1.2274461139246813 | validation: 1.6062100077054748]
	TIME [epoch: 8.16 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.755287207245758		[learning rate: 0.0072461]
		[batch 20/20] avg loss: 1.3766824505057866		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 1.565984828875772 | validation: 1.9662443971103847]
	TIME [epoch: 8.17 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5653582962768169		[learning rate: 0.0072111]
		[batch 20/20] avg loss: 1.5083239198179368		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 1.5368411080473767 | validation: 0.8661401625269983]
	TIME [epoch: 8.19 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1166808757264595		[learning rate: 0.0071762]
		[batch 20/20] avg loss: 1.0639382268059685		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 1.090309551266214 | validation: 0.7455832296369274]
	TIME [epoch: 8.17 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.167137321811659		[learning rate: 0.0071415]
		[batch 20/20] avg loss: 0.9156813624817639		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 1.0414093421467114 | validation: 0.9875621270976207]
	TIME [epoch: 8.16 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0180518926138276		[learning rate: 0.007107]
		[batch 20/20] avg loss: 1.6754638915030924		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 1.34675789205846 | validation: 3.57439029154351]
	TIME [epoch: 8.16 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5468487740599133		[learning rate: 0.0070726]
		[batch 20/20] avg loss: 1.392294895762728		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 1.4695718349113203 | validation: 0.7613816673455116]
	TIME [epoch: 8.19 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9044803047277099		[learning rate: 0.0070384]
		[batch 20/20] avg loss: 1.3634014063644602		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 1.133940855546085 | validation: 2.1870897824460833]
	TIME [epoch: 8.17 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4397419863448164		[learning rate: 0.0070044]
		[batch 20/20] avg loss: 1.5464804141698658		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 1.4931112002573412 | validation: 1.9363671174054815]
	TIME [epoch: 8.16 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.0281887443835496		[learning rate: 0.0069705]
		[batch 20/20] avg loss: 1.5244192017797777		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 1.7763039730816632 | validation: 3.6065241848312373]
	TIME [epoch: 8.16 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.0534370768897063		[learning rate: 0.0069368]
		[batch 20/20] avg loss: 1.4745334390563376		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 1.7639852579730217 | validation: 1.4423337674852625]
	TIME [epoch: 8.19 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3688756188354563		[learning rate: 0.0069032]
		[batch 20/20] avg loss: 1.7101023390120829		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 1.5394889789237696 | validation: 1.0367599417777695]
	TIME [epoch: 8.17 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7488779287850975		[learning rate: 0.0068699]
		[batch 20/20] avg loss: 1.4485292715302975		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 1.5987036001576975 | validation: 3.595405631582673]
	TIME [epoch: 8.16 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7918465957025589		[learning rate: 0.0068366]
		[batch 20/20] avg loss: 1.6023100651457791		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 1.6970783304241688 | validation: 1.9083305919581293]
	TIME [epoch: 8.17 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2691152615204477		[learning rate: 0.0068036]
		[batch 20/20] avg loss: 1.3899252417741752		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 1.3295202516473115 | validation: 1.5493131521176473]
	TIME [epoch: 8.18 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6568887217593709		[learning rate: 0.0067707]
		[batch 20/20] avg loss: 1.444437687461038		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 1.5506632046102047 | validation: 1.1764864542800064]
	TIME [epoch: 8.18 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2719371968283322		[learning rate: 0.0067379]
		[batch 20/20] avg loss: 1.2163451706163522		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 1.2441411837223422 | validation: 1.002812192695397]
	TIME [epoch: 8.16 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1872332166816282		[learning rate: 0.0067053]
		[batch 20/20] avg loss: 1.6168397398550276		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 1.4020364782683277 | validation: 1.3388726576968626]
	TIME [epoch: 8.17 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3002431823316232		[learning rate: 0.0066729]
		[batch 20/20] avg loss: 1.9955632946162243		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 1.647903238473924 | validation: 2.4725756133826677]
	TIME [epoch: 8.18 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.351804123830227		[learning rate: 0.0066406]
		[batch 20/20] avg loss: 1.2576784350044352		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 1.304741279417331 | validation: 1.379153764907773]
	TIME [epoch: 8.18 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8163550381774058		[learning rate: 0.0066085]
		[batch 20/20] avg loss: 1.1382209481490477		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 1.4772879931632266 | validation: 1.5045936777583713]
	TIME [epoch: 8.16 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.273336681160641		[learning rate: 0.0065766]
		[batch 20/20] avg loss: 1.696825320887632		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 1.4850810010241369 | validation: 1.3470978540193712]
	TIME [epoch: 8.16 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2429836036278081		[learning rate: 0.0065448]
		[batch 20/20] avg loss: 1.22630467200073		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 1.2346441378142692 | validation: 1.4059139818482742]
	TIME [epoch: 8.18 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4751794805880372		[learning rate: 0.0065131]
		[batch 20/20] avg loss: 1.3464516059491447		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 1.410815543268591 | validation: 1.0711834236110227]
	TIME [epoch: 8.17 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3835628552439483		[learning rate: 0.0064816]
		[batch 20/20] avg loss: 1.6228040213846184		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 1.5031834383142837 | validation: 1.1162006129136401]
	TIME [epoch: 8.16 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2437597588757352		[learning rate: 0.0064503]
		[batch 20/20] avg loss: 1.502536594661945		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 1.37314817676884 | validation: 1.0812612988577772]
	TIME [epoch: 8.16 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.1824297904354983		[learning rate: 0.0064191]
		[batch 20/20] avg loss: 1.2968587062348509		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 1.7396442483351744 | validation: 1.377963293702418]
	TIME [epoch: 8.17 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2905830075780733		[learning rate: 0.0063881]
		[batch 20/20] avg loss: 1.8356048480186515		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 1.5630939277983624 | validation: 1.2875931376742045]
	TIME [epoch: 8.18 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2629718939106627		[learning rate: 0.0063572]
		[batch 20/20] avg loss: 1.3879637976868389		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 1.3254678457987508 | validation: 1.507423380997625]
	TIME [epoch: 8.16 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4614113369327515		[learning rate: 0.0063264]
		[batch 20/20] avg loss: 1.462155957443849		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 1.4617836471883001 | validation: 1.1559628541447913]
	TIME [epoch: 8.16 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2973222155665227		[learning rate: 0.0062958]
		[batch 20/20] avg loss: 1.4271520400525015		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 1.3622371278095118 | validation: 1.8175880790769186]
	TIME [epoch: 8.17 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.323672985630721		[learning rate: 0.0062654]
		[batch 20/20] avg loss: 1.4768564746926354		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 1.400264730161678 | validation: 2.120348932214653]
	TIME [epoch: 8.19 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.722354794622936		[learning rate: 0.0062351]
		[batch 20/20] avg loss: 1.3094971485671145		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 1.5159259715950253 | validation: 1.1236991234886755]
	TIME [epoch: 8.17 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1232225982243365		[learning rate: 0.0062049]
		[batch 20/20] avg loss: 1.4636031416367146		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 1.2934128699305254 | validation: 1.7451196099996589]
	TIME [epoch: 8.16 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4111430769917435		[learning rate: 0.0061749]
		[batch 20/20] avg loss: 1.560909751334635		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 1.4860264141631891 | validation: 1.9431048730463638]
	TIME [epoch: 8.17 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5342595152626146		[learning rate: 0.0061451]
		[batch 20/20] avg loss: 1.4249709553893255		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 1.47961523532597 | validation: 1.4152360590369013]
	TIME [epoch: 8.19 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2974368250232953		[learning rate: 0.0061153]
		[batch 20/20] avg loss: 1.9105450478448254		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 1.60399093643406 | validation: 2.1262703315801987]
	TIME [epoch: 8.19 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4854146012984868		[learning rate: 0.0060858]
		[batch 20/20] avg loss: 1.2417064032517051		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 1.363560502275096 | validation: 1.4578316836721161]
	TIME [epoch: 8.16 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3651292666415138		[learning rate: 0.0060563]
		[batch 20/20] avg loss: 1.4689229517762519		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 1.4170261092088832 | validation: 1.2873955105435324]
	TIME [epoch: 8.16 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3024218240690197		[learning rate: 0.0060271]
		[batch 20/20] avg loss: 1.317476331343045		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 1.309949077706032 | validation: 1.0551183513843971]
	TIME [epoch: 8.19 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0529275783674974		[learning rate: 0.0059979]
		[batch 20/20] avg loss: 1.4158545829231097		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 1.2343910806453031 | validation: 1.2311467368562892]
	TIME [epoch: 8.17 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1632512743708872		[learning rate: 0.0059689]
		[batch 20/20] avg loss: 1.1180323816868278		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 1.140641828028857 | validation: 1.369037065857217]
	TIME [epoch: 8.16 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0280617625231667		[learning rate: 0.00594]
		[batch 20/20] avg loss: 1.0907190051426556		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 1.0593903838329108 | validation: 0.9214412924037002]
	TIME [epoch: 8.16 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0331076563189403		[learning rate: 0.0059113]
		[batch 20/20] avg loss: 1.1433212944428925		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 1.0882144753809166 | validation: 1.400747287921693]
	TIME [epoch: 8.19 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.06449202157483		[learning rate: 0.0058827]
		[batch 20/20] avg loss: 0.9979441481070414		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 1.031218084840936 | validation: 1.0064334906779102]
	TIME [epoch: 8.16 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1471596658379133		[learning rate: 0.0058543]
		[batch 20/20] avg loss: 1.1503585398148375		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 1.1487591028263755 | validation: 1.260657363812524]
	TIME [epoch: 8.16 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.035429938583056		[learning rate: 0.005826]
		[batch 20/20] avg loss: 1.061812040549571		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 1.0486209895663134 | validation: 0.9192246437250223]
	TIME [epoch: 8.16 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9789147604624547		[learning rate: 0.0057978]
		[batch 20/20] avg loss: 1.0016961250162644		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.9903054427393595 | validation: 1.2737170831819573]
	TIME [epoch: 8.19 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.032281633482225		[learning rate: 0.0057698]
		[batch 20/20] avg loss: 1.0230800390454906		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 1.0276808362638576 | validation: 2.337881544380278]
	TIME [epoch: 8.16 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1437139211013998		[learning rate: 0.0057419]
		[batch 20/20] avg loss: 1.0498523139126426		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 1.0967831175070208 | validation: 1.127483472778903]
	TIME [epoch: 8.16 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.180013302064171		[learning rate: 0.0057141]
		[batch 20/20] avg loss: 1.2839745700413119		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 1.2319939360527412 | validation: 1.8041831589984474]
	TIME [epoch: 8.16 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1505579592006274		[learning rate: 0.0056865]
		[batch 20/20] avg loss: 0.9833097252368372		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 1.0669338422187322 | validation: 0.8695980843958326]
	TIME [epoch: 8.19 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0300170971459788		[learning rate: 0.005659]
		[batch 20/20] avg loss: 1.0423529368404982		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 1.0361850169932385 | validation: 1.008858356168826]
	TIME [epoch: 8.17 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1681135132519482		[learning rate: 0.0056316]
		[batch 20/20] avg loss: 0.973163429295316		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 1.070638471273632 | validation: 1.6830281005825731]
	TIME [epoch: 8.15 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0372260593444402		[learning rate: 0.0056044]
		[batch 20/20] avg loss: 0.9423901962547042		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.9898081277995725 | validation: 0.6412019280350603]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_170.pth
	Model improved!!!
EPOCH 171/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9768861464684049		[learning rate: 0.0055773]
		[batch 20/20] avg loss: 0.9968529695002095		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.9868695579843072 | validation: 1.1526308180719074]
	TIME [epoch: 8.19 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4096432539346697		[learning rate: 0.0055503]
		[batch 20/20] avg loss: 0.9158276900417659		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 1.162735471988218 | validation: 1.5097461142674615]
	TIME [epoch: 8.17 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9954774320609125		[learning rate: 0.0055235]
		[batch 20/20] avg loss: 0.9478019419488618		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.9716396870048871 | validation: 1.7923216587442101]
	TIME [epoch: 8.16 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0858778494854757		[learning rate: 0.0054967]
		[batch 20/20] avg loss: 1.2365704722259017		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 1.161224160855689 | validation: 1.5821341993264588]
	TIME [epoch: 8.15 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.077327434301027		[learning rate: 0.0054702]
		[batch 20/20] avg loss: 0.8966773861658398		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.987002410233433 | validation: 1.3260892406647133]
	TIME [epoch: 8.19 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9628208570895698		[learning rate: 0.0054437]
		[batch 20/20] avg loss: 0.9113069378019704		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.93706389744577 | validation: 1.0710080290153987]
	TIME [epoch: 8.16 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9148011763471603		[learning rate: 0.0054174]
		[batch 20/20] avg loss: 0.8794768357484137		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.8971390060477867 | validation: 0.6952960014197263]
	TIME [epoch: 8.16 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0188417566396863		[learning rate: 0.0053912]
		[batch 20/20] avg loss: 1.1764474788813661		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 1.0976446177605261 | validation: 0.7991535051747096]
	TIME [epoch: 8.15 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9198472055101888		[learning rate: 0.0053651]
		[batch 20/20] avg loss: 1.0593799984232477		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.9896136019667182 | validation: 0.9090314293961244]
	TIME [epoch: 8.18 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0251775710749105		[learning rate: 0.0053392]
		[batch 20/20] avg loss: 0.8823161266722185		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.9537468488735646 | validation: 1.003011671778737]
	TIME [epoch: 8.16 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8759294626736442		[learning rate: 0.0053133]
		[batch 20/20] avg loss: 1.0999980962526001		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.9879637794631224 | validation: 0.9282947088866664]
	TIME [epoch: 8.16 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3586937125173324		[learning rate: 0.0052877]
		[batch 20/20] avg loss: 0.9662118175824208		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 1.1624527650498764 | validation: 0.8767779622672685]
	TIME [epoch: 8.16 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9369144088333723		[learning rate: 0.0052621]
		[batch 20/20] avg loss: 0.8624332717279362		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.8996738402806541 | validation: 1.0160144123086348]
	TIME [epoch: 8.18 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3310838688247582		[learning rate: 0.0052366]
		[batch 20/20] avg loss: 1.0053442181856798		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 1.1682140435052193 | validation: 0.9003569658934196]
	TIME [epoch: 8.17 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9262772020043168		[learning rate: 0.0052113]
		[batch 20/20] avg loss: 0.9588603732718448		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.9425687876380808 | validation: 0.6449836787900355]
	TIME [epoch: 8.16 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8880680399091905		[learning rate: 0.0051861]
		[batch 20/20] avg loss: 0.905498610436297		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.8967833251727436 | validation: 1.2293755128531674]
	TIME [epoch: 8.16 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.975196590033271		[learning rate: 0.005161]
		[batch 20/20] avg loss: 1.1471546368988088		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 1.06117561346604 | validation: 0.8487347685148738]
	TIME [epoch: 8.18 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9851911134998245		[learning rate: 0.0051361]
		[batch 20/20] avg loss: 0.826405168240987		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.9057981408704059 | validation: 1.049272894124455]
	TIME [epoch: 8.17 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8127813598281108		[learning rate: 0.0051112]
		[batch 20/20] avg loss: 1.1280920701738217		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.9704367150009661 | validation: 0.6108702827377497]
	TIME [epoch: 8.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_189.pth
	Model improved!!!
EPOCH 190/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8049722302375428		[learning rate: 0.0050865]
		[batch 20/20] avg loss: 0.7535521551087561		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.7792621926731494 | validation: 0.5630454145854994]
	TIME [epoch: 8.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_190.pth
	Model improved!!!
EPOCH 191/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8936379606597591		[learning rate: 0.0050619]
		[batch 20/20] avg loss: 0.7834567582928639		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.8385473594763114 | validation: 0.6955499222951261]
	TIME [epoch: 8.18 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8104568398502879		[learning rate: 0.0050374]
		[batch 20/20] avg loss: 0.73761337813423		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.7740351089922589 | validation: 0.8297199955345562]
	TIME [epoch: 8.17 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.732898035186508		[learning rate: 0.0050131]
		[batch 20/20] avg loss: 0.7562043284323399		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.744551181809424 | validation: 0.7647253528480795]
	TIME [epoch: 8.16 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7348941442512835		[learning rate: 0.0049888]
		[batch 20/20] avg loss: 0.7919929532900027		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.7634435487706432 | validation: 0.9088839261721222]
	TIME [epoch: 8.16 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7938086910803992		[learning rate: 0.0049647]
		[batch 20/20] avg loss: 0.6943882285314245		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.7440984598059118 | validation: 0.9910782353423337]
	TIME [epoch: 8.17 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.091280036645837		[learning rate: 0.0049407]
		[batch 20/20] avg loss: 1.1557252575961916		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 1.1235026471210146 | validation: 0.8634931348350285]
	TIME [epoch: 8.17 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.87538838246897		[learning rate: 0.0049168]
		[batch 20/20] avg loss: 0.796713933551842		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.836051158010406 | validation: 0.5024648734179985]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_197.pth
	Model improved!!!
EPOCH 198/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7586282480776716		[learning rate: 0.004893]
		[batch 20/20] avg loss: 1.198382796387352		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.978505522232512 | validation: 0.6888230176755182]
	TIME [epoch: 8.16 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.140728107076971		[learning rate: 0.0048694]
		[batch 20/20] avg loss: 0.8896621087416859		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 1.0151951079093287 | validation: 0.7391675101116606]
	TIME [epoch: 8.18 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9023089795469501		[learning rate: 0.0048458]
		[batch 20/20] avg loss: 0.9565076845858226		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.9294083320663864 | validation: 1.3982922410689618]
	TIME [epoch: 8.17 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9217932996242363		[learning rate: 0.0048224]
		[batch 20/20] avg loss: 1.2456278826216471		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 1.0837105911229417 | validation: 1.237040164623345]
	TIME [epoch: 8.16 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.054062236692852		[learning rate: 0.0047991]
		[batch 20/20] avg loss: 0.8601970130841913		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.9571296248885215 | validation: 0.7443076001418806]
	TIME [epoch: 8.16 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8531228137529437		[learning rate: 0.0047759]
		[batch 20/20] avg loss: 0.8229957523401463		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.838059283046545 | validation: 0.664993432334927]
	TIME [epoch: 8.18 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7698196854257237		[learning rate: 0.0047528]
		[batch 20/20] avg loss: 0.8418578473426719		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.8058387663841977 | validation: 1.3851480418230027]
	TIME [epoch: 8.17 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8542962340091936		[learning rate: 0.0047298]
		[batch 20/20] avg loss: 0.9160544130530119		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.8851753235311028 | validation: 0.617262831301461]
	TIME [epoch: 8.17 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8708013392312608		[learning rate: 0.0047069]
		[batch 20/20] avg loss: 0.7778755921909483		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.8243384657111044 | validation: 0.8404606331935474]
	TIME [epoch: 8.16 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7955779969404903		[learning rate: 0.0046842]
		[batch 20/20] avg loss: 0.9356653584846415		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.8656216777125658 | validation: 0.5327840464385751]
	TIME [epoch: 8.18 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3060167000023895		[learning rate: 0.0046615]
		[batch 20/20] avg loss: 1.2658610634705307		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 1.28593888173646 | validation: 0.9458471212814255]
	TIME [epoch: 8.16 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9287699342147441		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.7924806978418999		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.860625316028322 | validation: 0.4728012792301157]
	TIME [epoch: 8.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_209.pth
	Model improved!!!
EPOCH 210/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.818902274405674		[learning rate: 0.0046165]
		[batch 20/20] avg loss: 0.7777609777306885		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.7983316260681813 | validation: 0.6698693569934122]
	TIME [epoch: 8.16 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8116716948211964		[learning rate: 0.0045942]
		[batch 20/20] avg loss: 0.7766372597745227		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.7941544772978595 | validation: 0.7367861150806033]
	TIME [epoch: 8.17 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1605823442399867		[learning rate: 0.004572]
		[batch 20/20] avg loss: 0.9560150029054819		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 1.0582986735727344 | validation: 2.438617152423809]
	TIME [epoch: 8.19 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9283303511469662		[learning rate: 0.0045499]
		[batch 20/20] avg loss: 0.8247314842195447		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.8765309176832554 | validation: 0.8031127823667346]
	TIME [epoch: 8.16 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0319234888905884		[learning rate: 0.0045279]
		[batch 20/20] avg loss: 0.7457064947554765		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.8888149918230323 | validation: 0.589460008405343]
	TIME [epoch: 8.17 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8774131465597993		[learning rate: 0.004506]
		[batch 20/20] avg loss: 0.7012004881526857		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.7893068173562426 | validation: 0.7717832231388242]
	TIME [epoch: 8.17 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7860342527765017		[learning rate: 0.0044842]
		[batch 20/20] avg loss: 0.7670872836659094		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.7765607682212056 | validation: 0.6927659069775058]
	TIME [epoch: 8.18 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7708107891839238		[learning rate: 0.0044625]
		[batch 20/20] avg loss: 0.7759379944891432		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.7733743918365336 | validation: 1.156385604092825]
	TIME [epoch: 8.16 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8345780925463213		[learning rate: 0.0044409]
		[batch 20/20] avg loss: 0.8059048787508193		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.8202414856485701 | validation: 1.0133892077485995]
	TIME [epoch: 8.16 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7913376909775774		[learning rate: 0.0044195]
		[batch 20/20] avg loss: 0.7313083996019145		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.7613230452897459 | validation: 0.5164089410330978]
	TIME [epoch: 8.17 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7280457929526123		[learning rate: 0.0043981]
		[batch 20/20] avg loss: 0.7423165400868788		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.7351811665197455 | validation: 0.8676249396334275]
	TIME [epoch: 8.19 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7127989370201788		[learning rate: 0.0043768]
		[batch 20/20] avg loss: 0.7170666474026428		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.7149327922114109 | validation: 0.8175771081685872]
	TIME [epoch: 8.16 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6726113309250209		[learning rate: 0.0043556]
		[batch 20/20] avg loss: 0.7053561079095317		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.6889837194172763 | validation: 0.44467107232012143]
	TIME [epoch: 8.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_222.pth
	Model improved!!!
EPOCH 223/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7670169137828242		[learning rate: 0.0043346]
		[batch 20/20] avg loss: 0.9052314464934913		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.8361241801381578 | validation: 0.608058646994736]
	TIME [epoch: 8.17 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.75900821191878		[learning rate: 0.0043136]
		[batch 20/20] avg loss: 0.7807912108820153		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.7698997114003978 | validation: 0.9159408844067345]
	TIME [epoch: 8.2 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7364783756472674		[learning rate: 0.0042928]
		[batch 20/20] avg loss: 0.687201413591272		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.7118398946192697 | validation: 0.7077820635989348]
	TIME [epoch: 8.16 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6864599929218708		[learning rate: 0.004272]
		[batch 20/20] avg loss: 0.7605205841298337		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.7234902885258521 | validation: 0.49960629743121127]
	TIME [epoch: 8.16 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6093894218216656		[learning rate: 0.0042513]
		[batch 20/20] avg loss: 0.9153224548995604		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.762355938360613 | validation: 0.710131025640787]
	TIME [epoch: 8.16 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8477043473017016		[learning rate: 0.0042308]
		[batch 20/20] avg loss: 0.8583530956589888		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.8530287214803451 | validation: 2.1912200069954073]
	TIME [epoch: 8.2 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3223773871612785		[learning rate: 0.0042103]
		[batch 20/20] avg loss: 0.7844520017365663		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 1.0534146944489224 | validation: 0.5267178591480711]
	TIME [epoch: 8.16 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9977904086677546		[learning rate: 0.00419]
		[batch 20/20] avg loss: 0.7095991386699719		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.8536947736688631 | validation: 0.7916054088087098]
	TIME [epoch: 8.17 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6397578355853075		[learning rate: 0.0041697]
		[batch 20/20] avg loss: 0.6264410117485886		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.633099423666948 | validation: 0.8824567762683797]
	TIME [epoch: 8.17 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6765427591249089		[learning rate: 0.0041495]
		[batch 20/20] avg loss: 1.052601819601867		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.8645722893633879 | validation: 0.3936419176100554]
	TIME [epoch: 8.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r3_20240217_140923/states/model_tr_study2_232.pth
	Model improved!!!
EPOCH 233/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7813772766386726		[learning rate: 0.0041295]
		[batch 20/20] avg loss: 1.3958971994688947		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 1.0886372380537837 | validation: 0.5679847559433339]
	TIME [epoch: 8.16 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7812962671778875		[learning rate: 0.0041095]
		[batch 20/20] avg loss: 0.6850808133038844		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.7331885402408859 | validation: 0.4334736783640522]
	TIME [epoch: 8.17 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7176170203308938		[learning rate: 0.0040896]
		[batch 20/20] avg loss: 0.7010780462956665		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.7093475333132802 | validation: 0.5768741074212423]
	TIME [epoch: 8.15 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7152484632421444		[learning rate: 0.0040699]
		[batch 20/20] avg loss: 0.8820828350260193		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.7986656491340819 | validation: 0.9533824608332719]
	TIME [epoch: 8.19 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7787456312519028		[learning rate: 0.0040502]
		[batch 20/20] avg loss: 0.6301902847139054		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.7044679579829041 | validation: 1.6006984371937667]
	TIME [epoch: 8.16 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1366610785384983		[learning rate: 0.0040306]
		[batch 20/20] avg loss: 1.08792364884158		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 1.112292363690039 | validation: 1.6075845914216504]
	TIME [epoch: 8.15 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9138768037935423		[learning rate: 0.0040111]
		[batch 20/20] avg loss: 1.022897705114133		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.9683872544538377 | validation: 0.9152929667377073]
	TIME [epoch: 8.17 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8370395478459927		[learning rate: 0.0039917]
		[batch 20/20] avg loss: 0.8178665945802818		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.8274530712131372 | validation: 0.5698610969962659]
	TIME [epoch: 8.19 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8766193630188417		[learning rate: 0.0039724]
		[batch 20/20] avg loss: 0.7054896339477235		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.7910544984832826 | validation: 0.7764637058155301]
	TIME [epoch: 8.17 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.765375601727151		[learning rate: 0.0039532]
		[batch 20/20] avg loss: 0.934509899293895		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.8499427505105231 | validation: 0.9968366803748576]
	TIME [epoch: 8.16 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0239963202357238		[learning rate: 0.0039341]
		[batch 20/20] avg loss: 1.1043165026482162		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 1.0641564114419697 | validation: 0.4180007521073885]
	TIME [epoch: 8.16 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9439057704540996		[learning rate: 0.003915]
		[batch 20/20] avg loss: 1.7488552035078535		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 1.3463804869809768 | validation: 1.1896848190260894]
	TIME [epoch: 8.19 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2186510072329146		[learning rate: 0.0038961]
		[batch 20/20] avg loss: 1.1559294571172536		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 1.187290232175084 | validation: 0.7160525002125433]
	TIME [epoch: 8.17 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9098356779172431		[learning rate: 0.0038773]
		[batch 20/20] avg loss: 1.0964916284437929		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 1.003163653180518 | validation: 1.3502289008260886]
	TIME [epoch: 8.16 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2735816706493153		[learning rate: 0.0038585]
		[batch 20/20] avg loss: 1.8188295809325072		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 1.5462056257909111 | validation: 0.6278683543939149]
	TIME [epoch: 8.16 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.5641687335882097		[learning rate: 0.0038399]
		[batch 20/20] avg loss: 1.696650280766709		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 2.1304095071774602 | validation: 0.78590989368547]
	TIME [epoch: 8.19 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4396956030047812		[learning rate: 0.0038213]
		[batch 20/20] avg loss: 1.4732405307680092		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 1.4564680668863952 | validation: 2.0150070306566366]
	TIME [epoch: 8.16 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6902593171367672		[learning rate: 0.0038028]
		[batch 20/20] avg loss: 1.617039224849653		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 1.6536492709932102 | validation: 2.423300220719496]
	TIME [epoch: 8.16 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.979921034378587		[learning rate: 0.0037844]
		[batch 20/20] avg loss: 2.0982469878157373		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 2.0390840110971613 | validation: 1.206799789353711]
	TIME [epoch: 8.16 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.1302863387559485		[learning rate: 0.0037661]
		[batch 20/20] avg loss: 2.253237023288881		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 2.191761681022415 | validation: 2.0963742404258228]
	TIME [epoch: 8.19 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7399234392642149		[learning rate: 0.0037479]
		[batch 20/20] avg loss: 4.437392046286663		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 3.08865774277544 | validation: 2.94824248971962]
	TIME [epoch: 8.16 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/20] avg loss: 4.034885609520965		[learning rate: 0.0037298]
		[batch 20/20] avg loss: 3.8072776430300523		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 3.921081626275508 | validation: 5.550028865495816]
	TIME [epoch: 8.16 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/20] avg loss: nan		[learning rate: 0.0037118]
		[batch 20/20] avg loss: nan		[learning rate: 0.0037028]
ERROR:
nan encountered in epoch 254 (training loss).
