Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r1', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 111939730

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.820785675593894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.820785675593894 | validation: 6.306121352721043]
	TIME [epoch: 84.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7087543076370215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7087543076370215 | validation: 4.46480099093918]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.409291803360286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.409291803360286 | validation: 4.68006573663587]
	TIME [epoch: 6.4 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.136514144280866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.136514144280866 | validation: 3.311310900965065]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.407599323254847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.407599323254847 | validation: 3.0392279171670715]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.303140909873635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.303140909873635 | validation: 3.020304039443318]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.007930986613101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.007930986613101 | validation: 2.9905998361928825]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8238194735530806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8238194735530806 | validation: 3.0112103824100656]
	TIME [epoch: 6.4 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9033906810372283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9033906810372283 | validation: 3.4382511095377435]
	TIME [epoch: 6.38 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218185999955562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.218185999955562 | validation: 2.8650110615631497]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9237888819576976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9237888819576976 | validation: 3.141469970225728]
	TIME [epoch: 6.39 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9832043821799825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9832043821799825 | validation: 2.705310268706146]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5951457463593575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5951457463593575 | validation: 2.4162969846969746]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4144563091984583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4144563091984583 | validation: 2.3521346731046453]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3349375254373395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3349375254373395 | validation: 2.0122633266115777]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.331112960697652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.331112960697652 | validation: 2.6314177407911683]
	TIME [epoch: 6.4 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4659484746913147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4659484746913147 | validation: 1.8739055013183665]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052071610841101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.052071610841101 | validation: 1.922700229478054]
	TIME [epoch: 6.4 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9944911851104434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9944911851104434 | validation: 1.6294244305046415]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.888105424226178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.888105424226178 | validation: 1.9500869106656178]
	TIME [epoch: 6.39 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.903938920657026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.903938920657026 | validation: 1.7548264507986988]
	TIME [epoch: 6.4 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5885860298422507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5885860298422507 | validation: 1.3548576631965152]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5927401016396683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5927401016396683 | validation: 1.4732862887556832]
	TIME [epoch: 6.38 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3525480698247112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3525480698247112 | validation: 1.5311990543956402]
	TIME [epoch: 6.38 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5081365728079135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5081365728079135 | validation: 1.1141138079126527]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1808168717452059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1808168717452059 | validation: 0.9874630842251189]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4773349467645436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4773349467645436 | validation: 0.9236603870609925]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1191432719693513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1191432719693513 | validation: 2.0488446387494554]
	TIME [epoch: 6.38 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7393064379801841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7393064379801841 | validation: 1.5247874226143807]
	TIME [epoch: 6.38 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1574720063310913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1574720063310913 | validation: 1.4323561705353693]
	TIME [epoch: 6.39 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1844754088894383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1844754088894383 | validation: 0.9793111255292363]
	TIME [epoch: 6.39 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9661487293293453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9661487293293453 | validation: 0.7837229283245043]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1256392241953335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1256392241953335 | validation: 1.0133076391687452]
	TIME [epoch: 6.42 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1100982206977592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1100982206977592 | validation: 0.7311391437150099]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9123014348848338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9123014348848338 | validation: 0.8445776580099849]
	TIME [epoch: 6.38 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0164013183621996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0164013183621996 | validation: 0.6736508189955948]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8363242006803034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8363242006803034 | validation: 0.739461753671998]
	TIME [epoch: 6.37 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8959744585612176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8959744585612176 | validation: 1.4180688335115479]
	TIME [epoch: 6.39 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9352422846241979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9352422846241979 | validation: 0.6708058386875106]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8521720986239094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8521720986239094 | validation: 0.6512762020319282]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.924201963338575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.924201963338575 | validation: 0.8216892470131189]
	TIME [epoch: 6.4 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8271281911545931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8271281911545931 | validation: 0.687420510037883]
	TIME [epoch: 6.39 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1266120790807475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1266120790807475 | validation: 0.6144523609829796]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2708968804139928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2708968804139928 | validation: 2.060806853022496]
	TIME [epoch: 6.38 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2813230915351983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2813230915351983 | validation: 0.7752682418661522]
	TIME [epoch: 6.38 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8193681787037268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8193681787037268 | validation: 0.6199323095771517]
	TIME [epoch: 6.38 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192065526318273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7192065526318273 | validation: 0.9051897844449356]
	TIME [epoch: 6.42 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7415214715116918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7415214715116918 | validation: 0.8510656455411882]
	TIME [epoch: 6.38 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8507074329412662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8507074329412662 | validation: 0.5597536557532371]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6576487635348559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6576487635348559 | validation: 1.5041532570639238]
	TIME [epoch: 6.4 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8613852729457138		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.8613852729457138 | validation: 0.5612565903255053]
	TIME [epoch: 6.39 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.691003278958865		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.691003278958865 | validation: 0.6214235160022664]
	TIME [epoch: 6.39 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8495688497755839		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.8495688497755839 | validation: 1.1519852936253074]
	TIME [epoch: 6.39 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8583295959863885		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.8583295959863885 | validation: 0.5776004464087479]
	TIME [epoch: 6.41 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.612781935697135		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.612781935697135 | validation: 0.45041634370851974]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6519438549075153		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.6519438549075153 | validation: 0.5042808401252067]
	TIME [epoch: 6.39 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5666479084553881		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.5666479084553881 | validation: 0.4300856428634946]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6341426669571175		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.6341426669571175 | validation: 0.4602729196362221]
	TIME [epoch: 6.39 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7582413915090807		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.7582413915090807 | validation: 1.1385401299278075]
	TIME [epoch: 6.39 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6795818011729783		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.6795818011729783 | validation: 0.40004101797116376]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572114321291186		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.572114321291186 | validation: 0.4905500693286854]
	TIME [epoch: 6.41 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5278165200017809		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.5278165200017809 | validation: 0.6557212070247601]
	TIME [epoch: 6.38 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835859091166222		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.6835859091166222 | validation: 0.5787675660203453]
	TIME [epoch: 6.39 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.607714539688858		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.607714539688858 | validation: 0.42746585295277634]
	TIME [epoch: 6.38 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7492617333002101		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.7492617333002101 | validation: 0.6040265555090696]
	TIME [epoch: 6.37 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6702440127720273		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.6702440127720273 | validation: 0.4535468917996191]
	TIME [epoch: 6.37 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.502681976806368		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.502681976806368 | validation: 0.538080147247767]
	TIME [epoch: 6.38 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5920667968472774		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.5920667968472774 | validation: 0.43892320115765643]
	TIME [epoch: 6.39 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48607712891918253		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.48607712891918253 | validation: 0.6059731945830475]
	TIME [epoch: 6.41 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724958553888843		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.5724958553888843 | validation: 0.46891659249291406]
	TIME [epoch: 6.38 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7407945005121062		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.7407945005121062 | validation: 0.6466817769772467]
	TIME [epoch: 6.38 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5123702085507427		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.5123702085507427 | validation: 0.4582443445806483]
	TIME [epoch: 6.38 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6368015793875367		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.6368015793875367 | validation: 0.4280679861206081]
	TIME [epoch: 6.38 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5408709124505775		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.5408709124505775 | validation: 0.6733031052623432]
	TIME [epoch: 6.37 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5193822675754558		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.5193822675754558 | validation: 0.4050778392079793]
	TIME [epoch: 6.38 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46152248256343137		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.46152248256343137 | validation: 0.41647419924820844]
	TIME [epoch: 6.42 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4320118879757939		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.4320118879757939 | validation: 0.46281122513389]
	TIME [epoch: 6.39 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4973476625780104		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.4973476625780104 | validation: 0.8869517397268584]
	TIME [epoch: 6.38 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4933958326238235		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.4933958326238235 | validation: 0.8440739009916512]
	TIME [epoch: 6.39 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7598533630108328		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.7598533630108328 | validation: 0.5942150589695094]
	TIME [epoch: 6.38 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4672887487295667		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.4672887487295667 | validation: 0.41733604086245296]
	TIME [epoch: 6.39 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42582110276753954		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.42582110276753954 | validation: 0.32039486377796783]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3781741445771374		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.3781741445771374 | validation: 0.36009770596671387]
	TIME [epoch: 6.43 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45434078725807653		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.45434078725807653 | validation: 0.48011431469190097]
	TIME [epoch: 6.38 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5345746415175784		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.5345746415175784 | validation: 0.5085191934304887]
	TIME [epoch: 6.38 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49634048234653316		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.49634048234653316 | validation: 0.45459395827757076]
	TIME [epoch: 6.39 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.396023416226671		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.396023416226671 | validation: 0.5355281969254909]
	TIME [epoch: 6.37 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8925196979117522		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.8925196979117522 | validation: 0.5720890965513157]
	TIME [epoch: 6.39 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4694416140160198		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.4694416140160198 | validation: 0.3364751482688322]
	TIME [epoch: 6.39 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824707643959675		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.3824707643959675 | validation: 0.7234168567737399]
	TIME [epoch: 6.42 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6767269097183054		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6767269097183054 | validation: 0.42523459384351997]
	TIME [epoch: 6.41 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46078234514143546		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.46078234514143546 | validation: 0.3514604164546023]
	TIME [epoch: 6.38 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906289357183952		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.3906289357183952 | validation: 0.6298523946509756]
	TIME [epoch: 6.39 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4207537787206954		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.4207537787206954 | validation: 0.5997160094658852]
	TIME [epoch: 6.39 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46038105251736783		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.46038105251736783 | validation: 0.407261164937755]
	TIME [epoch: 6.37 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4874046854146963		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.4874046854146963 | validation: 0.45074124983969155]
	TIME [epoch: 6.39 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47667878337876907		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.47667878337876907 | validation: 0.6653364864015214]
	TIME [epoch: 6.41 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104835158156703		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.5104835158156703 | validation: 1.0880184476578818]
	TIME [epoch: 6.41 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7117398070783698		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.7117398070783698 | validation: 0.8144721299046759]
	TIME [epoch: 6.39 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6547813770269599		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.6547813770269599 | validation: 0.32448862374682363]
	TIME [epoch: 6.39 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40598444847387805		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.40598444847387805 | validation: 0.38499113516532335]
	TIME [epoch: 6.39 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38608131931543377		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.38608131931543377 | validation: 0.40100712572683955]
	TIME [epoch: 6.39 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4105166431144869		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.4105166431144869 | validation: 0.37748606927316836]
	TIME [epoch: 6.39 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3852688199682784		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.3852688199682784 | validation: 0.4441215092151213]
	TIME [epoch: 6.39 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039304277912071		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.5039304277912071 | validation: 0.3543807591851888]
	TIME [epoch: 6.43 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440408540093761		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.3440408540093761 | validation: 0.32288643422078844]
	TIME [epoch: 6.39 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32775478212813725		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.32775478212813725 | validation: 0.43408197704825413]
	TIME [epoch: 6.38 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.407131681740153		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.407131681740153 | validation: 0.41322546053147335]
	TIME [epoch: 6.38 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4273696870891017		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.4273696870891017 | validation: 0.30295200822152996]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555627448279848		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.3555627448279848 | validation: 0.43457617324852676]
	TIME [epoch: 6.38 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31999046462060476		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.31999046462060476 | validation: 0.6523965185601014]
	TIME [epoch: 6.39 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45602602508842943		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.45602602508842943 | validation: 0.2586047928627246]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.327671403887711		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.327671403887711 | validation: 0.27472905187613256]
	TIME [epoch: 6.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49193788000125255		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.49193788000125255 | validation: 0.8756144170402113]
	TIME [epoch: 6.39 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5298430826446286		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5298430826446286 | validation: 0.27731277945159505]
	TIME [epoch: 6.38 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455440354729058		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3455440354729058 | validation: 0.4153876961684668]
	TIME [epoch: 6.39 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2955329169646069		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.2955329169646069 | validation: 0.82428216516807]
	TIME [epoch: 6.39 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033655668735815		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.5033655668735815 | validation: 0.39280524129309513]
	TIME [epoch: 6.39 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37210615685794857		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.37210615685794857 | validation: 0.29490735673515206]
	TIME [epoch: 6.43 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34540303875499456		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.34540303875499456 | validation: 0.3206373954683687]
	TIME [epoch: 6.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39854936087030973		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.39854936087030973 | validation: 0.23918827188156505]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43389599466422535		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.43389599466422535 | validation: 0.303071090031849]
	TIME [epoch: 6.37 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3111212371781631		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.3111212371781631 | validation: 0.22744952666559873]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33114919437614776		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.33114919437614776 | validation: 0.22583471872197092]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38514190145574234		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.38514190145574234 | validation: 0.3001968582686933]
	TIME [epoch: 6.39 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31532016289524206		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.31532016289524206 | validation: 0.5038742886984121]
	TIME [epoch: 6.43 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3936205346241249		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.3936205346241249 | validation: 0.3719747155767223]
	TIME [epoch: 6.39 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2954146784518605		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.2954146784518605 | validation: 0.24357563258730036]
	TIME [epoch: 6.39 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2504970288507534		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.2504970288507534 | validation: 0.1697607281952473]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843339553276763		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.2843339553276763 | validation: 0.265085247205494]
	TIME [epoch: 6.38 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3536499438230042		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.3536499438230042 | validation: 0.2626195098656528]
	TIME [epoch: 6.39 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3277832581297416		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.3277832581297416 | validation: 0.3702284043969212]
	TIME [epoch: 6.37 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5364696190594573		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.5364696190594573 | validation: 0.27410679653686204]
	TIME [epoch: 6.41 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24615682726121665		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.24615682726121665 | validation: 0.23018019668594059]
	TIME [epoch: 6.39 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32944000019134445		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.32944000019134445 | validation: 0.31541555490283346]
	TIME [epoch: 6.39 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535226555238645		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.2535226555238645 | validation: 0.32776976215052983]
	TIME [epoch: 6.38 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28218009811295086		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.28218009811295086 | validation: 0.4313599173674899]
	TIME [epoch: 6.39 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3932505186960019		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.3932505186960019 | validation: 0.6325463853779391]
	TIME [epoch: 6.38 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30173055918812636		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.30173055918812636 | validation: 0.19056029572142413]
	TIME [epoch: 6.39 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23474478550632658		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.23474478550632658 | validation: 0.4350303478395739]
	TIME [epoch: 6.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3606712555257529		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.3606712555257529 | validation: 0.39039307488548686]
	TIME [epoch: 6.41 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27974570334042465		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.27974570334042465 | validation: 0.3261193846687676]
	TIME [epoch: 6.38 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3828494168998965		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3828494168998965 | validation: 0.32402524624632356]
	TIME [epoch: 6.39 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34897891319720054		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.34897891319720054 | validation: 0.28127356275165144]
	TIME [epoch: 6.37 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28041640833449855		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.28041640833449855 | validation: 0.16009442785276537]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2662044577485188		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.2662044577485188 | validation: 0.22396244319216632]
	TIME [epoch: 6.38 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3699717514951808		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.3699717514951808 | validation: 0.22612454702427365]
	TIME [epoch: 6.39 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3389534554774015		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.3389534554774015 | validation: 0.29343844014091347]
	TIME [epoch: 6.42 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3833226190649842		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.3833226190649842 | validation: 0.25394652636336973]
	TIME [epoch: 6.38 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2809512049982304		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.2809512049982304 | validation: 0.3891188335853047]
	TIME [epoch: 6.39 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32584189405622743		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.32584189405622743 | validation: 0.4595351948205503]
	TIME [epoch: 6.38 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40085338133037446		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.40085338133037446 | validation: 2.233181530989401]
	TIME [epoch: 6.38 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1041847871822483		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.1041847871822483 | validation: 0.4045121256639693]
	TIME [epoch: 6.38 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3647108483293175		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.3647108483293175 | validation: 0.2543123361124261]
	TIME [epoch: 6.39 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29768280825647525		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.29768280825647525 | validation: 0.3450939037710204]
	TIME [epoch: 6.42 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29386132734019516		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.29386132734019516 | validation: 0.417057360231823]
	TIME [epoch: 6.38 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3223049424810353		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.3223049424810353 | validation: 0.5836680222660349]
	TIME [epoch: 6.38 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38158945061378646		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.38158945061378646 | validation: 0.3020579551468677]
	TIME [epoch: 6.38 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3129189814290876		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3129189814290876 | validation: 0.24207258339692087]
	TIME [epoch: 6.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24856716759827313		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.24856716759827313 | validation: 0.20160774217981925]
	TIME [epoch: 6.38 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24856440976329072		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.24856440976329072 | validation: 0.18315100211980645]
	TIME [epoch: 6.39 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1978653999361415		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.1978653999361415 | validation: 0.2682858025498491]
	TIME [epoch: 6.42 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25583216817806437		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.25583216817806437 | validation: 0.26508630333344757]
	TIME [epoch: 6.39 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24704817193996675		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.24704817193996675 | validation: 0.12870275228185077]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1628384508653487		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.1628384508653487 | validation: 0.15445333919031942]
	TIME [epoch: 6.38 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28658709809149585		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.28658709809149585 | validation: 0.3848137321318245]
	TIME [epoch: 6.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31658212354008486		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.31658212354008486 | validation: 0.36323940393810367]
	TIME [epoch: 6.38 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40845661031088565		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.40845661031088565 | validation: 0.28098805029438195]
	TIME [epoch: 6.39 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23992045056340405		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.23992045056340405 | validation: 0.1815080795682232]
	TIME [epoch: 6.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2784929625421595		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.2784929625421595 | validation: 0.34994788600278354]
	TIME [epoch: 6.41 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2895247707523635		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.2895247707523635 | validation: 0.17627203797231025]
	TIME [epoch: 6.38 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1942481259351103		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.1942481259351103 | validation: 0.16551392462008302]
	TIME [epoch: 6.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2323841115672603		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.2323841115672603 | validation: 0.26766400522157585]
	TIME [epoch: 6.38 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26413462877819766		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.26413462877819766 | validation: 0.2150858558369564]
	TIME [epoch: 6.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532196321036965		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.2532196321036965 | validation: 0.15497989694282416]
	TIME [epoch: 6.39 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1979031209040343		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.1979031209040343 | validation: 0.16441318250638343]
	TIME [epoch: 6.41 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4884796117244714		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.4884796117244714 | validation: 0.2109111918826467]
	TIME [epoch: 6.41 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282070337601411		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.282070337601411 | validation: 0.27249187223767757]
	TIME [epoch: 6.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2448382803878168		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2448382803878168 | validation: 0.21218682138817663]
	TIME [epoch: 6.38 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20479119937248919		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.20479119937248919 | validation: 0.23920720945722054]
	TIME [epoch: 6.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19891422781573165		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.19891422781573165 | validation: 0.21237352379635724]
	TIME [epoch: 6.39 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2331476042914848		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.2331476042914848 | validation: 0.18226590406333198]
	TIME [epoch: 6.39 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1759989651300932		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.1759989651300932 | validation: 0.14672563372327727]
	TIME [epoch: 6.39 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22909047258152065		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.22909047258152065 | validation: 0.17443874634954504]
	TIME [epoch: 6.43 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2188104387396115		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.2188104387396115 | validation: 0.20879399453179417]
	TIME [epoch: 6.38 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17256563286630144		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.17256563286630144 | validation: 0.16699634964751983]
	TIME [epoch: 6.41 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20276544274062022		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.20276544274062022 | validation: 0.2536298672228816]
	TIME [epoch: 6.38 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21393845515422572		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.21393845515422572 | validation: 0.28755230307615043]
	TIME [epoch: 6.4 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22428903275508819		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.22428903275508819 | validation: 0.14114150331965344]
	TIME [epoch: 6.38 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17940261296542456		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.17940261296542456 | validation: 0.2856199873614974]
	TIME [epoch: 6.38 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2861852623820335		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.2861852623820335 | validation: 0.1973297006076335]
	TIME [epoch: 6.43 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27552086833148015		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.27552086833148015 | validation: 0.2633631591678819]
	TIME [epoch: 6.39 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24668061097669763		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.24668061097669763 | validation: 0.27974122299799176]
	TIME [epoch: 6.39 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3485637636249991		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.3485637636249991 | validation: 0.45133953358181655]
	TIME [epoch: 6.38 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3979825526988637		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.3979825526988637 | validation: 0.19872602766381797]
	TIME [epoch: 6.39 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20432692877900765		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.20432692877900765 | validation: 0.13583822229195736]
	TIME [epoch: 6.39 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.338202897916268		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.338202897916268 | validation: 0.32726628717558043]
	TIME [epoch: 6.39 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34237286461319455		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.34237286461319455 | validation: 0.1674893759972811]
	TIME [epoch: 6.41 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19466735409722197		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.19466735409722197 | validation: 0.23174800245026478]
	TIME [epoch: 6.42 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20079686681630785		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.20079686681630785 | validation: 0.15824241139115006]
	TIME [epoch: 6.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16955576083475885		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.16955576083475885 | validation: 0.14454322889695254]
	TIME [epoch: 6.39 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2073809781823564		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.2073809781823564 | validation: 0.12380022105979388]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25204738092190904		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.25204738092190904 | validation: 0.44618964144067974]
	TIME [epoch: 6.39 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28937156429718913		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.28937156429718913 | validation: 0.4879096680504759]
	TIME [epoch: 6.39 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005857833490242		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.3005857833490242 | validation: 0.23475324145945564]
	TIME [epoch: 6.4 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32187145872842143		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.32187145872842143 | validation: 0.24940944246997462]
	TIME [epoch: 6.41 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2187975425577246		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.2187975425577246 | validation: 0.17360376982985615]
	TIME [epoch: 6.39 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1775019396223989		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.1775019396223989 | validation: 0.21164712458908952]
	TIME [epoch: 6.39 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17749573881023678		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.17749573881023678 | validation: 0.1762475248339221]
	TIME [epoch: 6.39 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074384170559529		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.3074384170559529 | validation: 0.31081216449976523]
	TIME [epoch: 6.39 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27454181716034537		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.27454181716034537 | validation: 0.15977735745605487]
	TIME [epoch: 6.39 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22285649532021262		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.22285649532021262 | validation: 0.34008931149196997]
	TIME [epoch: 6.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2892260942830273		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.2892260942830273 | validation: 0.15897944374241818]
	TIME [epoch: 6.43 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29968226680893945		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.29968226680893945 | validation: 0.1995344488005329]
	TIME [epoch: 6.39 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28904133513256336		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.28904133513256336 | validation: 0.12796429033677084]
	TIME [epoch: 6.39 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19431626075810188		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.19431626075810188 | validation: 0.37543418188743843]
	TIME [epoch: 6.39 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28605711177272475		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.28605711177272475 | validation: 0.12929838271290653]
	TIME [epoch: 6.38 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18830881261821256		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.18830881261821256 | validation: 0.30283730072890325]
	TIME [epoch: 6.39 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20697076502446993		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.20697076502446993 | validation: 0.11932339656922673]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1837332454224813		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.1837332454224813 | validation: 0.26875737319712206]
	TIME [epoch: 6.43 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18290618340075965		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.18290618340075965 | validation: 0.12042508385867186]
	TIME [epoch: 6.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15952885847973725		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.15952885847973725 | validation: 0.12685013513639692]
	TIME [epoch: 6.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21643438648262384		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.21643438648262384 | validation: 0.20292534602519932]
	TIME [epoch: 6.39 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20314279755617531		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.20314279755617531 | validation: 0.17368854598488478]
	TIME [epoch: 6.39 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22406432929877867		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.22406432929877867 | validation: 0.14474679129771914]
	TIME [epoch: 6.38 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20329798694735685		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.20329798694735685 | validation: 0.21227705405492522]
	TIME [epoch: 6.39 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2320141842639702		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.2320141842639702 | validation: 0.18708798400377397]
	TIME [epoch: 6.42 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23251137375057773		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.23251137375057773 | validation: 0.3079107040964465]
	TIME [epoch: 6.39 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2905808930239921		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.2905808930239921 | validation: 0.24968816688873138]
	TIME [epoch: 6.38 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17887758150219335		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.17887758150219335 | validation: 0.13871257521557617]
	TIME [epoch: 6.38 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13364719746665477		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.13364719746665477 | validation: 0.1390595733893906]
	TIME [epoch: 6.39 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30011117959414174		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.30011117959414174 | validation: 0.19174991894431923]
	TIME [epoch: 6.39 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15886455502185778		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.15886455502185778 | validation: 0.20164967075679227]
	TIME [epoch: 6.39 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20230987449648946		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.20230987449648946 | validation: 0.2851212524481108]
	TIME [epoch: 6.41 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2151572528795287		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.2151572528795287 | validation: 0.20350617462533438]
	TIME [epoch: 6.41 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30015432505771156		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.30015432505771156 | validation: 0.2844634797975092]
	TIME [epoch: 6.38 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977271345500628		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.2977271345500628 | validation: 0.20953383634792858]
	TIME [epoch: 6.37 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638372187584365		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.1638372187584365 | validation: 0.14753082668945416]
	TIME [epoch: 6.39 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12168633160150068		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.12168633160150068 | validation: 0.11525800092066549]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20337592360109102		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.20337592360109102 | validation: 0.1463921368107765]
	TIME [epoch: 6.39 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13464860835427003		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.13464860835427003 | validation: 0.1150759606756067]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31007791261177126		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.31007791261177126 | validation: 0.15482287459657162]
	TIME [epoch: 6.4 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18578735089555665		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.18578735089555665 | validation: 0.2474933112284235]
	TIME [epoch: 6.39 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17946040994784554		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.17946040994784554 | validation: 0.08512416888420038]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13935692950736642		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.13935692950736642 | validation: 0.16237756969907213]
	TIME [epoch: 6.39 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15619454179179135		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.15619454179179135 | validation: 0.22445075541365042]
	TIME [epoch: 6.39 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22477840912658018		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.22477840912658018 | validation: 0.1647635036206215]
	TIME [epoch: 6.38 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254140150021499		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.1254140150021499 | validation: 0.08559580281351345]
	TIME [epoch: 6.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19963810013155792		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.19963810013155792 | validation: 0.11861322099474084]
	TIME [epoch: 6.43 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15504260737466388		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.15504260737466388 | validation: 0.21229001098298667]
	TIME [epoch: 6.39 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15545897604947112		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.15545897604947112 | validation: 0.14140329210651506]
	TIME [epoch: 6.39 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1405239635747107		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.1405239635747107 | validation: 0.1545437773778022]
	TIME [epoch: 6.39 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.187433343064503		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.187433343064503 | validation: 0.15519230964716535]
	TIME [epoch: 6.39 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14943735520878423		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.14943735520878423 | validation: 0.14385968718703696]
	TIME [epoch: 6.39 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131579243100281		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.1131579243100281 | validation: 0.17613617831771247]
	TIME [epoch: 6.39 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13091389040506396		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.13091389040506396 | validation: 0.13376299408431877]
	TIME [epoch: 6.43 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15452438855779346		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.15452438855779346 | validation: 0.21837862328317953]
	TIME [epoch: 6.4 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14378429354172553		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.14378429354172553 | validation: 0.12149081363194779]
	TIME [epoch: 6.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08467755797377428		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.08467755797377428 | validation: 0.07276087147552826]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323596009585806		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.1323596009585806 | validation: 0.16719527028120104]
	TIME [epoch: 6.39 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24547540538977905		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.24547540538977905 | validation: 0.18652595002529773]
	TIME [epoch: 6.39 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13009624367151482		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.13009624367151482 | validation: 0.08061398810618783]
	TIME [epoch: 6.39 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371414117897127		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.1371414117897127 | validation: 0.09100237802258555]
	TIME [epoch: 6.42 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1688351288884794		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.1688351288884794 | validation: 0.15644439467347332]
	TIME [epoch: 6.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21028445225083198		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.21028445225083198 | validation: 0.09498629387661123]
	TIME [epoch: 6.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14928332392174434		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.14928332392174434 | validation: 0.10848505220442257]
	TIME [epoch: 6.4 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17249392301290772		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.17249392301290772 | validation: 0.1855881389757939]
	TIME [epoch: 6.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16745979885850173		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.16745979885850173 | validation: 0.10637549035656645]
	TIME [epoch: 6.39 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10263001795475443		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.10263001795475443 | validation: 0.102737416115878]
	TIME [epoch: 6.4 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15847283671008972		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.15847283671008972 | validation: 0.134834624334907]
	TIME [epoch: 6.41 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13514918198642278		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.13514918198642278 | validation: 0.16452557229906084]
	TIME [epoch: 6.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17066606615846985		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.17066606615846985 | validation: 0.09575001209660602]
	TIME [epoch: 6.39 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960565474958309		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.1960565474958309 | validation: 0.15369055811458715]
	TIME [epoch: 6.39 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16711390081468774		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.16711390081468774 | validation: 0.18907451893971788]
	TIME [epoch: 6.39 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14884404256658398		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.14884404256658398 | validation: 0.2174721193696832]
	TIME [epoch: 6.39 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15460004662641555		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.15460004662641555 | validation: 0.09245306142851491]
	TIME [epoch: 6.39 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08080177407142901		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.08080177407142901 | validation: 0.30197088040743486]
	TIME [epoch: 6.41 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17568844929942612		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.17568844929942612 | validation: 0.12206751822204145]
	TIME [epoch: 6.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14324385698803999		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.14324385698803999 | validation: 0.160500787624555]
	TIME [epoch: 6.39 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3199306561580316		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.3199306561580316 | validation: 0.34464659499653627]
	TIME [epoch: 6.39 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2529443070881987		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.2529443070881987 | validation: 0.19977738805441697]
	TIME [epoch: 6.39 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32063382322110845		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.32063382322110845 | validation: 0.29584364905314126]
	TIME [epoch: 6.39 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2165276138473819		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.2165276138473819 | validation: 0.1414223989113006]
	TIME [epoch: 6.39 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789323963288285		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.2789323963288285 | validation: 0.792470679284616]
	TIME [epoch: 6.39 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037194298400055		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.5037194298400055 | validation: 0.2587672453763997]
	TIME [epoch: 6.41 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20201511746360426		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.20201511746360426 | validation: 0.11519204207673032]
	TIME [epoch: 6.39 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10582829161969287		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.10582829161969287 | validation: 0.11150812758483851]
	TIME [epoch: 6.39 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1715092061640412		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.1715092061640412 | validation: 0.17276552371676215]
	TIME [epoch: 6.39 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.178820111093271		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.178820111093271 | validation: 0.19993457857734775]
	TIME [epoch: 6.39 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1419902219717209		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.1419902219717209 | validation: 0.41464058828421885]
	TIME [epoch: 6.39 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3928105861997139		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.3928105861997139 | validation: 0.21181830827714646]
	TIME [epoch: 6.38 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16826094810399522		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.16826094810399522 | validation: 0.09815332889684325]
	TIME [epoch: 6.43 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17740882358832377		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.17740882358832377 | validation: 0.18219106351975584]
	TIME [epoch: 6.39 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11227627898604059		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.11227627898604059 | validation: 0.09543191997624918]
	TIME [epoch: 6.39 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09018774464523947		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.09018774464523947 | validation: 0.0992235327989054]
	TIME [epoch: 6.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07768436377685038		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.07768436377685038 | validation: 0.46222472798373654]
	TIME [epoch: 6.39 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2446524486597177		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.2446524486597177 | validation: 0.09830663452284992]
	TIME [epoch: 6.38 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12365329905818521		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.12365329905818521 | validation: 0.1580124834960941]
	TIME [epoch: 6.39 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1019212028644019		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.1019212028644019 | validation: 0.07181878766497017]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07878053052767002		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.07878053052767002 | validation: 0.1582015050583104]
	TIME [epoch: 6.39 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11717817456177551		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.11717817456177551 | validation: 0.18642022896838353]
	TIME [epoch: 6.4 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15939709518732897		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.15939709518732897 | validation: 0.20752045982759107]
	TIME [epoch: 6.39 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559730350162966		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.1559730350162966 | validation: 0.10030182444639062]
	TIME [epoch: 6.39 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12637746780529716		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.12637746780529716 | validation: 0.09696974225571117]
	TIME [epoch: 6.4 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663237642946298		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.1663237642946298 | validation: 0.1321761768508542]
	TIME [epoch: 6.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12294474436020601		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.12294474436020601 | validation: 0.11034071968551087]
	TIME [epoch: 6.43 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13475565355515437		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.13475565355515437 | validation: 0.13001905409287778]
	TIME [epoch: 6.42 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09639586752004642		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.09639586752004642 | validation: 0.07123754872517095]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355047352218607		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.11355047352218607 | validation: 0.11646850723758437]
	TIME [epoch: 6.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08974371855419572		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.08974371855419572 | validation: 0.1042533359767532]
	TIME [epoch: 6.41 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12472024771809154		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.12472024771809154 | validation: 0.09854057677963841]
	TIME [epoch: 6.41 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10943129644959086		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.10943129644959086 | validation: 0.09579152290179992]
	TIME [epoch: 6.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10742835252825161		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.10742835252825161 | validation: 0.07668643695702791]
	TIME [epoch: 6.43 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08152812885133552		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.08152812885133552 | validation: 0.12053037883783158]
	TIME [epoch: 6.41 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16543072083101393		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.16543072083101393 | validation: 0.2074785155533712]
	TIME [epoch: 6.41 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13452088737809242		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.13452088737809242 | validation: 0.10024690979315053]
	TIME [epoch: 6.39 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07087283226398364		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.07087283226398364 | validation: 0.13722286067041173]
	TIME [epoch: 6.41 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14493463234171272		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.14493463234171272 | validation: 0.14125678893785742]
	TIME [epoch: 6.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12945677366987798		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.12945677366987798 | validation: 0.1291693850500222]
	TIME [epoch: 6.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10445497452779431		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.10445497452779431 | validation: 0.07714228890475915]
	TIME [epoch: 6.41 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0885685003437665		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.0885685003437665 | validation: 0.05811768053632414]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10871037653429663		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.10871037653429663 | validation: 0.12509812653107305]
	TIME [epoch: 6.39 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20127516559900116		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.20127516559900116 | validation: 0.3587466247682251]
	TIME [epoch: 6.39 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20109254772613777		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.20109254772613777 | validation: 0.15437795635274285]
	TIME [epoch: 6.39 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2654778818024649		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.2654778818024649 | validation: 0.3178087718920061]
	TIME [epoch: 6.39 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3075467599081192		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.3075467599081192 | validation: 0.19681303888870091]
	TIME [epoch: 6.39 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16582184056912752		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.16582184056912752 | validation: 0.1401383835187746]
	TIME [epoch: 6.39 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11576385970735771		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.11576385970735771 | validation: 0.09661421447100495]
	TIME [epoch: 6.44 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09199205622369448		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.09199205622369448 | validation: 0.11038880571939824]
	TIME [epoch: 6.4 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0933928927900545		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.0933928927900545 | validation: 0.08110808872128449]
	TIME [epoch: 6.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08939119437935093		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.08939119437935093 | validation: 0.11186457022937088]
	TIME [epoch: 6.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13640642514105297		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.13640642514105297 | validation: 0.11098787414085802]
	TIME [epoch: 6.39 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13706050215609036		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.13706050215609036 | validation: 0.12566390535557545]
	TIME [epoch: 6.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08407195240558185		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.08407195240558185 | validation: 0.15617304865385775]
	TIME [epoch: 6.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10787617507308464		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.10787617507308464 | validation: 0.11785495933226624]
	TIME [epoch: 6.43 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15791389971471337		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.15791389971471337 | validation: 0.19319318327298057]
	TIME [epoch: 6.39 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10333752291641018		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.10333752291641018 | validation: 0.09622824998183159]
	TIME [epoch: 6.38 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08586146304456384		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.08586146304456384 | validation: 0.17733059980662388]
	TIME [epoch: 6.38 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17125569551947606		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.17125569551947606 | validation: 0.1298026054251509]
	TIME [epoch: 6.39 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10550883049397913		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.10550883049397913 | validation: 0.1043833655635617]
	TIME [epoch: 6.39 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08598307278458234		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.08598307278458234 | validation: 0.08612740478722368]
	TIME [epoch: 6.38 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16249862516061292		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.16249862516061292 | validation: 0.21031430701457823]
	TIME [epoch: 6.42 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1685489809012674		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.1685489809012674 | validation: 0.180100900728271]
	TIME [epoch: 6.41 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839673883094158		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.2839673883094158 | validation: 0.17326789377902926]
	TIME [epoch: 6.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17058932817534883		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.17058932817534883 | validation: 0.18781108085474163]
	TIME [epoch: 6.39 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14146661123097726		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.14146661123097726 | validation: 0.08604349801750054]
	TIME [epoch: 6.4 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08342758475316789		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.08342758475316789 | validation: 0.054425780656900596]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0922026145779517		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.0922026145779517 | validation: 0.0790186175902281]
	TIME [epoch: 6.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08771326949012671		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.08771326949012671 | validation: 0.17052829590265872]
	TIME [epoch: 6.4 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12667048468634204		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.12667048468634204 | validation: 0.15188062545693445]
	TIME [epoch: 6.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12430261886976836		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.12430261886976836 | validation: 0.09200664856151392]
	TIME [epoch: 6.39 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13759279955266168		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.13759279955266168 | validation: 0.11980448987139798]
	TIME [epoch: 6.39 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08406511677905112		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.08406511677905112 | validation: 0.1296274535952083]
	TIME [epoch: 6.38 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908040539514925		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.08908040539514925 | validation: 0.09751626291296837]
	TIME [epoch: 6.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10209122158218097		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.10209122158218097 | validation: 0.13079319159101702]
	TIME [epoch: 6.39 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15868582945569173		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.15868582945569173 | validation: 0.11877349780263476]
	TIME [epoch: 6.38 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368705539804847		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.1368705539804847 | validation: 0.13835654649440624]
	TIME [epoch: 6.43 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11957611763355531		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.11957611763355531 | validation: 0.08729634222581212]
	TIME [epoch: 6.38 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0951698329120163		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.0951698329120163 | validation: 0.062487081200951894]
	TIME [epoch: 6.38 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08547824264961779		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.08547824264961779 | validation: 0.06709312265196198]
	TIME [epoch: 6.4 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06301377553920197		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.06301377553920197 | validation: 0.04776761466289225]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08579617152932492		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.08579617152932492 | validation: 0.15974831183250782]
	TIME [epoch: 6.38 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14277855220793415		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.14277855220793415 | validation: 0.09353224227327676]
	TIME [epoch: 6.38 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09637607309363996		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.09637607309363996 | validation: 0.10511852168966997]
	TIME [epoch: 6.43 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07142153598640356		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.07142153598640356 | validation: 0.09185389669999165]
	TIME [epoch: 6.39 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09272131567106669		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.09272131567106669 | validation: 0.14678484319856633]
	TIME [epoch: 6.39 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1769911849210271		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.1769911849210271 | validation: 0.1433227256933199]
	TIME [epoch: 6.38 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15613746313749144		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.15613746313749144 | validation: 0.07703904031675665]
	TIME [epoch: 6.39 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124479478760258		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.124479478760258 | validation: 0.17411468603732508]
	TIME [epoch: 6.39 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10632702800076027		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.10632702800076027 | validation: 0.06627880798295432]
	TIME [epoch: 6.39 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356850686360638		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.1356850686360638 | validation: 0.1295027658751269]
	TIME [epoch: 6.43 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1045702088388536		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.1045702088388536 | validation: 0.08190200579150973]
	TIME [epoch: 6.39 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975084818362229		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.06975084818362229 | validation: 0.09915872577843139]
	TIME [epoch: 6.39 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10894456724294785		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.10894456724294785 | validation: 0.10949045044465486]
	TIME [epoch: 6.38 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1064609426705477		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1064609426705477 | validation: 0.11489537565827652]
	TIME [epoch: 6.38 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09288993557342443		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.09288993557342443 | validation: 0.09072991498558562]
	TIME [epoch: 6.38 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09600494123238841		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.09600494123238841 | validation: 0.10448885405307998]
	TIME [epoch: 6.38 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09439450336738356		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.09439450336738356 | validation: 0.09821555622880165]
	TIME [epoch: 6.4 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960787109102062		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.0960787109102062 | validation: 0.14200251886639187]
	TIME [epoch: 6.41 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15192653578578258		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.15192653578578258 | validation: 0.11304372713055212]
	TIME [epoch: 6.38 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12960338990793038		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.12960338990793038 | validation: 0.1287896594697073]
	TIME [epoch: 6.38 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16774733033815514		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.16774733033815514 | validation: 0.282651245886949]
	TIME [epoch: 6.38 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16626118999216632		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.16626118999216632 | validation: 0.07494949592334216]
	TIME [epoch: 6.38 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09327600717511353		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.09327600717511353 | validation: 0.14299170847887133]
	TIME [epoch: 6.38 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09071472749357865		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.09071472749357865 | validation: 0.11038365260571736]
	TIME [epoch: 6.39 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0739125614319872		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.0739125614319872 | validation: 0.0878688438450732]
	TIME [epoch: 6.43 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08925361280053495		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.08925361280053495 | validation: 0.31235946632245004]
	TIME [epoch: 6.39 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19308803340475172		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.19308803340475172 | validation: 0.08033311075056432]
	TIME [epoch: 6.39 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07095385167596642		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.07095385167596642 | validation: 0.07930836223499538]
	TIME [epoch: 6.4 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08613354632012032		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.08613354632012032 | validation: 0.0870097003386865]
	TIME [epoch: 6.4 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08136441764011954		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.08136441764011954 | validation: 0.08482866524933375]
	TIME [epoch: 6.39 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10028764147877067		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.10028764147877067 | validation: 0.08184085995661718]
	TIME [epoch: 6.38 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060285679926908156		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.060285679926908156 | validation: 0.12830948642871273]
	TIME [epoch: 6.44 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12315173396786316		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.12315173396786316 | validation: 0.07191201039060513]
	TIME [epoch: 6.39 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09489912298842088		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.09489912298842088 | validation: 0.08962051914440856]
	TIME [epoch: 6.39 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08825757917067034		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.08825757917067034 | validation: 0.05799108820210492]
	TIME [epoch: 6.39 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0838918384858032		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.0838918384858032 | validation: 0.0928311683409018]
	TIME [epoch: 6.38 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761188553797373		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.0761188553797373 | validation: 0.06492723827445923]
	TIME [epoch: 6.4 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06528914251239928		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.06528914251239928 | validation: 0.08359657481942008]
	TIME [epoch: 6.4 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765179845399214		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.0765179845399214 | validation: 0.1242281624160735]
	TIME [epoch: 6.43 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08452576453034809		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.08452576453034809 | validation: 0.06168479855653468]
	TIME [epoch: 6.4 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06461558035719335		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.06461558035719335 | validation: 0.07619463393228025]
	TIME [epoch: 6.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09653034373644387		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.09653034373644387 | validation: 0.0705764473888206]
	TIME [epoch: 6.39 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06622271336167884		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.06622271336167884 | validation: 0.1940059653698601]
	TIME [epoch: 6.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17280407415163476		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.17280407415163476 | validation: 0.09704951582514636]
	TIME [epoch: 6.39 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10571019375201503		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.10571019375201503 | validation: 0.3343707752005953]
	TIME [epoch: 6.39 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31328670015714394		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.31328670015714394 | validation: 0.1899296433972374]
	TIME [epoch: 6.39 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15343756505111592		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.15343756505111592 | validation: 0.2316531171915088]
	TIME [epoch: 6.42 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26694826521707765		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.26694826521707765 | validation: 0.3436858071181302]
	TIME [epoch: 6.39 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25418346449409795		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.25418346449409795 | validation: 0.23977619674259587]
	TIME [epoch: 6.39 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23370823867110546		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.23370823867110546 | validation: 0.1486388972413822]
	TIME [epoch: 6.39 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11246843938891028		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.11246843938891028 | validation: 0.06717660547349107]
	TIME [epoch: 6.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06274830931511881		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.06274830931511881 | validation: 0.07410342896811527]
	TIME [epoch: 6.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0543220725333674		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.0543220725333674 | validation: 0.05316000855444305]
	TIME [epoch: 6.41 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04650146282656509		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.04650146282656509 | validation: 0.051607741526141455]
	TIME [epoch: 6.43 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060457142845813605		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.060457142845813605 | validation: 0.12470223233726532]
	TIME [epoch: 6.41 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11501026735757233		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.11501026735757233 | validation: 0.0779992554216467]
	TIME [epoch: 6.39 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08398545246575152		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.08398545246575152 | validation: 0.08191218158984068]
	TIME [epoch: 6.4 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09917050105501012		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.09917050105501012 | validation: 0.08166937556127739]
	TIME [epoch: 6.39 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08715968985275396		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.08715968985275396 | validation: 0.07149126040929137]
	TIME [epoch: 6.39 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06913970821733158		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.06913970821733158 | validation: 0.07412535963340897]
	TIME [epoch: 6.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059955233370402976		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.059955233370402976 | validation: 0.06053159700174085]
	TIME [epoch: 6.44 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04995945574227124		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.04995945574227124 | validation: 0.05810342260733057]
	TIME [epoch: 6.41 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06346325591882508		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.06346325591882508 | validation: 0.09483050015898364]
	TIME [epoch: 6.41 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05184876404792172		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.05184876404792172 | validation: 0.053160755413777634]
	TIME [epoch: 6.39 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05012657607414911		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.05012657607414911 | validation: 0.06507067827036102]
	TIME [epoch: 6.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873260753404422		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.05873260753404422 | validation: 0.08266852246388388]
	TIME [epoch: 6.38 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08708907536809968		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.08708907536809968 | validation: 0.06602293207666098]
	TIME [epoch: 6.39 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07333368379411201		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.07333368379411201 | validation: 0.11467564520928508]
	TIME [epoch: 6.42 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08614451795495383		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.08614451795495383 | validation: 0.2789197892994317]
	TIME [epoch: 6.39 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13790254895706186		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.13790254895706186 | validation: 0.10039279420013912]
	TIME [epoch: 6.38 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08710125790459755		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.08710125790459755 | validation: 0.07387608951152355]
	TIME [epoch: 6.38 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06713524253624346		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.06713524253624346 | validation: 0.06358517873479416]
	TIME [epoch: 6.39 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08622886380510303		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.08622886380510303 | validation: 0.12507200763101733]
	TIME [epoch: 6.41 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11353731481690275		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.11353731481690275 | validation: 0.08063017134804847]
	TIME [epoch: 6.4 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05234379693618177		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.05234379693618177 | validation: 0.04880390194269726]
	TIME [epoch: 6.43 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07885210400915259		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.07885210400915259 | validation: 0.06952401880423387]
	TIME [epoch: 6.42 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641742456052452		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.06641742456052452 | validation: 0.05778818863518676]
	TIME [epoch: 6.41 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07063613821989716		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.07063613821989716 | validation: 0.09827760542447063]
	TIME [epoch: 6.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06849367284923294		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.06849367284923294 | validation: 0.06726082838777309]
	TIME [epoch: 6.38 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782346238668111		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.0782346238668111 | validation: 0.09029987027201897]
	TIME [epoch: 6.39 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08613984965931748		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.08613984965931748 | validation: 0.07107725850799364]
	TIME [epoch: 6.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08307654459906937		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.08307654459906937 | validation: 0.07077641399522663]
	TIME [epoch: 6.4 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07992467217380538		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.07992467217380538 | validation: 0.10391813551266274]
	TIME [epoch: 6.43 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08073427779109744		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.08073427779109744 | validation: 0.1277668518356451]
	TIME [epoch: 6.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10580283249930673		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.10580283249930673 | validation: 0.052790360215111125]
	TIME [epoch: 6.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06803528060342755		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.06803528060342755 | validation: 0.07147960579800032]
	TIME [epoch: 6.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09333953056767702		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.09333953056767702 | validation: 0.11602906052782407]
	TIME [epoch: 6.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07277929866079785		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.07277929866079785 | validation: 0.061319380940230504]
	TIME [epoch: 6.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06120343606873045		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.06120343606873045 | validation: 0.061654111478984176]
	TIME [epoch: 6.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053685981477437084		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.053685981477437084 | validation: 0.0559464300805764]
	TIME [epoch: 6.45 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0517813147434522		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.0517813147434522 | validation: 0.07492022098326334]
	TIME [epoch: 6.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06802194942045664		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.06802194942045664 | validation: 0.0560204530980688]
	TIME [epoch: 6.4 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04924658473405879		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.04924658473405879 | validation: 0.04745152642531094]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04978325562507151		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.04978325562507151 | validation: 0.0385608291318051]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05629298583017214		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.05629298583017214 | validation: 0.05752036150378144]
	TIME [epoch: 6.38 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05573170922726457		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.05573170922726457 | validation: 0.05846171317843535]
	TIME [epoch: 6.38 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04856452718636611		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.04856452718636611 | validation: 0.07043725333091728]
	TIME [epoch: 6.42 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05600045231136291		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.05600045231136291 | validation: 0.06155289672096442]
	TIME [epoch: 6.38 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10221991016864132		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.10221991016864132 | validation: 0.17569882519764274]
	TIME [epoch: 6.37 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10915147491795055		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.10915147491795055 | validation: 0.09313182434198777]
	TIME [epoch: 6.37 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07436938158706		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.07436938158706 | validation: 0.08387807632974187]
	TIME [epoch: 6.37 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06776843511786301		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.06776843511786301 | validation: 0.05068297011526873]
	TIME [epoch: 6.37 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06037545042041468		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.06037545042041468 | validation: 0.1617850059460721]
	TIME [epoch: 6.37 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10170835578734617		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.10170835578734617 | validation: 0.0582772064474461]
	TIME [epoch: 6.4 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057204540066942325		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.057204540066942325 | validation: 0.12465361327428454]
	TIME [epoch: 6.37 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06840402932146554		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.06840402932146554 | validation: 0.08241663514071629]
	TIME [epoch: 6.37 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08433346587564258		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.08433346587564258 | validation: 0.07860801573398252]
	TIME [epoch: 6.37 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.072988249222943		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.072988249222943 | validation: 0.10765983102327255]
	TIME [epoch: 6.37 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0528089608566867		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.0528089608566867 | validation: 0.07094860717528088]
	TIME [epoch: 6.37 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057590705832979164		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.057590705832979164 | validation: 0.06703523390408814]
	TIME [epoch: 6.37 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06769552993441458		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.06769552993441458 | validation: 0.03982335081784034]
	TIME [epoch: 6.39 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04771011927118364		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.04771011927118364 | validation: 0.05327823387689702]
	TIME [epoch: 6.39 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05288107514096464		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.05288107514096464 | validation: 0.06954102662319699]
	TIME [epoch: 6.38 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06174975961741294		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.06174975961741294 | validation: 0.10961948793010243]
	TIME [epoch: 6.37 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06863027949211091		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.06863027949211091 | validation: 0.0531021924588554]
	TIME [epoch: 6.37 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0362403566692523		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.0362403566692523 | validation: 0.062366960094759526]
	TIME [epoch: 6.37 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05633027019480075		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.05633027019480075 | validation: 0.0693294681323002]
	TIME [epoch: 6.37 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05366970112795488		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.05366970112795488 | validation: 0.08620347140253523]
	TIME [epoch: 6.38 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07884223814534834		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.07884223814534834 | validation: 0.065981264683707]
	TIME [epoch: 6.4 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06512541798441007		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.06512541798441007 | validation: 0.05453317424715442]
	TIME [epoch: 6.38 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04179048703724916		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.04179048703724916 | validation: 0.10393831441614806]
	TIME [epoch: 6.38 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253977188497738		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.1253977188497738 | validation: 0.1445785258419322]
	TIME [epoch: 6.37 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06545362082164928		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.06545362082164928 | validation: 0.08545722044582606]
	TIME [epoch: 6.39 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04753628088617841		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.04753628088617841 | validation: 0.0493715074453557]
	TIME [epoch: 6.39 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052862258209370724		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.052862258209370724 | validation: 0.044156099019304625]
	TIME [epoch: 6.39 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605589238001028		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.05605589238001028 | validation: 0.06569484348689335]
	TIME [epoch: 6.43 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05230014759864672		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.05230014759864672 | validation: 0.049045888864418574]
	TIME [epoch: 6.4 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452932464673061		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.0452932464673061 | validation: 0.05216969227637138]
	TIME [epoch: 6.39 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07966361678629169		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.07966361678629169 | validation: 0.09022077889356861]
	TIME [epoch: 6.4 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789785553968866		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.07789785553968866 | validation: 0.03759654743415766]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_491.pth
	Model improved!!!
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030822486743433505		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.030822486743433505 | validation: 0.03740110106343552]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07475666328193362		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.07475666328193362 | validation: 0.11791808571025722]
	TIME [epoch: 6.39 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07416613671437325		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.07416613671437325 | validation: 0.08400711858497151]
	TIME [epoch: 6.43 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07708078578059063		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.07708078578059063 | validation: 0.09747067344541463]
	TIME [epoch: 6.39 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06719818635396346		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.06719818635396346 | validation: 0.05565873843857116]
	TIME [epoch: 6.4 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04746714124000073		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.04746714124000073 | validation: 0.06402971549998024]
	TIME [epoch: 6.39 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06048496701291981		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.06048496701291981 | validation: 0.0754195800877492]
	TIME [epoch: 6.39 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061369100791063246		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.061369100791063246 | validation: 0.08312936407918439]
	TIME [epoch: 6.39 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043600510014234005		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.043600510014234005 | validation: 0.03195602668209286]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_500.pth
	Model improved!!!
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051163581875530016		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.051163581875530016 | validation: 0.0791324083807868]
	TIME [epoch: 6.43 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390604151272693		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.06390604151272693 | validation: 0.047003645197298244]
	TIME [epoch: 6.41 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08798324841632682		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.08798324841632682 | validation: 0.15779908984411667]
	TIME [epoch: 6.41 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0705582553304114		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.0705582553304114 | validation: 0.07249748640038967]
	TIME [epoch: 6.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0692671314638188		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.0692671314638188 | validation: 0.058035604503716975]
	TIME [epoch: 6.41 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889429974778082		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.05889429974778082 | validation: 0.12271148838998627]
	TIME [epoch: 6.41 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07529643607573033		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.07529643607573033 | validation: 0.07455210203333695]
	TIME [epoch: 6.39 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07427123305863416		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.07427123305863416 | validation: 0.08536893815015201]
	TIME [epoch: 6.41 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07030656751810266		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.07030656751810266 | validation: 0.10800987127425417]
	TIME [epoch: 6.41 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06443613084482742		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.06443613084482742 | validation: 0.07664624025827158]
	TIME [epoch: 6.41 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05527070025693444		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.05527070025693444 | validation: 0.0644848351745475]
	TIME [epoch: 6.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05934617401470435		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.05934617401470435 | validation: 0.1128973739624078]
	TIME [epoch: 6.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07450381258485136		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.07450381258485136 | validation: 0.05464769529445862]
	TIME [epoch: 6.39 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052186926705741515		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.052186926705741515 | validation: 0.0440725132502941]
	TIME [epoch: 6.41 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04164378372841595		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.04164378372841595 | validation: 0.05269964041297679]
	TIME [epoch: 6.41 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055843629358941604		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.055843629358941604 | validation: 0.052259288551832594]
	TIME [epoch: 6.44 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06741869604783673		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.06741869604783673 | validation: 0.06457801234621463]
	TIME [epoch: 6.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05210731539456387		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.05210731539456387 | validation: 0.05412500867138826]
	TIME [epoch: 6.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047964039864602036		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.047964039864602036 | validation: 0.09467756966511008]
	TIME [epoch: 6.41 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08663392671448458		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.08663392671448458 | validation: 0.09851028332405154]
	TIME [epoch: 6.39 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187761771548038		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.11187761771548038 | validation: 0.06431812464738491]
	TIME [epoch: 6.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044400461048963405		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.044400461048963405 | validation: 0.040729196431383896]
	TIME [epoch: 6.4 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041071164926145265		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.041071164926145265 | validation: 0.08172127677982666]
	TIME [epoch: 6.44 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06585858552716288		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.06585858552716288 | validation: 0.09258566135083544]
	TIME [epoch: 6.41 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06737403259070113		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.06737403259070113 | validation: 0.1361154361890767]
	TIME [epoch: 6.39 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08844930821489841		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.08844930821489841 | validation: 0.07465846487305253]
	TIME [epoch: 6.41 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049134581528243515		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.049134581528243515 | validation: 0.039849260833402164]
	TIME [epoch: 6.4 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05002468362230025		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.05002468362230025 | validation: 0.061434620483920135]
	TIME [epoch: 6.41 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054474583563243306		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.054474583563243306 | validation: 0.05612992426715268]
	TIME [epoch: 6.41 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565608946446893		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.05565608946446893 | validation: 0.11797921430537248]
	TIME [epoch: 6.44 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14012867872054727		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.14012867872054727 | validation: 0.144883642122419]
	TIME [epoch: 6.4 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09351501170763382		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.09351501170763382 | validation: 0.07337945528850184]
	TIME [epoch: 6.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467045682197847		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.04467045682197847 | validation: 0.10349072712440792]
	TIME [epoch: 6.41 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07000749527579986		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.07000749527579986 | validation: 0.08411369981741167]
	TIME [epoch: 6.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661732784792282		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.03661732784792282 | validation: 0.053141906121629376]
	TIME [epoch: 6.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699042666285216		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.05699042666285216 | validation: 0.05085649418459541]
	TIME [epoch: 6.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05235123760891297		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.05235123760891297 | validation: 0.07438242009858506]
	TIME [epoch: 6.4 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05645461496358941		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.05645461496358941 | validation: 0.06072086077860773]
	TIME [epoch: 6.41 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05781523256027913		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.05781523256027913 | validation: 0.09884832955921727]
	TIME [epoch: 6.41 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062324964288483116		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.062324964288483116 | validation: 0.06318013826613837]
	TIME [epoch: 6.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04088453788972276		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.04088453788972276 | validation: 0.050185124259600186]
	TIME [epoch: 6.41 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04946381087759226		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.04946381087759226 | validation: 0.07313280367094581]
	TIME [epoch: 6.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056407582965527746		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.056407582965527746 | validation: 0.049112644185222654]
	TIME [epoch: 6.4 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04898821937230706		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.04898821937230706 | validation: 0.05317315487616801]
	TIME [epoch: 6.4 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05852987432693652		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.05852987432693652 | validation: 0.06976788281017139]
	TIME [epoch: 6.41 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06326138391124445		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.06326138391124445 | validation: 0.08475264430460207]
	TIME [epoch: 6.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06456999730458174		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.06456999730458174 | validation: 0.08965107040405122]
	TIME [epoch: 6.39 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04577945080636395		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.04577945080636395 | validation: 0.04545084458081766]
	TIME [epoch: 6.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042459402601039094		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.042459402601039094 | validation: 0.04335046830615229]
	TIME [epoch: 6.39 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03811976332878236		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.03811976332878236 | validation: 0.05048335201663866]
	TIME [epoch: 6.39 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043738200842349834		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.043738200842349834 | validation: 0.06848393435320736]
	TIME [epoch: 6.39 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05893394296457795		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.05893394296457795 | validation: 0.07186993873126164]
	TIME [epoch: 6.44 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05155656955974473		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.05155656955974473 | validation: 0.05977762860076021]
	TIME [epoch: 6.39 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06582114066691222		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.06582114066691222 | validation: 0.049057963294747944]
	TIME [epoch: 6.41 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06558781404174659		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.06558781404174659 | validation: 0.04523258072823954]
	TIME [epoch: 6.41 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046085110511506766		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.046085110511506766 | validation: 0.06601262484794314]
	TIME [epoch: 6.41 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08812736393303697		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.08812736393303697 | validation: 0.11408918807612213]
	TIME [epoch: 6.38 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08774753743506243		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.08774753743506243 | validation: 0.0637816608823171]
	TIME [epoch: 6.39 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04759617964202207		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.04759617964202207 | validation: 0.05442123981530583]
	TIME [epoch: 6.43 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055507938384015826		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.055507938384015826 | validation: 0.06312237284809687]
	TIME [epoch: 6.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06068171136040508		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.06068171136040508 | validation: 0.05467165946878946]
	TIME [epoch: 6.39 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03697640104140838		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.03697640104140838 | validation: 0.058571436365264316]
	TIME [epoch: 6.39 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05579879051128838		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.05579879051128838 | validation: 0.05700549196813844]
	TIME [epoch: 6.39 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05979275620773422		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.05979275620773422 | validation: 0.08419444676217719]
	TIME [epoch: 6.39 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055798057423428235		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.055798057423428235 | validation: 0.03293850274640157]
	TIME [epoch: 6.38 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04361660688120643		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.04361660688120643 | validation: 0.052371455261958605]
	TIME [epoch: 6.42 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04758641542635108		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.04758641542635108 | validation: 0.05379142360830644]
	TIME [epoch: 6.39 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032178008359129456		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.032178008359129456 | validation: 0.0647024731981478]
	TIME [epoch: 6.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07028418054513186		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.07028418054513186 | validation: 0.09354943598943369]
	TIME [epoch: 6.39 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12005124860554178		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.12005124860554178 | validation: 0.1299035848828376]
	TIME [epoch: 6.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13866893892997		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.13866893892997 | validation: 0.12648901749839186]
	TIME [epoch: 6.38 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0977111502250961		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.0977111502250961 | validation: 0.07358327478514949]
	TIME [epoch: 6.39 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07942003946324974		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.07942003946324974 | validation: 0.06060275099619115]
	TIME [epoch: 6.43 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038527056124005546		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.038527056124005546 | validation: 0.051831358532318406]
	TIME [epoch: 6.41 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054348131130217595		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.054348131130217595 | validation: 0.04966452841330067]
	TIME [epoch: 6.39 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045435174970729034		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.045435174970729034 | validation: 0.06084696733899175]
	TIME [epoch: 6.39 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07700702801950746		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.07700702801950746 | validation: 0.0649226494296261]
	TIME [epoch: 6.39 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04615438529845493		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.04615438529845493 | validation: 0.07331087024224439]
	TIME [epoch: 6.39 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05445741418448502		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.05445741418448502 | validation: 0.05509262985355214]
	TIME [epoch: 6.39 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059230397463684706		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.059230397463684706 | validation: 0.049882199399115236]
	TIME [epoch: 6.39 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04477121060130933		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.04477121060130933 | validation: 0.051879534123188534]
	TIME [epoch: 6.42 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046739784187981664		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.046739784187981664 | validation: 0.05076400786313939]
	TIME [epoch: 6.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050093938821703696		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.050093938821703696 | validation: 0.06729290344598036]
	TIME [epoch: 6.39 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0488285468648996		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.0488285468648996 | validation: 0.05369897293289516]
	TIME [epoch: 6.39 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054884136300709006		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.054884136300709006 | validation: 0.04632038750860115]
	TIME [epoch: 6.38 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04313555101043219		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.04313555101043219 | validation: 0.052697791087989485]
	TIME [epoch: 6.39 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02952083633808959		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.02952083633808959 | validation: 0.038769257192669875]
	TIME [epoch: 6.39 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04873574517916339		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.04873574517916339 | validation: 0.04948215378636933]
	TIME [epoch: 6.43 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0472712792479969		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.0472712792479969 | validation: 0.05066431344890186]
	TIME [epoch: 6.39 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0456733633764211		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.0456733633764211 | validation: 0.0480517355322333]
	TIME [epoch: 6.38 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0424708053883029		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.0424708053883029 | validation: 0.06541770903211384]
	TIME [epoch: 6.39 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05422596478151925		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.05422596478151925 | validation: 0.049183262533583925]
	TIME [epoch: 6.39 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04333612229952329		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.04333612229952329 | validation: 0.07155870008363649]
	TIME [epoch: 6.39 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06172913313201073		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.06172913313201073 | validation: 0.07438637798373925]
	TIME [epoch: 6.39 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06548683422836132		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.06548683422836132 | validation: 0.05689850082458252]
	TIME [epoch: 6.42 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04931525730848748		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.04931525730848748 | validation: 0.08929628083764744]
	TIME [epoch: 6.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0531111139851206		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.0531111139851206 | validation: 0.06728130187414903]
	TIME [epoch: 6.38 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05260105481530677		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.05260105481530677 | validation: 0.04660642605130648]
	TIME [epoch: 6.38 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059450392748474634		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.059450392748474634 | validation: 0.11595427329303293]
	TIME [epoch: 6.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06994196334866717		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.06994196334866717 | validation: 0.05816893288088625]
	TIME [epoch: 6.41 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05235007189814528		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.05235007189814528 | validation: 0.05549561668604346]
	TIME [epoch: 6.39 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050831828109415104		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.050831828109415104 | validation: 0.048681508150142036]
	TIME [epoch: 6.41 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054566899880114185		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.054566899880114185 | validation: 0.07183813836768481]
	TIME [epoch: 6.41 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911835265373287		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.06911835265373287 | validation: 0.07329662816701928]
	TIME [epoch: 6.39 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06163239431425575		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.06163239431425575 | validation: 0.06547150869803912]
	TIME [epoch: 6.39 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04362385203575947		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.04362385203575947 | validation: 0.08804193205556633]
	TIME [epoch: 6.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04903291495165836		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.04903291495165836 | validation: 0.043346753879925794]
	TIME [epoch: 6.39 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924243203743531		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.03924243203743531 | validation: 0.05541922095471831]
	TIME [epoch: 6.39 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05438174887397706		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.05438174887397706 | validation: 0.03276237122330925]
	TIME [epoch: 6.39 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02698155273411247		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.02698155273411247 | validation: 0.05792357955121004]
	TIME [epoch: 6.42 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04370948466277681		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.04370948466277681 | validation: 0.05681413447426465]
	TIME [epoch: 6.38 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05518426872901819		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.05518426872901819 | validation: 0.07837846118788346]
	TIME [epoch: 6.38 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058469752104178964		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.058469752104178964 | validation: 0.03544785486397843]
	TIME [epoch: 6.39 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036616616602454057		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.036616616602454057 | validation: 0.05649333225608918]
	TIME [epoch: 6.39 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042907337947212444		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.042907337947212444 | validation: 0.028129986207999228]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026422791179414575		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.026422791179414575 | validation: 0.0348090132462892]
	TIME [epoch: 6.38 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023361848575904492		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.023361848575904492 | validation: 0.049973331371301805]
	TIME [epoch: 6.42 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07380954435009907		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.07380954435009907 | validation: 0.10981712751902535]
	TIME [epoch: 6.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426962342875387		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.0426962342875387 | validation: 0.04630113150137997]
	TIME [epoch: 6.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026536122791089925		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.026536122791089925 | validation: 0.03999739888178556]
	TIME [epoch: 6.38 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035365221436794034		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.035365221436794034 | validation: 0.03828995909435613]
	TIME [epoch: 6.39 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034978875891054736		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.034978875891054736 | validation: 0.049451786993243235]
	TIME [epoch: 6.39 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04544704289044813		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.04544704289044813 | validation: 0.06068667877000682]
	TIME [epoch: 6.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04898307623424666		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.04898307623424666 | validation: 0.054026520923915404]
	TIME [epoch: 6.42 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04612545266944681		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.04612545266944681 | validation: 0.05183309098483123]
	TIME [epoch: 6.42 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03385108096980902		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.03385108096980902 | validation: 0.04244900373825195]
	TIME [epoch: 6.41 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03844671478146213		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.03844671478146213 | validation: 0.07101107606195381]
	TIME [epoch: 6.41 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430771486539595		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.03430771486539595 | validation: 0.03702460564446858]
	TIME [epoch: 6.42 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03623569424620542		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.03623569424620542 | validation: 0.05314904510821302]
	TIME [epoch: 6.41 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05046028691655408		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.05046028691655408 | validation: 0.0927428480207373]
	TIME [epoch: 6.41 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06744677777931002		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.06744677777931002 | validation: 0.06937289453772769]
	TIME [epoch: 6.43 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04832692517129639		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.04832692517129639 | validation: 0.05686300793184874]
	TIME [epoch: 6.42 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0454202617795469		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.0454202617795469 | validation: 0.05981723467204698]
	TIME [epoch: 6.41 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026493234007420933		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.026493234007420933 | validation: 0.036026910705544264]
	TIME [epoch: 6.41 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022120192897276188		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.022120192897276188 | validation: 0.03219615123700651]
	TIME [epoch: 6.41 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04954054184182177		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.04954054184182177 | validation: 0.10224977380016977]
	TIME [epoch: 6.41 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06622168834192327		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.06622168834192327 | validation: 0.0331247394401739]
	TIME [epoch: 6.41 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025583965150429384		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.025583965150429384 | validation: 0.054631476484190956]
	TIME [epoch: 6.43 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04749597180799191		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.04749597180799191 | validation: 0.04241412251626064]
	TIME [epoch: 6.43 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023050921636757333		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.023050921636757333 | validation: 0.04341890589127164]
	TIME [epoch: 6.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0298342603273717		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.0298342603273717 | validation: 0.03634991099134985]
	TIME [epoch: 6.42 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03479523153192343		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.03479523153192343 | validation: 0.038410819787491786]
	TIME [epoch: 6.41 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033098744878426456		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.033098744878426456 | validation: 0.05603542435651815]
	TIME [epoch: 6.41 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038927056975559156		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.038927056975559156 | validation: 0.04738357430880189]
	TIME [epoch: 6.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029340214604155042		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.029340214604155042 | validation: 0.058081336951795015]
	TIME [epoch: 6.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029988840742275067		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.029988840742275067 | validation: 0.055730464651458644]
	TIME [epoch: 6.42 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03226521905047743		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.03226521905047743 | validation: 0.046430144038422154]
	TIME [epoch: 6.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036346848576614924		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.036346848576614924 | validation: 0.04478416001112794]
	TIME [epoch: 6.39 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03879658263994265		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.03879658263994265 | validation: 0.07830935705186035]
	TIME [epoch: 6.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0485150061642278		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.0485150061642278 | validation: 0.04957026956586957]
	TIME [epoch: 6.39 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04407462257907351		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.04407462257907351 | validation: 0.04702155190212789]
	TIME [epoch: 6.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030566117132106566		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.030566117132106566 | validation: 0.035815242884543554]
	TIME [epoch: 6.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025665470067633575		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.025665470067633575 | validation: 0.051492509791961454]
	TIME [epoch: 6.44 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02558017951133001		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.02558017951133001 | validation: 0.032723584476843544]
	TIME [epoch: 6.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04310611447907493		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.04310611447907493 | validation: 0.05946813575332634]
	TIME [epoch: 6.41 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03935374530282097		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.03935374530282097 | validation: 0.04966418301642506]
	TIME [epoch: 6.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027575423277904486		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.027575423277904486 | validation: 0.06647262334986818]
	TIME [epoch: 6.41 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06866363501233018		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.06866363501233018 | validation: 0.058725860826603554]
	TIME [epoch: 6.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03997383610763553		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.03997383610763553 | validation: 0.04841396426026229]
	TIME [epoch: 6.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05637934822023073		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.05637934822023073 | validation: 0.06265918803531903]
	TIME [epoch: 6.43 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04789997643530354		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.04789997643530354 | validation: 0.05048635609417135]
	TIME [epoch: 6.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03929611920431979		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.03929611920431979 | validation: 0.04376057719144689]
	TIME [epoch: 6.39 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047415450910719574		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.047415450910719574 | validation: 0.047003385103712506]
	TIME [epoch: 6.4 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05314644634798868		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.05314644634798868 | validation: 0.050135709463677805]
	TIME [epoch: 6.39 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061787319874551716		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.061787319874551716 | validation: 0.05388093217567426]
	TIME [epoch: 6.41 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060759696957831566		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.060759696957831566 | validation: 0.0639375242105046]
	TIME [epoch: 6.41 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048444729313994205		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.048444729313994205 | validation: 0.04574905449180159]
	TIME [epoch: 6.42 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049195686147977424		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.049195686147977424 | validation: 0.038086211608665106]
	TIME [epoch: 6.42 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031986374829280295		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.031986374829280295 | validation: 0.04580119473091686]
	TIME [epoch: 6.39 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03645484842743913		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.03645484842743913 | validation: 0.06097842981957727]
	TIME [epoch: 6.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048323249964759396		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.048323249964759396 | validation: 0.054251366055209756]
	TIME [epoch: 6.39 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04230074872098145		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.04230074872098145 | validation: 0.04728096031158589]
	TIME [epoch: 6.4 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661723425807176		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.03661723425807176 | validation: 0.06948377376377181]
	TIME [epoch: 6.41 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03589478784665677		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.03589478784665677 | validation: 0.030973053493002656]
	TIME [epoch: 6.4 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237079860046278		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.03237079860046278 | validation: 0.03854586987207163]
	TIME [epoch: 6.44 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030440227292557645		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.030440227292557645 | validation: 0.04756397263393499]
	TIME [epoch: 6.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03632835353306368		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.03632835353306368 | validation: 0.038358392500967786]
	TIME [epoch: 6.39 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552146612114376		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.03552146612114376 | validation: 0.05036122968747384]
	TIME [epoch: 6.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03295474013439439		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.03295474013439439 | validation: 0.047792852035023724]
	TIME [epoch: 6.42 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02502571865896496		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.02502571865896496 | validation: 0.03301636350112011]
	TIME [epoch: 6.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04585453451251066		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.04585453451251066 | validation: 0.07501996321677408]
	TIME [epoch: 6.4 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05295392165380563		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.05295392165380563 | validation: 0.04616699825353805]
	TIME [epoch: 6.46 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03809033036669977		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.03809033036669977 | validation: 0.03335348614508261]
	TIME [epoch: 6.41 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026370277291909588		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.026370277291909588 | validation: 0.0429364041649338]
	TIME [epoch: 6.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04280060779875914		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.04280060779875914 | validation: 0.05565207053607556]
	TIME [epoch: 6.39 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0390659392009524		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.0390659392009524 | validation: 0.032409956043936365]
	TIME [epoch: 6.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029732069105110275		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.029732069105110275 | validation: 0.06080671464028221]
	TIME [epoch: 6.4 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04723646113512479		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.04723646113512479 | validation: 0.03165407953324412]
	TIME [epoch: 6.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030817231193150794		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.030817231193150794 | validation: 0.04735076398703808]
	TIME [epoch: 6.43 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024629068689012046		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.024629068689012046 | validation: 0.0498623785822972]
	TIME [epoch: 6.4 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05014411069663136		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.05014411069663136 | validation: 0.052399839874061986]
	TIME [epoch: 6.39 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046482278333806686		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.046482278333806686 | validation: 0.057362718302338855]
	TIME [epoch: 6.39 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06097669962078774		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.06097669962078774 | validation: 0.054610387341415205]
	TIME [epoch: 6.41 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07976733338047008		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.07976733338047008 | validation: 0.07777405449615094]
	TIME [epoch: 6.39 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07170845347112972		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.07170845347112972 | validation: 0.04920866392067239]
	TIME [epoch: 6.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05675078119872837		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.05675078119872837 | validation: 0.053526608328753174]
	TIME [epoch: 6.42 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04111179264633453		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.04111179264633453 | validation: 0.059105100952436804]
	TIME [epoch: 6.42 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286518648837364		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.05286518648837364 | validation: 0.05733037580099007]
	TIME [epoch: 6.41 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385602776714423		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.04385602776714423 | validation: 0.05211936686658003]
	TIME [epoch: 6.41 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04111067726187169		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.04111067726187169 | validation: 0.05542363607641018]
	TIME [epoch: 6.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043737695824928036		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.043737695824928036 | validation: 0.04886842124420291]
	TIME [epoch: 6.41 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052357586782934576		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.052357586782934576 | validation: 0.07187854085792034]
	TIME [epoch: 6.4 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0493912635096759		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.0493912635096759 | validation: 0.03552181416656047]
	TIME [epoch: 6.43 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02962188236441225		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.02962188236441225 | validation: 0.030630185793986305]
	TIME [epoch: 6.42 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045130073282115296		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.045130073282115296 | validation: 0.0651844484982453]
	TIME [epoch: 6.4 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057120971712123325		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.057120971712123325 | validation: 0.04447565789440887]
	TIME [epoch: 6.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032986372303378114		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.032986372303378114 | validation: 0.02098879178758935]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044805181864533666		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.044805181864533666 | validation: 0.07104047753203424]
	TIME [epoch: 6.4 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269023583673938		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.06269023583673938 | validation: 0.0632832535378068]
	TIME [epoch: 6.4 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062190141859989126		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.062190141859989126 | validation: 0.060216833257519566]
	TIME [epoch: 6.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565050180162349		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.05565050180162349 | validation: 0.0530833556868132]
	TIME [epoch: 6.44 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0552784693512573		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.0552784693512573 | validation: 0.030737322078992272]
	TIME [epoch: 6.39 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03619795994052359		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.03619795994052359 | validation: 0.041871755662478666]
	TIME [epoch: 6.41 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03258886127067208		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.03258886127067208 | validation: 0.02938495566808074]
	TIME [epoch: 6.4 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028008358123919413		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.028008358123919413 | validation: 0.0421262347329147]
	TIME [epoch: 6.41 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046602671565190115		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.046602671565190115 | validation: 0.07927124857092821]
	TIME [epoch: 6.4 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06223530261309144		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.06223530261309144 | validation: 0.06007575559713845]
	TIME [epoch: 6.41 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046660591668429646		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.046660591668429646 | validation: 0.04607948241198013]
	TIME [epoch: 6.45 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06868478940203114		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.06868478940203114 | validation: 0.03980632259329296]
	TIME [epoch: 6.41 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05009365787112994		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.05009365787112994 | validation: 0.03159474127808363]
	TIME [epoch: 6.39 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030466453918044437		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.030466453918044437 | validation: 0.04053166525875806]
	TIME [epoch: 6.39 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028591708775935445		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.028591708775935445 | validation: 0.044798708142039935]
	TIME [epoch: 6.39 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029399622524403486		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.029399622524403486 | validation: 0.047388947100612866]
	TIME [epoch: 6.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035210268648699646		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.035210268648699646 | validation: 0.02946534998801854]
	TIME [epoch: 6.39 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03165562182107935		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.03165562182107935 | validation: 0.029595549089084516]
	TIME [epoch: 6.44 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026966642593968845		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.026966642593968845 | validation: 0.03263014317990187]
	TIME [epoch: 6.41 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026021146109317925		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.026021146109317925 | validation: 0.03316523247350848]
	TIME [epoch: 6.41 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03389762668505415		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.03389762668505415 | validation: 0.040796124600293124]
	TIME [epoch: 6.41 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03333025819927937		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.03333025819927937 | validation: 0.04164883379703985]
	TIME [epoch: 6.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032172807245176384		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.032172807245176384 | validation: 0.049420393182313845]
	TIME [epoch: 6.41 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03200216194013282		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.03200216194013282 | validation: 0.048668261073351156]
	TIME [epoch: 6.41 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037498305617349084		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.037498305617349084 | validation: 0.022647141056715347]
	TIME [epoch: 6.43 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023180042044633472		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.023180042044633472 | validation: 0.052759519255373435]
	TIME [epoch: 6.43 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04616241415319627		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.04616241415319627 | validation: 0.047473212088211925]
	TIME [epoch: 6.41 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053641559929002734		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.053641559929002734 | validation: 0.0778053911954189]
	TIME [epoch: 6.39 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05154448394382651		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.05154448394382651 | validation: 0.06456273834848301]
	TIME [epoch: 6.41 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037730881192786156		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.037730881192786156 | validation: 0.03970599313199808]
	TIME [epoch: 6.41 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0234996371918367		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.0234996371918367 | validation: 0.03620137816170269]
	TIME [epoch: 6.41 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02293151511957847		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.02293151511957847 | validation: 0.030325197593431375]
	TIME [epoch: 6.44 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029096860186326765		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.029096860186326765 | validation: 0.04345170769401925]
	TIME [epoch: 6.43 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03295278642929276		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.03295278642929276 | validation: 0.040894901352001585]
	TIME [epoch: 6.42 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027774331644873758		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.027774331644873758 | validation: 0.033597184171288645]
	TIME [epoch: 6.4 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023378352794605352		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.023378352794605352 | validation: 0.05756349864633066]
	TIME [epoch: 6.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0503758418938515		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.0503758418938515 | validation: 0.07499926108270731]
	TIME [epoch: 6.39 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045203432096440795		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.045203432096440795 | validation: 0.049197096372510636]
	TIME [epoch: 6.42 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039296170685083245		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.039296170685083245 | validation: 0.05549124187529007]
	TIME [epoch: 6.42 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049546699732511815		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.049546699732511815 | validation: 0.06328005992916134]
	TIME [epoch: 6.45 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06075670457173243		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.06075670457173243 | validation: 0.04597732318609657]
	TIME [epoch: 6.42 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03499439168829991		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.03499439168829991 | validation: 0.03704699862348733]
	TIME [epoch: 6.42 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028215647967444323		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.028215647967444323 | validation: 0.03165864074250342]
	TIME [epoch: 6.41 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029151922297242047		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.029151922297242047 | validation: 0.04234076112783661]
	TIME [epoch: 6.41 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035392841341881504		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.035392841341881504 | validation: 0.04991239979614002]
	TIME [epoch: 6.42 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046521243418919625		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.046521243418919625 | validation: 0.035936100382723275]
	TIME [epoch: 6.42 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027450732313575227		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.027450732313575227 | validation: 0.040211558109863675]
	TIME [epoch: 6.45 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04474726478074863		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.04474726478074863 | validation: 0.05224148067515576]
	TIME [epoch: 6.42 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03174198056579747		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.03174198056579747 | validation: 0.05791196927346514]
	TIME [epoch: 6.42 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04037492674466038		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.04037492674466038 | validation: 0.05909473446990612]
	TIME [epoch: 6.41 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04560103426013484		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.04560103426013484 | validation: 0.047738298761752736]
	TIME [epoch: 6.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430754837715024		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.03430754837715024 | validation: 0.04430899674861812]
	TIME [epoch: 6.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027156934987282888		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.027156934987282888 | validation: 0.04642422358721328]
	TIME [epoch: 6.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04010955741516743		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.04010955741516743 | validation: 0.05857746735109978]
	TIME [epoch: 6.44 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048920804816841135		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.048920804816841135 | validation: 0.04977416668894458]
	TIME [epoch: 6.38 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04055668250881646		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.04055668250881646 | validation: 0.04221983573829991]
	TIME [epoch: 6.38 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03710481240437397		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.03710481240437397 | validation: 0.05244555178777255]
	TIME [epoch: 6.37 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03134698604179174		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.03134698604179174 | validation: 0.04088452179785802]
	TIME [epoch: 6.38 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026771349546482442		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.026771349546482442 | validation: 0.030526621188667384]
	TIME [epoch: 6.37 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024634583358485493		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.024634583358485493 | validation: 0.025817686071704912]
	TIME [epoch: 6.38 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026589910150693313		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.026589910150693313 | validation: 0.06617044341925672]
	TIME [epoch: 6.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05371410661391273		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.05371410661391273 | validation: 0.045610719989410714]
	TIME [epoch: 6.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022763297359510458		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.022763297359510458 | validation: 0.04090637407923033]
	TIME [epoch: 6.37 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048521198429128054		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.048521198429128054 | validation: 0.08930019819076751]
	TIME [epoch: 6.38 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06351691669594374		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.06351691669594374 | validation: 0.0678964725928005]
	TIME [epoch: 6.38 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046823189475820266		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.046823189475820266 | validation: 0.05569793627779848]
	TIME [epoch: 6.38 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04403615168835522		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.04403615168835522 | validation: 0.04054516306661417]
	TIME [epoch: 6.37 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029393315098697435		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.029393315098697435 | validation: 0.02529739787139153]
	TIME [epoch: 6.38 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030240046538573668		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.030240046538573668 | validation: 0.03811723507095326]
	TIME [epoch: 6.41 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03796124239605945		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.03796124239605945 | validation: 0.03988400994886988]
	TIME [epoch: 6.38 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150058126052021		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.03150058126052021 | validation: 0.06128707378399722]
	TIME [epoch: 6.37 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03671128952449387		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.03671128952449387 | validation: 0.05915958746333112]
	TIME [epoch: 6.38 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03648560548312982		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.03648560548312982 | validation: 0.038763564281459245]
	TIME [epoch: 6.38 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025644833280789262		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.025644833280789262 | validation: 0.04396783490242771]
	TIME [epoch: 6.38 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414620865980647		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.0414620865980647 | validation: 0.05018419835450876]
	TIME [epoch: 6.37 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031055455392477987		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.031055455392477987 | validation: 0.03675089313949708]
	TIME [epoch: 6.42 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034546850010390484		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.034546850010390484 | validation: 0.059925710994113354]
	TIME [epoch: 6.38 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05770722014260428		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.05770722014260428 | validation: 0.03586442412752943]
	TIME [epoch: 6.38 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04244765238047009		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.04244765238047009 | validation: 0.042426902269200914]
	TIME [epoch: 6.39 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02877756822227957		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.02877756822227957 | validation: 0.041262868383731215]
	TIME [epoch: 6.39 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0294991843702729		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.0294991843702729 | validation: 0.04229087273074279]
	TIME [epoch: 6.39 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026707536443112707		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.026707536443112707 | validation: 0.03162354336969972]
	TIME [epoch: 6.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026666049078210748		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.026666049078210748 | validation: 0.0286305494951036]
	TIME [epoch: 6.43 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027069112582829125		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.027069112582829125 | validation: 0.04083596582612431]
	TIME [epoch: 6.41 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029586397648439046		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.029586397648439046 | validation: 0.04327147677839882]
	TIME [epoch: 6.4 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03704176067394805		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.03704176067394805 | validation: 0.08768680380424257]
	TIME [epoch: 6.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05788143480432849		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.05788143480432849 | validation: 0.040846119468148034]
	TIME [epoch: 6.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03385998689017984		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.03385998689017984 | validation: 0.03834367206671247]
	TIME [epoch: 6.39 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026965651849227338		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.026965651849227338 | validation: 0.038475989323823616]
	TIME [epoch: 6.42 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0323871368628869		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.0323871368628869 | validation: 0.04803422534268374]
	TIME [epoch: 6.43 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03080350502892686		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.03080350502892686 | validation: 0.03594816122977188]
	TIME [epoch: 6.43 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02715640901553744		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.02715640901553744 | validation: 0.03867020642972825]
	TIME [epoch: 6.41 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0251185269099701		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.0251185269099701 | validation: 0.0327107132547512]
	TIME [epoch: 6.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031481883044349616		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.031481883044349616 | validation: 0.029959417563835977]
	TIME [epoch: 6.41 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025644258322502413		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.025644258322502413 | validation: 0.03267773191518296]
	TIME [epoch: 6.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023576784384051853		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.023576784384051853 | validation: 0.040280626684705195]
	TIME [epoch: 6.39 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026124573813071383		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.026124573813071383 | validation: 0.0453342766863328]
	TIME [epoch: 6.41 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026404294169442632		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.026404294169442632 | validation: 0.028707781606552022]
	TIME [epoch: 6.45 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029945002021927458		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.029945002021927458 | validation: 0.06431230133109413]
	TIME [epoch: 6.42 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03646371318918494		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.03646371318918494 | validation: 0.03976588268853222]
	TIME [epoch: 6.41 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025433717788467248		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.025433717788467248 | validation: 0.03346867412806784]
	TIME [epoch: 6.42 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02057998120516931		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.02057998120516931 | validation: 0.02474095148999089]
	TIME [epoch: 6.41 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01808781549998175		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.01808781549998175 | validation: 0.027000868080149693]
	TIME [epoch: 6.42 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02898513953589476		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.02898513953589476 | validation: 0.04218491011981341]
	TIME [epoch: 6.41 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025108422278132418		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.025108422278132418 | validation: 0.03783123552409634]
	TIME [epoch: 6.43 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024731343841638463		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.024731343841638463 | validation: 0.043606660364962906]
	TIME [epoch: 6.41 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02517406417730609		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.02517406417730609 | validation: 0.0348344415012928]
	TIME [epoch: 6.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030394882932665287		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.030394882932665287 | validation: 0.042138115855032694]
	TIME [epoch: 6.41 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03701810221556337		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.03701810221556337 | validation: 0.04247275405428835]
	TIME [epoch: 6.4 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042455385945796086		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.042455385945796086 | validation: 0.03242919555583067]
	TIME [epoch: 6.39 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03228517949492773		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.03228517949492773 | validation: 0.04264043360465255]
	TIME [epoch: 6.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04126263654144675		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.04126263654144675 | validation: 0.051068530322338344]
	TIME [epoch: 6.44 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04366523985265178		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.04366523985265178 | validation: 0.033151276726123384]
	TIME [epoch: 6.4 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037447948031383634		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.037447948031383634 | validation: 0.03173805559604402]
	TIME [epoch: 6.39 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145685364856006		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.03145685364856006 | validation: 0.04052113459572427]
	TIME [epoch: 6.4 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03206215354885747		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.03206215354885747 | validation: 0.03471854187150808]
	TIME [epoch: 6.4 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533419063124382		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.03533419063124382 | validation: 0.0336993110558187]
	TIME [epoch: 6.39 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02601897136376039		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.02601897136376039 | validation: 0.03053957993083051]
	TIME [epoch: 6.38 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029177466145043955		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.029177466145043955 | validation: 0.038205678793988083]
	TIME [epoch: 6.42 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379619880979263		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.03379619880979263 | validation: 0.04464003888067957]
	TIME [epoch: 6.38 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04023416458876952		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.04023416458876952 | validation: 0.03873278243504829]
	TIME [epoch: 6.38 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03861805178740094		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.03861805178740094 | validation: 0.039283362051757045]
	TIME [epoch: 6.38 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031417892813100076		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.031417892813100076 | validation: 0.05226792246117445]
	TIME [epoch: 6.4 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04490988465421285		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.04490988465421285 | validation: 0.036128014048090205]
	TIME [epoch: 6.38 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282323277452204		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.03282323277452204 | validation: 0.03635114375517502]
	TIME [epoch: 6.38 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204665133649995		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.03204665133649995 | validation: 0.04711611458050978]
	TIME [epoch: 6.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036163059429232924		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.036163059429232924 | validation: 0.036905927668282636]
	TIME [epoch: 6.42 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039815054096966486		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.039815054096966486 | validation: 0.041101027509421136]
	TIME [epoch: 6.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04073022949821906		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.04073022949821906 | validation: 0.041616675515959496]
	TIME [epoch: 6.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034890444876014094		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.034890444876014094 | validation: 0.043808050475712935]
	TIME [epoch: 6.4 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03163451604462264		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.03163451604462264 | validation: 0.048956096283261696]
	TIME [epoch: 6.38 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030486283018234837		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.030486283018234837 | validation: 0.043002350581187024]
	TIME [epoch: 6.4 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02728631820799966		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.02728631820799966 | validation: 0.05143119511003499]
	TIME [epoch: 6.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333806770869997		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.0333806770869997 | validation: 0.049819314727068395]
	TIME [epoch: 6.43 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04029715663842895		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.04029715663842895 | validation: 0.04051644412291798]
	TIME [epoch: 6.39 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023871913159913515		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.023871913159913515 | validation: 0.03104497036189054]
	TIME [epoch: 6.39 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03325957169037101		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.03325957169037101 | validation: 0.039962315250331275]
	TIME [epoch: 6.39 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326981640782688		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.0326981640782688 | validation: 0.06780378104910574]
	TIME [epoch: 6.4 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568480135618618		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.03568480135618618 | validation: 0.03261318008572127]
	TIME [epoch: 6.39 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02281821105372922		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.02281821105372922 | validation: 0.0435837889800653]
	TIME [epoch: 6.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030706471995633138		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.030706471995633138 | validation: 0.027742242526821673]
	TIME [epoch: 6.43 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030920582624170252		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.030920582624170252 | validation: 0.0328386880723566]
	TIME [epoch: 6.39 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028465247506567648		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.028465247506567648 | validation: 0.04632739154247086]
	TIME [epoch: 6.39 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03739430303766435		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.03739430303766435 | validation: 0.04258567155379886]
	TIME [epoch: 6.4 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030774423245762978		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.030774423245762978 | validation: 0.041458904414890474]
	TIME [epoch: 6.39 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039434970699167675		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.039434970699167675 | validation: 0.0435724462933908]
	TIME [epoch: 6.39 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023664779887425165		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.023664779887425165 | validation: 0.04049197666412185]
	TIME [epoch: 6.39 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029881582629744503		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.029881582629744503 | validation: 0.058093396297498226]
	TIME [epoch: 6.45 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04673444055082522		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.04673444055082522 | validation: 0.064498545111623]
	TIME [epoch: 6.41 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04459898787048369		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.04459898787048369 | validation: 0.03400916656795912]
	TIME [epoch: 6.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029722125001121535		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.029722125001121535 | validation: 0.038825717749718824]
	TIME [epoch: 6.41 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02774352122369146		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.02774352122369146 | validation: 0.035729463565264]
	TIME [epoch: 6.41 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026489378386166388		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.026489378386166388 | validation: 0.0336568065271707]
	TIME [epoch: 6.39 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021669756584902534		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.021669756584902534 | validation: 0.022838028078266345]
	TIME [epoch: 6.39 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02427870713924843		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.02427870713924843 | validation: 0.029991766510541598]
	TIME [epoch: 6.41 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02579794206374913		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.02579794206374913 | validation: 0.032934794448011645]
	TIME [epoch: 6.42 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027238939974352512		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.027238939974352512 | validation: 0.04191592948779961]
	TIME [epoch: 6.39 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0290110101143179		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.0290110101143179 | validation: 0.0289673904899335]
	TIME [epoch: 6.39 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029888086773746984		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.029888086773746984 | validation: 0.0392782837985309]
	TIME [epoch: 6.39 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145239203627071		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.03145239203627071 | validation: 0.039279410318043946]
	TIME [epoch: 6.39 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026462924745681217		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.026462924745681217 | validation: 0.01572279280177653]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_868.pth
	Model improved!!!
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022966575838576208		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.022966575838576208 | validation: 0.03933290814789897]
	TIME [epoch: 6.43 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03096907433499641		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.03096907433499641 | validation: 0.02617150365426171]
	TIME [epoch: 6.43 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023110619122584972		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.023110619122584972 | validation: 0.04149583661509487]
	TIME [epoch: 6.42 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025564801061047034		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.025564801061047034 | validation: 0.03767394467867215]
	TIME [epoch: 6.41 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021285997887559346		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.021285997887559346 | validation: 0.03096263454659374]
	TIME [epoch: 6.41 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021515138953635684		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.021515138953635684 | validation: 0.03401711101199817]
	TIME [epoch: 6.39 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02559987960620071		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.02559987960620071 | validation: 0.033367655041596396]
	TIME [epoch: 6.39 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528679165812982		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.03528679165812982 | validation: 0.055248305407889574]
	TIME [epoch: 6.4 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03634749597367323		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.03634749597367323 | validation: 0.060479027042743376]
	TIME [epoch: 6.44 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04129578363448094		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.04129578363448094 | validation: 0.039597114652597215]
	TIME [epoch: 6.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03114804858930683		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.03114804858930683 | validation: 0.029078208993296457]
	TIME [epoch: 6.41 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02383297735583926		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.02383297735583926 | validation: 0.029126810621701773]
	TIME [epoch: 6.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018050683064402648		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.018050683064402648 | validation: 0.026463609183528414]
	TIME [epoch: 6.41 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017330704905632356		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.017330704905632356 | validation: 0.0356646555613962]
	TIME [epoch: 6.42 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02225523673274079		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.02225523673274079 | validation: 0.03709000699947458]
	TIME [epoch: 6.41 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018310540971000742		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.018310540971000742 | validation: 0.03090000334540366]
	TIME [epoch: 6.44 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024595567064904747		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.024595567064904747 | validation: 0.03375453588429185]
	TIME [epoch: 6.4 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019676792207756484		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.019676792207756484 | validation: 0.0373374852842299]
	TIME [epoch: 6.42 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03213054755007006		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.03213054755007006 | validation: 0.053234628305119165]
	TIME [epoch: 6.39 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03363362718075393		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.03363362718075393 | validation: 0.041939319118293523]
	TIME [epoch: 6.39 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022377566186894224		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.022377566186894224 | validation: 0.02589770175771328]
	TIME [epoch: 6.39 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022450995381843985		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.022450995381843985 | validation: 0.024667477443888676]
	TIME [epoch: 6.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01996199127328157		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.01996199127328157 | validation: 0.03284336521327885]
	TIME [epoch: 6.44 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365815613706243		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.02365815613706243 | validation: 0.035085005713839275]
	TIME [epoch: 6.41 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029078984854609476		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.029078984854609476 | validation: 0.03640895656717055]
	TIME [epoch: 6.41 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027943477704852504		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.027943477704852504 | validation: 0.0391880645989394]
	TIME [epoch: 6.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03472219161948951		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.03472219161948951 | validation: 0.04457033903356005]
	TIME [epoch: 6.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02908741763730665		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.02908741763730665 | validation: 0.03456661076783554]
	TIME [epoch: 6.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035137579957630775		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.035137579957630775 | validation: 0.038969741820482615]
	TIME [epoch: 6.4 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030213039396201985		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.030213039396201985 | validation: 0.042397301704875046]
	TIME [epoch: 6.42 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022088433611330314		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.022088433611330314 | validation: 0.03378541548157804]
	TIME [epoch: 6.42 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024957304670487828		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.024957304670487828 | validation: 0.047836844445194995]
	TIME [epoch: 6.41 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027406228838601394		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.027406228838601394 | validation: 0.04096848507901571]
	TIME [epoch: 6.39 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02306210304252513		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.02306210304252513 | validation: 0.034260921743026904]
	TIME [epoch: 6.41 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02121809015109055		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.02121809015109055 | validation: 0.02755301380845842]
	TIME [epoch: 6.41 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017693730325199396		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.017693730325199396 | validation: 0.03312079498876908]
	TIME [epoch: 6.4 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0193811229392589		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.0193811229392589 | validation: 0.037260791562441414]
	TIME [epoch: 6.42 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021261839209825596		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.021261839209825596 | validation: 0.02863937063885083]
	TIME [epoch: 6.44 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01633017917614355		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.01633017917614355 | validation: 0.019450460265434705]
	TIME [epoch: 6.39 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022627733139573475		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.022627733139573475 | validation: 0.03264907212896441]
	TIME [epoch: 6.4 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03418504833643774		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.03418504833643774 | validation: 0.03516626945765499]
	TIME [epoch: 6.39 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022448029238989545		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.022448029238989545 | validation: 0.03095835272233478]
	TIME [epoch: 6.4 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024600867854039137		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.024600867854039137 | validation: 0.03962589588804715]
	TIME [epoch: 6.42 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02518378249031239		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.02518378249031239 | validation: 0.036805505053017815]
	TIME [epoch: 6.42 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029002022719108858		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.029002022719108858 | validation: 0.04007415476687812]
	TIME [epoch: 6.44 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02386847880352123		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.02386847880352123 | validation: 0.038978226045437075]
	TIME [epoch: 6.39 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028348338607855485		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.028348338607855485 | validation: 0.034043075968769154]
	TIME [epoch: 6.41 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02662424686813398		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.02662424686813398 | validation: 0.029620390974914337]
	TIME [epoch: 6.4 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029254938538243194		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.029254938538243194 | validation: 0.020240953433880212]
	TIME [epoch: 6.4 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02127255279981998		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.02127255279981998 | validation: 0.027731552926780347]
	TIME [epoch: 6.4 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017483855140200538		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.017483855140200538 | validation: 0.03386965015651987]
	TIME [epoch: 6.4 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02172623811665332		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.02172623811665332 | validation: 0.03200968777225063]
	TIME [epoch: 6.44 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025969864476492598		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.025969864476492598 | validation: 0.03588026253545458]
	TIME [epoch: 6.41 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02393777241579622		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.02393777241579622 | validation: 0.028305025804942343]
	TIME [epoch: 6.4 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0193153851613924		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0193153851613924 | validation: 0.021577937001590514]
	TIME [epoch: 6.41 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020468570839101478		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.020468570839101478 | validation: 0.03221207965034627]
	TIME [epoch: 6.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01978797617369081		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.01978797617369081 | validation: 0.04534127846529286]
	TIME [epoch: 6.41 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031078387367434256		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.031078387367434256 | validation: 0.03701353357607015]
	TIME [epoch: 6.39 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028298266708907015		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.028298266708907015 | validation: 0.02982908592734985]
	TIME [epoch: 6.41 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02716665297782639		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.02716665297782639 | validation: 0.044536750532786815]
	TIME [epoch: 6.42 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030846534683296314		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.030846534683296314 | validation: 0.043402533242200544]
	TIME [epoch: 6.41 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027056271816141036		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.027056271816141036 | validation: 0.044500193766826575]
	TIME [epoch: 6.4 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02639345865920777		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.02639345865920777 | validation: 0.0491130586881809]
	TIME [epoch: 6.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031205578204439654		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.031205578204439654 | validation: 0.03522884000747403]
	TIME [epoch: 6.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02321576261409789		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.02321576261409789 | validation: 0.03551014129376135]
	TIME [epoch: 6.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019474194744805697		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.019474194744805697 | validation: 0.027961919547457654]
	TIME [epoch: 6.42 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018533836093814423		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.018533836093814423 | validation: 0.03581938861769475]
	TIME [epoch: 6.42 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01996456698124675		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.01996456698124675 | validation: 0.03835531218670961]
	TIME [epoch: 6.4 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027660721964581483		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.027660721964581483 | validation: 0.022724731058827316]
	TIME [epoch: 6.4 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017649838730586835		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.017649838730586835 | validation: 0.02937006003737956]
	TIME [epoch: 6.39 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020575618661660692		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.020575618661660692 | validation: 0.03567369721516751]
	TIME [epoch: 6.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016524943594063955		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.016524943594063955 | validation: 0.02490715496244771]
	TIME [epoch: 6.4 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01909200898650914		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.01909200898650914 | validation: 0.03012553863271519]
	TIME [epoch: 6.41 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02374962168194366		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.02374962168194366 | validation: 0.03859066358665387]
	TIME [epoch: 6.43 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020581368582897462		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.020581368582897462 | validation: 0.033987146538692004]
	TIME [epoch: 6.4 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024561242352682686		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.024561242352682686 | validation: 0.024605901375014953]
	TIME [epoch: 6.4 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01920869414998672		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.01920869414998672 | validation: 0.026137977815205344]
	TIME [epoch: 6.4 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017139135093436734		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.017139135093436734 | validation: 0.030975744478233588]
	TIME [epoch: 6.41 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016889945042394234		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.016889945042394234 | validation: 0.02821937124019259]
	TIME [epoch: 6.4 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01973603757155759		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.01973603757155759 | validation: 0.023465223820046833]
	TIME [epoch: 6.41 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02380423121866446		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.02380423121866446 | validation: 0.03241056533799259]
	TIME [epoch: 6.43 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021611542142580292		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.021611542142580292 | validation: 0.02570378127139039]
	TIME [epoch: 6.41 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022236933492863598		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.022236933492863598 | validation: 0.030722745490190488]
	TIME [epoch: 6.39 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025580084448986608		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.025580084448986608 | validation: 0.03147259499754297]
	TIME [epoch: 6.41 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02615823221569884		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.02615823221569884 | validation: 0.04389099473140783]
	TIME [epoch: 6.39 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02540152163361376		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.02540152163361376 | validation: 0.03361093225362131]
	TIME [epoch: 6.39 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017249655807431766		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.017249655807431766 | validation: 0.03947360042853343]
	TIME [epoch: 6.4 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024189988651488033		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.024189988651488033 | validation: 0.028039949381847097]
	TIME [epoch: 6.42 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022917260673923384		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.022917260673923384 | validation: 0.03126077090760629]
	TIME [epoch: 6.4 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022520663995231706		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.022520663995231706 | validation: 0.02842708551792815]
	TIME [epoch: 6.41 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025814084367191115		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.025814084367191115 | validation: 0.029909363156383074]
	TIME [epoch: 6.42 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022580348310260352		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.022580348310260352 | validation: 0.03791482708234582]
	TIME [epoch: 6.38 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022750246419344988		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.022750246419344988 | validation: 0.04160505973193354]
	TIME [epoch: 6.39 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026559527504286525		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.026559527504286525 | validation: 0.033847552871889786]
	TIME [epoch: 6.4 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028263559011854976		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.028263559011854976 | validation: 0.040323571061142725]
	TIME [epoch: 6.41 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03315638965550617		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.03315638965550617 | validation: 0.04230670175003745]
	TIME [epoch: 6.42 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02507325264213703		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.02507325264213703 | validation: 0.03893863505192618]
	TIME [epoch: 6.39 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023747848926015506		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.023747848926015506 | validation: 0.035982366956861106]
	TIME [epoch: 6.39 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023628160202626376		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.023628160202626376 | validation: 0.02809359799043404]
	TIME [epoch: 6.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023570975899557804		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.023570975899557804 | validation: 0.02932677306836167]
	TIME [epoch: 6.39 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025639359659773146		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.025639359659773146 | validation: 0.02672876788534217]
	TIME [epoch: 6.4 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02855355833250155		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.02855355833250155 | validation: 0.03132830871944637]
	TIME [epoch: 6.4 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030016514959597493		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.030016514959597493 | validation: 0.032754883421141086]
	TIME [epoch: 6.43 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029099863688612587		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.029099863688612587 | validation: 0.027542777210971855]
	TIME [epoch: 6.4 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02107579350102097		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.02107579350102097 | validation: 0.03148639144768925]
	TIME [epoch: 6.41 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024370743896804263		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.024370743896804263 | validation: 0.044897316998193056]
	TIME [epoch: 6.39 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02028287100673422		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.02028287100673422 | validation: 0.02894163175205708]
	TIME [epoch: 6.4 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021466419500339104		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.021466419500339104 | validation: 0.030509028200977603]
	TIME [epoch: 6.39 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022545647751308972		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.022545647751308972 | validation: 0.03531869985326026]
	TIME [epoch: 6.39 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020429558601462013		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.020429558601462013 | validation: 0.032713287433547074]
	TIME [epoch: 6.44 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018092435945426283		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.018092435945426283 | validation: 0.018357024629549166]
	TIME [epoch: 6.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020425554164424375		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.020425554164424375 | validation: 0.02408893622622529]
	TIME [epoch: 6.39 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02357134325332995		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.02357134325332995 | validation: 0.03883092805372921]
	TIME [epoch: 6.41 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03049801131288386		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.03049801131288386 | validation: 0.04324366858182486]
	TIME [epoch: 6.4 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025406721206742387		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.025406721206742387 | validation: 0.03354271775927049]
	TIME [epoch: 6.39 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02009548186245557		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.02009548186245557 | validation: 0.03014651600712349]
	TIME [epoch: 6.41 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02334963356173767		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.02334963356173767 | validation: 0.03752165720978837]
	TIME [epoch: 6.43 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02895527940077661		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.02895527940077661 | validation: 0.03655597660294912]
	TIME [epoch: 6.39 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031090001147407703		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.031090001147407703 | validation: 0.0348800605111847]
	TIME [epoch: 6.39 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02716009054952304		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.02716009054952304 | validation: 0.038042018394892366]
	TIME [epoch: 6.38 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028511659465016253		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.028511659465016253 | validation: 0.03724398832019928]
	TIME [epoch: 6.39 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219682848984903		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.03219682848984903 | validation: 0.042034414726007566]
	TIME [epoch: 6.38 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034077581333708896		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.034077581333708896 | validation: 0.029442934965689338]
	TIME [epoch: 6.39 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029154822791928235		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.029154822791928235 | validation: 0.02875495752393193]
	TIME [epoch: 6.42 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02591989146282465		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.02591989146282465 | validation: 0.03273936075025238]
	TIME [epoch: 6.42 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02957565849071022		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.02957565849071022 | validation: 0.03171039361597097]
	TIME [epoch: 6.4 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026548485456616058		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.026548485456616058 | validation: 0.03743142544402085]
	TIME [epoch: 6.41 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02362519114623001		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.02362519114623001 | validation: 0.03769305734642034]
	TIME [epoch: 6.39 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0283308014691857		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.0283308014691857 | validation: 0.03469894213282205]
	TIME [epoch: 6.39 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025484356827063712		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.025484356827063712 | validation: 0.038714420873398436]
	TIME [epoch: 6.4 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02973257897817767		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.02973257897817767 | validation: 0.025341147789763565]
	TIME [epoch: 6.41 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019342688541815655		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.019342688541815655 | validation: 0.03829228734262466]
	TIME [epoch: 6.43 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02886722778660892		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.02886722778660892 | validation: 0.036504220762455325]
	TIME [epoch: 6.39 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0220235492536582		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.0220235492536582 | validation: 0.03213871979947502]
	TIME [epoch: 6.4 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01661721491022167		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.01661721491022167 | validation: 0.02911553312273561]
	TIME [epoch: 6.39 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018377178213499573		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.018377178213499573 | validation: 0.029890239960819565]
	TIME [epoch: 6.4 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018685291615832527		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.018685291615832527 | validation: 0.03684419799075127]
	TIME [epoch: 6.4 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02598851898128267		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.02598851898128267 | validation: 0.040198792111527624]
	TIME [epoch: 6.4 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026269893016826175		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.026269893016826175 | validation: 0.04480337857493238]
	TIME [epoch: 6.42 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025180897272981492		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.025180897272981492 | validation: 0.027401406131989856]
	TIME [epoch: 6.4 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01760754839589635		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.01760754839589635 | validation: 0.025942897364413176]
	TIME [epoch: 6.4 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02207995754280334		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.02207995754280334 | validation: 0.03467930873329999]
	TIME [epoch: 6.41 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01743503489067251		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.01743503489067251 | validation: 0.030554308389557097]
	TIME [epoch: 6.4 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022305973518929205		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.022305973518929205 | validation: 0.02340232438924372]
	TIME [epoch: 6.39 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029576145523245074		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.029576145523245074 | validation: 0.03313441112116154]
	TIME [epoch: 6.39 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025388073846435204		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.025388073846435204 | validation: 0.03623084774715333]
	TIME [epoch: 6.43 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01893811286080539		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.01893811286080539 | validation: 0.03209388221104003]
	TIME [epoch: 6.39 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018272291214056546		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.018272291214056546 | validation: 0.032168552029751725]
	TIME [epoch: 6.41 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02351101310194846		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.02351101310194846 | validation: 0.03910653181326489]
	TIME [epoch: 6.41 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030245121993926774		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.030245121993926774 | validation: 0.03987213625789663]
	TIME [epoch: 6.4 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029603987584123338		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.029603987584123338 | validation: 0.030925448051720882]
	TIME [epoch: 6.39 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025977593753200544		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.025977593753200544 | validation: 0.028057877287575996]
	TIME [epoch: 6.4 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019635537726022147		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.019635537726022147 | validation: 0.03224454830088701]
	TIME [epoch: 6.42 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01967453517155128		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.01967453517155128 | validation: 0.022547349226923107]
	TIME [epoch: 6.4 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017323956289805743		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.017323956289805743 | validation: 0.027759401924745578]
	TIME [epoch: 6.39 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017641749862376026		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.017641749862376026 | validation: 0.018592275928522292]
	TIME [epoch: 6.39 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019906900276352238		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.019906900276352238 | validation: 0.0391519159549935]
	TIME [epoch: 6.39 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02942286388587509		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.02942286388587509 | validation: 0.041875076180769834]
	TIME [epoch: 6.4 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028060034670438595		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.028060034670438595 | validation: 0.03355901601097451]
	TIME [epoch: 6.39 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02639725418462375		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.02639725418462375 | validation: 0.03673527680303849]
	TIME [epoch: 6.42 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018836103989036693		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.018836103989036693 | validation: 0.024540279255096983]
	TIME [epoch: 6.43 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020030763501093254		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.020030763501093254 | validation: 0.03610667417312063]
	TIME [epoch: 6.4 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019016615809252763		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.019016615809252763 | validation: 0.0351965923889617]
	TIME [epoch: 6.38 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019216309344893483		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.019216309344893483 | validation: 0.03500150378409914]
	TIME [epoch: 6.4 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017649467350132467		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.017649467350132467 | validation: 0.027474584868779628]
	TIME [epoch: 6.41 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027713618087485053		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.027713618087485053 | validation: 0.030559819813324073]
	TIME [epoch: 6.39 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023227708028430313		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.023227708028430313 | validation: 0.034540404221689254]
	TIME [epoch: 6.4 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020925397979466475		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.020925397979466475 | validation: 0.027885894496775584]
	TIME [epoch: 6.44 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0186234438251894		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.0186234438251894 | validation: 0.031185187513560076]
	TIME [epoch: 6.42 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02254252477452426		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.02254252477452426 | validation: 0.038791653456269275]
	TIME [epoch: 6.4 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020948223456883748		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.020948223456883748 | validation: 0.03359425738117011]
	TIME [epoch: 6.4 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018347945077958876		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.018347945077958876 | validation: 0.026963899228820337]
	TIME [epoch: 6.41 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017012664251596123		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.017012664251596123 | validation: 0.027965714805677368]
	TIME [epoch: 6.4 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020071684836803938		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.020071684836803938 | validation: 0.023307680075895353]
	TIME [epoch: 6.42 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01828571524192859		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.01828571524192859 | validation: 0.017697749564158767]
	TIME [epoch: 6.43 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015123661078874832		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.015123661078874832 | validation: 0.020046934215772243]
	TIME [epoch: 6.4 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017575425597692675		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.017575425597692675 | validation: 0.030941945746399566]
	TIME [epoch: 6.4 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017002275926363844		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.017002275926363844 | validation: 0.03249587838157802]
	TIME [epoch: 6.41 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020925529453932105		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.020925529453932105 | validation: 0.03542272340702008]
	TIME [epoch: 6.39 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020185113598256775		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.020185113598256775 | validation: 0.027829316648852874]
	TIME [epoch: 6.39 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01591268495247508		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.01591268495247508 | validation: 0.02617336542713715]
	TIME [epoch: 6.4 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018496560057506065		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.018496560057506065 | validation: 0.037233134411451874]
	TIME [epoch: 6.44 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020517116994181992		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.020517116994181992 | validation: 0.028962377644718654]
	TIME [epoch: 6.4 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021044962921725037		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.021044962921725037 | validation: 0.027968127451882974]
	TIME [epoch: 6.39 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020340671570603125		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.020340671570603125 | validation: 0.027711393739074035]
	TIME [epoch: 6.4 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01716389437839147		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.01716389437839147 | validation: 0.025297564573801178]
	TIME [epoch: 6.4 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014285859132832784		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.014285859132832784 | validation: 0.0308219825442243]
	TIME [epoch: 6.4 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017929808329975584		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.017929808329975584 | validation: 0.03437193975959686]
	TIME [epoch: 6.4 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01905753617046015		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.01905753617046015 | validation: 0.029567946666853723]
	TIME [epoch: 6.44 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019183426951056345		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.019183426951056345 | validation: 0.03102782625779117]
	TIME [epoch: 6.41 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017098631793793277		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.017098631793793277 | validation: 0.029412446021111364]
	TIME [epoch: 6.42 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02074673239365781		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.02074673239365781 | validation: 0.029064079025679736]
	TIME [epoch: 6.41 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021780930406535146		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.021780930406535146 | validation: 0.029970497845222873]
	TIME [epoch: 6.41 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017934916534361422		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.017934916534361422 | validation: 0.03370237771546281]
	TIME [epoch: 6.41 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025805526604070005		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.025805526604070005 | validation: 0.03496848003332809]
	TIME [epoch: 6.4 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025115410563966066		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.025115410563966066 | validation: 0.040517616515053395]
	TIME [epoch: 6.42 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023805262816171152		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.023805262816171152 | validation: 0.0432404736195417]
	TIME [epoch: 6.42 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0206513509826389		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.0206513509826389 | validation: 0.03671177652929697]
	TIME [epoch: 6.41 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021686446787856306		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.021686446787856306 | validation: 0.029675918837226305]
	TIME [epoch: 6.42 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023040017144754878		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.023040017144754878 | validation: 0.03775594652591592]
	TIME [epoch: 6.42 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021617781858907684		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.021617781858907684 | validation: 0.039428081677636256]
	TIME [epoch: 6.41 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016524709486159462		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.016524709486159462 | validation: 0.03082976971198678]
	TIME [epoch: 6.41 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01952487656467966		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.01952487656467966 | validation: 0.02751459068113788]
	TIME [epoch: 6.41 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017112167868394534		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.017112167868394534 | validation: 0.03370478242428012]
	TIME [epoch: 6.44 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015161427417606593		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.015161427417606593 | validation: 0.03495427098897382]
	TIME [epoch: 6.41 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02209019466209083		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.02209019466209083 | validation: 0.033708062523774986]
	TIME [epoch: 6.39 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015617864184994286		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.015617864184994286 | validation: 0.02376248978437239]
	TIME [epoch: 6.39 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018823945424297404		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.018823945424297404 | validation: 0.0351817645644941]
	TIME [epoch: 6.39 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020530722712644802		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.020530722712644802 | validation: 0.03124951425277762]
	TIME [epoch: 6.4 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022302036678290324		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.022302036678290324 | validation: 0.02969059175729317]
	TIME [epoch: 6.41 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01802236450024163		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.01802236450024163 | validation: 0.02141208328784754]
	TIME [epoch: 6.44 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015436819867883832		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.015436819867883832 | validation: 0.02502447694094759]
	TIME [epoch: 6.42 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019003682112314253		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.019003682112314253 | validation: 0.03128657403415281]
	TIME [epoch: 6.39 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01613900605674131		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.01613900605674131 | validation: 0.03262181258948396]
	TIME [epoch: 6.41 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015929483664803644		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.015929483664803644 | validation: 0.029546750159245374]
	TIME [epoch: 6.39 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01432143459323524		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.01432143459323524 | validation: 0.03004728404536504]
	TIME [epoch: 6.41 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021081456390724455		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.021081456390724455 | validation: 0.03235013689801059]
	TIME [epoch: 6.39 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02306193584800416		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.02306193584800416 | validation: 0.034062337068319126]
	TIME [epoch: 6.45 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017770499086026587		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.017770499086026587 | validation: 0.022039918667908793]
	TIME [epoch: 6.42 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018421535341940257		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.018421535341940257 | validation: 0.028917373456602957]
	TIME [epoch: 6.41 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017517018648547485		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.017517018648547485 | validation: 0.03481205497905629]
	TIME [epoch: 6.41 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021954925600697218		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.021954925600697218 | validation: 0.03284751499896341]
	TIME [epoch: 6.41 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020759013503962424		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.020759013503962424 | validation: 0.033528076977782345]
	TIME [epoch: 6.41 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025077019220755663		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.025077019220755663 | validation: 0.03760808353236472]
	TIME [epoch: 6.42 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0185100760076045		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.0185100760076045 | validation: 0.029537853317944406]
	TIME [epoch: 6.43 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019097637185864408		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.019097637185864408 | validation: 0.033996893866195366]
	TIME [epoch: 6.43 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019005379897454787		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.019005379897454787 | validation: 0.0364077474524067]
	TIME [epoch: 6.4 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026035912459551006		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.026035912459551006 | validation: 0.03582154648898869]
	TIME [epoch: 6.41 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022124613625159377		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.022124613625159377 | validation: 0.03268662347397568]
	TIME [epoch: 6.4 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017643367372684036		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.017643367372684036 | validation: 0.02954961789816711]
	TIME [epoch: 6.41 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020015362655567224		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.020015362655567224 | validation: 0.04158515977013364]
	TIME [epoch: 6.39 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021752842812864322		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.021752842812864322 | validation: 0.03724439853646417]
	TIME [epoch: 6.43 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02111006023129424		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.02111006023129424 | validation: 0.024813393601951228]
	TIME [epoch: 6.42 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019293934128033555		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.019293934128033555 | validation: 0.026176401550295082]
	TIME [epoch: 6.42 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017961631503402044		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.017961631503402044 | validation: 0.026108925563558434]
	TIME [epoch: 6.4 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017084584536372918		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.017084584536372918 | validation: 0.03172104901752408]
	TIME [epoch: 6.42 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020206271780311074		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.020206271780311074 | validation: 0.03830553039688554]
	TIME [epoch: 6.4 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01480146041168346		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.01480146041168346 | validation: 0.03597771291972152]
	TIME [epoch: 6.42 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019157171259827153		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.019157171259827153 | validation: 0.033044351953436316]
	TIME [epoch: 6.41 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019243381907426527		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.019243381907426527 | validation: 0.026902807843916597]
	TIME [epoch: 6.45 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024165643075289022		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.024165643075289022 | validation: 0.030079197977539406]
	TIME [epoch: 6.41 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026432622033185204		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.026432622033185204 | validation: 0.040715645259454473]
	TIME [epoch: 6.42 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020735696874788326		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.020735696874788326 | validation: 0.034059089249786074]
	TIME [epoch: 6.4 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019370858308190284		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.019370858308190284 | validation: 0.034852288253721046]
	TIME [epoch: 6.42 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020480157844437446		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.020480157844437446 | validation: 0.025381256376950895]
	TIME [epoch: 6.42 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019647944688586192		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.019647944688586192 | validation: 0.03120961816574877]
	TIME [epoch: 6.4 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015508397357973889		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.015508397357973889 | validation: 0.022284743495236067]
	TIME [epoch: 6.45 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017164983435232945		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.017164983435232945 | validation: 0.031038310788368585]
	TIME [epoch: 6.41 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01824217699067204		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.01824217699067204 | validation: 0.03350976346493481]
	TIME [epoch: 6.4 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02849811631923462		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.02849811631923462 | validation: 0.031441935325865054]
	TIME [epoch: 6.4 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025296090047667384		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.025296090047667384 | validation: 0.03313514726765095]
	TIME [epoch: 6.41 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02497181400255321		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.02497181400255321 | validation: 0.03733501415432117]
	TIME [epoch: 6.41 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024961425105787707		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.024961425105787707 | validation: 0.025912000937441705]
	TIME [epoch: 6.4 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02064248571551154		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.02064248571551154 | validation: 0.029573917885141833]
	TIME [epoch: 6.44 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018946121367821547		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.018946121367821547 | validation: 0.022279811661098412]
	TIME [epoch: 6.42 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01750026427574443		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.01750026427574443 | validation: 0.01968856434128004]
	TIME [epoch: 6.4 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015179618753197528		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.015179618753197528 | validation: 0.03009408000866279]
	TIME [epoch: 6.39 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02160436547961931		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.02160436547961931 | validation: 0.036446238339506574]
	TIME [epoch: 6.41 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02567325101677166		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.02567325101677166 | validation: 0.03534225915216719]
	TIME [epoch: 6.41 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02334262493133968		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.02334262493133968 | validation: 0.037864688352853275]
	TIME [epoch: 6.4 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02075265071762786		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.02075265071762786 | validation: 0.03762717814689305]
	TIME [epoch: 6.42 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026607882035005095		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.026607882035005095 | validation: 0.03421581879182543]
	TIME [epoch: 6.44 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02586547843256801		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.02586547843256801 | validation: 0.0262289801470044]
	TIME [epoch: 6.42 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016720776734373083		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.016720776734373083 | validation: 0.025489597029984132]
	TIME [epoch: 6.4 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017149929820099486		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.017149929820099486 | validation: 0.026685751821961392]
	TIME [epoch: 6.41 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016052050084030697		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.016052050084030697 | validation: 0.028644288049214036]
	TIME [epoch: 6.4 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01664063582225094		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.01664063582225094 | validation: 0.020714429829134913]
	TIME [epoch: 6.41 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019792708202674203		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.019792708202674203 | validation: 0.034353517746240146]
	TIME [epoch: 6.42 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0277881659835298		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.0277881659835298 | validation: 0.026549058699944568]
	TIME [epoch: 6.42 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018491775744097615		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.018491775744097615 | validation: 0.034742498222068076]
	TIME [epoch: 6.4 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01984609063446472		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.01984609063446472 | validation: 0.032043219702798255]
	TIME [epoch: 6.42 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016692863289422395		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.016692863289422395 | validation: 0.02540984209734508]
	TIME [epoch: 6.41 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024168848824519563		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.024168848824519563 | validation: 0.03368491862158623]
	TIME [epoch: 6.4 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016235200472360194		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.016235200472360194 | validation: 0.022771449829342864]
	TIME [epoch: 6.4 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01730118976328883		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.01730118976328883 | validation: 0.03061512111197515]
	TIME [epoch: 6.41 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015612590332339858		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.015612590332339858 | validation: 0.025329446545913698]
	TIME [epoch: 6.44 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016152158999561503		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.016152158999561503 | validation: 0.027726688803747967]
	TIME [epoch: 6.42 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012793629076922736		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.012793629076922736 | validation: 0.02308886416771791]
	TIME [epoch: 6.41 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015053829660923657		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.015053829660923657 | validation: 0.030950466766720468]
	TIME [epoch: 6.41 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01663792039868749		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.01663792039868749 | validation: 0.026851315326964765]
	TIME [epoch: 6.42 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015883271381287402		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.015883271381287402 | validation: 0.02613606579596034]
	TIME [epoch: 6.4 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017339915951145937		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.017339915951145937 | validation: 0.030513795345270447]
	TIME [epoch: 6.4 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018478920164286167		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.018478920164286167 | validation: 0.019513213130764474]
	TIME [epoch: 6.44 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013951188258543863		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.013951188258543863 | validation: 0.036556350586674564]
	TIME [epoch: 6.4 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021792571408893985		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.021792571408893985 | validation: 0.03183047383354092]
	TIME [epoch: 6.4 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021096322471700797		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.021096322471700797 | validation: 0.027852040028345407]
	TIME [epoch: 6.41 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015484126378858936		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.015484126378858936 | validation: 0.024694053518569313]
	TIME [epoch: 6.4 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014852869497298402		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.014852869497298402 | validation: 0.03140645213335644]
	TIME [epoch: 6.4 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0188529350363717		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.0188529350363717 | validation: 0.025547883726037193]
	TIME [epoch: 6.39 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014132989539304718		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.014132989539304718 | validation: 0.02660496219350012]
	TIME [epoch: 6.44 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014513110860987043		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.014513110860987043 | validation: 0.035093491760405965]
	TIME [epoch: 6.41 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019785000595628804		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.019785000595628804 | validation: 0.02262793809594605]
	TIME [epoch: 6.41 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01351590881777642		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.01351590881777642 | validation: 0.030809390787210164]
	TIME [epoch: 6.39 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01486657187080338		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.01486657187080338 | validation: 0.02757200549349391]
	TIME [epoch: 6.4 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01932728989040191		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.01932728989040191 | validation: 0.02954462812707809]
	TIME [epoch: 6.39 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019850814367374476		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.019850814367374476 | validation: 0.03200504174216937]
	TIME [epoch: 6.41 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014977813015410672		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.014977813015410672 | validation: 0.028945778579145633]
	TIME [epoch: 6.43 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01710533137704626		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.01710533137704626 | validation: 0.03278393774106928]
	TIME [epoch: 6.43 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01881905326472067		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.01881905326472067 | validation: 0.026835627035471897]
	TIME [epoch: 6.4 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01664441730922948		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.01664441730922948 | validation: 0.03954660378151723]
	TIME [epoch: 6.4 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017272288256900335		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.017272288256900335 | validation: 0.033548488906479976]
	TIME [epoch: 6.39 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02293364825661287		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.02293364825661287 | validation: 0.0252335750064379]
	TIME [epoch: 6.41 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01238718643858576		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.01238718643858576 | validation: 0.02619821645737378]
	TIME [epoch: 6.42 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020101674030989045		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.020101674030989045 | validation: 0.026869478420891428]
	TIME [epoch: 6.41 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01691837597181141		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.01691837597181141 | validation: 0.020814549704516915]
	TIME [epoch: 6.41 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015586427739533462		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.015586427739533462 | validation: 0.016473473423226626]
	TIME [epoch: 6.4 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012580159724738438		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.012580159724738438 | validation: 0.027590293228108864]
	TIME [epoch: 6.39 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01551828830909649		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.01551828830909649 | validation: 0.03539462801765566]
	TIME [epoch: 6.4 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01562287344058109		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.01562287344058109 | validation: 0.031490952083380555]
	TIME [epoch: 6.39 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018174763869381053		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.018174763869381053 | validation: 0.02818681026403513]
	TIME [epoch: 6.4 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018106132046539786		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.018106132046539786 | validation: 0.035424352469728054]
	TIME [epoch: 6.42 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01530739085636851		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.01530739085636851 | validation: 0.03458892897542055]
	TIME [epoch: 6.44 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016473278757812296		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.016473278757812296 | validation: 0.02580235364305856]
	TIME [epoch: 6.39 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017526495912977044		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.017526495912977044 | validation: 0.030965001093704467]
	TIME [epoch: 6.41 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015699132147459133		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.015699132147459133 | validation: 0.023958425594707178]
	TIME [epoch: 6.4 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016004053899319196		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.016004053899319196 | validation: 0.02605953953154617]
	TIME [epoch: 6.4 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020922236416107496		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.020922236416107496 | validation: 0.03448989812054683]
	TIME [epoch: 6.4 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017140857770285296		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.017140857770285296 | validation: 0.030885673796644586]
	TIME [epoch: 6.4 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01799348495901938		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.01799348495901938 | validation: 0.021846901242895882]
	TIME [epoch: 6.43 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015314791351064616		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.015314791351064616 | validation: 0.023763147986227678]
	TIME [epoch: 6.4 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017202759676317014		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.017202759676317014 | validation: 0.03449006301229113]
	TIME [epoch: 6.39 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015157419325146282		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.015157419325146282 | validation: 0.021739803989199197]
	TIME [epoch: 6.4 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01668778067205321		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.01668778067205321 | validation: 0.03343899100123898]
	TIME [epoch: 6.4 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0187946669252479		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.0187946669252479 | validation: 0.03361866014455841]
	TIME [epoch: 6.4 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017557389715696568		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.017557389715696568 | validation: 0.029699333794394222]
	TIME [epoch: 6.39 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014420348156826333		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.014420348156826333 | validation: 0.020532155216815357]
	TIME [epoch: 6.43 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015239113880720658		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.015239113880720658 | validation: 0.02697482335464736]
	TIME [epoch: 6.4 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016932763527165717		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.016932763527165717 | validation: 0.022759377860515122]
	TIME [epoch: 6.42 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015491767523915546		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.015491767523915546 | validation: 0.026167626780555713]
	TIME [epoch: 6.39 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016197207199739345		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.016197207199739345 | validation: 0.02904651877886022]
	TIME [epoch: 6.4 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01766980606426816		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.01766980606426816 | validation: 0.02342187090175433]
	TIME [epoch: 6.4 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01847236889751698		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.01847236889751698 | validation: 0.026244027744669936]
	TIME [epoch: 6.41 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016975726896242497		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.016975726896242497 | validation: 0.025634919937336256]
	TIME [epoch: 6.42 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019959739568519583		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.019959739568519583 | validation: 0.02730162658885764]
	TIME [epoch: 6.42 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019358806091358226		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.019358806091358226 | validation: 0.021716361550090834]
	TIME [epoch: 6.4 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016840272856625663		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.016840272856625663 | validation: 0.02678480319247254]
	TIME [epoch: 6.4 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01664462695563681		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.01664462695563681 | validation: 0.02746179013270387]
	TIME [epoch: 6.4 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0130341338042765		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.0130341338042765 | validation: 0.024955154679483994]
	TIME [epoch: 6.41 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015877027884812107		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.015877027884812107 | validation: 0.019337262660201245]
	TIME [epoch: 6.4 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018045724764280874		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.018045724764280874 | validation: 0.027860600191234694]
	TIME [epoch: 6.41 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01597191632339191		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.01597191632339191 | validation: 0.019660680723616236]
	TIME [epoch: 6.43 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011764618733194818		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.011764618733194818 | validation: 0.02867011178021434]
	TIME [epoch: 6.4 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01648418263935849		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.01648418263935849 | validation: 0.022454168954572716]
	TIME [epoch: 6.41 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02532651174235883		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.02532651174235883 | validation: 0.03019889426188736]
	TIME [epoch: 6.4 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017022056077362787		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.017022056077362787 | validation: 0.02989838824505787]
	TIME [epoch: 6.4 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01913651932914218		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.01913651932914218 | validation: 0.02827056247710445]
	TIME [epoch: 6.41 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013262893352479243		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.013262893352479243 | validation: 0.02110000169164421]
	TIME [epoch: 6.41 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017331749770067503		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.017331749770067503 | validation: 0.028574429720697778]
	TIME [epoch: 6.44 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018253790269662167		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.018253790269662167 | validation: 0.023381295858938025]
	TIME [epoch: 6.4 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01879562133320571		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.01879562133320571 | validation: 0.02350349525193022]
	TIME [epoch: 6.42 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017052814457724146		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.017052814457724146 | validation: 0.026958409761564158]
	TIME [epoch: 6.41 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01588061768292618		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.01588061768292618 | validation: 0.01856131696361737]
	TIME [epoch: 6.4 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016576110810144807		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.016576110810144807 | validation: 0.028358027077694265]
	TIME [epoch: 6.41 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01801195499999465		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.01801195499999465 | validation: 0.03405916027857889]
	TIME [epoch: 6.4 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018233297574455347		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.018233297574455347 | validation: 0.02087844053884253]
	TIME [epoch: 6.44 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016097925449905036		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.016097925449905036 | validation: 0.023946316208357656]
	TIME [epoch: 6.41 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018065347626684047		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.018065347626684047 | validation: 0.03231847361428902]
	TIME [epoch: 6.41 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014946653973613503		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.014946653973613503 | validation: 0.027018705204809673]
	TIME [epoch: 6.41 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022845837701553105		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.022845837701553105 | validation: 0.0306515491873733]
	TIME [epoch: 6.4 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02079323335195523		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.02079323335195523 | validation: 0.024614448031082262]
	TIME [epoch: 6.41 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015362157126279323		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.015362157126279323 | validation: 0.025841194348182658]
	TIME [epoch: 6.41 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016370605838278963		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.016370605838278963 | validation: 0.024354993088673168]
	TIME [epoch: 6.44 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015825521718801923		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.015825521718801923 | validation: 0.017680458732280874]
	TIME [epoch: 6.42 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019294340870320482		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.019294340870320482 | validation: 0.02608329285771628]
	TIME [epoch: 6.42 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013284277500813752		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.013284277500813752 | validation: 0.023691428036916234]
	TIME [epoch: 6.4 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013223899401250296		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.013223899401250296 | validation: 0.02962530143190123]
	TIME [epoch: 6.4 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013560665661738159		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.013560665661738159 | validation: 0.01803010150869016]
	TIME [epoch: 6.4 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016321128163273267		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.016321128163273267 | validation: 0.029302394179970725]
	TIME [epoch: 6.41 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016931504666213137		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.016931504666213137 | validation: 0.02027790597042975]
	TIME [epoch: 6.44 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015373570241077711		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.015373570241077711 | validation: 0.021442893786000398]
	TIME [epoch: 6.43 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01048539841651704		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.01048539841651704 | validation: 0.022081286050725967]
	TIME [epoch: 6.41 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014283690735288814		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.014283690735288814 | validation: 0.025079630407118192]
	TIME [epoch: 6.41 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01708512820448293		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.01708512820448293 | validation: 0.025683459283150602]
	TIME [epoch: 6.42 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013331379954834754		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.013331379954834754 | validation: 0.030021435920942984]
	TIME [epoch: 6.42 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014598836563713151		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.014598836563713151 | validation: 0.03726979650306974]
	TIME [epoch: 6.4 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017712259107977902		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.017712259107977902 | validation: 0.03090440208611365]
	TIME [epoch: 6.41 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01980411614618934		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.01980411614618934 | validation: 0.027871302028384386]
	TIME [epoch: 6.46 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019756621455305025		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.019756621455305025 | validation: 0.02653983356505739]
	TIME [epoch: 6.4 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017691728385271457		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.017691728385271457 | validation: 0.02554714073796753]
	TIME [epoch: 6.43 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01776724194712995		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.01776724194712995 | validation: 0.02790761726219083]
	TIME [epoch: 6.39 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015379038176447719		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.015379038176447719 | validation: 0.022451020895403774]
	TIME [epoch: 6.4 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01855015758106738		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.01855015758106738 | validation: 0.02744596456198319]
	TIME [epoch: 6.39 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01592615520381182		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.01592615520381182 | validation: 0.028319513232767605]
	TIME [epoch: 6.41 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017497015742050523		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.017497015742050523 | validation: 0.028201088747624913]
	TIME [epoch: 6.43 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018884189318272397		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.018884189318272397 | validation: 0.03640010656147917]
	TIME [epoch: 6.41 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01870850342545195		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.01870850342545195 | validation: 0.028933731579038616]
	TIME [epoch: 6.41 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01886801194639011		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.01886801194639011 | validation: 0.016890895413730754]
	TIME [epoch: 6.41 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016061990791556076		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.016061990791556076 | validation: 0.027213075033401153]
	TIME [epoch: 6.41 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014754800162821723		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.014754800162821723 | validation: 0.029602849199714436]
	TIME [epoch: 6.41 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015549866440568905		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.015549866440568905 | validation: 0.029946971600250897]
	TIME [epoch: 6.4 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01349651900117088		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.01349651900117088 | validation: 0.02295750057085617]
	TIME [epoch: 6.44 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014746094565239109		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.014746094565239109 | validation: 0.025734407517795717]
	TIME [epoch: 6.42 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01085608693842072		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.01085608693842072 | validation: 0.022711493877678287]
	TIME [epoch: 6.41 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015672303763879493		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.015672303763879493 | validation: 0.02921621251866932]
	TIME [epoch: 6.4 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014493702400678963		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.014493702400678963 | validation: 0.025121209062563838]
	TIME [epoch: 6.41 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01846448118845033		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.01846448118845033 | validation: 0.028057544191421417]
	TIME [epoch: 6.42 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013725719965161476		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.013725719965161476 | validation: 0.027837195717027682]
	TIME [epoch: 6.4 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020154415053727427		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.020154415053727427 | validation: 0.022162517745430304]
	TIME [epoch: 6.45 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016485310111859976		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.016485310111859976 | validation: 0.026401125966348474]
	TIME [epoch: 6.41 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015458297559360033		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.015458297559360033 | validation: 0.02147523364593698]
	TIME [epoch: 6.41 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019323087194444814		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.019323087194444814 | validation: 0.03125063105236304]
	TIME [epoch: 6.39 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015588080670179166		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.015588080670179166 | validation: 0.028608001387789146]
	TIME [epoch: 6.42 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019753616346229422		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.019753616346229422 | validation: 0.03426317656087798]
	TIME [epoch: 6.41 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02129309273644979		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.02129309273644979 | validation: 0.025510082426507267]
	TIME [epoch: 6.4 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020717463700432412		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.020717463700432412 | validation: 0.04155842856944981]
	TIME [epoch: 6.41 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024698139837375822		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.024698139837375822 | validation: 0.029661419803118268]
	TIME [epoch: 6.43 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016845551090883964		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.016845551090883964 | validation: 0.032880714078748444]
	TIME [epoch: 6.41 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015662545448142513		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.015662545448142513 | validation: 0.022436928708125175]
	TIME [epoch: 6.4 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01696672127280988		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.01696672127280988 | validation: 0.021874697615221258]
	TIME [epoch: 6.39 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016614947916794874		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.016614947916794874 | validation: 0.023966952879823495]
	TIME [epoch: 6.41 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018129380200461773		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.018129380200461773 | validation: 0.02750292343264323]
	TIME [epoch: 6.39 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01699487476826412		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.01699487476826412 | validation: 0.030920443519697187]
	TIME [epoch: 6.41 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017702767397714623		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.017702767397714623 | validation: 0.023185749894498703]
	TIME [epoch: 6.45 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01925198567685719		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.01925198567685719 | validation: 0.03504141397400618]
	TIME [epoch: 6.4 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0165027951398495		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.0165027951398495 | validation: 0.02896586291407079]
	TIME [epoch: 6.4 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014129156665514484		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.014129156665514484 | validation: 0.029596746083111535]
	TIME [epoch: 6.4 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015040002550451787		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.015040002550451787 | validation: 0.024482816346933545]
	TIME [epoch: 6.41 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015526862617329634		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.015526862617329634 | validation: 0.025911629784002185]
	TIME [epoch: 6.41 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01743624248823996		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.01743624248823996 | validation: 0.031082303374605304]
	TIME [epoch: 6.42 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016696212635296574		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.016696212635296574 | validation: 0.025408183529369126]
	TIME [epoch: 6.44 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016071773929469492		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.016071773929469492 | validation: 0.03373718865237537]
	TIME [epoch: 6.43 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02174031331644813		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.02174031331644813 | validation: 0.03290712420635792]
	TIME [epoch: 6.41 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01659593814744615		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.01659593814744615 | validation: 0.02695553446471805]
	TIME [epoch: 6.41 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017197424578804157		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.017197424578804157 | validation: 0.023892956745864693]
	TIME [epoch: 6.41 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01621247603402222		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.01621247603402222 | validation: 0.02518748399066503]
	TIME [epoch: 6.4 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01695399453815296		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.01695399453815296 | validation: 0.026213359496304142]
	TIME [epoch: 6.38 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01807897678869616		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.01807897678869616 | validation: 0.025929600468236433]
	TIME [epoch: 6.42 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015831913744546507		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.015831913744546507 | validation: 0.02871749355606946]
	TIME [epoch: 6.39 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016045981428579964		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.016045981428579964 | validation: 0.02422791230863844]
	TIME [epoch: 6.37 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0109036540347887		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.0109036540347887 | validation: 0.019081844065004103]
	TIME [epoch: 6.38 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0156508498473128		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.0156508498473128 | validation: 0.03058992117587115]
	TIME [epoch: 6.39 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014922254437911208		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.014922254437911208 | validation: 0.020101568933686136]
	TIME [epoch: 6.39 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013273067867644504		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.013273067867644504 | validation: 0.02403213436832899]
	TIME [epoch: 6.38 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01640575397768451		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.01640575397768451 | validation: 0.0240556854285556]
	TIME [epoch: 6.41 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01332600065555441		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.01332600065555441 | validation: 0.022016701543902374]
	TIME [epoch: 6.41 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013470317539204602		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.013470317539204602 | validation: 0.0263086164722442]
	TIME [epoch: 6.38 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016782875713247488		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.016782875713247488 | validation: 0.026095283997810505]
	TIME [epoch: 6.37 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016683256321391646		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.016683256321391646 | validation: 0.021961138630885568]
	TIME [epoch: 6.39 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014250832065160254		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.014250832065160254 | validation: 0.02335081585814385]
	TIME [epoch: 6.38 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012606753144255977		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.012606753144255977 | validation: 0.02169734755165586]
	TIME [epoch: 6.38 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0150075709316229		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.0150075709316229 | validation: 0.03288653102799032]
	TIME [epoch: 6.4 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01600182869683883		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.01600182869683883 | validation: 0.0293995613030035]
	TIME [epoch: 6.41 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020537850902168003		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.020537850902168003 | validation: 0.027287568609868203]
	TIME [epoch: 6.38 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017771420021660454		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.017771420021660454 | validation: 0.03596325521521445]
	TIME [epoch: 6.39 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01680477547604488		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.01680477547604488 | validation: 0.028171840158680225]
	TIME [epoch: 6.37 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013629109233009914		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.013629109233009914 | validation: 0.027447423889801818]
	TIME [epoch: 6.38 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01595477001393788		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.01595477001393788 | validation: 0.023461904704440456]
	TIME [epoch: 6.4 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014730468481746079		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.014730468481746079 | validation: 0.028752802536260523]
	TIME [epoch: 6.4 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01658451097204895		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.01658451097204895 | validation: 0.029231127836210097]
	TIME [epoch: 6.43 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014132167149524321		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.014132167149524321 | validation: 0.02353589264212309]
	TIME [epoch: 6.39 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017353654576342064		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.017353654576342064 | validation: 0.03568703683899692]
	TIME [epoch: 6.4 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020853273323492835		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.020853273323492835 | validation: 0.03309591752032589]
	TIME [epoch: 6.39 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021254019527979538		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.021254019527979538 | validation: 0.033051551065265306]
	TIME [epoch: 6.41 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020599801360584157		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.020599801360584157 | validation: 0.03610155013177316]
	TIME [epoch: 6.4 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020359802455676184		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.020359802455676184 | validation: 0.03735286901064089]
	TIME [epoch: 6.4 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018455077280691616		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.018455077280691616 | validation: 0.0318108237190747]
	TIME [epoch: 6.44 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01460508415159052		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.01460508415159052 | validation: 0.024340196544963097]
	TIME [epoch: 6.4 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015067684667475722		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.015067684667475722 | validation: 0.03452607867605666]
	TIME [epoch: 6.4 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015027100825901571		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.015027100825901571 | validation: 0.03001063275476142]
	TIME [epoch: 6.4 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014291051116640077		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.014291051116640077 | validation: 0.02480080130058826]
	TIME [epoch: 6.4 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015795138960334323		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.015795138960334323 | validation: 0.026293307759588352]
	TIME [epoch: 6.39 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015853481476937804		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.015853481476937804 | validation: 0.023994797962933214]
	TIME [epoch: 6.4 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014348732356583366		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.014348732356583366 | validation: 0.031856534457687866]
	TIME [epoch: 6.43 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016735966353955738		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.016735966353955738 | validation: 0.030501580271350248]
	TIME [epoch: 6.42 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010757404937931042		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.010757404937931042 | validation: 0.0279167556785732]
	TIME [epoch: 6.41 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015174265402245608		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.015174265402245608 | validation: 0.026377922306453905]
	TIME [epoch: 6.4 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020669467678629996		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.020669467678629996 | validation: 0.02646347431792231]
	TIME [epoch: 6.4 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014595272904887836		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.014595272904887836 | validation: 0.026046449099610004]
	TIME [epoch: 6.4 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017029080126698112		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.017029080126698112 | validation: 0.029316245825135392]
	TIME [epoch: 6.39 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01828616970752431		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.01828616970752431 | validation: 0.025323051084161392]
	TIME [epoch: 6.43 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016395227558008006		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.016395227558008006 | validation: 0.030854500299290252]
	TIME [epoch: 6.43 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014427343512378382		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.014427343512378382 | validation: 0.02478441404514624]
	TIME [epoch: 6.42 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0174860661735465		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.0174860661735465 | validation: 0.026086365147922834]
	TIME [epoch: 6.4 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019864486823972557		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.019864486823972557 | validation: 0.022173332800552177]
	TIME [epoch: 6.41 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014248775579577502		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.014248775579577502 | validation: 0.032285110438804276]
	TIME [epoch: 6.39 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015496577564163028		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.015496577564163028 | validation: 0.0256855599306115]
	TIME [epoch: 6.4 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01545378748827082		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.01545378748827082 | validation: 0.028430688835463826]
	TIME [epoch: 6.41 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018012815645302896		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.018012815645302896 | validation: 0.02185135851950316]
	TIME [epoch: 6.44 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01618600381942468		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.01618600381942468 | validation: 0.023000320726692704]
	TIME [epoch: 6.42 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01610816843160279		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.01610816843160279 | validation: 0.02487066038119582]
	TIME [epoch: 6.39 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012742581339855053		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.012742581339855053 | validation: 0.0283032883953004]
	TIME [epoch: 6.41 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01593645310037313		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.01593645310037313 | validation: 0.03245794924037685]
	TIME [epoch: 6.38 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01181675673293037		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.01181675673293037 | validation: 0.028850583831088114]
	TIME [epoch: 6.42 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017911167584670172		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.017911167584670172 | validation: 0.019370820955902757]
	TIME [epoch: 6.42 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010593316177478232		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.010593316177478232 | validation: 0.031195049377530575]
	TIME [epoch: 6.44 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01351357895472923		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.01351357895472923 | validation: 0.026408741306199385]
	TIME [epoch: 6.4 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01269661693851974		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.01269661693851974 | validation: 0.02515222866229549]
	TIME [epoch: 6.41 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016322605224684466		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.016322605224684466 | validation: 0.019713889013559926]
	TIME [epoch: 6.41 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01507497552181948		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.01507497552181948 | validation: 0.022865777672952482]
	TIME [epoch: 6.41 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021178866606920133		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.021178866606920133 | validation: 0.027504276153850038]
	TIME [epoch: 6.39 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017549326145554385		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.017549326145554385 | validation: 0.03352313051924944]
	TIME [epoch: 6.4 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018221604269820287		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.018221604269820287 | validation: 0.021289574864098704]
	TIME [epoch: 6.45 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014659264815691679		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.014659264815691679 | validation: 0.021939925137980078]
	TIME [epoch: 6.41 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015987957458950458		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.015987957458950458 | validation: 0.023900718439626614]
	TIME [epoch: 6.4 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01367640034843175		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.01367640034843175 | validation: 0.027840339528534694]
	TIME [epoch: 6.39 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017734239577655905		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.017734239577655905 | validation: 0.03014022510252092]
	TIME [epoch: 6.38 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0168381343360043		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.0168381343360043 | validation: 0.03347475473094179]
	TIME [epoch: 6.4 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010540104000179264		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.010540104000179264 | validation: 0.035698142868878804]
	TIME [epoch: 6.4 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013640940376277074		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.013640940376277074 | validation: 0.02330084069360389]
	TIME [epoch: 6.43 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017636993638119103		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.017636993638119103 | validation: 0.028675332827912958]
	TIME [epoch: 6.4 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01689918328015702		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.01689918328015702 | validation: 0.025588877698078893]
	TIME [epoch: 6.4 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018057761226177315		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.018057761226177315 | validation: 0.02838703205399103]
	TIME [epoch: 6.39 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01586498674933729		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.01586498674933729 | validation: 0.03457494417397494]
	TIME [epoch: 6.39 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014628808310413268		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.014628808310413268 | validation: 0.028381165474306122]
	TIME [epoch: 6.4 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02157523990936846		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.02157523990936846 | validation: 0.02591693261979389]
	TIME [epoch: 6.4 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017518842283850186		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.017518842283850186 | validation: 0.02327745975571516]
	TIME [epoch: 6.41 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013724078728500802		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.013724078728500802 | validation: 0.027681865297672675]
	TIME [epoch: 6.43 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019520233228470504		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.019520233228470504 | validation: 0.028220723268989185]
	TIME [epoch: 6.42 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016586211319504766		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.016586211319504766 | validation: 0.026017259660886798]
	TIME [epoch: 6.41 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017081094820381084		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.017081094820381084 | validation: 0.03382091145017756]
	TIME [epoch: 6.39 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016247972104971385		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.016247972104971385 | validation: 0.028774906945910405]
	TIME [epoch: 6.41 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01531854757268618		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.01531854757268618 | validation: 0.029632499085478665]
	TIME [epoch: 6.39 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015611442505125413		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.015611442505125413 | validation: 0.027811215480648112]
	TIME [epoch: 6.41 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017622080324775587		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.017622080324775587 | validation: 0.024888377717914193]
	TIME [epoch: 6.45 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013928269898178984		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.013928269898178984 | validation: 0.030295733880664803]
	TIME [epoch: 6.39 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013496289584952623		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.013496289584952623 | validation: 0.02381118835830768]
	TIME [epoch: 6.4 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011643720406900555		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.011643720406900555 | validation: 0.026371913484607674]
	TIME [epoch: 6.42 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017133055614865337		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.017133055614865337 | validation: 0.025894713962647843]
	TIME [epoch: 6.41 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017404881193765414		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.017404881193765414 | validation: 0.029980995583701875]
	TIME [epoch: 6.4 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01831315284601001		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.01831315284601001 | validation: 0.023435411043827684]
	TIME [epoch: 6.41 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01512705272640106		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.01512705272640106 | validation: 0.02311229582174307]
	TIME [epoch: 6.45 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0199576409756977		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.0199576409756977 | validation: 0.036404716981038095]
	TIME [epoch: 6.4 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017176582398408333		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.017176582398408333 | validation: 0.012149453380084406]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r1_20240309_135632/states/model_tr_study2_1391.pth
	Model improved!!!
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015119090295290908		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.015119090295290908 | validation: 0.025828157090478723]
	TIME [epoch: 6.39 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013066607636859514		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.013066607636859514 | validation: 0.026987842683736555]
	TIME [epoch: 6.38 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014329307630974541		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.014329307630974541 | validation: 0.024009737510037165]
	TIME [epoch: 6.4 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018183492841663235		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.018183492841663235 | validation: 0.026380570545757497]
	TIME [epoch: 6.4 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016043949337918674		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.016043949337918674 | validation: 0.030153201932337375]
	TIME [epoch: 6.43 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014396270413580084		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.014396270413580084 | validation: 0.026191370966808427]
	TIME [epoch: 6.39 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016839092413504866		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.016839092413504866 | validation: 0.028348590516942537]
	TIME [epoch: 6.4 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018748818368023525		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.018748818368023525 | validation: 0.024899927895097772]
	TIME [epoch: 6.4 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017138032079321283		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.017138032079321283 | validation: 0.024452303576390576]
	TIME [epoch: 6.39 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015895474947102764		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.015895474947102764 | validation: 0.030611195979822755]
	TIME [epoch: 6.39 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015477373792414349		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.015477373792414349 | validation: 0.019402250811274203]
	TIME [epoch: 6.39 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01524915592081754		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.01524915592081754 | validation: 0.021316858440089393]
	TIME [epoch: 6.45 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01559067897573821		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.01559067897573821 | validation: 0.025947956087605993]
	TIME [epoch: 6.41 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01696586646978455		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.01696586646978455 | validation: 0.023612485307770985]
	TIME [epoch: 6.41 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015025907077038398		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.015025907077038398 | validation: 0.014143034774231658]
	TIME [epoch: 6.41 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015198479589662212		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.015198479589662212 | validation: 0.02665370281260307]
	TIME [epoch: 6.42 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015954621780926537		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.015954621780926537 | validation: 0.024108427171830912]
	TIME [epoch: 6.41 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014535546933199282		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.014535546933199282 | validation: 0.027299249788774446]
	TIME [epoch: 6.42 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014149693244474223		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.014149693244474223 | validation: 0.025913886948642356]
	TIME [epoch: 6.43 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015940339752434876		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.015940339752434876 | validation: 0.022068640006228008]
	TIME [epoch: 6.44 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014122746140101412		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.014122746140101412 | validation: 0.02277033815827385]
	TIME [epoch: 6.42 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01381158740934393		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.01381158740934393 | validation: 0.025726851142565375]
	TIME [epoch: 6.39 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010483214137916468		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.010483214137916468 | validation: 0.030018510533420164]
	TIME [epoch: 6.4 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01449731710172758		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.01449731710172758 | validation: 0.026040816879432997]
	TIME [epoch: 6.41 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015026090377464822		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.015026090377464822 | validation: 0.02985209747597415]
	TIME [epoch: 6.41 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014862221622726254		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.014862221622726254 | validation: 0.032871796409944275]
	TIME [epoch: 6.41 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012205158863502825		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.012205158863502825 | validation: 0.021834542453185005]
	TIME [epoch: 6.43 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014402260034223407		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.014402260034223407 | validation: 0.02287610897220305]
	TIME [epoch: 6.4 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015875214905207644		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.015875214905207644 | validation: 0.030676869509688846]
	TIME [epoch: 6.39 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02125390620184063		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.02125390620184063 | validation: 0.026753278639073532]
	TIME [epoch: 6.38 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017527470273577907		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.017527470273577907 | validation: 0.02998773076894175]
	TIME [epoch: 6.37 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014080550243120032		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.014080550243120032 | validation: 0.02229443655747643]
	TIME [epoch: 6.39 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01911890272584714		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.01911890272584714 | validation: 0.02829044097768042]
	TIME [epoch: 6.4 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013463590231603019		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.013463590231603019 | validation: 0.03561272036068404]
	TIME [epoch: 6.44 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018219947784707882		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.018219947784707882 | validation: 0.022420511190533295]
	TIME [epoch: 6.41 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013363199299012203		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.013363199299012203 | validation: 0.01827947227770569]
	TIME [epoch: 6.41 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013802871552301034		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.013802871552301034 | validation: 0.030275522755260527]
	TIME [epoch: 6.39 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015182428241597509		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.015182428241597509 | validation: 0.0263605074291556]
	TIME [epoch: 6.42 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016670316662189787		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.016670316662189787 | validation: 0.02221846785985788]
	TIME [epoch: 6.41 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01599347268717298		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.01599347268717298 | validation: 0.0239210562238548]
	TIME [epoch: 6.39 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011483228639436916		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.011483228639436916 | validation: 0.024266158151103015]
	TIME [epoch: 6.44 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01444306138191381		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.01444306138191381 | validation: 0.027646396016105742]
	TIME [epoch: 6.4 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013492047792636977		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.013492047792636977 | validation: 0.019575119230886295]
	TIME [epoch: 6.4 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01566622745140016		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.01566622745140016 | validation: 0.028837228005455462]
	TIME [epoch: 6.41 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011580730845734606		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.011580730845734606 | validation: 0.029682745442481284]
	TIME [epoch: 6.41 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012140902938291901		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.012140902938291901 | validation: 0.034427103323896584]
	TIME [epoch: 6.41 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01428439885176963		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.01428439885176963 | validation: 0.02386127857535319]
	TIME [epoch: 6.4 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01350520953750824		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.01350520953750824 | validation: 0.027957504750489845]
	TIME [epoch: 6.45 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01585418620453495		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.01585418620453495 | validation: 0.02307661598479612]
	TIME [epoch: 6.4 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014116183599564356		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.014116183599564356 | validation: 0.02589718284656]
	TIME [epoch: 6.4 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01504395750679308		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.01504395750679308 | validation: 0.029958367800760936]
	TIME [epoch: 6.41 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01407686945920656		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.01407686945920656 | validation: 0.028855552187592164]
	TIME [epoch: 6.41 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009918867582702008		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.009918867582702008 | validation: 0.026410815834576988]
	TIME [epoch: 6.4 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014454418148178994		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.014454418148178994 | validation: 0.021105409417748473]
	TIME [epoch: 6.42 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01381607504994589		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.01381607504994589 | validation: 0.025452756201271885]
	TIME [epoch: 6.43 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01896741705739472		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.01896741705739472 | validation: 0.024925087980487953]
	TIME [epoch: 6.42 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013476609653578504		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.013476609653578504 | validation: 0.023371277948987176]
	TIME [epoch: 6.39 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014722887928894375		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.014722887928894375 | validation: 0.02327759948719104]
	TIME [epoch: 6.4 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015487066732271534		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.015487066732271534 | validation: 0.027203664140015862]
	TIME [epoch: 6.4 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014759290762375712		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.014759290762375712 | validation: 0.0226257135351888]
	TIME [epoch: 6.41 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016524944761973206		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.016524944761973206 | validation: 0.02882327366468118]
	TIME [epoch: 6.41 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014694419690517758		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.014694419690517758 | validation: 0.027621886916936313]
	TIME [epoch: 6.41 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014406753777001145		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.014406753777001145 | validation: 0.03506354615256918]
	TIME [epoch: 6.43 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017507064907207513		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.017507064907207513 | validation: 0.02682533911713355]
	TIME [epoch: 6.39 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014723989710596647		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.014723989710596647 | validation: 0.026456348406362053]
	TIME [epoch: 6.4 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013070546876500824		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.013070546876500824 | validation: 0.024435045621590882]
	TIME [epoch: 6.4 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01614586069802737		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.01614586069802737 | validation: 0.02522654007322925]
	TIME [epoch: 6.39 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0142517503054727		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.0142517503054727 | validation: 0.028154572231811774]
	TIME [epoch: 6.39 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015752861132207766		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.015752861132207766 | validation: 0.02968051706105431]
	TIME [epoch: 6.39 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014095015234742162		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.014095015234742162 | validation: 0.02337506610716577]
	TIME [epoch: 6.43 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010937858877138112		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.010937858877138112 | validation: 0.022402548353172534]
	TIME [epoch: 6.4 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0186424883717164		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.0186424883717164 | validation: 0.03498520909971151]
	TIME [epoch: 6.4 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013777381182680331		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.013777381182680331 | validation: 0.026947808658263163]
	TIME [epoch: 6.39 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016932796854940296		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.016932796854940296 | validation: 0.03729402785265108]
	TIME [epoch: 6.4 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014758510422632067		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.014758510422632067 | validation: 0.029568596989393035]
	TIME [epoch: 6.39 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012331434954030902		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.012331434954030902 | validation: 0.02177736803466871]
	TIME [epoch: 6.39 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01589087130102384		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.01589087130102384 | validation: 0.026313197663784576]
	TIME [epoch: 6.43 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019780287204728065		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.019780287204728065 | validation: 0.02217750339093459]
	TIME [epoch: 6.4 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01657270735662016		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.01657270735662016 | validation: 0.021632823948705117]
	TIME [epoch: 6.39 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018082390417175215		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.018082390417175215 | validation: 0.027807223749654525]
	TIME [epoch: 6.39 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015939394153910304		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.015939394153910304 | validation: 0.025978092999890894]
	TIME [epoch: 6.38 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014752904697498041		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.014752904697498041 | validation: 0.017835751395782737]
	TIME [epoch: 6.39 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01527831547836278		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.01527831547836278 | validation: 0.03842874638064417]
	TIME [epoch: 6.4 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012963641950296124		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.012963641950296124 | validation: 0.026341393250274982]
	TIME [epoch: 6.42 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015901300327622582		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.015901300327622582 | validation: 0.02289234291327751]
	TIME [epoch: 6.4 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011881348549428128		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.011881348549428128 | validation: 0.022044040861976963]
	TIME [epoch: 6.39 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015069905674957869		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.015069905674957869 | validation: 0.02189905407156034]
	TIME [epoch: 6.39 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013346695234927078		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.013346695234927078 | validation: 0.025605632949904544]
	TIME [epoch: 6.4 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015808162896858324		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.015808162896858324 | validation: 0.01430175037553649]
	TIME [epoch: 6.4 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015771670748204385		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.015771670748204385 | validation: 0.024530664464404807]
	TIME [epoch: 6.4 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012668661443619429		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.012668661443619429 | validation: 0.02288286931068563]
	TIME [epoch: 6.41 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017702868374542925		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.017702868374542925 | validation: 0.02310884446169835]
	TIME [epoch: 6.41 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01812763701755002		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.01812763701755002 | validation: 0.018711934221594728]
	TIME [epoch: 6.4 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014304202639336006		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.014304202639336006 | validation: 0.026841075151936213]
	TIME [epoch: 6.4 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012720953968352804		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.012720953968352804 | validation: 0.02919440571134402]
	TIME [epoch: 6.4 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01893634785737406		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.01893634785737406 | validation: 0.0210278198492614]
	TIME [epoch: 6.4 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01066285898499477		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.01066285898499477 | validation: 0.021749690633197174]
	TIME [epoch: 6.4 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014335190041424526		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.014335190041424526 | validation: 0.026141163345662556]
	TIME [epoch: 6.41 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012320646340127639		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.012320646340127639 | validation: 0.02930197667366713]
	TIME [epoch: 6.42 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01338224046092467		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.01338224046092467 | validation: 0.02849845404031364]
	TIME [epoch: 6.4 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015255085011311183		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.015255085011311183 | validation: 0.02512258062425321]
	TIME [epoch: 6.4 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01348968076133888		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.01348968076133888 | validation: 0.018295503316514]
	TIME [epoch: 6.4 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017152157202994192		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.017152157202994192 | validation: 0.019668413485076097]
	TIME [epoch: 6.4 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014009686640410933		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.014009686640410933 | validation: 0.015312357663704734]
	TIME [epoch: 6.4 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01369945885931819		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.01369945885931819 | validation: 0.025348417940706327]
	TIME [epoch: 6.4 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017833593383139966		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.017833593383139966 | validation: 0.025321362499743455]
	TIME [epoch: 6.43 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014562643377912675		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.014562643377912675 | validation: 0.03413261758508614]
	TIME [epoch: 6.4 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015399852074982286		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.015399852074982286 | validation: 0.0345755891525924]
	TIME [epoch: 6.4 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018055371361026477		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.018055371361026477 | validation: 0.02412097312392862]
	TIME [epoch: 6.4 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01598569483865691		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.01598569483865691 | validation: 0.024212572864445694]
	TIME [epoch: 6.4 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01682569987434166		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.01682569987434166 | validation: 0.028814828918776954]
	TIME [epoch: 6.42 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016318418238445424		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.016318418238445424 | validation: 0.028669193154884018]
	TIME [epoch: 6.4 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012176625872179875		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.012176625872179875 | validation: 0.024513017563660845]
	TIME [epoch: 6.44 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012681467915668267		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.012681467915668267 | validation: 0.024886437326249067]
	TIME [epoch: 6.4 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012455373265264164		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.012455373265264164 | validation: 0.020430962221523997]
	TIME [epoch: 6.41 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014231801177707334		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.014231801177707334 | validation: 0.026859501912941015]
	TIME [epoch: 6.41 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015596036573132317		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.015596036573132317 | validation: 0.02453635122348429]
	TIME [epoch: 6.41 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013679344488952092		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.013679344488952092 | validation: 0.027612876080975308]
	TIME [epoch: 6.4 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010740447553416315		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.010740447553416315 | validation: 0.03071599255321623]
	TIME [epoch: 6.42 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017340074567855013		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.017340074567855013 | validation: 0.023036953602265268]
	TIME [epoch: 6.43 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015165717418910173		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.015165717418910173 | validation: 0.022474913118748052]
	TIME [epoch: 6.39 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014377785710691362		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.014377785710691362 | validation: 0.018998033740143052]
	TIME [epoch: 6.4 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01215240029478164		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.01215240029478164 | validation: 0.019774899944677543]
	TIME [epoch: 6.41 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014965838601181634		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.014965838601181634 | validation: 0.027937347694493644]
	TIME [epoch: 6.41 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015682493462940934		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.015682493462940934 | validation: 0.03218232981923406]
	TIME [epoch: 6.4 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01925202199298099		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.01925202199298099 | validation: 0.025394990034155112]
	TIME [epoch: 6.4 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01634688381155768		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.01634688381155768 | validation: 0.022683525887087726]
	TIME [epoch: 6.42 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013425909587702987		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.013425909587702987 | validation: 0.029324197836239695]
	TIME [epoch: 6.43 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01286204557206463		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.01286204557206463 | validation: 0.028067241748419]
	TIME [epoch: 6.4 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012778942502020763		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.012778942502020763 | validation: 0.02589817589794625]
	TIME [epoch: 6.4 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014202999041357611		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.014202999041357611 | validation: 0.019470494703272896]
	TIME [epoch: 6.41 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011699376231404554		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.011699376231404554 | validation: 0.024343272611483623]
	TIME [epoch: 6.4 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009778072464022111		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.009778072464022111 | validation: 0.030066499219125235]
	TIME [epoch: 6.41 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016072062458042886		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.016072062458042886 | validation: 0.029794968242011503]
	TIME [epoch: 6.42 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012383734623666464		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.012383734623666464 | validation: 0.026438676392748363]
	TIME [epoch: 6.45 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01279022575782195		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.01279022575782195 | validation: 0.03165929050795023]
	TIME [epoch: 6.41 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014691140552652276		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.014691140552652276 | validation: 0.013987104459770715]
	TIME [epoch: 6.41 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016745637272818994		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.016745637272818994 | validation: 0.02000582788009967]
	TIME [epoch: 6.4 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017334578451309045		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.017334578451309045 | validation: 0.022539137840750536]
	TIME [epoch: 6.41 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01704156328639018		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.01704156328639018 | validation: 0.019270559367141477]
	TIME [epoch: 6.41 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01729059710864793		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.01729059710864793 | validation: 0.03136357829235545]
	TIME [epoch: 6.41 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016912166485943115		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.016912166485943115 | validation: 0.01842738036009086]
	TIME [epoch: 6.44 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015556450764928825		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.015556450764928825 | validation: 0.028204108854402332]
	TIME [epoch: 6.41 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015076864670915385		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.015076864670915385 | validation: 0.029223019130661197]
	TIME [epoch: 6.41 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013893214178276238		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.013893214178276238 | validation: 0.02223992575577473]
	TIME [epoch: 6.41 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01576521398631479		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.01576521398631479 | validation: 0.023937866753866343]
	TIME [epoch: 6.41 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013119980513145103		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.013119980513145103 | validation: 0.029147093912002955]
	TIME [epoch: 6.41 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014066469876214401		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.014066469876214401 | validation: 0.02511425608572483]
	TIME [epoch: 6.41 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013820136129587653		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.013820136129587653 | validation: 0.02102631442030158]
	TIME [epoch: 6.45 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01212118290423317		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.01212118290423317 | validation: 0.023851601658380007]
	TIME [epoch: 6.41 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016332484321942013		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.016332484321942013 | validation: 0.030475896435958702]
	TIME [epoch: 6.41 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014757422975706149		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.014757422975706149 | validation: 0.029117145106161004]
	TIME [epoch: 6.4 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01222420600571329		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.01222420600571329 | validation: 0.02294822453789293]
	TIME [epoch: 6.41 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014138992337855788		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.014138992337855788 | validation: 0.02205163883873575]
	TIME [epoch: 6.41 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015113252448818356		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.015113252448818356 | validation: 0.024252157880295538]
	TIME [epoch: 6.42 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01577130429651314		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.01577130429651314 | validation: 0.027417320646320756]
	TIME [epoch: 6.44 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017354590707432675		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.017354590707432675 | validation: 0.0287225745685956]
	TIME [epoch: 6.41 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013163977020294846		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.013163977020294846 | validation: 0.035311055005704486]
	TIME [epoch: 6.4 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013618938935901078		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.013618938935901078 | validation: 0.02976139105649743]
	TIME [epoch: 6.4 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0140193160225753		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.0140193160225753 | validation: 0.027255117259164314]
	TIME [epoch: 6.41 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011681748581537883		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.011681748581537883 | validation: 0.022292956268654397]
	TIME [epoch: 6.41 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007032316583206232		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.007032316583206232 | validation: 0.019405993247083662]
	TIME [epoch: 6.42 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01625793663135955		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.01625793663135955 | validation: 0.023691040592567953]
	TIME [epoch: 6.41 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01457684220535468		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.01457684220535468 | validation: 0.03450719851580011]
	TIME [epoch: 6.42 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01471485236627413		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.01471485236627413 | validation: 0.01999559377499766]
	TIME [epoch: 6.39 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014660492592782837		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.014660492592782837 | validation: 0.021211347798582105]
	TIME [epoch: 6.39 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01566227122816609		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.01566227122816609 | validation: 0.01743153082542173]
	TIME [epoch: 6.38 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015600128306959608		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.015600128306959608 | validation: 0.027022097714389928]
	TIME [epoch: 6.39 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015054809325990796		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.015054809325990796 | validation: 0.03034921532113485]
	TIME [epoch: 6.38 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01709454844676481		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.01709454844676481 | validation: 0.02817319648405971]
	TIME [epoch: 6.39 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012425139209432466		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.012425139209432466 | validation: 0.03322792306297706]
	TIME [epoch: 6.42 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014347986624710068		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.014347986624710068 | validation: 0.017362831734352064]
	TIME [epoch: 6.39 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014551369837944923		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.014551369837944923 | validation: 0.028760195110520106]
	TIME [epoch: 6.39 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011481080756404326		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.011481080756404326 | validation: 0.02934671845781608]
	TIME [epoch: 6.38 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016403031469957256		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.016403031469957256 | validation: 0.025528026052099754]
	TIME [epoch: 6.39 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014589226597996349		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.014589226597996349 | validation: 0.0213780682312774]
	TIME [epoch: 6.39 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015675071650272668		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.015675071650272668 | validation: 0.02655844613839129]
	TIME [epoch: 6.39 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011858669408414128		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.011858669408414128 | validation: 0.03194834958372295]
	TIME [epoch: 6.43 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011415019806402246		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.011415019806402246 | validation: 0.02755626259781276]
	TIME [epoch: 6.4 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014654073497842628		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.014654073497842628 | validation: 0.02691816316775892]
	TIME [epoch: 6.4 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015509358176682368		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.015509358176682368 | validation: 0.02614469093393077]
	TIME [epoch: 6.41 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017461366136737228		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.017461366136737228 | validation: 0.02360022106911945]
	TIME [epoch: 6.4 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011879893638078311		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.011879893638078311 | validation: 0.022782025706259278]
	TIME [epoch: 6.4 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011538391941348838		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.011538391941348838 | validation: 0.029612106399134953]
	TIME [epoch: 6.4 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018181779297340356		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.018181779297340356 | validation: 0.023705605697051827]
	TIME [epoch: 6.45 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014749577380748724		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.014749577380748724 | validation: 0.02511658310558832]
	TIME [epoch: 6.39 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013468013359773328		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.013468013359773328 | validation: 0.027909124793426426]
	TIME [epoch: 6.4 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013660653694638569		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.013660653694638569 | validation: 0.023481657325637242]
	TIME [epoch: 6.39 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01494207002629733		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.01494207002629733 | validation: 0.019863884455971]
	TIME [epoch: 6.4 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013081678580616539		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.013081678580616539 | validation: 0.024684884797256973]
	TIME [epoch: 6.39 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01576523128799999		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.01576523128799999 | validation: 0.024202107893559265]
	TIME [epoch: 6.41 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011759233617885157		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.011759233617885157 | validation: 0.023042659301883154]
	TIME [epoch: 6.44 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019879440529976266		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.019879440529976266 | validation: 0.02816464134164992]
	TIME [epoch: 6.41 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01195416650063913		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.01195416650063913 | validation: 0.025894623427003337]
	TIME [epoch: 6.4 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01474944414553677		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.01474944414553677 | validation: 0.028625739408079217]
	TIME [epoch: 6.41 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01661444818212112		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.01661444818212112 | validation: 0.03236526824475943]
	TIME [epoch: 6.41 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014307422654166974		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.014307422654166974 | validation: 0.031864868707628745]
	TIME [epoch: 6.39 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01656508863594673		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.01656508863594673 | validation: 0.028137229673551777]
	TIME [epoch: 6.42 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015539443145077079		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.015539443145077079 | validation: 0.028931846989648635]
	TIME [epoch: 6.43 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016436711205415157		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.016436711205415157 | validation: 0.029592500880537564]
	TIME [epoch: 6.44 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016800628739750592		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.016800628739750592 | validation: 0.029248334974365246]
	TIME [epoch: 6.4 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016015171276350586		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.016015171276350586 | validation: 0.024375879444307396]
	TIME [epoch: 6.41 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016059774024685773		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.016059774024685773 | validation: 0.025967546908134468]
	TIME [epoch: 6.4 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010922042854702566		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.010922042854702566 | validation: 0.02587338673241309]
	TIME [epoch: 6.42 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011372393106781472		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.011372393106781472 | validation: 0.022487414892722844]
	TIME [epoch: 6.4 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016707005903786015		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.016707005903786015 | validation: 0.021304606660513575]
	TIME [epoch: 6.42 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017266195327927433		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.017266195327927433 | validation: 0.022198875673419043]
	TIME [epoch: 6.45 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017649680714181274		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.017649680714181274 | validation: 0.01739915140233659]
	TIME [epoch: 6.42 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013960020793132327		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.013960020793132327 | validation: 0.026486788601771307]
	TIME [epoch: 6.41 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012509688685278044		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.012509688685278044 | validation: 0.028114837279357707]
	TIME [epoch: 6.41 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019131097104640102		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.019131097104640102 | validation: 0.027998152840471472]
	TIME [epoch: 6.41 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013851411947012612		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.013851411947012612 | validation: 0.026812590014400364]
	TIME [epoch: 6.41 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01671091841941934		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.01671091841941934 | validation: 0.03120899882405122]
	TIME [epoch: 6.41 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0188301767714399		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.0188301767714399 | validation: 0.025860620462000217]
	TIME [epoch: 6.44 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01766803188985071		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.01766803188985071 | validation: 0.024986024625224257]
	TIME [epoch: 6.41 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013600034291238778		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.013600034291238778 | validation: 0.021614478432032094]
	TIME [epoch: 6.41 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013564456560556153		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.013564456560556153 | validation: 0.021809865227628854]
	TIME [epoch: 6.41 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016464691276930756		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.016464691276930756 | validation: 0.024606533952051847]
	TIME [epoch: 6.41 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01920861029439634		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.01920861029439634 | validation: 0.024405852611172778]
	TIME [epoch: 6.4 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01557861029430365		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.01557861029430365 | validation: 0.022743650265807377]
	TIME [epoch: 6.4 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013352158430626773		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.013352158430626773 | validation: 0.03460448251221614]
	TIME [epoch: 6.44 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013080453095795768		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.013080453095795768 | validation: 0.022996098674786244]
	TIME [epoch: 6.4 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01304425362788273		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.01304425362788273 | validation: 0.024634643714183918]
	TIME [epoch: 6.4 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01405615201960863		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.01405615201960863 | validation: 0.02250668537531034]
	TIME [epoch: 6.41 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012615471771880788		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.012615471771880788 | validation: 0.03223641247395644]
	TIME [epoch: 6.42 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015669119326453734		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.015669119326453734 | validation: 0.02341667349539073]
	TIME [epoch: 6.41 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01701239428881307		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.01701239428881307 | validation: 0.02468958365774942]
	TIME [epoch: 6.41 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015761912376174737		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.015761912376174737 | validation: 0.023933515987688392]
	TIME [epoch: 6.45 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014260645736067345		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.014260645736067345 | validation: 0.013647980880636701]
	TIME [epoch: 6.41 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014190004386294546		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.014190004386294546 | validation: 0.02213505961831203]
	TIME [epoch: 6.41 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014033586670245495		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.014033586670245495 | validation: 0.02111822840754665]
	TIME [epoch: 6.41 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014241027410928893		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.014241027410928893 | validation: 0.025956410983401054]
	TIME [epoch: 6.41 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013700069349407306		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.013700069349407306 | validation: 0.027888923759902377]
	TIME [epoch: 6.41 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01329674339131557		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.01329674339131557 | validation: 0.021357372322884524]
	TIME [epoch: 6.41 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013576259145320482		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.013576259145320482 | validation: 0.024175994880708266]
	TIME [epoch: 6.41 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015490531223475636		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.015490531223475636 | validation: 0.03173626019907525]
	TIME [epoch: 6.43 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012991335038688444		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.012991335038688444 | validation: 0.0326200874329519]
	TIME [epoch: 6.4 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012797926995322177		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.012797926995322177 | validation: 0.03011806353603932]
	TIME [epoch: 6.42 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015514664932754016		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.015514664932754016 | validation: 0.023674934709169565]
	TIME [epoch: 6.4 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016872532592387704		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.016872532592387704 | validation: 0.018454816616190067]
	TIME [epoch: 6.39 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014437165321368762		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.014437165321368762 | validation: 0.028284076805265807]
	TIME [epoch: 6.41 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013706968255174862		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.013706968255174862 | validation: 0.022541785923934642]
	TIME [epoch: 6.41 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014176185255281977		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.014176185255281977 | validation: 0.017781506885731883]
	TIME [epoch: 6.45 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01418034951428877		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.01418034951428877 | validation: 0.02717235197783337]
	TIME [epoch: 6.42 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013407770513415972		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.013407770513415972 | validation: 0.03059701625046987]
	TIME [epoch: 6.4 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011658321248771565		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.011658321248771565 | validation: 0.031027679880052218]
	TIME [epoch: 6.42 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013211755270773541		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.013211755270773541 | validation: 0.024311975343428896]
	TIME [epoch: 6.41 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013165832487120688		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.013165832487120688 | validation: 0.013927773647528126]
	TIME [epoch: 6.41 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012707843768436304		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.012707843768436304 | validation: 0.025713358109492993]
	TIME [epoch: 6.42 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017588504375371114		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.017588504375371114 | validation: 0.026944066359307746]
	TIME [epoch: 6.42 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015934167411205787		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.015934167411205787 | validation: 0.017806985714030547]
	TIME [epoch: 6.41 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014306329453682032		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.014306329453682032 | validation: 0.02560112500355203]
	TIME [epoch: 6.41 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012762507204363605		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.012762507204363605 | validation: 0.021012221364198662]
	TIME [epoch: 6.42 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014989053880703453		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.014989053880703453 | validation: 0.02633044090739392]
	TIME [epoch: 6.41 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014224640535379723		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.014224640535379723 | validation: 0.025874147009973623]
	TIME [epoch: 6.42 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012283909237481246		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.012283909237481246 | validation: 0.023004245223496148]
	TIME [epoch: 6.42 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014219471871645515		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.014219471871645515 | validation: 0.020741339167274716]
	TIME [epoch: 6.46 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01750605749168364		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.01750605749168364 | validation: 0.018594554694156617]
	TIME [epoch: 6.42 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014265995071888346		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.014265995071888346 | validation: 0.020137377991667718]
	TIME [epoch: 6.39 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012710418960375006		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.012710418960375006 | validation: 0.033734128083469136]
	TIME [epoch: 6.41 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014928615226331163		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.014928615226331163 | validation: 0.02453901074215442]
	TIME [epoch: 6.41 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013026068616783364		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.013026068616783364 | validation: 0.020043892535256524]
	TIME [epoch: 6.41 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013004064355780777		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.013004064355780777 | validation: 0.03531949666109527]
	TIME [epoch: 6.42 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013249364511253376		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.013249364511253376 | validation: 0.024326954265269665]
	TIME [epoch: 6.45 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014842821454211147		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.014842821454211147 | validation: 0.0238207569224252]
	TIME [epoch: 6.42 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014762129852395818		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.014762129852395818 | validation: 0.013843380070078607]
	TIME [epoch: 6.41 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012094212168717897		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.012094212168717897 | validation: 0.03070871248156381]
	TIME [epoch: 6.41 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014735641055543803		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.014735641055543803 | validation: 0.023062449426591174]
	TIME [epoch: 6.4 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013162075185026944		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.013162075185026944 | validation: 0.012210106766864539]
	TIME [epoch: 6.41 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013119556919555998		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.013119556919555998 | validation: 0.020793400089965896]
	TIME [epoch: 6.4 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011945105740113836		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.011945105740113836 | validation: 0.02529946738397121]
	TIME [epoch: 6.43 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01614583259754713		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.01614583259754713 | validation: 0.029357721105864147]
	TIME [epoch: 6.43 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01330944193142588		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.01330944193142588 | validation: 0.023703340715617686]
	TIME [epoch: 6.41 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016961360259054686		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.016961360259054686 | validation: 0.021015713477992783]
	TIME [epoch: 6.4 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016400276688841548		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.016400276688841548 | validation: 0.02278787365033872]
	TIME [epoch: 6.41 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013780603963378447		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.013780603963378447 | validation: 0.027037425037508472]
	TIME [epoch: 6.42 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01340617929762027		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.01340617929762027 | validation: 0.02725068430623473]
	TIME [epoch: 6.41 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014026275772793646		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.014026275772793646 | validation: 0.0195885684457706]
	TIME [epoch: 6.41 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012589622491198615		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.012589622491198615 | validation: 0.026025890842699254]
	TIME [epoch: 6.42 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014251911802374236		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.014251911802374236 | validation: 0.025548607912725618]
	TIME [epoch: 6.4 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015180775054424351		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.015180775054424351 | validation: 0.02613744712591337]
	TIME [epoch: 6.41 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012947848571421127		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.012947848571421127 | validation: 0.01941287719086921]
	TIME [epoch: 6.38 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011647559052613844		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.011647559052613844 | validation: 0.025578888094352478]
	TIME [epoch: 6.4 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012944272906307527		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.012944272906307527 | validation: 0.026972900914533877]
	TIME [epoch: 6.39 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015866465249966155		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.015866465249966155 | validation: 0.019379687162548308]
	TIME [epoch: 6.41 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012880969691185244		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.012880969691185244 | validation: 0.023751731694933782]
	TIME [epoch: 6.44 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017578718015685335		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.017578718015685335 | validation: 0.027900739473943635]
	TIME [epoch: 6.4 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014672188451567666		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.014672188451567666 | validation: 0.02484441483638852]
	TIME [epoch: 6.41 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010734474078559167		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.010734474078559167 | validation: 0.026432888691533034]
	TIME [epoch: 6.4 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012548117155936749		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.012548117155936749 | validation: 0.018227870835682974]
	TIME [epoch: 6.4 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012330872538761086		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.012330872538761086 | validation: 0.030728543662097884]
	TIME [epoch: 6.41 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013715978115928638		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.013715978115928638 | validation: 0.01786589871533749]
	TIME [epoch: 6.39 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014403159178959613		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.014403159178959613 | validation: 0.015231185860273095]
	TIME [epoch: 6.44 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01661369291440409		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.01661369291440409 | validation: 0.025602142091743156]
	TIME [epoch: 6.41 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013252475744133234		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.013252475744133234 | validation: 0.03100974327343193]
	TIME [epoch: 6.4 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013692966729630215		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.013692966729630215 | validation: 0.025585668733434583]
	TIME [epoch: 6.42 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013396351975593954		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.013396351975593954 | validation: 0.026470351022226085]
	TIME [epoch: 6.4 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012327271147229278		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.012327271147229278 | validation: 0.024310930048988006]
	TIME [epoch: 6.39 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013121052802479957		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.013121052802479957 | validation: 0.026079203261395803]
	TIME [epoch: 6.4 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012955196037974615		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.012955196037974615 | validation: 0.025694767809513124]
	TIME [epoch: 6.45 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01640751291983457		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.01640751291983457 | validation: 0.026737036292039062]
	TIME [epoch: 6.4 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013375987277712862		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.013375987277712862 | validation: 0.02595555197135679]
	TIME [epoch: 6.41 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013778842023251338		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.013778842023251338 | validation: 0.027115411231249508]
	TIME [epoch: 6.41 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012425161698521559		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.012425161698521559 | validation: 0.02399563144180933]
	TIME [epoch: 6.41 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01133541835802272		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.01133541835802272 | validation: 0.021393851783245217]
	TIME [epoch: 6.41 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01547112822171284		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.01547112822171284 | validation: 0.02447982473101412]
	TIME [epoch: 6.41 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01088145498635006		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.01088145498635006 | validation: 0.029038385133541463]
	TIME [epoch: 6.41 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01702857241459018		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.01702857241459018 | validation: 0.022123773210668284]
	TIME [epoch: 6.42 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014701903276577208		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.014701903276577208 | validation: 0.024814733236921353]
	TIME [epoch: 6.41 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012789537542210468		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.012789537542210468 | validation: 0.03217737814369546]
	TIME [epoch: 6.41 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014088880545004392		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.014088880545004392 | validation: 0.018954129311574034]
	TIME [epoch: 6.39 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015491058368127256		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.015491058368127256 | validation: 0.029414505901165466]
	TIME [epoch: 6.42 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012190450862393617		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.012190450862393617 | validation: 0.020149093416592073]
	TIME [epoch: 6.41 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014296290042492658		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.014296290042492658 | validation: 0.031712604112101826]
	TIME [epoch: 6.43 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015500880081396051		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.015500880081396051 | validation: 0.022854862632734056]
	TIME [epoch: 6.42 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013151075022100887		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.013151075022100887 | validation: 0.030659710612093417]
	TIME [epoch: 6.41 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012010325536093994		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.012010325536093994 | validation: 0.029508800394262628]
	TIME [epoch: 6.41 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013980367219202601		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.013980367219202601 | validation: 0.02674439540221764]
	TIME [epoch: 6.39 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007978925849096798		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.007978925849096798 | validation: 0.012979312500048306]
	TIME [epoch: 6.39 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01269874990913097		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.01269874990913097 | validation: 0.025134087796793273]
	TIME [epoch: 6.42 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013528001163998915		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.013528001163998915 | validation: 0.028486792222953063]
	TIME [epoch: 6.4 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014994568106014752		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.014994568106014752 | validation: 0.019397293021135173]
	TIME [epoch: 6.43 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01235527389313501		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.01235527389313501 | validation: 0.024658874314761912]
	TIME [epoch: 6.4 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012446451076600066		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.012446451076600066 | validation: 0.024792715369249693]
	TIME [epoch: 6.41 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012213586190404892		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.012213586190404892 | validation: 0.017766127055341946]
	TIME [epoch: 6.4 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013354254032772845		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.013354254032772845 | validation: 0.023708291005903895]
	TIME [epoch: 6.41 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014526769212565975		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.014526769212565975 | validation: 0.020856369621651546]
	TIME [epoch: 6.4 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012938963197438293		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.012938963197438293 | validation: 0.029696230049837073]
	TIME [epoch: 6.4 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012645272667521905		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.012645272667521905 | validation: 0.03375273204624303]
	TIME [epoch: 6.45 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016443267661751484		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.016443267661751484 | validation: 0.02875920334442432]
	TIME [epoch: 6.42 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012855442978118997		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.012855442978118997 | validation: 0.026241384273054665]
	TIME [epoch: 6.39 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011955910512307072		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.011955910512307072 | validation: 0.026630423077831224]
	TIME [epoch: 6.41 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015191920790354366		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.015191920790354366 | validation: 0.03478138532293002]
	TIME [epoch: 6.4 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014277681752496116		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.014277681752496116 | validation: 0.029520600483135696]
	TIME [epoch: 6.41 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014960514703618264		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.014960514703618264 | validation: 0.024295284831520533]
	TIME [epoch: 6.4 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017720987333653508		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.017720987333653508 | validation: 0.028770501058132832]
	TIME [epoch: 6.44 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013211528627567318		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.013211528627567318 | validation: 0.024860589044889966]
	TIME [epoch: 6.41 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015301896794417732		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.015301896794417732 | validation: 0.027601606049189837]
	TIME [epoch: 6.42 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012833991718812294		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.012833991718812294 | validation: 0.03051255374411599]
	TIME [epoch: 6.4 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00950953961981175		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.00950953961981175 | validation: 0.024681256486942686]
	TIME [epoch: 6.42 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012071144457473076		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.012071144457473076 | validation: 0.02483888980708666]
	TIME [epoch: 6.39 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013977711802441641		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.013977711802441641 | validation: 0.0206532238549228]
	TIME [epoch: 6.41 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013051986907816247		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.013051986907816247 | validation: 0.027294098045104968]
	TIME [epoch: 6.41 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01587944790701995		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.01587944790701995 | validation: 0.03652743263879539]
	TIME [epoch: 6.44 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012816379802805493		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.012816379802805493 | validation: 0.026839097131746252]
	TIME [epoch: 6.4 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016355249161858463		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.016355249161858463 | validation: 0.02544222727613449]
	TIME [epoch: 6.37 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012056232777151524		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.012056232777151524 | validation: 0.029784975224517254]
	TIME [epoch: 6.39 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012207344282414727		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.012207344282414727 | validation: 0.029788242355295425]
	TIME [epoch: 6.39 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01414611622293149		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.01414611622293149 | validation: 0.021108146025166495]
	TIME [epoch: 6.39 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01709556197050172		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.01709556197050172 | validation: 0.02922643886497746]
	TIME [epoch: 6.41 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013819090181234887		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.013819090181234887 | validation: 0.022675877929896872]
	TIME [epoch: 6.42 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011069069735005318		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.011069069735005318 | validation: 0.026188484974938007]
	TIME [epoch: 6.4 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011041872724007917		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.011041872724007917 | validation: 0.024928863905865004]
	TIME [epoch: 6.39 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012614767356569634		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.012614767356569634 | validation: 0.020117709710572244]
	TIME [epoch: 6.39 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013746884263117286		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.013746884263117286 | validation: 0.02481244783646369]
	TIME [epoch: 6.37 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0115501560118556		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.0115501560118556 | validation: 0.03312311601608621]
	TIME [epoch: 6.39 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010840817523397958		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.010840817523397958 | validation: 0.025440842100424133]
	TIME [epoch: 6.39 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011615988240952795		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.011615988240952795 | validation: 0.02860417698044174]
	TIME [epoch: 6.44 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014635161957125293		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.014635161957125293 | validation: 0.02469616306268778]
	TIME [epoch: 6.4 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012582806203924525		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.012582806203924525 | validation: 0.016646653135923985]
	TIME [epoch: 6.39 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015979227982733303		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.015979227982733303 | validation: 0.023568610133397675]
	TIME [epoch: 6.4 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013766024600489264		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.013766024600489264 | validation: 0.026270331114182692]
	TIME [epoch: 6.41 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011581826632684186		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.011581826632684186 | validation: 0.02046807165995617]
	TIME [epoch: 6.39 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01411482538995862		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.01411482538995862 | validation: 0.02736645105086763]
	TIME [epoch: 6.41 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01068805076256405		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.01068805076256405 | validation: 0.0317350519164368]
	TIME [epoch: 6.44 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015013786936134567		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.015013786936134567 | validation: 0.025758298675518765]
	TIME [epoch: 6.41 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01019731350695294		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.01019731350695294 | validation: 0.0321945006779205]
	TIME [epoch: 6.39 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009899122940210801		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.009899122940210801 | validation: 0.022343325671694267]
	TIME [epoch: 6.4 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012911042502835254		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.012911042502835254 | validation: 0.020624550584607337]
	TIME [epoch: 6.41 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01487101754835504		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.01487101754835504 | validation: 0.021752228271954808]
	TIME [epoch: 6.41 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014653468028468912		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.014653468028468912 | validation: 0.028259893658719372]
	TIME [epoch: 6.42 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012923807701121358		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.012923807701121358 | validation: 0.022868292818318967]
	TIME [epoch: 6.45 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012834147144465218		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.012834147144465218 | validation: 0.026380249378402124]
	TIME [epoch: 6.4 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01566657121021633		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.01566657121021633 | validation: 0.022824630814591594]
	TIME [epoch: 6.41 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012674025104949598		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.012674025104949598 | validation: 0.024226639845930303]
	TIME [epoch: 6.43 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01129228308173222		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.01129228308173222 | validation: 0.03334999670361515]
	TIME [epoch: 6.41 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015448089774914983		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.015448089774914983 | validation: 0.020723006508149403]
	TIME [epoch: 6.41 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011797334747102832		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.011797334747102832 | validation: 0.026855292359931206]
	TIME [epoch: 6.4 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01425010670163294		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.01425010670163294 | validation: 0.01717324933967657]
	TIME [epoch: 6.42 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011704074881320456		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.011704074881320456 | validation: 0.02800583063528145]
	TIME [epoch: 6.43 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012910510517022663		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.012910510517022663 | validation: 0.02777676334497186]
	TIME [epoch: 6.42 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012059681324345914		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.012059681324345914 | validation: 0.025412030303892996]
	TIME [epoch: 6.41 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013738850799896618		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.013738850799896618 | validation: 0.025351015977021395]
	TIME [epoch: 6.4 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015849893896594493		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.015849893896594493 | validation: 0.026950842393424983]
	TIME [epoch: 6.4 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012343138811676414		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.012343138811676414 | validation: 0.0217902253287966]
	TIME [epoch: 6.39 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014094917356859983		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.014094917356859983 | validation: 0.02521070323075143]
	TIME [epoch: 6.43 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01482555172150291		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.01482555172150291 | validation: 0.030893068455827254]
	TIME [epoch: 6.43 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011567918815719986		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.011567918815719986 | validation: 0.03307862186326213]
	TIME [epoch: 6.41 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013232931703502943		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.013232931703502943 | validation: 0.019061942192722996]
	TIME [epoch: 6.4 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013066904205237964		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.013066904205237964 | validation: 0.023952870176907125]
	TIME [epoch: 6.42 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013690808524072163		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.013690808524072163 | validation: 0.02403107677862423]
	TIME [epoch: 6.4 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0145189242706809		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.0145189242706809 | validation: 0.017553706570875724]
	TIME [epoch: 6.41 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017532552448320502		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.017532552448320502 | validation: 0.02219216576694665]
	TIME [epoch: 6.41 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013626146015367923		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.013626146015367923 | validation: 0.018512792576431996]
	TIME [epoch: 6.43 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015093554030413008		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.015093554030413008 | validation: 0.02238201651228657]
	TIME [epoch: 6.4 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014194481396144171		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.014194481396144171 | validation: 0.020402387085485144]
	TIME [epoch: 6.4 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017398389688054336		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.017398389688054336 | validation: 0.02829693160774488]
	TIME [epoch: 6.4 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013735944593558414		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.013735944593558414 | validation: 0.02873664272556516]
	TIME [epoch: 6.4 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014278730240520992		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.014278730240520992 | validation: 0.02278950436812684]
	TIME [epoch: 6.4 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015326287878859346		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.015326287878859346 | validation: 0.024716839256238417]
	TIME [epoch: 6.4 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013834881480616068		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.013834881480616068 | validation: 0.019966544953679062]
	TIME [epoch: 6.44 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010495076150518732		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.010495076150518732 | validation: 0.02101661659812915]
	TIME [epoch: 6.4 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015094666322357269		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.015094666322357269 | validation: 0.02550094875995575]
	TIME [epoch: 6.41 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015554773648624304		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.015554773648624304 | validation: 0.015006927632532013]
	TIME [epoch: 6.42 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01269986266856025		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.01269986266856025 | validation: 0.030443643377861405]
	TIME [epoch: 6.41 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013759891979657633		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.013759891979657633 | validation: 0.024773691729224685]
	TIME [epoch: 6.39 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01345045322372809		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.01345045322372809 | validation: 0.028635911625478655]
	TIME [epoch: 6.41 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01374444332002098		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.01374444332002098 | validation: 0.023520919721805967]
	TIME [epoch: 6.43 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013258036517066831		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.013258036517066831 | validation: 0.01977257158983841]
	TIME [epoch: 6.42 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01431141225163285		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.01431141225163285 | validation: 0.02744244715376464]
	TIME [epoch: 6.41 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012497370966763142		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.012497370966763142 | validation: 0.017401517215989665]
	TIME [epoch: 6.42 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011830221907297055		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.011830221907297055 | validation: 0.024152159607140167]
	TIME [epoch: 6.4 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014123191413156194		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.014123191413156194 | validation: 0.025965127754134825]
	TIME [epoch: 6.42 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013593053889221595		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.013593053889221595 | validation: 0.018890188028214197]
	TIME [epoch: 6.39 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012829979527543622		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.012829979527543622 | validation: 0.024479537528996537]
	TIME [epoch: 6.45 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015064152052994096		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.015064152052994096 | validation: 0.030702795527434344]
	TIME [epoch: 6.41 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012977311133511905		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.012977311133511905 | validation: 0.025797068864627844]
	TIME [epoch: 6.4 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013960862363564319		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.013960862363564319 | validation: 0.028878248273714303]
	TIME [epoch: 6.41 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01308462946482292		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.01308462946482292 | validation: 0.022907189807418796]
	TIME [epoch: 6.4 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016612528638747407		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.016612528638747407 | validation: 0.029655313172104028]
	TIME [epoch: 6.39 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013159036775261604		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.013159036775261604 | validation: 0.023504208076771702]
	TIME [epoch: 6.41 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014633929276211498		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.014633929276211498 | validation: 0.02801282744145115]
	TIME [epoch: 6.41 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01521479508078647		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.01521479508078647 | validation: 0.025789126449673613]
	TIME [epoch: 6.44 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015528232653719535		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.015528232653719535 | validation: 0.024859567691114498]
	TIME [epoch: 6.4 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013283061857284994		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.013283061857284994 | validation: 0.024484288988550297]
	TIME [epoch: 6.41 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013565606445022848		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.013565606445022848 | validation: 0.030006626465522965]
	TIME [epoch: 6.38 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016111087508371872		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.016111087508371872 | validation: 0.022103861876567623]
	TIME [epoch: 6.39 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011992287075146914		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.011992287075146914 | validation: 0.026535359051857985]
	TIME [epoch: 6.4 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013115066626433863		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.013115066626433863 | validation: 0.028143784565892754]
	TIME [epoch: 6.41 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01276183518395601		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.01276183518395601 | validation: 0.031030541853570376]
	TIME [epoch: 6.43 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01281486307787485		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.01281486307787485 | validation: 0.017622604508579703]
	TIME [epoch: 6.41 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013167260740715836		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.013167260740715836 | validation: 0.017477539041434717]
	TIME [epoch: 6.41 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016173555995438283		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.016173555995438283 | validation: 0.02511490713057401]
	TIME [epoch: 6.41 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014335695855293798		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.014335695855293798 | validation: 0.022712958378173952]
	TIME [epoch: 6.41 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014464025304096434		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.014464025304096434 | validation: 0.02655185342655348]
	TIME [epoch: 6.41 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01324282227574807		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.01324282227574807 | validation: 0.02209777890935465]
	TIME [epoch: 6.42 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011601187998814513		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.011601187998814513 | validation: 0.027533541982435905]
	TIME [epoch: 6.43 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012693771634836629		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.012693771634836629 | validation: 0.012545270781788725]
	TIME [epoch: 6.4 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011039729431562145		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.011039729431562145 | validation: 0.01862222875023442]
	TIME [epoch: 6.41 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014169420109705226		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.014169420109705226 | validation: 0.026176428320164515]
	TIME [epoch: 6.4 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012598814838817122		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.012598814838817122 | validation: 0.02273389495211707]
	TIME [epoch: 6.4 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01600430341262976		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.01600430341262976 | validation: 0.012766001485062371]
	TIME [epoch: 6.41 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01831673837377427		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.01831673837377427 | validation: 0.027581945282235266]
	TIME [epoch: 6.4 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012677818931265974		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.012677818931265974 | validation: 0.023674981611423954]
	TIME [epoch: 6.44 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011708354236489362		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.011708354236489362 | validation: 0.017574261282921885]
	TIME [epoch: 6.41 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013614396586608804		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.013614396586608804 | validation: 0.021939701317878476]
	TIME [epoch: 6.41 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01146722120507309		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.01146722120507309 | validation: 0.014507643496266714]
	TIME [epoch: 6.4 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016197881416098056		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.016197881416098056 | validation: 0.027686105588819544]
	TIME [epoch: 6.39 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012138672860362573		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.012138672860362573 | validation: 0.029379556446691733]
	TIME [epoch: 6.39 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012873635812381707		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.012873635812381707 | validation: 0.022459864958450818]
	TIME [epoch: 6.39 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015321545197803843		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.015321545197803843 | validation: 0.02115707549319696]
	TIME [epoch: 6.44 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012883426290358312		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.012883426290358312 | validation: 0.02437468532477264]
	TIME [epoch: 6.4 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014640551050145442		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.014640551050145442 | validation: 0.02183854732744127]
	TIME [epoch: 6.4 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01543428079790941		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.01543428079790941 | validation: 0.018616442495732317]
	TIME [epoch: 6.4 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014131715597593266		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.014131715597593266 | validation: 0.026389794791715656]
	TIME [epoch: 6.39 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01124133578156856		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.01124133578156856 | validation: 0.028080314787933647]
	TIME [epoch: 6.4 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012597823083659202		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.012597823083659202 | validation: 0.016638865770300763]
	TIME [epoch: 6.4 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012992298329937445		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.012992298329937445 | validation: 0.028396118241669387]
	TIME [epoch: 6.41 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016574532772360075		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.016574532772360075 | validation: 0.02417687790571814]
	TIME [epoch: 6.42 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013557377891608657		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.013557377891608657 | validation: 0.02567610954359089]
	TIME [epoch: 6.4 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0160463444234627		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.0160463444234627 | validation: 0.02738645182792414]
	TIME [epoch: 6.4 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013194224915998237		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.013194224915998237 | validation: 0.02749740995500165]
	TIME [epoch: 6.4 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013986716624784956		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.013986716624784956 | validation: 0.01990237011101074]
	TIME [epoch: 6.4 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010810957050619057		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.010810957050619057 | validation: 0.02740925643543157]
	TIME [epoch: 6.4 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016433873466669423		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.016433873466669423 | validation: 0.025908083679570752]
	TIME [epoch: 6.4 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012365516099999514		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.012365516099999514 | validation: 0.027612280576337574]
	TIME [epoch: 6.42 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011496060072323157		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.011496060072323157 | validation: 0.025950377294458874]
	TIME [epoch: 6.39 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011402544136384836		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.011402544136384836 | validation: 0.028785623973171616]
	TIME [epoch: 6.4 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012962483072674941		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.012962483072674941 | validation: 0.022442898659323657]
	TIME [epoch: 6.39 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01609656892329501		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.01609656892329501 | validation: 0.021469383894533813]
	TIME [epoch: 6.4 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012240074111826833		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.012240074111826833 | validation: 0.023239090584200716]
	TIME [epoch: 6.4 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014904528091935076		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.014904528091935076 | validation: 0.02297923749626263]
	TIME [epoch: 6.39 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014877694585700756		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.014877694585700756 | validation: 0.030350016690140664]
	TIME [epoch: 6.43 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01247716617436919		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.01247716617436919 | validation: 0.020538315390835903]
	TIME [epoch: 6.39 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015009928613657186		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.015009928613657186 | validation: 0.02715619815362576]
	TIME [epoch: 6.39 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012290087370103245		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.012290087370103245 | validation: 0.020374573372101804]
	TIME [epoch: 6.39 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012241323281025139		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.012241323281025139 | validation: 0.03145987463685504]
	TIME [epoch: 6.4 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018077330835253817		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.018077330835253817 | validation: 0.023181243953384917]
	TIME [epoch: 6.39 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01357557092320107		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.01357557092320107 | validation: 0.024759860585981227]
	TIME [epoch: 6.42 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013699811992864974		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.013699811992864974 | validation: 0.020706305599757314]
	TIME [epoch: 6.43 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014893463296363449		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.014893463296363449 | validation: 0.01967229151891633]
	TIME [epoch: 6.4 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011980966948482951		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.011980966948482951 | validation: 0.029633367808818648]
	TIME [epoch: 6.41 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015527894508864947		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.015527894508864947 | validation: 0.02343580992401159]
	TIME [epoch: 6.39 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012901889073274192		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.012901889073274192 | validation: 0.026407540646050054]
	TIME [epoch: 6.4 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011369938602103516		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.011369938602103516 | validation: 0.017838972624502198]
	TIME [epoch: 6.4 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014786569830479214		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.014786569830479214 | validation: 0.031564632040348546]
	TIME [epoch: 6.4 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014827969924058472		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.014827969924058472 | validation: 0.022773825436507585]
	TIME [epoch: 6.42 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014383103365022305		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.014383103365022305 | validation: 0.025556776422090276]
	TIME [epoch: 6.38 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01342701107220448		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.01342701107220448 | validation: 0.02341962295750009]
	TIME [epoch: 6.38 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016070988020942943		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.016070988020942943 | validation: 0.022529401846109364]
	TIME [epoch: 6.38 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012413013332868744		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.012413013332868744 | validation: 0.03486695788572586]
	TIME [epoch: 6.39 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009494492027806434		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.009494492027806434 | validation: 0.03259552144426931]
	TIME [epoch: 6.38 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01181708913933253		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.01181708913933253 | validation: 0.02493364189280705]
	TIME [epoch: 6.4 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012456489884225218		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.012456489884225218 | validation: 0.02721245792823609]
	TIME [epoch: 6.4 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00966004017627693		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.00966004017627693 | validation: 0.03289404456196932]
	TIME [epoch: 6.41 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014886908090848017		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.014886908090848017 | validation: 0.024332038952146005]
	TIME [epoch: 6.37 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012886849326131905		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.012886849326131905 | validation: 0.025238162692020012]
	TIME [epoch: 6.39 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013156165865561596		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.013156165865561596 | validation: 0.022561212989550695]
	TIME [epoch: 6.38 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007627746663410911		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.007627746663410911 | validation: 0.024168935129623623]
	TIME [epoch: 6.37 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010660200931880078		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.010660200931880078 | validation: 0.02204663988564042]
	TIME [epoch: 6.39 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01397173862485471		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.01397173862485471 | validation: 0.02530507061620707]
	TIME [epoch: 6.4 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014133922682533263		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.014133922682533263 | validation: 0.013363223618096736]
	TIME [epoch: 6.42 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013352113776600498		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.013352113776600498 | validation: 0.019490710940913963]
	TIME [epoch: 6.4 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015621348116915929		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.015621348116915929 | validation: 0.022689281132913432]
	TIME [epoch: 6.38 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014820026478857672		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.014820026478857672 | validation: 0.02356356020938665]
	TIME [epoch: 6.4 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015663883499552205		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.015663883499552205 | validation: 0.020874490795448876]
	TIME [epoch: 6.4 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011146205737117582		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.011146205737117582 | validation: 0.028174957399691575]
	TIME [epoch: 6.38 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01268992823042525		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.01268992823042525 | validation: 0.03215759278555672]
	TIME [epoch: 6.39 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01566011668500032		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.01566011668500032 | validation: 0.019480579795196625]
	TIME [epoch: 6.45 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014784061240457998		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.014784061240457998 | validation: 0.029300734984912397]
	TIME [epoch: 6.38 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012439407776042964		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.012439407776042964 | validation: 0.021601227793005152]
	TIME [epoch: 6.39 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014313597759218376		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.014313597759218376 | validation: 0.025162070753121685]
	TIME [epoch: 6.39 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014054247628187473		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.014054247628187473 | validation: 0.028002492796940445]
	TIME [epoch: 6.4 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013638738875357968		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.013638738875357968 | validation: 0.029709363027383612]
	TIME [epoch: 6.37 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011213409289205773		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.011213409289205773 | validation: 0.01748842459766847]
	TIME [epoch: 6.38 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011238901082385525		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.011238901082385525 | validation: 0.034836919493459594]
	TIME [epoch: 6.41 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013734519618053876		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.013734519618053876 | validation: 0.02146862497921196]
	TIME [epoch: 6.4 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013913469415378413		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.013913469415378413 | validation: 0.018771315008635717]
	TIME [epoch: 6.39 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014423416539993454		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.014423416539993454 | validation: 0.024993853817673495]
	TIME [epoch: 6.39 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01565968537564058		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.01565968537564058 | validation: 0.01812967021779583]
	TIME [epoch: 6.4 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010556258813199819		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.010556258813199819 | validation: 0.03274962868253014]
	TIME [epoch: 6.38 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01373666726566882		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.01373666726566882 | validation: 0.019525818320541972]
	TIME [epoch: 6.4 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012291325743222562		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.012291325743222562 | validation: 0.028393490319097256]
	TIME [epoch: 6.42 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011692789284505109		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.011692789284505109 | validation: 0.017397861487862893]
	TIME [epoch: 6.41 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015499019324105641		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.015499019324105641 | validation: 0.015672270354347543]
	TIME [epoch: 6.4 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010688732227806932		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.010688732227806932 | validation: 0.01631074078353754]
	TIME [epoch: 6.4 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014217462904290644		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.014217462904290644 | validation: 0.02161366372117122]
	TIME [epoch: 6.39 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011938523243791405		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.011938523243791405 | validation: 0.02860922474270869]
	TIME [epoch: 6.4 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012941917112553405		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.012941917112553405 | validation: 0.026787462879248523]
	TIME [epoch: 6.39 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010573597860388253		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.010573597860388253 | validation: 0.020915252597608305]
	TIME [epoch: 6.41 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014080241548264968		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.014080241548264968 | validation: 0.018868878251680685]
	TIME [epoch: 6.42 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01018299076374249		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.01018299076374249 | validation: 0.023452027583503]
	TIME [epoch: 6.4 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01502987937325188		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.01502987937325188 | validation: 0.019068448262714283]
	TIME [epoch: 6.39 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015050953068322444		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.015050953068322444 | validation: 0.03440520582951249]
	TIME [epoch: 6.4 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010679154689974928		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.010679154689974928 | validation: 0.024734213022015405]
	TIME [epoch: 6.4 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014286087159669416		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.014286087159669416 | validation: 0.02803979437552828]
	TIME [epoch: 6.4 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014981154797457253		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.014981154797457253 | validation: 0.023095075828370382]
	TIME [epoch: 6.41 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010964758529671985		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.010964758529671985 | validation: 0.02742370751431933]
	TIME [epoch: 6.43 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01080469214649674		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.01080469214649674 | validation: 0.021047198742543977]
	TIME [epoch: 6.41 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010216297734291646		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.010216297734291646 | validation: 0.028647490034028614]
	TIME [epoch: 6.4 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015894752895089997		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.015894752895089997 | validation: 0.030586278665200306]
	TIME [epoch: 6.41 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01525265069981592		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.01525265069981592 | validation: 0.02399551285395557]
	TIME [epoch: 6.41 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014662215810827973		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.014662215810827973 | validation: 0.02944132341772574]
	TIME [epoch: 6.41 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012184186262599827		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.012184186262599827 | validation: 0.018847919078223117]
	TIME [epoch: 6.42 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01350995423176574		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.01350995423176574 | validation: 0.026730184751524454]
	TIME [epoch: 6.46 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015679766003401565		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.015679766003401565 | validation: 0.026738889202308744]
	TIME [epoch: 6.41 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013783322231180579		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.013783322231180579 | validation: 0.0330137756070759]
	TIME [epoch: 6.42 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014609919303048911		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.014609919303048911 | validation: 0.024049459360284447]
	TIME [epoch: 6.41 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014975223076445329		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.014975223076445329 | validation: 0.024036230284180754]
	TIME [epoch: 6.43 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015433728331802558		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.015433728331802558 | validation: 0.02918074547733505]
	TIME [epoch: 6.42 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010630445703152802		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.010630445703152802 | validation: 0.02222698762513168]
	TIME [epoch: 6.43 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01530518345032884		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.01530518345032884 | validation: 0.01899576913330959]
	TIME [epoch: 6.46 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01320264834559628		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.01320264834559628 | validation: 0.02053236551815997]
	TIME [epoch: 6.42 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014166193955920439		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.014166193955920439 | validation: 0.023835804963307835]
	TIME [epoch: 6.4 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014192369255355164		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.014192369255355164 | validation: 0.029100319024221485]
	TIME [epoch: 6.41 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013041466402477461		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.013041466402477461 | validation: 0.027119579381617638]
	TIME [epoch: 6.4 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014649813448585017		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.014649813448585017 | validation: 0.01751324128243425]
	TIME [epoch: 6.4 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013659160053009338		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.013659160053009338 | validation: 0.029426174573145242]
	TIME [epoch: 6.4 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014951507472009302		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.014951507472009302 | validation: 0.02394898268619449]
	TIME [epoch: 6.44 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019013106653764735		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.019013106653764735 | validation: 0.026754610726463676]
	TIME [epoch: 6.4 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016763719888289896		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.016763719888289896 | validation: 0.019247106951671113]
	TIME [epoch: 6.42 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01480810872816094		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.01480810872816094 | validation: 0.022797896402318624]
	TIME [epoch: 6.41 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01681065458846936		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.01681065458846936 | validation: 0.02171135508141167]
	TIME [epoch: 6.37 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012481968953416578		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.012481968953416578 | validation: 0.02264005895098329]
	TIME [epoch: 6.4 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011140497129942379		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.011140497129942379 | validation: 0.02027460475874644]
	TIME [epoch: 6.4 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012591777824659365		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.012591777824659365 | validation: 0.02774401623272335]
	TIME [epoch: 6.41 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018007811737047717		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.018007811737047717 | validation: 0.03258362069913865]
	TIME [epoch: 6.41 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012257052449186895		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.012257052449186895 | validation: 0.026328096168111645]
	TIME [epoch: 6.4 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01392248075051434		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.01392248075051434 | validation: 0.022002449191911667]
	TIME [epoch: 6.4 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01321536248052399		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.01321536248052399 | validation: 0.022530345689569627]
	TIME [epoch: 6.39 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014890265625080886		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.014890265625080886 | validation: 0.02187372689820773]
	TIME [epoch: 6.39 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01600415642131967		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.01600415642131967 | validation: 0.027884474066893202]
	TIME [epoch: 6.39 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017038697103119366		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.017038697103119366 | validation: 0.02421966450737056]
	TIME [epoch: 6.4 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014241757637843884		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.014241757637843884 | validation: 0.023581698902908503]
	TIME [epoch: 6.43 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016185927477924113		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.016185927477924113 | validation: 0.023844664758897415]
	TIME [epoch: 6.39 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01297342890527812		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.01297342890527812 | validation: 0.03582054786629838]
	TIME [epoch: 6.39 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015740935659922003		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.015740935659922003 | validation: 0.023666806772483263]
	TIME [epoch: 6.4 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01038915576896914		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.01038915576896914 | validation: 0.023196653263926503]
	TIME [epoch: 6.39 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013689140367287099		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.013689140367287099 | validation: 0.021478489736064376]
	TIME [epoch: 6.39 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01510441004563616		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.01510441004563616 | validation: 0.015735748069053236]
	TIME [epoch: 6.39 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014948385002815322		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.014948385002815322 | validation: 0.02140906719689869]
	TIME [epoch: 6.43 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015902058704170254		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.015902058704170254 | validation: 0.02560199786503636]
	TIME [epoch: 6.39 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01127513164845383		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.01127513164845383 | validation: 0.024319057090363798]
	TIME [epoch: 6.38 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012157177265923498		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.012157177265923498 | validation: 0.028625110447283327]
	TIME [epoch: 6.39 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01594313309045833		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.01594313309045833 | validation: 0.023064295987611165]
	TIME [epoch: 6.39 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017711334696314338		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.017711334696314338 | validation: 0.02259312579196436]
	TIME [epoch: 6.37 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014383791371778887		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.014383791371778887 | validation: 0.02763190064145515]
	TIME [epoch: 6.38 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013617373968839153		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.013617373968839153 | validation: 0.02534341540844503]
	TIME [epoch: 6.44 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014587380639343964		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.014587380639343964 | validation: 0.033738346044317614]
	TIME [epoch: 6.4 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014235965133642448		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.014235965133642448 | validation: 0.03036716486876899]
	TIME [epoch: 6.41 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01255595111463894		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.01255595111463894 | validation: 0.018375286196834113]
	TIME [epoch: 6.4 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016047356955168162		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.016047356955168162 | validation: 0.02717735788141332]
	TIME [epoch: 6.4 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012866720895653414		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.012866720895653414 | validation: 0.02083307106285755]
	TIME [epoch: 6.4 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011844081723572892		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.011844081723572892 | validation: 0.02594161425831138]
	TIME [epoch: 6.4 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014199941353363093		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.014199941353363093 | validation: 0.022941705561362866]
	TIME [epoch: 6.44 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01353739111854594		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.01353739111854594 | validation: 0.022045591768275443]
	TIME [epoch: 6.41 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011502637680963858		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.011502637680963858 | validation: 0.02799960579447422]
	TIME [epoch: 6.4 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012864510651171914		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.012864510651171914 | validation: 0.022513232801467248]
	TIME [epoch: 6.4 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014023444398724747		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.014023444398724747 | validation: 0.01679927789689097]
	TIME [epoch: 6.4 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015709988599730558		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.015709988599730558 | validation: 0.029361101433136718]
	TIME [epoch: 6.41 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013592665398583843		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.013592665398583843 | validation: 0.025058233516132386]
	TIME [epoch: 6.4 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013635516337898857		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.013635516337898857 | validation: 0.027158218834720357]
	TIME [epoch: 6.41 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00987010253226181		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.00987010253226181 | validation: 0.02170450433433346]
	TIME [epoch: 6.42 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016826166880308843		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.016826166880308843 | validation: 0.028051642753339268]
	TIME [epoch: 6.4 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013550565076662273		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.013550565076662273 | validation: 0.02352403883665647]
	TIME [epoch: 6.39 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013599820841464126		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.013599820841464126 | validation: 0.025190444678688584]
	TIME [epoch: 6.41 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014566518040577871		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.014566518040577871 | validation: 0.025159319367256978]
	TIME [epoch: 6.4 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014246333885693404		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.014246333885693404 | validation: 0.028466991206316745]
	TIME [epoch: 6.41 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012356254593677434		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.012356254593677434 | validation: 0.022646343923889756]
	TIME [epoch: 6.41 sec]
Finished training in 12981.689 seconds.
