Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r4', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 412302805

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.14023126976803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.14023126976803 | validation: 7.116130435205123]
	TIME [epoch: 94.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.161509204068279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.161509204068279 | validation: 5.633499999646144]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7769098941444845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7769098941444845 | validation: 4.154837131994176]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.955489779111173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.955489779111173 | validation: 4.206888288664904]
	TIME [epoch: 5.71 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.416445010187677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.416445010187677 | validation: 2.8776468687993773]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1126536170923154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1126536170923154 | validation: 2.6868810017715403]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.910427464197818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.910427464197818 | validation: 3.132812841875906]
	TIME [epoch: 5.7 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.955535894189261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.955535894189261 | validation: 2.6951182678458516]
	TIME [epoch: 5.72 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5694443564059224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5694443564059224 | validation: 2.470225059746199]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5615313005435896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5615313005435896 | validation: 2.5166994364917126]
	TIME [epoch: 5.73 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3150813887748587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3150813887748587 | validation: 2.022864924400963]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2051136347661324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2051136347661324 | validation: 1.9315253053432653]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9284995625034773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9284995625034773 | validation: 1.7550298508174464]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.795532073435837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.795532073435837 | validation: 1.5609018895383915]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.903538481871312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.903538481871312 | validation: 2.8832496757613444]
	TIME [epoch: 5.76 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.175994203379021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.175994203379021 | validation: 1.6065518748255534]
	TIME [epoch: 5.72 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6907308676797796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6907308676797796 | validation: 1.6257497258722777]
	TIME [epoch: 5.72 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6234207032007897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6234207032007897 | validation: 1.457401623276482]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.508314260763945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.508314260763945 | validation: 1.435099991258135]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.399978891791833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.399978891791833 | validation: 1.6543602738318466]
	TIME [epoch: 5.71 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4403360781046735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4403360781046735 | validation: 1.1704073889909246]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6452408379134944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6452408379134944 | validation: 1.9092084041511868]
	TIME [epoch: 5.73 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5544182691614878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5544182691614878 | validation: 1.4092260875382352]
	TIME [epoch: 5.7 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5300557456322244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5300557456322244 | validation: 1.2334785422361028]
	TIME [epoch: 5.7 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3113304675864454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3113304675864454 | validation: 1.1246781254641978]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.43255798771351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.43255798771351 | validation: 1.8896043951073376]
	TIME [epoch: 5.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3612730149952739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3612730149952739 | validation: 1.0622560375056462]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.199133107820532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.199133107820532 | validation: 1.0395962818068543]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1000247884150434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1000247884150434 | validation: 1.0677519039434231]
	TIME [epoch: 5.71 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1566745665938107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1566745665938107 | validation: 1.4596565692493368]
	TIME [epoch: 5.7 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2081717342406992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2081717342406992 | validation: 1.1645344667636515]
	TIME [epoch: 5.7 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.273120478349312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.273120478349312 | validation: 0.9620564034673673]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1753922802382941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1753922802382941 | validation: 1.360506092282704]
	TIME [epoch: 5.71 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1687284669017648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1687284669017648 | validation: 1.2291822545709719]
	TIME [epoch: 5.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1238855531306595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1238855531306595 | validation: 0.841016245987377]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0472747307319992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0472747307319992 | validation: 1.3073704536677326]
	TIME [epoch: 5.96 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058920482166481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.058920482166481 | validation: 1.7323607181597152]
	TIME [epoch: 5.71 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.08826993494816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.08826993494816 | validation: 1.059185911275426]
	TIME [epoch: 5.73 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0745974644208378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0745974644208378 | validation: 0.8871930801558691]
	TIME [epoch: 5.73 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.963126037767962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.963126037767962 | validation: 1.6699048561702932]
	TIME [epoch: 5.72 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0168918552553587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0168918552553587 | validation: 0.8669440778049955]
	TIME [epoch: 5.74 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0964051958107495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0964051958107495 | validation: 0.78691377001317]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1100140831546774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1100140831546774 | validation: 1.6084179488174168]
	TIME [epoch: 5.73 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1471846099897949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1471846099897949 | validation: 0.7305172293532182]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8105884559005689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8105884559005689 | validation: 1.3304685539080225]
	TIME [epoch: 5.72 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1196144262919763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1196144262919763 | validation: 0.8710985113820285]
	TIME [epoch: 5.72 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.979603627782865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.979603627782865 | validation: 0.9512446023047103]
	TIME [epoch: 5.72 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9466004156909061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9466004156909061 | validation: 0.6867020542599606]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8805426864479406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8805426864479406 | validation: 0.9017632119445156]
	TIME [epoch: 5.74 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733589241861261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.733589241861261 | validation: 1.0056866257864798]
	TIME [epoch: 5.72 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0839359931034538		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.0839359931034538 | validation: 0.6275424268682397]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9432794763596182		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.9432794763596182 | validation: 0.8957191343450981]
	TIME [epoch: 5.71 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8056067183486392		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.8056067183486392 | validation: 0.5898809427798447]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7825355054935534		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.7825355054935534 | validation: 0.7416260369184507]
	TIME [epoch: 5.72 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8967955909704004		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.8967955909704004 | validation: 0.6773700773775662]
	TIME [epoch: 5.75 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042002986808455		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.7042002986808455 | validation: 0.5593624724228822]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7382583983605269		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.7382583983605269 | validation: 0.9399776710745441]
	TIME [epoch: 5.71 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7833688283194157		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.7833688283194157 | validation: 0.6381770900836365]
	TIME [epoch: 5.71 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.569456811106683		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.569456811106683 | validation: 0.5391022272890582]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7686510049009567		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.7686510049009567 | validation: 0.6109095467462171]
	TIME [epoch: 5.72 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7474412073698673		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.7474412073698673 | validation: 0.5046349233521547]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7714612709936529		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.7714612709936529 | validation: 1.6689772879207831]
	TIME [epoch: 5.75 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1150000623458516		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.1150000623458516 | validation: 0.6572784962333705]
	TIME [epoch: 5.73 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6101581571788413		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.6101581571788413 | validation: 0.4770870372271642]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5253491120272007		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.5253491120272007 | validation: 0.7016907264204738]
	TIME [epoch: 5.72 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.946494949953677		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.946494949953677 | validation: 0.6544357980059187]
	TIME [epoch: 5.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7331572132509011		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.7331572132509011 | validation: 0.5060432093617446]
	TIME [epoch: 5.71 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5763524529520546		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.5763524529520546 | validation: 0.6656128467991583]
	TIME [epoch: 5.75 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890313725791307		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.6890313725791307 | validation: 0.5110529807050648]
	TIME [epoch: 5.72 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6912759715021917		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.6912759715021917 | validation: 0.3627621941794445]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.483781472493192		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.483781472493192 | validation: 0.7701289896768043]
	TIME [epoch: 5.73 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5820885851536374		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.5820885851536374 | validation: 0.6002070839670546]
	TIME [epoch: 5.72 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7129367870377357		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.7129367870377357 | validation: 0.5312452638755657]
	TIME [epoch: 5.72 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43692866215551224		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.43692866215551224 | validation: 0.6549926586918297]
	TIME [epoch: 5.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5244817920665648		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.5244817920665648 | validation: 0.5996937813046705]
	TIME [epoch: 5.76 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6364940983105758		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.6364940983105758 | validation: 0.4096003458587929]
	TIME [epoch: 5.72 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8081809760690135		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.8081809760690135 | validation: 0.7582220799862316]
	TIME [epoch: 5.72 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5401289403257492		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.5401289403257492 | validation: 0.7764023105278909]
	TIME [epoch: 5.71 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874540438951016		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.5874540438951016 | validation: 0.7659974467801763]
	TIME [epoch: 5.72 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220632270118212		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.5220632270118212 | validation: 0.4095281522558304]
	TIME [epoch: 5.72 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6035849530434256		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.6035849530434256 | validation: 0.3396274450089621]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5927116280895978		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.5927116280895978 | validation: 0.38348341867257035]
	TIME [epoch: 5.98 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5223489420193427		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.5223489420193427 | validation: 0.3977397727007963]
	TIME [epoch: 5.73 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5010874325018289		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.5010874325018289 | validation: 0.3138698007993728]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6376799984203149		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.6376799984203149 | validation: 0.3469212167072393]
	TIME [epoch: 5.73 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41990773022702255		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.41990773022702255 | validation: 0.30855527197275673]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38823410001278724		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.38823410001278724 | validation: 0.6216174776730686]
	TIME [epoch: 5.74 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6609126943028096		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.6609126943028096 | validation: 0.5479440454700695]
	TIME [epoch: 5.75 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5815005124821464		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.5815005124821464 | validation: 0.39491257211387243]
	TIME [epoch: 5.73 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5689832854782956		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.5689832854782956 | validation: 0.41546618730745943]
	TIME [epoch: 5.72 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3854085678075064		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.3854085678075064 | validation: 0.6261727496973581]
	TIME [epoch: 5.72 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5299047635952124		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.5299047635952124 | validation: 0.43444657842956835]
	TIME [epoch: 5.72 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925205170515468		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.3925205170515468 | validation: 0.33307045730153456]
	TIME [epoch: 5.73 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409468758031631		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.409468758031631 | validation: 0.5322956788167553]
	TIME [epoch: 5.76 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45122863318099743		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.45122863318099743 | validation: 0.7712160929961298]
	TIME [epoch: 5.73 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.503309197278772		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.503309197278772 | validation: 0.33860033551692326]
	TIME [epoch: 5.72 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6901890792006988		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6901890792006988 | validation: 0.7949263941890925]
	TIME [epoch: 5.72 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6064637431355961		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.6064637431355961 | validation: 0.2611411181636093]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41501116413479366		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.41501116413479366 | validation: 0.45807198853846276]
	TIME [epoch: 5.72 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32319443612849064		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.32319443612849064 | validation: 0.5811753891582291]
	TIME [epoch: 5.73 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4585411666471833		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.4585411666471833 | validation: 0.7041910387592134]
	TIME [epoch: 5.75 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48626561337221014		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.48626561337221014 | validation: 0.5972179762260565]
	TIME [epoch: 5.72 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5312415746676673		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.5312415746676673 | validation: 0.5785203865801382]
	TIME [epoch: 5.71 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4798678116306381		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.4798678116306381 | validation: 0.4718699376088695]
	TIME [epoch: 5.71 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39438038614043597		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.39438038614043597 | validation: 0.43357553851532155]
	TIME [epoch: 5.71 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4414134500544825		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.4414134500544825 | validation: 0.859663438605575]
	TIME [epoch: 5.71 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8149866508201873		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.8149866508201873 | validation: 0.5044213816766798]
	TIME [epoch: 5.75 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45699050587572065		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.45699050587572065 | validation: 0.48336956251661023]
	TIME [epoch: 5.72 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42419171263417604		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.42419171263417604 | validation: 0.22081097394828322]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336754656742477		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.3336754656742477 | validation: 0.47580364810966247]
	TIME [epoch: 5.71 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39401219351835826		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.39401219351835826 | validation: 0.41308215439491364]
	TIME [epoch: 5.71 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3602447767842847		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.3602447767842847 | validation: 0.3150151040979767]
	TIME [epoch: 5.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929682297141321		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.3929682297141321 | validation: 0.49603796726893307]
	TIME [epoch: 5.72 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46318457780353756		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.46318457780353756 | validation: 0.2842103987790968]
	TIME [epoch: 5.74 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47156994082078874		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.47156994082078874 | validation: 0.48263183387677205]
	TIME [epoch: 5.71 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45465796621455057		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.45465796621455057 | validation: 0.6956884592152691]
	TIME [epoch: 5.71 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49012996489339294		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.49012996489339294 | validation: 0.5093967084429769]
	TIME [epoch: 5.71 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41861447914187244		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.41861447914187244 | validation: 0.35205806147614555]
	TIME [epoch: 5.71 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640509369522533		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.3640509369522533 | validation: 0.32231239349396673]
	TIME [epoch: 5.71 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4335613144199032		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.4335613144199032 | validation: 0.3901174175318225]
	TIME [epoch: 5.75 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525773262413948		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.4525773262413948 | validation: 0.4019747594826941]
	TIME [epoch: 5.71 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4432564556842289		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.4432564556842289 | validation: 0.4770408752004853]
	TIME [epoch: 5.71 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34654596386628334		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.34654596386628334 | validation: 0.4682040257930341]
	TIME [epoch: 5.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31930302390967036		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.31930302390967036 | validation: 0.26803762412298343]
	TIME [epoch: 5.71 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440266639084205		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3440266639084205 | validation: 0.21557309334520422]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373228821158147		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.373228821158147 | validation: 0.36858238469086163]
	TIME [epoch: 5.73 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33784991666795317		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.33784991666795317 | validation: 0.25477841142372315]
	TIME [epoch: 5.73 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3789054282336338		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.3789054282336338 | validation: 0.23568084295046762]
	TIME [epoch: 5.71 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4001984070247982		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.4001984070247982 | validation: 0.23433252326288947]
	TIME [epoch: 5.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37134044193849497		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.37134044193849497 | validation: 0.5103606643267818]
	TIME [epoch: 5.71 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4544199482767436		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.4544199482767436 | validation: 0.3736057846973856]
	TIME [epoch: 5.71 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35773966306731986		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.35773966306731986 | validation: 0.6152709034800372]
	TIME [epoch: 5.71 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44449906386455035		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.44449906386455035 | validation: 0.27540193034113125]
	TIME [epoch: 5.75 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34582221693963205		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.34582221693963205 | validation: 0.5518669830175525]
	TIME [epoch: 5.72 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45470900062435526		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.45470900062435526 | validation: 0.2669533280406601]
	TIME [epoch: 5.72 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31980733425479446		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.31980733425479446 | validation: 0.3082208352755958]
	TIME [epoch: 5.71 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3384526812172759		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.3384526812172759 | validation: 0.33164646516704593]
	TIME [epoch: 5.72 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36812164314682233		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.36812164314682233 | validation: 0.4770868615685611]
	TIME [epoch: 5.72 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4041917773304401		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.4041917773304401 | validation: 0.3029081126514366]
	TIME [epoch: 5.73 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3445228217359935		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.3445228217359935 | validation: 0.2751737050852979]
	TIME [epoch: 5.74 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6384232978542113		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.6384232978542113 | validation: 0.2886771336627882]
	TIME [epoch: 5.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3246668739577789		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.3246668739577789 | validation: 0.32390010703508554]
	TIME [epoch: 5.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820545763214914		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3820545763214914 | validation: 0.5771176660615349]
	TIME [epoch: 5.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45674624481160064		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.45674624481160064 | validation: 0.28810897805538455]
	TIME [epoch: 5.71 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31846655018807646		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.31846655018807646 | validation: 0.2701676414590795]
	TIME [epoch: 5.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359137025884252		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.359137025884252 | validation: 0.30856426514285956]
	TIME [epoch: 5.74 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3297523433188762		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.3297523433188762 | validation: 0.2848321203684907]
	TIME [epoch: 5.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25896477605931184		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.25896477605931184 | validation: 0.21390801878187524]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39975404870535397		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.39975404870535397 | validation: 0.30787847537516094]
	TIME [epoch: 5.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638873180510592		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.4638873180510592 | validation: 0.26946673605946936]
	TIME [epoch: 5.71 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31556338281814655		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.31556338281814655 | validation: 0.22603207769942088]
	TIME [epoch: 5.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27863285772120433		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.27863285772120433 | validation: 0.5297300960281703]
	TIME [epoch: 5.73 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500415410413825		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.4500415410413825 | validation: 0.3313503347690539]
	TIME [epoch: 5.75 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42447285609512597		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.42447285609512597 | validation: 0.2450494260152437]
	TIME [epoch: 5.71 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42499389861934833		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.42499389861934833 | validation: 0.3185592833206296]
	TIME [epoch: 5.71 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.338873098610647		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.338873098610647 | validation: 0.24961288594981831]
	TIME [epoch: 5.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26524800399230525		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.26524800399230525 | validation: 0.18884077895470278]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4231953459576181		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.4231953459576181 | validation: 0.30640580396841033]
	TIME [epoch: 5.71 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2735221051747382		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.2735221051747382 | validation: 0.2914475384612398]
	TIME [epoch: 5.75 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36335851396278146		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.36335851396278146 | validation: 0.27474709925864604]
	TIME [epoch: 5.72 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35741221660903655		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.35741221660903655 | validation: 0.4043644669588437]
	TIME [epoch: 5.71 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42076006634807483		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.42076006634807483 | validation: 0.325241862331313]
	TIME [epoch: 5.71 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2705901796557073		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.2705901796557073 | validation: 0.36078154657659545]
	TIME [epoch: 5.71 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39287902217421644		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.39287902217421644 | validation: 0.28724362128055186]
	TIME [epoch: 5.71 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858345752957264		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.2858345752957264 | validation: 0.31819119925554484]
	TIME [epoch: 5.72 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43610035700750405		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.43610035700750405 | validation: 0.4472042446113111]
	TIME [epoch: 5.75 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.445923913730599		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.445923913730599 | validation: 0.3128928621845958]
	TIME [epoch: 5.71 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31980105550426347		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.31980105550426347 | validation: 0.37822597326496665]
	TIME [epoch: 5.71 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36552341706546043		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.36552341706546043 | validation: 0.30912402163131275]
	TIME [epoch: 5.71 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890412798861997		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.2890412798861997 | validation: 0.40388515336219244]
	TIME [epoch: 5.71 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368596935716358		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.368596935716358 | validation: 0.2226046060346678]
	TIME [epoch: 5.71 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28510464344341935		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.28510464344341935 | validation: 0.2716183652255363]
	TIME [epoch: 5.75 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2910518833818184		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.2910518833818184 | validation: 0.6336127968812104]
	TIME [epoch: 5.71 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5924326995123255		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.5924326995123255 | validation: 0.32510386356150406]
	TIME [epoch: 5.72 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36959955687833923		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.36959955687833923 | validation: 0.41945373666520397]
	TIME [epoch: 5.71 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3599232442213005		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3599232442213005 | validation: 0.24016143337424178]
	TIME [epoch: 5.7 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264485776529346		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.264485776529346 | validation: 0.4333643627395338]
	TIME [epoch: 5.71 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38481887026978906		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.38481887026978906 | validation: 0.3129083241546314]
	TIME [epoch: 5.73 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30064686786098194		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.30064686786098194 | validation: 0.5124061828958434]
	TIME [epoch: 5.73 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37348988415688317		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.37348988415688317 | validation: 0.23911313563978898]
	TIME [epoch: 5.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535724877561769		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.2535724877561769 | validation: 0.4572368107313287]
	TIME [epoch: 5.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38980488556047765		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.38980488556047765 | validation: 0.35731345440503504]
	TIME [epoch: 5.71 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29843140716380645		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.29843140716380645 | validation: 0.3108670349709696]
	TIME [epoch: 5.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40528025351983665		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.40528025351983665 | validation: 0.3314271805523177]
	TIME [epoch: 5.72 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32731703890677993		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.32731703890677993 | validation: 0.2384879445693677]
	TIME [epoch: 5.75 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754421629432996		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.2754421629432996 | validation: 0.3945166109352404]
	TIME [epoch: 5.72 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3045342221008137		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.3045342221008137 | validation: 0.26007364051458104]
	TIME [epoch: 5.71 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487251879503275		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2487251879503275 | validation: 0.2315836200946353]
	TIME [epoch: 5.71 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27098861738276137		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.27098861738276137 | validation: 0.5571658977901821]
	TIME [epoch: 5.71 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41325390432848175		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.41325390432848175 | validation: 0.2596278468145938]
	TIME [epoch: 5.71 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3981618272060702		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.3981618272060702 | validation: 0.34475762318259784]
	TIME [epoch: 5.72 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2930702621878232		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.2930702621878232 | validation: 0.2553607379395352]
	TIME [epoch: 5.76 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524747260079942		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.2524747260079942 | validation: 0.25613343281065026]
	TIME [epoch: 5.71 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786769796182492		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.2786769796182492 | validation: 0.19441346985299518]
	TIME [epoch: 5.71 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671954859610228		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.2671954859610228 | validation: 0.28663911262944597]
	TIME [epoch: 5.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28585090778707545		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.28585090778707545 | validation: 0.16108315832300515]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20327950631972447		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.20327950631972447 | validation: 0.26794184685852446]
	TIME [epoch: 5.72 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30844129809281884		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.30844129809281884 | validation: 0.24300743311859435]
	TIME [epoch: 5.76 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26806796268492994		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.26806796268492994 | validation: 0.284816623565076]
	TIME [epoch: 5.72 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3244822288685446		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3244822288685446 | validation: 0.21224929381097923]
	TIME [epoch: 5.72 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3014971156152624		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.3014971156152624 | validation: 0.2670200713705259]
	TIME [epoch: 5.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29715164596777244		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.29715164596777244 | validation: 0.45012249923960496]
	TIME [epoch: 5.72 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34216227936548105		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.34216227936548105 | validation: 0.2044561945196454]
	TIME [epoch: 5.72 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296917102908008		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.296917102908008 | validation: 0.190133892556204]
	TIME [epoch: 5.73 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45484033678056945		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.45484033678056945 | validation: 0.31247791752347687]
	TIME [epoch: 5.75 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27052325281115125		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.27052325281115125 | validation: 0.25395198388675794]
	TIME [epoch: 5.71 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897404980903249		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.2897404980903249 | validation: 0.3941027315086744]
	TIME [epoch: 5.72 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27482169781370447		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.27482169781370447 | validation: 0.22422622561975103]
	TIME [epoch: 5.71 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2523947134452704		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2523947134452704 | validation: 0.14776081257518978]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28249736884051646		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.28249736884051646 | validation: 0.2099351320960249]
	TIME [epoch: 5.71 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26186452818954414		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.26186452818954414 | validation: 0.30038342125578626]
	TIME [epoch: 5.75 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2548177239779169		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.2548177239779169 | validation: 0.19243317874807236]
	TIME [epoch: 5.71 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24429830644317505		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.24429830644317505 | validation: 0.15530750865630186]
	TIME [epoch: 5.72 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24409416401743478		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.24409416401743478 | validation: 0.25329668159302404]
	TIME [epoch: 5.71 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.291346631782361		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.291346631782361 | validation: 0.20551569201381242]
	TIME [epoch: 5.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2861291291215934		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.2861291291215934 | validation: 0.384475960516696]
	TIME [epoch: 5.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3221733426040633		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.3221733426040633 | validation: 0.22108232257520719]
	TIME [epoch: 5.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3166496368142677		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.3166496368142677 | validation: 0.3766334097989882]
	TIME [epoch: 5.75 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2997968415122926		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.2997968415122926 | validation: 0.40152711245490685]
	TIME [epoch: 5.71 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3233248650107813		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.3233248650107813 | validation: 0.31193026993927875]
	TIME [epoch: 5.71 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32972649702891194		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.32972649702891194 | validation: 0.38392576608161405]
	TIME [epoch: 5.71 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3294759912355999		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.3294759912355999 | validation: 0.30329180091126146]
	TIME [epoch: 5.71 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26835831009303934		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.26835831009303934 | validation: 0.18192731615925506]
	TIME [epoch: 5.72 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3394594681701888		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.3394594681701888 | validation: 0.17963425297996316]
	TIME [epoch: 5.76 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286812898083341		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.286812898083341 | validation: 0.22311005944242035]
	TIME [epoch: 5.71 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23245743103461797		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.23245743103461797 | validation: 0.19107285782186573]
	TIME [epoch: 5.71 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2052463129241064		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.2052463129241064 | validation: 0.16985831150683953]
	TIME [epoch: 5.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21825539716430853		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.21825539716430853 | validation: 0.2641908354820176]
	TIME [epoch: 5.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645054014462854		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.2645054014462854 | validation: 0.17113463957795275]
	TIME [epoch: 5.71 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23742859075632372		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.23742859075632372 | validation: 0.2135530084224859]
	TIME [epoch: 5.71 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24372983861849976		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.24372983861849976 | validation: 0.18767882309560058]
	TIME [epoch: 5.75 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721755967381818		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.3721755967381818 | validation: 0.7763334316794646]
	TIME [epoch: 5.71 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4927697595820044		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.4927697595820044 | validation: 0.29011585378252575]
	TIME [epoch: 5.71 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501221285854698		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.2501221285854698 | validation: 0.2406476281287463]
	TIME [epoch: 5.71 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3256509347290888		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.3256509347290888 | validation: 0.23257778557704187]
	TIME [epoch: 5.71 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21906737710995		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.21906737710995 | validation: 0.26899421724943784]
	TIME [epoch: 5.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3288733529899637		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.3288733529899637 | validation: 0.5507218068075279]
	TIME [epoch: 5.75 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34106715527948556		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.34106715527948556 | validation: 0.18001090115229268]
	TIME [epoch: 5.73 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19965920287810932		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.19965920287810932 | validation: 0.18725417372816888]
	TIME [epoch: 5.71 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23314363096641347		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.23314363096641347 | validation: 0.23978882188923278]
	TIME [epoch: 5.72 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23350961850097057		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.23350961850097057 | validation: 0.18684603786412105]
	TIME [epoch: 5.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22027095687074538		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.22027095687074538 | validation: 0.15543028212220553]
	TIME [epoch: 5.71 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26581504897380653		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.26581504897380653 | validation: 0.16790893483849612]
	TIME [epoch: 5.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25533173410151994		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.25533173410151994 | validation: 0.1821764585530867]
	TIME [epoch: 5.74 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.289138341447981		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.289138341447981 | validation: 0.3502890413522727]
	TIME [epoch: 5.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3164714133611748		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.3164714133611748 | validation: 0.15261250553437333]
	TIME [epoch: 5.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748090403869976		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.2748090403869976 | validation: 0.1477124390323619]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16892160414168203		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.16892160414168203 | validation: 0.16963280615847168]
	TIME [epoch: 5.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2403943252853661		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.2403943252853661 | validation: 0.21751278502666688]
	TIME [epoch: 5.71 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21904845582753743		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.21904845582753743 | validation: 0.16656797193491918]
	TIME [epoch: 5.73 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2453924522601197		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2453924522601197 | validation: 0.22977929961088428]
	TIME [epoch: 5.73 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24713904089216782		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.24713904089216782 | validation: 0.12314101145478454]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18866003799433673		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.18866003799433673 | validation: 0.12919082606358084]
	TIME [epoch: 5.71 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33705911625081253		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.33705911625081253 | validation: 0.4362090823115823]
	TIME [epoch: 5.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2830417870308658		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.2830417870308658 | validation: 0.18750819906459712]
	TIME [epoch: 5.71 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24002898027439748		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.24002898027439748 | validation: 0.2179367058272515]
	TIME [epoch: 5.72 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21663597886322514		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.21663597886322514 | validation: 0.1304203061100025]
	TIME [epoch: 5.73 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2310577398732486		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.2310577398732486 | validation: 0.20007979214490917]
	TIME [epoch: 5.71 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3182347518423441		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.3182347518423441 | validation: 0.25574228840162877]
	TIME [epoch: 5.71 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24773432399140516		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.24773432399140516 | validation: 0.19037665676278498]
	TIME [epoch: 5.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2261179423581508		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.2261179423581508 | validation: 0.14775151820635896]
	TIME [epoch: 5.71 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1775254928218321		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.1775254928218321 | validation: 0.1639275374573372]
	TIME [epoch: 5.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088485531204713		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.2088485531204713 | validation: 0.20775026605261737]
	TIME [epoch: 5.73 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2010342726983731		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.2010342726983731 | validation: 0.2254046385301758]
	TIME [epoch: 5.72 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25437227020568937		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.25437227020568937 | validation: 0.22819926500456145]
	TIME [epoch: 5.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2413612989159848		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.2413612989159848 | validation: 0.3443138804378087]
	TIME [epoch: 5.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3134458006335059		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.3134458006335059 | validation: 0.1680319065559412]
	TIME [epoch: 5.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19840179234894756		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.19840179234894756 | validation: 0.1329736852562827]
	TIME [epoch: 5.71 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6296595966420064		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.6296595966420064 | validation: 0.1866347884918752]
	TIME [epoch: 5.71 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18916862981265045		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.18916862981265045 | validation: 0.24635848793855444]
	TIME [epoch: 5.75 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22124525685655574		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.22124525685655574 | validation: 0.19697251217604275]
	TIME [epoch: 5.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17621674044605698		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.17621674044605698 | validation: 0.2040644860981903]
	TIME [epoch: 5.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24116236415559844		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.24116236415559844 | validation: 0.17536091855025618]
	TIME [epoch: 5.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17413363888205352		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.17413363888205352 | validation: 0.3130054764362654]
	TIME [epoch: 5.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24828942687034405		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.24828942687034405 | validation: 0.1972742205098977]
	TIME [epoch: 5.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17094928993083416		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.17094928993083416 | validation: 0.24969680709888875]
	TIME [epoch: 5.73 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21924643665391047		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.21924643665391047 | validation: 0.16671219874436496]
	TIME [epoch: 5.72 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740318314515112		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.1740318314515112 | validation: 0.13335222899070887]
	TIME [epoch: 5.71 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2287886933596764		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2287886933596764 | validation: 0.3580571061700055]
	TIME [epoch: 5.71 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21679158673666377		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.21679158673666377 | validation: 0.2244852175497586]
	TIME [epoch: 5.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2498145946065531		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.2498145946065531 | validation: 0.2884896411300466]
	TIME [epoch: 5.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30270860346226436		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.30270860346226436 | validation: 0.21795022595597366]
	TIME [epoch: 5.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24258590599987545		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.24258590599987545 | validation: 0.26821527119916877]
	TIME [epoch: 5.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20946940358822172		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.20946940358822172 | validation: 0.14566551040722103]
	TIME [epoch: 5.71 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17378910858311217		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.17378910858311217 | validation: 0.15534351117847675]
	TIME [epoch: 5.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22308383586249644		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.22308383586249644 | validation: 0.24228595346082857]
	TIME [epoch: 5.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20084081773595758		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.20084081773595758 | validation: 0.3742460245291906]
	TIME [epoch: 5.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24027237721162298		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.24027237721162298 | validation: 0.19361499503213395]
	TIME [epoch: 5.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16934634934331927		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.16934634934331927 | validation: 0.2716092277128305]
	TIME [epoch: 5.73 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2597957675082104		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.2597957675082104 | validation: 0.11073303387769347]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21039930130729365		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.21039930130729365 | validation: 0.17069732694281853]
	TIME [epoch: 5.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26055030979194926		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.26055030979194926 | validation: 0.2450110954132674]
	TIME [epoch: 5.72 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680626634964435		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.2680626634964435 | validation: 0.22320796811576146]
	TIME [epoch: 5.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21219964307331948		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.21219964307331948 | validation: 0.14199600781433633]
	TIME [epoch: 5.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18540363456343403		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.18540363456343403 | validation: 0.3652202392545324]
	TIME [epoch: 5.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27121927795994033		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.27121927795994033 | validation: 0.15471615514109668]
	TIME [epoch: 5.74 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28624445503980894		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.28624445503980894 | validation: 0.3283487624621425]
	TIME [epoch: 5.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2265677911074471		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.2265677911074471 | validation: 0.19926568556878899]
	TIME [epoch: 5.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22245904823043056		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.22245904823043056 | validation: 0.27903260806144997]
	TIME [epoch: 5.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29175532960513845		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.29175532960513845 | validation: 0.44109267392317725]
	TIME [epoch: 5.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31723812884999997		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.31723812884999997 | validation: 0.16138308892253045]
	TIME [epoch: 5.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20537346100878948		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.20537346100878948 | validation: 0.15344307957598047]
	TIME [epoch: 5.73 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2422188502503561		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.2422188502503561 | validation: 0.3458480222835436]
	TIME [epoch: 5.72 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24405644146073946		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.24405644146073946 | validation: 0.1957591533157344]
	TIME [epoch: 5.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20240678565596557		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.20240678565596557 | validation: 0.21329197405055286]
	TIME [epoch: 5.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26723479599388755		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.26723479599388755 | validation: 0.2236019947436617]
	TIME [epoch: 5.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20007340141827273		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.20007340141827273 | validation: 0.10604763263289402]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647200190792749		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.1647200190792749 | validation: 0.20508635613966472]
	TIME [epoch: 5.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24028832652876386		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.24028832652876386 | validation: 0.3762506950359088]
	TIME [epoch: 5.74 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2440457038091071		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.2440457038091071 | validation: 0.15181254344018486]
	TIME [epoch: 5.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22820830132420353		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.22820830132420353 | validation: 0.24474079034152765]
	TIME [epoch: 5.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24799969612659375		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.24799969612659375 | validation: 0.1277800244751999]
	TIME [epoch: 5.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1965044459678302		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.1965044459678302 | validation: 0.234835167808601]
	TIME [epoch: 5.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17734771986216905		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.17734771986216905 | validation: 0.1494363448059971]
	TIME [epoch: 5.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14248871306579677		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.14248871306579677 | validation: 0.11146783667831618]
	TIME [epoch: 5.73 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16460106540257954		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.16460106540257954 | validation: 0.09826513089321683]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14363939979741508		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.14363939979741508 | validation: 0.3718126355076015]
	TIME [epoch: 5.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2750724352262053		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.2750724352262053 | validation: 0.3117766620734662]
	TIME [epoch: 5.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27519255557101074		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.27519255557101074 | validation: 0.28119578902517484]
	TIME [epoch: 5.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18038779675921715		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.18038779675921715 | validation: 0.18431454827665256]
	TIME [epoch: 5.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1804759957818876		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.1804759957818876 | validation: 0.14588456495731564]
	TIME [epoch: 5.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15251121151804642		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.15251121151804642 | validation: 0.21544310980664158]
	TIME [epoch: 5.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19613606565005026		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.19613606565005026 | validation: 0.3283454230660097]
	TIME [epoch: 5.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22782589064589587		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.22782589064589587 | validation: 0.12700193149904213]
	TIME [epoch: 5.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17807681882911058		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.17807681882911058 | validation: 0.22613748451337537]
	TIME [epoch: 5.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16155273323946295		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.16155273323946295 | validation: 0.13026955154119635]
	TIME [epoch: 5.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20207451575374946		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.20207451575374946 | validation: 0.12818608181679966]
	TIME [epoch: 5.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18202347586410428		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.18202347586410428 | validation: 0.12838147376917655]
	TIME [epoch: 5.73 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15918357796917323		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.15918357796917323 | validation: 0.2572828240258729]
	TIME [epoch: 5.71 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17628575234465832		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.17628575234465832 | validation: 0.15548157029671297]
	TIME [epoch: 5.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741479246525895		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.1741479246525895 | validation: 0.19250258000620737]
	TIME [epoch: 5.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20592513679269897		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.20592513679269897 | validation: 0.16427276495391233]
	TIME [epoch: 5.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18213724656915015		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.18213724656915015 | validation: 0.16387284145028225]
	TIME [epoch: 5.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21363148513586666		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.21363148513586666 | validation: 0.1271923633113849]
	TIME [epoch: 5.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16742924178121138		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.16742924178121138 | validation: 0.17795668274813167]
	TIME [epoch: 5.74 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023989976178783		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.2023989976178783 | validation: 0.3376384565464569]
	TIME [epoch: 5.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20899964204207638		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.20899964204207638 | validation: 0.14196819420833964]
	TIME [epoch: 5.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410906169760315		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.1410906169760315 | validation: 0.2492023243989239]
	TIME [epoch: 5.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2030695778855077		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.2030695778855077 | validation: 0.1345220664250098]
	TIME [epoch: 5.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20943652504416813		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.20943652504416813 | validation: 0.11158840920798341]
	TIME [epoch: 5.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541343220309943		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.1541343220309943 | validation: 0.18097928552100753]
	TIME [epoch: 5.71 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19115825029258493		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.19115825029258493 | validation: 0.16961298021492752]
	TIME [epoch: 5.73 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2268447878539722		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.2268447878539722 | validation: 0.2746864650358483]
	TIME [epoch: 5.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2268173043369968		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.2268173043369968 | validation: 0.1535149312360498]
	TIME [epoch: 5.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256881099340444		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.256881099340444 | validation: 0.21989566438866662]
	TIME [epoch: 5.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1805093438621707		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.1805093438621707 | validation: 0.11565445054638833]
	TIME [epoch: 5.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14580295910391056		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.14580295910391056 | validation: 0.11241247343490918]
	TIME [epoch: 5.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139384370199064		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.139384370199064 | validation: 0.11675024950951535]
	TIME [epoch: 5.74 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705480009868342		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.1705480009868342 | validation: 0.1373750662279126]
	TIME [epoch: 5.71 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16292251002916558		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16292251002916558 | validation: 0.10056033379583067]
	TIME [epoch: 5.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14474879861159431		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.14474879861159431 | validation: 0.11161446827488977]
	TIME [epoch: 5.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19169104191289205		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.19169104191289205 | validation: 0.0896644105942286]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11010039973622784		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.11010039973622784 | validation: 0.30212571508494757]
	TIME [epoch: 5.72 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264207053003763		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.264207053003763 | validation: 0.18816757747472146]
	TIME [epoch: 5.74 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14562729081461356		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.14562729081461356 | validation: 0.12942226540451654]
	TIME [epoch: 5.75 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1401496269509251		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.1401496269509251 | validation: 0.19664150907991257]
	TIME [epoch: 5.72 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15805238079963418		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.15805238079963418 | validation: 0.2054097314022608]
	TIME [epoch: 5.72 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15856733913923376		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.15856733913923376 | validation: 0.14620067072993287]
	TIME [epoch: 5.72 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13998422241779818		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.13998422241779818 | validation: 0.13125570280304696]
	TIME [epoch: 5.72 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17597798773772283		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.17597798773772283 | validation: 0.17704530252677883]
	TIME [epoch: 5.72 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13213044752329256		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.13213044752329256 | validation: 0.10060405597168857]
	TIME [epoch: 5.76 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10850097917892079		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.10850097917892079 | validation: 0.12169603393425844]
	TIME [epoch: 5.73 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14494735111534113		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.14494735111534113 | validation: 0.11266170122677872]
	TIME [epoch: 5.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15682153836577592		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.15682153836577592 | validation: 0.18676034976890737]
	TIME [epoch: 5.72 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14597967337340823		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.14597967337340823 | validation: 0.1613813072270546]
	TIME [epoch: 5.72 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20079131482002358		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.20079131482002358 | validation: 0.1350645837950535]
	TIME [epoch: 5.72 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18357041379220557		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.18357041379220557 | validation: 0.14843717271389686]
	TIME [epoch: 5.74 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18629177507910744		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.18629177507910744 | validation: 0.18687481121300528]
	TIME [epoch: 5.75 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2639692597059913		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.2639692597059913 | validation: 0.42332124737436105]
	TIME [epoch: 5.72 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907648676528248		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.2907648676528248 | validation: 0.307756275663035]
	TIME [epoch: 5.72 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18402810877523257		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.18402810877523257 | validation: 0.12834090485165248]
	TIME [epoch: 5.72 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18891669352286422		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.18891669352286422 | validation: 0.1525816613632413]
	TIME [epoch: 5.72 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15364721989456476		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.15364721989456476 | validation: 0.15705815262671738]
	TIME [epoch: 5.72 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13832781813770914		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.13832781813770914 | validation: 0.1960624567294748]
	TIME [epoch: 5.76 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18958574228270003		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.18958574228270003 | validation: 0.17060590859119718]
	TIME [epoch: 5.73 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1595004829522773		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.1595004829522773 | validation: 0.09740253631598607]
	TIME [epoch: 5.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187314661761638		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.11187314661761638 | validation: 0.0975471558394253]
	TIME [epoch: 5.72 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142000203664533		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.142000203664533 | validation: 0.13135893995776]
	TIME [epoch: 5.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21766806255342108		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.21766806255342108 | validation: 0.13419829979557812]
	TIME [epoch: 5.71 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17192170362085818		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.17192170362085818 | validation: 0.12432492966865354]
	TIME [epoch: 5.72 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364990982561942		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.1364990982561942 | validation: 0.12461466328851069]
	TIME [epoch: 5.73 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14628783219293456		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.14628783219293456 | validation: 0.1381550126146376]
	TIME [epoch: 5.71 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19806432220720244		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.19806432220720244 | validation: 0.1998656071011926]
	TIME [epoch: 5.72 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646422584711702		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.1646422584711702 | validation: 0.09607180377790683]
	TIME [epoch: 5.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21768874636869884		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.21768874636869884 | validation: 0.39893124564784216]
	TIME [epoch: 5.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21093831017252385		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.21093831017252385 | validation: 0.22219616583559926]
	TIME [epoch: 5.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1719859596698375		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.1719859596698375 | validation: 0.1270693950256555]
	TIME [epoch: 5.75 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22273466020324345		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.22273466020324345 | validation: 0.24149448534017587]
	TIME [epoch: 5.71 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16709923082347944		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.16709923082347944 | validation: 0.12193869405574763]
	TIME [epoch: 5.71 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12544966468568147		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.12544966468568147 | validation: 0.10772059022470448]
	TIME [epoch: 5.71 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900353962756039		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.10900353962756039 | validation: 0.12744107843074226]
	TIME [epoch: 5.71 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14646498256654483		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.14646498256654483 | validation: 0.09255683095957401]
	TIME [epoch: 5.71 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09767208542057829		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.09767208542057829 | validation: 0.16215258067645807]
	TIME [epoch: 5.73 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505991735436305		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.1505991735436305 | validation: 0.09868564687434321]
	TIME [epoch: 5.74 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13042781761441657		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.13042781761441657 | validation: 0.09697188524587834]
	TIME [epoch: 5.72 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23843155709527658		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.23843155709527658 | validation: 0.10199949753969868]
	TIME [epoch: 5.71 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228168111264981		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.12228168111264981 | validation: 0.09179333971966935]
	TIME [epoch: 5.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1604684201007176		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.1604684201007176 | validation: 0.1126913140265344]
	TIME [epoch: 5.71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1191968712286742		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.1191968712286742 | validation: 0.08533731268565097]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_399.pth
	Model improved!!!
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09495004049973292		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.09495004049973292 | validation: 0.1280731149827442]
	TIME [epoch: 5.75 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12282057840207314		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.12282057840207314 | validation: 0.28794140205849034]
	TIME [epoch: 5.72 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29251464106576114		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.29251464106576114 | validation: 0.2863458832544683]
	TIME [epoch: 5.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36886462639607803		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.36886462639607803 | validation: 0.2027676007385405]
	TIME [epoch: 5.72 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14564587743208032		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.14564587743208032 | validation: 0.11745189913068725]
	TIME [epoch: 5.71 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10512087231825602		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.10512087231825602 | validation: 0.10945072614034893]
	TIME [epoch: 5.71 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09728832191046602		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.09728832191046602 | validation: 0.12144486899980843]
	TIME [epoch: 5.73 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17336103687543622		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.17336103687543622 | validation: 0.19797743881958588]
	TIME [epoch: 5.74 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23912722728042665		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.23912722728042665 | validation: 0.10853521288251546]
	TIME [epoch: 5.72 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508605378249124		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.10508605378249124 | validation: 0.14270377510642193]
	TIME [epoch: 5.71 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15307149302542433		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.15307149302542433 | validation: 0.11648781776623761]
	TIME [epoch: 5.72 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10527882562167469		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.10527882562167469 | validation: 0.07746884475031857]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12510962814339932		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.12510962814339932 | validation: 0.08763505302383896]
	TIME [epoch: 5.72 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10395582669246445		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.10395582669246445 | validation: 0.08517343240647358]
	TIME [epoch: 5.75 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320809691804064		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.1320809691804064 | validation: 0.10380069600349458]
	TIME [epoch: 5.71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15786858954308203		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.15786858954308203 | validation: 0.09552699486958939]
	TIME [epoch: 5.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212566251330576		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.1212566251330576 | validation: 0.07807182171958381]
	TIME [epoch: 5.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11592852219296189		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.11592852219296189 | validation: 0.09966510579146132]
	TIME [epoch: 5.71 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11685458974695984		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.11685458974695984 | validation: 0.10729437400296377]
	TIME [epoch: 5.71 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1775708251510625		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.1775708251510625 | validation: 0.11127537375540177]
	TIME [epoch: 5.73 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11072143059828254		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.11072143059828254 | validation: 0.14505329430421462]
	TIME [epoch: 5.73 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15704176663978517		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.15704176663978517 | validation: 0.2345497162892624]
	TIME [epoch: 5.71 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23141303268131014		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.23141303268131014 | validation: 0.08735865964871944]
	TIME [epoch: 5.71 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16380154256546545		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.16380154256546545 | validation: 0.1284908192527407]
	TIME [epoch: 5.71 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1133421636803329		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.1133421636803329 | validation: 0.0672829968589624]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09863745686837314		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.09863745686837314 | validation: 0.06733305952139787]
	TIME [epoch: 5.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15352355488559086		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.15352355488559086 | validation: 0.0684407420212424]
	TIME [epoch: 5.76 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081820607151874		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.1081820607151874 | validation: 0.13934080103331684]
	TIME [epoch: 5.71 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280805951835902		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.1280805951835902 | validation: 0.14385046123241405]
	TIME [epoch: 5.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11247754599125157		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.11247754599125157 | validation: 0.08292539877420946]
	TIME [epoch: 5.71 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11155803632690375		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.11155803632690375 | validation: 0.1413489751804648]
	TIME [epoch: 5.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617867948043189		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.1617867948043189 | validation: 0.11102455301081053]
	TIME [epoch: 5.71 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13812731937125536		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.13812731937125536 | validation: 0.25586916144535005]
	TIME [epoch: 5.72 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.221136547659998		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.221136547659998 | validation: 0.08259977615749187]
	TIME [epoch: 5.73 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09667805772225975		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.09667805772225975 | validation: 0.0662705416715942]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10876074949223861		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.10876074949223861 | validation: 0.32102964597908085]
	TIME [epoch: 5.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19484436566329782		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.19484436566329782 | validation: 0.17212121663356886]
	TIME [epoch: 5.71 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13083883125749113		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.13083883125749113 | validation: 0.08765785301428207]
	TIME [epoch: 5.71 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14045833205057906		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.14045833205057906 | validation: 0.08956919870115655]
	TIME [epoch: 5.71 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09605388283421368		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.09605388283421368 | validation: 0.08916154135034887]
	TIME [epoch: 5.75 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429306818261197		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.1429306818261197 | validation: 0.0893022652896206]
	TIME [epoch: 5.72 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355740993661725		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.12355740993661725 | validation: 0.16350018310902242]
	TIME [epoch: 5.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1565270440883558		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.1565270440883558 | validation: 0.27265007418842296]
	TIME [epoch: 5.71 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497447481042371		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.1497447481042371 | validation: 0.15249326762425194]
	TIME [epoch: 5.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10926236180643151		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.10926236180643151 | validation: 0.08398971031683218]
	TIME [epoch: 5.71 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09640325882566544		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.09640325882566544 | validation: 0.07783955075950157]
	TIME [epoch: 5.72 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11552657528720751		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.11552657528720751 | validation: 0.10566174127291596]
	TIME [epoch: 5.74 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11794056916749575		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.11794056916749575 | validation: 0.10889321852057465]
	TIME [epoch: 5.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2337013387749051		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.2337013387749051 | validation: 0.12647990738757023]
	TIME [epoch: 5.71 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09927974881965287		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.09927974881965287 | validation: 0.12198482850100505]
	TIME [epoch: 5.71 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13017037471341036		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.13017037471341036 | validation: 0.07952523262028979]
	TIME [epoch: 5.72 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09849028774299062		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.09849028774299062 | validation: 0.09142418582787229]
	TIME [epoch: 5.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08988436734204874		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.08988436734204874 | validation: 0.09100792610376114]
	TIME [epoch: 5.74 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09516817821601462		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.09516817821601462 | validation: 0.1265078209462148]
	TIME [epoch: 5.71 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11255335083753154		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.11255335083753154 | validation: 0.1452571697372758]
	TIME [epoch: 5.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428484401630969		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1428484401630969 | validation: 0.16097666941101824]
	TIME [epoch: 5.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13124729395955798		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.13124729395955798 | validation: 0.12925074634169292]
	TIME [epoch: 5.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214464176366629		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.11214464176366629 | validation: 0.13490057219997856]
	TIME [epoch: 5.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18832756062250758		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.18832756062250758 | validation: 0.1422488624893175]
	TIME [epoch: 5.71 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13317154794367017		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.13317154794367017 | validation: 0.1109549098296771]
	TIME [epoch: 5.73 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13439036521452544		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.13439036521452544 | validation: 0.1592970465545944]
	TIME [epoch: 5.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10288046965274572		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.10288046965274572 | validation: 0.09138163265105612]
	TIME [epoch: 5.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09350051471676844		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.09350051471676844 | validation: 0.08689005325623086]
	TIME [epoch: 5.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13680134895268142		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.13680134895268142 | validation: 0.14982175135911954]
	TIME [epoch: 5.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12510831834188763		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.12510831834188763 | validation: 0.07774836370040487]
	TIME [epoch: 5.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17006534261506906		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.17006534261506906 | validation: 0.09670573943575227]
	TIME [epoch: 5.74 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13008489875807608		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.13008489875807608 | validation: 0.12026885783337196]
	TIME [epoch: 5.71 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11388088710997218		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.11388088710997218 | validation: 0.19881073689167117]
	TIME [epoch: 5.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14409266609216287		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.14409266609216287 | validation: 0.11501677173546365]
	TIME [epoch: 5.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09311611420288221		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.09311611420288221 | validation: 0.05651558008601224]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11141246397179978		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.11141246397179978 | validation: 0.2801951125159651]
	TIME [epoch: 5.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17003445361190145		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.17003445361190145 | validation: 0.10213134147415064]
	TIME [epoch: 5.71 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14348114495668424		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.14348114495668424 | validation: 0.13613641009046692]
	TIME [epoch: 5.73 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14222786634851686		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.14222786634851686 | validation: 0.1368757033262254]
	TIME [epoch: 5.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13990347076354787		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.13990347076354787 | validation: 0.14915000202615425]
	TIME [epoch: 5.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13925263504874186		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.13925263504874186 | validation: 0.09674626246371179]
	TIME [epoch: 5.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15372671618937067		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.15372671618937067 | validation: 0.096019811596965]
	TIME [epoch: 5.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10399015363474672		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.10399015363474672 | validation: 0.09427119309414309]
	TIME [epoch: 5.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10481346960109367		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.10481346960109367 | validation: 0.07854342602152099]
	TIME [epoch: 5.74 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14201491577648512		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.14201491577648512 | validation: 0.14244610409541852]
	TIME [epoch: 5.71 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17003393474443473		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.17003393474443473 | validation: 0.17231762414195728]
	TIME [epoch: 5.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335982472257868		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.1335982472257868 | validation: 0.08496790560990845]
	TIME [epoch: 5.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10830769821364664		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.10830769821364664 | validation: 0.08955000441508747]
	TIME [epoch: 5.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484845326495152		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.08484845326495152 | validation: 0.10716962354155421]
	TIME [epoch: 5.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133647217033832		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.133647217033832 | validation: 0.08334702349873613]
	TIME [epoch: 5.71 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13799164262035124		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.13799164262035124 | validation: 0.0927466880793769]
	TIME [epoch: 5.73 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11954707403701034		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.11954707403701034 | validation: 0.05538437627833239]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_486.pth
	Model improved!!!
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08239953843259121		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.08239953843259121 | validation: 0.1772927794581934]
	TIME [epoch: 5.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12190458384340834		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.12190458384340834 | validation: 0.10118053625180498]
	TIME [epoch: 5.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09122702087898696		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.09122702087898696 | validation: 0.10450336957137049]
	TIME [epoch: 5.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13735609373484509		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.13735609373484509 | validation: 0.17707175389736243]
	TIME [epoch: 5.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21621511021780987		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.21621511021780987 | validation: 0.19343111488331496]
	TIME [epoch: 5.74 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15996936932671293		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.15996936932671293 | validation: 0.09777947490625216]
	TIME [epoch: 5.71 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874157248400857		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.1874157248400857 | validation: 0.3624545262728742]
	TIME [epoch: 5.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23696272384372313		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.23696272384372313 | validation: 0.13049500455138466]
	TIME [epoch: 5.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12156283427528068		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.12156283427528068 | validation: 0.12433484707975655]
	TIME [epoch: 5.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10299194037711153		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.10299194037711153 | validation: 0.07684763935358165]
	TIME [epoch: 5.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10117910955030222		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.10117910955030222 | validation: 0.06239422519807564]
	TIME [epoch: 5.72 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0893783082084644		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.0893783082084644 | validation: 0.09681066466455615]
	TIME [epoch: 5.73 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09670202216766621		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.09670202216766621 | validation: 0.07193056769468337]
	TIME [epoch: 5.71 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07506309564112038		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.07506309564112038 | validation: 0.06755568281249642]
	TIME [epoch: 5.71 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07791642248475644		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.07791642248475644 | validation: 0.13876775068593988]
	TIME [epoch: 5.71 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13519873285914433		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.13519873285914433 | validation: 0.1625624077907242]
	TIME [epoch: 5.71 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14836260780295088		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.14836260780295088 | validation: 0.1326293022836344]
	TIME [epoch: 5.71 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915270614630801		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.0915270614630801 | validation: 0.06956692106821699]
	TIME [epoch: 5.75 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08768909003510311		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.08768909003510311 | validation: 0.1389229350985326]
	TIME [epoch: 5.71 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12134769529668925		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.12134769529668925 | validation: 0.14503002759507982]
	TIME [epoch: 5.71 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11669097162809879		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.11669097162809879 | validation: 0.08626231699083288]
	TIME [epoch: 5.71 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10700424551003034		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.10700424551003034 | validation: 0.058855353408187025]
	TIME [epoch: 5.71 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1007949207941368		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.1007949207941368 | validation: 0.10407702223129572]
	TIME [epoch: 5.71 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0750842707075997		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.0750842707075997 | validation: 0.06765549951347762]
	TIME [epoch: 5.72 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07568340618018705		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.07568340618018705 | validation: 0.06822866220328358]
	TIME [epoch: 5.73 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15762640540233316		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.15762640540233316 | validation: 0.12704032989897407]
	TIME [epoch: 5.71 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09564102976247661		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.09564102976247661 | validation: 0.0950963988554126]
	TIME [epoch: 5.71 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11252764625267762		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.11252764625267762 | validation: 0.09883701135646594]
	TIME [epoch: 5.71 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.091824824119326		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.091824824119326 | validation: 0.07801028868467727]
	TIME [epoch: 5.71 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442435660466243		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.10442435660466243 | validation: 0.08810221315845918]
	TIME [epoch: 5.71 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08641708854900759		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.08641708854900759 | validation: 0.11428478022691083]
	TIME [epoch: 5.74 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12557295186118972		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.12557295186118972 | validation: 0.06252235573975165]
	TIME [epoch: 5.72 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09083521249896341		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.09083521249896341 | validation: 0.07584640767537185]
	TIME [epoch: 5.71 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08259386031769325		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.08259386031769325 | validation: 0.15273858403339052]
	TIME [epoch: 5.71 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254037428092582		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.1254037428092582 | validation: 0.11182048419349987]
	TIME [epoch: 5.71 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11733599961376528		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.11733599961376528 | validation: 0.08039149843184883]
	TIME [epoch: 5.71 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09505932896781336		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.09505932896781336 | validation: 0.11321837900844056]
	TIME [epoch: 5.71 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09344560605428939		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.09344560605428939 | validation: 0.08417774454089468]
	TIME [epoch: 5.75 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07307828229931307		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.07307828229931307 | validation: 0.08732879472459004]
	TIME [epoch: 5.71 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0953591549241346		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.0953591549241346 | validation: 0.08712430860105265]
	TIME [epoch: 5.71 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1201179856629595		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.1201179856629595 | validation: 0.06582438817858577]
	TIME [epoch: 5.71 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09897379751453544		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.09897379751453544 | validation: 0.07587131276614599]
	TIME [epoch: 5.71 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07668738552883218		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.07668738552883218 | validation: 0.1043669358154955]
	TIME [epoch: 5.71 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10570486941463107		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.10570486941463107 | validation: 0.06739601817396214]
	TIME [epoch: 5.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13156706698340723		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.13156706698340723 | validation: 0.10619428570759937]
	TIME [epoch: 5.72 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196612851905691		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.08196612851905691 | validation: 0.07103397780928714]
	TIME [epoch: 5.71 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09212554427194979		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.09212554427194979 | validation: 0.0907967041785146]
	TIME [epoch: 5.71 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08035033585578306		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.08035033585578306 | validation: 0.05923039208148549]
	TIME [epoch: 5.71 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13409846043794524		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.13409846043794524 | validation: 0.11748547477688562]
	TIME [epoch: 5.71 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08810651434685438		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.08810651434685438 | validation: 0.09126885235639008]
	TIME [epoch: 5.71 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09630595164048991		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.09630595164048991 | validation: 0.07924960245090322]
	TIME [epoch: 5.75 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831766851474963		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.08831766851474963 | validation: 0.0631917944700938]
	TIME [epoch: 5.71 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10655670276421075		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.10655670276421075 | validation: 0.3122653361360924]
	TIME [epoch: 5.71 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21273362395811277		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.21273362395811277 | validation: 0.07533245563034006]
	TIME [epoch: 5.71 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11939171880735182		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.11939171880735182 | validation: 0.14747448266112026]
	TIME [epoch: 5.71 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337714813058095		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.1337714813058095 | validation: 0.2328108545280292]
	TIME [epoch: 5.71 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16410390098053237		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.16410390098053237 | validation: 0.11922594050082987]
	TIME [epoch: 5.74 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11917731788486201		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.11917731788486201 | validation: 0.09000867973694397]
	TIME [epoch: 5.72 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10033198525580903		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.10033198525580903 | validation: 0.08393243080342642]
	TIME [epoch: 5.71 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09189050484655704		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.09189050484655704 | validation: 0.10644985966991292]
	TIME [epoch: 5.71 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306483137861418		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.1306483137861418 | validation: 0.18438565903609]
	TIME [epoch: 5.71 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12402183450465018		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.12402183450465018 | validation: 0.08958224973622825]
	TIME [epoch: 5.71 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0961592229246985		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.0961592229246985 | validation: 0.08704780880358412]
	TIME [epoch: 5.71 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12341563543918393		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.12341563543918393 | validation: 0.12492978528949905]
	TIME [epoch: 5.75 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114010381641833		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.114010381641833 | validation: 0.09713080330874899]
	TIME [epoch: 5.71 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09396202187658914		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.09396202187658914 | validation: 0.1335031166068457]
	TIME [epoch: 5.71 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13387638233239463		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.13387638233239463 | validation: 0.07550520817775137]
	TIME [epoch: 5.71 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10393552404999358		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.10393552404999358 | validation: 0.08926357799443918]
	TIME [epoch: 5.71 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0957940036937023		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.0957940036937023 | validation: 0.08849410175810929]
	TIME [epoch: 5.71 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14585001119907462		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.14585001119907462 | validation: 0.06342615545201281]
	TIME [epoch: 5.73 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09357128316122211		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.09357128316122211 | validation: 0.1134774296266803]
	TIME [epoch: 5.72 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09063087723498006		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.09063087723498006 | validation: 0.12128702511650169]
	TIME [epoch: 5.71 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12575782032176114		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.12575782032176114 | validation: 0.0530052066272033]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07237638337868586		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.07237638337868586 | validation: 0.0728804180055024]
	TIME [epoch: 5.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07206463823854989		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.07206463823854989 | validation: 0.15527565128030069]
	TIME [epoch: 5.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515697312114778		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1515697312114778 | validation: 0.10799756083266576]
	TIME [epoch: 5.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09697349369441817		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.09697349369441817 | validation: 0.0635736814214792]
	TIME [epoch: 5.74 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08445054803920835		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.08445054803920835 | validation: 0.049021573611505866]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08735498673046013		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.08735498673046013 | validation: 0.06389782318457417]
	TIME [epoch: 5.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08497354283427755		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.08497354283427755 | validation: 0.0800687399889151]
	TIME [epoch: 5.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09507885841960736		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.09507885841960736 | validation: 0.1039687299261854]
	TIME [epoch: 5.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12232355506391807		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.12232355506391807 | validation: 0.24155303121707952]
	TIME [epoch: 5.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22439493053590806		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.22439493053590806 | validation: 0.08118977296612925]
	TIME [epoch: 5.73 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318470130457575		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.08318470130457575 | validation: 0.09989475806421688]
	TIME [epoch: 5.71 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11427656366856007		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.11427656366856007 | validation: 0.08779003793248412]
	TIME [epoch: 5.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08564550330671761		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.08564550330671761 | validation: 0.10829216054200848]
	TIME [epoch: 5.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0951679542875858		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.0951679542875858 | validation: 0.08040587959147551]
	TIME [epoch: 5.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1222495380209003		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.1222495380209003 | validation: 0.1250760033800761]
	TIME [epoch: 5.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10218701363414956		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.10218701363414956 | validation: 0.0860644217937651]
	TIME [epoch: 5.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756584967612842		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.0756584967612842 | validation: 0.09062556666749587]
	TIME [epoch: 5.74 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07991739341852333		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.07991739341852333 | validation: 0.09264246208019873]
	TIME [epoch: 5.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07076603760830966		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.07076603760830966 | validation: 0.08687619594088881]
	TIME [epoch: 5.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09513540682162604		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.09513540682162604 | validation: 0.08905070492020403]
	TIME [epoch: 5.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818108085281318		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.12818108085281318 | validation: 0.2320430735295917]
	TIME [epoch: 5.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2230310394958771		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.2230310394958771 | validation: 0.11401027244284141]
	TIME [epoch: 5.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07929661939917289		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.07929661939917289 | validation: 0.04143081886224903]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07619596777257177		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.07619596777257177 | validation: 0.07514564686829782]
	TIME [epoch: 5.72 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11519682597082159		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.11519682597082159 | validation: 0.10467347800789537]
	TIME [epoch: 5.71 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859268197501131		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.11859268197501131 | validation: 0.08313746974099619]
	TIME [epoch: 5.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08635205971101342		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.08635205971101342 | validation: 0.059178901092757766]
	TIME [epoch: 5.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0701432878083327		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.0701432878083327 | validation: 0.08315519764335395]
	TIME [epoch: 5.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127979942870858		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.08127979942870858 | validation: 0.06839655280936781]
	TIME [epoch: 5.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06672626783479492		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.06672626783479492 | validation: 0.0758899953202855]
	TIME [epoch: 5.74 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08617301358815244		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.08617301358815244 | validation: 0.08785885656825411]
	TIME [epoch: 5.71 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539375696450677		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.10539375696450677 | validation: 0.10199744839829034]
	TIME [epoch: 5.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17591313399322167		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.17591313399322167 | validation: 0.15270240687793735]
	TIME [epoch: 5.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11772061867091999		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.11772061867091999 | validation: 0.07199082583193082]
	TIME [epoch: 5.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09718350136543774		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.09718350136543774 | validation: 0.0840114910550571]
	TIME [epoch: 5.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07761637873591337		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.07761637873591337 | validation: 0.08744532876251813]
	TIME [epoch: 5.73 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09692770400450187		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.09692770400450187 | validation: 0.09546877410880317]
	TIME [epoch: 5.72 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09370296129131375		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.09370296129131375 | validation: 0.08624866123986369]
	TIME [epoch: 5.71 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08069729852219555		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.08069729852219555 | validation: 0.08752836321252333]
	TIME [epoch: 5.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09230628865082985		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.09230628865082985 | validation: 0.06139687874157223]
	TIME [epoch: 5.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07467273779730632		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.07467273779730632 | validation: 0.05867461496000515]
	TIME [epoch: 5.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06389902152121547		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.06389902152121547 | validation: 0.06361357471174986]
	TIME [epoch: 5.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10579119086119332		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.10579119086119332 | validation: 0.08992732592143057]
	TIME [epoch: 5.74 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0867505085424651		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.0867505085424651 | validation: 0.08300302732945151]
	TIME [epoch: 5.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07075969594412737		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.07075969594412737 | validation: 0.06872045318645464]
	TIME [epoch: 5.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07356862187186493		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.07356862187186493 | validation: 0.10096246820005586]
	TIME [epoch: 5.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10620278234408288		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.10620278234408288 | validation: 0.07655981705846555]
	TIME [epoch: 5.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07255906578593518		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.07255906578593518 | validation: 0.0951149923028035]
	TIME [epoch: 5.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12860995325910166		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.12860995325910166 | validation: 0.08253978137053387]
	TIME [epoch: 5.73 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676493616810015		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.09676493616810015 | validation: 0.08496775686800413]
	TIME [epoch: 5.71 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08336797144449276		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.08336797144449276 | validation: 0.09082279269603774]
	TIME [epoch: 5.71 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0680483680713997		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.0680483680713997 | validation: 0.0493850861128148]
	TIME [epoch: 5.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06730377828245118		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.06730377828245118 | validation: 0.10248262127789623]
	TIME [epoch: 5.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991731520617202		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.0991731520617202 | validation: 0.04972920440719546]
	TIME [epoch: 5.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08540206541535446		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.08540206541535446 | validation: 0.10936689255194279]
	TIME [epoch: 5.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08840920776472673		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.08840920776472673 | validation: 0.08419097541635327]
	TIME [epoch: 5.74 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11794008731764134		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.11794008731764134 | validation: 0.06588072837883416]
	TIME [epoch: 5.71 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07926044062470426		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.07926044062470426 | validation: 0.10696592425410631]
	TIME [epoch: 5.71 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09658470204707571		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.09658470204707571 | validation: 0.06372863411740451]
	TIME [epoch: 5.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06963137831227915		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.06963137831227915 | validation: 0.08680748622593336]
	TIME [epoch: 5.71 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09461714943870228		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.09461714943870228 | validation: 0.13481004374341535]
	TIME [epoch: 5.71 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10354020362664101		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.10354020362664101 | validation: 0.0732130060713352]
	TIME [epoch: 5.72 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07202972368702293		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.07202972368702293 | validation: 0.08343367708106676]
	TIME [epoch: 5.73 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08168129555634526		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.08168129555634526 | validation: 0.06679581843247658]
	TIME [epoch: 5.71 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07230949569576611		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.07230949569576611 | validation: 0.06747003508574441]
	TIME [epoch: 5.71 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09104380902299221		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.09104380902299221 | validation: 0.07169957496451883]
	TIME [epoch: 5.71 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07999751988227718		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.07999751988227718 | validation: 0.058477986731248155]
	TIME [epoch: 5.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10911069070996396		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.10911069070996396 | validation: 0.12244962838920642]
	TIME [epoch: 5.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10143657507595075		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.10143657507595075 | validation: 0.09140234309128595]
	TIME [epoch: 5.74 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11218298900961782		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.11218298900961782 | validation: 0.11475019454693598]
	TIME [epoch: 5.71 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10138878560698653		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.10138878560698653 | validation: 0.07188732730034003]
	TIME [epoch: 5.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07785828168701911		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.07785828168701911 | validation: 0.0491354396144593]
	TIME [epoch: 5.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06664345949109407		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.06664345949109407 | validation: 0.07747471894454966]
	TIME [epoch: 5.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08538991752557774		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.08538991752557774 | validation: 0.0751021975480096]
	TIME [epoch: 5.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07545190532806871		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.07545190532806871 | validation: 0.07976129544577218]
	TIME [epoch: 5.71 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07539861554215113		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.07539861554215113 | validation: 0.07847291813394626]
	TIME [epoch: 5.73 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07813795669936048		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.07813795669936048 | validation: 0.09947090039570736]
	TIME [epoch: 5.71 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833713914733709		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.10833713914733709 | validation: 0.06395576426023478]
	TIME [epoch: 5.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0733426732856799		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.0733426732856799 | validation: 0.08328921276672492]
	TIME [epoch: 5.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09192227060692416		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.09192227060692416 | validation: 0.05635066099917244]
	TIME [epoch: 5.71 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06500423320914536		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.06500423320914536 | validation: 0.06907924206032044]
	TIME [epoch: 5.71 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09495068025025481		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.09495068025025481 | validation: 0.06290761573470897]
	TIME [epoch: 5.74 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07176901429417394		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.07176901429417394 | validation: 0.10409612806525628]
	TIME [epoch: 5.71 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14944688710514076		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.14944688710514076 | validation: 0.13475908679394208]
	TIME [epoch: 5.71 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08668819894781302		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.08668819894781302 | validation: 0.05998198233235091]
	TIME [epoch: 5.71 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07487356311149496		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.07487356311149496 | validation: 0.08761462118645741]
	TIME [epoch: 5.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06692553126435491		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.06692553126435491 | validation: 0.04638642113674562]
	TIME [epoch: 5.71 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06836444053289703		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.06836444053289703 | validation: 0.05445128800892458]
	TIME [epoch: 5.72 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08673889983995556		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.08673889983995556 | validation: 0.11157359525193605]
	TIME [epoch: 5.73 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09588116785137757		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.09588116785137757 | validation: 0.06565970848054149]
	TIME [epoch: 5.71 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07459390140931582		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.07459390140931582 | validation: 0.05612126786913899]
	TIME [epoch: 5.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06968353409283942		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.06968353409283942 | validation: 0.09177954715053847]
	TIME [epoch: 5.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10527448590111442		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.10527448590111442 | validation: 0.048000977401691076]
	TIME [epoch: 5.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306055855358901		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.06306055855358901 | validation: 0.05261098532792678]
	TIME [epoch: 5.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07097363019830166		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.07097363019830166 | validation: 0.053815511581952295]
	TIME [epoch: 5.74 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06890238670613774		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.06890238670613774 | validation: 0.057320922648441804]
	TIME [epoch: 5.71 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059456105182242536		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.059456105182242536 | validation: 0.07716000444980342]
	TIME [epoch: 5.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07345139777682506		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.07345139777682506 | validation: 0.05255734470332763]
	TIME [epoch: 5.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06514460758341717		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.06514460758341717 | validation: 0.08486394421343949]
	TIME [epoch: 5.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0831617311547195		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.0831617311547195 | validation: 0.06459042917876243]
	TIME [epoch: 5.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07284525449189037		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.07284525449189037 | validation: 0.05994366936254198]
	TIME [epoch: 5.72 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09728489250701175		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.09728489250701175 | validation: 0.09786783820886441]
	TIME [epoch: 5.73 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11074576973792662		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.11074576973792662 | validation: 0.07929861737909848]
	TIME [epoch: 5.71 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08633262923874753		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.08633262923874753 | validation: 0.05010639708467906]
	TIME [epoch: 5.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06447500643709148		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.06447500643709148 | validation: 0.08138251407689814]
	TIME [epoch: 5.71 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11581483260429348		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.11581483260429348 | validation: 0.09057176076342512]
	TIME [epoch: 5.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08918887546258844		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.08918887546258844 | validation: 0.05304542003905608]
	TIME [epoch: 5.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06040860338777239		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.06040860338777239 | validation: 0.04406226016229871]
	TIME [epoch: 5.73 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06536819240554523		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.06536819240554523 | validation: 0.0960325838242113]
	TIME [epoch: 5.72 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09447871239476738		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.09447871239476738 | validation: 0.052081328340617045]
	TIME [epoch: 5.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07727253525424332		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.07727253525424332 | validation: 0.05810714209702903]
	TIME [epoch: 5.71 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08664433913279544		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.08664433913279544 | validation: 0.05393172069255353]
	TIME [epoch: 5.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062303844993538096		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.062303844993538096 | validation: 0.04670602999678228]
	TIME [epoch: 5.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08573241901957268		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.08573241901957268 | validation: 0.09239541149085831]
	TIME [epoch: 5.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07981675565064857		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.07981675565064857 | validation: 0.06691416849902726]
	TIME [epoch: 5.74 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07983212108659196		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.07983212108659196 | validation: 0.0483788842917869]
	TIME [epoch: 5.71 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07033745039926326		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.07033745039926326 | validation: 0.059155250248274706]
	TIME [epoch: 5.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057111615120598626		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.057111615120598626 | validation: 0.04836282289876128]
	TIME [epoch: 5.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06732668631983375		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.06732668631983375 | validation: 0.08557117098970225]
	TIME [epoch: 5.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09778699055828488		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.09778699055828488 | validation: 0.08886743652586583]
	TIME [epoch: 5.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07501552472110062		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.07501552472110062 | validation: 0.05706422502186147]
	TIME [epoch: 5.73 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06959468886987491		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.06959468886987491 | validation: 0.07276117243553017]
	TIME [epoch: 5.72 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09604538766360193		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.09604538766360193 | validation: 0.09719373921150268]
	TIME [epoch: 5.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278346533727999		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.1278346533727999 | validation: 0.07056147645669418]
	TIME [epoch: 5.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07842010116974055		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.07842010116974055 | validation: 0.09676535023418417]
	TIME [epoch: 5.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08522233327533334		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.08522233327533334 | validation: 0.05245167582194021]
	TIME [epoch: 5.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08405648559126508		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.08405648559126508 | validation: 0.05071391347703671]
	TIME [epoch: 5.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06237858457120396		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.06237858457120396 | validation: 0.05512737369627601]
	TIME [epoch: 5.74 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07349094650069277		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.07349094650069277 | validation: 0.06907364865384796]
	TIME [epoch: 5.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09296412115338		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.09296412115338 | validation: 0.08201609784280266]
	TIME [epoch: 5.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11509530862974368		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.11509530862974368 | validation: 0.06418290588728763]
	TIME [epoch: 5.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08320368814721844		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.08320368814721844 | validation: 0.0714395677702454]
	TIME [epoch: 5.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09141372624834478		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.09141372624834478 | validation: 0.06088926065314688]
	TIME [epoch: 5.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08774826549144762		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.08774826549144762 | validation: 0.06748551821064445]
	TIME [epoch: 5.73 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06471770268650315		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.06471770268650315 | validation: 0.030924209428210538]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_694.pth
	Model improved!!!
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057595642839989775		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.057595642839989775 | validation: 0.04104249693626821]
	TIME [epoch: 5.71 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06000546100726764		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.06000546100726764 | validation: 0.04356059562657785]
	TIME [epoch: 5.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06369314800221569		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.06369314800221569 | validation: 0.07750247931490276]
	TIME [epoch: 5.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07188483259976769		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.07188483259976769 | validation: 0.06394949126332816]
	TIME [epoch: 5.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057251584651065016		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.057251584651065016 | validation: 0.049996230660464824]
	TIME [epoch: 5.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09552553844620501		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.09552553844620501 | validation: 0.15620877299411606]
	TIME [epoch: 5.74 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09624243760431132		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.09624243760431132 | validation: 0.04489277722640555]
	TIME [epoch: 5.71 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06701548542083585		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.06701548542083585 | validation: 0.04984094309779806]
	TIME [epoch: 5.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062344965044476314		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.062344965044476314 | validation: 0.07010213707166926]
	TIME [epoch: 5.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10752829924777324		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.10752829924777324 | validation: 0.09307162549706434]
	TIME [epoch: 5.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08608694309182391		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.08608694309182391 | validation: 0.056887049124733836]
	TIME [epoch: 5.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07042660442559386		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.07042660442559386 | validation: 0.05572068062178961]
	TIME [epoch: 5.73 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06903069733775864		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.06903069733775864 | validation: 0.06034714380085216]
	TIME [epoch: 5.72 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07294131091277159		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.07294131091277159 | validation: 0.06382082301411246]
	TIME [epoch: 5.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07779876180994992		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.07779876180994992 | validation: 0.07426687574504663]
	TIME [epoch: 5.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07137714153300857		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.07137714153300857 | validation: 0.05274402856488356]
	TIME [epoch: 5.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06850501486471436		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.06850501486471436 | validation: 0.0885101371770065]
	TIME [epoch: 5.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09653931594272025		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.09653931594272025 | validation: 0.08761818383224448]
	TIME [epoch: 5.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0885657665482091		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.0885657665482091 | validation: 0.06472138283361434]
	TIME [epoch: 5.74 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06893846109623235		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.06893846109623235 | validation: 0.051716902690385924]
	TIME [epoch: 5.71 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05574054359207793		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.05574054359207793 | validation: 0.05354221077674323]
	TIME [epoch: 5.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07251880192868324		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.07251880192868324 | validation: 0.06389913623198588]
	TIME [epoch: 5.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07058974286891614		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.07058974286891614 | validation: 0.05650017238761351]
	TIME [epoch: 5.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07229720367912994		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.07229720367912994 | validation: 0.048959295836319285]
	TIME [epoch: 5.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06238429440486984		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.06238429440486984 | validation: 0.06491862213237014]
	TIME [epoch: 5.73 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07953428439661771		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.07953428439661771 | validation: 0.06899184748031881]
	TIME [epoch: 5.72 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07472463268390851		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.07472463268390851 | validation: 0.07816260830548873]
	TIME [epoch: 5.71 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07995393083315194		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.07995393083315194 | validation: 0.09793189591915308]
	TIME [epoch: 5.71 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11019666162547126		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.11019666162547126 | validation: 0.06980258074688254]
	TIME [epoch: 5.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08903347841220877		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.08903347841220877 | validation: 0.0644965832319135]
	TIME [epoch: 5.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09298138809605186		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.09298138809605186 | validation: 0.11976787389747692]
	TIME [epoch: 5.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078347922508053		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.1078347922508053 | validation: 0.04620483850384195]
	TIME [epoch: 5.74 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060913218355034396		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.060913218355034396 | validation: 0.08097678781177392]
	TIME [epoch: 5.71 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08923214983827825		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.08923214983827825 | validation: 0.1486089542528694]
	TIME [epoch: 5.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295850970192253		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.1295850970192253 | validation: 0.08491379767837237]
	TIME [epoch: 5.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06995886517877725		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.06995886517877725 | validation: 0.0466896392777895]
	TIME [epoch: 5.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07112231035641904		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.07112231035641904 | validation: 0.06169534713021145]
	TIME [epoch: 5.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058450213290004736		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.058450213290004736 | validation: 0.0779562157924094]
	TIME [epoch: 5.72 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07200796751354685		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.07200796751354685 | validation: 0.06790906174909091]
	TIME [epoch: 5.73 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06443660992360992		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.06443660992360992 | validation: 0.045625021400141894]
	TIME [epoch: 5.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060477113306603825		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.060477113306603825 | validation: 0.06067207708710885]
	TIME [epoch: 5.71 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08594465051479969		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.08594465051479969 | validation: 0.09216200724665534]
	TIME [epoch: 5.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08260391645609055		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.08260391645609055 | validation: 0.054912995300285886]
	TIME [epoch: 5.71 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06943904444143653		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.06943904444143653 | validation: 0.06818556789351722]
	TIME [epoch: 5.71 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07862264741203341		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.07862264741203341 | validation: 0.0679114587355157]
	TIME [epoch: 5.74 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12063161054264299		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.12063161054264299 | validation: 0.13567919123602423]
	TIME [epoch: 5.71 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10811932140192848		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.10811932140192848 | validation: 0.11577976875613288]
	TIME [epoch: 5.72 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11674112551382196		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.11674112551382196 | validation: 0.06833648895979504]
	TIME [epoch: 5.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.074108621347384		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.074108621347384 | validation: 0.06699315480536204]
	TIME [epoch: 5.71 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09231869810489238		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.09231869810489238 | validation: 0.15419150871514062]
	TIME [epoch: 5.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13558673864623105		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.13558673864623105 | validation: 0.061895833858839476]
	TIME [epoch: 5.72 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05921238474581449		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.05921238474581449 | validation: 0.06328172614383433]
	TIME [epoch: 5.74 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05683730934191939		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.05683730934191939 | validation: 0.0575075798052108]
	TIME [epoch: 5.71 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06216823692071283		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.06216823692071283 | validation: 0.054866346830806545]
	TIME [epoch: 5.71 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05642053213802767		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.05642053213802767 | validation: 0.06627497700631782]
	TIME [epoch: 5.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06005332498806712		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.06005332498806712 | validation: 0.08464607655385323]
	TIME [epoch: 5.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06569226306869702		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.06569226306869702 | validation: 0.06156856324227796]
	TIME [epoch: 5.71 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06571999702209523		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.06571999702209523 | validation: 0.07319779204300414]
	TIME [epoch: 5.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06855425230168138		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.06855425230168138 | validation: 0.061743759915293864]
	TIME [epoch: 5.71 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07109281001449498		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.07109281001449498 | validation: 0.06380245985880759]
	TIME [epoch: 5.71 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07634197224633603		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.07634197224633603 | validation: 0.07368336982429455]
	TIME [epoch: 5.71 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09934057654243053		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.09934057654243053 | validation: 0.07548714269379134]
	TIME [epoch: 5.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770898743377953		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.0770898743377953 | validation: 0.060834884876505096]
	TIME [epoch: 5.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845632109620109		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.06845632109620109 | validation: 0.07093305255668461]
	TIME [epoch: 5.71 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809062915584775		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.0809062915584775 | validation: 0.06776883182313585]
	TIME [epoch: 5.73 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06978438559030739		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.06978438559030739 | validation: 0.08288632820674977]
	TIME [epoch: 5.71 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09362477717410243		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.09362477717410243 | validation: 0.0672958560282446]
	TIME [epoch: 5.71 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06973074042817798		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.06973074042817798 | validation: 0.07572805406398396]
	TIME [epoch: 5.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07771585368565298		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.07771585368565298 | validation: 0.06926314826781367]
	TIME [epoch: 5.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07307870724925981		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.07307870724925981 | validation: 0.09098120253620208]
	TIME [epoch: 5.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08916032533567077		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08916032533567077 | validation: 0.07914906257486468]
	TIME [epoch: 5.74 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09202991453102624		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.09202991453102624 | validation: 0.08244309117005667]
	TIME [epoch: 5.71 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09068768652286947		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.09068768652286947 | validation: 0.06929464285300432]
	TIME [epoch: 5.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07651245535990284		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.07651245535990284 | validation: 0.09922684258898508]
	TIME [epoch: 5.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833848635599921		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.10833848635599921 | validation: 0.0944543310470381]
	TIME [epoch: 5.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078056782165866		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.10078056782165866 | validation: 0.0854978306811621]
	TIME [epoch: 5.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08938219255797833		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.08938219255797833 | validation: 0.07748793870006027]
	TIME [epoch: 5.71 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0859455286040678		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.0859455286040678 | validation: 0.06983873071431701]
	TIME [epoch: 5.73 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07247961271744716		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.07247961271744716 | validation: 0.04765234161026365]
	TIME [epoch: 5.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667898751374162		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.0667898751374162 | validation: 0.05661376512416317]
	TIME [epoch: 5.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05904299401580213		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.05904299401580213 | validation: 0.056841204344622955]
	TIME [epoch: 5.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06618604532182956		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.06618604532182956 | validation: 0.06520049431982168]
	TIME [epoch: 5.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07462916709153622		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.07462916709153622 | validation: 0.06587152397026323]
	TIME [epoch: 5.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0666739823540279		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.0666739823540279 | validation: 0.05448942478257042]
	TIME [epoch: 5.74 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052989940536698005		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.052989940536698005 | validation: 0.07003481739903265]
	TIME [epoch: 5.71 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08342000147866313		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.08342000147866313 | validation: 0.08308053210612078]
	TIME [epoch: 5.71 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09534720674983585		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.09534720674983585 | validation: 0.05049681757669866]
	TIME [epoch: 5.71 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513137367931794		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.06513137367931794 | validation: 0.06340360789810848]
	TIME [epoch: 5.71 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06370117871994968		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.06370117871994968 | validation: 0.05071454626079229]
	TIME [epoch: 5.71 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06597857281494256		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.06597857281494256 | validation: 0.07773220227649119]
	TIME [epoch: 5.71 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06788326773748408		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.06788326773748408 | validation: 0.04958590729554217]
	TIME [epoch: 5.74 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06443077065821026		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.06443077065821026 | validation: 0.06265150853612157]
	TIME [epoch: 5.71 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09376219601361208		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.09376219601361208 | validation: 0.12722854758483684]
	TIME [epoch: 5.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10190809574233922		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.10190809574233922 | validation: 0.06469640931211398]
	TIME [epoch: 5.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05847445185605051		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.05847445185605051 | validation: 0.059011391483513476]
	TIME [epoch: 5.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060834861537819945		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.060834861537819945 | validation: 0.05700165663982355]
	TIME [epoch: 5.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06216375413779765		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.06216375413779765 | validation: 0.05152361378482329]
	TIME [epoch: 5.73 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05610881615168904		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.05610881615168904 | validation: 0.05130654800682919]
	TIME [epoch: 5.71 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06591283154216329		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.06591283154216329 | validation: 0.05090925649595795]
	TIME [epoch: 5.71 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055013573617956765		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.055013573617956765 | validation: 0.06838672829862322]
	TIME [epoch: 5.71 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06903602630829833		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.06903602630829833 | validation: 0.04781528923718581]
	TIME [epoch: 5.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051547739781351964		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.051547739781351964 | validation: 0.05521993193415174]
	TIME [epoch: 5.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056994619133962414		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.056994619133962414 | validation: 0.07219031498762178]
	TIME [epoch: 5.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0745688914904356		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.0745688914904356 | validation: 0.07231277150741032]
	TIME [epoch: 5.74 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06903246376563998		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.06903246376563998 | validation: 0.06303928732320575]
	TIME [epoch: 5.71 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06743189880107893		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.06743189880107893 | validation: 0.044294872319699675]
	TIME [epoch: 5.71 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054381096598026986		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.054381096598026986 | validation: 0.038109014078812606]
	TIME [epoch: 5.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04985419869004493		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.04985419869004493 | validation: 0.041239753797890154]
	TIME [epoch: 5.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05164508070978521		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.05164508070978521 | validation: 0.04563599523543534]
	TIME [epoch: 5.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05250030994178134		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.05250030994178134 | validation: 0.05933342138363873]
	TIME [epoch: 5.73 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07812846105125675		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.07812846105125675 | validation: 0.0470826024455795]
	TIME [epoch: 5.72 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603420696633574		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.05603420696633574 | validation: 0.05029968637004414]
	TIME [epoch: 5.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06346738669311539		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.06346738669311539 | validation: 0.04642731304058945]
	TIME [epoch: 5.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06392679582263645		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.06392679582263645 | validation: 0.048412892505550274]
	TIME [epoch: 5.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05268658651264588		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.05268658651264588 | validation: 0.042026617218581634]
	TIME [epoch: 5.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047758001118283905		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.047758001118283905 | validation: 0.042804282786063574]
	TIME [epoch: 5.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04277715110577854		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.04277715110577854 | validation: 0.03965710291047562]
	TIME [epoch: 5.75 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04081389474854145		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.04081389474854145 | validation: 0.04014416377099229]
	TIME [epoch: 5.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052145708109973335		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.052145708109973335 | validation: 0.05737051630265182]
	TIME [epoch: 5.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05444654428411758		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.05444654428411758 | validation: 0.050795374774992484]
	TIME [epoch: 5.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045623701282223345		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.045623701282223345 | validation: 0.03548938290270199]
	TIME [epoch: 5.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04609799193282291		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.04609799193282291 | validation: 0.03959686476302289]
	TIME [epoch: 5.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05949071611803133		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.05949071611803133 | validation: 0.07372440054308746]
	TIME [epoch: 5.73 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061753665993424876		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.061753665993424876 | validation: 0.043397847363850134]
	TIME [epoch: 5.72 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061229704262379815		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.061229704262379815 | validation: 0.04885766032254258]
	TIME [epoch: 5.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054242435648411705		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.054242435648411705 | validation: 0.037886282074442015]
	TIME [epoch: 5.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05460332720648274		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.05460332720648274 | validation: 0.07728666325554995]
	TIME [epoch: 5.71 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07453914720260761		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.07453914720260761 | validation: 0.06913758104115068]
	TIME [epoch: 5.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08214084265653157		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.08214084265653157 | validation: 0.05608059663912124]
	TIME [epoch: 5.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05160426953392493		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.05160426953392493 | validation: 0.03906752772808309]
	TIME [epoch: 5.75 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05125694486396264		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.05125694486396264 | validation: 0.0621911555910261]
	TIME [epoch: 5.71 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07295450029773143		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.07295450029773143 | validation: 0.06761281893659093]
	TIME [epoch: 5.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05928242275686666		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.05928242275686666 | validation: 0.04406393936513962]
	TIME [epoch: 5.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04827999524638005		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.04827999524638005 | validation: 0.04293027669292796]
	TIME [epoch: 5.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0528281002832335		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.0528281002832335 | validation: 0.03760635784543488]
	TIME [epoch: 5.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04693153139898737		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.04693153139898737 | validation: 0.055842022182323425]
	TIME [epoch: 5.73 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11819992607885701		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.11819992607885701 | validation: 0.07886669206925688]
	TIME [epoch: 5.71 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06932890832118406		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.06932890832118406 | validation: 0.04795951740054062]
	TIME [epoch: 5.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0698744247158821		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.0698744247158821 | validation: 0.05969433401274742]
	TIME [epoch: 5.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05461570009435564		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.05461570009435564 | validation: 0.03771710430438778]
	TIME [epoch: 5.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04286615009846421		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.04286615009846421 | validation: 0.047712986187215735]
	TIME [epoch: 5.71 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047673054436085334		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.047673054436085334 | validation: 0.047768141416838786]
	TIME [epoch: 5.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056027205089225984		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.056027205089225984 | validation: 0.050643862851055134]
	TIME [epoch: 5.74 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046750946826894325		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.046750946826894325 | validation: 0.05137973931955208]
	TIME [epoch: 5.71 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054462981791797614		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.054462981791797614 | validation: 0.06292055059285626]
	TIME [epoch: 5.71 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05261742250094554		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.05261742250094554 | validation: 0.04492417701347641]
	TIME [epoch: 5.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04482112914437687		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.04482112914437687 | validation: 0.03729905340881023]
	TIME [epoch: 5.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044696260191515194		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.044696260191515194 | validation: 0.05875692542691269]
	TIME [epoch: 5.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093274593960907		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.06093274593960907 | validation: 0.061647884398858224]
	TIME [epoch: 5.72 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495840447115674		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.05495840447115674 | validation: 0.03459666180373524]
	TIME [epoch: 5.73 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04918315934718674		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.04918315934718674 | validation: 0.05866730557291538]
	TIME [epoch: 5.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05730684007253424		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.05730684007253424 | validation: 0.0439307055453817]
	TIME [epoch: 5.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04599848404888521		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.04599848404888521 | validation: 0.045169351168583775]
	TIME [epoch: 5.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050531506072129834		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.050531506072129834 | validation: 0.046443856986776694]
	TIME [epoch: 5.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05724124501732664		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.05724124501732664 | validation: 0.056368403706082926]
	TIME [epoch: 5.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0641534774087463		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.0641534774087463 | validation: 0.039769514709103795]
	TIME [epoch: 5.74 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04360165325685531		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.04360165325685531 | validation: 0.03781613149339006]
	TIME [epoch: 5.71 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046751528960185786		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.046751528960185786 | validation: 0.04613029736747288]
	TIME [epoch: 5.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05570930318945277		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.05570930318945277 | validation: 0.03823187782238268]
	TIME [epoch: 5.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05597985192653239		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.05597985192653239 | validation: 0.059657911504664186]
	TIME [epoch: 5.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049565372712617746		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.049565372712617746 | validation: 0.04060226492804185]
	TIME [epoch: 5.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04750167394171093		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.04750167394171093 | validation: 0.0439261550717372]
	TIME [epoch: 5.71 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0515298109161796		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.0515298109161796 | validation: 0.01973895504184783]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_857.pth
	Model improved!!!
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04597585384315912		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.04597585384315912 | validation: 0.0378296446899331]
	TIME [epoch: 5.71 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04511831436020913		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.04511831436020913 | validation: 0.0315407040797782]
	TIME [epoch: 5.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048679522993784904		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.048679522993784904 | validation: 0.037631235375219674]
	TIME [epoch: 5.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04433573711392025		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.04433573711392025 | validation: 0.03281679733377763]
	TIME [epoch: 5.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04438398743942386		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.04438398743942386 | validation: 0.034923652910123074]
	TIME [epoch: 5.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04724782360076417		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.04724782360076417 | validation: 0.04009456820394881]
	TIME [epoch: 5.74 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309838686940527		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.04309838686940527 | validation: 0.03409129040385839]
	TIME [epoch: 5.71 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043457447333081156		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.043457447333081156 | validation: 0.05450768210585615]
	TIME [epoch: 5.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059753503706417674		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.059753503706417674 | validation: 0.06786983946391072]
	TIME [epoch: 5.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06757797048552382		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.06757797048552382 | validation: 0.0489913871447015]
	TIME [epoch: 5.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057517325679687356		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.057517325679687356 | validation: 0.04833527660539068]
	TIME [epoch: 5.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06997532207627725		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.06997532207627725 | validation: 0.06867021768471529]
	TIME [epoch: 5.71 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385468896020584		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.08385468896020584 | validation: 0.04254765303708224]
	TIME [epoch: 5.73 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05676846525930487		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.05676846525930487 | validation: 0.051468792059812]
	TIME [epoch: 5.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0513936701256463		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.0513936701256463 | validation: 0.06355998214623108]
	TIME [epoch: 5.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06516985382494846		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.06516985382494846 | validation: 0.06070561132377094]
	TIME [epoch: 5.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06486191070900554		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.06486191070900554 | validation: 0.05333632283028894]
	TIME [epoch: 5.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04577198335740597		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.04577198335740597 | validation: 0.03955703192205511]
	TIME [epoch: 5.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038757457158169875		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.038757457158169875 | validation: 0.03645955389877389]
	TIME [epoch: 5.74 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050746165213500595		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.050746165213500595 | validation: 0.049271540617629145]
	TIME [epoch: 5.71 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051906142713976776		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.051906142713976776 | validation: 0.045608909799719315]
	TIME [epoch: 5.72 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046704084322161526		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.046704084322161526 | validation: 0.0317798461712355]
	TIME [epoch: 5.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04241062820855835		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.04241062820855835 | validation: 0.04321277411130062]
	TIME [epoch: 5.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426059284740792		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.0426059284740792 | validation: 0.051790870491778655]
	TIME [epoch: 5.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054369813325887605		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.054369813325887605 | validation: 0.04111025008778962]
	TIME [epoch: 5.71 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044229341629829604		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.044229341629829604 | validation: 0.03633222751126164]
	TIME [epoch: 5.73 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04269890378525347		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.04269890378525347 | validation: 0.027110906563708428]
	TIME [epoch: 5.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041924057038521964		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.041924057038521964 | validation: 0.042991445806862]
	TIME [epoch: 5.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047997807322234465		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.047997807322234465 | validation: 0.03165372238749735]
	TIME [epoch: 5.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487069096174703		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.0487069096174703 | validation: 0.06023500723205828]
	TIME [epoch: 5.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056718151902246064		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.056718151902246064 | validation: 0.044744867658660877]
	TIME [epoch: 5.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05706178634304225		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.05706178634304225 | validation: 0.02839020584636752]
	TIME [epoch: 5.74 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048726210858662466		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.048726210858662466 | validation: 0.059337921614311784]
	TIME [epoch: 5.71 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08195689909892363		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.08195689909892363 | validation: 0.05285398448049379]
	TIME [epoch: 5.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04716366482120607		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.04716366482120607 | validation: 0.03396365288748489]
	TIME [epoch: 5.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03666177438593007		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.03666177438593007 | validation: 0.03462451999809612]
	TIME [epoch: 5.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0428446776256587		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.0428446776256587 | validation: 0.041501841645648]
	TIME [epoch: 5.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041530361556612674		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.041530361556612674 | validation: 0.06952204339873426]
	TIME [epoch: 5.71 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08176060830726134		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.08176060830726134 | validation: 0.0646448798919263]
	TIME [epoch: 5.73 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055555787956868205		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.055555787956868205 | validation: 0.06330351294640085]
	TIME [epoch: 5.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05272689434087086		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.05272689434087086 | validation: 0.044438978893095823]
	TIME [epoch: 5.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045363493811171496		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.045363493811171496 | validation: 0.03979571803996291]
	TIME [epoch: 5.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04448847645323202		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.04448847645323202 | validation: 0.06099271380548775]
	TIME [epoch: 5.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388853990669892		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.06388853990669892 | validation: 0.05268146720233235]
	TIME [epoch: 5.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05545721327533622		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.05545721327533622 | validation: 0.047641844417011366]
	TIME [epoch: 5.74 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05160852271245539		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.05160852271245539 | validation: 0.043039958020159155]
	TIME [epoch: 5.71 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051934398299679906		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.051934398299679906 | validation: 0.03700504010932801]
	TIME [epoch: 5.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05791438393522323		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.05791438393522323 | validation: 0.05804048115948218]
	TIME [epoch: 5.7 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06044722495987072		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.06044722495987072 | validation: 0.04532816066448904]
	TIME [epoch: 5.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05887941622794914		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.05887941622794914 | validation: 0.05862441734632341]
	TIME [epoch: 5.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06539511213966646		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.06539511213966646 | validation: 0.029656841454089408]
	TIME [epoch: 5.71 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053558620802981564		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.053558620802981564 | validation: 0.043275553103970237]
	TIME [epoch: 5.73 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03898374569335562		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.03898374569335562 | validation: 0.02796902014469982]
	TIME [epoch: 5.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04233941326612142		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.04233941326612142 | validation: 0.04036413262600035]
	TIME [epoch: 5.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03997768100917558		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.03997768100917558 | validation: 0.04106350404215393]
	TIME [epoch: 5.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0700118917565885		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.0700118917565885 | validation: 0.07542792400698155]
	TIME [epoch: 5.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06643335328641466		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.06643335328641466 | validation: 0.04254101887334453]
	TIME [epoch: 5.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04397959961363584		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.04397959961363584 | validation: 0.03343538663087176]
	TIME [epoch: 5.73 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047101292123894155		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.047101292123894155 | validation: 0.05006942243960185]
	TIME [epoch: 5.71 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056825938077225066		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.056825938077225066 | validation: 0.03965794538107988]
	TIME [epoch: 5.7 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04822097625921222		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.04822097625921222 | validation: 0.030630840434859207]
	TIME [epoch: 5.71 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04471939307186071		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.04471939307186071 | validation: 0.029351380759398797]
	TIME [epoch: 5.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04231503946627052		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.04231503946627052 | validation: 0.03267415705097587]
	TIME [epoch: 5.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0435045304881738		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.0435045304881738 | validation: 0.033176146556005544]
	TIME [epoch: 5.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0480089627794683		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.0480089627794683 | validation: 0.04209943172445403]
	TIME [epoch: 5.74 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0502132439882005		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0502132439882005 | validation: 0.03456417784449128]
	TIME [epoch: 5.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04459088423581892		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.04459088423581892 | validation: 0.049744055239539606]
	TIME [epoch: 5.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055243652278903835		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.055243652278903835 | validation: 0.044200629483638156]
	TIME [epoch: 5.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05428290908325752		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.05428290908325752 | validation: 0.05838142062427364]
	TIME [epoch: 5.7 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053131889758029245		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.053131889758029245 | validation: 0.05707994873143365]
	TIME [epoch: 5.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05517220018219482		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.05517220018219482 | validation: 0.04531839286735975]
	TIME [epoch: 5.73 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05105441611013566		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.05105441611013566 | validation: 0.03541261642530916]
	TIME [epoch: 5.71 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05130756814216203		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.05130756814216203 | validation: 0.044109582636464015]
	TIME [epoch: 5.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0491823452088353		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.0491823452088353 | validation: 0.04388689673922679]
	TIME [epoch: 5.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04641073340715144		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.04641073340715144 | validation: 0.0383471469385053]
	TIME [epoch: 5.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04308692023043832		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.04308692023043832 | validation: 0.04359528330611423]
	TIME [epoch: 5.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07627601013205473		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.07627601013205473 | validation: 0.09268610781728313]
	TIME [epoch: 5.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07244591573545471		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.07244591573545471 | validation: 0.04693392066977989]
	TIME [epoch: 5.74 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04729596455303191		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.04729596455303191 | validation: 0.04597312645669099]
	TIME [epoch: 5.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045079572364033225		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.045079572364033225 | validation: 0.03355957620368145]
	TIME [epoch: 5.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041772015304954516		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.041772015304954516 | validation: 0.05683409769545577]
	TIME [epoch: 5.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04613077715904523		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.04613077715904523 | validation: 0.043941038516606634]
	TIME [epoch: 5.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05117319838372862		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.05117319838372862 | validation: 0.05906148622939578]
	TIME [epoch: 5.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05430150051973948		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.05430150051973948 | validation: 0.07717122570549888]
	TIME [epoch: 5.73 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06074375377174658		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.06074375377174658 | validation: 0.049271466093808974]
	TIME [epoch: 5.71 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04518079687719315		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.04518079687719315 | validation: 0.04230903014295761]
	TIME [epoch: 5.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043824309747417425		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.043824309747417425 | validation: 0.04099059639882392]
	TIME [epoch: 5.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04003870644001162		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.04003870644001162 | validation: 0.03390528844282272]
	TIME [epoch: 5.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041576320687079275		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.041576320687079275 | validation: 0.03734716485420926]
	TIME [epoch: 5.7 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04778215999730702		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.04778215999730702 | validation: 0.027702413828094005]
	TIME [epoch: 5.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262943676106802		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.04262943676106802 | validation: 0.035810375397033065]
	TIME [epoch: 5.74 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03602189939184504		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.03602189939184504 | validation: 0.03889455738589289]
	TIME [epoch: 5.7 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04798111844890988		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.04798111844890988 | validation: 0.0442009824472056]
	TIME [epoch: 5.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356189210616904		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.06356189210616904 | validation: 0.058046691439479985]
	TIME [epoch: 5.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05946397719105306		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.05946397719105306 | validation: 0.08505652428649121]
	TIME [epoch: 5.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08489487142337866		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.08489487142337866 | validation: 0.1011248344595587]
	TIME [epoch: 5.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127313423348492		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.08127313423348492 | validation: 0.05590371881946488]
	TIME [epoch: 5.73 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05481287502704331		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.05481287502704331 | validation: 0.07050701597798602]
	TIME [epoch: 5.71 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06415327235024801		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.06415327235024801 | validation: 0.05870638237128534]
	TIME [epoch: 5.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054925757352459637		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.054925757352459637 | validation: 0.057617105361453425]
	TIME [epoch: 5.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057042645610049125		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.057042645610049125 | validation: 0.048756982264356256]
	TIME [epoch: 5.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04830977704951934		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.04830977704951934 | validation: 0.05228688811259863]
	TIME [epoch: 5.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0616072822058454		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.0616072822058454 | validation: 0.04758832054307119]
	TIME [epoch: 5.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05797545112106337		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.05797545112106337 | validation: 0.04823749079013343]
	TIME [epoch: 5.74 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046888969563101665		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.046888969563101665 | validation: 0.04885778729104031]
	TIME [epoch: 5.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05341431034181352		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.05341431034181352 | validation: 0.05637053979143377]
	TIME [epoch: 5.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051208016053541874		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.051208016053541874 | validation: 0.03894616662284582]
	TIME [epoch: 5.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047578026948351795		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.047578026948351795 | validation: 0.04453424370244541]
	TIME [epoch: 5.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04099395424603984		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.04099395424603984 | validation: 0.04605023732439489]
	TIME [epoch: 5.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0555807474824911		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.0555807474824911 | validation: 0.04980034507169851]
	TIME [epoch: 5.71 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04696868730008037		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.04696868730008037 | validation: 0.03478792905218932]
	TIME [epoch: 5.73 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036655009658607365		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.036655009658607365 | validation: 0.03300268972749588]
	TIME [epoch: 5.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03852093519383362		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.03852093519383362 | validation: 0.04011245572874899]
	TIME [epoch: 5.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04665734100584261		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.04665734100584261 | validation: 0.06808923860557096]
	TIME [epoch: 5.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053873389131975764		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.053873389131975764 | validation: 0.04047488232226584]
	TIME [epoch: 5.7 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05236739018374446		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.05236739018374446 | validation: 0.05549766417920107]
	TIME [epoch: 5.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04738278072415649		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.04738278072415649 | validation: 0.03706131128470301]
	TIME [epoch: 5.74 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0527030001929578		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.0527030001929578 | validation: 0.057839494461743295]
	TIME [epoch: 5.71 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062155822538152036		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.062155822538152036 | validation: 0.06739871458411054]
	TIME [epoch: 5.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059438709976132736		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.059438709976132736 | validation: 0.04237087919027786]
	TIME [epoch: 5.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049147500235303		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.05049147500235303 | validation: 0.060201051406606435]
	TIME [epoch: 5.7 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06522373599609214		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.06522373599609214 | validation: 0.05758434319630986]
	TIME [epoch: 5.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05381470167975792		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.05381470167975792 | validation: 0.05036021215910371]
	TIME [epoch: 5.71 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04560609434786003		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.04560609434786003 | validation: 0.03718170553388092]
	TIME [epoch: 5.73 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04469885596712725		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.04469885596712725 | validation: 0.035515429374025194]
	TIME [epoch: 5.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049105838558617845		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.049105838558617845 | validation: 0.04569705602310494]
	TIME [epoch: 5.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052739092985094216		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.052739092985094216 | validation: 0.04331913183472192]
	TIME [epoch: 5.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048509281599003376		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.048509281599003376 | validation: 0.033838060318396534]
	TIME [epoch: 5.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04525922100700252		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.04525922100700252 | validation: 0.028028441041425625]
	TIME [epoch: 5.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0516053466429584		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.0516053466429584 | validation: 0.05338965289682834]
	TIME [epoch: 5.74 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0694903427580595		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.0694903427580595 | validation: 0.06228381426083349]
	TIME [epoch: 5.71 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057973556763167663		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.057973556763167663 | validation: 0.04779442382227128]
	TIME [epoch: 5.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047977150857073		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.047977150857073 | validation: 0.0563667817483654]
	TIME [epoch: 5.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059506370394113946		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.059506370394113946 | validation: 0.0416175375013567]
	TIME [epoch: 5.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047288465936583264		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.047288465936583264 | validation: 0.03794400131852133]
	TIME [epoch: 5.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04284317909812063		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.04284317909812063 | validation: 0.03972888837999096]
	TIME [epoch: 5.71 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04168407629026335		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.04168407629026335 | validation: 0.030346344024183663]
	TIME [epoch: 5.73 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049271920552422056		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.049271920552422056 | validation: 0.06514965738013156]
	TIME [epoch: 5.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093325807853489		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.06093325807853489 | validation: 0.0583490020385333]
	TIME [epoch: 5.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055883719650861134		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.055883719650861134 | validation: 0.029797251362197814]
	TIME [epoch: 5.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04045627848527293		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.04045627848527293 | validation: 0.03867287924186782]
	TIME [epoch: 5.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05001050214651516		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.05001050214651516 | validation: 0.037949116858960505]
	TIME [epoch: 5.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04502012967426395		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.04502012967426395 | validation: 0.034744329724145685]
	TIME [epoch: 5.73 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039916224346336945		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.039916224346336945 | validation: 0.03979864293461146]
	TIME [epoch: 5.71 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183596026318613		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.04183596026318613 | validation: 0.03135151834128146]
	TIME [epoch: 5.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0513823513990006		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0513823513990006 | validation: 0.049026438158990084]
	TIME [epoch: 5.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05166362163591305		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.05166362163591305 | validation: 0.04724262373212497]
	TIME [epoch: 5.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04748714837681503		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.04748714837681503 | validation: 0.040099803282911683]
	TIME [epoch: 5.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04460537106733628		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.04460537106733628 | validation: 0.044543587780413604]
	TIME [epoch: 5.71 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0459362960825476		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.0459362960825476 | validation: 0.03902582180034354]
	TIME [epoch: 5.73 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03876165524926582		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.03876165524926582 | validation: 0.0425849232842039]
	TIME [epoch: 5.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04377545452743101		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.04377545452743101 | validation: 0.04433769626600285]
	TIME [epoch: 5.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04327242025404902		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.04327242025404902 | validation: 0.04180909051845317]
	TIME [epoch: 5.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04636870965346951		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.04636870965346951 | validation: 0.04087179789401166]
	TIME [epoch: 5.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04226418650110606		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.04226418650110606 | validation: 0.043526693544366724]
	TIME [epoch: 5.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048347219741501565		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.048347219741501565 | validation: 0.05550489072447493]
	TIME [epoch: 5.74 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06249855080399419		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.06249855080399419 | validation: 0.06638693663417117]
	TIME [epoch: 5.71 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07254300879201762		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.07254300879201762 | validation: 0.06129860048958511]
	TIME [epoch: 5.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060475057628056994		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.060475057628056994 | validation: 0.0442130491064764]
	TIME [epoch: 5.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04872434183443087		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.04872434183443087 | validation: 0.045250720700586826]
	TIME [epoch: 5.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05175899180149793		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.05175899180149793 | validation: 0.034688850210435634]
	TIME [epoch: 5.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03859337606584735		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.03859337606584735 | validation: 0.031341947512090886]
	TIME [epoch: 5.71 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03840747367170749		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.03840747367170749 | validation: 0.04111980491397615]
	TIME [epoch: 5.73 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03655938306854644		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.03655938306854644 | validation: 0.039946913594874844]
	TIME [epoch: 5.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04217925942470287		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.04217925942470287 | validation: 0.044250415717173634]
	TIME [epoch: 5.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04208577836513047		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.04208577836513047 | validation: 0.022576943109221582]
	TIME [epoch: 5.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03326986538915939		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.03326986538915939 | validation: 0.03849701770030922]
	TIME [epoch: 5.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04153741551261991		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.04153741551261991 | validation: 0.044550369117219046]
	TIME [epoch: 5.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04689565137571068		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.04689565137571068 | validation: 0.033058659551054734]
	TIME [epoch: 5.73 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03805443314563382		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.03805443314563382 | validation: 0.03655790061160821]
	TIME [epoch: 5.71 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621180922557539		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.03621180922557539 | validation: 0.026751897698337933]
	TIME [epoch: 5.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04136349866484979		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.04136349866484979 | validation: 0.036363007640580536]
	TIME [epoch: 5.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03966657884986701		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.03966657884986701 | validation: 0.038210335974099494]
	TIME [epoch: 5.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03435943715688203		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.03435943715688203 | validation: 0.03717088583447231]
	TIME [epoch: 5.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04460781792244943		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.04460781792244943 | validation: 0.058476710247004515]
	TIME [epoch: 5.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05134025659005615		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.05134025659005615 | validation: 0.04896381047181096]
	TIME [epoch: 5.74 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04357386367652528		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.04357386367652528 | validation: 0.04336509294624058]
	TIME [epoch: 5.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04722537885765434		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.04722537885765434 | validation: 0.0398603104382063]
	TIME [epoch: 5.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044982817240495895		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.044982817240495895 | validation: 0.03365547516929213]
	TIME [epoch: 5.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04641631036780481		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.04641631036780481 | validation: 0.03902516879842965]
	TIME [epoch: 5.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524650427814663		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.04524650427814663 | validation: 0.039355507970623475]
	TIME [epoch: 5.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04394778461876728		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.04394778461876728 | validation: 0.03921964539309943]
	TIME [epoch: 5.73 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0387162822593357		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.0387162822593357 | validation: 0.03601256022741395]
	TIME [epoch: 5.71 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041666494354252834		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.041666494354252834 | validation: 0.04546596332360405]
	TIME [epoch: 5.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04390116942562592		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.04390116942562592 | validation: 0.0433689418339871]
	TIME [epoch: 5.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04529884754890714		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.04529884754890714 | validation: 0.04666199830038663]
	TIME [epoch: 5.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04582034785059059		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.04582034785059059 | validation: 0.053946669218204645]
	TIME [epoch: 5.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726115153810195		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.05726115153810195 | validation: 0.04908410983117824]
	TIME [epoch: 5.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04648815467803746		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.04648815467803746 | validation: 0.028430869137764346]
	TIME [epoch: 5.74 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04254561291326817		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.04254561291326817 | validation: 0.0394987969348853]
	TIME [epoch: 5.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041188214126468406		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.041188214126468406 | validation: 0.04266637075054289]
	TIME [epoch: 5.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04200824362016817		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.04200824362016817 | validation: 0.03552880703359785]
	TIME [epoch: 5.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03724594475010527		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.03724594475010527 | validation: 0.0499893960258386]
	TIME [epoch: 5.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04586747086691746		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.04586747086691746 | validation: 0.046267131548618265]
	TIME [epoch: 5.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04795994398609185		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.04795994398609185 | validation: 0.028675171611144454]
	TIME [epoch: 5.73 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04119775201240375		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.04119775201240375 | validation: 0.03964210147307452]
	TIME [epoch: 5.71 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03972776751179956		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.03972776751179956 | validation: 0.033382768276279576]
	TIME [epoch: 5.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03968596787179014		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.03968596787179014 | validation: 0.04468233626323196]
	TIME [epoch: 5.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04891261717878586		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.04891261717878586 | validation: 0.04405166757626018]
	TIME [epoch: 5.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05395177574212212		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.05395177574212212 | validation: 0.055862421271930515]
	TIME [epoch: 5.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06066771690228048		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.06066771690228048 | validation: 0.057859279039936616]
	TIME [epoch: 5.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06268692099835708		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.06268692099835708 | validation: 0.04916998432262698]
	TIME [epoch: 5.74 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057239313980630854		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.057239313980630854 | validation: 0.03543613686778304]
	TIME [epoch: 5.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286831212542106		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.05286831212542106 | validation: 0.04929136408911341]
	TIME [epoch: 5.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05242684803511123		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.05242684803511123 | validation: 0.03290124034158032]
	TIME [epoch: 5.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046569581946083155		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.046569581946083155 | validation: 0.0405016347217673]
	TIME [epoch: 5.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04286373639079293		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.04286373639079293 | validation: 0.02704459752637373]
	TIME [epoch: 5.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040838497262179134		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.040838497262179134 | validation: 0.030814832133243028]
	TIME [epoch: 5.73 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03936991654387294		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.03936991654387294 | validation: 0.056177804498034174]
	TIME [epoch: 5.71 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04666648470672781		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.04666648470672781 | validation: 0.047267245545090424]
	TIME [epoch: 5.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04329092068234897		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.04329092068234897 | validation: 0.037518577504614174]
	TIME [epoch: 5.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03800747309417234		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.03800747309417234 | validation: 0.03875956406610071]
	TIME [epoch: 5.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533440925972864		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.03533440925972864 | validation: 0.04244976164320537]
	TIME [epoch: 5.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03864415936367152		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.03864415936367152 | validation: 0.035549276110701016]
	TIME [epoch: 5.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03996753423644474		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.03996753423644474 | validation: 0.0390584746460869]
	TIME [epoch: 5.74 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043646824863482175		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.043646824863482175 | validation: 0.047986558934102155]
	TIME [epoch: 5.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04217789554964741		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.04217789554964741 | validation: 0.03280787650770852]
	TIME [epoch: 5.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03890907236828682		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.03890907236828682 | validation: 0.04332653906858036]
	TIME [epoch: 5.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039454578257032816		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.039454578257032816 | validation: 0.04523888088371404]
	TIME [epoch: 5.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04308871328005036		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.04308871328005036 | validation: 0.043879689766514816]
	TIME [epoch: 5.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04537752590190264		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.04537752590190264 | validation: 0.04860757843928241]
	TIME [epoch: 5.73 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040628467782615904		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.040628467782615904 | validation: 0.028748803608026174]
	TIME [epoch: 5.71 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0388043578819095		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.0388043578819095 | validation: 0.036881813474455856]
	TIME [epoch: 5.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041602915716743544		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.041602915716743544 | validation: 0.033654074029782884]
	TIME [epoch: 5.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0406548575160637		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.0406548575160637 | validation: 0.03810947651113097]
	TIME [epoch: 5.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183479661109573		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.04183479661109573 | validation: 0.03101195629423238]
	TIME [epoch: 5.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039942554078479506		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.039942554078479506 | validation: 0.032119636640686386]
	TIME [epoch: 5.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048699173405060116		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.048699173405060116 | validation: 0.04351248485355958]
	TIME [epoch: 5.73 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04817529639425034		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.04817529639425034 | validation: 0.031101870617627158]
	TIME [epoch: 5.71 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0390145286989913		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.0390145286989913 | validation: 0.029322380293773823]
	TIME [epoch: 5.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046013580291408694		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.046013580291408694 | validation: 0.05760218524496827]
	TIME [epoch: 5.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05950060484437256		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.05950060484437256 | validation: 0.05940728342350411]
	TIME [epoch: 5.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04891935932714725		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.04891935932714725 | validation: 0.03694421677382417]
	TIME [epoch: 5.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03855230856314725		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.03855230856314725 | validation: 0.044724937514386574]
	TIME [epoch: 5.71 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04863963145410631		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.04863963145410631 | validation: 0.038819035449675486]
	TIME [epoch: 5.72 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04132843112071928		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.04132843112071928 | validation: 0.03957058385946047]
	TIME [epoch: 5.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04132194697290167		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.04132194697290167 | validation: 0.03993734176223314]
	TIME [epoch: 5.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03727001838548993		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.03727001838548993 | validation: 0.0450408998766032]
	TIME [epoch: 5.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035593602732476505		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.035593602732476505 | validation: 0.042530703201909596]
	TIME [epoch: 5.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041504065463615625		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.041504065463615625 | validation: 0.054425929831187894]
	TIME [epoch: 5.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05190785863799205		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.05190785863799205 | validation: 0.059388093225921285]
	TIME [epoch: 5.73 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0507092106294091		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.0507092106294091 | validation: 0.05631070714558581]
	TIME [epoch: 5.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041596435327671516		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.041596435327671516 | validation: 0.03940448825807955]
	TIME [epoch: 5.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042145019602061795		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.042145019602061795 | validation: 0.043626022165346]
	TIME [epoch: 5.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860196230368812		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.03860196230368812 | validation: 0.03470995010527196]
	TIME [epoch: 5.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03960185264783417		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.03960185264783417 | validation: 0.0302656917944256]
	TIME [epoch: 5.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043125498748536585		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.043125498748536585 | validation: 0.03905542100317529]
	TIME [epoch: 5.71 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03973479176654463		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.03973479176654463 | validation: 0.03893094641690565]
	TIME [epoch: 5.72 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0429108784207107		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0429108784207107 | validation: 0.046006879271987336]
	TIME [epoch: 5.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04184291430445236		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.04184291430445236 | validation: 0.037472562543130396]
	TIME [epoch: 5.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04142507200246081		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.04142507200246081 | validation: 0.02859913342988669]
	TIME [epoch: 5.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04647898534289309		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.04647898534289309 | validation: 0.03901538801487763]
	TIME [epoch: 5.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03521595058284605		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.03521595058284605 | validation: 0.030919869582722637]
	TIME [epoch: 5.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035959991024901015		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.035959991024901015 | validation: 0.029019362188076936]
	TIME [epoch: 5.73 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04053197329910363		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.04053197329910363 | validation: 0.03769529142291874]
	TIME [epoch: 5.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042564316551263144		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.042564316551263144 | validation: 0.05654941934049651]
	TIME [epoch: 5.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05252797247901295		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.05252797247901295 | validation: 0.041928918125544196]
	TIME [epoch: 5.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044171604549975325		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.044171604549975325 | validation: 0.040774266327156694]
	TIME [epoch: 5.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04894364491061641		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.04894364491061641 | validation: 0.05044981693044175]
	TIME [epoch: 5.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04465307560051852		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.04465307560051852 | validation: 0.039018511831826835]
	TIME [epoch: 5.71 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043111405927762414		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.043111405927762414 | validation: 0.044034593707706564]
	TIME [epoch: 5.72 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05102373237824888		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.05102373237824888 | validation: 0.05528278013087135]
	TIME [epoch: 5.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05178659344921183		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.05178659344921183 | validation: 0.040149227566521034]
	TIME [epoch: 5.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04303614503583216		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.04303614503583216 | validation: 0.03627809371120904]
	TIME [epoch: 5.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04507226149501156		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.04507226149501156 | validation: 0.04382518056263072]
	TIME [epoch: 5.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04527494541058509		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.04527494541058509 | validation: 0.04082860110569249]
	TIME [epoch: 5.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04078525598892649		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.04078525598892649 | validation: 0.03490662437930706]
	TIME [epoch: 5.73 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03685479839127532		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.03685479839127532 | validation: 0.033388259302028746]
	TIME [epoch: 5.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04116696820477034		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.04116696820477034 | validation: 0.029530324024555556]
	TIME [epoch: 5.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04495094754513213		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.04495094754513213 | validation: 0.03767832676926965]
	TIME [epoch: 5.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0532163675881096		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0532163675881096 | validation: 0.037376407526624494]
	TIME [epoch: 5.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05051061085671013		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.05051061085671013 | validation: 0.03734200537173324]
	TIME [epoch: 5.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04324278689511905		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.04324278689511905 | validation: 0.030774703101453502]
	TIME [epoch: 5.71 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03475373939587458		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.03475373939587458 | validation: 0.036243113613109536]
	TIME [epoch: 5.73 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03372771301913258		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.03372771301913258 | validation: 0.034221463475269304]
	TIME [epoch: 5.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033917771284773725		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.033917771284773725 | validation: 0.027684147997838235]
	TIME [epoch: 5.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03593678843967116		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.03593678843967116 | validation: 0.03235750074875472]
	TIME [epoch: 5.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03631792508337233		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.03631792508337233 | validation: 0.038719655927996074]
	TIME [epoch: 5.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03863096182332468		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.03863096182332468 | validation: 0.03731443047053232]
	TIME [epoch: 5.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040573797419735144		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.040573797419735144 | validation: 0.03384570204966609]
	TIME [epoch: 5.73 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042536784723165744		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.042536784723165744 | validation: 0.03951053063515416]
	TIME [epoch: 5.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033897236085296746		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.033897236085296746 | validation: 0.041267357765121915]
	TIME [epoch: 5.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033170442004651995		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.033170442004651995 | validation: 0.03882436326732416]
	TIME [epoch: 5.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04075169500118154		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.04075169500118154 | validation: 0.029516109475072994]
	TIME [epoch: 5.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03985921404533089		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.03985921404533089 | validation: 0.032247552161834725]
	TIME [epoch: 5.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03887313906603173		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.03887313906603173 | validation: 0.02993703251780658]
	TIME [epoch: 5.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036579669860178625		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.036579669860178625 | validation: 0.03921859102913384]
	TIME [epoch: 5.73 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04555359115305015		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.04555359115305015 | validation: 0.053904399209186916]
	TIME [epoch: 5.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385077607098206		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.04385077607098206 | validation: 0.03691460029718682]
	TIME [epoch: 5.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451701739955546		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.03451701739955546 | validation: 0.02929188223653207]
	TIME [epoch: 5.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326886114998923		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.0326886114998923 | validation: 0.043719914798069234]
	TIME [epoch: 5.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473470870958409		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.03473470870958409 | validation: 0.035027563341075936]
	TIME [epoch: 5.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03701626658095451		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.03701626658095451 | validation: 0.039849116976260444]
	TIME [epoch: 5.73 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04014132264996512		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.04014132264996512 | validation: 0.039499586134204824]
	TIME [epoch: 5.71 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04204390444904454		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.04204390444904454 | validation: 0.04204080796819566]
	TIME [epoch: 5.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03776472906723107		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.03776472906723107 | validation: 0.03955740832396317]
	TIME [epoch: 5.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03749025169528747		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.03749025169528747 | validation: 0.023224401667436306]
	TIME [epoch: 5.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039251653080081515		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.039251653080081515 | validation: 0.02361373667573924]
	TIME [epoch: 5.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034014748942674956		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.034014748942674956 | validation: 0.03820798796047235]
	TIME [epoch: 5.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040448681624967744		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.040448681624967744 | validation: 0.03484811569496667]
	TIME [epoch: 5.74 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04825750092021725		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.04825750092021725 | validation: 0.05322916501648339]
	TIME [epoch: 5.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05081156775426221		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.05081156775426221 | validation: 0.04753407032006776]
	TIME [epoch: 5.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052348557721750795		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.052348557721750795 | validation: 0.04106103483042364]
	TIME [epoch: 5.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043762302141721755		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.043762302141721755 | validation: 0.04432974625378991]
	TIME [epoch: 5.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041836859100394114		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.041836859100394114 | validation: 0.05037355557805002]
	TIME [epoch: 5.7 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048094742728742514		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.048094742728742514 | validation: 0.04642055029215267]
	TIME [epoch: 5.73 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037298873465497234		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.037298873465497234 | validation: 0.04217598903880106]
	TIME [epoch: 5.71 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621601793514911		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.03621601793514911 | validation: 0.031594787048846544]
	TIME [epoch: 5.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03805485210612733		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.03805485210612733 | validation: 0.03240790527102736]
	TIME [epoch: 5.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04214590734575186		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.04214590734575186 | validation: 0.042336503004177024]
	TIME [epoch: 5.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04109058222304443		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.04109058222304443 | validation: 0.03884457262681226]
	TIME [epoch: 5.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041789406115724806		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.041789406115724806 | validation: 0.03260113467544846]
	TIME [epoch: 5.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03879800465445514		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.03879800465445514 | validation: 0.03981424011092256]
	TIME [epoch: 5.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03971380026665801		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.03971380026665801 | validation: 0.03864011193565258]
	TIME [epoch: 5.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03774513187421933		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.03774513187421933 | validation: 0.03446153932403935]
	TIME [epoch: 5.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03787920045341412		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.03787920045341412 | validation: 0.04397428646235943]
	TIME [epoch: 5.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036638872466052574		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.036638872466052574 | validation: 0.03560224460491816]
	TIME [epoch: 5.7 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035514346411391645		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.035514346411391645 | validation: 0.039001494126224084]
	TIME [epoch: 5.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032423943499686164		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.032423943499686164 | validation: 0.027283097202685576]
	TIME [epoch: 5.72 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03627685530154216		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.03627685530154216 | validation: 0.026507963033546158]
	TIME [epoch: 5.72 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0363496515049482		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.0363496515049482 | validation: 0.03438968557177752]
	TIME [epoch: 5.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04303576264366316		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.04303576264366316 | validation: 0.036122378867804505]
	TIME [epoch: 5.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03956063654322777		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.03956063654322777 | validation: 0.030964837524185235]
	TIME [epoch: 5.7 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03612618587397445		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.03612618587397445 | validation: 0.03419407379260047]
	TIME [epoch: 5.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03442130118082548		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.03442130118082548 | validation: 0.03217763348235274]
	TIME [epoch: 5.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038262560583549855		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.038262560583549855 | validation: 0.026936222717140516]
	TIME [epoch: 5.74 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037313498121847796		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.037313498121847796 | validation: 0.0375772124056261]
	TIME [epoch: 5.7 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037164969447692695		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.037164969447692695 | validation: 0.036739065917679836]
	TIME [epoch: 5.7 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04076843044769744		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.04076843044769744 | validation: 0.03179889450247958]
	TIME [epoch: 5.7 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03280666755701987		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.03280666755701987 | validation: 0.029837202488150426]
	TIME [epoch: 5.7 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0329495223198708		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.0329495223198708 | validation: 0.03455458705034399]
	TIME [epoch: 5.7 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030075765838921867		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.030075765838921867 | validation: 0.0320834325411746]
	TIME [epoch: 5.73 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040022979057095086		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.040022979057095086 | validation: 0.041686814660556876]
	TIME [epoch: 5.71 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04359048629632942		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.04359048629632942 | validation: 0.04363394234926337]
	TIME [epoch: 5.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04998982513065415		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.04998982513065415 | validation: 0.050825994438067346]
	TIME [epoch: 5.7 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044260992511671184		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.044260992511671184 | validation: 0.03718752950121851]
	TIME [epoch: 5.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03959573903582513		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.03959573903582513 | validation: 0.030906475197956175]
	TIME [epoch: 5.7 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03585312446619245		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.03585312446619245 | validation: 0.028251404728885713]
	TIME [epoch: 5.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037927909268256906		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.037927909268256906 | validation: 0.027239923413527024]
	TIME [epoch: 5.75 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036932208716129095		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.036932208716129095 | validation: 0.03066388020087996]
	TIME [epoch: 5.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037536457351569914		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.037536457351569914 | validation: 0.024426509343901222]
	TIME [epoch: 5.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03809446438482602		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.03809446438482602 | validation: 0.027321291871786602]
	TIME [epoch: 5.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03644015720069203		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.03644015720069203 | validation: 0.027953388934560286]
	TIME [epoch: 5.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04011335209389337		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.04011335209389337 | validation: 0.03319685652271643]
	TIME [epoch: 5.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0371574011725366		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.0371574011725366 | validation: 0.036867041520676956]
	TIME [epoch: 5.73 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045476553450769376		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.045476553450769376 | validation: 0.04364084096523258]
	TIME [epoch: 5.71 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04060036638810607		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.04060036638810607 | validation: 0.029024780746088937]
	TIME [epoch: 5.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037739629493931934		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.037739629493931934 | validation: 0.02921745597425451]
	TIME [epoch: 5.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038937969662563014		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.038937969662563014 | validation: 0.02400642986929589]
	TIME [epoch: 5.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03614636142516722		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.03614636142516722 | validation: 0.03592523280877301]
	TIME [epoch: 5.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595348162877421		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.03595348162877421 | validation: 0.03428457602404624]
	TIME [epoch: 5.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03709230546166857		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.03709230546166857 | validation: 0.028309138390017044]
	TIME [epoch: 5.74 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035042021340648426		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.035042021340648426 | validation: 0.02717835735476963]
	TIME [epoch: 5.7 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034670798199877756		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.034670798199877756 | validation: 0.041415284150146725]
	TIME [epoch: 5.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036892752209219996		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.036892752209219996 | validation: 0.02772694869560759]
	TIME [epoch: 5.7 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033427201078622494		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.033427201078622494 | validation: 0.03562394575683459]
	TIME [epoch: 5.7 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03618412924888826		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.03618412924888826 | validation: 0.033661997947478664]
	TIME [epoch: 5.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039460590108311794		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.039460590108311794 | validation: 0.03217005165996557]
	TIME [epoch: 5.71 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039854428205605724		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.039854428205605724 | validation: 0.03310879890422259]
	TIME [epoch: 5.73 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0390698183057735		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.0390698183057735 | validation: 0.028270095483701994]
	TIME [epoch: 5.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03339326561005643		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.03339326561005643 | validation: 0.02919140267318828]
	TIME [epoch: 5.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040460167818007285		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.040460167818007285 | validation: 0.03600147097604972]
	TIME [epoch: 5.7 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036487347289859		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.036487347289859 | validation: 0.031377365735767535]
	TIME [epoch: 5.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043045387758474385		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.043045387758474385 | validation: 0.0359822661228092]
	TIME [epoch: 5.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03981565570003719		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.03981565570003719 | validation: 0.023042793004918197]
	TIME [epoch: 5.74 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034576117554589246		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.034576117554589246 | validation: 0.03020177781726471]
	TIME [epoch: 5.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035945142118940954		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.035945142118940954 | validation: 0.024799256549370013]
	TIME [epoch: 5.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03186117916170438		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.03186117916170438 | validation: 0.03303172258686472]
	TIME [epoch: 5.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03356973555345586		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.03356973555345586 | validation: 0.02556713225514355]
	TIME [epoch: 5.7 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03325181401955082		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.03325181401955082 | validation: 0.029376258877247034]
	TIME [epoch: 5.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03539233605127167		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.03539233605127167 | validation: 0.03611399939296976]
	TIME [epoch: 5.71 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038093431155719955		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.038093431155719955 | validation: 0.029057562543296604]
	TIME [epoch: 5.73 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03769087929598947		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.03769087929598947 | validation: 0.036915386560630176]
	TIME [epoch: 5.7 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03458955645553423		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.03458955645553423 | validation: 0.03689346086562402]
	TIME [epoch: 5.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038058351940354736		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.038058351940354736 | validation: 0.031665345971610526]
	TIME [epoch: 5.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032710580866634864		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.032710580866634864 | validation: 0.03045439358635055]
	TIME [epoch: 5.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0372294832879864		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.0372294832879864 | validation: 0.03462704355456211]
	TIME [epoch: 5.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043419644348572164		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.043419644348572164 | validation: 0.04673108958499817]
	TIME [epoch: 5.73 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0413726887797371		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.0413726887797371 | validation: 0.030983651012934033]
	TIME [epoch: 5.71 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03295255578732351		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.03295255578732351 | validation: 0.03116543656996278]
	TIME [epoch: 5.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0316549380489711		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.0316549380489711 | validation: 0.028466716172192888]
	TIME [epoch: 5.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028629923856018258		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.028629923856018258 | validation: 0.027787201510432413]
	TIME [epoch: 5.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03164444751092617		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.03164444751092617 | validation: 0.027775285197860572]
	TIME [epoch: 5.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03437206472223912		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.03437206472223912 | validation: 0.027064533947202013]
	TIME [epoch: 5.71 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0332872629617849		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.0332872629617849 | validation: 0.023139008300294625]
	TIME [epoch: 5.73 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03397385362018835		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.03397385362018835 | validation: 0.032981832640528015]
	TIME [epoch: 5.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03848168158167514		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.03848168158167514 | validation: 0.032077604855184384]
	TIME [epoch: 5.7 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03691048882349494		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.03691048882349494 | validation: 0.035444379308596126]
	TIME [epoch: 5.7 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03549548598067212		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.03549548598067212 | validation: 0.02949361228477887]
	TIME [epoch: 5.7 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036553847669225474		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.036553847669225474 | validation: 0.038813871163011236]
	TIME [epoch: 5.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031968778884561386		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.031968778884561386 | validation: 0.029753963237740728]
	TIME [epoch: 5.74 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032481647836328974		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.032481647836328974 | validation: 0.024705832537185106]
	TIME [epoch: 5.71 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031587025139180956		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.031587025139180956 | validation: 0.025474713257343264]
	TIME [epoch: 5.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036507970672252886		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.036507970672252886 | validation: 0.03336018736002498]
	TIME [epoch: 5.7 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03046767221682587		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.03046767221682587 | validation: 0.0170193322367827]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_1252.pth
	Model improved!!!
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0321373880941344		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.0321373880941344 | validation: 0.0307520518976776]
	TIME [epoch: 5.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03343124870592189		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.03343124870592189 | validation: 0.0303014608278385]
	TIME [epoch: 5.71 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03271350453012341		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.03271350453012341 | validation: 0.022434458677996278]
	TIME [epoch: 5.72 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03364939193598636		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.03364939193598636 | validation: 0.028012897228213797]
	TIME [epoch: 5.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03395336943876857		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.03395336943876857 | validation: 0.02552254353972579]
	TIME [epoch: 5.7 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03487639017713282		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.03487639017713282 | validation: 0.020878977588105762]
	TIME [epoch: 5.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03536405052565793		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.03536405052565793 | validation: 0.027490603905923176]
	TIME [epoch: 5.7 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033286811823240885		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.033286811823240885 | validation: 0.026472601850463275]
	TIME [epoch: 5.7 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237380182605913		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.03237380182605913 | validation: 0.03449089843822072]
	TIME [epoch: 5.73 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03588804201079361		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.03588804201079361 | validation: 0.028075885347428237]
	TIME [epoch: 5.71 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03207414254018216		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.03207414254018216 | validation: 0.02600968373153248]
	TIME [epoch: 5.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03562357314562364		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.03562357314562364 | validation: 0.023208842848710828]
	TIME [epoch: 5.7 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370718804918292		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.03370718804918292 | validation: 0.028998736894554237]
	TIME [epoch: 5.7 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034303310837782555		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.034303310837782555 | validation: 0.03516561286551231]
	TIME [epoch: 5.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03587932510799984		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.03587932510799984 | validation: 0.037872966407304205]
	TIME [epoch: 5.71 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039464317514200535		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.039464317514200535 | validation: 0.04220548261043727]
	TIME [epoch: 5.72 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039423718387185405		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.039423718387185405 | validation: 0.037411921198333135]
	TIME [epoch: 5.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03727341579187144		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.03727341579187144 | validation: 0.03410285981086893]
	TIME [epoch: 5.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031261012005316044		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.031261012005316044 | validation: 0.04084453602587406]
	TIME [epoch: 5.7 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740302980405834		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.03740302980405834 | validation: 0.03548512889625819]
	TIME [epoch: 5.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040613649959072365		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.040613649959072365 | validation: 0.04411921357582088]
	TIME [epoch: 5.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03984489450449619		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.03984489450449619 | validation: 0.0371981871025384]
	TIME [epoch: 5.73 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03920449280146291		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.03920449280146291 | validation: 0.030136079241418038]
	TIME [epoch: 5.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0348997158425206		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.0348997158425206 | validation: 0.029972353629537568]
	TIME [epoch: 5.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03272712315793805		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.03272712315793805 | validation: 0.024726694643126566]
	TIME [epoch: 5.7 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03358472107635405		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.03358472107635405 | validation: 0.025240685917343075]
	TIME [epoch: 5.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03487254635802263		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.03487254635802263 | validation: 0.03001181773112201]
	TIME [epoch: 5.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0322923666914072		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.0322923666914072 | validation: 0.023727192577105916]
	TIME [epoch: 5.71 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034897136762930575		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.034897136762930575 | validation: 0.025108390169729013]
	TIME [epoch: 5.72 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03693006538508978		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.03693006538508978 | validation: 0.027160282091788304]
	TIME [epoch: 5.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03617844325076478		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.03617844325076478 | validation: 0.02872661532516177]
	TIME [epoch: 5.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03423551454982287		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.03423551454982287 | validation: 0.03708103756351324]
	TIME [epoch: 5.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030222377920531895		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.030222377920531895 | validation: 0.024569603274203464]
	TIME [epoch: 5.7 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03347057820099477		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.03347057820099477 | validation: 0.029711934451503642]
	TIME [epoch: 5.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03678602805999508		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.03678602805999508 | validation: 0.028760407431053157]
	TIME [epoch: 5.73 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03952285853768681		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.03952285853768681 | validation: 0.032004259315327896]
	TIME [epoch: 5.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03589180754293371		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.03589180754293371 | validation: 0.02606776162906477]
	TIME [epoch: 5.7 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03173241479191038		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.03173241479191038 | validation: 0.025406556108855064]
	TIME [epoch: 5.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127134363939613		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.03127134363939613 | validation: 0.031418937885116835]
	TIME [epoch: 5.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145949386728206		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.03145949386728206 | validation: 0.021820773747480544]
	TIME [epoch: 5.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034598181849230476		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.034598181849230476 | validation: 0.031011111724304184]
	TIME [epoch: 5.71 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03054158207663296		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.03054158207663296 | validation: 0.029749160875061787]
	TIME [epoch: 5.72 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03269098039474734		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.03269098039474734 | validation: 0.035034761336658636]
	TIME [epoch: 5.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03245559903769359		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.03245559903769359 | validation: 0.031760196669423195]
	TIME [epoch: 5.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03958788819078418		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.03958788819078418 | validation: 0.038960374995943556]
	TIME [epoch: 5.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040613918968391644		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.040613918968391644 | validation: 0.03829750051607034]
	TIME [epoch: 5.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044820510318811235		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.044820510318811235 | validation: 0.03941811575915907]
	TIME [epoch: 5.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04730385217581443		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.04730385217581443 | validation: 0.0415181004682483]
	TIME [epoch: 5.73 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04307465075474423		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.04307465075474423 | validation: 0.0388913746756054]
	TIME [epoch: 5.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03711971458168851		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.03711971458168851 | validation: 0.03231266290100642]
	TIME [epoch: 5.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03169231365733756		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.03169231365733756 | validation: 0.03037040687474164]
	TIME [epoch: 5.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154391438219752		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.03154391438219752 | validation: 0.03765925189748625]
	TIME [epoch: 5.7 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036948615110825124		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.036948615110825124 | validation: 0.027858116781616697]
	TIME [epoch: 5.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035885861590187605		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.035885861590187605 | validation: 0.03513335946290052]
	TIME [epoch: 5.71 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037326677490950574		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.037326677490950574 | validation: 0.03526322028026517]
	TIME [epoch: 5.72 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03559356981004659		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.03559356981004659 | validation: 0.027186701112861904]
	TIME [epoch: 5.7 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03775469353258051		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.03775469353258051 | validation: 0.02212726349473524]
	TIME [epoch: 5.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030501284723320213		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.030501284723320213 | validation: 0.02947207321724859]
	TIME [epoch: 5.7 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03319523434605959		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.03319523434605959 | validation: 0.02824729498401335]
	TIME [epoch: 5.7 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033730776696589436		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.033730776696589436 | validation: 0.032226710743636575]
	TIME [epoch: 5.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03297640756293086		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.03297640756293086 | validation: 0.03148548294760265]
	TIME [epoch: 5.72 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03440650730382374		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.03440650730382374 | validation: 0.028892909921592432]
	TIME [epoch: 5.71 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03534222255058683		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.03534222255058683 | validation: 0.03274562136419357]
	TIME [epoch: 5.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032615847612454875		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.032615847612454875 | validation: 0.02633490881981759]
	TIME [epoch: 5.7 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03711882416698456		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.03711882416698456 | validation: 0.03352336831931488]
	TIME [epoch: 5.7 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581667712853642		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.03581667712853642 | validation: 0.0412780145591109]
	TIME [epoch: 5.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03767134208156705		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.03767134208156705 | validation: 0.03621279275110361]
	TIME [epoch: 5.7 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032648953300102354		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.032648953300102354 | validation: 0.03427629852046632]
	TIME [epoch: 5.73 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036246442442937336		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.036246442442937336 | validation: 0.033704485596641576]
	TIME [epoch: 5.7 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032299998215085245		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.032299998215085245 | validation: 0.028915619401819158]
	TIME [epoch: 5.7 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03364529154670244		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.03364529154670244 | validation: 0.029879140050011133]
	TIME [epoch: 5.7 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03482861948585229		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.03482861948585229 | validation: 0.03072818453398101]
	TIME [epoch: 5.7 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0324332289173764		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.0324332289173764 | validation: 0.029329705695101942]
	TIME [epoch: 5.7 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03457147650659359		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.03457147650659359 | validation: 0.027922273876592178]
	TIME [epoch: 5.73 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237987943199881		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.03237987943199881 | validation: 0.02880260039102486]
	TIME [epoch: 5.71 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030668085759430544		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.030668085759430544 | validation: 0.028299279295156007]
	TIME [epoch: 5.7 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030540631620721494		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.030540631620721494 | validation: 0.022122061244810275]
	TIME [epoch: 5.7 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035148843253144234		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.035148843253144234 | validation: 0.026570988560289825]
	TIME [epoch: 5.7 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0329949543800538		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.0329949543800538 | validation: 0.023619507355959236]
	TIME [epoch: 5.7 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038973175134970894		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.038973175134970894 | validation: 0.024895201609448813]
	TIME [epoch: 5.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035888953958066516		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.035888953958066516 | validation: 0.03678551756973092]
	TIME [epoch: 5.74 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03844239298425945		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.03844239298425945 | validation: 0.030321595724598627]
	TIME [epoch: 5.7 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032317077253603964		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.032317077253603964 | validation: 0.02501405552266555]
	TIME [epoch: 5.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033545788417637536		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.033545788417637536 | validation: 0.0364073746682306]
	TIME [epoch: 5.7 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03386763668280866		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.03386763668280866 | validation: 0.027176544883091118]
	TIME [epoch: 5.7 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03516969416501016		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.03516969416501016 | validation: 0.020669681964931984]
	TIME [epoch: 5.7 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033763068862906115		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.033763068862906115 | validation: 0.02707461242419166]
	TIME [epoch: 5.72 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035462250633197426		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.035462250633197426 | validation: 0.02377754675323957]
	TIME [epoch: 5.71 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03303430157482711		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.03303430157482711 | validation: 0.03350439977734926]
	TIME [epoch: 5.7 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03413461461679317		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.03413461461679317 | validation: 0.03771326219826438]
	TIME [epoch: 5.7 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0313375885757985		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.0313375885757985 | validation: 0.032959765810375796]
	TIME [epoch: 5.7 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032892237734676824		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.032892237734676824 | validation: 0.028145197413454354]
	TIME [epoch: 5.7 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03442166047694753		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.03442166047694753 | validation: 0.020460372987415047]
	TIME [epoch: 5.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03224805568369215		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.03224805568369215 | validation: 0.03944109839252204]
	TIME [epoch: 5.74 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03276461673913164		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.03276461673913164 | validation: 0.032768561894061916]
	TIME [epoch: 5.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034494234459763344		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.034494234459763344 | validation: 0.030421610374995817]
	TIME [epoch: 5.7 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028702570174678945		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.028702570174678945 | validation: 0.03389374238169775]
	TIME [epoch: 5.7 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030258832927003567		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.030258832927003567 | validation: 0.02872165582369606]
	TIME [epoch: 5.7 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033641006989128086		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.033641006989128086 | validation: 0.027423592885182008]
	TIME [epoch: 5.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03361560610777125		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.03361560610777125 | validation: 0.025071903650034085]
	TIME [epoch: 5.72 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02938215410716993		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.02938215410716993 | validation: 0.027480144887411947]
	TIME [epoch: 5.71 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0297173332804006		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.0297173332804006 | validation: 0.02925709224094061]
	TIME [epoch: 5.7 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0347005592439065		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.0347005592439065 | validation: 0.02300754161435351]
	TIME [epoch: 5.7 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030517520503929987		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.030517520503929987 | validation: 0.028315033446270472]
	TIME [epoch: 5.7 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028652904527507527		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.028652904527507527 | validation: 0.028974354465804583]
	TIME [epoch: 5.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035729681044683055		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.035729681044683055 | validation: 0.03749207525241873]
	TIME [epoch: 5.7 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03871487547259027		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.03871487547259027 | validation: 0.031247670768102944]
	TIME [epoch: 5.74 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03590405159278917		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.03590405159278917 | validation: 0.03505506764023415]
	TIME [epoch: 5.7 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357329097939053		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.0357329097939053 | validation: 0.028416773396779473]
	TIME [epoch: 5.7 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03664062979789421		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.03664062979789421 | validation: 0.023170515737052658]
	TIME [epoch: 5.7 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140692192916796		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.03140692192916796 | validation: 0.024112739788032658]
	TIME [epoch: 5.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0317424392309259		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.0317424392309259 | validation: 0.027058533970569478]
	TIME [epoch: 5.7 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03262555346908084		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.03262555346908084 | validation: 0.030982706478012965]
	TIME [epoch: 5.72 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03745332937308072		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.03745332937308072 | validation: 0.0405952975330697]
	TIME [epoch: 5.71 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04014699800573078		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.04014699800573078 | validation: 0.032382183997943965]
	TIME [epoch: 5.7 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032052317227775906		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.032052317227775906 | validation: 0.030236714982944064]
	TIME [epoch: 5.7 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031187913847025506		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.031187913847025506 | validation: 0.03134498587965889]
	TIME [epoch: 5.7 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033206277142548375		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.033206277142548375 | validation: 0.02803677910493023]
	TIME [epoch: 5.7 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029076387054415852		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.029076387054415852 | validation: 0.02123411448234313]
	TIME [epoch: 5.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03122975080662053		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.03122975080662053 | validation: 0.027496032474551846]
	TIME [epoch: 5.74 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03549473676602627		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.03549473676602627 | validation: 0.021399720445692504]
	TIME [epoch: 5.7 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03190122511060361		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.03190122511060361 | validation: 0.0393123089076546]
	TIME [epoch: 5.7 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03267530855638002		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.03267530855638002 | validation: 0.031424438473727515]
	TIME [epoch: 5.7 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032928617687091655		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.032928617687091655 | validation: 0.03033449929727735]
	TIME [epoch: 5.7 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429444935814732		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.03429444935814732 | validation: 0.04407800281035666]
	TIME [epoch: 5.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03726640171748491		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.03726640171748491 | validation: 0.030414699838014213]
	TIME [epoch: 5.73 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031779999870325		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.031779999870325 | validation: 0.031185371626999726]
	TIME [epoch: 5.71 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027990073232306532		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.027990073232306532 | validation: 0.03326625933372821]
	TIME [epoch: 5.7 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038067146092695285		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.038067146092695285 | validation: 0.029791538682935242]
	TIME [epoch: 5.7 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370023379011782		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.03370023379011782 | validation: 0.02836251639770282]
	TIME [epoch: 5.7 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03556263737333732		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.03556263737333732 | validation: 0.039146602938291995]
	TIME [epoch: 5.7 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037704116256369435		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.037704116256369435 | validation: 0.03240690616914514]
	TIME [epoch: 5.7 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029613359443816028		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.029613359443816028 | validation: 0.018397148020956492]
	TIME [epoch: 5.74 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03238336920368806		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.03238336920368806 | validation: 0.020766689253062985]
	TIME [epoch: 5.7 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030974341024692056		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.030974341024692056 | validation: 0.022172233418911846]
	TIME [epoch: 5.7 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032774451874516684		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.032774451874516684 | validation: 0.023437266844161125]
	TIME [epoch: 5.7 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033906335725758074		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.033906335725758074 | validation: 0.025115933463190025]
	TIME [epoch: 5.7 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03279830368654091		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.03279830368654091 | validation: 0.023633629655464918]
	TIME [epoch: 5.7 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0300826262198862		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.0300826262198862 | validation: 0.03510022319811397]
	TIME [epoch: 5.71 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03553263097382299		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.03553263097382299 | validation: 0.030126739953262694]
	TIME [epoch: 5.73 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031324910300050704		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.031324910300050704 | validation: 0.03384584116619867]
	TIME [epoch: 5.7 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034203814817015676		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.034203814817015676 | validation: 0.029067370722233754]
	TIME [epoch: 5.7 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030850792870666034		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.030850792870666034 | validation: 0.02811183062963107]
	TIME [epoch: 5.7 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035128992066844555		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.035128992066844555 | validation: 0.030631868860593096]
	TIME [epoch: 5.7 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035558341360752		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.035558341360752 | validation: 0.0302305407436626]
	TIME [epoch: 5.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036545855496868875		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.036545855496868875 | validation: 0.029034911322386774]
	TIME [epoch: 5.74 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03053041373640791		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.03053041373640791 | validation: 0.023453929964485476]
	TIME [epoch: 5.71 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035212015143614224		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.035212015143614224 | validation: 0.033836373046708716]
	TIME [epoch: 5.7 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528769111348789		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.03528769111348789 | validation: 0.02148031554422371]
	TIME [epoch: 5.7 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03149904658391834		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.03149904658391834 | validation: 0.02108925149033878]
	TIME [epoch: 5.7 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03264631175399847		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.03264631175399847 | validation: 0.02649211173526295]
	TIME [epoch: 5.7 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03608998871057177		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.03608998871057177 | validation: 0.023142241863184188]
	TIME [epoch: 5.71 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03172280711911224		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.03172280711911224 | validation: 0.019928978887405187]
	TIME [epoch: 5.72 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034326145657095526		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.034326145657095526 | validation: 0.024664751068437775]
	TIME [epoch: 5.7 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029709543914095922		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.029709543914095922 | validation: 0.02742601907124931]
	TIME [epoch: 5.7 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028982718502422757		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.028982718502422757 | validation: 0.0253910296892305]
	TIME [epoch: 5.7 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033507406109909335		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.033507406109909335 | validation: 0.024283565170244107]
	TIME [epoch: 5.7 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028793410777979693		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.028793410777979693 | validation: 0.027470610109376816]
	TIME [epoch: 5.7 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03960748219344981		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.03960748219344981 | validation: 0.032617291546671374]
	TIME [epoch: 5.73 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035232450309491826		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.035232450309491826 | validation: 0.026255718766277036]
	TIME [epoch: 5.71 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282350791137281		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.03282350791137281 | validation: 0.029567598169118338]
	TIME [epoch: 5.7 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030807408427668666		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.030807408427668666 | validation: 0.024575958336171617]
	TIME [epoch: 5.7 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02994629570952909		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.02994629570952909 | validation: 0.021259031613822747]
	TIME [epoch: 5.7 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034280605477307755		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.034280605477307755 | validation: 0.025358296808138576]
	TIME [epoch: 5.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033557794195868726		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.033557794195868726 | validation: 0.02293779152385353]
	TIME [epoch: 5.71 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0351693064372051		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.0351693064372051 | validation: 0.028204101405454908]
	TIME [epoch: 5.73 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034216064514943224		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.034216064514943224 | validation: 0.03171260570233594]
	TIME [epoch: 5.7 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166308378967428		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.03166308378967428 | validation: 0.028371308011645224]
	TIME [epoch: 5.7 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033830274189514196		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.033830274189514196 | validation: 0.03592589721999772]
	TIME [epoch: 5.7 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0325076777150345		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.0325076777150345 | validation: 0.02771771361479153]
	TIME [epoch: 5.7 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030808158395983734		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.030808158395983734 | validation: 0.024693963468801906]
	TIME [epoch: 5.7 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029553964990897012		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.029553964990897012 | validation: 0.022403195591396346]
	TIME [epoch: 5.73 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02930622216787994		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.02930622216787994 | validation: 0.02354627241007493]
	TIME [epoch: 5.7 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028921988089767106		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.028921988089767106 | validation: 0.032386583606499666]
	TIME [epoch: 5.7 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030563242680005927		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.030563242680005927 | validation: 0.023675381668207606]
	TIME [epoch: 5.7 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03100495514510789		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.03100495514510789 | validation: 0.0342920995430242]
	TIME [epoch: 5.7 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03401391145869634		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.03401391145869634 | validation: 0.029624314651424212]
	TIME [epoch: 5.7 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03049192790071561		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.03049192790071561 | validation: 0.029642197712326124]
	TIME [epoch: 5.71 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03458566466904115		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.03458566466904115 | validation: 0.03140030279980035]
	TIME [epoch: 5.72 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037487595608118235		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.037487595608118235 | validation: 0.041153114660737025]
	TIME [epoch: 5.7 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035012527980631		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.035012527980631 | validation: 0.026829697349018636]
	TIME [epoch: 5.7 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036188017874072914		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.036188017874072914 | validation: 0.032191210538634205]
	TIME [epoch: 5.7 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035000576552558726		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.035000576552558726 | validation: 0.025273007452887686]
	TIME [epoch: 5.7 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02774990703987224		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.02774990703987224 | validation: 0.03318877538389184]
	TIME [epoch: 5.7 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028445779774278403		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.028445779774278403 | validation: 0.02575891619294753]
	TIME [epoch: 5.73 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03186869998696924		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.03186869998696924 | validation: 0.02880770193139503]
	TIME [epoch: 5.7 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030725279310041063		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.030725279310041063 | validation: 0.024813088231369768]
	TIME [epoch: 5.7 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037153822385384706		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.037153822385384706 | validation: 0.02974235850988263]
	TIME [epoch: 5.7 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03818368737702413		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03818368737702413 | validation: 0.0196130417461896]
	TIME [epoch: 5.7 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034253375797417975		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.034253375797417975 | validation: 0.03137960516611637]
	TIME [epoch: 5.7 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03156630317422323		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.03156630317422323 | validation: 0.03113708867526895]
	TIME [epoch: 5.71 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03399890867180843		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.03399890867180843 | validation: 0.021437707076134967]
	TIME [epoch: 5.72 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031657129437845336		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.031657129437845336 | validation: 0.02153259061104116]
	TIME [epoch: 5.7 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03427283531201077		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.03427283531201077 | validation: 0.03411073682415508]
	TIME [epoch: 5.7 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035237139737549904		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.035237139737549904 | validation: 0.02779213559093399]
	TIME [epoch: 5.7 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329740875563392		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.03329740875563392 | validation: 0.025322265331508307]
	TIME [epoch: 5.7 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033689021801118976		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.033689021801118976 | validation: 0.02813156807050511]
	TIME [epoch: 5.7 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036457541720833965		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.036457541720833965 | validation: 0.03222055108176844]
	TIME [epoch: 5.73 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578593670783678		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.03578593670783678 | validation: 0.02799869357497613]
	TIME [epoch: 5.7 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032518494368284294		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.032518494368284294 | validation: 0.031672516893950835]
	TIME [epoch: 5.7 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0360325230454807		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.0360325230454807 | validation: 0.026336613303634647]
	TIME [epoch: 5.7 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02983664797533929		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.02983664797533929 | validation: 0.021866958128851297]
	TIME [epoch: 5.7 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029751096706970487		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.029751096706970487 | validation: 0.024213119059892083]
	TIME [epoch: 5.7 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03342530592559261		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.03342530592559261 | validation: 0.01889605542865882]
	TIME [epoch: 5.71 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03293222528016505		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.03293222528016505 | validation: 0.03495968639128452]
	TIME [epoch: 5.73 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030438057586255306		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.030438057586255306 | validation: 0.03742686534478269]
	TIME [epoch: 5.7 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03518084577144517		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.03518084577144517 | validation: 0.036425432350068475]
	TIME [epoch: 5.7 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034384467506277966		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.034384467506277966 | validation: 0.02391350199977679]
	TIME [epoch: 5.7 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030525997897910925		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.030525997897910925 | validation: 0.02888298446041156]
	TIME [epoch: 5.7 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03498748583280009		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.03498748583280009 | validation: 0.02880220925235755]
	TIME [epoch: 5.7 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033121827039215596		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.033121827039215596 | validation: 0.03670007060768425]
	TIME [epoch: 5.73 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03009318943062163		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.03009318943062163 | validation: 0.021837781687744244]
	TIME [epoch: 5.7 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028809935613113465		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.028809935613113465 | validation: 0.02953329274340139]
	TIME [epoch: 5.7 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02853622531507965		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.02853622531507965 | validation: 0.02770692401271429]
	TIME [epoch: 5.7 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032539498569666044		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.032539498569666044 | validation: 0.023335348865844385]
	TIME [epoch: 5.7 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03227075859460806		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.03227075859460806 | validation: 0.026418750113280005]
	TIME [epoch: 5.7 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028672302268345787		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.028672302268345787 | validation: 0.02546250598006115]
	TIME [epoch: 5.71 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029948936735825826		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.029948936735825826 | validation: 0.028712279578967423]
	TIME [epoch: 5.72 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03240738622364914		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.03240738622364914 | validation: 0.03127905641595707]
	TIME [epoch: 5.7 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031137688389515153		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.031137688389515153 | validation: 0.02203527151622255]
	TIME [epoch: 5.7 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204021582997758		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.03204021582997758 | validation: 0.03252336198032405]
	TIME [epoch: 5.7 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035179260688942636		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.035179260688942636 | validation: 0.023390626285271502]
	TIME [epoch: 5.7 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03103228178192861		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.03103228178192861 | validation: 0.028242541183832688]
	TIME [epoch: 5.7 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03555202739893464		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.03555202739893464 | validation: 0.03380263264732895]
	TIME [epoch: 5.73 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03066510874068878		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.03066510874068878 | validation: 0.02369363488598537]
	TIME [epoch: 5.71 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03275240892652878		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.03275240892652878 | validation: 0.037650570641744714]
	TIME [epoch: 5.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033718742922154224		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.033718742922154224 | validation: 0.028972303470250198]
	TIME [epoch: 5.7 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030297635159023492		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.030297635159023492 | validation: 0.021273512418456236]
	TIME [epoch: 5.7 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034075712072971824		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.034075712072971824 | validation: 0.028406327349850678]
	TIME [epoch: 5.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030801908862801687		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.030801908862801687 | validation: 0.02844897168362759]
	TIME [epoch: 5.7 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030061610283324353		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.030061610283324353 | validation: 0.02691122596002774]
	TIME [epoch: 5.73 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03228791392256061		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.03228791392256061 | validation: 0.027459594920140856]
	TIME [epoch: 5.7 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02918120357790694		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.02918120357790694 | validation: 0.0267678904936505]
	TIME [epoch: 5.7 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03359836696164111		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.03359836696164111 | validation: 0.026989038549280944]
	TIME [epoch: 5.7 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289459453436022		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.03289459453436022 | validation: 0.026060676960006912]
	TIME [epoch: 5.7 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032241056377938275		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.032241056377938275 | validation: 0.029220731428722307]
	TIME [epoch: 5.7 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030977326626991222		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.030977326626991222 | validation: 0.026857308681937937]
	TIME [epoch: 5.72 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03431557195424787		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.03431557195424787 | validation: 0.032534138890944274]
	TIME [epoch: 5.71 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030404491701813433		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.030404491701813433 | validation: 0.02633656113172489]
	TIME [epoch: 5.7 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029552465029401218		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.029552465029401218 | validation: 0.022937323356884153]
	TIME [epoch: 5.7 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031655804178250264		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.031655804178250264 | validation: 0.012698599000513205]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r4_20240309_135637/states/model_tr_study2_1493.pth
	Model improved!!!
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032235468057482945		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.032235468057482945 | validation: 0.020063906032178794]
	TIME [epoch: 5.7 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03309253258173744		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.03309253258173744 | validation: 0.03329904878430055]
	TIME [epoch: 5.71 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145618021984596		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.03145618021984596 | validation: 0.021943290653076163]
	TIME [epoch: 5.72 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03559639699124574		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.03559639699124574 | validation: 0.02459151266743457]
	TIME [epoch: 5.7 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02937211038758011		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.02937211038758011 | validation: 0.028887720934815137]
	TIME [epoch: 5.69 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02791920310692897		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.02791920310692897 | validation: 0.028952814998540938]
	TIME [epoch: 5.7 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314726845308267		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.0314726845308267 | validation: 0.021257347940052657]
	TIME [epoch: 5.7 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032627974644432775		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.032627974644432775 | validation: 0.024007021030234537]
	TIME [epoch: 5.69 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0327092006768059		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.0327092006768059 | validation: 0.02433114906329438]
	TIME [epoch: 5.73 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034139027070919634		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.034139027070919634 | validation: 0.025130058773077772]
	TIME [epoch: 5.7 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030071368729132356		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.030071368729132356 | validation: 0.026714004659921475]
	TIME [epoch: 5.7 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03292659786740319		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.03292659786740319 | validation: 0.03165696778022389]
	TIME [epoch: 5.7 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031151846884106604		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.031151846884106604 | validation: 0.023148091368536718]
	TIME [epoch: 5.7 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03160601580095987		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.03160601580095987 | validation: 0.027064200206323143]
	TIME [epoch: 5.7 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296736300925643		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.03296736300925643 | validation: 0.023878806329501647]
	TIME [epoch: 5.71 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028091318475746394		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.028091318475746394 | validation: 0.03405446740313532]
	TIME [epoch: 5.72 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029344288818223083		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.029344288818223083 | validation: 0.022487815178043366]
	TIME [epoch: 5.7 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03350825788461854		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.03350825788461854 | validation: 0.016656535615016947]
	TIME [epoch: 5.7 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0334792806979654		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.0334792806979654 | validation: 0.020705037390143365]
	TIME [epoch: 5.7 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0324931207976484		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.0324931207976484 | validation: 0.0292373727430165]
	TIME [epoch: 5.7 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028212649994157818		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.028212649994157818 | validation: 0.02594446582368772]
	TIME [epoch: 5.7 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033675015543751186		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.033675015543751186 | validation: 0.026266841288042173]
	TIME [epoch: 5.72 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030144607540891613		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.030144607540891613 | validation: 0.02188788047331533]
	TIME [epoch: 5.71 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219594345875927		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.03219594345875927 | validation: 0.029799762670003806]
	TIME [epoch: 5.7 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03288274535114863		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.03288274535114863 | validation: 0.022413466911851615]
	TIME [epoch: 5.7 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03216881280829948		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.03216881280829948 | validation: 0.023352107889011178]
	TIME [epoch: 5.7 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031797860554274235		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.031797860554274235 | validation: 0.028316470567676354]
	TIME [epoch: 5.7 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03300206051219236		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.03300206051219236 | validation: 0.030454179532460365]
	TIME [epoch: 5.7 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03516555701770488		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.03516555701770488 | validation: 0.02693333581492337]
	TIME [epoch: 5.73 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031627600946281156		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.031627600946281156 | validation: 0.01895320191055102]
	TIME [epoch: 5.7 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0318653393490737		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.0318653393490737 | validation: 0.02978593808487977]
	TIME [epoch: 5.7 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035032562841060606		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.035032562841060606 | validation: 0.035527070954467665]
	TIME [epoch: 5.7 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033308858632639174		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.033308858632639174 | validation: 0.03342047752913041]
	TIME [epoch: 5.7 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031872203458406446		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.031872203458406446 | validation: 0.020788782507501897]
	TIME [epoch: 5.7 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030380553432211653		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.030380553432211653 | validation: 0.028598159096634972]
	TIME [epoch: 5.72 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03179020545089349		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.03179020545089349 | validation: 0.02188289238697692]
	TIME [epoch: 5.71 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0364836176554795		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.0364836176554795 | validation: 0.026578192020571247]
	TIME [epoch: 5.7 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03506363336314919		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.03506363336314919 | validation: 0.019723246045849116]
	TIME [epoch: 5.7 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033041627433360456		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.033041627433360456 | validation: 0.027918913686111622]
	TIME [epoch: 5.7 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03474979570064796		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.03474979570064796 | validation: 0.03457781495494821]
	TIME [epoch: 5.7 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039020274681569794		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.039020274681569794 | validation: 0.020442724378626865]
	TIME [epoch: 5.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031784212832121676		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.031784212832121676 | validation: 0.0332270958812103]
	TIME [epoch: 5.73 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031991049955744394		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.031991049955744394 | validation: 0.03295848533713731]
	TIME [epoch: 5.7 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034443356339089445		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.034443356339089445 | validation: 0.03006252550960602]
	TIME [epoch: 5.7 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036113512015123826		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.036113512015123826 | validation: 0.03229543874035299]
	TIME [epoch: 5.7 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033755345544506696		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.033755345544506696 | validation: 0.025150215441688672]
	TIME [epoch: 5.7 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03275081366735743		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.03275081366735743 | validation: 0.027132474945139064]
	TIME [epoch: 5.7 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036950882066926816		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.036950882066926816 | validation: 0.035012484001325735]
	TIME [epoch: 5.72 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03466318803974731		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.03466318803974731 | validation: 0.02079024641454918]
	TIME [epoch: 5.71 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0345088644335805		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.0345088644335805 | validation: 0.02292961156715632]
	TIME [epoch: 5.7 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03423629590923882		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.03423629590923882 | validation: 0.036618544970222114]
	TIME [epoch: 5.7 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035612614304695395		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.035612614304695395 | validation: 0.032356970191828566]
	TIME [epoch: 5.7 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438277405359716		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.03438277405359716 | validation: 0.020121273717586617]
	TIME [epoch: 5.7 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035850523207433045		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.035850523207433045 | validation: 0.02243038502753081]
	TIME [epoch: 5.7 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330525117052366		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.0330525117052366 | validation: 0.031221698837384102]
	TIME [epoch: 5.73 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03620470744446853		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.03620470744446853 | validation: 0.039906233761642505]
	TIME [epoch: 5.7 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03585889331821831		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.03585889331821831 | validation: 0.03970341139827132]
	TIME [epoch: 5.7 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03083570766939811		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.03083570766939811 | validation: 0.030268913242705]
	TIME [epoch: 5.7 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02864066129085956		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.02864066129085956 | validation: 0.029094941967250626]
	TIME [epoch: 5.7 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03018366059173297		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.03018366059173297 | validation: 0.027909157076808445]
	TIME [epoch: 5.7 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032323848370905184		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.032323848370905184 | validation: 0.025431049988516363]
	TIME [epoch: 5.72 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034334244169404525		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.034334244169404525 | validation: 0.02974897356246811]
	TIME [epoch: 5.71 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03609607099811686		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.03609607099811686 | validation: 0.029129801895251172]
	TIME [epoch: 5.7 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0306459363944846		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.0306459363944846 | validation: 0.021171812299489702]
	TIME [epoch: 5.7 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031525067747053846		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.031525067747053846 | validation: 0.02790237582860948]
	TIME [epoch: 5.7 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031686324833776855		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.031686324833776855 | validation: 0.03352691563377463]
	TIME [epoch: 5.7 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03243989938756865		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.03243989938756865 | validation: 0.027635178921003024]
	TIME [epoch: 5.7 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032609010652536484		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.032609010652536484 | validation: 0.02233133171256954]
	TIME [epoch: 5.73 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03254432479580409		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.03254432479580409 | validation: 0.03334888288988537]
	TIME [epoch: 5.7 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030292809586078974		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.030292809586078974 | validation: 0.0288208485830237]
	TIME [epoch: 5.7 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032367760934915515		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.032367760934915515 | validation: 0.027241203994126658]
	TIME [epoch: 5.7 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03308435360373874		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.03308435360373874 | validation: 0.025289691554529564]
	TIME [epoch: 5.7 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033988814584840335		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.033988814584840335 | validation: 0.028877047976715673]
	TIME [epoch: 5.7 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03436839194000606		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.03436839194000606 | validation: 0.022463409244670593]
	TIME [epoch: 5.72 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03220448178579779		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.03220448178579779 | validation: 0.024946280409294013]
	TIME [epoch: 5.71 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028804386742412078		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.028804386742412078 | validation: 0.026275447307891008]
	TIME [epoch: 5.7 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03111292282311407		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.03111292282311407 | validation: 0.030735921303424795]
	TIME [epoch: 5.7 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03412030753079707		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.03412030753079707 | validation: 0.034209155725235516]
	TIME [epoch: 5.7 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318770981084876		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.03318770981084876 | validation: 0.032544062743127544]
	TIME [epoch: 5.7 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034862334561339914		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.034862334561339914 | validation: 0.032833966150463086]
	TIME [epoch: 5.7 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031717053381263474		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.031717053381263474 | validation: 0.020027650372992145]
	TIME [epoch: 5.73 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031444218914471744		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.031444218914471744 | validation: 0.026452253968486012]
	TIME [epoch: 5.7 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029600790081412698		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.029600790081412698 | validation: 0.028850558873993848]
	TIME [epoch: 5.7 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036720720230976736		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.036720720230976736 | validation: 0.02639772871953362]
	TIME [epoch: 5.7 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030841269874168725		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.030841269874168725 | validation: 0.023426248121481592]
	TIME [epoch: 5.7 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029970370933782735		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.029970370933782735 | validation: 0.02328938198233806]
	TIME [epoch: 5.7 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035316990284767945		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.035316990284767945 | validation: 0.027161039505381797]
	TIME [epoch: 5.72 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030827576576416774		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.030827576576416774 | validation: 0.024035151387626776]
	TIME [epoch: 5.71 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031252094856761975		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.031252094856761975 | validation: 0.027248072984349118]
	TIME [epoch: 5.7 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032882028240961564		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.032882028240961564 | validation: 0.0268838337939835]
	TIME [epoch: 5.7 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029961639092921113		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.029961639092921113 | validation: 0.023456450748456648]
	TIME [epoch: 5.7 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0325424244498087		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.0325424244498087 | validation: 0.025397122794660942]
	TIME [epoch: 5.7 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032122088481854064		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.032122088481854064 | validation: 0.02833834414286733]
	TIME [epoch: 5.7 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318967279263491		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.03318967279263491 | validation: 0.01876505366490842]
	TIME [epoch: 5.73 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032720121343949846		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.032720121343949846 | validation: 0.0274270719875513]
	TIME [epoch: 5.7 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03163148280843757		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.03163148280843757 | validation: 0.021397513382896874]
	TIME [epoch: 5.7 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03089795856963222		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.03089795856963222 | validation: 0.025453589109626376]
	TIME [epoch: 5.7 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03293684834882484		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.03293684834882484 | validation: 0.021613507318863075]
	TIME [epoch: 5.7 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034069193348381946		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.034069193348381946 | validation: 0.0253039875236999]
	TIME [epoch: 5.7 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03359574880914273		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.03359574880914273 | validation: 0.022330602282367912]
	TIME [epoch: 5.72 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146823312624642		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.03146823312624642 | validation: 0.022374821655278678]
	TIME [epoch: 5.71 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031869856637944116		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.031869856637944116 | validation: 0.023083766592221215]
	TIME [epoch: 5.7 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028979587122887392		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.028979587122887392 | validation: 0.01743286873438311]
	TIME [epoch: 5.7 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03101889978805495		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.03101889978805495 | validation: 0.03133954777621207]
	TIME [epoch: 5.7 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026988050537149515		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.026988050537149515 | validation: 0.021561915991069613]
	TIME [epoch: 5.7 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346958594291443		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.03346958594291443 | validation: 0.0286702146612675]
	TIME [epoch: 5.7 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031633883534160606		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.031633883534160606 | validation: 0.01672712144681486]
	TIME [epoch: 5.74 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02943112535985382		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.02943112535985382 | validation: 0.026065087714171434]
	TIME [epoch: 5.7 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03277798019115161		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.03277798019115161 | validation: 0.026095761547687762]
	TIME [epoch: 5.7 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02994078214801893		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.02994078214801893 | validation: 0.031510979580054436]
	TIME [epoch: 5.7 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025856047745591908		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.025856047745591908 | validation: 0.02619802871717189]
	TIME [epoch: 5.7 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028514402041142445		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.028514402041142445 | validation: 0.02720245310026779]
	TIME [epoch: 5.7 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031647787017944164		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.031647787017944164 | validation: 0.03262967873879601]
	TIME [epoch: 5.72 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031071147041580635		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.031071147041580635 | validation: 0.024333112285607965]
	TIME [epoch: 5.71 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03355226034312376		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.03355226034312376 | validation: 0.030292424220485788]
	TIME [epoch: 5.7 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030469617488525405		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.030469617488525405 | validation: 0.03152372291386623]
	TIME [epoch: 5.7 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033612109930840316		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.033612109930840316 | validation: 0.027631467748245948]
	TIME [epoch: 5.7 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430545069565804		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.03430545069565804 | validation: 0.025698574836536023]
	TIME [epoch: 5.7 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029684697847224648		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.029684697847224648 | validation: 0.03137530617078681]
	TIME [epoch: 5.7 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028501910326812756		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.028501910326812756 | validation: 0.03491530513373199]
	TIME [epoch: 5.73 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028565906992410208		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.028565906992410208 | validation: 0.031172814463427123]
	TIME [epoch: 5.7 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03177636063284343		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.03177636063284343 | validation: 0.02633794845261323]
	TIME [epoch: 5.7 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03288647027692055		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.03288647027692055 | validation: 0.016164021734928553]
	TIME [epoch: 5.7 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0318840364821559		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.0318840364821559 | validation: 0.0341333806061518]
	TIME [epoch: 5.7 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03395724483001879		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.03395724483001879 | validation: 0.03488607953284946]
	TIME [epoch: 5.7 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028050439281792017		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.028050439281792017 | validation: 0.028885492130812464]
	TIME [epoch: 5.71 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03077419660172362		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.03077419660172362 | validation: 0.02171236119227642]
	TIME [epoch: 5.72 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03033762654821717		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.03033762654821717 | validation: 0.024004902264507195]
	TIME [epoch: 5.7 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0306160992087127		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.0306160992087127 | validation: 0.026746829020085905]
	TIME [epoch: 5.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0323621656501349		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.0323621656501349 | validation: 0.030585222770445564]
	TIME [epoch: 5.7 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259317214779925		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.03259317214779925 | validation: 0.0250696910362756]
	TIME [epoch: 5.7 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03222479096158525		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.03222479096158525 | validation: 0.028830171304256993]
	TIME [epoch: 5.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03480221829006484		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.03480221829006484 | validation: 0.030443779347639508]
	TIME [epoch: 5.73 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029469812341611525		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.029469812341611525 | validation: 0.02844222437915211]
	TIME [epoch: 5.7 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03537017973975461		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.03537017973975461 | validation: 0.032429586689914816]
	TIME [epoch: 5.7 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03157021809760314		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.03157021809760314 | validation: 0.02556595221190285]
	TIME [epoch: 5.7 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03217698025317463		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.03217698025317463 | validation: 0.023033164235964156]
	TIME [epoch: 5.7 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032083662347386424		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.032083662347386424 | validation: 0.03114180196006066]
	TIME [epoch: 5.7 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03244861343636329		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.03244861343636329 | validation: 0.022648477823265584]
	TIME [epoch: 5.71 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034086850714938936		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.034086850714938936 | validation: 0.02594356851244104]
	TIME [epoch: 5.72 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030490881737467813		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.030490881737467813 | validation: 0.020757824503001596]
	TIME [epoch: 5.7 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03735075206980408		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.03735075206980408 | validation: 0.024446757353801602]
	TIME [epoch: 5.7 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03058131185782625		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.03058131185782625 | validation: 0.020001968809958193]
	TIME [epoch: 5.7 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031062964906144176		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.031062964906144176 | validation: 0.028697075517491566]
	TIME [epoch: 5.7 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030628594895421146		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.030628594895421146 | validation: 0.025853578107753485]
	TIME [epoch: 5.7 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03349513256143295		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.03349513256143295 | validation: 0.02221392411233193]
	TIME [epoch: 5.73 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034114064545013076		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.034114064545013076 | validation: 0.028841579213889506]
	TIME [epoch: 5.7 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029661837247434278		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.029661837247434278 | validation: 0.02426868985224495]
	TIME [epoch: 5.7 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028483587757014914		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.028483587757014914 | validation: 0.026149365882295807]
	TIME [epoch: 5.7 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032170671121002824		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.032170671121002824 | validation: 0.018715999594529034]
	TIME [epoch: 5.7 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03199720646834333		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.03199720646834333 | validation: 0.02764120031121185]
	TIME [epoch: 5.7 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02956646060607297		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.02956646060607297 | validation: 0.023150354756980424]
	TIME [epoch: 5.71 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028109685399049227		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.028109685399049227 | validation: 0.01841625943418694]
	TIME [epoch: 5.72 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03131376844696459		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.03131376844696459 | validation: 0.022462039039917725]
	TIME [epoch: 5.7 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03268594877161088		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.03268594877161088 | validation: 0.02076879096151856]
	TIME [epoch: 5.7 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030053409150425356		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.030053409150425356 | validation: 0.024323497346579247]
	TIME [epoch: 5.7 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314385518768232		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.0314385518768232 | validation: 0.025455840873370637]
	TIME [epoch: 5.7 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03251955974073988		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.03251955974073988 | validation: 0.02387718936786925]
	TIME [epoch: 5.7 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029655354811686047		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.029655354811686047 | validation: 0.03604467313164451]
	TIME [epoch: 5.73 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032566974744108704		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.032566974744108704 | validation: 0.020655125036087022]
	TIME [epoch: 5.7 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03295334818979245		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.03295334818979245 | validation: 0.035070479598529485]
	TIME [epoch: 5.7 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158865695865084		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.03158865695865084 | validation: 0.02406553408258597]
	TIME [epoch: 5.7 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368019702289929		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.03368019702289929 | validation: 0.03180439551433962]
	TIME [epoch: 5.7 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034728598711306534		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.034728598711306534 | validation: 0.022113858947711857]
	TIME [epoch: 5.7 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03537124269205904		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.03537124269205904 | validation: 0.027304217686712606]
	TIME [epoch: 5.71 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03447082070178573		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.03447082070178573 | validation: 0.024355871674726123]
	TIME [epoch: 5.72 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03233167291428169		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.03233167291428169 | validation: 0.02820470945134187]
	TIME [epoch: 5.7 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140548539717839		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.03140548539717839 | validation: 0.021993478203252793]
	TIME [epoch: 5.7 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03605571390451909		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.03605571390451909 | validation: 0.025584686638736795]
	TIME [epoch: 5.7 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03111237601729838		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.03111237601729838 | validation: 0.018193531855573968]
	TIME [epoch: 5.7 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032826557573746466		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.032826557573746466 | validation: 0.025365544110442177]
	TIME [epoch: 5.7 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03295254256296749		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.03295254256296749 | validation: 0.025663023978725014]
	TIME [epoch: 5.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034638450980270095		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.034638450980270095 | validation: 0.025852681491666894]
	TIME [epoch: 5.7 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031102551949362078		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.031102551949362078 | validation: 0.024503705167672966]
	TIME [epoch: 5.7 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031590062953098116		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.031590062953098116 | validation: 0.025517697502559875]
	TIME [epoch: 5.7 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02924539565674857		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.02924539565674857 | validation: 0.026479724879100414]
	TIME [epoch: 5.7 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03287243623279386		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.03287243623279386 | validation: 0.02248509508939251]
	TIME [epoch: 5.7 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031068518331835555		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.031068518331835555 | validation: 0.02481601080140567]
	TIME [epoch: 5.71 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03065438341375068		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.03065438341375068 | validation: 0.02633189034686395]
	TIME [epoch: 5.72 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03375070867792264		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.03375070867792264 | validation: 0.023640366754503362]
	TIME [epoch: 5.7 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0299377726287989		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.0299377726287989 | validation: 0.02192907428508979]
	TIME [epoch: 5.7 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029509642240291827		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.029509642240291827 | validation: 0.026834389623496706]
	TIME [epoch: 5.7 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027911063286373952		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.027911063286373952 | validation: 0.03117154066483609]
	TIME [epoch: 5.7 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028576192206377533		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.028576192206377533 | validation: 0.026606769983452842]
	TIME [epoch: 5.7 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030819222272656162		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.030819222272656162 | validation: 0.02786779748805109]
	TIME [epoch: 5.73 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030230877562200442		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.030230877562200442 | validation: 0.022212531286503863]
	TIME [epoch: 5.7 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028097561732534127		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.028097561732534127 | validation: 0.027338793317848137]
	TIME [epoch: 5.7 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028611467310383377		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.028611467310383377 | validation: 0.01838508061917173]
	TIME [epoch: 5.7 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030026704588269688		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.030026704588269688 | validation: 0.032381326923873785]
	TIME [epoch: 5.7 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03251792189404035		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.03251792189404035 | validation: 0.014023343589988933]
	TIME [epoch: 5.7 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029441765851859356		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.029441765851859356 | validation: 0.02015807856016925]
	TIME [epoch: 5.71 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02948572672886858		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.02948572672886858 | validation: 0.01966834336391261]
	TIME [epoch: 5.72 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03236886878545003		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.03236886878545003 | validation: 0.019045425120990857]
	TIME [epoch: 5.7 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028856042467245706		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.028856042467245706 | validation: 0.03296010450468873]
	TIME [epoch: 5.7 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030347917487369112		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.030347917487369112 | validation: 0.021140555513013932]
	TIME [epoch: 5.7 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204133025945575		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.03204133025945575 | validation: 0.02979530991134812]
	TIME [epoch: 5.7 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030902837448840773		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.030902837448840773 | validation: 0.03522797344658021]
	TIME [epoch: 5.7 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02755639507571317		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.02755639507571317 | validation: 0.025226291445497883]
	TIME [epoch: 5.73 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031841548046781985		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.031841548046781985 | validation: 0.03188388752044699]
	TIME [epoch: 5.7 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02669922109450968		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.02669922109450968 | validation: 0.03701842963187]
	TIME [epoch: 5.7 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03245885894443198		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.03245885894443198 | validation: 0.027152166380563253]
	TIME [epoch: 5.7 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03175625163073111		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.03175625163073111 | validation: 0.025689004234372814]
	TIME [epoch: 5.7 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030639165551388455		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.030639165551388455 | validation: 0.024690807465515753]
	TIME [epoch: 5.7 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031046907582928523		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.031046907582928523 | validation: 0.03215546435960027]
	TIME [epoch: 5.71 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03276192473465901		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.03276192473465901 | validation: 0.023644972034863418]
	TIME [epoch: 5.72 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0288491659599355		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.0288491659599355 | validation: 0.02291862566793676]
	TIME [epoch: 5.7 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030399520335046906		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.030399520335046906 | validation: 0.026806757095220443]
	TIME [epoch: 5.7 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030285191282489386		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.030285191282489386 | validation: 0.03140150239155015]
	TIME [epoch: 5.7 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027372259091054812		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.027372259091054812 | validation: 0.02007898300305614]
	TIME [epoch: 5.7 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03280072106053212		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.03280072106053212 | validation: 0.02446228682641202]
	TIME [epoch: 5.7 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029085242857650878		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.029085242857650878 | validation: 0.021634771619608577]
	TIME [epoch: 5.73 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027348554407040652		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.027348554407040652 | validation: 0.02946445036425925]
	TIME [epoch: 5.7 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03207377531138974		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.03207377531138974 | validation: 0.021423216891688572]
	TIME [epoch: 5.7 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030588799926367604		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.030588799926367604 | validation: 0.029112107015528736]
	TIME [epoch: 5.7 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034200317536094385		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.034200317536094385 | validation: 0.025001728153791536]
	TIME [epoch: 5.7 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029700596664670866		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.029700596664670866 | validation: 0.022272314577140347]
	TIME [epoch: 5.7 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028909415648960313		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.028909415648960313 | validation: 0.027760369259396355]
	TIME [epoch: 5.71 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0320005872329305		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.0320005872329305 | validation: 0.03062002626984599]
	TIME [epoch: 5.72 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03126400232418114		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.03126400232418114 | validation: 0.03416182917125989]
	TIME [epoch: 5.7 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03330638552604178		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.03330638552604178 | validation: 0.028757205200691482]
	TIME [epoch: 5.7 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029988794247726977		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.029988794247726977 | validation: 0.02031180143917329]
	TIME [epoch: 5.7 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031752908872943617		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.031752908872943617 | validation: 0.025312212724209297]
	TIME [epoch: 5.7 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03285023046979176		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.03285023046979176 | validation: 0.030387779433246793]
	TIME [epoch: 5.7 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03162777086548867		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.03162777086548867 | validation: 0.028969757311815354]
	TIME [epoch: 5.73 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03215190397430613		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.03215190397430613 | validation: 0.029119145124460497]
	TIME [epoch: 5.7 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03050999082917936		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.03050999082917936 | validation: 0.03201482576425804]
	TIME [epoch: 5.7 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430000139771754		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.03430000139771754 | validation: 0.024448030184690044]
	TIME [epoch: 5.7 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032322361288932455		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.032322361288932455 | validation: 0.02873909498207639]
	TIME [epoch: 5.7 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029867652739863207		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.029867652739863207 | validation: 0.029442185460835192]
	TIME [epoch: 5.7 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036435048847714036		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.036435048847714036 | validation: 0.030381261367394663]
	TIME [epoch: 5.71 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368175610685791		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.03368175610685791 | validation: 0.023781686937143446]
	TIME [epoch: 5.72 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03532423537676177		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.03532423537676177 | validation: 0.032287696253296375]
	TIME [epoch: 5.7 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03498363871315305		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.03498363871315305 | validation: 0.026013483100246048]
	TIME [epoch: 5.7 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029936170698681968		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.029936170698681968 | validation: 0.027868029168778945]
	TIME [epoch: 5.7 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034702769086971244		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.034702769086971244 | validation: 0.03323449927711582]
	TIME [epoch: 5.7 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032968089317893856		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.032968089317893856 | validation: 0.03474028997212107]
	TIME [epoch: 5.7 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03252519409676541		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.03252519409676541 | validation: 0.03042222583844078]
	TIME [epoch: 5.72 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0319692716237008		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.0319692716237008 | validation: 0.026831160094887407]
	TIME [epoch: 5.71 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02864586212656084		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.02864586212656084 | validation: 0.02480951197989077]
	TIME [epoch: 5.7 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328875477282867		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.0328875477282867 | validation: 0.027174674130564604]
	TIME [epoch: 5.7 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030615921365605404		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.030615921365605404 | validation: 0.027057964744370132]
	TIME [epoch: 5.7 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03217737767195946		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.03217737767195946 | validation: 0.02412547506696045]
	TIME [epoch: 5.7 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029848062661333552		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.029848062661333552 | validation: 0.02445880495826253]
	TIME [epoch: 5.7 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02811936022708793		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.02811936022708793 | validation: 0.027556861224403244]
	TIME [epoch: 5.73 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03356715669835719		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.03356715669835719 | validation: 0.031230407900090296]
	TIME [epoch: 5.7 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028254506545080625		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.028254506545080625 | validation: 0.021272406841057627]
	TIME [epoch: 5.7 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03124514346597609		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.03124514346597609 | validation: 0.033682875756617436]
	TIME [epoch: 5.7 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030863200653970867		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.030863200653970867 | validation: 0.028206004602335088]
	TIME [epoch: 5.7 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030744928704186467		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.030744928704186467 | validation: 0.02444284518514513]
	TIME [epoch: 5.7 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03137155298590601		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.03137155298590601 | validation: 0.030667269094988382]
	TIME [epoch: 5.72 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03510139140958353		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.03510139140958353 | validation: 0.03390085298880407]
	TIME [epoch: 5.71 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03291775913560716		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.03291775913560716 | validation: 0.032707294284214046]
	TIME [epoch: 5.7 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030854612162290518		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.030854612162290518 | validation: 0.033093089627549796]
	TIME [epoch: 5.7 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030687263845363938		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.030687263845363938 | validation: 0.025908433925220437]
	TIME [epoch: 5.7 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034177287328858254		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.034177287328858254 | validation: 0.026146101132504103]
	TIME [epoch: 5.7 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030209421577591197		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.030209421577591197 | validation: 0.03172134874558656]
	TIME [epoch: 5.7 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328915064223775		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.0328915064223775 | validation: 0.028933927959522966]
	TIME [epoch: 5.73 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03546106169859779		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.03546106169859779 | validation: 0.032929290352715315]
	TIME [epoch: 5.7 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030527224407405226		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.030527224407405226 | validation: 0.02223710544492896]
	TIME [epoch: 5.7 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320042325027166		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.03320042325027166 | validation: 0.03339229054059554]
	TIME [epoch: 5.7 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03164845065879894		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.03164845065879894 | validation: 0.03425149450528684]
	TIME [epoch: 5.7 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03474149457503073		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.03474149457503073 | validation: 0.024384111185780967]
	TIME [epoch: 5.7 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02877339191364733		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.02877339191364733 | validation: 0.028384765718606885]
	TIME [epoch: 5.72 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03183925062103095		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.03183925062103095 | validation: 0.03243140858066571]
	TIME [epoch: 5.71 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031446864429216084		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.031446864429216084 | validation: 0.030631456413676355]
	TIME [epoch: 5.7 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03461839826452167		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.03461839826452167 | validation: 0.02919811162106197]
	TIME [epoch: 5.7 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0284117111699069		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.0284117111699069 | validation: 0.023741253393978274]
	TIME [epoch: 5.7 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03372861152338818		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.03372861152338818 | validation: 0.026612507498647797]
	TIME [epoch: 5.7 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03217012399583505		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.03217012399583505 | validation: 0.021197602035513192]
	TIME [epoch: 5.7 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028739225050181345		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.028739225050181345 | validation: 0.029048312143037408]
	TIME [epoch: 5.73 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033131838353990334		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.033131838353990334 | validation: 0.029773115976471427]
	TIME [epoch: 5.7 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03170889263924858		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.03170889263924858 | validation: 0.03616463128244138]
	TIME [epoch: 5.7 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028795841534930706		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.028795841534930706 | validation: 0.027687535146751735]
	TIME [epoch: 5.7 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031184798426874112		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.031184798426874112 | validation: 0.025588569414513943]
	TIME [epoch: 5.7 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218058636870859		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.03218058636870859 | validation: 0.035792638216210856]
	TIME [epoch: 5.7 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03135211667940382		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.03135211667940382 | validation: 0.028820882100510516]
	TIME [epoch: 5.72 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032596420330418305		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.032596420330418305 | validation: 0.03503903761706585]
	TIME [epoch: 5.71 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03118209337417558		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.03118209337417558 | validation: 0.032543554160461244]
	TIME [epoch: 5.7 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145410134036726		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.03145410134036726 | validation: 0.02134962762472031]
	TIME [epoch: 5.7 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029535646658948464		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.029535646658948464 | validation: 0.018766222103862976]
	TIME [epoch: 5.7 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02714190773222719		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.02714190773222719 | validation: 0.021533506330637935]
	TIME [epoch: 5.7 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0317223890561115		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.0317223890561115 | validation: 0.026585000011484023]
	TIME [epoch: 5.7 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028605636476042112		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.028605636476042112 | validation: 0.03093506063448692]
	TIME [epoch: 5.73 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028387032081014688		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.028387032081014688 | validation: 0.020261908478449154]
	TIME [epoch: 5.7 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033370541045220886		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.033370541045220886 | validation: 0.025149524642510256]
	TIME [epoch: 5.7 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030145882304967692		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.030145882304967692 | validation: 0.03304880475008787]
	TIME [epoch: 5.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02656532205272267		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.02656532205272267 | validation: 0.028381073832388894]
	TIME [epoch: 5.7 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030231152283247936		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.030231152283247936 | validation: 0.021542677576200233]
	TIME [epoch: 5.7 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0323839798365699		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.0323839798365699 | validation: 0.024120156390546307]
	TIME [epoch: 5.72 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03240832449079555		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.03240832449079555 | validation: 0.02117388781566257]
	TIME [epoch: 5.71 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195512087485926		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.03195512087485926 | validation: 0.026251217049251627]
	TIME [epoch: 5.7 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029479310477369153		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.029479310477369153 | validation: 0.02020766007982173]
	TIME [epoch: 5.7 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03107508411757015		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.03107508411757015 | validation: 0.02995954966803531]
	TIME [epoch: 5.7 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03130765323262647		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.03130765323262647 | validation: 0.018393031961237278]
	TIME [epoch: 5.7 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029286469356633954		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.029286469356633954 | validation: 0.020846333481676603]
	TIME [epoch: 5.7 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03287731019113456		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.03287731019113456 | validation: 0.03186761380786492]
	TIME [epoch: 5.74 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03407285390369107		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.03407285390369107 | validation: 0.026539848857314686]
	TIME [epoch: 5.7 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028068706212452915		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.028068706212452915 | validation: 0.023695389225317526]
	TIME [epoch: 5.7 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03188632857895544		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.03188632857895544 | validation: 0.0199454852373233]
	TIME [epoch: 5.7 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029670753607309117		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.029670753607309117 | validation: 0.025322664207850263]
	TIME [epoch: 5.7 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03080106008077134		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.03080106008077134 | validation: 0.02730811753821495]
	TIME [epoch: 5.7 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030836655646381248		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.030836655646381248 | validation: 0.024061203303629104]
	TIME [epoch: 5.72 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02799260906281552		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.02799260906281552 | validation: 0.02335814217694935]
	TIME [epoch: 5.71 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027861085305306135		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.027861085305306135 | validation: 0.022187473770974672]
	TIME [epoch: 5.7 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030284147386863972		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.030284147386863972 | validation: 0.021530781951892945]
	TIME [epoch: 5.7 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03045942339950011		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.03045942339950011 | validation: 0.01879331418502933]
	TIME [epoch: 5.7 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028862206642237646		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.028862206642237646 | validation: 0.027376746644824684]
	TIME [epoch: 5.7 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02878829873183485		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.02878829873183485 | validation: 0.02235505567221028]
	TIME [epoch: 5.7 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031649079987923254		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.031649079987923254 | validation: 0.027634447407113256]
	TIME [epoch: 5.73 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030178987064784252		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.030178987064784252 | validation: 0.034775274474064005]
	TIME [epoch: 5.7 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03241019170668765		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.03241019170668765 | validation: 0.032793399859316084]
	TIME [epoch: 5.7 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328275755505678		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.0328275755505678 | validation: 0.02424037905190006]
	TIME [epoch: 5.7 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031281317091473616		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.031281317091473616 | validation: 0.024632977822277153]
	TIME [epoch: 5.7 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282754328069381		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.03282754328069381 | validation: 0.02637059889477798]
	TIME [epoch: 5.7 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029734044615961047		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.029734044615961047 | validation: 0.027193756114392932]
	TIME [epoch: 5.72 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0305691634624167		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0305691634624167 | validation: 0.017157489626201484]
	TIME [epoch: 5.71 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03000831684938149		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.03000831684938149 | validation: 0.022434332355934297]
	TIME [epoch: 5.7 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030758515617865197		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.030758515617865197 | validation: 0.03027430616796413]
	TIME [epoch: 5.7 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03472497936750193		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.03472497936750193 | validation: 0.023343502538248212]
	TIME [epoch: 5.7 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027942897625980172		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.027942897625980172 | validation: 0.019125187372212943]
	TIME [epoch: 5.69 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02736711728194574		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.02736711728194574 | validation: 0.0325079627930432]
	TIME [epoch: 5.7 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02971543370766447		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.02971543370766447 | validation: 0.02430485702685425]
	TIME [epoch: 5.73 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028977573528913815		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.028977573528913815 | validation: 0.02217604891452128]
	TIME [epoch: 5.7 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029767199974702598		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.029767199974702598 | validation: 0.026512362300041767]
	TIME [epoch: 5.7 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030978037607059066		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.030978037607059066 | validation: 0.025471914416362935]
	TIME [epoch: 5.7 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026200194650646887		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.026200194650646887 | validation: 0.018736905307679037]
	TIME [epoch: 5.69 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368521878454175		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.03368521878454175 | validation: 0.020514552235885317]
	TIME [epoch: 5.7 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02956892178249362		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.02956892178249362 | validation: 0.029749651743654945]
	TIME [epoch: 5.72 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028784942470454256		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.028784942470454256 | validation: 0.03250006492094169]
	TIME [epoch: 5.71 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282357902121544		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.03282357902121544 | validation: 0.023015094014822334]
	TIME [epoch: 5.7 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03319840937918933		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.03319840937918933 | validation: 0.02393397221277339]
	TIME [epoch: 5.7 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154848934191973		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.03154848934191973 | validation: 0.025588183615775084]
	TIME [epoch: 5.69 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03056930647645205		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.03056930647645205 | validation: 0.027966745627814583]
	TIME [epoch: 5.69 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028357714157530477		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.028357714157530477 | validation: 0.023820153814318186]
	TIME [epoch: 5.7 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030314730672325627		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.030314730672325627 | validation: 0.030683691251611852]
	TIME [epoch: 5.73 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032536843302221154		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.032536843302221154 | validation: 0.03373901830987945]
	TIME [epoch: 5.7 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03171643466775129		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.03171643466775129 | validation: 0.029531801004456286]
	TIME [epoch: 5.7 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028657194025374956		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.028657194025374956 | validation: 0.02331904252006974]
	TIME [epoch: 5.7 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027148911235573357		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.027148911235573357 | validation: 0.029032505024151667]
	TIME [epoch: 5.69 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331833749148059		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.0331833749148059 | validation: 0.02277523623688218]
	TIME [epoch: 5.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032279084098051365		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.032279084098051365 | validation: 0.028129467883537238]
	TIME [epoch: 5.72 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029260571710941763		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.029260571710941763 | validation: 0.0285175934291144]
	TIME [epoch: 5.71 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02892837694232421		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.02892837694232421 | validation: 0.031665056657775546]
	TIME [epoch: 5.7 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02969000310582218		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.02969000310582218 | validation: 0.031274509521605647]
	TIME [epoch: 5.7 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030710959704780952		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.030710959704780952 | validation: 0.023128242814038965]
	TIME [epoch: 5.7 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03159871987660867		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.03159871987660867 | validation: 0.025449689466891016]
	TIME [epoch: 5.7 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028558071770117394		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.028558071770117394 | validation: 0.023063180173378443]
	TIME [epoch: 5.7 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02897980659603014		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.02897980659603014 | validation: 0.022326672067441277]
	TIME [epoch: 5.73 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03302770505203126		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.03302770505203126 | validation: 0.0326536226971626]
	TIME [epoch: 5.7 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030725994550844758		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.030725994550844758 | validation: 0.025789145759282643]
	TIME [epoch: 5.7 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028540118290733864		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.028540118290733864 | validation: 0.022604319078909564]
	TIME [epoch: 5.7 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02956861272272079		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.02956861272272079 | validation: 0.02523086859125183]
	TIME [epoch: 5.7 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03225260040627616		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.03225260040627616 | validation: 0.03368141631737565]
	TIME [epoch: 5.7 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031809865592791475		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.031809865592791475 | validation: 0.027534606052668515]
	TIME [epoch: 5.72 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033106863181892904		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.033106863181892904 | validation: 0.02030051754327057]
	TIME [epoch: 5.71 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030248990655307655		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.030248990655307655 | validation: 0.02578372667449145]
	TIME [epoch: 5.7 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154227163484047		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.03154227163484047 | validation: 0.027612912972893398]
	TIME [epoch: 5.7 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03203729714039413		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.03203729714039413 | validation: 0.02499363639325293]
	TIME [epoch: 5.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03129563152058422		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.03129563152058422 | validation: 0.018542002678466375]
	TIME [epoch: 5.69 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028293601561605833		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.028293601561605833 | validation: 0.022770911011133706]
	TIME [epoch: 5.7 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030844440130947413		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.030844440130947413 | validation: 0.028216945467099564]
	TIME [epoch: 5.73 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030358462372359046		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.030358462372359046 | validation: 0.02076581677152222]
	TIME [epoch: 5.7 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030858589582441632		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.030858589582441632 | validation: 0.024013833375161508]
	TIME [epoch: 5.7 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028419031325729004		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.028419031325729004 | validation: 0.02580039134397789]
	TIME [epoch: 5.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03033261188602205		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.03033261188602205 | validation: 0.013366025538702007]
	TIME [epoch: 5.7 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03168421560892969		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.03168421560892969 | validation: 0.019671145743758486]
	TIME [epoch: 5.7 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02483502647618232		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.02483502647618232 | validation: 0.02536730090621405]
	TIME [epoch: 5.72 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03026051597889577		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.03026051597889577 | validation: 0.02169967562985707]
	TIME [epoch: 5.71 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033127509787136834		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.033127509787136834 | validation: 0.02454117123994327]
	TIME [epoch: 5.7 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028335019701895524		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.028335019701895524 | validation: 0.02439266113896654]
	TIME [epoch: 5.7 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027426127562253516		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.027426127562253516 | validation: 0.01894448826744581]
	TIME [epoch: 5.7 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166992704291491		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.03166992704291491 | validation: 0.02072784397824544]
	TIME [epoch: 5.7 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03117051688406467		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.03117051688406467 | validation: 0.025797135728524063]
	TIME [epoch: 5.7 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029374091336194785		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.029374091336194785 | validation: 0.020483997193036695]
	TIME [epoch: 5.73 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03509761873427346		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.03509761873427346 | validation: 0.01953381785023499]
	TIME [epoch: 5.7 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0287194183413911		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.0287194183413911 | validation: 0.02654307324237465]
	TIME [epoch: 5.7 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03213200726105022		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.03213200726105022 | validation: 0.03177127572582858]
	TIME [epoch: 5.7 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370268182729569		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.03370268182729569 | validation: 0.0315424031778944]
	TIME [epoch: 5.7 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030334195033968447		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.030334195033968447 | validation: 0.022714921304397492]
	TIME [epoch: 5.69 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030852268348323567		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.030852268348323567 | validation: 0.023894689212534122]
	TIME [epoch: 5.72 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03479700162493675		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.03479700162493675 | validation: 0.035205168999879494]
	TIME [epoch: 5.71 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0329761378675554		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.0329761378675554 | validation: 0.029459073910185787]
	TIME [epoch: 5.7 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031587779052447786		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.031587779052447786 | validation: 0.022124754885922488]
	TIME [epoch: 5.7 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030265113094737284		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.030265113094737284 | validation: 0.021020229184632748]
	TIME [epoch: 5.7 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03151741962660991		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.03151741962660991 | validation: 0.01675377971830998]
	TIME [epoch: 5.7 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030385139689700948		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.030385139689700948 | validation: 0.019643361706065884]
	TIME [epoch: 5.7 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03018027151463651		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.03018027151463651 | validation: 0.02645382634323204]
	TIME [epoch: 5.73 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030476839269001257		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.030476839269001257 | validation: 0.023318280665751083]
	TIME [epoch: 5.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030712034678969526		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.030712034678969526 | validation: 0.026669397261839107]
	TIME [epoch: 5.7 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03205185975281889		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.03205185975281889 | validation: 0.02335121421190747]
	TIME [epoch: 5.7 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031722362212420925		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.031722362212420925 | validation: 0.028270985895720226]
	TIME [epoch: 5.7 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282881163917022		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.03282881163917022 | validation: 0.02768779667763577]
	TIME [epoch: 5.7 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032007502039338304		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.032007502039338304 | validation: 0.029978922720514837]
	TIME [epoch: 5.72 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03081910889506065		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.03081910889506065 | validation: 0.027385460141097627]
	TIME [epoch: 5.71 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03461082248801228		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.03461082248801228 | validation: 0.028011777939145343]
	TIME [epoch: 5.7 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02896117085553211		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.02896117085553211 | validation: 0.030883438171972127]
	TIME [epoch: 5.7 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030742293896349505		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.030742293896349505 | validation: 0.02167468517007035]
	TIME [epoch: 5.7 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03341990854767609		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.03341990854767609 | validation: 0.02481748507368036]
	TIME [epoch: 5.7 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030442086451003623		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.030442086451003623 | validation: 0.02998375105003953]
	TIME [epoch: 5.7 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030370751174676653		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.030370751174676653 | validation: 0.026943509915441078]
	TIME [epoch: 5.73 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02867139945187992		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.02867139945187992 | validation: 0.0256113490460484]
	TIME [epoch: 5.7 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03167634558009566		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.03167634558009566 | validation: 0.021060355777285805]
	TIME [epoch: 5.7 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030537742634029273		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.030537742634029273 | validation: 0.026285834079091793]
	TIME [epoch: 5.7 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031552369754259194		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.031552369754259194 | validation: 0.025197319997140668]
	TIME [epoch: 5.7 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026608555625012003		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.026608555625012003 | validation: 0.03339275425102658]
	TIME [epoch: 5.7 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03050571877994458		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.03050571877994458 | validation: 0.02510043356631682]
	TIME [epoch: 5.71 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029375775988323933		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.029375775988323933 | validation: 0.016369258604050106]
	TIME [epoch: 5.72 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033013742377657446		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.033013742377657446 | validation: 0.02061799633749582]
	TIME [epoch: 5.7 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03007334864557533		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.03007334864557533 | validation: 0.02297206324628828]
	TIME [epoch: 5.7 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03503770208879869		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.03503770208879869 | validation: 0.023107179958644055]
	TIME [epoch: 5.7 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029343543662078468		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.029343543662078468 | validation: 0.02050959148808821]
	TIME [epoch: 5.7 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237827840802811		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.03237827840802811 | validation: 0.020540503939054818]
	TIME [epoch: 5.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02868673190727046		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.02868673190727046 | validation: 0.021228048533969045]
	TIME [epoch: 5.73 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027237371295447815		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.027237371295447815 | validation: 0.02502673790206365]
	TIME [epoch: 5.7 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030652865450996186		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.030652865450996186 | validation: 0.013935166710180224]
	TIME [epoch: 5.7 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0311185540568354		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.0311185540568354 | validation: 0.027359988538548805]
	TIME [epoch: 5.7 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027341319756069876		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.027341319756069876 | validation: 0.0331967046353867]
	TIME [epoch: 5.7 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03137476929168647		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.03137476929168647 | validation: 0.027569429332203486]
	TIME [epoch: 5.7 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03187649871167495		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.03187649871167495 | validation: 0.02125927875195703]
	TIME [epoch: 5.71 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030892425744335945		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.030892425744335945 | validation: 0.014446255983831825]
	TIME [epoch: 5.72 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030552447624823953		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.030552447624823953 | validation: 0.022635570502135667]
	TIME [epoch: 5.7 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03143817028990032		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.03143817028990032 | validation: 0.01853904665917027]
	TIME [epoch: 5.7 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030968557440391443		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.030968557440391443 | validation: 0.02335645036313919]
	TIME [epoch: 5.7 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02918471145900766		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.02918471145900766 | validation: 0.025227025330525316]
	TIME [epoch: 5.7 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02883332661562197		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.02883332661562197 | validation: 0.02239926659911862]
	TIME [epoch: 5.7 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030839030686188727		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.030839030686188727 | validation: 0.027266166839327186]
	TIME [epoch: 5.73 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03078541723570336		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.03078541723570336 | validation: 0.01904322686756873]
	TIME [epoch: 5.7 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028968882122625175		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.028968882122625175 | validation: 0.020814033284380508]
	TIME [epoch: 5.7 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330017063087628		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.0330017063087628 | validation: 0.02067369951014131]
	TIME [epoch: 5.7 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03087342791728675		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.03087342791728675 | validation: 0.022948032952931508]
	TIME [epoch: 5.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03435799807633949		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.03435799807633949 | validation: 0.023302191714389412]
	TIME [epoch: 5.7 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028466685851352275		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.028466685851352275 | validation: 0.02141422871645325]
	TIME [epoch: 5.71 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032858786745871046		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.032858786745871046 | validation: 0.024386642432622778]
	TIME [epoch: 5.72 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029968889591598893		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.029968889591598893 | validation: 0.02701463325724411]
	TIME [epoch: 5.7 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027769213107408215		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.027769213107408215 | validation: 0.02185577792460672]
	TIME [epoch: 5.7 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03156427811842041		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.03156427811842041 | validation: 0.023159711042727862]
	TIME [epoch: 5.7 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030722594962046938		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.030722594962046938 | validation: 0.027034485739779752]
	TIME [epoch: 5.7 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029672394180201588		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.029672394180201588 | validation: 0.02779670477798715]
	TIME [epoch: 5.7 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029795386413866462		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.029795386413866462 | validation: 0.02458181295439537]
	TIME [epoch: 5.73 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02862139487924925		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.02862139487924925 | validation: 0.02798220075387479]
	TIME [epoch: 5.7 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031047335458149476		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.031047335458149476 | validation: 0.01826361455226893]
	TIME [epoch: 5.7 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03576837354669077		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.03576837354669077 | validation: 0.01899976405056712]
	TIME [epoch: 5.7 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027362704875604053		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.027362704875604053 | validation: 0.026640754816026402]
	TIME [epoch: 5.7 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02875924546509788		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.02875924546509788 | validation: 0.01972104461088503]
	TIME [epoch: 5.7 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166622381212715		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.03166622381212715 | validation: 0.025706440803557263]
	TIME [epoch: 5.71 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030593467495076892		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.030593467495076892 | validation: 0.025411180913426437]
	TIME [epoch: 5.72 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028310295090989958		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.028310295090989958 | validation: 0.029117909756702663]
	TIME [epoch: 5.7 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03104308686323554		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.03104308686323554 | validation: 0.026303025148985925]
	TIME [epoch: 5.7 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02374312299936476		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.02374312299936476 | validation: 0.021364455092163885]
	TIME [epoch: 5.7 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026356184999834362		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.026356184999834362 | validation: 0.023714175848713527]
	TIME [epoch: 5.7 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030298300903731843		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.030298300903731843 | validation: 0.021777554102640498]
	TIME [epoch: 5.7 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030234751193245386		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.030234751193245386 | validation: 0.015935627541825113]
	TIME [epoch: 5.73 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03186188552587095		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.03186188552587095 | validation: 0.022797143612240636]
	TIME [epoch: 5.7 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028930714343500745		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.028930714343500745 | validation: 0.022251436749809287]
	TIME [epoch: 5.7 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03070381187944979		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.03070381187944979 | validation: 0.019066026805888713]
	TIME [epoch: 5.7 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03124805782524554		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.03124805782524554 | validation: 0.020621815988158054]
	TIME [epoch: 5.7 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030217483295072914		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.030217483295072914 | validation: 0.027393771119682452]
	TIME [epoch: 5.7 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030689016573701114		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.030689016573701114 | validation: 0.02049305366489805]
	TIME [epoch: 5.71 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032793021106315046		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.032793021106315046 | validation: 0.02056755005468937]
	TIME [epoch: 5.72 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02998524210382742		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.02998524210382742 | validation: 0.026606970453435883]
	TIME [epoch: 5.7 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02813091432943375		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.02813091432943375 | validation: 0.02804427410850766]
	TIME [epoch: 5.7 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02768021938523103		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.02768021938523103 | validation: 0.022946958308050398]
	TIME [epoch: 5.7 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02803440115268498		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.02803440115268498 | validation: 0.03115852807654969]
	TIME [epoch: 5.7 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028932001524272694		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.028932001524272694 | validation: 0.01798483502653639]
	TIME [epoch: 5.7 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025638114008225958		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.025638114008225958 | validation: 0.025777437839036983]
	TIME [epoch: 5.73 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027449737254490555		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.027449737254490555 | validation: 0.02553464579567911]
	TIME [epoch: 5.7 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028082907789769858		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.028082907789769858 | validation: 0.02137197723315013]
	TIME [epoch: 5.7 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028554992879987934		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.028554992879987934 | validation: 0.028886775813014853]
	TIME [epoch: 5.7 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03210912300983075		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.03210912300983075 | validation: 0.022227222461629934]
	TIME [epoch: 5.7 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03249496716718701		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.03249496716718701 | validation: 0.024943349805497506]
	TIME [epoch: 5.7 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027376003674426927		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.027376003674426927 | validation: 0.028013821430315798]
	TIME [epoch: 5.71 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028695202105720664		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.028695202105720664 | validation: 0.019304361937799157]
	TIME [epoch: 5.72 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028666179582534104		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.028666179582534104 | validation: 0.02602877854272746]
	TIME [epoch: 5.7 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03288639628748902		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.03288639628748902 | validation: 0.03129497263811011]
	TIME [epoch: 5.7 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028778584212673635		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.028778584212673635 | validation: 0.0293379475393957]
	TIME [epoch: 5.7 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029477874963048524		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.029477874963048524 | validation: 0.014707286166287706]
	TIME [epoch: 5.7 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03101682946879919		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.03101682946879919 | validation: 0.025315942985691564]
	TIME [epoch: 5.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030959141692214944		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.030959141692214944 | validation: 0.024018724770739467]
	TIME [epoch: 5.73 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034855564258645375		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.034855564258645375 | validation: 0.02855160676137614]
	TIME [epoch: 5.7 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031024409817376686		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.031024409817376686 | validation: 0.03016426799565049]
	TIME [epoch: 5.7 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031381235079232885		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.031381235079232885 | validation: 0.027856596779366083]
	TIME [epoch: 5.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028970944297759853		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.028970944297759853 | validation: 0.030941030555414698]
	TIME [epoch: 5.69 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028212067976757908		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.028212067976757908 | validation: 0.024193621171236985]
	TIME [epoch: 5.7 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02916687905357469		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.02916687905357469 | validation: 0.029623680440098107]
	TIME [epoch: 5.71 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029787729273694462		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.029787729273694462 | validation: 0.01827493440730059]
	TIME [epoch: 5.72 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03359006934245943		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.03359006934245943 | validation: 0.019590916004449635]
	TIME [epoch: 5.7 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158894271756802		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.03158894271756802 | validation: 0.020370002551909707]
	TIME [epoch: 5.7 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030254089658191395		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.030254089658191395 | validation: 0.029703387077824887]
	TIME [epoch: 5.7 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030024863788920553		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.030024863788920553 | validation: 0.026534424972936694]
	TIME [epoch: 5.7 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218265810541155		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.03218265810541155 | validation: 0.02411927146888832]
	TIME [epoch: 5.7 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030402268261315313		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.030402268261315313 | validation: 0.02176577849447103]
	TIME [epoch: 5.73 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02934578249985318		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.02934578249985318 | validation: 0.02396525848128567]
	TIME [epoch: 5.7 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03028077870480738		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.03028077870480738 | validation: 0.02272116612347869]
	TIME [epoch: 5.7 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03129323040727311		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.03129323040727311 | validation: 0.025474439602281095]
	TIME [epoch: 5.7 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030248624866536414		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.030248624866536414 | validation: 0.029616323297357167]
	TIME [epoch: 5.7 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030962745223076064		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.030962745223076064 | validation: 0.018881734255284867]
	TIME [epoch: 5.7 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027914530759257948		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.027914530759257948 | validation: 0.029845444180418106]
	TIME [epoch: 5.71 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02986962328059794		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.02986962328059794 | validation: 0.024042830563618365]
	TIME [epoch: 5.72 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03399401025605056		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.03399401025605056 | validation: 0.02938802185448138]
	TIME [epoch: 5.7 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02766185385409882		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.02766185385409882 | validation: 0.022414654988056962]
	TIME [epoch: 5.7 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032004865147108194		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.032004865147108194 | validation: 0.025400661329772648]
	TIME [epoch: 5.7 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03148583063585119		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.03148583063585119 | validation: 0.02446728023591623]
	TIME [epoch: 5.7 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027221592376286075		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.027221592376286075 | validation: 0.025972909808008426]
	TIME [epoch: 5.7 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02348769514381677		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.02348769514381677 | validation: 0.024771901571731952]
	TIME [epoch: 5.73 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02867001778237726		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.02867001778237726 | validation: 0.02894693206406413]
	TIME [epoch: 5.7 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03067384621861043		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.03067384621861043 | validation: 0.024886823667167175]
	TIME [epoch: 5.7 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03198445156265854		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.03198445156265854 | validation: 0.01900017056102741]
	TIME [epoch: 5.7 sec]
Finished training in 11609.429 seconds.
