Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r0', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2024124460

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/20] avg loss: 7.192637842743508		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.748553939646131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.970595891194819 | validation: 5.968833948904988]
	TIME [epoch: 70.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.997894534551003		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.237189611859565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.117542073205284 | validation: 5.799616036186179]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/20] avg loss: 6.111056430624442		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.799631779611852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.955344105118146 | validation: 5.695148340487668]
	TIME [epoch: 8.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.266478430937599		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.4652705781411965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.865874504539398 | validation: 3.467943352339606]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.7841604893918386		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.9816084346824594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3828844620371483 | validation: 2.905254034632329]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.051926136616309		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.0515745831302916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0517503598733002 | validation: 1.489866032978416]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8837043928679553		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5197243746613447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.70171438376465 | validation: 1.032967590571475]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.678210184575504		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6492713153438565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6637407499596808 | validation: 1.383892021398156]
	TIME [epoch: 8.76 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.537826552948095		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4095432801018155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4736849165249555 | validation: 1.740613065662171]
	TIME [epoch: 8.77 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.835111048062052		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4534478521249465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.644279450093499 | validation: 1.3393860644278228]
	TIME [epoch: 8.78 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.326714595704869		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6240576256289458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4753861106669068 | validation: 1.1063585301999743]
	TIME [epoch: 8.78 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4691629243221507		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.483375945516557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4762694349193541 | validation: 1.2744903176738342]
	TIME [epoch: 8.76 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4019519236749716		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.422226889314375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.412089406494673 | validation: 1.088152634958422]
	TIME [epoch: 8.78 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5522704182618905		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4898616794527713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5210660488573309 | validation: 1.3598763331378403]
	TIME [epoch: 8.76 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5419678937570604		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2721585483084223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4070632210327414 | validation: 2.711560431664122]
	TIME [epoch: 8.75 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.84771049250585		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4497224814559102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6487164869808801 | validation: 1.1568208870470524]
	TIME [epoch: 8.77 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.61470898638619		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6224187952485742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6185638908173825 | validation: 1.0816038832746298]
	TIME [epoch: 8.77 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5151343278882614		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.438990936984392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.477062632436327 | validation: 1.0342987091890956]
	TIME [epoch: 8.76 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4692239907387343		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5688015831546542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.519012786946694 | validation: 1.046445311137223]
	TIME [epoch: 8.76 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3039509254556314		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6946446392374004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.499297782346516 | validation: 1.5052550007796852]
	TIME [epoch: 8.76 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3932854467087592		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4194722666569979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4063788566828783 | validation: 1.6757883455580214]
	TIME [epoch: 8.79 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6286806725401053		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.378689954951321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.503685313745713 | validation: 1.1156725472058424]
	TIME [epoch: 8.77 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3619830988175996		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5213458051312323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4416644519744157 | validation: 1.3013679450464795]
	TIME [epoch: 8.76 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3690138541080676		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.439307007896645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.404160431002356 | validation: 1.2185921584194332]
	TIME [epoch: 8.76 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4475896814806681		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5682295564003845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5079096189405266 | validation: 1.6993127485709696]
	TIME [epoch: 8.77 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5155379443944554		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3060952079651662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4108165761798108 | validation: 1.1579922636177653]
	TIME [epoch: 8.78 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.296740744951773		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5771221715860422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4369314582689074 | validation: 1.449021343360664]
	TIME [epoch: 8.77 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3677995326251953		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4221512173894184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3949753750073066 | validation: 1.1119225651057336]
	TIME [epoch: 8.76 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3267195741985767		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3432662998129108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3349929370057436 | validation: 1.342600331712811]
	TIME [epoch: 8.76 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3865933311998622		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.467577202760768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4270852669803151 | validation: 1.8053011181975884]
	TIME [epoch: 8.76 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.840728649743562		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2449087462311685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0428186979873653 | validation: 1.0614594450895347]
	TIME [epoch: 8.77 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.477812957394065		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4203454197837742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4490791885889198 | validation: 1.3765111217174901]
	TIME [epoch: 8.76 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.322567297283506		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3284997004550614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3255334988692835 | validation: 1.1517666204487358]
	TIME [epoch: 8.76 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.475250481055891		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6311993230929982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5532249020744449 | validation: 1.4729775643297103]
	TIME [epoch: 8.75 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3750007859188285		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.324033042709712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3495169143142705 | validation: 1.2067966095152192]
	TIME [epoch: 8.76 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3422912461680194		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2973031982109366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3197972221894778 | validation: 1.4151958017957988]
	TIME [epoch: 8.76 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.383424204479245		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3844374786155895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.383930841547417 | validation: 1.2525777634569586]
	TIME [epoch: 8.77 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3202275935632743		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5764220462585874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.448324819910931 | validation: 1.0654805889035068]
	TIME [epoch: 8.75 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5035480626743105		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.286440416967874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3949942398210922 | validation: 1.079184708060825]
	TIME [epoch: 8.75 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2915496379354487		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3645396392989366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3280446386171927 | validation: 1.2191249670594764]
	TIME [epoch: 8.76 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4947300941030024		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6258129037619593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5602714989324806 | validation: 1.1204295302867113]
	TIME [epoch: 8.76 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3998094927797209		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5493183904076988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.47456394159371 | validation: 1.3077398695403393]
	TIME [epoch: 8.77 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2664296881927823		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.300777623828858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2836036560108202 | validation: 1.1537175078881694]
	TIME [epoch: 8.76 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.436276378771452		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3308743806309544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.383575379701203 | validation: 1.5079763183940125]
	TIME [epoch: 8.75 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.338798073489975		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4542328343852184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3965154539375966 | validation: 1.2552743255664318]
	TIME [epoch: 8.74 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5432381271875388		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6530722752913234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5981552012394311 | validation: 1.107377947098692]
	TIME [epoch: 8.76 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3035589696640995		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5472876794497559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4254233245569279 | validation: 1.1977735627145243]
	TIME [epoch: 8.78 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2949739747142375		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3473110350186521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3211425048664451 | validation: 1.3549728263681726]
	TIME [epoch: 8.77 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3511455980551321		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4027544051008485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3769500015779905 | validation: 1.2289586261563827]
	TIME [epoch: 8.77 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.25758491114204		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3656217858974358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3116033485197378 | validation: 1.2232791177188544]
	TIME [epoch: 8.77 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3364624577425392		[learning rate: 0.0099782]
		[batch 20/20] avg loss: 1.3641838842945315		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 1.3503231710185355 | validation: 1.0149024998265712]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.32963145956138		[learning rate: 0.00993]
		[batch 20/20] avg loss: 1.297830441875987		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 1.3137309507186834 | validation: 1.6567621961670151]
	TIME [epoch: 8.79 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.316822381436708		[learning rate: 0.0098819]
		[batch 20/20] avg loss: 1.2811091516374247		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 1.2989657665370664 | validation: 1.0551953621626313]
	TIME [epoch: 8.77 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3006697147738362		[learning rate: 0.0098341]
		[batch 20/20] avg loss: 1.2656596006421932		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 1.283164657708015 | validation: 1.4846174951626903]
	TIME [epoch: 8.78 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.339364190470498		[learning rate: 0.0097866]
		[batch 20/20] avg loss: 1.201331112826913		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 1.2703476516487053 | validation: 1.2057153479856684]
	TIME [epoch: 8.77 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3335603106916794		[learning rate: 0.0097393]
		[batch 20/20] avg loss: 1.4347399888188377		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 1.3841501497552584 | validation: 1.1231175590061728]
	TIME [epoch: 8.76 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3883399519781612		[learning rate: 0.0096922]
		[batch 20/20] avg loss: 1.417639889341543		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 1.402989920659852 | validation: 1.1303740339252826]
	TIME [epoch: 8.78 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2649834083354636		[learning rate: 0.0096453]
		[batch 20/20] avg loss: 1.2464653123524325		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 1.255724360343948 | validation: 1.8048434161289788]
	TIME [epoch: 8.78 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3561484031054738		[learning rate: 0.0095987]
		[batch 20/20] avg loss: 1.2607241154712174		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 1.3084362592883454 | validation: 1.0399076746789886]
	TIME [epoch: 8.77 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2406884023738336		[learning rate: 0.0095522]
		[batch 20/20] avg loss: 1.3912227857928332		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 1.3159555940833334 | validation: 1.015436340436086]
	TIME [epoch: 8.78 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1661953320650882		[learning rate: 0.009506]
		[batch 20/20] avg loss: 1.3322689041841405		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 1.2492321181246144 | validation: 1.5021023973778658]
	TIME [epoch: 8.76 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3174012399576152		[learning rate: 0.0094601]
		[batch 20/20] avg loss: 1.218837730372194		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 1.2681194851649045 | validation: 0.9477901812463447]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2692291229777397		[learning rate: 0.0094143]
		[batch 20/20] avg loss: 1.208663738463044		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 1.2389464307203917 | validation: 1.1203706223551309]
	TIME [epoch: 8.78 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1852183427432048		[learning rate: 0.0093688]
		[batch 20/20] avg loss: 1.1819273322389756		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 1.18357283749109 | validation: 3.4639121504698958]
	TIME [epoch: 8.78 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5715673377116748		[learning rate: 0.0093235]
		[batch 20/20] avg loss: 1.2786174105556156		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 1.4250923741336452 | validation: 0.9492548121264873]
	TIME [epoch: 8.76 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.219504877641579		[learning rate: 0.0092784]
		[batch 20/20] avg loss: 1.232892604271571		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 1.226198740956575 | validation: 1.0341100030573551]
	TIME [epoch: 8.77 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2792858905871123		[learning rate: 0.0092335]
		[batch 20/20] avg loss: 1.2094987510676039		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 1.2443923208273582 | validation: 0.9143341851819271]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2815635136692438		[learning rate: 0.0091889]
		[batch 20/20] avg loss: 1.391707754838388		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 1.3366356342538162 | validation: 1.2254787656470802]
	TIME [epoch: 8.82 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2766762781484218		[learning rate: 0.0091445]
		[batch 20/20] avg loss: 1.3413299362684297		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 1.3090031072084258 | validation: 0.9888743104281328]
	TIME [epoch: 8.76 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2663441243407934		[learning rate: 0.0091002]
		[batch 20/20] avg loss: 1.2343671091998978		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 1.2503556167703458 | validation: 1.0501968452899482]
	TIME [epoch: 8.78 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2564658918898375		[learning rate: 0.0090562]
		[batch 20/20] avg loss: 1.2005941720695084		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 1.2285300319796728 | validation: 1.0603173854941477]
	TIME [epoch: 8.78 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2347443930171134		[learning rate: 0.0090124]
		[batch 20/20] avg loss: 1.22423905801766		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 1.2294917255173867 | validation: 0.8918172199251625]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_72.pth
	Model improved!!!
EPOCH 73/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2722026588817006		[learning rate: 0.0089689]
		[batch 20/20] avg loss: 1.2487635760934555		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 1.2604831174875781 | validation: 1.1052778532099599]
	TIME [epoch: 8.87 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.185792348116292		[learning rate: 0.0089255]
		[batch 20/20] avg loss: 1.2426497767448013		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 1.2142210624305467 | validation: 1.390296791613734]
	TIME [epoch: 8.77 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.283465038394996		[learning rate: 0.0088823]
		[batch 20/20] avg loss: 1.2482987646040606		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 1.2658819014995282 | validation: 1.4488198276209934]
	TIME [epoch: 8.78 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.0493315051828738		[learning rate: 0.0088394]
		[batch 20/20] avg loss: 1.189560990165192		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 1.6194462476740334 | validation: 1.0350691180599358]
	TIME [epoch: 8.76 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2929256068889707		[learning rate: 0.0087966]
		[batch 20/20] avg loss: 1.1937653590939115		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 1.2433454829914412 | validation: 1.091356460855569]
	TIME [epoch: 8.78 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1524629925087992		[learning rate: 0.0087541]
		[batch 20/20] avg loss: 1.4293511337122697		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 1.2909070631105348 | validation: 1.0718121172911088]
	TIME [epoch: 8.78 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3574387903276233		[learning rate: 0.0087117]
		[batch 20/20] avg loss: 1.217141868711113		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 1.287290329519368 | validation: 0.9309990560228126]
	TIME [epoch: 8.78 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2232004334616873		[learning rate: 0.0086696]
		[batch 20/20] avg loss: 1.2252772316485312		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 1.224238832555109 | validation: 1.1522293962082881]
	TIME [epoch: 8.77 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1387981248939951		[learning rate: 0.0086277]
		[batch 20/20] avg loss: 1.3207453094683987		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 1.229771717181197 | validation: 1.4446660479985358]
	TIME [epoch: 8.78 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3034724848968968		[learning rate: 0.008586]
		[batch 20/20] avg loss: 1.1622543239678425		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 1.2328634044323699 | validation: 1.0267005316993705]
	TIME [epoch: 8.76 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1991137363236657		[learning rate: 0.0085445]
		[batch 20/20] avg loss: 1.147379904386361		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 1.1732468203550135 | validation: 1.473334291151804]
	TIME [epoch: 8.79 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1267981015646185		[learning rate: 0.0085031]
		[batch 20/20] avg loss: 1.5413719440108495		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 1.3340850227877339 | validation: 1.0708856675488025]
	TIME [epoch: 8.76 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1106979360231608		[learning rate: 0.008462]
		[batch 20/20] avg loss: 1.114114521984169		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 1.1124062290036651 | validation: 1.3155494623003532]
	TIME [epoch: 8.78 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1455532842722969		[learning rate: 0.0084211]
		[batch 20/20] avg loss: 1.2054440060283904		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 1.1754986451503435 | validation: 0.9623792574971786]
	TIME [epoch: 8.76 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.130481237053496		[learning rate: 0.0083804]
		[batch 20/20] avg loss: 1.2484202490363963		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 1.1894507430449461 | validation: 1.465620388266588]
	TIME [epoch: 8.77 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1769929330612858		[learning rate: 0.0083398]
		[batch 20/20] avg loss: 1.1306374370921943		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 1.15381518507674 | validation: 1.0231275811499156]
	TIME [epoch: 8.79 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1559864031106648		[learning rate: 0.0082995]
		[batch 20/20] avg loss: 1.0688288663310694		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 1.1124076347208671 | validation: 1.2504613877122515]
	TIME [epoch: 8.77 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2373591358945268		[learning rate: 0.0082594]
		[batch 20/20] avg loss: 1.08236479856508		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 1.1598619672298036 | validation: 0.9598887780258949]
	TIME [epoch: 8.77 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0882027132345093		[learning rate: 0.0082194]
		[batch 20/20] avg loss: 1.1027679844082618		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 1.0954853488213856 | validation: 1.7248001481085389]
	TIME [epoch: 8.77 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1480931165945298		[learning rate: 0.0081797]
		[batch 20/20] avg loss: 1.2116155853167687		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 1.1798543509556494 | validation: 1.009443299276841]
	TIME [epoch: 8.76 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0907209191782599		[learning rate: 0.0081401]
		[batch 20/20] avg loss: 1.1670159757751164		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 1.1288684474766881 | validation: 1.178386649641367]
	TIME [epoch: 8.77 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2597099118951829		[learning rate: 0.0081008]
		[batch 20/20] avg loss: 1.2163377708873049		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 1.2380238413912434 | validation: 1.1247773199292728]
	TIME [epoch: 8.77 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.19782023066286		[learning rate: 0.0080616]
		[batch 20/20] avg loss: 1.2764463046193544		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 1.237133267641107 | validation: 1.4898805113729887]
	TIME [epoch: 8.76 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.355950947521427		[learning rate: 0.0080226]
		[batch 20/20] avg loss: 1.3744576458621092		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 1.3652042966917681 | validation: 1.0060427242945154]
	TIME [epoch: 8.77 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1359472247752327		[learning rate: 0.0079838]
		[batch 20/20] avg loss: 1.2768147879977598		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 1.2063810063864961 | validation: 0.9590008523002501]
	TIME [epoch: 8.77 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.271062742642663		[learning rate: 0.0079452]
		[batch 20/20] avg loss: 1.1661935046559768		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 1.2186281236493202 | validation: 1.0142885437852998]
	TIME [epoch: 8.78 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1057967383796095		[learning rate: 0.0079068]
		[batch 20/20] avg loss: 1.3014364181190863		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 1.2036165782493478 | validation: 1.0735954725215873]
	TIME [epoch: 8.79 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1081585263564144		[learning rate: 0.0078685]
		[batch 20/20] avg loss: 1.1637722321414061		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 1.1359653792489097 | validation: 1.5595210067084166]
	TIME [epoch: 8.78 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2675131318724353		[learning rate: 0.0078305]
		[batch 20/20] avg loss: 1.2739494476230415		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 1.2707312897477385 | validation: 1.098425204529124]
	TIME [epoch: 8.77 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2173524454509217		[learning rate: 0.0077926]
		[batch 20/20] avg loss: 1.1955803313732851		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 1.2064663884121036 | validation: 0.8242346558468917]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_102.pth
	Model improved!!!
EPOCH 103/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1082342285814075		[learning rate: 0.0077549]
		[batch 20/20] avg loss: 1.148341307975123		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 1.1282877682782655 | validation: 0.7876346732011943]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_103.pth
	Model improved!!!
EPOCH 104/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4192274590963465		[learning rate: 0.0077174]
		[batch 20/20] avg loss: 1.2921757925863584		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 1.3557016258413526 | validation: 1.4880515959387197]
	TIME [epoch: 8.77 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2531040502399027		[learning rate: 0.0076801]
		[batch 20/20] avg loss: 1.3051333675799404		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 1.2791187089099219 | validation: 1.0270332971824399]
	TIME [epoch: 8.77 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.130910518949607		[learning rate: 0.007643]
		[batch 20/20] avg loss: 1.112169506281232		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 1.1215400126154198 | validation: 1.938133178103619]
	TIME [epoch: 8.76 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2915938539853073		[learning rate: 0.007606]
		[batch 20/20] avg loss: 1.2088337635022208		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 1.2502138087437642 | validation: 1.5836786387041868]
	TIME [epoch: 8.78 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2452528486272523		[learning rate: 0.0075692]
		[batch 20/20] avg loss: 1.1790769074037222		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 1.212164878015487 | validation: 1.5377012559025474]
	TIME [epoch: 8.79 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1680769195223848		[learning rate: 0.0075326]
		[batch 20/20] avg loss: 1.2997963483687025		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 1.2339366339455435 | validation: 0.945364108541469]
	TIME [epoch: 8.79 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2067095415098046		[learning rate: 0.0074962]
		[batch 20/20] avg loss: 1.1799675223351702		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 1.1933385319224876 | validation: 1.9796313131404017]
	TIME [epoch: 8.78 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4487960237582382		[learning rate: 0.00746]
		[batch 20/20] avg loss: 1.2788787806735822		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 1.36383740221591 | validation: 0.9142761147695383]
	TIME [epoch: 9.05 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1214933528266955		[learning rate: 0.0074239]
		[batch 20/20] avg loss: 1.1014187353970566		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 1.111456044111876 | validation: 1.164999695955803]
	TIME [epoch: 8.77 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1391830414679878		[learning rate: 0.007388]
		[batch 20/20] avg loss: 1.1219792440529788		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 1.1305811427604833 | validation: 1.0655194556565188]
	TIME [epoch: 8.77 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.324098390391061		[learning rate: 0.0073523]
		[batch 20/20] avg loss: 1.1298662864306703		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 1.2269823384108656 | validation: 0.9249009427531776]
	TIME [epoch: 8.78 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1514102419222065		[learning rate: 0.0073167]
		[batch 20/20] avg loss: 1.2893736252376196		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 1.2203919335799134 | validation: 1.1306140877755884]
	TIME [epoch: 8.76 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.171804156557104		[learning rate: 0.0072813]
		[batch 20/20] avg loss: 1.2020814606500914		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 1.1869428086035978 | validation: 1.076216690946423]
	TIME [epoch: 8.76 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.341655091103651		[learning rate: 0.0072461]
		[batch 20/20] avg loss: 1.267335549588235		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 1.304495320345943 | validation: 0.9785903923741548]
	TIME [epoch: 8.78 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1908933004245832		[learning rate: 0.0072111]
		[batch 20/20] avg loss: 1.1575828462266429		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 1.1742380733256135 | validation: 0.8741893800024085]
	TIME [epoch: 8.76 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1618787184940622		[learning rate: 0.0071762]
		[batch 20/20] avg loss: 1.2004741033870059		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 1.1811764109405338 | validation: 0.9409485841988261]
	TIME [epoch: 8.78 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3417998610084125		[learning rate: 0.0071415]
		[batch 20/20] avg loss: 1.2033252514183024		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 1.2725625562133576 | validation: 1.073507233535705]
	TIME [epoch: 8.76 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.141015687445144		[learning rate: 0.007107]
		[batch 20/20] avg loss: 1.2135097552382637		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 1.1772627213417037 | validation: 0.7399532441976315]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_121.pth
	Model improved!!!
EPOCH 122/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3479385351675428		[learning rate: 0.0070726]
		[batch 20/20] avg loss: 1.138780991545369		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 1.2433597633564561 | validation: 1.2394669820700641]
	TIME [epoch: 8.76 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3990804654404774		[learning rate: 0.0070384]
		[batch 20/20] avg loss: 1.1996899492941888		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 1.2993852073673335 | validation: 0.8767771512426157]
	TIME [epoch: 8.77 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1047081279588273		[learning rate: 0.0070044]
		[batch 20/20] avg loss: 1.0983531284508639		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 1.1015306282048454 | validation: 0.8423128707986238]
	TIME [epoch: 8.79 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0560827564243382		[learning rate: 0.0069705]
		[batch 20/20] avg loss: 1.115658346630305		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 1.085870551527322 | validation: 0.939045644685734]
	TIME [epoch: 8.77 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2634883197295812		[learning rate: 0.0069368]
		[batch 20/20] avg loss: 1.1198429778767691		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 1.1916656488031752 | validation: 0.9074075524395366]
	TIME [epoch: 8.77 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2136550299424358		[learning rate: 0.0069032]
		[batch 20/20] avg loss: 1.0724770995533983		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 1.143066064747917 | validation: 0.7216579105304132]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_127.pth
	Model improved!!!
EPOCH 128/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4809107242423516		[learning rate: 0.0068699]
		[batch 20/20] avg loss: 1.1177794323885473		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 1.2993450783154492 | validation: 1.0018616485593597]
	TIME [epoch: 8.77 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0826871186992526		[learning rate: 0.0068366]
		[batch 20/20] avg loss: 1.1155811363956432		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 1.099134127547448 | validation: 0.9766502797807346]
	TIME [epoch: 8.78 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0757389660157188		[learning rate: 0.0068036]
		[batch 20/20] avg loss: 1.0845037398357529		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 1.0801213529257359 | validation: 1.318012409134537]
	TIME [epoch: 8.79 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0898911186357843		[learning rate: 0.0067707]
		[batch 20/20] avg loss: 1.352804008516093		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 1.2213475635759388 | validation: 1.5297145582062464]
	TIME [epoch: 8.77 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2045766795831123		[learning rate: 0.0067379]
		[batch 20/20] avg loss: 1.0409143666181104		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 1.1227455231006114 | validation: 0.9752766096273191]
	TIME [epoch: 8.76 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0818409713154569		[learning rate: 0.0067053]
		[batch 20/20] avg loss: 1.3411106510003914		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 1.2114758111579245 | validation: 0.9442342450525147]
	TIME [epoch: 8.77 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1268135249501823		[learning rate: 0.0066729]
		[batch 20/20] avg loss: 1.0708012837238274		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 1.0988074043370049 | validation: 0.8251626152406527]
	TIME [epoch: 8.77 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0390265130123721		[learning rate: 0.0066406]
		[batch 20/20] avg loss: 1.0704339099786015		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 1.0547302114954868 | validation: 0.721317384593612]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_135.pth
	Model improved!!!
EPOCH 136/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0623016908164158		[learning rate: 0.0066085]
		[batch 20/20] avg loss: 1.048961370679791		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 1.0556315307481032 | validation: 0.91308816056936]
	TIME [epoch: 8.78 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9149800779818159		[learning rate: 0.0065766]
		[batch 20/20] avg loss: 1.1099508559562157		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 1.0124654669690158 | validation: 0.6961893959940341]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_137.pth
	Model improved!!!
EPOCH 138/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.211505034040813		[learning rate: 0.0065448]
		[batch 20/20] avg loss: 1.0867447857615273		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 1.14912490990117 | validation: 1.2527302373751403]
	TIME [epoch: 8.76 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1036479337841134		[learning rate: 0.0065131]
		[batch 20/20] avg loss: 1.1906120856903115		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 1.1471300097372124 | validation: 0.9690729673485693]
	TIME [epoch: 8.76 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9788403640192638		[learning rate: 0.0064816]
		[batch 20/20] avg loss: 1.1322812780906948		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 1.0555608210549794 | validation: 0.9837504288767968]
	TIME [epoch: 8.78 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9699364061503243		[learning rate: 0.0064503]
		[batch 20/20] avg loss: 1.2337245186800765		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 1.1018304624152002 | validation: 0.9540248379551926]
	TIME [epoch: 8.77 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1307834604830422		[learning rate: 0.0064191]
		[batch 20/20] avg loss: 1.260754117225673		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 1.1957687888543576 | validation: 0.8390207613657169]
	TIME [epoch: 8.76 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9509604362219589		[learning rate: 0.0063881]
		[batch 20/20] avg loss: 1.0063865294354262		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.9786734828286925 | validation: 2.1985963124675383]
	TIME [epoch: 8.77 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2335533383789703		[learning rate: 0.0063572]
		[batch 20/20] avg loss: 1.007890228265395		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 1.1207217833221825 | validation: 0.7921724659115295]
	TIME [epoch: 8.77 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9863197621396983		[learning rate: 0.0063264]
		[batch 20/20] avg loss: 1.0491366709658254		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 1.0177282165527621 | validation: 0.8171166240126354]
	TIME [epoch: 8.79 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.917405013660207		[learning rate: 0.0062958]
		[batch 20/20] avg loss: 0.9284849296758937		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.9229449716680502 | validation: 0.9553388365537194]
	TIME [epoch: 8.77 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1265484505747345		[learning rate: 0.0062654]
		[batch 20/20] avg loss: 1.0188299899565567		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 1.0726892202656455 | validation: 0.6810033605173853]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_147.pth
	Model improved!!!
EPOCH 148/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9934274457273828		[learning rate: 0.0062351]
		[batch 20/20] avg loss: 0.9542769646920906		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.9738522052097368 | validation: 0.8360060216067435]
	TIME [epoch: 8.77 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3507733751966216		[learning rate: 0.0062049]
		[batch 20/20] avg loss: 0.9609986896215845		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 1.155886032409103 | validation: 1.2077297989184628]
	TIME [epoch: 8.76 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9242859969266399		[learning rate: 0.0061749]
		[batch 20/20] avg loss: 1.0731242221847161		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.9987051095556779 | validation: 1.0611893924959228]
	TIME [epoch: 8.79 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9889565887963553		[learning rate: 0.0061451]
		[batch 20/20] avg loss: 1.1660402728119552		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 1.0774984308041553 | validation: 1.0278733323751272]
	TIME [epoch: 8.77 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9568889761565706		[learning rate: 0.0061153]
		[batch 20/20] avg loss: 0.900433562331043		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.928661269243807 | validation: 0.7628234802907616]
	TIME [epoch: 8.77 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8697193716098349		[learning rate: 0.0060858]
		[batch 20/20] avg loss: 1.0054023682112412		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.9375608699105381 | validation: 0.6899144198912857]
	TIME [epoch: 8.78 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9005113786872808		[learning rate: 0.0060563]
		[batch 20/20] avg loss: 1.1148379411841263		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 1.0076746599357036 | validation: 0.5715864009201358]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_154.pth
	Model improved!!!
EPOCH 155/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8295294274139596		[learning rate: 0.0060271]
		[batch 20/20] avg loss: 0.9110803707763425		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.8703048990951509 | validation: 0.8142243103241389]
	TIME [epoch: 8.8 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.118327063622648		[learning rate: 0.0059979]
		[batch 20/20] avg loss: 0.9757845124385425		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 1.0470557880305953 | validation: 0.607557444235493]
	TIME [epoch: 8.78 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8634666555193118		[learning rate: 0.0059689]
		[batch 20/20] avg loss: 1.0534057706292381		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.9584362130742748 | validation: 0.8091146520501483]
	TIME [epoch: 8.77 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9252953123821281		[learning rate: 0.00594]
		[batch 20/20] avg loss: 0.9939608763313027		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.9596280943567154 | validation: 0.6663947099359196]
	TIME [epoch: 8.79 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8333076472612074		[learning rate: 0.0059113]
		[batch 20/20] avg loss: 1.2970142492398244		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 1.0651609482505158 | validation: 1.3900698921982266]
	TIME [epoch: 8.78 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9724599085488974		[learning rate: 0.0058827]
		[batch 20/20] avg loss: 1.5388481428818648		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 1.2556540257153812 | validation: 0.9664365762083518]
	TIME [epoch: 8.79 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3491224198117213		[learning rate: 0.0058543]
		[batch 20/20] avg loss: 1.1645703295324898		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 1.2568463746721057 | validation: 0.6662578505525707]
	TIME [epoch: 8.78 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.008235627252218		[learning rate: 0.005826]
		[batch 20/20] avg loss: 1.0178474397639103		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 1.013041533508064 | validation: 2.6984632534791064]
	TIME [epoch: 8.77 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4420597971971867		[learning rate: 0.0057978]
		[batch 20/20] avg loss: 1.3707840072866602		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 1.4064219022419235 | validation: 0.4373765331019953]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_163.pth
	Model improved!!!
EPOCH 164/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9769881136069658		[learning rate: 0.0057698]
		[batch 20/20] avg loss: 1.3319975716442947		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 1.1544928426256305 | validation: 1.4874911996836673]
	TIME [epoch: 8.78 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0108004147854444		[learning rate: 0.0057419]
		[batch 20/20] avg loss: 1.0473930400147329		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 1.0290967274000886 | validation: 1.2101347182514415]
	TIME [epoch: 8.78 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0580817251602288		[learning rate: 0.0057141]
		[batch 20/20] avg loss: 0.9795979217797383		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 1.0188398234699834 | validation: 0.6022816439638548]
	TIME [epoch: 8.78 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5259231132929532		[learning rate: 0.0056865]
		[batch 20/20] avg loss: 1.504474113227213		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 1.515198613260083 | validation: 0.5303352240523083]
	TIME [epoch: 8.78 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4641059610466327		[learning rate: 0.005659]
		[batch 20/20] avg loss: 0.9690984288834061		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 1.216602194965019 | validation: 1.5768655346625997]
	TIME [epoch: 8.79 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.57653435373497		[learning rate: 0.0056316]
		[batch 20/20] avg loss: 1.1962558514473949		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 1.3863951025911825 | validation: 1.4180964249704902]
	TIME [epoch: 8.79 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8930509166322874		[learning rate: 0.0056044]
		[batch 20/20] avg loss: 0.8591336899433134		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.8760923032878004 | validation: 1.0235420855551411]
	TIME [epoch: 8.79 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8252590289131663		[learning rate: 0.0055773]
		[batch 20/20] avg loss: 0.9564157341153428		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.8908373815142545 | validation: 3.1460089118392847]
	TIME [epoch: 8.79 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.326395588702543		[learning rate: 0.0055503]
		[batch 20/20] avg loss: 1.0934740228799988		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 1.2099348057912707 | validation: 1.0056294088090474]
	TIME [epoch: 8.78 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.925777066726193		[learning rate: 0.0055235]
		[batch 20/20] avg loss: 0.9132972079969193		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.9195371373615563 | validation: 1.1505882194740722]
	TIME [epoch: 8.77 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1454146361940167		[learning rate: 0.0054967]
		[batch 20/20] avg loss: 1.0523386460699515		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 1.0988766411319841 | validation: 0.5129312857895352]
	TIME [epoch: 8.77 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8185476574320608		[learning rate: 0.0054702]
		[batch 20/20] avg loss: 1.1561367312042676		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.9873421943181642 | validation: 3.4025408785709277]
	TIME [epoch: 8.78 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5057960125136498		[learning rate: 0.0054437]
		[batch 20/20] avg loss: 0.804743055776251		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 1.1552695341449506 | validation: 0.5451982824491259]
	TIME [epoch: 8.8 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7939855499526689		[learning rate: 0.0054174]
		[batch 20/20] avg loss: 0.8300816060562047		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.812033578004437 | validation: 0.6175241189402996]
	TIME [epoch: 8.79 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7660172085483087		[learning rate: 0.0053912]
		[batch 20/20] avg loss: 0.890167220153239		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.8280922143507737 | validation: 0.4248955829064507]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_178.pth
	Model improved!!!
EPOCH 179/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8521357533126347		[learning rate: 0.0053651]
		[batch 20/20] avg loss: 0.7841789507805105		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.8181573520465724 | validation: 0.7774688866970638]
	TIME [epoch: 8.78 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7538635740673941		[learning rate: 0.0053392]
		[batch 20/20] avg loss: 0.9306741866609747		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.8422688803641846 | validation: 0.6505187761151442]
	TIME [epoch: 8.78 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8621298770855415		[learning rate: 0.0053133]
		[batch 20/20] avg loss: 1.546679633700849		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 1.2044047553931951 | validation: 1.833921296719097]
	TIME [epoch: 8.8 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8616181230858017		[learning rate: 0.0052877]
		[batch 20/20] avg loss: 1.292674403662421		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 1.0771462633741116 | validation: 0.4569617471934746]
	TIME [epoch: 8.78 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8055240870753011		[learning rate: 0.0052621]
		[batch 20/20] avg loss: 1.0517043878093562		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.9286142374423285 | validation: 0.30801487386493553]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_183.pth
	Model improved!!!
EPOCH 184/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1671649632613854		[learning rate: 0.0052366]
		[batch 20/20] avg loss: 0.856639314627839		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 1.011902138944612 | validation: 0.6137230546565631]
	TIME [epoch: 8.78 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9471238017749519		[learning rate: 0.0052113]
		[batch 20/20] avg loss: 0.9867918850349067		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.9669578434049292 | validation: 0.5788966668887671]
	TIME [epoch: 8.78 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.088954681724449		[learning rate: 0.0051861]
		[batch 20/20] avg loss: 0.955850652824536		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 1.0224026672744926 | validation: 1.9032457876783262]
	TIME [epoch: 8.8 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.069379246707833		[learning rate: 0.005161]
		[batch 20/20] avg loss: 0.8834471473271414		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.9764131970174873 | validation: 0.4393072401612009]
	TIME [epoch: 8.77 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9303617396307396		[learning rate: 0.0051361]
		[batch 20/20] avg loss: 0.9933901078539653		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.9618759237423523 | validation: 0.5655428365587605]
	TIME [epoch: 8.78 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8535862963690045		[learning rate: 0.0051112]
		[batch 20/20] avg loss: 1.6965350405243338		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 1.2750606684466692 | validation: 1.9233140439631897]
	TIME [epoch: 8.77 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1942072382225573		[learning rate: 0.0050865]
		[batch 20/20] avg loss: 1.3305187437286263		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 1.2623629909755918 | validation: 1.6572415697256262]
	TIME [epoch: 8.77 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0641989746051737		[learning rate: 0.0050619]
		[batch 20/20] avg loss: 1.3094122176975849		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 1.1868055961513795 | validation: 0.9330462311461877]
	TIME [epoch: 8.78 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9038041304815572		[learning rate: 0.0050374]
		[batch 20/20] avg loss: 1.0061812193842983		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.9549926749329275 | validation: 0.6320818978724017]
	TIME [epoch: 8.79 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8824811462596258		[learning rate: 0.0050131]
		[batch 20/20] avg loss: 0.7874650741309		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.8349731101952628 | validation: 0.8176273411774052]
	TIME [epoch: 8.76 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8134099738329714		[learning rate: 0.0049888]
		[batch 20/20] avg loss: 1.0469744073445368		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.9301921905887541 | validation: 0.7862133400364193]
	TIME [epoch: 8.77 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8952779912666688		[learning rate: 0.0049647]
		[batch 20/20] avg loss: 0.8432436051141543		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.8692607981904116 | validation: 0.6942411825282645]
	TIME [epoch: 8.78 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.832791224524214		[learning rate: 0.0049407]
		[batch 20/20] avg loss: 2.0861005537863866		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 1.4594458891553004 | validation: 0.6606384649712983]
	TIME [epoch: 8.78 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8006627368060378		[learning rate: 0.0049168]
		[batch 20/20] avg loss: 1.0600399854887042		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.9303513611473709 | validation: 1.5021991457966322]
	TIME [epoch: 8.8 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1178408480294089		[learning rate: 0.004893]
		[batch 20/20] avg loss: 0.9578894319217959		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 1.0378651399756025 | validation: 0.6755406143455381]
	TIME [epoch: 8.78 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6945326211744618		[learning rate: 0.0048694]
		[batch 20/20] avg loss: 0.7949274813484921		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.7447300512614768 | validation: 0.7599834944194195]
	TIME [epoch: 8.78 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7316332262411056		[learning rate: 0.0048458]
		[batch 20/20] avg loss: 0.8476515313054728		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.7896423787732891 | validation: 0.94160879917338]
	TIME [epoch: 8.76 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8076169925301689		[learning rate: 0.0048224]
		[batch 20/20] avg loss: 0.684010678723309		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.7458138356267389 | validation: 0.2364186869106752]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_201.pth
	Model improved!!!
EPOCH 202/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7218277291505049		[learning rate: 0.0047991]
		[batch 20/20] avg loss: 0.6979260516847641		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.7098768904176345 | validation: 0.751209688897935]
	TIME [epoch: 8.81 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7922699801830347		[learning rate: 0.0047759]
		[batch 20/20] avg loss: 0.8031187664061636		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.7976943732945992 | validation: 0.6977977345935643]
	TIME [epoch: 8.78 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9623187581374577		[learning rate: 0.0047528]
		[batch 20/20] avg loss: 0.9498267131250708		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.9560727356312645 | validation: 1.1786398353128433]
	TIME [epoch: 8.77 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8145024810737889		[learning rate: 0.0047298]
		[batch 20/20] avg loss: 0.7379130298940396		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.7762077554839142 | validation: 0.5156205903748767]
	TIME [epoch: 8.77 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7089746302196482		[learning rate: 0.0047069]
		[batch 20/20] avg loss: 0.6495713831875577		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.6792730067036029 | validation: 0.6112557753432315]
	TIME [epoch: 8.78 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.741535550395924		[learning rate: 0.0046842]
		[batch 20/20] avg loss: 0.6814909431825986		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.7115132467892613 | validation: 0.38640848146841367]
	TIME [epoch: 8.8 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.74943962818396		[learning rate: 0.0046615]
		[batch 20/20] avg loss: 0.660052748096301		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.7047461881401305 | validation: 0.5789838669475423]
	TIME [epoch: 8.78 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7175167186217125		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.6875518593386893		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.7025342889802009 | validation: 2.002608987538121]
	TIME [epoch: 8.77 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0250046240392818		[learning rate: 0.0046165]
		[batch 20/20] avg loss: 0.7253640381100777		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.8751843310746796 | validation: 0.7894241140508691]
	TIME [epoch: 8.78 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7446479797922777		[learning rate: 0.0045942]
		[batch 20/20] avg loss: 0.8326555681077098		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.7886517739499939 | validation: 0.7831340512933114]
	TIME [epoch: 8.77 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7188170767378265		[learning rate: 0.004572]
		[batch 20/20] avg loss: 1.1855206274371755		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.9521688520875008 | validation: 0.5423707347865567]
	TIME [epoch: 8.79 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6704965843523282		[learning rate: 0.0045499]
		[batch 20/20] avg loss: 0.7565165453873796		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.713506564869854 | validation: 0.7742965249980258]
	TIME [epoch: 8.78 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9757214544949564		[learning rate: 0.0045279]
		[batch 20/20] avg loss: 0.9924490724423635		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.9840852634686599 | validation: 0.5141015103479245]
	TIME [epoch: 8.77 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8119203933957767		[learning rate: 0.004506]
		[batch 20/20] avg loss: 0.8118078911297383		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.8118641422627576 | validation: 1.0746753417449297]
	TIME [epoch: 8.78 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8158112845526956		[learning rate: 0.0044842]
		[batch 20/20] avg loss: 0.9007189157648222		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.8582651001587591 | validation: 0.7563869383381188]
	TIME [epoch: 8.77 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7058726548207063		[learning rate: 0.0044625]
		[batch 20/20] avg loss: 0.7819846444348404		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.7439286496277734 | validation: 0.4004414918068334]
	TIME [epoch: 8.79 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7375334526086094		[learning rate: 0.0044409]
		[batch 20/20] avg loss: 0.7656747678268708		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.7516041102177401 | validation: 1.656303063688049]
	TIME [epoch: 8.79 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9501262977986992		[learning rate: 0.0044195]
		[batch 20/20] avg loss: 0.6932776505927654		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.8217019741957323 | validation: 1.0126353582477816]
	TIME [epoch: 8.79 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9183236938017316		[learning rate: 0.0043981]
		[batch 20/20] avg loss: 0.8222127151532164		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.8702682044774738 | validation: 0.4718428866357971]
	TIME [epoch: 8.78 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8108533850615046		[learning rate: 0.0043768]
		[batch 20/20] avg loss: 1.0993503184404205		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.9551018517509625 | validation: 0.9472585342727241]
	TIME [epoch: 8.78 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7906046199949974		[learning rate: 0.0043556]
		[batch 20/20] avg loss: 0.6193580764066838		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.7049813482008407 | validation: 0.6011885462363692]
	TIME [epoch: 8.79 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7749135158731828		[learning rate: 0.0043346]
		[batch 20/20] avg loss: 0.6970216666425546		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.7359675912578688 | validation: 0.5911460910223796]
	TIME [epoch: 8.8 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7146969534508495		[learning rate: 0.0043136]
		[batch 20/20] avg loss: 0.8613260463668109		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.7880114999088301 | validation: 1.4741553665208194]
	TIME [epoch: 8.78 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0926507076257737		[learning rate: 0.0042928]
		[batch 20/20] avg loss: 0.7789355777067013		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.9357931426662377 | validation: 0.42115496817864717]
	TIME [epoch: 8.79 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7579591711430329		[learning rate: 0.004272]
		[batch 20/20] avg loss: 0.7430173613811419		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.7504882662620874 | validation: 0.5070699438938633]
	TIME [epoch: 8.77 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7446758237800406		[learning rate: 0.0042513]
		[batch 20/20] avg loss: 0.6866679711085272		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.7156718974442837 | validation: 0.418488170924312]
	TIME [epoch: 8.78 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.893536368002929		[learning rate: 0.0042308]
		[batch 20/20] avg loss: 0.9851706994496693		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.939353533726299 | validation: 1.6875665428231128]
	TIME [epoch: 8.78 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.072750997229266		[learning rate: 0.0042103]
		[batch 20/20] avg loss: 0.7668796285239524		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.9198153128766092 | validation: 0.9425647434942847]
	TIME [epoch: 8.77 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7723932400155298		[learning rate: 0.00419]
		[batch 20/20] avg loss: 0.7348430299905556		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.7536181350030428 | validation: 0.8717611134744492]
	TIME [epoch: 8.78 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6046246762117673		[learning rate: 0.0041697]
		[batch 20/20] avg loss: 1.1615564538487653		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.8830905650302665 | validation: 1.0934718631285014]
	TIME [epoch: 8.79 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8571376623516423		[learning rate: 0.0041495]
		[batch 20/20] avg loss: 0.7154556228592651		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.7862966426054536 | validation: 0.89272527582878]
	TIME [epoch: 8.79 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7834237923118176		[learning rate: 0.0041295]
		[batch 20/20] avg loss: 1.0714245780296978		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.9274241851707579 | validation: 0.8139523115188709]
	TIME [epoch: 8.8 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0917986395126902		[learning rate: 0.0041095]
		[batch 20/20] avg loss: 0.7904149426150028		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.9411067910638463 | validation: 0.8098566679182385]
	TIME [epoch: 8.78 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8593972002421791		[learning rate: 0.0040896]
		[batch 20/20] avg loss: 0.7405371934652907		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.799967196853735 | validation: 1.2867648736453052]
	TIME [epoch: 8.77 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0908609774174651		[learning rate: 0.0040699]
		[batch 20/20] avg loss: 1.101883743108586		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 1.0963723602630255 | validation: 0.44419397928878696]
	TIME [epoch: 8.78 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6810825113966726		[learning rate: 0.0040502]
		[batch 20/20] avg loss: 0.7434855594473634		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.712284035422018 | validation: 0.38176390878251276]
	TIME [epoch: 8.78 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8783394783006265		[learning rate: 0.0040306]
		[batch 20/20] avg loss: 0.9277946335304813		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.903067055915554 | validation: 0.3966673032210498]
	TIME [epoch: 8.8 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9392913579354769		[learning rate: 0.0040111]
		[batch 20/20] avg loss: 0.603449772007455		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.7713705649714659 | validation: 0.36822499843144246]
	TIME [epoch: 8.79 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.054622424132007		[learning rate: 0.0039917]
		[batch 20/20] avg loss: 0.6936458043806417		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.8741341142563245 | validation: 0.8901003927633743]
	TIME [epoch: 8.78 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9816634157815575		[learning rate: 0.0039724]
		[batch 20/20] avg loss: 0.697887746844333		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.8397755813129454 | validation: 0.43988240803157264]
	TIME [epoch: 8.78 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.726240575220083		[learning rate: 0.0039532]
		[batch 20/20] avg loss: 0.718854377101882		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.7225474761609825 | validation: 0.7310084563334229]
	TIME [epoch: 8.78 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.705887154790733		[learning rate: 0.0039341]
		[batch 20/20] avg loss: 0.9386844386914444		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.8222857967410887 | validation: 0.7238906036621162]
	TIME [epoch: 8.81 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7163597447590359		[learning rate: 0.003915]
		[batch 20/20] avg loss: 0.6478975915264396		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.6821286681427378 | validation: 0.835266890033957]
	TIME [epoch: 8.78 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7190182906159277		[learning rate: 0.0038961]
		[batch 20/20] avg loss: 0.9041077861459564		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.8115630383809419 | validation: 0.3766000811072008]
	TIME [epoch: 8.84 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8032774077966686		[learning rate: 0.0038773]
		[batch 20/20] avg loss: 0.8694933880185463		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.8363853979076072 | validation: 0.6699079532202726]
	TIME [epoch: 8.78 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.59986538153672		[learning rate: 0.0038585]
		[batch 20/20] avg loss: 0.8871096941636821		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.7434875378502012 | validation: 0.6815722961950482]
	TIME [epoch: 8.78 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8881073415796195		[learning rate: 0.0038399]
		[batch 20/20] avg loss: 0.6183854499313013		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.7532463957554603 | validation: 0.5512289317420617]
	TIME [epoch: 8.8 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8556831267852612		[learning rate: 0.0038213]
		[batch 20/20] avg loss: 0.5557303731660965		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.705706749975679 | validation: 0.4499431781257177]
	TIME [epoch: 8.78 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5976823685979771		[learning rate: 0.0038028]
		[batch 20/20] avg loss: 0.9064305294226978		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.7520564490103373 | validation: 0.469057913439555]
	TIME [epoch: 8.78 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5923262259033494		[learning rate: 0.0037844]
		[batch 20/20] avg loss: 0.6202613252175493		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.6062937755604494 | validation: 0.5650772254048028]
	TIME [epoch: 8.77 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8159115147076461		[learning rate: 0.0037661]
		[batch 20/20] avg loss: 0.6509928952465875		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.7334522049771169 | validation: 0.3142087613364647]
	TIME [epoch: 8.79 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6185350574322839		[learning rate: 0.0037479]
		[batch 20/20] avg loss: 1.3155026828280731		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.9670188701301786 | validation: 0.43339898363910734]
	TIME [epoch: 8.78 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5830770627581932		[learning rate: 0.0037298]
		[batch 20/20] avg loss: 0.5314496583153663		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.5572633605367798 | validation: 0.42459307288991577]
	TIME [epoch: 8.8 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6294137071243585		[learning rate: 0.0037118]
		[batch 20/20] avg loss: 0.5987080230282136		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.6140608650762861 | validation: 1.0664337492948972]
	TIME [epoch: 8.77 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.730008953538539		[learning rate: 0.0036938]
		[batch 20/20] avg loss: 0.5726387043766827		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.6513238289576109 | validation: 0.31814985056137296]
	TIME [epoch: 8.77 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.848442776343908		[learning rate: 0.0036759]
		[batch 20/20] avg loss: 0.572690790027147		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.7105667831855275 | validation: 0.6596195203337787]
	TIME [epoch: 8.77 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6069068378996784		[learning rate: 0.0036582]
		[batch 20/20] avg loss: 0.5740780397221547		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.5904924388109165 | validation: 0.3192260840142548]
	TIME [epoch: 8.78 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4730375558957395		[learning rate: 0.0036405]
		[batch 20/20] avg loss: 0.5877041651160483		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.5303708605058939 | validation: 0.45179423044801104]
	TIME [epoch: 8.78 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8059023729339879		[learning rate: 0.0036229]
		[batch 20/20] avg loss: 0.8156999232609484		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.8108011480974682 | validation: 0.49149333052407235]
	TIME [epoch: 8.79 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7124847611084453		[learning rate: 0.0036053]
		[batch 20/20] avg loss: 0.7628841763689226		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.7376844687386839 | validation: 0.346685873792923]
	TIME [epoch: 8.79 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48652207015544346		[learning rate: 0.0035879]
		[batch 20/20] avg loss: 0.6842788043472119		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.5854004372513277 | validation: 0.9033624361467668]
	TIME [epoch: 8.78 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8667910537461211		[learning rate: 0.0035706]
		[batch 20/20] avg loss: 0.8949278119865767		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.880859432866349 | validation: 0.6769262906569655]
	TIME [epoch: 8.78 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9084255233937549		[learning rate: 0.0035533]
		[batch 20/20] avg loss: 0.5773066659376667		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.7428660946657106 | validation: 0.26923732430380726]
	TIME [epoch: 8.8 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5801692063340529		[learning rate: 0.0035361]
		[batch 20/20] avg loss: 0.6294985953615795		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.6048339008478163 | validation: 0.6085272088635317]
	TIME [epoch: 8.89 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5995504583905333		[learning rate: 0.003519]
		[batch 20/20] avg loss: 0.551770940492945		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.5756606994417393 | validation: 1.9977999474811412]
	TIME [epoch: 8.78 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8862533165260553		[learning rate: 0.003502]
		[batch 20/20] avg loss: 0.4748494639769162		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.6805513902514859 | validation: 0.7284296522345838]
	TIME [epoch: 8.78 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6035729421862495		[learning rate: 0.0034851]
		[batch 20/20] avg loss: 0.5687092747089871		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.5861411084476182 | validation: 0.38970813204327437]
	TIME [epoch: 8.78 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6507449793284446		[learning rate: 0.0034682]
		[batch 20/20] avg loss: 0.8427518119896668		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.7467483956590557 | validation: 0.6227474668357191]
	TIME [epoch: 8.8 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6523885386612619		[learning rate: 0.0034514]
		[batch 20/20] avg loss: 0.48292497392368655		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.5676567562924743 | validation: 0.6574048943694326]
	TIME [epoch: 8.77 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4587798307066671		[learning rate: 0.0034347]
		[batch 20/20] avg loss: 0.6733662317653417		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.5660730312360044 | validation: 0.4063052032495566]
	TIME [epoch: 8.76 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7693417956503893		[learning rate: 0.0034181]
		[batch 20/20] avg loss: 0.6886082562969131		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.7289750259736512 | validation: 0.36367801595913585]
	TIME [epoch: 8.78 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6740739517401615		[learning rate: 0.0034016]
		[batch 20/20] avg loss: 0.5012759682917001		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.5876749600159308 | validation: 0.4642131168177492]
	TIME [epoch: 8.76 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5554844375302189		[learning rate: 0.0033852]
		[batch 20/20] avg loss: 0.5101126589063283		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.5327985482182737 | validation: 0.2896143223968475]
	TIME [epoch: 8.79 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39277782170342024		[learning rate: 0.0033688]
		[batch 20/20] avg loss: 0.5320780344693709		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.46242792808639555 | validation: 0.46664711808789966]
	TIME [epoch: 8.77 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5971316022853599		[learning rate: 0.0033525]
		[batch 20/20] avg loss: 0.5191768699805223		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.558154236132941 | validation: 0.3906046378092929]
	TIME [epoch: 8.77 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7907067501027437		[learning rate: 0.0033363]
		[batch 20/20] avg loss: 0.7638222351830992		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.7772644926429215 | validation: 0.7644345190534831]
	TIME [epoch: 8.77 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7374220458640639		[learning rate: 0.0033202]
		[batch 20/20] avg loss: 0.4519405239854935		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.5946812849247787 | validation: 0.6535279204339015]
	TIME [epoch: 8.76 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6616801705394423		[learning rate: 0.0033041]
		[batch 20/20] avg loss: 0.7908063078945584		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.7262432392170004 | validation: 0.4797389247270222]
	TIME [epoch: 8.78 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4882983191100183		[learning rate: 0.0032881]
		[batch 20/20] avg loss: 0.4211310701601415		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.45471469463508 | validation: 0.3688559873040244]
	TIME [epoch: 8.79 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4367581159602548		[learning rate: 0.0032722]
		[batch 20/20] avg loss: 0.6311804289918916		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.5339692724760733 | validation: 0.5922838895412241]
	TIME [epoch: 8.79 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6639954513349587		[learning rate: 0.0032564]
		[batch 20/20] avg loss: 0.45548608008961367		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.5597407657122864 | validation: 0.6352017519821004]
	TIME [epoch: 8.76 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4922226720866688		[learning rate: 0.0032406]
		[batch 20/20] avg loss: 0.7073864928318354		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.5998045824592521 | validation: 1.0090349928744466]
	TIME [epoch: 8.77 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6591830803472949		[learning rate: 0.003225]
		[batch 20/20] avg loss: 0.6601484437854543		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.6596657620663746 | validation: 0.4908457660929843]
	TIME [epoch: 8.77 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4695263047979289		[learning rate: 0.0032094]
		[batch 20/20] avg loss: 0.6067571223194875		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.5381417135587082 | validation: 0.5150928380729898]
	TIME [epoch: 8.79 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6449547473138841		[learning rate: 0.0031939]
		[batch 20/20] avg loss: 0.39537368426120434		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.5201642157875442 | validation: 0.2872401886875977]
	TIME [epoch: 8.77 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6890398722228696		[learning rate: 0.0031784]
		[batch 20/20] avg loss: 0.7147907129820013		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.7019152926024353 | validation: 0.9221790302035099]
	TIME [epoch: 8.77 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6258985218475221		[learning rate: 0.003163]
		[batch 20/20] avg loss: 0.7148637362388582		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.6703811290431902 | validation: 0.7025060237241945]
	TIME [epoch: 8.76 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8331927065051989		[learning rate: 0.0031477]
		[batch 20/20] avg loss: 0.610587492038732		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.7218900992719653 | validation: 0.9996312233841407]
	TIME [epoch: 8.78 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6547199466899836		[learning rate: 0.0031325]
		[batch 20/20] avg loss: 0.5705696607374272		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.6126448037137054 | validation: 0.4550965701595897]
	TIME [epoch: 8.78 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5682901331040722		[learning rate: 0.0031174]
		[batch 20/20] avg loss: 0.648854746655026		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.608572439879549 | validation: 0.6786114784850149]
	TIME [epoch: 8.76 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.44709066192235414		[learning rate: 0.0031023]
		[batch 20/20] avg loss: 0.42059315957894317		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.43384191075064854 | validation: 0.4286951356805906]
	TIME [epoch: 8.77 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6567514595706461		[learning rate: 0.0030873]
		[batch 20/20] avg loss: 0.8690898213041753		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.7629206404374107 | validation: 0.5399425312422648]
	TIME [epoch: 8.77 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6994261373171469		[learning rate: 0.0030724]
		[batch 20/20] avg loss: 0.5906015686657745		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.6450138529914607 | validation: 0.2954347897328218]
	TIME [epoch: 8.77 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6398838515908116		[learning rate: 0.0030575]
		[batch 20/20] avg loss: 0.6963185690349641		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.6681012103128878 | validation: 0.24318965995449707]
	TIME [epoch: 8.8 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5772234693019307		[learning rate: 0.0030427]
		[batch 20/20] avg loss: 0.6976425551204902		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.6374330122112105 | validation: 0.34644519275967517]
	TIME [epoch: 8.77 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6531245942093638		[learning rate: 0.003028]
		[batch 20/20] avg loss: 0.459234677694524		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.5561796359519438 | validation: 0.2511369225988452]
	TIME [epoch: 8.76 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7250090623061485		[learning rate: 0.0030134]
		[batch 20/20] avg loss: 0.6800479233206973		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.702528492813423 | validation: 0.32909246963332234]
	TIME [epoch: 8.77 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47057310721345164		[learning rate: 0.0029988]
		[batch 20/20] avg loss: 0.4317474290385973		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.4511602681260244 | validation: 1.1004161894145905]
	TIME [epoch: 8.77 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6870504172964197		[learning rate: 0.0029843]
		[batch 20/20] avg loss: 0.5123803567556748		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.5997153870260473 | validation: 0.2507189258265708]
	TIME [epoch: 8.8 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46172167569558215		[learning rate: 0.0029699]
		[batch 20/20] avg loss: 0.4238508553542058		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.442786265524894 | validation: 0.3467564968505207]
	TIME [epoch: 8.77 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43801464989992667		[learning rate: 0.0029555]
		[batch 20/20] avg loss: 0.44557026132928534		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.4417924556146061 | validation: 0.46453612609365463]
	TIME [epoch: 8.78 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.555222259824723		[learning rate: 0.0029412]
		[batch 20/20] avg loss: 0.6612514928046263		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.6082368763146746 | validation: 1.0251965409973518]
	TIME [epoch: 8.79 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5734306589446495		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.6398608472934142		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.6066457531190319 | validation: 0.2740563276303405]
	TIME [epoch: 8.77 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5195346756788469		[learning rate: 0.0029128]
		[batch 20/20] avg loss: 0.47906938611552086		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.49930203089718395 | validation: 0.1643409740580874]
	TIME [epoch: 8.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_305.pth
	Model improved!!!
EPOCH 306/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4978400773829332		[learning rate: 0.0028987]
		[batch 20/20] avg loss: 0.42874240414624054		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.46329124076458694 | validation: 0.31243336310176867]
	TIME [epoch: 8.78 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3494867114702929		[learning rate: 0.0028847]
		[batch 20/20] avg loss: 0.4196558089845066		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.38457126022739974 | validation: 1.323659259174411]
	TIME [epoch: 8.77 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9486953989684173		[learning rate: 0.0028708]
		[batch 20/20] avg loss: 0.6096292248635055		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.7791623119159615 | validation: 0.7214723218105541]
	TIME [epoch: 8.77 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6386231934302883		[learning rate: 0.0028569]
		[batch 20/20] avg loss: 0.6985718879428624		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.6685975406865754 | validation: 0.6712455660312232]
	TIME [epoch: 8.78 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4371252076671083		[learning rate: 0.0028431]
		[batch 20/20] avg loss: 0.720371853578941		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.5787485306230248 | validation: 0.28543187806991427]
	TIME [epoch: 8.78 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5779383995619564		[learning rate: 0.0028293]
		[batch 20/20] avg loss: 0.7109118768150182		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.6444251381884872 | validation: 0.22565034785887972]
	TIME [epoch: 8.79 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38446044146590524		[learning rate: 0.0028157]
		[batch 20/20] avg loss: 0.4322409367326389		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.40835068909927213 | validation: 0.5089321509450174]
	TIME [epoch: 8.76 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4461077794818683		[learning rate: 0.002802]
		[batch 20/20] avg loss: 0.592851637198512		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.5194797083401903 | validation: 0.1551141338617986]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_313.pth
	Model improved!!!
EPOCH 314/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7114677088945538		[learning rate: 0.0027885]
		[batch 20/20] avg loss: 0.4931341877618102		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.602300948328182 | validation: 0.9560647748446781]
	TIME [epoch: 8.78 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.715674025698417		[learning rate: 0.002775]
		[batch 20/20] avg loss: 0.3633549474396644		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.5395144865690408 | validation: 1.0048397368629947]
	TIME [epoch: 8.79 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4583918404754478		[learning rate: 0.0027616]
		[batch 20/20] avg loss: 0.7072013779862834		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.5827966092308656 | validation: 0.2764585580982005]
	TIME [epoch: 8.79 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34938836277734353		[learning rate: 0.0027482]
		[batch 20/20] avg loss: 0.729107816688669		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.5392480897330062 | validation: 0.40437954829939615]
	TIME [epoch: 8.78 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7313457146412599		[learning rate: 0.0027349]
		[batch 20/20] avg loss: 0.5016981895461166		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.6165219520936882 | validation: 0.17193857525470954]
	TIME [epoch: 8.77 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6140893201943685		[learning rate: 0.0027217]
		[batch 20/20] avg loss: 0.4754929720863944		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.5447911461403815 | validation: 0.7123903984615156]
	TIME [epoch: 8.78 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6838937813712328		[learning rate: 0.0027086]
		[batch 20/20] avg loss: 0.622494262412147		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.6531940218916898 | validation: 0.3526500590987536]
	TIME [epoch: 8.78 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4309211866075751		[learning rate: 0.0026955]
		[batch 20/20] avg loss: 0.4576250983961819		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.4442731425018785 | validation: 0.18826152292826484]
	TIME [epoch: 8.81 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5494841764963968		[learning rate: 0.0026824]
		[batch 20/20] avg loss: 0.5369520602456033		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.543218118371 | validation: 0.46234432557604616]
	TIME [epoch: 8.78 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.571046733639037		[learning rate: 0.0026694]
		[batch 20/20] avg loss: 0.7313370273502733		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.6511918804946553 | validation: 0.2831142437789219]
	TIME [epoch: 8.77 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4012891222920594		[learning rate: 0.0026565]
		[batch 20/20] avg loss: 0.40079345079671774		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.40104128654438853 | validation: 0.44241407282957534]
	TIME [epoch: 8.78 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4690376536308481		[learning rate: 0.0026437]
		[batch 20/20] avg loss: 0.3556935569655337		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.4123656052981909 | validation: 0.24390476158581464]
	TIME [epoch: 8.78 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31938648109341716		[learning rate: 0.0026309]
		[batch 20/20] avg loss: 0.7303099254825829		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.5248482032880001 | validation: 0.16129531918847723]
	TIME [epoch: 8.79 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5638813895635544		[learning rate: 0.0026182]
		[batch 20/20] avg loss: 0.4889021723818717		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.5263917809727131 | validation: 0.39487222220776197]
	TIME [epoch: 8.78 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4139700887030645		[learning rate: 0.0026055]
		[batch 20/20] avg loss: 0.39985967659566884		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.40691488264936665 | validation: 0.2187457755108665]
	TIME [epoch: 8.78 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3894100604828842		[learning rate: 0.0025929]
		[batch 20/20] avg loss: 0.5319546585348294		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.4606823595088569 | validation: 0.4762565670072675]
	TIME [epoch: 8.77 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5900709114835837		[learning rate: 0.0025804]
		[batch 20/20] avg loss: 0.6620169378407786		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.626043924662181 | validation: 0.4641261385730396]
	TIME [epoch: 8.78 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6000896570222644		[learning rate: 0.0025679]
		[batch 20/20] avg loss: 0.6347229269994933		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.6174062920108787 | validation: 0.4002212329443995]
	TIME [epoch: 8.81 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.49596776091084865		[learning rate: 0.0025555]
		[batch 20/20] avg loss: 0.4636319544725363		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.4797998576916925 | validation: 0.22869045460534312]
	TIME [epoch: 8.78 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39705264886241387		[learning rate: 0.0025431]
		[batch 20/20] avg loss: 0.46051783612921915		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.42878524249581657 | validation: 0.368692268600926]
	TIME [epoch: 8.78 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.401199570289294		[learning rate: 0.0025308]
		[batch 20/20] avg loss: 0.3454156108977817		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.37330759059353785 | validation: 0.38493920172406904]
	TIME [epoch: 8.78 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46865299541488625		[learning rate: 0.0025186]
		[batch 20/20] avg loss: 0.3076067568994753		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.3881298761571807 | validation: 0.14764755778794966]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_335.pth
	Model improved!!!
EPOCH 336/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36825670130742316		[learning rate: 0.0025064]
		[batch 20/20] avg loss: 0.5400502682719265		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.4541534847896749 | validation: 0.1740317901066858]
	TIME [epoch: 8.8 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3927253074367172		[learning rate: 0.0024943]
		[batch 20/20] avg loss: 0.4370431972029463		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.4148842523198318 | validation: 0.3023498643661358]
	TIME [epoch: 8.77 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3813093692284879		[learning rate: 0.0024822]
		[batch 20/20] avg loss: 0.4768749163082237		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.4290921427683558 | validation: 0.27569013156109357]
	TIME [epoch: 8.77 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.40450190485638143		[learning rate: 0.0024702]
		[batch 20/20] avg loss: 0.6303468273656139		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.5174243661109977 | validation: 0.5871042557000421]
	TIME [epoch: 8.78 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48128686316993124		[learning rate: 0.0024583]
		[batch 20/20] avg loss: 0.3646957807159985		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.42299132194296496 | validation: 0.18836823947126796]
	TIME [epoch: 8.78 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4414113278860138		[learning rate: 0.0024464]
		[batch 20/20] avg loss: 0.3415758771413964		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.39149360251370513 | validation: 0.36745147131147116]
	TIME [epoch: 8.79 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3920563928269104		[learning rate: 0.0024346]
		[batch 20/20] avg loss: 0.2982310398450713		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.34514371633599084 | validation: 0.206625583837154]
	TIME [epoch: 8.79 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30163301370720874		[learning rate: 0.0024228]
		[batch 20/20] avg loss: 0.44469019888055994		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.3731616062938844 | validation: 0.39495336705220685]
	TIME [epoch: 8.78 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32147997077604173		[learning rate: 0.0024111]
		[batch 20/20] avg loss: 0.3319749865923995		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.3267274786842206 | validation: 0.198015285294603]
	TIME [epoch: 8.78 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26480921831052695		[learning rate: 0.0023994]
		[batch 20/20] avg loss: 0.32571359245901793		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.29526140538477247 | validation: 0.18986121137385087]
	TIME [epoch: 8.77 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37214379605570685		[learning rate: 0.0023878]
		[batch 20/20] avg loss: 0.31561414344462724		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.3438789697501671 | validation: 0.38072177856474076]
	TIME [epoch: 8.78 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5431003530457992		[learning rate: 0.0023763]
		[batch 20/20] avg loss: 0.3767420076301683		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.4599211803379837 | validation: 0.3630637777745942]
	TIME [epoch: 8.8 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32374443817229703		[learning rate: 0.0023648]
		[batch 20/20] avg loss: 0.24974958418957663		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.2867470111809369 | validation: 0.1988762813060006]
	TIME [epoch: 8.77 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3178473096445495		[learning rate: 0.0023533]
		[batch 20/20] avg loss: 0.35872993398212893		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.33828862181333913 | validation: 0.290893805056808]
	TIME [epoch: 8.77 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2716703661827888		[learning rate: 0.002342]
		[batch 20/20] avg loss: 0.2916884202631035		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.2816793932229461 | validation: 0.27413335426159186]
	TIME [epoch: 8.77 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45282158301657277		[learning rate: 0.0023306]
		[batch 20/20] avg loss: 0.5088824950004055		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.4808520390084891 | validation: 0.6062298764790868]
	TIME [epoch: 8.77 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4696025176819436		[learning rate: 0.0023194]
		[batch 20/20] avg loss: 0.6170385518912129		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.5433205347865783 | validation: 0.5256896439969868]
	TIME [epoch: 8.79 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.40357151726937024		[learning rate: 0.0023081]
		[batch 20/20] avg loss: 0.36270726656819685		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.3831393919187835 | validation: 0.1535153693991379]
	TIME [epoch: 8.77 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32354823381337655		[learning rate: 0.002297]
		[batch 20/20] avg loss: 0.5106106233299594		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.41707942857166797 | validation: 0.1491093347561818]
	TIME [epoch: 8.77 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.35172104546509564		[learning rate: 0.0022859]
		[batch 20/20] avg loss: 0.2997693185321186		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.32574518199860725 | validation: 0.4902913138167224]
	TIME [epoch: 8.77 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.466717888913624		[learning rate: 0.0022748]
		[batch 20/20] avg loss: 0.4231857939961993		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.4449518414549116 | validation: 0.3123943134478612]
	TIME [epoch: 8.78 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30627483906666697		[learning rate: 0.0022638]
		[batch 20/20] avg loss: 0.31952647972340226		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.31290065939503464 | validation: 0.13533449201235898]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_357.pth
	Model improved!!!
EPOCH 358/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3194438085699023		[learning rate: 0.0022529]
		[batch 20/20] avg loss: 0.5144993610854007		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.4169715848276515 | validation: 0.27385197578228915]
	TIME [epoch: 8.78 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3776418322495771		[learning rate: 0.002242]
		[batch 20/20] avg loss: 0.26914814689398336		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.3233949895717802 | validation: 0.22151210807678062]
	TIME [epoch: 8.77 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3042597399333821		[learning rate: 0.0022311]
		[batch 20/20] avg loss: 0.5255574828408308		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.41490861138710644 | validation: 0.6346018338839687]
	TIME [epoch: 8.77 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45223856247010363		[learning rate: 0.0022203]
		[batch 20/20] avg loss: 0.4781479586584093		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.46519326056425647 | validation: 0.37213242871702545]
	TIME [epoch: 8.77 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3440921709826393		[learning rate: 0.0022096]
		[batch 20/20] avg loss: 0.5258540818971984		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.4349731264399187 | validation: 0.1267618754198323]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_362.pth
	Model improved!!!
EPOCH 363/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4254368695024756		[learning rate: 0.0021989]
		[batch 20/20] avg loss: 0.7022816967956734		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.5638592831490744 | validation: 0.25166566524065187]
	TIME [epoch: 8.79 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2571406462852035		[learning rate: 0.0021883]
		[batch 20/20] avg loss: 0.335759456220784		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.29645005125299384 | validation: 0.5311193563524801]
	TIME [epoch: 8.77 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41085663432184283		[learning rate: 0.0021777]
		[batch 20/20] avg loss: 0.2633025687385956		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.33707960153021915 | validation: 0.43679827625010625]
	TIME [epoch: 8.77 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5049835312506965		[learning rate: 0.0021672]
		[batch 20/20] avg loss: 0.4361183233049136		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.470550927277805 | validation: 0.2122423714477303]
	TIME [epoch: 8.77 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41517824435414463		[learning rate: 0.0021567]
		[batch 20/20] avg loss: 0.3144437187115008		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.36481098153282276 | validation: 0.3012594836462464]
	TIME [epoch: 8.8 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2869446786770101		[learning rate: 0.0021463]
		[batch 20/20] avg loss: 0.4309118129674336		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.3589282458222219 | validation: 0.5289849999427211]
	TIME [epoch: 8.77 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.42523579634421027		[learning rate: 0.0021359]
		[batch 20/20] avg loss: 0.33188633025718417		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.37856106330069716 | validation: 0.16525301719472674]
	TIME [epoch: 8.76 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39366392162977537		[learning rate: 0.0021256]
		[batch 20/20] avg loss: 0.29176884995558033		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.34271638579267794 | validation: 0.30782425870219055]
	TIME [epoch: 8.77 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37571621334356947		[learning rate: 0.0021153]
		[batch 20/20] avg loss: 0.40830266049162545		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.3920094369175974 | validation: 0.13274135269033782]
	TIME [epoch: 8.76 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28455069769760405		[learning rate: 0.0021051]
		[batch 20/20] avg loss: 0.2465742945478865		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.2655624961227453 | validation: 0.23857640019210594]
	TIME [epoch: 8.78 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3058934201898694		[learning rate: 0.0020949]
		[batch 20/20] avg loss: 0.35530004155828454		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.33059673087407687 | validation: 0.5092734028545516]
	TIME [epoch: 8.79 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3074882686036817		[learning rate: 0.0020847]
		[batch 20/20] avg loss: 0.27153748975770464		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.2895128791806932 | validation: 0.1816081055440391]
	TIME [epoch: 8.77 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37247593155667813		[learning rate: 0.0020747]
		[batch 20/20] avg loss: 0.3387574332589688		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.3556166824078235 | validation: 0.5652998671965559]
	TIME [epoch: 8.77 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5061314612857918		[learning rate: 0.0020646]
		[batch 20/20] avg loss: 0.23503440977409085		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.37058293552994126 | validation: 0.1897746956892365]
	TIME [epoch: 8.77 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2890133899895523		[learning rate: 0.0020546]
		[batch 20/20] avg loss: 0.365442030151344		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.32722771007044815 | validation: 0.23957717935955808]
	TIME [epoch: 8.77 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3222142437933427		[learning rate: 0.0020447]
		[batch 20/20] avg loss: 0.27293878951207184		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.29757651665270723 | validation: 1.0996199653279397]
	TIME [epoch: 8.79 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4916439163830185		[learning rate: 0.0020348]
		[batch 20/20] avg loss: 0.24225642393264613		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.3669501701578324 | validation: 0.28869838621740707]
	TIME [epoch: 8.77 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2852277276174912		[learning rate: 0.002025]
		[batch 20/20] avg loss: 0.20407929407935024		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.24465351084842077 | validation: 0.22951761242584917]
	TIME [epoch: 8.77 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3308373768295398		[learning rate: 0.0020152]
		[batch 20/20] avg loss: 0.33407063222432004		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.33245400452692997 | validation: 0.15474564262153379]
	TIME [epoch: 8.77 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21104956456271293		[learning rate: 0.0020054]
		[batch 20/20] avg loss: 0.36734798855561124		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.2891987765591622 | validation: 0.5197043108250253]
	TIME [epoch: 8.77 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32296629495782975		[learning rate: 0.0019957]
		[batch 20/20] avg loss: 0.23909600065496533		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.2810311478063975 | validation: 0.07379114510035588]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_383.pth
	Model improved!!!
EPOCH 384/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34251645799104236		[learning rate: 0.0019861]
		[batch 20/20] avg loss: 0.25597523032714364		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.299245844159093 | validation: 0.2687011980369598]
	TIME [epoch: 8.78 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3135546492554796		[learning rate: 0.0019765]
		[batch 20/20] avg loss: 0.33841958832349867		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.32598711878948916 | validation: 0.5071949904358326]
	TIME [epoch: 8.77 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28150380575705247		[learning rate: 0.0019669]
		[batch 20/20] avg loss: 0.29503058827790485		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.28826719701747866 | validation: 0.28118971989068203]
	TIME [epoch: 8.78 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30822307362422463		[learning rate: 0.0019574]
		[batch 20/20] avg loss: 0.4616068928785272		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.38491498325137585 | validation: 0.14755359895835318]
	TIME [epoch: 8.77 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23728526177193804		[learning rate: 0.001948]
		[batch 20/20] avg loss: 0.2734553128680181		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.255370287319978 | validation: 0.15249907829896442]
	TIME [epoch: 8.8 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19185757016036203		[learning rate: 0.0019385]
		[batch 20/20] avg loss: 0.28301330485105636		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.2374354375057092 | validation: 0.2515139560328547]
	TIME [epoch: 8.78 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20563505691145986		[learning rate: 0.0019292]
		[batch 20/20] avg loss: 0.3591620693580476		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.28239856313475376 | validation: 0.25568493936539594]
	TIME [epoch: 8.78 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30344493030538827		[learning rate: 0.0019198]
		[batch 20/20] avg loss: 0.22007190755448516		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.2617584189299367 | validation: 0.491118986706643]
	TIME [epoch: 8.78 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3152508405081834		[learning rate: 0.0019105]
		[batch 20/20] avg loss: 0.3444554310871877		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.3298531357976856 | validation: 0.19155812253155408]
	TIME [epoch: 8.78 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28012369119314184		[learning rate: 0.0019013]
		[batch 20/20] avg loss: 0.3131749956581027		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.29664934342562227 | validation: 0.1512955314040928]
	TIME [epoch: 8.8 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1899971972992933		[learning rate: 0.0018921]
		[batch 20/20] avg loss: 0.25803273082537415		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.22401496406233373 | validation: 0.6541217118010958]
	TIME [epoch: 8.78 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2925224426130992		[learning rate: 0.001883]
		[batch 20/20] avg loss: 0.33974391995758674		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.31613318128534296 | validation: 0.8809458371193973]
	TIME [epoch: 8.78 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48819048462476894		[learning rate: 0.0018739]
		[batch 20/20] avg loss: 0.33350492263860154		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.4108477036316852 | validation: 0.25579668924623844]
	TIME [epoch: 8.78 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24553930273457603		[learning rate: 0.0018648]
		[batch 20/20] avg loss: 0.3459942327119243		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.29576676772325017 | validation: 0.24448036169970533]
	TIME [epoch: 8.78 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2928694988549805		[learning rate: 0.0018558]
		[batch 20/20] avg loss: 0.4687682662323436		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.38081888254366203 | validation: 0.6010160381887079]
	TIME [epoch: 8.8 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28472316101846534		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.2094039546693356		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.2470635578439005 | validation: 0.18084691927834948]
	TIME [epoch: 8.79 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27017326712796214		[learning rate: 0.0018379]
		[batch 20/20] avg loss: 0.23518106004432554		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.25267716358614384 | validation: 0.3405681918142661]
	TIME [epoch: 8.77 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3634183948028901		[learning rate: 0.001829]
		[batch 20/20] avg loss: 0.32842634073311117		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.34592236776800067 | validation: 0.10640560024877599]
	TIME [epoch: 8.78 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31325538270798575		[learning rate: 0.0018201]
		[batch 20/20] avg loss: 0.2544425827216561		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.28384898271482095 | validation: 0.1073883992785492]
	TIME [epoch: 8.78 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.317902905751872		[learning rate: 0.0018113]
		[batch 20/20] avg loss: 0.27826719418854046		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.29808504997020624 | validation: 0.35237581721160377]
	TIME [epoch: 8.78 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22820962566313918		[learning rate: 0.0018026]
		[batch 20/20] avg loss: 0.32042912861164907		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.2743193771373941 | validation: 0.07011085568715032]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_404.pth
	Model improved!!!
EPOCH 405/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37893085886390543		[learning rate: 0.0017939]
		[batch 20/20] avg loss: 0.40857007903876197		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.3937504689513337 | validation: 0.14637512429713184]
	TIME [epoch: 8.79 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32389697078025914		[learning rate: 0.0017852]
		[batch 20/20] avg loss: 0.26985471071954337		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.29687584074990125 | validation: 0.08692184371207844]
	TIME [epoch: 8.79 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1677146906503307		[learning rate: 0.0017766]
		[batch 20/20] avg loss: 0.3465204076959587		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.25711754917314467 | validation: 0.17061472193444624]
	TIME [epoch: 8.8 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29685002045343106		[learning rate: 0.001768]
		[batch 20/20] avg loss: 0.3271481584216663		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.31199908943754867 | validation: 0.13988585151472788]
	TIME [epoch: 8.78 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24528282390146675		[learning rate: 0.0017594]
		[batch 20/20] avg loss: 0.3405226605347371		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.292902742218102 | validation: 0.20451507537021846]
	TIME [epoch: 8.81 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2533509712761881		[learning rate: 0.0017509]
		[batch 20/20] avg loss: 0.2119880733705161		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.23266952232335208 | validation: 0.27308673890794266]
	TIME [epoch: 8.79 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22004715459465035		[learning rate: 0.0017424]
		[batch 20/20] avg loss: 0.29783858055742707		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.2589428675760387 | validation: 0.10611949125224002]
	TIME [epoch: 8.77 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24044064071590535		[learning rate: 0.001734]
		[batch 20/20] avg loss: 0.29141938412024004		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.2659300124180726 | validation: 0.10719953769057702]
	TIME [epoch: 8.77 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3499934228201026		[learning rate: 0.0017256]
		[batch 20/20] avg loss: 0.2549553101783946		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.30247436649924864 | validation: 0.12179056853974868]
	TIME [epoch: 8.77 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31634838684639355		[learning rate: 0.0017173]
		[batch 20/20] avg loss: 0.33985957130777666		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.3281039790770851 | validation: 0.7328592055700814]
	TIME [epoch: 8.8 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2629599636490233		[learning rate: 0.001709]
		[batch 20/20] avg loss: 0.24647648996672794		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.2547182268078757 | validation: 0.26901834951133247]
	TIME [epoch: 8.78 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19846406295917657		[learning rate: 0.0017007]
		[batch 20/20] avg loss: 0.2427570189758536		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.22061054096751512 | validation: 1.017163338475254]
	TIME [epoch: 8.78 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34633146521262914		[learning rate: 0.0016925]
		[batch 20/20] avg loss: 0.19896151901409806		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.27264649211336367 | validation: 0.12984854570400947]
	TIME [epoch: 8.78 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2561246538348401		[learning rate: 0.0016843]
		[batch 20/20] avg loss: 0.24549768226718943		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.2508111680510148 | validation: 0.27639085625703946]
	TIME [epoch: 8.78 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2809069025461195		[learning rate: 0.0016762]
		[batch 20/20] avg loss: 0.3260094466740825		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.303458174610101 | validation: 0.2981952690587756]
	TIME [epoch: 8.81 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21200485121489496		[learning rate: 0.0016681]
		[batch 20/20] avg loss: 0.14145816037564002		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.1767315057952675 | validation: 0.3076440873012607]
	TIME [epoch: 8.78 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3138939993164856		[learning rate: 0.00166]
		[batch 20/20] avg loss: 0.2986528867635027		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.30627344303999415 | validation: 0.22799716460205482]
	TIME [epoch: 8.79 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21320845001568345		[learning rate: 0.001652]
		[batch 20/20] avg loss: 0.27967384192621003		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.24644114597094674 | validation: 0.27530744203269486]
	TIME [epoch: 8.79 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19698036575765432		[learning rate: 0.001644]
		[batch 20/20] avg loss: 0.2636018041225254		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.23029108494008982 | validation: 0.4974299469898906]
	TIME [epoch: 8.78 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26169237118153993		[learning rate: 0.001636]
		[batch 20/20] avg loss: 0.2782708652226965		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.26998161820211825 | validation: 0.06184633397686111]
	TIME [epoch: 8.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_424.pth
	Model improved!!!
EPOCH 425/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19528421336268956		[learning rate: 0.0016281]
		[batch 20/20] avg loss: 0.20857878371694896		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.20193149853981923 | validation: 0.10842182350705737]
	TIME [epoch: 8.79 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21001824576771014		[learning rate: 0.0016202]
		[batch 20/20] avg loss: 0.2523230054602638		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.23117062561398702 | validation: 0.20561898967487544]
	TIME [epoch: 8.79 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3730189408915724		[learning rate: 0.0016124]
		[batch 20/20] avg loss: 0.2624926673995172		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.31775580414554483 | validation: 0.14518882067018538]
	TIME [epoch: 8.78 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1699054597264246		[learning rate: 0.0016046]
		[batch 20/20] avg loss: 0.17165675214223694		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.17078110593433077 | validation: 0.12006887401741871]
	TIME [epoch: 8.78 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1613814084375014		[learning rate: 0.0015968]
		[batch 20/20] avg loss: 0.2154648473991067		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.18842312791830404 | validation: 0.6357112136175285]
	TIME [epoch: 8.8 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26181398988545546		[learning rate: 0.0015891]
		[batch 20/20] avg loss: 0.1977936792200526		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.229803834552754 | validation: 0.15390126189638803]
	TIME [epoch: 8.79 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1636817796148349		[learning rate: 0.0015814]
		[batch 20/20] avg loss: 0.2450623763168954		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.20437207796586515 | validation: 0.10762281163071324]
	TIME [epoch: 8.78 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30010260751159995		[learning rate: 0.0015738]
		[batch 20/20] avg loss: 0.29733154523406186		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.2987170763728309 | validation: 0.1785920369442827]
	TIME [epoch: 8.8 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23004926323470037		[learning rate: 0.0015662]
		[batch 20/20] avg loss: 0.21788499771763759		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.22396713047616895 | validation: 0.09295451670870315]
	TIME [epoch: 8.78 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24874682193805153		[learning rate: 0.0015586]
		[batch 20/20] avg loss: 0.21498072424259723		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.23186377309032435 | validation: 0.4028752489251051]
	TIME [epoch: 8.79 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22130462907784834		[learning rate: 0.0015511]
		[batch 20/20] avg loss: 0.2387977939291653		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.2300512115035068 | validation: 0.08494028872817311]
	TIME [epoch: 8.8 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2629638380212701		[learning rate: 0.0015436]
		[batch 20/20] avg loss: 0.1968145440019275		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.22988919101159883 | validation: 0.17661989795485578]
	TIME [epoch: 8.78 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.239573838527174		[learning rate: 0.0015361]
		[batch 20/20] avg loss: 0.15645088040626862		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.1980123594667213 | validation: 0.054299354632937086]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_437.pth
	Model improved!!!
EPOCH 438/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16183492341669486		[learning rate: 0.0015287]
		[batch 20/20] avg loss: 0.17664367154755456		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.16923929748212474 | validation: 0.1061932044265637]
	TIME [epoch: 8.78 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30093893173084074		[learning rate: 0.0015213]
		[batch 20/20] avg loss: 0.2892250848763939		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.29508200830361736 | validation: 0.4113222076495315]
	TIME [epoch: 8.78 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2182829948172394		[learning rate: 0.0015139]
		[batch 20/20] avg loss: 0.18029158991634753		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.19928729236679346 | validation: 0.20028060139794157]
	TIME [epoch: 8.8 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22584826026367524		[learning rate: 0.0015066]
		[batch 20/20] avg loss: 0.19439639664232486		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.210122328453 | validation: 0.10859207878505996]
	TIME [epoch: 8.79 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2626617945041311		[learning rate: 0.0014993]
		[batch 20/20] avg loss: 0.2572196459762378		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.25994072024018444 | validation: 0.4168016656490734]
	TIME [epoch: 8.78 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2665588641735145		[learning rate: 0.0014921]
		[batch 20/20] avg loss: 0.2952633886727221		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.28091112642311833 | validation: 0.11854606672334202]
	TIME [epoch: 8.78 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17026654514513623		[learning rate: 0.0014849]
		[batch 20/20] avg loss: 0.32627083830369713		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.2482686917244167 | validation: 0.2025159024816483]
	TIME [epoch: 8.79 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16997167148982867		[learning rate: 0.0014777]
		[batch 20/20] avg loss: 0.2618850398593313		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.21592835567458007 | validation: 0.13091710469402687]
	TIME [epoch: 8.8 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2457685901898678		[learning rate: 0.0014705]
		[batch 20/20] avg loss: 0.22628075644691462		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.2360246733183912 | validation: 0.061769928612523346]
	TIME [epoch: 8.79 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20458434452755503		[learning rate: 0.0014634]
		[batch 20/20] avg loss: 0.20959039660902032		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.20708737056828772 | validation: 0.050599994629096784]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_447.pth
	Model improved!!!
EPOCH 448/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25065592646223334		[learning rate: 0.0014563]
		[batch 20/20] avg loss: 0.25082496448988706		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.2507404454760601 | validation: 0.048405750004750545]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_448.pth
	Model improved!!!
EPOCH 449/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1440500318467524		[learning rate: 0.0014493]
		[batch 20/20] avg loss: 0.25721586970030313		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.20063295077352775 | validation: 0.11650568143528992]
	TIME [epoch: 8.78 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.247799135032217		[learning rate: 0.0014423]
		[batch 20/20] avg loss: 0.23124275916792394		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.23952094710007046 | validation: 0.14695461283598427]
	TIME [epoch: 8.8 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20726083950293606		[learning rate: 0.0014353]
		[batch 20/20] avg loss: 0.16173589909782643		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.18449836930038124 | validation: 0.17765117203706488]
	TIME [epoch: 8.78 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31775448590114225		[learning rate: 0.0014284]
		[batch 20/20] avg loss: 0.20064878499154254		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.25920163544634245 | validation: 0.12335682093154668]
	TIME [epoch: 8.77 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18053881154152468		[learning rate: 0.0014215]
		[batch 20/20] avg loss: 0.22928804718714324		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.20491342936433393 | validation: 0.3169692618182629]
	TIME [epoch: 8.78 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24139726146486495		[learning rate: 0.0014146]
		[batch 20/20] avg loss: 0.21403236939754486		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.22771481543120484 | validation: 0.06443342801857235]
	TIME [epoch: 8.77 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20652234895608493		[learning rate: 0.0014078]
		[batch 20/20] avg loss: 0.22715801462697377		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.21684018179152936 | validation: 0.11938235746564664]
	TIME [epoch: 8.8 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1802219002886642		[learning rate: 0.0014009]
		[batch 20/20] avg loss: 0.18294840483762312		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.18158515256314367 | validation: 0.3086467735901278]
	TIME [epoch: 8.77 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2936398141823563		[learning rate: 0.0013942]
		[batch 20/20] avg loss: 0.18777539310999308		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.2407076036461747 | validation: 0.24838046386729098]
	TIME [epoch: 8.78 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23236550824415536		[learning rate: 0.0013874]
		[batch 20/20] avg loss: 0.20888791678094867		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.220626712512552 | validation: 0.14295503862273362]
	TIME [epoch: 8.78 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30174040288033116		[learning rate: 0.0013807]
		[batch 20/20] avg loss: 0.23764412477470662		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.2696922638275189 | validation: 0.661809603160733]
	TIME [epoch: 8.78 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24352194772721578		[learning rate: 0.001374]
		[batch 20/20] avg loss: 0.11533258357693014		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.17942726565207298 | validation: 0.7555915844926455]
	TIME [epoch: 8.84 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24788537336316488		[learning rate: 0.0013674]
		[batch 20/20] avg loss: 0.1852777720480157		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.21658157270559034 | validation: 0.19825381293094413]
	TIME [epoch: 8.78 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20242565140379432		[learning rate: 0.0013608]
		[batch 20/20] avg loss: 0.18077496637638885		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.19160030889009155 | validation: 0.19343005768086563]
	TIME [epoch: 8.77 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20289908455895533		[learning rate: 0.0013542]
		[batch 20/20] avg loss: 0.11918665886117774		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.16104287171006657 | validation: 0.05110664635769413]
	TIME [epoch: 8.77 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20791363875563879		[learning rate: 0.0013477]
		[batch 20/20] avg loss: 0.18101003371885177		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.19446183623724528 | validation: 0.2985414407690252]
	TIME [epoch: 8.77 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1775783682970958		[learning rate: 0.0013411]
		[batch 20/20] avg loss: 0.18901143358835884		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.18329490094272732 | validation: 0.0983167171700484]
	TIME [epoch: 8.78 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26433696993043687		[learning rate: 0.0013347]
		[batch 20/20] avg loss: 0.3135895354974938		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.28896325271396534 | validation: 0.426206781030462]
	TIME [epoch: 8.8 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19136196521100818		[learning rate: 0.0013282]
		[batch 20/20] avg loss: 0.18489933143117923		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.1881306483210937 | validation: 0.055873080992754794]
	TIME [epoch: 8.78 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20158788323516394		[learning rate: 0.0013218]
		[batch 20/20] avg loss: 0.1585993881658314		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.1800936357004977 | validation: 0.2462122530258218]
	TIME [epoch: 8.78 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20220812255083062		[learning rate: 0.0013154]
		[batch 20/20] avg loss: 0.1998525048206914		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.20103031368576105 | validation: 0.2181895208624563]
	TIME [epoch: 8.78 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1610175100679129		[learning rate: 0.001309]
		[batch 20/20] avg loss: 0.1630641399512464		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.16204082500957964 | validation: 0.2880929785179856]
	TIME [epoch: 8.78 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18335739446845395		[learning rate: 0.0013027]
		[batch 20/20] avg loss: 0.16931534730031722		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.17633637088438558 | validation: 0.12258162089129129]
	TIME [epoch: 8.79 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15389576942273636		[learning rate: 0.0012964]
		[batch 20/20] avg loss: 0.2458156595060849		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.19985571446441058 | validation: 0.10154317390546075]
	TIME [epoch: 8.79 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1628832920365376		[learning rate: 0.0012901]
		[batch 20/20] avg loss: 0.17332239081310283		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.1681028414248202 | validation: 0.0746240260268632]
	TIME [epoch: 8.78 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20895538278534714		[learning rate: 0.0012839]
		[batch 20/20] avg loss: 0.28628234447679624		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.24761886363107172 | validation: 0.11122984872356961]
	TIME [epoch: 8.78 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1907671243066389		[learning rate: 0.0012777]
		[batch 20/20] avg loss: 0.17837904729393117		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.18457308580028503 | validation: 0.5971369579142609]
	TIME [epoch: 8.78 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23561233675958992		[learning rate: 0.0012715]
		[batch 20/20] avg loss: 0.13396353582189324		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.18478793629074156 | validation: 0.12234563805703255]
	TIME [epoch: 8.8 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10835930308638757		[learning rate: 0.0012653]
		[batch 20/20] avg loss: 0.22475489776086982		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.1665571004236287 | validation: 0.06472630046830528]
	TIME [epoch: 8.78 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.135248566669794		[learning rate: 0.0012592]
		[batch 20/20] avg loss: 0.20738926504972816		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.17131891585976106 | validation: 0.048287169021572554]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_478.pth
	Model improved!!!
EPOCH 479/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15370271301178903		[learning rate: 0.0012531]
		[batch 20/20] avg loss: 0.1800103918938661		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.16685655245282754 | validation: 0.3253789079926061]
	TIME [epoch: 8.78 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17773076592082046		[learning rate: 0.0012471]
		[batch 20/20] avg loss: 0.22621900903491904		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.20197488747786974 | validation: 0.2825907119105984]
	TIME [epoch: 8.78 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22766359682068868		[learning rate: 0.0012411]
		[batch 20/20] avg loss: 0.15111908350133138		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.18939134016101 | validation: 0.24425796299212107]
	TIME [epoch: 8.81 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1547062038532365		[learning rate: 0.001235]
		[batch 20/20] avg loss: 0.186983614783894		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.17084490931856527 | validation: 0.12951449016675232]
	TIME [epoch: 8.78 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21302223311962787		[learning rate: 0.0012291]
		[batch 20/20] avg loss: 0.40902196079990916		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.31102209695976846 | validation: 0.5493980127586441]
	TIME [epoch: 8.77 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1832570006683334		[learning rate: 0.0012231]
		[batch 20/20] avg loss: 0.11928311369193004		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.1512700571801317 | validation: 0.24085141051528208]
	TIME [epoch: 8.77 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1871800297031423		[learning rate: 0.0012172]
		[batch 20/20] avg loss: 0.27520205826336774		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.23119104398325505 | validation: 0.3492415413647848]
	TIME [epoch: 8.77 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.214836501559129		[learning rate: 0.0012113]
		[batch 20/20] avg loss: 0.2940886893492747		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.2544625954542018 | validation: 0.14626069255521718]
	TIME [epoch: 8.8 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18120700981327928		[learning rate: 0.0012055]
		[batch 20/20] avg loss: 0.1552665871512605		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.1682367984822699 | validation: 0.11246597326317478]
	TIME [epoch: 8.79 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13606345809561182		[learning rate: 0.0011996]
		[batch 20/20] avg loss: 0.13469338185025953		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.1353784199729357 | validation: 0.4508736682647125]
	TIME [epoch: 8.78 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16293985503926536		[learning rate: 0.0011938]
		[batch 20/20] avg loss: 0.17406458624593824		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.1685022206426018 | validation: 0.1495225793554449]
	TIME [epoch: 8.78 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1879756400138602		[learning rate: 0.0011881]
		[batch 20/20] avg loss: 0.1696730747018272		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.17882435735784363 | validation: 0.1318745256306461]
	TIME [epoch: 8.78 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17696952015441997		[learning rate: 0.0011823]
		[batch 20/20] avg loss: 0.18079541894363269		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.1788824695490263 | validation: 0.06498021514484054]
	TIME [epoch: 8.8 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13085686827562132		[learning rate: 0.0011766]
		[batch 20/20] avg loss: 0.16180267677446888		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.14632977252504506 | validation: 0.026207675612329225]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_492.pth
	Model improved!!!
EPOCH 493/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10295865610892019		[learning rate: 0.0011709]
		[batch 20/20] avg loss: 0.12521045832377048		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.11408455721634533 | validation: 0.28427868199111317]
	TIME [epoch: 8.78 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14259010326303145		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.158267312933905		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.15042870809846826 | validation: 0.10529315113033426]
	TIME [epoch: 8.79 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1392738463874909		[learning rate: 0.0011596]
		[batch 20/20] avg loss: 0.13806556703953524		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.13866970671351309 | validation: 0.051279983206975806]
	TIME [epoch: 8.78 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18132833890885577		[learning rate: 0.001154]
		[batch 20/20] avg loss: 0.13627456606220906		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.15880145248553243 | validation: 0.08015655155139179]
	TIME [epoch: 8.78 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12840018773996315		[learning rate: 0.0011484]
		[batch 20/20] avg loss: 0.13645773846569154		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.13242896310282734 | validation: 0.05777731124225957]
	TIME [epoch: 8.81 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17986575755282924		[learning rate: 0.0011429]
		[batch 20/20] avg loss: 0.1353102168326154		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.15758798719272232 | validation: 0.10880261636125352]
	TIME [epoch: 8.77 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14465057749398594		[learning rate: 0.0011374]
		[batch 20/20] avg loss: 0.1232531116375409		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.13395184456576342 | validation: 0.15999025976365894]
	TIME [epoch: 8.78 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19667633514405744		[learning rate: 0.0011319]
		[batch 20/20] avg loss: 0.12484660908870082		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.1607614721163792 | validation: 0.15864784199707108]
	TIME [epoch: 8.79 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1018017616488843		[learning rate: 0.0011264]
		[batch 20/20] avg loss: 0.1331872942441769		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.11749452794653062 | validation: 0.3775776316504502]
	TIME [epoch: 8.79 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2004600860447588		[learning rate: 0.0011209]
		[batch 20/20] avg loss: 0.13201184830861773		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.16623596717668823 | validation: 0.16151862848690884]
	TIME [epoch: 8.81 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1658160778007823		[learning rate: 0.0011155]
		[batch 20/20] avg loss: 0.13141430447476646		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.14861519113777438 | validation: 0.08222734870057002]
	TIME [epoch: 8.78 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17006644918964242		[learning rate: 0.0011101]
		[batch 20/20] avg loss: 0.165586073656564		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.16782626142310322 | validation: 0.11503479196504734]
	TIME [epoch: 8.78 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10376613098165373		[learning rate: 0.0011047]
		[batch 20/20] avg loss: 0.20378325057993396		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.15377469078079384 | validation: 0.08877736583270683]
	TIME [epoch: 8.77 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1875235449796975		[learning rate: 0.0010994]
		[batch 20/20] avg loss: 0.15463548625134757		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.17107951561552256 | validation: 0.10535626782805986]
	TIME [epoch: 8.78 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1740506389267213		[learning rate: 0.0010941]
		[batch 20/20] avg loss: 0.15751670215828265		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.16578367054250195 | validation: 0.07453293439594004]
	TIME [epoch: 8.81 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1400364648994023		[learning rate: 0.0010888]
		[batch 20/20] avg loss: 0.16520752156688495		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.15262199323314363 | validation: 0.09415652513334921]
	TIME [epoch: 8.78 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10974333006593373		[learning rate: 0.0010835]
		[batch 20/20] avg loss: 0.1927937048758989		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.15126851747091632 | validation: 0.1463022943345673]
	TIME [epoch: 8.79 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11814613057474296		[learning rate: 0.0010783]
		[batch 20/20] avg loss: 0.15664104357612327		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.13739358707543312 | validation: 0.07029790154900398]
	TIME [epoch: 8.78 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07709055258030767		[learning rate: 0.0010731]
		[batch 20/20] avg loss: 0.16771951876970712		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.1224050356750074 | validation: 0.17014883764453803]
	TIME [epoch: 8.77 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1721787698005231		[learning rate: 0.0010679]
		[batch 20/20] avg loss: 0.14409650202382226		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.1581376359121727 | validation: 0.20895011336362923]
	TIME [epoch: 8.8 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13176566110627336		[learning rate: 0.0010627]
		[batch 20/20] avg loss: 0.14686950529121537		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.13931758319874432 | validation: 0.31990226778786707]
	TIME [epoch: 8.78 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15361530757569244		[learning rate: 0.0010576]
		[batch 20/20] avg loss: 0.12205660869064121		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.1378359581331668 | validation: 0.15954218884233978]
	TIME [epoch: 8.78 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16233230736608786		[learning rate: 0.0010525]
		[batch 20/20] avg loss: 0.1698484496736427		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.1660903785198653 | validation: 0.06168492372798647]
	TIME [epoch: 8.79 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1002585178480589		[learning rate: 0.0010474]
		[batch 20/20] avg loss: 0.1461364655314623		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.12319749168976062 | validation: 0.06033712810259917]
	TIME [epoch: 8.78 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18378405000980189		[learning rate: 0.0010423]
		[batch 20/20] avg loss: 0.20807100764275838		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.19592752882628015 | validation: 0.15990773240098055]
	TIME [epoch: 8.8 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11024017435182558		[learning rate: 0.0010373]
		[batch 20/20] avg loss: 0.16169177790464379		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.13596597612823466 | validation: 0.10035723913706021]
	TIME [epoch: 8.78 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07740866314393616		[learning rate: 0.0010323]
		[batch 20/20] avg loss: 0.24067511228247812		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.15904188771320715 | validation: 0.26866756058948144]
	TIME [epoch: 8.79 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1740805083661633		[learning rate: 0.0010273]
		[batch 20/20] avg loss: 0.08735765289096128		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.1307190806285623 | validation: 0.032796949382425354]
	TIME [epoch: 8.77 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12776961901933387		[learning rate: 0.0010223]
		[batch 20/20] avg loss: 0.09633787277189479		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.11205374589561434 | validation: 0.1451825995119613]
	TIME [epoch: 8.78 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14377365138322062		[learning rate: 0.0010174]
		[batch 20/20] avg loss: 0.07905867652862061		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.11141616395592062 | validation: 0.057235678892686735]
	TIME [epoch: 8.8 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11092448450526615		[learning rate: 0.0010124]
		[batch 20/20] avg loss: 0.09156812722808735		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.10124630586667678 | validation: 0.026901424564368125]
	TIME [epoch: 8.79 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11224985925494638		[learning rate: 0.0010075]
		[batch 20/20] avg loss: 0.11258021105098308		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.11241503515296472 | validation: 0.11036183036991977]
	TIME [epoch: 8.78 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1722941956198191		[learning rate: 0.0010027]
		[batch 20/20] avg loss: 0.25645128051160804		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.21437273806571353 | validation: 0.27052542879847696]
	TIME [epoch: 8.78 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14008702583644608		[learning rate: 0.00099782]
		[batch 20/20] avg loss: 0.08247311134446608		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.1112800685904561 | validation: 0.115845092132378]
	TIME [epoch: 8.78 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11199725475042144		[learning rate: 0.000993]
		[batch 20/20] avg loss: 0.16526634337890495		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.1386317990646632 | validation: 0.03421617680634333]
	TIME [epoch: 8.78 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11534835746701966		[learning rate: 0.00098819]
		[batch 20/20] avg loss: 0.15905406154131935		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.13720120950416953 | validation: 0.029355614719207907]
	TIME [epoch: 8.81 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18471516898482926		[learning rate: 0.00098341]
		[batch 20/20] avg loss: 0.14025594438020678		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.16248555668251802 | validation: 0.43765428620737296]
	TIME [epoch: 8.79 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19832915332210824		[learning rate: 0.00097866]
		[batch 20/20] avg loss: 0.10760227503798958		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.1529657141800489 | validation: 0.11669672066621607]
	TIME [epoch: 8.78 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20121314169402646		[learning rate: 0.00097393]
		[batch 20/20] avg loss: 0.151507156364164		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.17636014902909528 | validation: 0.19314037271075385]
	TIME [epoch: 8.78 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10940571111957816		[learning rate: 0.00096922]
		[batch 20/20] avg loss: 0.21567639586269244		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.1625410534911353 | validation: 0.06547290538828966]
	TIME [epoch: 8.78 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11094385689576136		[learning rate: 0.00096453]
		[batch 20/20] avg loss: 0.11955171451570186		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.11524778570573162 | validation: 0.11151131874694481]
	TIME [epoch: 8.8 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12301699504716437		[learning rate: 0.00095987]
		[batch 20/20] avg loss: 0.15539260967789104		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.13920480236252772 | validation: 0.04564134622681794]
	TIME [epoch: 8.77 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12458041740571676		[learning rate: 0.00095522]
		[batch 20/20] avg loss: 0.18088039792295627		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.15273040766433651 | validation: 0.0721783162236453]
	TIME [epoch: 8.78 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09276967779715709		[learning rate: 0.0009506]
		[batch 20/20] avg loss: 0.1641681718575867		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.1284689248273719 | validation: 0.058848238213451]
	TIME [epoch: 8.79 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1112066488390387		[learning rate: 0.00094601]
		[batch 20/20] avg loss: 0.09881245759167145		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.10500955321535507 | validation: 0.11185740219434764]
	TIME [epoch: 8.78 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14828017369254748		[learning rate: 0.00094143]
		[batch 20/20] avg loss: 0.15630716824656007		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.1522936709695538 | validation: 0.07013940482075708]
	TIME [epoch: 8.81 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12332653226682108		[learning rate: 0.00093688]
		[batch 20/20] avg loss: 0.1280862551222772		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.12570639369454917 | validation: 0.1182920695959967]
	TIME [epoch: 8.77 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15223860707749798		[learning rate: 0.00093235]
		[batch 20/20] avg loss: 0.11110381518341397		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.13167121113045593 | validation: 0.04164024972188774]
	TIME [epoch: 8.78 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11944296839325959		[learning rate: 0.00092784]
		[batch 20/20] avg loss: 0.13959158877573147		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.1295172785844955 | validation: 0.047590220224545156]
	TIME [epoch: 8.78 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1150841413227627		[learning rate: 0.00092335]
		[batch 20/20] avg loss: 0.13214844881978052		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.12361629507127163 | validation: 0.08536416546235526]
	TIME [epoch: 8.78 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10695231041865243		[learning rate: 0.00091889]
		[batch 20/20] avg loss: 0.11195505537959179		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.10945368289912212 | validation: 0.05091629029443419]
	TIME [epoch: 8.8 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.188224356339684		[learning rate: 0.00091445]
		[batch 20/20] avg loss: 0.08767964739232051		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.13795200186600226 | validation: 0.12431431661822753]
	TIME [epoch: 8.78 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12970432744015797		[learning rate: 0.00091002]
		[batch 20/20] avg loss: 0.10776529907118362		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.11873481325567078 | validation: 0.07075846644288658]
	TIME [epoch: 8.78 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08980836176631758		[learning rate: 0.00090562]
		[batch 20/20] avg loss: 0.14880302128540437		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.11930569152586099 | validation: 0.07025361863479924]
	TIME [epoch: 8.78 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14465991112750715		[learning rate: 0.00090124]
		[batch 20/20] avg loss: 0.08309146185725452		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.11387568649238085 | validation: 0.08302052579546756]
	TIME [epoch: 8.78 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11119760523669105		[learning rate: 0.00089689]
		[batch 20/20] avg loss: 0.0959753439953209		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.10358647461600598 | validation: 0.10348451657748098]
	TIME [epoch: 8.81 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11056594192334124		[learning rate: 0.00089255]
		[batch 20/20] avg loss: 0.10704802778841827		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.10880698485587978 | validation: 0.230483436663202]
	TIME [epoch: 8.78 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1389752895166907		[learning rate: 0.00088823]
		[batch 20/20] avg loss: 0.1373613420313003		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.13816831577399552 | validation: 0.15447591074978506]
	TIME [epoch: 8.79 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10534854034395062		[learning rate: 0.00088394]
		[batch 20/20] avg loss: 0.10488186830599104		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.10511520432497083 | validation: 0.06987466765110838]
	TIME [epoch: 8.77 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1035136558471939		[learning rate: 0.00087966]
		[batch 20/20] avg loss: 0.1455440976333381		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.124528876740266 | validation: 0.23200922499152296]
	TIME [epoch: 8.79 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12597693916342867		[learning rate: 0.00087541]
		[batch 20/20] avg loss: 0.07345973063177419		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.09971833489760143 | validation: 0.04249743455488863]
	TIME [epoch: 8.8 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13899640218441656		[learning rate: 0.00087117]
		[batch 20/20] avg loss: 0.11003835188340819		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.12451737703391237 | validation: 0.10380780021517219]
	TIME [epoch: 8.8 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09862347489877833		[learning rate: 0.00086696]
		[batch 20/20] avg loss: 0.13788908962358928		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.11825628226118379 | validation: 0.11971822487527883]
	TIME [epoch: 8.77 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09016321673825037		[learning rate: 0.00086277]
		[batch 20/20] avg loss: 0.09389084756147935		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.09202703214986485 | validation: 0.07541813388414297]
	TIME [epoch: 8.78 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18410392426459163		[learning rate: 0.0008586]
		[batch 20/20] avg loss: 0.08957179530965262		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.13683785978712212 | validation: 0.27367761958026343]
	TIME [epoch: 8.77 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12702522739993719		[learning rate: 0.00085445]
		[batch 20/20] avg loss: 0.12317686337029429		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.12510104538511574 | validation: 0.13187901804077837]
	TIME [epoch: 8.77 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16186695894833542		[learning rate: 0.00085031]
		[batch 20/20] avg loss: 0.11043316461663533		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.1361500617824854 | validation: 0.032069210189331454]
	TIME [epoch: 8.8 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12601581162828274		[learning rate: 0.0008462]
		[batch 20/20] avg loss: 0.1262333960836819		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.1261246038559823 | validation: 0.026423213944569413]
	TIME [epoch: 8.79 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10085158557117357		[learning rate: 0.00084211]
		[batch 20/20] avg loss: 0.13636853404945762		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.11861005981031561 | validation: 0.17867138930285908]
	TIME [epoch: 8.78 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1500839848124592		[learning rate: 0.00083804]
		[batch 20/20] avg loss: 0.09219114638837159		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.12113756560041537 | validation: 0.18014014668107037]
	TIME [epoch: 8.79 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14986235910593004		[learning rate: 0.00083398]
		[batch 20/20] avg loss: 0.11301724389014448		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.13143980149803725 | validation: 0.10326095034497988]
	TIME [epoch: 8.76 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12632568458359555		[learning rate: 0.00082995]
		[batch 20/20] avg loss: 0.09768427745040312		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.11200498101699934 | validation: 0.13006952313295123]
	TIME [epoch: 8.79 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14762597115223736		[learning rate: 0.00082594]
		[batch 20/20] avg loss: 0.12122937000015979		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.13442767057619856 | validation: 0.03688723574765879]
	TIME [epoch: 8.78 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1044328916785314		[learning rate: 0.00082194]
		[batch 20/20] avg loss: 0.09899760694106155		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.10171524930979647 | validation: 0.05502421934759674]
	TIME [epoch: 8.78 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08920155918578275		[learning rate: 0.00081797]
		[batch 20/20] avg loss: 0.1162780859505576		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.10273982256817019 | validation: 0.05054204873591689]
	TIME [epoch: 8.78 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11642682340384672		[learning rate: 0.00081401]
		[batch 20/20] avg loss: 0.1326745048222329		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.1245506641130398 | validation: 0.1531972215731495]
	TIME [epoch: 8.79 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1438714554412665		[learning rate: 0.00081008]
		[batch 20/20] avg loss: 0.1300548882735904		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.13696317185742843 | validation: 0.07724238016767027]
	TIME [epoch: 8.81 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10630729906624037		[learning rate: 0.00080616]
		[batch 20/20] avg loss: 0.09829162272872292		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.10229946089748165 | validation: 0.05706745245423087]
	TIME [epoch: 8.78 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08104712011978457		[learning rate: 0.00080226]
		[batch 20/20] avg loss: 0.1261874551437239		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.10361728763175423 | validation: 0.034698243963924964]
	TIME [epoch: 8.78 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08262654506873127		[learning rate: 0.00079838]
		[batch 20/20] avg loss: 0.08215551524422542		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.08239103015647833 | validation: 0.024169297659559268]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_572.pth
	Model improved!!!
EPOCH 573/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08287499426068001		[learning rate: 0.00079452]
		[batch 20/20] avg loss: 0.13040706201253582		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.10664102813660792 | validation: 0.029566522653657203]
	TIME [epoch: 8.78 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.061181542914152384		[learning rate: 0.00079068]
		[batch 20/20] avg loss: 0.12928103984450318		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.09523129137932776 | validation: 0.05849596973773738]
	TIME [epoch: 8.8 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18452503325125774		[learning rate: 0.00078686]
		[batch 20/20] avg loss: 0.13613500894651084		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.16033002109888433 | validation: 0.12183308403173085]
	TIME [epoch: 8.78 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10032048746638986		[learning rate: 0.00078305]
		[batch 20/20] avg loss: 0.09620673097108676		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.09826360921873831 | validation: 0.1079415388171604]
	TIME [epoch: 8.78 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1350659892225272		[learning rate: 0.00077926]
		[batch 20/20] avg loss: 0.10665933334557216		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.12086266128404968 | validation: 0.10465270303739047]
	TIME [epoch: 8.78 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08263922881189793		[learning rate: 0.00077549]
		[batch 20/20] avg loss: 0.1203669857534361		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.10150310728266702 | validation: 0.1801453497732244]
	TIME [epoch: 8.78 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12349347804283375		[learning rate: 0.00077174]
		[batch 20/20] avg loss: 0.08643064660598333		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.10496206232440852 | validation: 0.029492366960200557]
	TIME [epoch: 8.79 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0749004766238404		[learning rate: 0.00076801]
		[batch 20/20] avg loss: 0.08351552226743476		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.07920799944563758 | validation: 0.02996225375806518]
	TIME [epoch: 8.81 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10205573959090378		[learning rate: 0.0007643]
		[batch 20/20] avg loss: 0.11527121390187553		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.10866347674638963 | validation: 0.047754116518050435]
	TIME [epoch: 8.78 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0760237168792232		[learning rate: 0.0007606]
		[batch 20/20] avg loss: 0.07743461894166813		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.07672916791044566 | validation: 0.03151878877614607]
	TIME [epoch: 8.78 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10224115618626409		[learning rate: 0.00075692]
		[batch 20/20] avg loss: 0.12792020877131288		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.11508068247878848 | validation: 0.04263412265000187]
	TIME [epoch: 8.78 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11815066388212085		[learning rate: 0.00075326]
		[batch 20/20] avg loss: 0.095867011814556		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.10700883784833844 | validation: 0.0987347306543269]
	TIME [epoch: 8.79 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09149369807563129		[learning rate: 0.00074962]
		[batch 20/20] avg loss: 0.10853119586748217		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.10001244697155673 | validation: 0.03618952028277886]
	TIME [epoch: 8.8 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18631728667300135		[learning rate: 0.000746]
		[batch 20/20] avg loss: 0.09360660329468844		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.1399619449838449 | validation: 0.05464453915144286]
	TIME [epoch: 8.79 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0625572955421997		[learning rate: 0.00074239]
		[batch 20/20] avg loss: 0.10336479261873358		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.08296104408046664 | validation: 0.19936813486136085]
	TIME [epoch: 8.78 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11778691454534165		[learning rate: 0.0007388]
		[batch 20/20] avg loss: 0.10405565523335351		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.1109212848893476 | validation: 0.05618095706164751]
	TIME [epoch: 8.78 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09684979234461055		[learning rate: 0.00073523]
		[batch 20/20] avg loss: 0.10365815214063374		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.10025397224262214 | validation: 0.14528597360617107]
	TIME [epoch: 8.78 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09090604904883072		[learning rate: 0.00073167]
		[batch 20/20] avg loss: 0.10739212095828547		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.0991490850035581 | validation: 0.04593804351513044]
	TIME [epoch: 8.81 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08517262116551857		[learning rate: 0.00072813]
		[batch 20/20] avg loss: 0.09124131362463236		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.08820696739507547 | validation: 0.12066035576047938]
	TIME [epoch: 8.78 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07687052862750542		[learning rate: 0.00072461]
		[batch 20/20] avg loss: 0.10799836404454462		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.09243444633602502 | validation: 0.06051621481120129]
	TIME [epoch: 8.78 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0673609998647887		[learning rate: 0.00072111]
		[batch 20/20] avg loss: 0.09056423165543512		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.07896261576011192 | validation: 0.04162227056411852]
	TIME [epoch: 8.78 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08733858782882983		[learning rate: 0.00071762]
		[batch 20/20] avg loss: 0.09049760517674196		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.0889180965027859 | validation: 0.08169131024542416]
	TIME [epoch: 8.79 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07738874937308697		[learning rate: 0.00071415]
		[batch 20/20] avg loss: 0.08658306701972107		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.08198590819640403 | validation: 0.04605557151496617]
	TIME [epoch: 8.81 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08012610583201321		[learning rate: 0.0007107]
		[batch 20/20] avg loss: 0.11556148182949744		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.0978437938307553 | validation: 0.054325053426967404]
	TIME [epoch: 8.79 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05807039986749398		[learning rate: 0.00070726]
		[batch 20/20] avg loss: 0.10072242263086692		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.07939641124918047 | validation: 0.01895628613801301]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_597.pth
	Model improved!!!
EPOCH 598/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06733783444102026		[learning rate: 0.00070384]
		[batch 20/20] avg loss: 0.10225341206726064		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.08479562325414047 | validation: 0.03041510664835559]
	TIME [epoch: 8.78 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08423107748621292		[learning rate: 0.00070044]
		[batch 20/20] avg loss: 0.08676878220987487		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.08549992984804392 | validation: 0.05515616749110207]
	TIME [epoch: 8.78 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09776325543609585		[learning rate: 0.00069705]
		[batch 20/20] avg loss: 0.11182551482045569		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.10479438512827574 | validation: 0.1114418148711791]
	TIME [epoch: 8.81 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09103029604793356		[learning rate: 0.00069368]
		[batch 20/20] avg loss: 0.07693956460085848		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.08398493032439602 | validation: 0.0731139189475723]
	TIME [epoch: 8.79 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08125327640045034		[learning rate: 0.00069032]
		[batch 20/20] avg loss: 0.06567872359252555		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.07346599999648792 | validation: 0.02215397645642969]
	TIME [epoch: 8.78 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0874372511218757		[learning rate: 0.00068699]
		[batch 20/20] avg loss: 0.1354636027934631		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.11145042695766942 | validation: 0.06266131430620808]
	TIME [epoch: 8.78 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09930527410236308		[learning rate: 0.00068366]
		[batch 20/20] avg loss: 0.1074302978979172		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.10336778600014014 | validation: 0.051624769158920954]
	TIME [epoch: 8.78 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1017992613887636		[learning rate: 0.00068036]
		[batch 20/20] avg loss: 0.06775611070946629		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.08477768604911497 | validation: 0.035874002907859276]
	TIME [epoch: 8.79 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09991886765880034		[learning rate: 0.00067707]
		[batch 20/20] avg loss: 0.08926514245460423		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.0945920050567023 | validation: 0.20347809155253677]
	TIME [epoch: 8.79 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14742316315320259		[learning rate: 0.00067379]
		[batch 20/20] avg loss: 0.09532194540838732		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.12137255428079494 | validation: 0.08871400622897382]
	TIME [epoch: 8.78 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20323266282828908		[learning rate: 0.00067053]
		[batch 20/20] avg loss: 0.09453005744317992		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.1488813601357345 | validation: 0.06408899434492653]
	TIME [epoch: 8.78 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07029867068417456		[learning rate: 0.00066729]
		[batch 20/20] avg loss: 0.1029882291837639		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.08664344993396922 | validation: 0.05231099591835395]
	TIME [epoch: 8.78 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.061576014484818954		[learning rate: 0.00066406]
		[batch 20/20] avg loss: 0.08739349547324413		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.07448475497903155 | validation: 0.06456014101519485]
	TIME [epoch: 8.77 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13162387562206684		[learning rate: 0.00066085]
		[batch 20/20] avg loss: 0.10703037007543519		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.119327122848751 | validation: 0.07949078797560274]
	TIME [epoch: 8.8 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08054464624439925		[learning rate: 0.00065766]
		[batch 20/20] avg loss: 0.07077036423262718		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.07565750523851322 | validation: 0.07900429692838588]
	TIME [epoch: 8.78 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08365679880838793		[learning rate: 0.00065448]
		[batch 20/20] avg loss: 0.09893300432154827		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.09129490156496808 | validation: 0.09334946511647463]
	TIME [epoch: 8.79 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07429527720663558		[learning rate: 0.00065131]
		[batch 20/20] avg loss: 0.08467634636078565		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.07948581178371061 | validation: 0.15846649935461754]
	TIME [epoch: 8.78 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19607339593020479		[learning rate: 0.00064816]
		[batch 20/20] avg loss: 0.07259271898845929		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.13433305745933205 | validation: 0.1080612325670875]
	TIME [epoch: 8.78 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0907608703909486		[learning rate: 0.00064503]
		[batch 20/20] avg loss: 0.07803441718115056		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.0843976437860496 | validation: 0.13469509167633892]
	TIME [epoch: 8.8 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08601390677665388		[learning rate: 0.00064191]
		[batch 20/20] avg loss: 0.08782791292185661		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.08692090984925524 | validation: 0.09062922037321974]
	TIME [epoch: 8.79 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09053031053305086		[learning rate: 0.00063881]
		[batch 20/20] avg loss: 0.08834343318661446		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.08943687185983265 | validation: 0.06902787940689276]
	TIME [epoch: 8.78 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08435351118789347		[learning rate: 0.00063572]
		[batch 20/20] avg loss: 0.08119427524601922		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.08277389321695636 | validation: 0.03554143143577422]
	TIME [epoch: 8.79 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08326641664519935		[learning rate: 0.00063264]
		[batch 20/20] avg loss: 0.09485611129634791		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.08906126397077363 | validation: 0.03737284467762221]
	TIME [epoch: 8.78 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.057697250670712096		[learning rate: 0.00062958]
		[batch 20/20] avg loss: 0.07559134306941533		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.06664429687006371 | validation: 0.01842665190799101]
	TIME [epoch: 8.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_621.pth
	Model improved!!!
EPOCH 622/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05882945229467938		[learning rate: 0.00062654]
		[batch 20/20] avg loss: 0.08183046890389314		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.07032996059928627 | validation: 0.03802657185238873]
	TIME [epoch: 8.79 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11399362586282598		[learning rate: 0.00062351]
		[batch 20/20] avg loss: 0.11595144673083646		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.11497253629683121 | validation: 0.025851830380780188]
	TIME [epoch: 8.79 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06505356652493997		[learning rate: 0.00062049]
		[batch 20/20] avg loss: 0.06792822624502613		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.06649089638498307 | validation: 0.03044524419120596]
	TIME [epoch: 8.78 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12550836259748357		[learning rate: 0.00061749]
		[batch 20/20] avg loss: 0.1177316447872703		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.12162000369237694 | validation: 0.03314613824932306]
	TIME [epoch: 8.79 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10041437047174366		[learning rate: 0.00061451]
		[batch 20/20] avg loss: 0.09610840471902395		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.0982613875953838 | validation: 0.032288496759112426]
	TIME [epoch: 8.79 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08085841944048486		[learning rate: 0.00061153]
		[batch 20/20] avg loss: 0.07223714432298363		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.07654778188173425 | validation: 0.0636459742200188]
	TIME [epoch: 8.81 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06923862872521357		[learning rate: 0.00060858]
		[batch 20/20] avg loss: 0.08658008417181684		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.07790935644851521 | validation: 0.05627426511693301]
	TIME [epoch: 8.79 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06294635563039472		[learning rate: 0.00060563]
		[batch 20/20] avg loss: 0.08344297014602159		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.07319466288820814 | validation: 0.1115188308565363]
	TIME [epoch: 8.78 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08662230052664309		[learning rate: 0.00060271]
		[batch 20/20] avg loss: 0.07175954489393592		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.0791909227102895 | validation: 0.0672464756374714]
	TIME [epoch: 8.78 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10622554580160266		[learning rate: 0.00059979]
		[batch 20/20] avg loss: 0.057024259133917864		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.08162490246776027 | validation: 0.1304117719519527]
	TIME [epoch: 8.79 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08625022743000892		[learning rate: 0.00059689]
		[batch 20/20] avg loss: 0.0697473162693199		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.07799877184966442 | validation: 0.026539078019608333]
	TIME [epoch: 8.8 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08954749330625533		[learning rate: 0.000594]
		[batch 20/20] avg loss: 0.13253640097349104		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.11104194713987318 | validation: 0.034413862908120686]
	TIME [epoch: 8.78 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.073797125742734		[learning rate: 0.00059113]
		[batch 20/20] avg loss: 0.10050502252972933		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.08715107413623165 | validation: 0.17264808805957224]
	TIME [epoch: 8.79 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10287364775957306		[learning rate: 0.00058827]
		[batch 20/20] avg loss: 0.07452797732534629		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.08870081254245968 | validation: 0.1822892323128486]
	TIME [epoch: 8.78 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14948195173939988		[learning rate: 0.00058543]
		[batch 20/20] avg loss: 0.0922414360822729		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.12086169391083641 | validation: 0.08470417772412703]
	TIME [epoch: 8.79 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12151517768091358		[learning rate: 0.0005826]
		[batch 20/20] avg loss: 0.06729051633232616		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.09440284700661986 | validation: 0.06732146318183893]
	TIME [epoch: 8.8 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07793468079573035		[learning rate: 0.00057978]
		[batch 20/20] avg loss: 0.0906549605726222		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.08429482068417628 | validation: 0.02738156737224776]
	TIME [epoch: 8.78 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0645561987827775		[learning rate: 0.00057698]
		[batch 20/20] avg loss: 0.0948037314725029		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.07967996512764021 | validation: 0.0402551882013572]
	TIME [epoch: 8.77 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10668675958897364		[learning rate: 0.00057419]
		[batch 20/20] avg loss: 0.06435764873669456		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.0855222041628341 | validation: 0.034505876167787525]
	TIME [epoch: 8.79 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06346845489590762		[learning rate: 0.00057141]
		[batch 20/20] avg loss: 0.09783370905592484		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.08065108197591624 | validation: 0.1303766388894509]
	TIME [epoch: 8.79 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09761243721855237		[learning rate: 0.00056865]
		[batch 20/20] avg loss: 0.09921497657868476		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.09841370689861856 | validation: 0.06835439927454996]
	TIME [epoch: 8.81 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10055703247817278		[learning rate: 0.0005659]
		[batch 20/20] avg loss: 0.09492821130066045		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.09774262188941661 | validation: 0.1204547777751567]
	TIME [epoch: 8.78 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08296095345971123		[learning rate: 0.00056316]
		[batch 20/20] avg loss: 0.08543539205117742		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.0841981727554443 | validation: 0.05282686093776982]
	TIME [epoch: 8.76 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08011512126716688		[learning rate: 0.00056044]
		[batch 20/20] avg loss: 0.06476003760277163		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.07243757943496927 | validation: 0.02842769957843458]
	TIME [epoch: 8.78 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06707001452197896		[learning rate: 0.00055773]
		[batch 20/20] avg loss: 0.08199465863522223		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.0745323365786006 | validation: 0.024424475522294146]
	TIME [epoch: 8.79 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06734850519205944		[learning rate: 0.00055503]
		[batch 20/20] avg loss: 0.06411908071648435		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.06573379295427188 | validation: 0.033054663198459344]
	TIME [epoch: 8.81 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06359412331286021		[learning rate: 0.00055235]
		[batch 20/20] avg loss: 0.07282496868781183		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.06820954600033603 | validation: 0.028422391356162854]
	TIME [epoch: 8.78 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0755911752274228		[learning rate: 0.00054967]
		[batch 20/20] avg loss: 0.07383927125680281		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.0747152232421128 | validation: 0.06864102766353251]
	TIME [epoch: 8.78 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0711317863791874		[learning rate: 0.00054702]
		[batch 20/20] avg loss: 0.08486942729532151		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.07800060683725446 | validation: 0.05765969108581043]
	TIME [epoch: 8.78 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0831471872951785		[learning rate: 0.00054437]
		[batch 20/20] avg loss: 0.05848299921484699		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.07081509325501276 | validation: 0.03627422322355804]
	TIME [epoch: 8.77 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07464622212445045		[learning rate: 0.00054174]
		[batch 20/20] avg loss: 0.06696262343380835		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.07080442277912943 | validation: 0.019212008123361164]
	TIME [epoch: 8.79 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06513764696972638		[learning rate: 0.00053912]
		[batch 20/20] avg loss: 0.09737118729135694		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.08125441713054164 | validation: 0.07409383826400326]
	TIME [epoch: 8.79 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07562958496232028		[learning rate: 0.00053651]
		[batch 20/20] avg loss: 0.10005120379342214		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.08784039437787121 | validation: 0.07437935018720197]
	TIME [epoch: 8.78 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08698334369427024		[learning rate: 0.00053392]
		[batch 20/20] avg loss: 0.07467346619540113		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.0808284049448357 | validation: 0.021682349127196902]
	TIME [epoch: 8.79 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06036750722415822		[learning rate: 0.00053134]
		[batch 20/20] avg loss: 0.0747447092909066		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.06755610825753242 | validation: 0.07414458994729753]
	TIME [epoch: 8.78 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06326823110092342		[learning rate: 0.00052877]
		[batch 20/20] avg loss: 0.07968207185247413		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.07147515147669876 | validation: 0.11409815043789917]
	TIME [epoch: 8.79 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06245442865521354		[learning rate: 0.00052621]
		[batch 20/20] avg loss: 0.08196481402061159		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.0722096213379126 | validation: 0.05194446358822565]
	TIME [epoch: 8.8 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08861975239427188		[learning rate: 0.00052366]
		[batch 20/20] avg loss: 0.08208458645761937		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.08535216942594562 | validation: 0.13408497079197165]
	TIME [epoch: 8.78 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11804523696669662		[learning rate: 0.00052113]
		[batch 20/20] avg loss: 0.07755359282503284		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.09779941489586474 | validation: 0.06421479823845443]
	TIME [epoch: 8.78 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07122852048746102		[learning rate: 0.00051861]
		[batch 20/20] avg loss: 0.08926620211312065		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.08024736130029084 | validation: 0.5327727117076494]
	TIME [epoch: 8.79 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1773969919130551		[learning rate: 0.0005161]
		[batch 20/20] avg loss: 0.06767753161872339		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.12253726176588924 | validation: 0.053695459448551294]
	TIME [epoch: 8.79 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0907893239370751		[learning rate: 0.00051361]
		[batch 20/20] avg loss: 0.06405404792120822		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.07742168592914167 | validation: 0.022205335316108847]
	TIME [epoch: 8.8 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07156493349595175		[learning rate: 0.00051112]
		[batch 20/20] avg loss: 0.06481998662982459		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.06819246006288818 | validation: 0.07575892263545957]
	TIME [epoch: 8.78 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0749605349104427		[learning rate: 0.00050865]
		[batch 20/20] avg loss: 0.061527982621430465		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.06824425876593658 | validation: 0.02169874002274039]
	TIME [epoch: 8.79 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06319962721902572		[learning rate: 0.00050619]
		[batch 20/20] avg loss: 0.07254819778640527		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.06787391250271549 | validation: 0.15013319425251345]
	TIME [epoch: 8.78 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08132596795236255		[learning rate: 0.00050374]
		[batch 20/20] avg loss: 0.07630332458932591		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.07881464627084425 | validation: 0.053711845059636554]
	TIME [epoch: 8.78 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06837260235030798		[learning rate: 0.00050131]
		[batch 20/20] avg loss: 0.07968510081950975		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.07402885158490888 | validation: 0.0824785835783366]
	TIME [epoch: 8.82 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07767549155651618		[learning rate: 0.00049888]
		[batch 20/20] avg loss: 0.06757175597819397		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.07262362376735508 | validation: 0.13920303581764373]
	TIME [epoch: 8.79 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07853161989148524		[learning rate: 0.00049647]
		[batch 20/20] avg loss: 0.0800180396022266		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.07927482974685592 | validation: 0.08044226652063952]
	TIME [epoch: 8.79 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06438876789813464		[learning rate: 0.00049407]
		[batch 20/20] avg loss: 0.04851551710218767		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.05645214250016116 | validation: 0.020981835656176912]
	TIME [epoch: 8.79 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0640264138602474		[learning rate: 0.00049168]
		[batch 20/20] avg loss: 0.04294751613276378		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.053486964996505584 | validation: 0.061146355829716184]
	TIME [epoch: 8.79 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06961706108523276		[learning rate: 0.0004893]
		[batch 20/20] avg loss: 0.09880370452360587		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.08421038280441931 | validation: 0.03229617582974394]
	TIME [epoch: 8.81 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07376360654502695		[learning rate: 0.00048694]
		[batch 20/20] avg loss: 0.08603436823086857		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.07989898738794776 | validation: 0.11040996025273644]
	TIME [epoch: 8.79 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11848131668929866		[learning rate: 0.00048458]
		[batch 20/20] avg loss: 0.0680426780238771		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.09326199735658788 | validation: 0.047864320804615584]
	TIME [epoch: 8.78 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09581910720027882		[learning rate: 0.00048224]
		[batch 20/20] avg loss: 0.09089957551190143		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.09335934135609011 | validation: 0.03857876577663604]
	TIME [epoch: 8.78 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10160417318803346		[learning rate: 0.00047991]
		[batch 20/20] avg loss: 0.1503928585179688		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.12599851585300115 | validation: 0.14716798582882007]
	TIME [epoch: 8.78 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07827545671394807		[learning rate: 0.00047759]
		[batch 20/20] avg loss: 0.054649293823398795		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.06646237526867342 | validation: 0.0321170343151694]
	TIME [epoch: 8.8 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07916666554956245		[learning rate: 0.00047528]
		[batch 20/20] avg loss: 0.08422999116820187		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.08169832835888216 | validation: 0.033971113673702175]
	TIME [epoch: 8.79 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06780075743592329		[learning rate: 0.00047298]
		[batch 20/20] avg loss: 0.062293295926960944		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.0650470266814421 | validation: 0.013840350093285332]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_680.pth
	Model improved!!!
EPOCH 681/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04858788565049551		[learning rate: 0.00047069]
		[batch 20/20] avg loss: 0.0722994645676825		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.06044367510908901 | validation: 0.3106532718492489]
	TIME [epoch: 8.78 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11577654447366414		[learning rate: 0.00046842]
		[batch 20/20] avg loss: 0.0857688292012036		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.10077268683743386 | validation: 0.09160213780884345]
	TIME [epoch: 8.77 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07543866254466283		[learning rate: 0.00046615]
		[batch 20/20] avg loss: 0.04928241434240551		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.06236053844353416 | validation: 0.040588132072940444]
	TIME [epoch: 8.78 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08170087942320803		[learning rate: 0.0004639]
		[batch 20/20] avg loss: 0.06387527484401112		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.07278807713360959 | validation: 0.03978919004753416]
	TIME [epoch: 8.8 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09387361056088313		[learning rate: 0.00046165]
		[batch 20/20] avg loss: 0.07583444968626347		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.0848540301235733 | validation: 0.1518437057574091]
	TIME [epoch: 8.78 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11431884535111252		[learning rate: 0.00045942]
		[batch 20/20] avg loss: 0.054444316831065834		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.08438158109108918 | validation: 0.08822330723403972]
	TIME [epoch: 8.79 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07292881516712736		[learning rate: 0.0004572]
		[batch 20/20] avg loss: 0.045742385463716784		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.05933560031542208 | validation: 0.05404974901587046]
	TIME [epoch: 8.78 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07198679889049739		[learning rate: 0.00045499]
		[batch 20/20] avg loss: 0.056402336564439305		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.06419456772746836 | validation: 0.014632410794861272]
	TIME [epoch: 8.79 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.060059222571699086		[learning rate: 0.00045279]
		[batch 20/20] avg loss: 0.06871641226432255		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.06438781741801082 | validation: 0.020517630541385952]
	TIME [epoch: 8.79 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05198658559641141		[learning rate: 0.0004506]
		[batch 20/20] avg loss: 0.11405202852973047		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.08301930706307094 | validation: 0.03377509923425218]
	TIME [epoch: 8.78 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07075473819989511		[learning rate: 0.00044842]
		[batch 20/20] avg loss: 0.05215418749469947		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.061454462847297275 | validation: 0.018664867164897247]
	TIME [epoch: 8.77 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04508895346977827		[learning rate: 0.00044625]
		[batch 20/20] avg loss: 0.07306832831196897		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.05907864089087363 | validation: 0.08610733906815467]
	TIME [epoch: 8.77 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05369602195842088		[learning rate: 0.00044409]
		[batch 20/20] avg loss: 0.08525561927592816		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.06947582061717453 | validation: 0.032628704954645565]
	TIME [epoch: 8.76 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07083474147171188		[learning rate: 0.00044195]
		[batch 20/20] avg loss: 0.05768093097572511		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.06425783622371849 | validation: 0.034406666946876156]
	TIME [epoch: 8.8 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.044953057624041004		[learning rate: 0.00043981]
		[batch 20/20] avg loss: 0.03905067833677418		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.04200186798040759 | validation: 0.027457389959234867]
	TIME [epoch: 8.76 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0698480748792472		[learning rate: 0.00043768]
		[batch 20/20] avg loss: 0.06559016725685113		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.06771912106804914 | validation: 0.09300820534786156]
	TIME [epoch: 8.77 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07660645659772683		[learning rate: 0.00043556]
		[batch 20/20] avg loss: 0.0586810983177668		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.06764377745774679 | validation: 0.07178650502094096]
	TIME [epoch: 8.77 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050530703382366114		[learning rate: 0.00043346]
		[batch 20/20] avg loss: 0.07314086050388925		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.061835781943127686 | validation: 0.021676985654075522]
	TIME [epoch: 8.78 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05958509359197227		[learning rate: 0.00043136]
		[batch 20/20] avg loss: 0.08671482909276486		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.07314996134236856 | validation: 0.06197158243408664]
	TIME [epoch: 8.8 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09591785461511156		[learning rate: 0.00042928]
		[batch 20/20] avg loss: 0.039024689060256086		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.06747127183768381 | validation: 0.03096444570025754]
	TIME [epoch: 8.78 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06284275698380107		[learning rate: 0.0004272]
		[batch 20/20] avg loss: 0.1315505694813253		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.09719666323256318 | validation: 0.0291680621806406]
	TIME [epoch: 8.77 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04781949670233185		[learning rate: 0.00042513]
		[batch 20/20] avg loss: 0.07453510331109045		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.06117730000671116 | validation: 0.04253174754944729]
	TIME [epoch: 8.77 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06729078639311893		[learning rate: 0.00042308]
		[batch 20/20] avg loss: 0.054806304725051505		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.06104854555908522 | validation: 0.15035720353482107]
	TIME [epoch: 8.78 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08370900694553712		[learning rate: 0.00042103]
		[batch 20/20] avg loss: 0.07318154006635319		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.07844527350594518 | validation: 0.02402311797349225]
	TIME [epoch: 8.79 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0599200206518839		[learning rate: 0.000419]
		[batch 20/20] avg loss: 0.08540714219186232		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.07266358142187311 | validation: 0.03368934974384019]
	TIME [epoch: 8.78 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06201028187074757		[learning rate: 0.00041697]
		[batch 20/20] avg loss: 0.06453720952952434		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.06327374570013597 | validation: 0.018066297948250192]
	TIME [epoch: 8.77 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05230645575271566		[learning rate: 0.00041495]
		[batch 20/20] avg loss: 0.0482360647771294		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.050271260264922527 | validation: 0.03595747539293219]
	TIME [epoch: 8.78 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05763548637770285		[learning rate: 0.00041295]
		[batch 20/20] avg loss: 0.04198670120737338		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.049811093792538105 | validation: 0.030553808449799533]
	TIME [epoch: 8.78 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05952118008211221		[learning rate: 0.00041095]
		[batch 20/20] avg loss: 0.06295840572176602		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.06123979290193911 | validation: 0.08975245924082002]
	TIME [epoch: 8.79 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05232259078707443		[learning rate: 0.00040896]
		[batch 20/20] avg loss: 0.05181326656430767		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.05206792867569106 | validation: 0.053871148034885435]
	TIME [epoch: 8.79 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09660951423286541		[learning rate: 0.00040699]
		[batch 20/20] avg loss: 0.055041415032539544		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.0758254646327025 | validation: 0.021279042054665742]
	TIME [epoch: 8.78 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.062075976276579826		[learning rate: 0.00040502]
		[batch 20/20] avg loss: 0.055496509795506965		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.058786243036043406 | validation: 0.012766354283158962]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_712.pth
	Model improved!!!
EPOCH 713/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04423995241007408		[learning rate: 0.00040306]
		[batch 20/20] avg loss: 0.06223718522822479		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.05323856881914944 | validation: 0.08855377358744826]
	TIME [epoch: 8.78 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.054076843176177544		[learning rate: 0.00040111]
		[batch 20/20] avg loss: 0.05408461628884442		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.05408072973251097 | validation: 0.08553649939058487]
	TIME [epoch: 8.79 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.054080035172556926		[learning rate: 0.00039917]
		[batch 20/20] avg loss: 0.06738442293723529		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.060732229054896114 | validation: 0.1000759318635149]
	TIME [epoch: 8.79 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07833747190327155		[learning rate: 0.00039724]
		[batch 20/20] avg loss: 0.06051354730681261		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.0694255096050421 | validation: 0.057285956420108496]
	TIME [epoch: 8.78 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03718993742736666		[learning rate: 0.00039532]
		[batch 20/20] avg loss: 0.0541235568166599		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.04565674712201327 | validation: 0.04473381238501191]
	TIME [epoch: 8.78 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.050355820918770465		[learning rate: 0.00039341]
		[batch 20/20] avg loss: 0.040267727642039175		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.045311774280404817 | validation: 0.09429834971776696]
	TIME [epoch: 8.78 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.056428740379807454		[learning rate: 0.0003915]
		[batch 20/20] avg loss: 0.0673988965369053		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.06191381845835636 | validation: 0.15273024326667078]
	TIME [epoch: 8.79 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07041071834651584		[learning rate: 0.00038961]
		[batch 20/20] avg loss: 0.08350394317423035		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.07695733076037306 | validation: 0.022487020616561257]
	TIME [epoch: 8.8 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.049609919194258285		[learning rate: 0.00038773]
		[batch 20/20] avg loss: 0.056955837670835896		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.05328287843254709 | validation: 0.07326131589422098]
	TIME [epoch: 8.78 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05192602241215875		[learning rate: 0.00038585]
		[batch 20/20] avg loss: 0.056613130916056784		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.054269576664107776 | validation: 0.05207916405244814]
	TIME [epoch: 8.79 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03876811150758547		[learning rate: 0.00038399]
		[batch 20/20] avg loss: 0.07916026815391984		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.058964189830752654 | validation: 0.0570464939256633]
	TIME [epoch: 8.78 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03778417081445788		[learning rate: 0.00038213]
		[batch 20/20] avg loss: 0.034761316225378855		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.03627274351991837 | validation: 0.08360098460943205]
	TIME [epoch: 8.79 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0838325683719944		[learning rate: 0.00038028]
		[batch 20/20] avg loss: 0.06021094926759668		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.07202175881979554 | validation: 0.03191112695501165]
	TIME [epoch: 8.82 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0563232206595539		[learning rate: 0.00037844]
		[batch 20/20] avg loss: 0.0611657707280124		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.05874449569378315 | validation: 0.04352088369003855]
	TIME [epoch: 8.78 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05990195928933817		[learning rate: 0.00037661]
		[batch 20/20] avg loss: 0.0331129813494296		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.04650747031938389 | validation: 0.031397538344303096]
	TIME [epoch: 8.78 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04473988175729663		[learning rate: 0.00037479]
		[batch 20/20] avg loss: 0.046603817481610514		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.045671849619453586 | validation: 0.04182265070737968]
	TIME [epoch: 8.78 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04947467195831852		[learning rate: 0.00037298]
		[batch 20/20] avg loss: 0.038265514979576955		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.04387009346894774 | validation: 0.03559776003423534]
	TIME [epoch: 8.78 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.056356703779665604		[learning rate: 0.00037118]
		[batch 20/20] avg loss: 0.06332127301452105		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.05983898839709334 | validation: 0.0680493722321204]
	TIME [epoch: 8.81 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06363236945100012		[learning rate: 0.00036938]
		[batch 20/20] avg loss: 0.0566779966699805		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.0601551830604903 | validation: 0.044877769685614396]
	TIME [epoch: 8.79 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06992013114191153		[learning rate: 0.00036759]
		[batch 20/20] avg loss: 0.08420858500245522		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.07706435807218337 | validation: 0.0197733897230807]
	TIME [epoch: 8.78 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04456029194427359		[learning rate: 0.00036582]
		[batch 20/20] avg loss: 0.0488661476796182		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.0467132198119459 | validation: 0.06330776668272439]
	TIME [epoch: 8.78 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08032688739166903		[learning rate: 0.00036405]
		[batch 20/20] avg loss: 0.06289337461636627		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.07161013100401765 | validation: 0.03866995265560022]
	TIME [epoch: 8.78 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.040941484201069876		[learning rate: 0.00036229]
		[batch 20/20] avg loss: 0.0759767687343921		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.05845912646773099 | validation: 0.020288306823762092]
	TIME [epoch: 8.81 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06590561911465849		[learning rate: 0.00036053]
		[batch 20/20] avg loss: 0.09191646484791748		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.078911041981288 | validation: 0.02703656201985585]
	TIME [epoch: 8.78 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.058965005906257986		[learning rate: 0.00035879]
		[batch 20/20] avg loss: 0.08331102716305702		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.0711380165346575 | validation: 0.0457215441280902]
	TIME [epoch: 8.79 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.051028784664037784		[learning rate: 0.00035706]
		[batch 20/20] avg loss: 0.08593720398064317		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.06848299432234048 | validation: 0.055668464784416755]
	TIME [epoch: 8.78 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07102115761319319		[learning rate: 0.00035533]
		[batch 20/20] avg loss: 0.0506631656609837		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.06084216163708844 | validation: 0.01719657326022511]
	TIME [epoch: 8.78 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04848546667423918		[learning rate: 0.00035361]
		[batch 20/20] avg loss: 0.05550079640751647		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.05199313154087783 | validation: 0.0692791675045025]
	TIME [epoch: 8.79 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07917356982149834		[learning rate: 0.0003519]
		[batch 20/20] avg loss: 0.062128713857278514		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.07065114183938843 | validation: 0.05509248204814584]
	TIME [epoch: 8.79 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.048121319304221574		[learning rate: 0.0003502]
		[batch 20/20] avg loss: 0.034714961454009305		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.04141814037911544 | validation: 0.013167964515504655]
	TIME [epoch: 8.78 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05418683227789378		[learning rate: 0.00034851]
		[batch 20/20] avg loss: 0.043048690308745786		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.04861776129331978 | validation: 0.07622508177933193]
	TIME [epoch: 8.78 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06819172879337451		[learning rate: 0.00034682]
		[batch 20/20] avg loss: 0.06431197594206596		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.06625185236772023 | validation: 0.017915704679505276]
	TIME [epoch: 8.79 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06381192934632743		[learning rate: 0.00034514]
		[batch 20/20] avg loss: 0.050186016772235095		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.05699897305928127 | validation: 0.046775387117394415]
	TIME [epoch: 8.79 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04311642327214321		[learning rate: 0.00034347]
		[batch 20/20] avg loss: 0.05879641857266073		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.05095642092240197 | validation: 0.02929441478592228]
	TIME [epoch: 8.8 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03789721731231059		[learning rate: 0.00034181]
		[batch 20/20] avg loss: 0.04231450318200678		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.04010586024715869 | validation: 0.0972987438879776]
	TIME [epoch: 8.79 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0557843840715723		[learning rate: 0.00034016]
		[batch 20/20] avg loss: 0.04735722992842305		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.05157080699999768 | validation: 0.031233088053446684]
	TIME [epoch: 8.78 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06666924936299576		[learning rate: 0.00033852]
		[batch 20/20] avg loss: 0.06263503158836496		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.06465214047568035 | validation: 0.12176293299091331]
	TIME [epoch: 8.79 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04971273280476389		[learning rate: 0.00033688]
		[batch 20/20] avg loss: 0.06629237355664336		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.05800255318070363 | validation: 0.019772822528590972]
	TIME [epoch: 8.79 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04414354879951836		[learning rate: 0.00033525]
		[batch 20/20] avg loss: 0.13207627431122554		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.08810991155537196 | validation: 0.03212433147713444]
	TIME [epoch: 8.81 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03862655657683771		[learning rate: 0.00033363]
		[batch 20/20] avg loss: 0.05131991241517029		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.044973234496004 | validation: 0.04061755406774567]
	TIME [epoch: 8.78 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04846692513886079		[learning rate: 0.00033202]
		[batch 20/20] avg loss: 0.036050610414739906		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.04225876777680035 | validation: 0.022014082089506705]
	TIME [epoch: 8.79 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.048261417123289276		[learning rate: 0.00033041]
		[batch 20/20] avg loss: 0.04224793817359311		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.0452546776484412 | validation: 0.030168314471971998]
	TIME [epoch: 8.79 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.036848101427341705		[learning rate: 0.00032881]
		[batch 20/20] avg loss: 0.053577952283396665		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.045213026855369175 | validation: 0.015685903302351912]
	TIME [epoch: 8.79 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.038418050192533984		[learning rate: 0.00032722]
		[batch 20/20] avg loss: 0.03957188599366181		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.03899496809309791 | validation: 0.021279338335190592]
	TIME [epoch: 8.81 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06118552866155762		[learning rate: 0.00032564]
		[batch 20/20] avg loss: 0.04882552110571806		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.055005524883637844 | validation: 0.03358053093419314]
	TIME [epoch: 8.79 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07185621359413995		[learning rate: 0.00032406]
		[batch 20/20] avg loss: 0.05103505596332412		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.061445634778732036 | validation: 0.08025767480956988]
	TIME [epoch: 8.79 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05229582912257732		[learning rate: 0.0003225]
		[batch 20/20] avg loss: 0.05692231736079869		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.054609073241688025 | validation: 0.046410071850898356]
	TIME [epoch: 8.79 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04702072019876987		[learning rate: 0.00032094]
		[batch 20/20] avg loss: 0.050379455966097275		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.04870008808243357 | validation: 0.017827321861104604]
	TIME [epoch: 8.78 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0669418376787943		[learning rate: 0.00031939]
		[batch 20/20] avg loss: 0.0692247981115556		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.06808331789517495 | validation: 0.06208748037437119]
	TIME [epoch: 8.81 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04293001324490518		[learning rate: 0.00031784]
		[batch 20/20] avg loss: 0.05820713286496636		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.05056857305493577 | validation: 0.036867684407026674]
	TIME [epoch: 8.78 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0645176898581564		[learning rate: 0.0003163]
		[batch 20/20] avg loss: 0.03524980400796222		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.0498837469330593 | validation: 0.029397912221330688]
	TIME [epoch: 8.79 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07891696534369029		[learning rate: 0.00031477]
		[batch 20/20] avg loss: 0.05002878385474813		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.06447287459921922 | validation: 0.02086466868424394]
	TIME [epoch: 8.79 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03826661072158989		[learning rate: 0.00031325]
		[batch 20/20] avg loss: 0.04693473947955008		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.04260067510056999 | validation: 0.06955394241170852]
	TIME [epoch: 8.78 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04037436469296649		[learning rate: 0.00031174]
		[batch 20/20] avg loss: 0.03974560803807808		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.040059986365522285 | validation: 0.022549809731137866]
	TIME [epoch: 8.8 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0418610014619734		[learning rate: 0.00031023]
		[batch 20/20] avg loss: 0.05319351412054796		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.04752725779126068 | validation: 0.021783120384953628]
	TIME [epoch: 8.79 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06197754638036122		[learning rate: 0.00030873]
		[batch 20/20] avg loss: 0.048594353497329414		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.055285949938845315 | validation: 0.07695469160704704]
	TIME [epoch: 8.79 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06545147589948938		[learning rate: 0.00030724]
		[batch 20/20] avg loss: 0.06924949536999384		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.06735048563474161 | validation: 0.016511328799265607]
	TIME [epoch: 8.79 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0522688404230419		[learning rate: 0.00030575]
		[batch 20/20] avg loss: 0.042543966531378374		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.04740640347721013 | validation: 0.05793058573790863]
	TIME [epoch: 8.78 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04982831339050779		[learning rate: 0.00030427]
		[batch 20/20] avg loss: 0.06267224000515466		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.05625027669783124 | validation: 0.09075870998151275]
	TIME [epoch: 8.8 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07178203680521446		[learning rate: 0.0003028]
		[batch 20/20] avg loss: 0.04239136614020077		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.05708670147270763 | validation: 0.028373588176755664]
	TIME [epoch: 8.8 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.054260934195418845		[learning rate: 0.00030134]
		[batch 20/20] avg loss: 0.04693809596981279		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.05059951508261581 | validation: 0.06583517602816341]
	TIME [epoch: 8.79 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04921689514693964		[learning rate: 0.00029988]
		[batch 20/20] avg loss: 0.04670367892175987		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.04796028703434975 | validation: 0.03343027593839408]
	TIME [epoch: 8.78 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0709695514445864		[learning rate: 0.00029843]
		[batch 20/20] avg loss: 0.049438957492605184		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.0602042544685958 | validation: 0.04218966914937257]
	TIME [epoch: 8.78 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.046532132513177185		[learning rate: 0.00029699]
		[batch 20/20] avg loss: 0.03911308704978406		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.042822609781480614 | validation: 0.06015146966025077]
	TIME [epoch: 8.79 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0405313763177711		[learning rate: 0.00029555]
		[batch 20/20] avg loss: 0.05934324825550398		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.049937312286637545 | validation: 0.019981845207217214]
	TIME [epoch: 8.8 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03832772117690834		[learning rate: 0.00029412]
		[batch 20/20] avg loss: 0.04135152369658039		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.03983962243674437 | validation: 0.01926072228694124]
	TIME [epoch: 8.78 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03961580837897903		[learning rate: 0.0002927]
		[batch 20/20] avg loss: 0.06127753226991632		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.05044667032444768 | validation: 0.05533432022396241]
	TIME [epoch: 8.77 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.036925546625591645		[learning rate: 0.00029128]
		[batch 20/20] avg loss: 0.06574740802399809		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.05133647732479487 | validation: 0.01440434635460387]
	TIME [epoch: 8.78 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04475417387598794		[learning rate: 0.00028987]
		[batch 20/20] avg loss: 0.07258799080056764		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.05867108233827778 | validation: 0.018129717536440486]
	TIME [epoch: 8.78 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06006878077582854		[learning rate: 0.00028847]
		[batch 20/20] avg loss: 0.03332132565571435		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.04669505321577145 | validation: 0.04226356560750556]
	TIME [epoch: 8.79 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04765965469205634		[learning rate: 0.00028708]
		[batch 20/20] avg loss: 0.04132488248277545		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.044492268587415895 | validation: 0.26228237138594823]
	TIME [epoch: 8.76 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0850591289401219		[learning rate: 0.00028569]
		[batch 20/20] avg loss: 0.04745376622908587		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.06625644758460389 | validation: 0.07666345202958501]
	TIME [epoch: 8.77 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0685395501069368		[learning rate: 0.00028431]
		[batch 20/20] avg loss: 0.04353334788531521		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.05603644899612602 | validation: 0.043617607442954384]
	TIME [epoch: 8.77 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05376585599739138		[learning rate: 0.00028293]
		[batch 20/20] avg loss: 0.045901133308813666		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.049833494653102516 | validation: 0.04429312917473552]
	TIME [epoch: 8.77 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03664940768728335		[learning rate: 0.00028157]
		[batch 20/20] avg loss: 0.03569477587791474		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.036172091782599045 | validation: 0.021322980075853024]
	TIME [epoch: 8.79 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04297034295238186		[learning rate: 0.0002802]
		[batch 20/20] avg loss: 0.0341121255211567		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.03854123423676928 | validation: 0.0312685097945598]
	TIME [epoch: 8.78 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04678663106298793		[learning rate: 0.00027885]
		[batch 20/20] avg loss: 0.043689814864236634		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.04523822296361228 | validation: 0.042069517486283944]
	TIME [epoch: 8.78 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07011333813117952		[learning rate: 0.0002775]
		[batch 20/20] avg loss: 0.034308419956065275		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.052210879043622406 | validation: 0.02491061502880053]
	TIME [epoch: 8.77 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.031030947131205095		[learning rate: 0.00027616]
		[batch 20/20] avg loss: 0.07699839091664518		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.05401466902392514 | validation: 0.048813574956975594]
	TIME [epoch: 8.78 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04090982047658491		[learning rate: 0.00027482]
		[batch 20/20] avg loss: 0.03163070197856922		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.036270261227577066 | validation: 0.03692567136201591]
	TIME [epoch: 8.8 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.056733102431265524		[learning rate: 0.00027349]
		[batch 20/20] avg loss: 0.04638986237674297		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.05156148240400423 | validation: 0.014113682822699208]
	TIME [epoch: 8.77 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05179314356602862		[learning rate: 0.00027217]
		[batch 20/20] avg loss: 0.06623978953798594		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.05901646655200728 | validation: 0.01425763043944215]
	TIME [epoch: 8.77 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03468206222113874		[learning rate: 0.00027086]
		[batch 20/20] avg loss: 0.050860033715201425		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.042771047968170085 | validation: 0.03479645635271885]
	TIME [epoch: 8.77 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03890213706718777		[learning rate: 0.00026955]
		[batch 20/20] avg loss: 0.04956947896405117		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.04423580801561948 | validation: 0.012283695025843226]
	TIME [epoch: 8.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_796.pth
	Model improved!!!
EPOCH 797/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05754672373066261		[learning rate: 0.00026824]
		[batch 20/20] avg loss: 0.030322635552475025		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.04393467964156882 | validation: 0.02831943349476142]
	TIME [epoch: 8.8 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04155208711680597		[learning rate: 0.00026694]
		[batch 20/20] avg loss: 0.05447151866143498		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.04801180288912048 | validation: 0.014979489316225123]
	TIME [epoch: 8.79 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04791749968927724		[learning rate: 0.00026565]
		[batch 20/20] avg loss: 0.041166318458706955		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.044541909073992095 | validation: 0.015699333713604602]
	TIME [epoch: 8.78 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0644496997158198		[learning rate: 0.00026437]
		[batch 20/20] avg loss: 0.03371818880870345		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.04908394426226163 | validation: 0.021716153491202837]
	TIME [epoch: 8.78 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05930077549515498		[learning rate: 0.00026309]
		[batch 20/20] avg loss: 0.03070510386151264		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.04500293967833381 | validation: 0.020400978638536654]
	TIME [epoch: 8.79 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03080102440906534		[learning rate: 0.00026182]
		[batch 20/20] avg loss: 0.04062996541773032		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.03571549491339783 | validation: 0.043372783024151096]
	TIME [epoch: 8.79 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.030287830280157062		[learning rate: 0.00026055]
		[batch 20/20] avg loss: 0.05922712642579127		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.04475747835297416 | validation: 0.07162037788637729]
	TIME [epoch: 8.79 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04567330129614336		[learning rate: 0.00025929]
		[batch 20/20] avg loss: 0.03527161197987396		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.04047245663800866 | validation: 0.024537890809077575]
	TIME [epoch: 8.78 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04286025507764861		[learning rate: 0.00025804]
		[batch 20/20] avg loss: 0.03551409089904335		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.039187172988345995 | validation: 0.04309577157901608]
	TIME [epoch: 8.78 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04359481860957981		[learning rate: 0.00025679]
		[batch 20/20] avg loss: 0.05478449468684846		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.04918965664821413 | validation: 0.03985888120390866]
	TIME [epoch: 8.78 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06641422713100256		[learning rate: 0.00025555]
		[batch 20/20] avg loss: 0.024442417435546634		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.0454283222832746 | validation: 0.02123906170011098]
	TIME [epoch: 8.78 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.051581331084533076		[learning rate: 0.00025431]
		[batch 20/20] avg loss: 0.039240159343744065		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.04541074521413858 | validation: 0.02422116047665924]
	TIME [epoch: 8.79 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03398903232418568		[learning rate: 0.00025308]
		[batch 20/20] avg loss: 0.037925399661284324		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.035957215992735006 | validation: 0.03607433045895292]
	TIME [epoch: 8.78 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.042711085624336696		[learning rate: 0.00025186]
		[batch 20/20] avg loss: 0.032465142304834674		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.03758811396458568 | validation: 0.019957682258287205]
	TIME [epoch: 8.78 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05950398768614932		[learning rate: 0.00025064]
		[batch 20/20] avg loss: 0.04011723049207693		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.049810609089113125 | validation: 0.026973767138071945]
	TIME [epoch: 8.84 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03817398824756719		[learning rate: 0.00024943]
		[batch 20/20] avg loss: 0.03520445281556191		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.036689220531564544 | validation: 0.0069647552912393005]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_812.pth
	Model improved!!!
EPOCH 813/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05003872296136007		[learning rate: 0.00024822]
		[batch 20/20] avg loss: 0.051618904232683574		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.050828813597021814 | validation: 0.023481946847690116]
	TIME [epoch: 8.82 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.035087325325832266		[learning rate: 0.00024702]
		[batch 20/20] avg loss: 0.03489826310749074		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.0349927942166615 | validation: 0.04018104990263613]
	TIME [epoch: 8.79 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05086850623887259		[learning rate: 0.00024583]
		[batch 20/20] avg loss: 0.05704911063155984		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.053958808435216235 | validation: 0.05368292800301385]
	TIME [epoch: 8.78 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.047420225497422655		[learning rate: 0.00024464]
		[batch 20/20] avg loss: 0.030183784433437482		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.03880200496543008 | validation: 0.030379422256249816]
	TIME [epoch: 8.79 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04734310847968657		[learning rate: 0.00024346]
		[batch 20/20] avg loss: 0.05085445593952727		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.049098782209606916 | validation: 0.1064496296791876]
	TIME [epoch: 8.78 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05385369470244884		[learning rate: 0.00024228]
		[batch 20/20] avg loss: 0.042047748014202344		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.04795072135832559 | validation: 0.025716301787251386]
	TIME [epoch: 8.81 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.032479791295085624		[learning rate: 0.00024111]
		[batch 20/20] avg loss: 0.031233018810369023		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.03185640505272732 | validation: 0.03592203710703364]
	TIME [epoch: 8.79 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04895641047978224		[learning rate: 0.00023994]
		[batch 20/20] avg loss: 0.05474382309750199		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.05185011678864211 | validation: 0.0317607369179378]
	TIME [epoch: 8.78 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0348498307314946		[learning rate: 0.00023878]
		[batch 20/20] avg loss: 0.02553372512495982		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.030191777928227203 | validation: 0.022757019434910708]
	TIME [epoch: 8.78 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04468455933274066		[learning rate: 0.00023763]
		[batch 20/20] avg loss: 0.08250043058516268		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.06359249495895165 | validation: 0.012435321408974435]
	TIME [epoch: 8.79 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03958015764436251		[learning rate: 0.00023648]
		[batch 20/20] avg loss: 0.03589684701918862		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.03773850233177557 | validation: 0.018341262259903245]
	TIME [epoch: 8.81 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03778426848453522		[learning rate: 0.00023533]
		[batch 20/20] avg loss: 0.04589493341369601		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.04183960094911562 | validation: 0.047166378552944276]
	TIME [epoch: 8.79 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.034652461963829026		[learning rate: 0.0002342]
		[batch 20/20] avg loss: 0.035288882187537486		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.03497067207568326 | validation: 0.036524965751789776]
	TIME [epoch: 8.78 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.034330343351279616		[learning rate: 0.00023306]
		[batch 20/20] avg loss: 0.04515675999424848		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.03974355167276404 | validation: 0.009886585653523775]
	TIME [epoch: 8.78 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04179792027760587		[learning rate: 0.00023194]
		[batch 20/20] avg loss: 0.031375366938686325		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.0365866436081461 | validation: 0.04474897416351291]
	TIME [epoch: 8.78 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03809971769456983		[learning rate: 0.00023081]
		[batch 20/20] avg loss: 0.04772190427907224		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.04291081098682103 | validation: 0.028892266725628477]
	TIME [epoch: 8.81 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.029763953379555126		[learning rate: 0.0002297]
		[batch 20/20] avg loss: 0.030561506624756256		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.03016273000215569 | validation: 0.016479560619458447]
	TIME [epoch: 8.79 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05174672007111123		[learning rate: 0.00022859]
		[batch 20/20] avg loss: 0.026620429187756745		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.03918357462943399 | validation: 0.027847383455354053]
	TIME [epoch: 8.78 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05619084249507328		[learning rate: 0.00022748]
		[batch 20/20] avg loss: 0.03028217812335418		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.04323651030921373 | validation: 0.004652661654272917]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_831.pth
	Model improved!!!
EPOCH 832/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03600198530917799		[learning rate: 0.00022638]
		[batch 20/20] avg loss: 0.058646794978435376		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.047324390143806676 | validation: 0.031634187096744405]
	TIME [epoch: 8.79 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04084836711093261		[learning rate: 0.00022529]
		[batch 20/20] avg loss: 0.029851783619762755		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.03535007536534768 | validation: 0.019113231167357286]
	TIME [epoch: 8.79 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.029850716184777824		[learning rate: 0.0002242]
		[batch 20/20] avg loss: 0.03321920040798134		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.03153495829637959 | validation: 0.045131250780348756]
	TIME [epoch: 8.8 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03325028539884582		[learning rate: 0.00022311]
		[batch 20/20] avg loss: 0.04838925613942885		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.040819770769137335 | validation: 0.027064415918169552]
	TIME [epoch: 8.78 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.041410040275705336		[learning rate: 0.00022203]
		[batch 20/20] avg loss: 0.03417999904143941		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.03779501965857237 | validation: 0.013287442499338328]
	TIME [epoch: 8.79 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03983867651229344		[learning rate: 0.00022096]
		[batch 20/20] avg loss: 0.04270529173762342		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.04127198412495843 | validation: 0.025549647702971766]
	TIME [epoch: 8.79 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05096774789625245		[learning rate: 0.00021989]
		[batch 20/20] avg loss: 0.03318126649860781		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.042074507197430125 | validation: 0.017513392163276763]
	TIME [epoch: 8.79 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.032825704415048014		[learning rate: 0.00021883]
		[batch 20/20] avg loss: 0.034777558984447635		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.03380163169974783 | validation: 0.013536996480377598]
	TIME [epoch: 8.8 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02829087446578642		[learning rate: 0.00021777]
		[batch 20/20] avg loss: 0.029589186707422954		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.02894003058660468 | validation: 0.051941566533370565]
	TIME [epoch: 8.79 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0396246452533687		[learning rate: 0.00021672]
		[batch 20/20] avg loss: 0.037397959237159224		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.03851130224526395 | validation: 0.008089949700014809]
	TIME [epoch: 8.79 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03386384177559455		[learning rate: 0.00021567]
		[batch 20/20] avg loss: 0.04713646342795254		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.04050015260177355 | validation: 0.020619216040452498]
	TIME [epoch: 8.78 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03373913397057737		[learning rate: 0.00021463]
		[batch 20/20] avg loss: 0.041314102510377856		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.03752661824047761 | validation: 0.03886554794682857]
	TIME [epoch: 8.79 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03962899545490879		[learning rate: 0.00021359]
		[batch 20/20] avg loss: 0.058524893852633084		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.049076944653770944 | validation: 0.024697091962891285]
	TIME [epoch: 8.82 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04127288676232688		[learning rate: 0.00021256]
		[batch 20/20] avg loss: 0.04223951447448466		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.04175620061840578 | validation: 0.03260353848335602]
	TIME [epoch: 8.79 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.039969088515456455		[learning rate: 0.00021153]
		[batch 20/20] avg loss: 0.03848879784286316		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.039228943179159814 | validation: 0.024123046213698852]
	TIME [epoch: 8.78 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.037512210171137324		[learning rate: 0.00021051]
		[batch 20/20] avg loss: 0.045954482897071894		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.04173334653410461 | validation: 0.03578536508007465]
	TIME [epoch: 8.78 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04226795671647572		[learning rate: 0.00020949]
		[batch 20/20] avg loss: 0.033579793152792276		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.037923874934634 | validation: 0.025554238344196532]
	TIME [epoch: 8.78 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.029000645429346373		[learning rate: 0.00020847]
		[batch 20/20] avg loss: 0.04474476075548542		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.0368727030924159 | validation: 0.06723467422037699]
	TIME [epoch: 8.81 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03867493603940136		[learning rate: 0.00020747]
		[batch 20/20] avg loss: 0.02659058206275016		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.032632759051075766 | validation: 0.023475249705143468]
	TIME [epoch: 8.78 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.025643352701174564		[learning rate: 0.00020646]
		[batch 20/20] avg loss: 0.04152394343847012		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.033583648069822336 | validation: 0.01161844488904631]
	TIME [epoch: 8.79 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05065487419232854		[learning rate: 0.00020546]
		[batch 20/20] avg loss: 0.03622133057038281		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.04343810238135567 | validation: 0.025306049717318965]
	TIME [epoch: 8.78 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03193562700433886		[learning rate: 0.00020447]
		[batch 20/20] avg loss: 0.038538754520187075		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.03523719076226297 | validation: 0.031059562084634458]
	TIME [epoch: 8.78 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.034158302545928235		[learning rate: 0.00020348]
		[batch 20/20] avg loss: 0.026874466089413917		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.03051638431767107 | validation: 0.031239144429120565]
	TIME [epoch: 8.81 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03695638212108046		[learning rate: 0.0002025]
		[batch 20/20] avg loss: 0.03364811340924838		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.03530224776516442 | validation: 0.028708859640764438]
	TIME [epoch: 8.78 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04049071039729737		[learning rate: 0.00020152]
		[batch 20/20] avg loss: 0.030354923122899467		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.03542281676009841 | validation: 0.012636747538036747]
	TIME [epoch: 8.78 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04380214870632686		[learning rate: 0.00020054]
		[batch 20/20] avg loss: 0.0394498237163808		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.04162598621135383 | validation: 0.04995684754572145]
	TIME [epoch: 8.79 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04904942922540593		[learning rate: 0.00019957]
		[batch 20/20] avg loss: 0.037514919751036935		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.04328217448822143 | validation: 0.004525613402499489]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_858.pth
	Model improved!!!
EPOCH 859/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.029568893995904576		[learning rate: 0.00019861]
		[batch 20/20] avg loss: 0.036792644595739554		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.03318076929582207 | validation: 0.019407572342239488]
	TIME [epoch: 8.8 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03254199293864326		[learning rate: 0.00019765]
		[batch 20/20] avg loss: 0.02761400982216991		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.030078001380406588 | validation: 0.0620346664568065]
	TIME [epoch: 8.79 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03872902370896655		[learning rate: 0.00019669]
		[batch 20/20] avg loss: 0.036326447801746244		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.0375277357553564 | validation: 0.015232135298678418]
	TIME [epoch: 8.78 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03639628386275664		[learning rate: 0.00019574]
		[batch 20/20] avg loss: 0.03538445497814427		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.035890369420450464 | validation: 0.02619807397802453]
	TIME [epoch: 8.78 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.030437933286422948		[learning rate: 0.0001948]
		[batch 20/20] avg loss: 0.03544229295180392		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.03294011311911345 | validation: 0.031223713171400855]
	TIME [epoch: 8.79 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.045813409556926435		[learning rate: 0.00019385]
		[batch 20/20] avg loss: 0.051574020567397794		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.048693715062162114 | validation: 0.03833810276300695]
	TIME [epoch: 8.79 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.033782743749962235		[learning rate: 0.00019292]
		[batch 20/20] avg loss: 0.06087121775830977		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.04732698075413601 | validation: 0.024986493582510653]
	TIME [epoch: 8.8 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03868134774882186		[learning rate: 0.00019198]
		[batch 20/20] avg loss: 0.029281378960199295		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.033981363354510574 | validation: 0.08365118328738502]
	TIME [epoch: 8.78 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04967769186076735		[learning rate: 0.00019105]
		[batch 20/20] avg loss: 0.03868225893226973		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.04417997539651854 | validation: 0.02051006592040116]
	TIME [epoch: 8.78 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03319851080458109		[learning rate: 0.00019013]
		[batch 20/20] avg loss: 0.04271784599940288		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.03795817840199198 | validation: 0.009278656095446]
	TIME [epoch: 8.79 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.037351766403666775		[learning rate: 0.00018921]
		[batch 20/20] avg loss: 0.07954181632388924		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.05844679136377799 | validation: 0.033052744902063995]
	TIME [epoch: 8.79 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03423195580480996		[learning rate: 0.0001883]
		[batch 20/20] avg loss: 0.04045828585582785		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.037345120830318906 | validation: 0.047600453077241166]
	TIME [epoch: 8.8 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03265655927428589		[learning rate: 0.00018739]
		[batch 20/20] avg loss: 0.04039108362393766		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.036523821449111794 | validation: 0.027306563340619604]
	TIME [epoch: 8.79 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.033399148327669444		[learning rate: 0.00018648]
		[batch 20/20] avg loss: 0.04056573447409187		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.03698244140088066 | validation: 0.026886438243711158]
	TIME [epoch: 8.78 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.036697321082685745		[learning rate: 0.00018558]
		[batch 20/20] avg loss: 0.03659481937715456		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.036646070229920155 | validation: 0.03017809732387509]
	TIME [epoch: 8.79 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.030475738604049913		[learning rate: 0.00018468]
		[batch 20/20] avg loss: 0.030863220797361292		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.030669479700705604 | validation: 0.03139036239164967]
	TIME [epoch: 8.78 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.05019145657433569		[learning rate: 0.00018379]
		[batch 20/20] avg loss: 0.0343038035645438		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.04224763006943974 | validation: 0.026371145502345376]
	TIME [epoch: 8.82 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03949346548272817		[learning rate: 0.0001829]
		[batch 20/20] avg loss: 0.056122678735021005		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.04780807210887458 | validation: 0.014820158027270991]
	TIME [epoch: 8.79 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03336863055484527		[learning rate: 0.00018201]
		[batch 20/20] avg loss: 0.047383916976542005		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.04037627376569363 | validation: 0.014596168756898991]
	TIME [epoch: 8.79 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.027093140558760963		[learning rate: 0.00018113]
		[batch 20/20] avg loss: 0.04154897093003176		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.03432105574439636 | validation: 0.04303293709285476]
	TIME [epoch: 8.79 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.034323294022561596		[learning rate: 0.00018026]
		[batch 20/20] avg loss: 0.03590776690704719		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.0351155304648044 | validation: 0.044818778453513196]
	TIME [epoch: 8.79 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03812327448160964		[learning rate: 0.00017939]
		[batch 20/20] avg loss: 0.02732664232560485		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.032724958403607236 | validation: 0.022892853237535992]
	TIME [epoch: 8.81 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03575913544190381		[learning rate: 0.00017852]
		[batch 20/20] avg loss: 0.03245887116396223		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.034109003302933025 | validation: 0.016986253454062676]
	TIME [epoch: 8.78 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02974111933637884		[learning rate: 0.00017766]
		[batch 20/20] avg loss: 0.04356398230415617		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.0366525508202675 | validation: 0.021398239846539907]
	TIME [epoch: 8.79 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03360573191136024		[learning rate: 0.0001768]
		[batch 20/20] avg loss: 0.028672088387745442		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.031138910149552845 | validation: 0.01748281620802725]
	TIME [epoch: 8.79 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03765211538321127		[learning rate: 0.00017594]
		[batch 20/20] avg loss: 0.03233477117934162		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.03499344328127645 | validation: 0.01777326538680193]
	TIME [epoch: 8.79 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03818309682536993		[learning rate: 0.00017509]
		[batch 20/20] avg loss: 0.02666473778313534		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.032423917304252634 | validation: 0.030928264885140992]
	TIME [epoch: 8.81 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06484356410616046		[learning rate: 0.00017424]
		[batch 20/20] avg loss: 0.028350675678315652		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.046597119892238054 | validation: 0.018605295818682414]
	TIME [epoch: 8.79 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02577656221192921		[learning rate: 0.0001734]
		[batch 20/20] avg loss: 0.031579625542329334		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.028678093877129267 | validation: 0.037078901446522525]
	TIME [epoch: 8.79 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.034593408594837054		[learning rate: 0.00017256]
		[batch 20/20] avg loss: 0.04057998414293361		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.03758669636888533 | validation: 0.045623546960556365]
	TIME [epoch: 8.78 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.030313943638528063		[learning rate: 0.00017173]
		[batch 20/20] avg loss: 0.03682321280509438		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.03356857822181121 | validation: 0.008861192496536592]
	TIME [epoch: 8.79 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.040345109484037286		[learning rate: 0.0001709]
		[batch 20/20] avg loss: 0.022499281399648526		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.0314221954418429 | validation: 0.01063251671557183]
	TIME [epoch: 8.81 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.032013794235502754		[learning rate: 0.00017007]
		[batch 20/20] avg loss: 0.025256168819984597		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.02863498152774368 | validation: 0.029894492729972945]
	TIME [epoch: 8.79 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02824992779799997		[learning rate: 0.00016925]
		[batch 20/20] avg loss: 0.06034318911889848		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.04429655845844922 | validation: 0.046876711889955736]
	TIME [epoch: 8.79 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03363901818063591		[learning rate: 0.00016843]
		[batch 20/20] avg loss: 0.025397888438004133		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.029518453309320025 | validation: 0.01576899680007235]
	TIME [epoch: 8.79 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.01962557069369358		[learning rate: 0.00016762]
		[batch 20/20] avg loss: 0.026718534230365177		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.02317205246202938 | validation: 0.011809945034313532]
	TIME [epoch: 8.78 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0207225534347896		[learning rate: 0.00016681]
		[batch 20/20] avg loss: 0.02338628133993382		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.022054417387361712 | validation: 0.020340894856930684]
	TIME [epoch: 8.8 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.032185713056104924		[learning rate: 0.000166]
		[batch 20/20] avg loss: 0.046127868199128466		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.03915679062761669 | validation: 0.015972364477383115]
	TIME [epoch: 8.8 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04429586102085867		[learning rate: 0.0001652]
		[batch 20/20] avg loss: 0.029075992253849613		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.036685926637354135 | validation: 0.013349791196227704]
	TIME [epoch: 8.79 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04419863148193242		[learning rate: 0.0001644]
		[batch 20/20] avg loss: 0.031303506047456416		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.03775106876469442 | validation: 0.017515766893103597]
	TIME [epoch: 8.78 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03779064872372541		[learning rate: 0.0001636]
		[batch 20/20] avg loss: 0.02845921236342519		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.03312493054357531 | validation: 0.020427637794055726]
	TIME [epoch: 8.78 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03332363156316541		[learning rate: 0.00016281]
		[batch 20/20] avg loss: 0.036657772738775504		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.03499070215097046 | validation: 0.009944619037756886]
	TIME [epoch: 8.8 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03305586683354387		[learning rate: 0.00016202]
		[batch 20/20] avg loss: 0.04416153600739173		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.038608701420467795 | validation: 0.015764642176281925]
	TIME [epoch: 8.8 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.024413729168766374		[learning rate: 0.00016124]
		[batch 20/20] avg loss: 0.04618132597640245		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.03529752757258441 | validation: 0.017652200116964167]
	TIME [epoch: 8.78 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02869105748419416		[learning rate: 0.00016046]
		[batch 20/20] avg loss: 0.03867084331045339		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.033680950397323765 | validation: 0.008592026501512513]
	TIME [epoch: 8.78 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.023658898695569065		[learning rate: 0.00015968]
		[batch 20/20] avg loss: 0.04197949866837331		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.032819198681971196 | validation: 0.051172752713546196]
	TIME [epoch: 8.79 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04010890544241773		[learning rate: 0.00015891]
		[batch 20/20] avg loss: 0.035153284682707495		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.03763109506256261 | validation: 0.009061911701583858]
	TIME [epoch: 8.79 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.034581305667317944		[learning rate: 0.00015814]
		[batch 20/20] avg loss: 0.02698057631335917		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.03078094099033856 | validation: 0.013883539735627894]
	TIME [epoch: 8.81 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.058387304763617795		[learning rate: 0.00015738]
		[batch 20/20] avg loss: 0.030475910052460076		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.04443160740803895 | validation: 0.07278746378601025]
	TIME [epoch: 8.79 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03411117795203241		[learning rate: 0.00015662]
		[batch 20/20] avg loss: 0.036382064045530974		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.03524662099878169 | validation: 0.011344280505274043]
	TIME [epoch: 8.79 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02499626616886983		[learning rate: 0.00015586]
		[batch 20/20] avg loss: 0.02868339910233269		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.026839832635601257 | validation: 0.022384322928212873]
	TIME [epoch: 8.79 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02865501534705439		[learning rate: 0.00015511]
		[batch 20/20] avg loss: 0.03321447895899292		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.03093474715302367 | validation: 0.014929325961531235]
	TIME [epoch: 8.79 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04053236482445159		[learning rate: 0.00015436]
		[batch 20/20] avg loss: 0.031742937823189196		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.036137651323820394 | validation: 0.01216195242461223]
	TIME [epoch: 8.81 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03173726944082289		[learning rate: 0.00015361]
		[batch 20/20] avg loss: 0.03670060224630277		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.03421893584356283 | validation: 0.051403842336794785]
	TIME [epoch: 8.79 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.024147485240718528		[learning rate: 0.00015287]
		[batch 20/20] avg loss: 0.031495370494033906		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.027821427867376215 | validation: 0.015649791904617766]
	TIME [epoch: 8.78 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.014126984986591753		[learning rate: 0.00015213]
		[batch 20/20] avg loss: 0.03920971830943602		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.026668351648013892 | validation: 0.019795170501479817]
	TIME [epoch: 8.79 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.036555845798547044		[learning rate: 0.00015139]
		[batch 20/20] avg loss: 0.02813739381685515		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.0323466198077011 | validation: 0.029622436713433425]
	TIME [epoch: 8.78 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0327237626885025		[learning rate: 0.00015066]
		[batch 20/20] avg loss: 0.0311828206275371		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.03195329165801979 | validation: 0.012425043775139281]
	TIME [epoch: 8.81 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02155005946235561		[learning rate: 0.00014993]
		[batch 20/20] avg loss: 0.024583073872064706		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.02306656666721016 | validation: 0.014739983473841037]
	TIME [epoch: 8.78 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02898943741297893		[learning rate: 0.00014921]
		[batch 20/20] avg loss: 0.02579143906655169		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.0273904382397653 | validation: 0.02168020564768781]
	TIME [epoch: 8.78 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03267540772286534		[learning rate: 0.00014849]
		[batch 20/20] avg loss: 0.027685822940635495		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.030180615331750416 | validation: 0.008980307698482551]
	TIME [epoch: 8.78 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.030316715264741233		[learning rate: 0.00014777]
		[batch 20/20] avg loss: 0.026580612305773955		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.0284486637852576 | validation: 0.04900966217356638]
	TIME [epoch: 8.78 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.021308335509207025		[learning rate: 0.00014705]
		[batch 20/20] avg loss: 0.024569709083410274		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.022939022296308648 | validation: 0.019900246780774157]
	TIME [epoch: 8.8 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03547910521248658		[learning rate: 0.00014634]
		[batch 20/20] avg loss: 0.02832858603911844		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.031903845625802514 | validation: 0.010169352609053042]
	TIME [epoch: 8.79 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.028214953230826005		[learning rate: 0.00014563]
		[batch 20/20] avg loss: 0.023896674942886578		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.02605581408685629 | validation: 0.0169467308310886]
	TIME [epoch: 8.78 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03791388434765904		[learning rate: 0.00014493]
		[batch 20/20] avg loss: 0.021622097568232284		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.029767990957945672 | validation: 0.019140608303169243]
	TIME [epoch: 8.78 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.027424558547593014		[learning rate: 0.00014423]
		[batch 20/20] avg loss: 0.03021240464576882		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.028818481596680913 | validation: 0.02222108419467836]
	TIME [epoch: 8.78 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.030568485493753805		[learning rate: 0.00014353]
		[batch 20/20] avg loss: 0.036363406510478896		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.033465946002116345 | validation: 0.02864805060123545]
	TIME [epoch: 8.8 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.024577696198147318		[learning rate: 0.00014284]
		[batch 20/20] avg loss: 0.024573891340506353		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.02457579376932683 | validation: 0.006277918819739441]
	TIME [epoch: 8.79 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02911874322242012		[learning rate: 0.00014215]
		[batch 20/20] avg loss: 0.024207900799897358		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.02666332201115874 | validation: 0.034498402129614913]
	TIME [epoch: 8.78 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03247990003188554		[learning rate: 0.00014146]
		[batch 20/20] avg loss: 0.02526049410322174		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.028870197067553633 | validation: 0.009647010393288628]
	TIME [epoch: 8.78 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.027213920409586957		[learning rate: 0.00014078]
		[batch 20/20] avg loss: 0.05132252482984011		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.03926822261971352 | validation: 0.008934803245050957]
	TIME [epoch: 8.78 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.031832519941792266		[learning rate: 0.00014009]
		[batch 20/20] avg loss: 0.023816950346432764		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.02782473514411251 | validation: 0.019829409110940163]
	TIME [epoch: 8.79 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02790105938543778		[learning rate: 0.00013942]
		[batch 20/20] avg loss: 0.04162083408675456		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.03476094673609617 | validation: 0.01462360460559478]
	TIME [epoch: 8.8 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03992539393668075		[learning rate: 0.00013874]
		[batch 20/20] avg loss: 0.02506926556306723		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.03249732974987399 | validation: 0.015932808841475146]
	TIME [epoch: 8.78 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.023474657405414674		[learning rate: 0.00013807]
		[batch 20/20] avg loss: 0.03164380349419274		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.027559230449803712 | validation: 0.015287612542373945]
	TIME [epoch: 8.79 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.025695550329245854		[learning rate: 0.0001374]
		[batch 20/20] avg loss: 0.028667422015890464		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.027181486172568166 | validation: 0.03223470653666503]
	TIME [epoch: 8.77 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.037640983173564416		[learning rate: 0.00013674]
		[batch 20/20] avg loss: 0.03372707766049908		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.03568403041703174 | validation: 0.06366363826487445]
	TIME [epoch: 8.78 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03356762228947875		[learning rate: 0.00013608]
		[batch 20/20] avg loss: 0.03070417898173486		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.0321359006356068 | validation: 0.007950744300083544]
	TIME [epoch: 8.81 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.023974521372784437		[learning rate: 0.00013542]
		[batch 20/20] avg loss: 0.03022430385454592		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.02709941261366518 | validation: 0.01253562920331915]
	TIME [epoch: 8.78 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03164783718243044		[learning rate: 0.00013477]
		[batch 20/20] avg loss: 0.028585557522198622		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.03011669735231453 | validation: 0.004345379364682483]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_939.pth
	Model improved!!!
EPOCH 940/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.025022722432736667		[learning rate: 0.00013411]
		[batch 20/20] avg loss: 0.027160846616449113		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.026091784524592886 | validation: 0.013335055762776297]
	TIME [epoch: 8.78 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02653184426884178		[learning rate: 0.00013347]
		[batch 20/20] avg loss: 0.03192081569968015		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.029226329984260967 | validation: 0.009928946838440016]
	TIME [epoch: 8.79 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.021934515149523628		[learning rate: 0.00013282]
		[batch 20/20] avg loss: 0.027460933739212247		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.024697724444367943 | validation: 0.009440616580316516]
	TIME [epoch: 8.8 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02520747418024233		[learning rate: 0.00013218]
		[batch 20/20] avg loss: 0.03510796768871416		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.030157720934478244 | validation: 0.015665424686367887]
	TIME [epoch: 8.79 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03094036232903833		[learning rate: 0.00013154]
		[batch 20/20] avg loss: 0.03119801765108383		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.031069189990061086 | validation: 0.018125398804320885]
	TIME [epoch: 8.78 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04401662917923717		[learning rate: 0.0001309]
		[batch 20/20] avg loss: 0.032936317667412354		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.03847647342332476 | validation: 0.022461033862418066]
	TIME [epoch: 8.78 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.021396816173987303		[learning rate: 0.00013027]
		[batch 20/20] avg loss: 0.04717048558076681		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.034283650877377066 | validation: 0.06830124738879625]
	TIME [epoch: 8.78 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.041362562902927905		[learning rate: 0.00012964]
		[batch 20/20] avg loss: 0.023311136599536833		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.03233684975123237 | validation: 0.017667139384618107]
	TIME [epoch: 8.8 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02368285253790995		[learning rate: 0.00012901]
		[batch 20/20] avg loss: 0.0463776356070952		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.03503024407250257 | validation: 0.04878673494189664]
	TIME [epoch: 8.78 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03028676670093358		[learning rate: 0.00012839]
		[batch 20/20] avg loss: 0.034805814725511336		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.03254629071322245 | validation: 0.021234785391948452]
	TIME [epoch: 8.79 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.048675909798534665		[learning rate: 0.00012777]
		[batch 20/20] avg loss: 0.023932385981934527		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.036304147890234596 | validation: 0.007229050594237301]
	TIME [epoch: 8.79 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.023574212958607708		[learning rate: 0.00012715]
		[batch 20/20] avg loss: 0.023842240451670643		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.023708226705139175 | validation: 0.0037702099221117737]
	TIME [epoch: 8.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_951.pth
	Model improved!!!
EPOCH 952/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.029407031013000722		[learning rate: 0.00012653]
		[batch 20/20] avg loss: 0.02987666492430105		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.02964184796865088 | validation: 0.024496309181221698]
	TIME [epoch: 8.81 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.042512954353697806		[learning rate: 0.00012592]
		[batch 20/20] avg loss: 0.02904310642298249		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.03577803038834016 | validation: 0.020280686401227526]
	TIME [epoch: 8.79 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02459318802265322		[learning rate: 0.00012531]
		[batch 20/20] avg loss: 0.02978631147516721		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.027189749748910214 | validation: 0.05279424516225502]
	TIME [epoch: 8.78 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.038430941702313454		[learning rate: 0.00012471]
		[batch 20/20] avg loss: 0.03326145681534185		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.035846199258827656 | validation: 0.024167720619432457]
	TIME [epoch: 8.78 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.024935064623454555		[learning rate: 0.00012411]
		[batch 20/20] avg loss: 0.02056889064439934		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.022751977633926952 | validation: 0.013151159090633894]
	TIME [epoch: 8.78 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03523870536135852		[learning rate: 0.0001235]
		[batch 20/20] avg loss: 0.023551429084424362		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.029395067222891435 | validation: 0.012598349934509244]
	TIME [epoch: 8.8 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03076613505950989		[learning rate: 0.00012291]
		[batch 20/20] avg loss: 0.027826894669462983		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.02929651486448644 | validation: 0.035238923794910976]
	TIME [epoch: 8.8 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04446309350049403		[learning rate: 0.00012231]
		[batch 20/20] avg loss: 0.022398989953312447		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.033431041726903234 | validation: 0.01384887331430013]
	TIME [epoch: 8.78 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.020756874501495888		[learning rate: 0.00012172]
		[batch 20/20] avg loss: 0.022871615991858697		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.02181424524667729 | validation: 0.041129891085170164]
	TIME [epoch: 8.79 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02616332351620653		[learning rate: 0.00012113]
		[batch 20/20] avg loss: 0.02995876553526062		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.028061044525733568 | validation: 0.010129778368256433]
	TIME [epoch: 8.79 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.021939952409860696		[learning rate: 0.00012055]
		[batch 20/20] avg loss: 0.040896241526191805		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.03141809696802625 | validation: 0.01196771545715497]
	TIME [epoch: 8.79 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.028211675375570754		[learning rate: 0.00011996]
		[batch 20/20] avg loss: 0.04060881496845352		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.03441024517201214 | validation: 0.04980997580820455]
	TIME [epoch: 8.8 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.034549057173744895		[learning rate: 0.00011938]
		[batch 20/20] avg loss: 0.03277291009504881		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.03366098363439686 | validation: 0.01449750801185312]
	TIME [epoch: 8.78 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.025066134335907892		[learning rate: 0.00011881]
		[batch 20/20] avg loss: 0.02907143122583644		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.02706878278087217 | validation: 0.01131205278311181]
	TIME [epoch: 8.79 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.035098430241778375		[learning rate: 0.00011823]
		[batch 20/20] avg loss: 0.0272014338287493		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.03114993203526384 | validation: 0.01559375316418564]
	TIME [epoch: 8.78 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03795256453114928		[learning rate: 0.00011766]
		[batch 20/20] avg loss: 0.03239397621190248		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.035173270371525886 | validation: 0.0125161159067557]
	TIME [epoch: 8.79 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03050412079847024		[learning rate: 0.00011709]
		[batch 20/20] avg loss: 0.024411191837870844		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.02745765631817055 | validation: 0.025384496892626084]
	TIME [epoch: 8.81 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.018214225186170194		[learning rate: 0.00011653]
		[batch 20/20] avg loss: 0.038145019202865976		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.02817962219451809 | validation: 0.04619367854329569]
	TIME [epoch: 8.77 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.04240640456600952		[learning rate: 0.00011596]
		[batch 20/20] avg loss: 0.03353358082982847		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.037969992697918994 | validation: 0.010658840020976543]
	TIME [epoch: 8.78 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02466278009155807		[learning rate: 0.0001154]
		[batch 20/20] avg loss: 0.03257974175733628		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.028621260924447167 | validation: 0.025531594249208825]
	TIME [epoch: 8.77 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02729618170698218		[learning rate: 0.00011484]
		[batch 20/20] avg loss: 0.022655011516484597		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.02497559661173339 | validation: 0.0337625045597028]
	TIME [epoch: 8.79 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.024362021414643654		[learning rate: 0.00011429]
		[batch 20/20] avg loss: 0.02881073452130404		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.026586377967973845 | validation: 0.011365780477373681]
	TIME [epoch: 8.8 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.019359675315950356		[learning rate: 0.00011374]
		[batch 20/20] avg loss: 0.03661369543109276		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.027986685373521558 | validation: 0.02472678876965499]
	TIME [epoch: 8.79 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03763840946483959		[learning rate: 0.00011319]
		[batch 20/20] avg loss: 0.028102639411492224		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.032870524438165905 | validation: 0.014039594135212649]
	TIME [epoch: 8.79 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.022967795464688225		[learning rate: 0.00011264]
		[batch 20/20] avg loss: 0.028840371311095202		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.02590408338789172 | validation: 0.023880738325560293]
	TIME [epoch: 8.78 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.027767261088666735		[learning rate: 0.00011209]
		[batch 20/20] avg loss: 0.014576898472370073		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.0211720797805184 | validation: 0.04460146134777812]
	TIME [epoch: 8.79 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03092689696014701		[learning rate: 0.00011155]
		[batch 20/20] avg loss: 0.02756804536835062		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.029247471164248817 | validation: 0.009106703762174337]
	TIME [epoch: 8.81 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02371901975914391		[learning rate: 0.00011101]
		[batch 20/20] avg loss: 0.02560986978129861		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.02466444477022126 | validation: 0.012376474523605532]
	TIME [epoch: 8.79 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.026994866953451862		[learning rate: 0.00011047]
		[batch 20/20] avg loss: 0.020819750999215087		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.023907308976333478 | validation: 0.025269683770070623]
	TIME [epoch: 8.79 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.028908886472615348		[learning rate: 0.00010994]
		[batch 20/20] avg loss: 0.021993610712421542		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.02545124859251844 | validation: 0.02341119950963092]
	TIME [epoch: 8.78 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03040774373593679		[learning rate: 0.00010941]
		[batch 20/20] avg loss: 0.01684784609096131		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.023627794913449046 | validation: 0.02701220234264875]
	TIME [epoch: 8.76 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.030269388381462488		[learning rate: 0.00010888]
		[batch 20/20] avg loss: 0.029522241520731		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.029895814951096743 | validation: 0.020280524747932138]
	TIME [epoch: 8.78 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.020868357544326598		[learning rate: 0.00010835]
		[batch 20/20] avg loss: 0.01742565999001474		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.01914700876717067 | validation: 0.011454371261121385]
	TIME [epoch: 8.8 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.018602237591229413		[learning rate: 0.00010783]
		[batch 20/20] avg loss: 0.023973509524323065		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.021287873557776234 | validation: 0.023707128030296346]
	TIME [epoch: 8.78 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02751501378526105		[learning rate: 0.00010731]
		[batch 20/20] avg loss: 0.018544471201930285		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.02302974249359567 | validation: 0.015423974042485813]
	TIME [epoch: 8.78 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.041822081922603026		[learning rate: 0.00010679]
		[batch 20/20] avg loss: 0.02858582168559038		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.0352039518040967 | validation: 0.008848829010342138]
	TIME [epoch: 8.79 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03630172741212147		[learning rate: 0.00010627]
		[batch 20/20] avg loss: 0.022480873542104866		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.029391300477113164 | validation: 0.011092843635835622]
	TIME [epoch: 8.79 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0227912617529566		[learning rate: 0.00010576]
		[batch 20/20] avg loss: 0.026376331096420857		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.02458379642468873 | validation: 0.01027254652630541]
	TIME [epoch: 8.8 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.027424572697054294		[learning rate: 0.00010525]
		[batch 20/20] avg loss: 0.02980911939588814		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.02861684604647121 | validation: 0.011707372736203793]
	TIME [epoch: 8.78 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.020887854465779794		[learning rate: 0.00010474]
		[batch 20/20] avg loss: 0.024876503506913332		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.02288217898634656 | validation: 0.01102325230008279]
	TIME [epoch: 8.78 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.023505553239349837		[learning rate: 0.00010423]
		[batch 20/20] avg loss: 0.022209844293134152		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.022857698766241993 | validation: 0.009062787685434597]
	TIME [epoch: 8.78 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.020029806283715448		[learning rate: 0.00010373]
		[batch 20/20] avg loss: 0.019230398395586427		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.019630102339650936 | validation: 0.014959476593536018]
	TIME [epoch: 8.78 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.03902660771621087		[learning rate: 0.00010323]
		[batch 20/20] avg loss: 0.01657472048248754		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.027800664099349198 | validation: 0.02338299895802006]
	TIME [epoch: 8.8 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0264404105131422		[learning rate: 0.00010273]
		[batch 20/20] avg loss: 0.025337991447502994		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.025889200980322602 | validation: 0.017971888810855485]
	TIME [epoch: 8.77 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.028417490417968077		[learning rate: 0.00010223]
		[batch 20/20] avg loss: 0.020127388004698838		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.024272439211333457 | validation: 0.014354594832541845]
	TIME [epoch: 8.78 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.02050978662667318		[learning rate: 0.00010174]
		[batch 20/20] avg loss: 0.02750009203453347		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.024004939330603325 | validation: 0.016186793611368603]
	TIME [epoch: 8.78 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.023476425880322758		[learning rate: 0.00010124]
		[batch 20/20] avg loss: 0.024734862999595892		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.02410564443995932 | validation: 0.011048052410569598]
	TIME [epoch: 8.78 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.021243733600251065		[learning rate: 0.00010075]
		[batch 20/20] avg loss: 0.03131051641213475		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.02627712500619291 | validation: 0.012536092526189853]
	TIME [epoch: 8.81 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.023013026843917865		[learning rate: 0.00010027]
		[batch 20/20] avg loss: 0.031954924889239414		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.027483975866578646 | validation: 0.0031962146425754314]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240217_140927/states/model_tr_study2_1000.pth
	Model improved!!!
Finished training in 8879.802 seconds.
