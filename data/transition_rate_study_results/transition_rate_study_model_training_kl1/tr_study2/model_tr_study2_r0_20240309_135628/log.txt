Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r0', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1565955132

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.068537732519676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.068537732519676 | validation: 7.27828283814111]
	TIME [epoch: 84.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.079272384561738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.079272384561738 | validation: 6.171779670365126]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.125297170050374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.125297170050374 | validation: 5.38589887809525]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500641269476809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.500641269476809 | validation: 4.6208632431598335]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.223972744008674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.223972744008674 | validation: 4.611613175821416]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3519208378917824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3519208378917824 | validation: 2.8247361965529603]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9265958277986073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9265958277986073 | validation: 2.810763789480345]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6064335084895536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6064335084895536 | validation: 2.521730755807049]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2229094914402356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2229094914402356 | validation: 2.9927758496579533]
	TIME [epoch: 6.39 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.514217398102069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.514217398102069 | validation: 2.22542532866423]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1798685640597917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1798685640597917 | validation: 2.17090057425812]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.217768581628707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.217768581628707 | validation: 2.4399406698411124]
	TIME [epoch: 6.43 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279407177370504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.279407177370504 | validation: 1.8168744781303263]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7869906829870543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7869906829870543 | validation: 1.7761546008091211]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2801617333394715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2801617333394715 | validation: 2.001297598569128]
	TIME [epoch: 6.39 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7024267286451402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7024267286451402 | validation: 1.7193053763223418]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.662777123691856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.662777123691856 | validation: 2.379046882365948]
	TIME [epoch: 6.39 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.808386037653658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.808386037653658 | validation: 2.4202879241516637]
	TIME [epoch: 6.4 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6248075347911701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6248075347911701 | validation: 1.785556077451648]
	TIME [epoch: 6.42 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5736554959765372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5736554959765372 | validation: 1.4713550968136497]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4390096305039166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4390096305039166 | validation: 1.4892513816743236]
	TIME [epoch: 6.39 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3004433696843551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3004433696843551 | validation: 1.2033696934257978]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2783709420412326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2783709420412326 | validation: 2.065172719976931]
	TIME [epoch: 6.39 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8463931022483089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8463931022483089 | validation: 2.0715501123130045]
	TIME [epoch: 6.38 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4692910753090782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4692910753090782 | validation: 1.254055682710749]
	TIME [epoch: 6.38 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.177172167167089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.177172167167089 | validation: 1.3563333329270488]
	TIME [epoch: 6.43 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2571337939958498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2571337939958498 | validation: 2.2340130703957026]
	TIME [epoch: 6.38 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.277437135169027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.277437135169027 | validation: 1.2881180914821306]
	TIME [epoch: 6.39 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2499889199341232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2499889199341232 | validation: 1.0052728100499424]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0492321737654737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0492321737654737 | validation: 1.0196240298720765]
	TIME [epoch: 6.39 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1129956473564173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1129956473564173 | validation: 0.9568841735541921]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9926514426387072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9926514426387072 | validation: 1.474806531769951]
	TIME [epoch: 6.39 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2079104559032252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2079104559032252 | validation: 1.1148633682639169]
	TIME [epoch: 6.44 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0936545937459594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0936545937459594 | validation: 0.8542810212233342]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9848737281857808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9848737281857808 | validation: 1.0350457257964647]
	TIME [epoch: 6.39 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0075760704860486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0075760704860486 | validation: 0.9793727719641828]
	TIME [epoch: 6.39 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9117298778895571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9117298778895571 | validation: 0.968441575524592]
	TIME [epoch: 6.39 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0784746802478358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0784746802478358 | validation: 0.7131361663462292]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7431628149957565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7431628149957565 | validation: 0.9581584376003056]
	TIME [epoch: 6.38 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3421280683864412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3421280683864412 | validation: 0.8650460267755145]
	TIME [epoch: 6.41 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0142430992803884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0142430992803884 | validation: 1.0036132403525597]
	TIME [epoch: 6.38 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.802063158601128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.802063158601128 | validation: 0.6999951005927335]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.902320680053221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.902320680053221 | validation: 0.7397551673968623]
	TIME [epoch: 6.38 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6692915630338186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6692915630338186 | validation: 1.090552357586568]
	TIME [epoch: 6.38 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8740243798055358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8740243798055358 | validation: 0.5887220507729131]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7964148465777331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7964148465777331 | validation: 1.2184269468272229]
	TIME [epoch: 6.37 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8820923003967025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8820923003967025 | validation: 0.9428557784887888]
	TIME [epoch: 6.41 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7603749372549378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7603749372549378 | validation: 0.735256400266143]
	TIME [epoch: 6.38 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7883890435682587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7883890435682587 | validation: 0.5767918918125823]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6109732549806154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6109732549806154 | validation: 0.6985438640688253]
	TIME [epoch: 6.38 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7607090725446769		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.7607090725446769 | validation: 0.5566995967022215]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5661783446749906		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.5661783446749906 | validation: 0.5691173622018154]
	TIME [epoch: 6.38 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6756378399573799		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.6756378399573799 | validation: 0.5949657490711594]
	TIME [epoch: 6.38 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1460350935136463		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.1460350935136463 | validation: 0.9353141847708858]
	TIME [epoch: 6.41 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866006630342206		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.866006630342206 | validation: 0.7028250990981627]
	TIME [epoch: 6.38 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047124048324586		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.7047124048324586 | validation: 0.5214567566417554]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116827079635222		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.7116827079635222 | validation: 0.562587044042652]
	TIME [epoch: 6.38 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568457861086969		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.568457861086969 | validation: 0.5422883325482424]
	TIME [epoch: 6.38 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6669243008070338		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.6669243008070338 | validation: 0.4888335758975448]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771746494151642		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.4771746494151642 | validation: 0.6246562604869417]
	TIME [epoch: 6.38 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.63140114659129		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.63140114659129 | validation: 0.7305951078822404]
	TIME [epoch: 6.39 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65442331116164		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.65442331116164 | validation: 0.6011307498436484]
	TIME [epoch: 6.39 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687333858841528		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.687333858841528 | validation: 0.5920698677414759]
	TIME [epoch: 6.38 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6366773503107579		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.6366773503107579 | validation: 0.9637027061527534]
	TIME [epoch: 6.38 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8110181163775423		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.8110181163775423 | validation: 0.46312124299486385]
	TIME [epoch: 6.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5320663573026413		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.5320663573026413 | validation: 0.4856918694677002]
	TIME [epoch: 6.38 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5210732419417954		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.5210732419417954 | validation: 0.7739920205288467]
	TIME [epoch: 6.38 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5509577574502867		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.5509577574502867 | validation: 0.7566665696658081]
	TIME [epoch: 6.39 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8376224894987494		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.8376224894987494 | validation: 1.0052510770466152]
	TIME [epoch: 6.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7859253914476768		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.7859253914476768 | validation: 0.8174495854310314]
	TIME [epoch: 6.38 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6524370569501203		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.6524370569501203 | validation: 0.653315274829308]
	TIME [epoch: 6.38 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4265666815089821		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.4265666815089821 | validation: 0.8155656613740101]
	TIME [epoch: 6.39 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6577219051369717		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.6577219051369717 | validation: 0.4326320094563063]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5023462480839919		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.5023462480839919 | validation: 1.0068317299482992]
	TIME [epoch: 6.38 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6031146777769885		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.6031146777769885 | validation: 0.8556127265565832]
	TIME [epoch: 6.38 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.649971182545606		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.649971182545606 | validation: 0.36595940910643365]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4164779968334553		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.4164779968334553 | validation: 0.5707659187205176]
	TIME [epoch: 6.38 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49842067681946245		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.49842067681946245 | validation: 0.38289966904707323]
	TIME [epoch: 6.38 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48108088033069163		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.48108088033069163 | validation: 0.38289441805941066]
	TIME [epoch: 6.39 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5032701509736536		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.5032701509736536 | validation: 0.5348836493896515]
	TIME [epoch: 6.39 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331615004327172		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5331615004327172 | validation: 0.6013050498589183]
	TIME [epoch: 6.39 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5403922117386963		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.5403922117386963 | validation: 0.5495697520548944]
	TIME [epoch: 6.39 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5916128591819112		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.5916128591819112 | validation: 0.6675780434187274]
	TIME [epoch: 6.42 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126680947397211		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.5126680947397211 | validation: 0.6651030756465882]
	TIME [epoch: 6.39 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013433189802395		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.5013433189802395 | validation: 0.4617693003402901]
	TIME [epoch: 6.39 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3882334785120686		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.3882334785120686 | validation: 0.6122828183676626]
	TIME [epoch: 6.39 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5828677876605745		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.5828677876605745 | validation: 0.518163240332167]
	TIME [epoch: 6.39 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5045577342118366		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.5045577342118366 | validation: 0.3075076872958149]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3751004015602072		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.3751004015602072 | validation: 0.33439084565430227]
	TIME [epoch: 6.39 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6048974167147625		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.6048974167147625 | validation: 0.4985632296383228]
	TIME [epoch: 6.42 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4869194058377918		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.4869194058377918 | validation: 0.4764664006899429]
	TIME [epoch: 6.39 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47338085593009316		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.47338085593009316 | validation: 0.5867619576683724]
	TIME [epoch: 6.39 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4452363728166506		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.4452363728166506 | validation: 0.3533192729924814]
	TIME [epoch: 6.39 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46272036976711295		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.46272036976711295 | validation: 0.4114042523004973]
	TIME [epoch: 6.39 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44739175482063265		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.44739175482063265 | validation: 0.44240000683327496]
	TIME [epoch: 6.39 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45322140685484524		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.45322140685484524 | validation: 0.42016141492598486]
	TIME [epoch: 6.39 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4374553522452876		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.4374553522452876 | validation: 0.37820269930822875]
	TIME [epoch: 6.42 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34753271581710743		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.34753271581710743 | validation: 0.2863917188628213]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5890334212884085		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.5890334212884085 | validation: 0.7090919176981443]
	TIME [epoch: 6.4 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44024872059419246		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.44024872059419246 | validation: 0.3894239785368119]
	TIME [epoch: 6.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4766826820617368		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.4766826820617368 | validation: 0.2818511680449428]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38349885556086993		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.38349885556086993 | validation: 0.6597268285595836]
	TIME [epoch: 6.39 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4422515562234075		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.4422515562234075 | validation: 0.3673787283458128]
	TIME [epoch: 6.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001163299500073		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.5001163299500073 | validation: 0.68707844302886]
	TIME [epoch: 6.41 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6212277407929455		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.6212277407929455 | validation: 0.31834755222777733]
	TIME [epoch: 6.38 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42283473424308626		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.42283473424308626 | validation: 0.3176047570607675]
	TIME [epoch: 6.39 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33542113048376115		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.33542113048376115 | validation: 0.5940480414689226]
	TIME [epoch: 6.39 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4652549747605546		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.4652549747605546 | validation: 0.5339503614366483]
	TIME [epoch: 6.39 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4053790281280373		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.4053790281280373 | validation: 0.3711307248308734]
	TIME [epoch: 6.39 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3999964570713027		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.3999964570713027 | validation: 0.3205248971241321]
	TIME [epoch: 6.39 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46134838069428286		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.46134838069428286 | validation: 0.45146634678048825]
	TIME [epoch: 6.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3984335489618799		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.3984335489618799 | validation: 0.4639384418176677]
	TIME [epoch: 6.4 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4312695393813465		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.4312695393813465 | validation: 0.6636540707916033]
	TIME [epoch: 6.39 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49013127742660667		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.49013127742660667 | validation: 0.34179195783157007]
	TIME [epoch: 6.39 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3483738328762228		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.3483738328762228 | validation: 0.4049241798012305]
	TIME [epoch: 6.39 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36005380155952216		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.36005380155952216 | validation: 0.39647727958588547]
	TIME [epoch: 6.39 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38803847486862797		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.38803847486862797 | validation: 0.35195929863180014]
	TIME [epoch: 6.39 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4179908688805768		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.4179908688805768 | validation: 0.4870357062673827]
	TIME [epoch: 6.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45152933434616077		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.45152933434616077 | validation: 0.4178518663462938]
	TIME [epoch: 6.42 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3900074233151663		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.3900074233151663 | validation: 0.3010824986059178]
	TIME [epoch: 6.39 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3345726510705812		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.3345726510705812 | validation: 0.4628828028323852]
	TIME [epoch: 6.39 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47141524933888357		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.47141524933888357 | validation: 0.6733657942269693]
	TIME [epoch: 6.38 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5453351639289931		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.5453351639289931 | validation: 0.4036586924110535]
	TIME [epoch: 6.38 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34236812283019047		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.34236812283019047 | validation: 0.40029899908685296]
	TIME [epoch: 6.39 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5485544496735109		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5485544496735109 | validation: 0.5888407954975972]
	TIME [epoch: 6.39 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5022018244226342		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.5022018244226342 | validation: 0.40192452373187937]
	TIME [epoch: 6.41 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3712690975765798		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.3712690975765798 | validation: 0.26524732500839465]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5373202478938115		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.5373202478938115 | validation: 0.41196811914388326]
	TIME [epoch: 6.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36258422533014417		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.36258422533014417 | validation: 0.5332652940807739]
	TIME [epoch: 6.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6547329245866045		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.6547329245866045 | validation: 0.41437933390110787]
	TIME [epoch: 6.38 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46199826354437323		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.46199826354437323 | validation: 0.3543450652608983]
	TIME [epoch: 6.38 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47697160764832025		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.47697160764832025 | validation: 0.3355794368350036]
	TIME [epoch: 6.38 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3858492737467612		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.3858492737467612 | validation: 0.3697288970675646]
	TIME [epoch: 6.41 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4174169903016088		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.4174169903016088 | validation: 0.6033672866974945]
	TIME [epoch: 6.39 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3978443770403226		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.3978443770403226 | validation: 0.53868532789178]
	TIME [epoch: 6.38 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41593436771208847		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.41593436771208847 | validation: 0.38743149371182783]
	TIME [epoch: 6.39 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36601484895921155		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.36601484895921155 | validation: 0.8411489512467207]
	TIME [epoch: 6.39 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6268125688484927		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.6268125688484927 | validation: 0.497976686140573]
	TIME [epoch: 6.38 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5822929105879573		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.5822929105879573 | validation: 0.5459870652441717]
	TIME [epoch: 6.38 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.422490057137202		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.422490057137202 | validation: 0.472375283345971]
	TIME [epoch: 6.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558768139675724		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.558768139675724 | validation: 0.37088619896444536]
	TIME [epoch: 6.4 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934268840749279		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.3934268840749279 | validation: 0.3369737113333532]
	TIME [epoch: 6.38 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35544690812438556		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.35544690812438556 | validation: 0.6072595520337756]
	TIME [epoch: 6.39 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4580376650541851		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.4580376650541851 | validation: 0.33747090491088955]
	TIME [epoch: 6.38 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3631594537205865		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.3631594537205865 | validation: 0.2977211648800912]
	TIME [epoch: 6.39 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30854813870991227		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.30854813870991227 | validation: 0.2530265004852808]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3513909555001534		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.3513909555001534 | validation: 0.34858251708316973]
	TIME [epoch: 6.42 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3485423363174887		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.3485423363174887 | validation: 0.2926647171999865]
	TIME [epoch: 6.42 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39736211046660713		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.39736211046660713 | validation: 0.34394532461334726]
	TIME [epoch: 6.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.395244533565154		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.395244533565154 | validation: 0.3574190908525343]
	TIME [epoch: 6.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3373432010315694		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.3373432010315694 | validation: 0.2503867808908661]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2811693718172892		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.2811693718172892 | validation: 0.4966233819432992]
	TIME [epoch: 6.39 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3885651956251483		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.3885651956251483 | validation: 0.6504019737081598]
	TIME [epoch: 6.38 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45227111398143843		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.45227111398143843 | validation: 0.36930912787593706]
	TIME [epoch: 6.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049643364053913		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.3049643364053913 | validation: 0.2403883363770654]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.381141435018419		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.381141435018419 | validation: 0.3129568609628804]
	TIME [epoch: 6.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36797089093400975		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.36797089093400975 | validation: 0.36969279256721377]
	TIME [epoch: 6.39 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32216551186772424		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.32216551186772424 | validation: 0.3962588143613161]
	TIME [epoch: 6.39 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3560731795237796		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3560731795237796 | validation: 0.3408787630600408]
	TIME [epoch: 6.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4388903817222768		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.4388903817222768 | validation: 0.4164931793634451]
	TIME [epoch: 6.38 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444460456124193		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3444460456124193 | validation: 0.9713356604059138]
	TIME [epoch: 6.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5252844325610373		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.5252844325610373 | validation: 0.4665848983315575]
	TIME [epoch: 6.42 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4110147900252483		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.4110147900252483 | validation: 0.37755923426147664]
	TIME [epoch: 6.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3712945293659809		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.3712945293659809 | validation: 0.36812022611032647]
	TIME [epoch: 6.39 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4200944068996864		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.4200944068996864 | validation: 0.4739136533510813]
	TIME [epoch: 6.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39236425600386793		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.39236425600386793 | validation: 0.28592847333700966]
	TIME [epoch: 6.39 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33290082026760676		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.33290082026760676 | validation: 0.26992613356281353]
	TIME [epoch: 6.39 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4495250340290109		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.4495250340290109 | validation: 0.4840129378239285]
	TIME [epoch: 6.39 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3636900863654954		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.3636900863654954 | validation: 0.33830831185142773]
	TIME [epoch: 6.43 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4168192624374548		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.4168192624374548 | validation: 0.5550686380841239]
	TIME [epoch: 6.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36637201167568223		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.36637201167568223 | validation: 0.46664829466735946]
	TIME [epoch: 6.39 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35307250489138914		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.35307250489138914 | validation: 0.5261113636307543]
	TIME [epoch: 6.39 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7478974103845157		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.7478974103845157 | validation: 0.28035524340564855]
	TIME [epoch: 6.39 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5769090534926105		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.5769090534926105 | validation: 0.8024837144976606]
	TIME [epoch: 6.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5472769472656911		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.5472769472656911 | validation: 0.3936364713581277]
	TIME [epoch: 6.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3208786856092395		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3208786856092395 | validation: 0.3804097722114254]
	TIME [epoch: 6.44 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652506690139871		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.3652506690139871 | validation: 0.3516654351970696]
	TIME [epoch: 6.41 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31210989941177103		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.31210989941177103 | validation: 0.3394742112711217]
	TIME [epoch: 6.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454611939939079		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.454611939939079 | validation: 0.4643498753887974]
	TIME [epoch: 6.41 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39501239485333406		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.39501239485333406 | validation: 0.342376645922284]
	TIME [epoch: 6.39 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4100886433910798		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.4100886433910798 | validation: 0.41336337256985267]
	TIME [epoch: 6.39 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4861351857484423		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.4861351857484423 | validation: 0.34856388693150275]
	TIME [epoch: 6.39 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318060100270974		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.3318060100270974 | validation: 0.2957013434946114]
	TIME [epoch: 6.42 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771467773222573		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.3771467773222573 | validation: 0.2513661633799215]
	TIME [epoch: 6.42 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3902155460772584		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.3902155460772584 | validation: 0.34353084368928805]
	TIME [epoch: 6.39 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141383245312946		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.3141383245312946 | validation: 0.3509761777207598]
	TIME [epoch: 6.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34867111399427936		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.34867111399427936 | validation: 0.6070068683938481]
	TIME [epoch: 6.39 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35772370049132374		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.35772370049132374 | validation: 0.5191847581423695]
	TIME [epoch: 6.4 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615507444502159		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.5615507444502159 | validation: 0.43238913589106664]
	TIME [epoch: 6.39 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3276890578559696		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.3276890578559696 | validation: 0.5359999920351871]
	TIME [epoch: 6.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3387744846276121		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.3387744846276121 | validation: 0.38642523294221665]
	TIME [epoch: 6.42 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.575028501282468		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.575028501282468 | validation: 0.24943824229653877]
	TIME [epoch: 6.4 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4009576271786974		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.4009576271786974 | validation: 0.26699364271636905]
	TIME [epoch: 6.39 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2817134078273277		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.2817134078273277 | validation: 0.2729989098798782]
	TIME [epoch: 6.41 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25313712439190594		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.25313712439190594 | validation: 0.34839306406182624]
	TIME [epoch: 6.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3207886440996131		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.3207886440996131 | validation: 0.30748733085071683]
	TIME [epoch: 6.41 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33551280888445845		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.33551280888445845 | validation: 0.2839738016723964]
	TIME [epoch: 6.39 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3092356773436231		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.3092356773436231 | validation: 0.4296830165340868]
	TIME [epoch: 6.44 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34380405249419277		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.34380405249419277 | validation: 0.2789658833125091]
	TIME [epoch: 6.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820012459413131		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3820012459413131 | validation: 0.4335744427348081]
	TIME [epoch: 6.41 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628671611783967		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.3628671611783967 | validation: 0.3557353458215963]
	TIME [epoch: 6.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32628893224134825		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.32628893224134825 | validation: 0.3618242300676056]
	TIME [epoch: 6.4 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2901471458151129		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.2901471458151129 | validation: 0.2775642807490819]
	TIME [epoch: 6.41 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3366078606477374		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.3366078606477374 | validation: 0.3706758132639834]
	TIME [epoch: 6.4 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362079476317957		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.362079476317957 | validation: 0.4075585689392071]
	TIME [epoch: 6.43 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3580592157653447		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3580592157653447 | validation: 0.4730976984421949]
	TIME [epoch: 6.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35576728314693284		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.35576728314693284 | validation: 0.3005193671642488]
	TIME [epoch: 6.4 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.318721123117303		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.318721123117303 | validation: 0.5936344721400072]
	TIME [epoch: 6.41 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43844058995556834		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.43844058995556834 | validation: 0.32939222292390535]
	TIME [epoch: 6.39 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3801596705679982		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.3801596705679982 | validation: 1.2266571624517726]
	TIME [epoch: 6.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5179783023882877		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.5179783023882877 | validation: 0.5149967081627123]
	TIME [epoch: 6.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44880779857408126		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.44880779857408126 | validation: 0.617087089068694]
	TIME [epoch: 6.42 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4607524797864769		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.4607524797864769 | validation: 0.41377110122300875]
	TIME [epoch: 6.42 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3258959298809342		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.3258959298809342 | validation: 0.28897039273588376]
	TIME [epoch: 6.4 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403552951002962		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3403552951002962 | validation: 0.3117123585981684]
	TIME [epoch: 6.41 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3480697562048765		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.3480697562048765 | validation: 0.291766567462228]
	TIME [epoch: 6.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3096587184263738		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.3096587184263738 | validation: 0.3027140909633336]
	TIME [epoch: 6.41 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41049439235548113		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.41049439235548113 | validation: 0.2725704681295114]
	TIME [epoch: 6.4 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2774025177476383		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.2774025177476383 | validation: 0.382395459525989]
	TIME [epoch: 6.42 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4818265841072148		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.4818265841072148 | validation: 0.6354074234425997]
	TIME [epoch: 6.42 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35884680783726114		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.35884680783726114 | validation: 0.3902188282497367]
	TIME [epoch: 6.41 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.311054797859342		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.311054797859342 | validation: 0.3280638913345868]
	TIME [epoch: 6.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5878530575815519		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.5878530575815519 | validation: 0.9727793666990228]
	TIME [epoch: 6.4 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40754066322973526		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.40754066322973526 | validation: 0.36239990170283987]
	TIME [epoch: 6.39 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5287365065198814		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.5287365065198814 | validation: 0.4422701196506425]
	TIME [epoch: 6.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3244370615170016		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.3244370615170016 | validation: 0.25431743443544774]
	TIME [epoch: 6.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26700830643747114		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.26700830643747114 | validation: 0.21645390094494774]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27264516717883297		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.27264516717883297 | validation: 0.2295303933423159]
	TIME [epoch: 6.39 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25033347841508785		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.25033347841508785 | validation: 0.3134185783805411]
	TIME [epoch: 6.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30283793186008146		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.30283793186008146 | validation: 0.2153618163701826]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26430912326416933		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.26430912326416933 | validation: 0.24894205096195535]
	TIME [epoch: 6.39 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3644063755070416		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.3644063755070416 | validation: 0.20919403981976778]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.426265471994674		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.426265471994674 | validation: 0.2809723825797122]
	TIME [epoch: 6.38 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23276047118785453		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.23276047118785453 | validation: 0.23982187177828046]
	TIME [epoch: 6.43 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25318981292903486		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.25318981292903486 | validation: 0.3769176593917041]
	TIME [epoch: 6.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2817307655354354		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.2817307655354354 | validation: 0.37376975996023154]
	TIME [epoch: 6.41 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.552532584803414		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.552532584803414 | validation: 0.2124334583322408]
	TIME [epoch: 6.4 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26390793135731216		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.26390793135731216 | validation: 0.3244197049192621]
	TIME [epoch: 6.41 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4646259368443313		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.4646259368443313 | validation: 0.3460492942799681]
	TIME [epoch: 6.39 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32720393935161657		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.32720393935161657 | validation: 0.220579934900677]
	TIME [epoch: 6.39 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2913710103111726		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.2913710103111726 | validation: 0.3021616003598049]
	TIME [epoch: 6.43 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26579847014131436		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.26579847014131436 | validation: 0.21367569499397224]
	TIME [epoch: 6.41 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26558381163076716		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.26558381163076716 | validation: 0.24199568921427222]
	TIME [epoch: 6.39 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2833890102855396		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.2833890102855396 | validation: 0.22936363223121092]
	TIME [epoch: 6.4 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338823713678868		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.3338823713678868 | validation: 0.2644299220418425]
	TIME [epoch: 6.39 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23800863173517986		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.23800863173517986 | validation: 0.34309947879268476]
	TIME [epoch: 6.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926394421692159		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.3926394421692159 | validation: 0.32428923040801666]
	TIME [epoch: 6.39 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6500244190754672		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.6500244190754672 | validation: 0.30018331961116823]
	TIME [epoch: 6.43 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3554987739662576		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.3554987739662576 | validation: 0.44684858993362214]
	TIME [epoch: 6.4 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33468993026478977		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.33468993026478977 | validation: 0.43905295285638607]
	TIME [epoch: 6.41 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4436741560215312		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.4436741560215312 | validation: 0.3347071377852528]
	TIME [epoch: 6.39 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2841942093677994		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.2841942093677994 | validation: 0.37747261189321607]
	TIME [epoch: 6.4 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3022809972003951		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.3022809972003951 | validation: 0.245651089306105]
	TIME [epoch: 6.41 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28413454915879566		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.28413454915879566 | validation: 0.2554520499915561]
	TIME [epoch: 6.42 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30792209544918114		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.30792209544918114 | validation: 0.25980939593046176]
	TIME [epoch: 6.42 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25756691568683904		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.25756691568683904 | validation: 0.2729744634942264]
	TIME [epoch: 6.42 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26138918060180766		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.26138918060180766 | validation: 0.25792001409648746]
	TIME [epoch: 6.4 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25773148330119844		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.25773148330119844 | validation: 0.6446582034621028]
	TIME [epoch: 6.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4349696942279229		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.4349696942279229 | validation: 0.3683993021474794]
	TIME [epoch: 6.39 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26066675983184373		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.26066675983184373 | validation: 0.28317071508157093]
	TIME [epoch: 6.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26688315400927626		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.26688315400927626 | validation: 0.2865229324066394]
	TIME [epoch: 6.4 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940567653964035		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.2940567653964035 | validation: 0.6785959200619791]
	TIME [epoch: 6.4 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45748064877464817		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.45748064877464817 | validation: 0.2791904222362155]
	TIME [epoch: 6.42 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2712089708672472		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.2712089708672472 | validation: 0.21437141564462295]
	TIME [epoch: 6.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.231229502662485		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.231229502662485 | validation: 0.29776559887718795]
	TIME [epoch: 6.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27522475479507197		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.27522475479507197 | validation: 0.3562653480699651]
	TIME [epoch: 6.4 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3246611818076567		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.3246611818076567 | validation: 0.237454805701689]
	TIME [epoch: 6.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461316456629377		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.3461316456629377 | validation: 0.26608587158784225]
	TIME [epoch: 6.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27259256016461236		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.27259256016461236 | validation: 0.23500846979982926]
	TIME [epoch: 6.4 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23772775669933294		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.23772775669933294 | validation: 0.30935608833512795]
	TIME [epoch: 6.43 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2604612806648226		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.2604612806648226 | validation: 0.3470851368475074]
	TIME [epoch: 6.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.317053709261226		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.317053709261226 | validation: 0.35139409137647]
	TIME [epoch: 6.39 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2698937542461695		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.2698937542461695 | validation: 0.2609212316461512]
	TIME [epoch: 6.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31920537728266013		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.31920537728266013 | validation: 0.20514696093474805]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29573530645729695		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.29573530645729695 | validation: 0.2834891404584908]
	TIME [epoch: 6.39 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23679844640584446		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.23679844640584446 | validation: 0.264884304768765]
	TIME [epoch: 6.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2981464545541976		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.2981464545541976 | validation: 0.23033229258031246]
	TIME [epoch: 6.42 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27598172461843495		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.27598172461843495 | validation: 0.3400695384441048]
	TIME [epoch: 6.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34975709191791177		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.34975709191791177 | validation: 0.48997086126388395]
	TIME [epoch: 6.39 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37722051423493275		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.37722051423493275 | validation: 0.3022363480846716]
	TIME [epoch: 6.39 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2579406898721551		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.2579406898721551 | validation: 0.25060920159536937]
	TIME [epoch: 6.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23880174795390172		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.23880174795390172 | validation: 0.2695000648191271]
	TIME [epoch: 6.4 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3175580345775183		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.3175580345775183 | validation: 0.2876283830329934]
	TIME [epoch: 6.39 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25352916191076214		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.25352916191076214 | validation: 0.39625941043378404]
	TIME [epoch: 6.41 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29787208638874085		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.29787208638874085 | validation: 0.3701639951872548]
	TIME [epoch: 6.41 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3129715085528052		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.3129715085528052 | validation: 0.3213895838187735]
	TIME [epoch: 6.4 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2765649911661051		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2765649911661051 | validation: 0.2933206018942351]
	TIME [epoch: 6.4 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758632491035427		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.2758632491035427 | validation: 0.3286899435966859]
	TIME [epoch: 6.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24503128524536671		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.24503128524536671 | validation: 0.19679065737276105]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22564632859493644		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.22564632859493644 | validation: 0.32991044220904314]
	TIME [epoch: 6.39 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933694368897229		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.2933694368897229 | validation: 0.2605520387500645]
	TIME [epoch: 6.41 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838478407038583		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.2838478407038583 | validation: 0.3554860061323705]
	TIME [epoch: 6.41 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33637676242115616		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.33637676242115616 | validation: 0.20874410683146394]
	TIME [epoch: 6.39 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2443523945223128		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.2443523945223128 | validation: 0.2713499032560122]
	TIME [epoch: 6.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26682233891440316		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.26682233891440316 | validation: 0.323564227564377]
	TIME [epoch: 6.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.265994469038964		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.265994469038964 | validation: 0.27047260868180595]
	TIME [epoch: 6.4 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22774333474201883		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.22774333474201883 | validation: 0.37799875285203427]
	TIME [epoch: 6.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2386295366081144		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.2386295366081144 | validation: 0.35203819415807636]
	TIME [epoch: 6.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2852787892137101		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.2852787892137101 | validation: 0.31340079243341823]
	TIME [epoch: 6.43 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30062917997704963		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.30062917997704963 | validation: 0.2780479994380213]
	TIME [epoch: 6.39 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21996222966332446		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.21996222966332446 | validation: 0.23786222045592864]
	TIME [epoch: 6.4 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21196369136595633		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.21196369136595633 | validation: 0.2103841873497825]
	TIME [epoch: 6.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20606135482256377		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.20606135482256377 | validation: 0.29631589722640983]
	TIME [epoch: 6.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296518035325064		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.296518035325064 | validation: 0.2789554044820475]
	TIME [epoch: 6.39 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24677657349300408		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.24677657349300408 | validation: 0.2312371002158931]
	TIME [epoch: 6.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24705757920859006		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.24705757920859006 | validation: 0.30269085832840875]
	TIME [epoch: 6.43 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263845401824133		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.263845401824133 | validation: 0.23617705363705824]
	TIME [epoch: 6.4 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21220019647606891		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.21220019647606891 | validation: 0.21850780831132574]
	TIME [epoch: 6.4 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20568189498026138		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.20568189498026138 | validation: 0.2284061488641013]
	TIME [epoch: 6.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2405343231216559		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.2405343231216559 | validation: 0.3266886536713352]
	TIME [epoch: 6.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703030445744812		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.2703030445744812 | validation: 0.2446589226240252]
	TIME [epoch: 6.39 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24346962901648123		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.24346962901648123 | validation: 0.307689700285762]
	TIME [epoch: 6.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22901016270579821		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.22901016270579821 | validation: 0.2120315554935673]
	TIME [epoch: 6.44 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20987624516535117		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.20987624516535117 | validation: 0.26744550023362584]
	TIME [epoch: 6.41 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3222992049398603		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.3222992049398603 | validation: 0.1757622298002914]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23801339664055923		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.23801339664055923 | validation: 0.2059634688313644]
	TIME [epoch: 6.39 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21458784741955053		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.21458784741955053 | validation: 0.30714310917358756]
	TIME [epoch: 6.39 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2378269894664751		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.2378269894664751 | validation: 0.23699710223221757]
	TIME [epoch: 6.39 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2338074897147021		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.2338074897147021 | validation: 0.18213686293642764]
	TIME [epoch: 6.39 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.186298926044818		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.186298926044818 | validation: 0.2665343450510103]
	TIME [epoch: 6.42 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2136530142176461		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.2136530142176461 | validation: 0.24771890201625696]
	TIME [epoch: 6.39 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23173553309199157		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.23173553309199157 | validation: 0.20488746192762236]
	TIME [epoch: 6.39 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20646858917978297		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.20646858917978297 | validation: 0.19355118734025575]
	TIME [epoch: 6.39 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2422824490502632		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.2422824490502632 | validation: 0.19955522014135102]
	TIME [epoch: 6.39 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22723193167439137		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.22723193167439137 | validation: 0.17422481370570558]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20738934527673603		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.20738934527673603 | validation: 0.19279458235846839]
	TIME [epoch: 6.39 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30097008245526863		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.30097008245526863 | validation: 0.2832689721672287]
	TIME [epoch: 6.4 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27620231383781024		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.27620231383781024 | validation: 0.22178145884836106]
	TIME [epoch: 6.41 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20302062534552862		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.20302062534552862 | validation: 0.20245761682753496]
	TIME [epoch: 6.39 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2222635947671665		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.2222635947671665 | validation: 0.19924016948481238]
	TIME [epoch: 6.39 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2850948479849824		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.2850948479849824 | validation: 0.5375970149549275]
	TIME [epoch: 6.39 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2852377098637007		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2852377098637007 | validation: 0.20851779707246296]
	TIME [epoch: 6.39 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24705699194634095		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.24705699194634095 | validation: 0.1749108175325626]
	TIME [epoch: 6.39 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21368289661296552		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.21368289661296552 | validation: 0.20618939708682732]
	TIME [epoch: 6.41 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042936919216784		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.2042936919216784 | validation: 0.2372448806954879]
	TIME [epoch: 6.41 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20396711508418391		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.20396711508418391 | validation: 0.242254851637041]
	TIME [epoch: 6.39 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859290616697337		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.2859290616697337 | validation: 0.4249349733222166]
	TIME [epoch: 6.39 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2577885079565624		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.2577885079565624 | validation: 0.25435351303424747]
	TIME [epoch: 6.38 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20948809432860227		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.20948809432860227 | validation: 0.37047296232925975]
	TIME [epoch: 6.39 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27583947616271365		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.27583947616271365 | validation: 0.20237710601813802]
	TIME [epoch: 6.39 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20527965396019035		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.20527965396019035 | validation: 0.32312728326433887]
	TIME [epoch: 6.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255979613199042		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.2255979613199042 | validation: 0.2681605358477424]
	TIME [epoch: 6.43 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25743011690570566		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.25743011690570566 | validation: 0.26320279389214496]
	TIME [epoch: 6.4 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19433969054679445		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.19433969054679445 | validation: 0.2628481303804459]
	TIME [epoch: 6.39 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2417773829388388		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.2417773829388388 | validation: 0.20642980073237735]
	TIME [epoch: 6.39 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22851586804416846		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.22851586804416846 | validation: 0.272048880403294]
	TIME [epoch: 6.39 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27570365620782517		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.27570365620782517 | validation: 0.23805609628594973]
	TIME [epoch: 6.39 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20137640324457481		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.20137640324457481 | validation: 0.20210131484237115]
	TIME [epoch: 6.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19844122194274383		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.19844122194274383 | validation: 0.20589552335089806]
	TIME [epoch: 6.42 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1920275621335514		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.1920275621335514 | validation: 0.25666429708052435]
	TIME [epoch: 6.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19582268867590485		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.19582268867590485 | validation: 0.22387474747860336]
	TIME [epoch: 6.39 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595318305617651		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.2595318305617651 | validation: 0.26360977804031155]
	TIME [epoch: 6.4 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20936300950489573		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.20936300950489573 | validation: 0.1764211635123121]
	TIME [epoch: 6.39 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938262090529702		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.1938262090529702 | validation: 0.23805016510425156]
	TIME [epoch: 6.39 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21539691188735996		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.21539691188735996 | validation: 0.2726380265903749]
	TIME [epoch: 6.39 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19682270134392393		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.19682270134392393 | validation: 0.1753656375297364]
	TIME [epoch: 6.42 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17154413910329439		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.17154413910329439 | validation: 0.2020327079567572]
	TIME [epoch: 6.4 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23927709423338853		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.23927709423338853 | validation: 0.20844748174747438]
	TIME [epoch: 6.39 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2147503495702647		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2147503495702647 | validation: 0.23858127581210337]
	TIME [epoch: 6.39 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20828895052653146		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.20828895052653146 | validation: 0.19288578949653887]
	TIME [epoch: 6.39 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19586021672526155		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.19586021672526155 | validation: 0.1935878029700121]
	TIME [epoch: 6.39 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19856232792320805		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.19856232792320805 | validation: 0.19947824308206918]
	TIME [epoch: 6.39 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1872966783470697		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.1872966783470697 | validation: 0.3216685970761576]
	TIME [epoch: 6.4 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2338420007144508		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.2338420007144508 | validation: 0.21391235718252596]
	TIME [epoch: 6.41 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936737388809347		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.1936737388809347 | validation: 0.23670026264007932]
	TIME [epoch: 6.39 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20157715579030655		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.20157715579030655 | validation: 0.7116934282168623]
	TIME [epoch: 6.4 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4028233322056899		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.4028233322056899 | validation: 0.16928960090561637]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2117239508538611		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.2117239508538611 | validation: 0.18396750305815224]
	TIME [epoch: 6.39 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21965954938074767		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.21965954938074767 | validation: 0.18567100983403406]
	TIME [epoch: 6.39 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24241863089264598		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.24241863089264598 | validation: 0.20668837644318594]
	TIME [epoch: 6.39 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17227999537765662		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.17227999537765662 | validation: 0.1675545259974443]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26291860129854		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.26291860129854 | validation: 0.3180913742716753]
	TIME [epoch: 6.39 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2302308066368745		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.2302308066368745 | validation: 0.24903251397937542]
	TIME [epoch: 6.38 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3503665243170252		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.3503665243170252 | validation: 0.33241897647230717]
	TIME [epoch: 6.39 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23260163987879356		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.23260163987879356 | validation: 0.25792106130363807]
	TIME [epoch: 6.39 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23016770119183314		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.23016770119183314 | validation: 0.1996932227325419]
	TIME [epoch: 6.39 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19849556640112986		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.19849556640112986 | validation: 0.24526500219927427]
	TIME [epoch: 6.39 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26908768244556136		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.26908768244556136 | validation: 0.3524860527522293]
	TIME [epoch: 6.42 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24559555656680285		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.24559555656680285 | validation: 0.17876749585822083]
	TIME [epoch: 6.39 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18225426588016022		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.18225426588016022 | validation: 0.2333616073709196]
	TIME [epoch: 6.39 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21983067866219022		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.21983067866219022 | validation: 0.20636356969698588]
	TIME [epoch: 6.4 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17769858020904408		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.17769858020904408 | validation: 0.17121508293514395]
	TIME [epoch: 6.4 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1782937542128264		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.1782937542128264 | validation: 0.191527893355496]
	TIME [epoch: 6.39 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19041219992687175		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.19041219992687175 | validation: 0.22055943689189655]
	TIME [epoch: 6.39 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896242082575118		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.1896242082575118 | validation: 0.19382032070570404]
	TIME [epoch: 6.43 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19798489742023975		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.19798489742023975 | validation: 0.24973542133871846]
	TIME [epoch: 6.4 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2051880203696313		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.2051880203696313 | validation: 0.1850854159811052]
	TIME [epoch: 6.39 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21394809814110333		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.21394809814110333 | validation: 0.19180046893118957]
	TIME [epoch: 6.39 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1868329107980423		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.1868329107980423 | validation: 0.23619245265614086]
	TIME [epoch: 6.39 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630861711438826		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.1630861711438826 | validation: 0.17434442879145057]
	TIME [epoch: 6.39 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2043464201645488		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.2043464201645488 | validation: 0.17682309370359814]
	TIME [epoch: 6.39 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17594608727034633		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.17594608727034633 | validation: 0.2506936527876446]
	TIME [epoch: 6.42 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2126405340102735		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.2126405340102735 | validation: 0.4115578418279897]
	TIME [epoch: 6.39 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2355586949910885		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.2355586949910885 | validation: 0.2392848060640688]
	TIME [epoch: 6.39 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19847956226012245		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.19847956226012245 | validation: 0.22980017368612735]
	TIME [epoch: 6.39 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16768000675478373		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.16768000675478373 | validation: 0.20087696764552704]
	TIME [epoch: 6.39 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22255912360357183		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.22255912360357183 | validation: 0.15087714737080873]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22828748956489828		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.22828748956489828 | validation: 0.22460621568707612]
	TIME [epoch: 6.39 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19563661945098879		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.19563661945098879 | validation: 0.26092994435561134]
	TIME [epoch: 6.41 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19129527224200982		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.19129527224200982 | validation: 0.20783455379631793]
	TIME [epoch: 6.41 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16933923440809523		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.16933923440809523 | validation: 0.18511582919828212]
	TIME [epoch: 6.39 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19677496346699275		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.19677496346699275 | validation: 0.19861069552189306]
	TIME [epoch: 6.39 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16910857270487267		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.16910857270487267 | validation: 0.1752877652938473]
	TIME [epoch: 6.39 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17745570679478379		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.17745570679478379 | validation: 0.2518092834705552]
	TIME [epoch: 6.39 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18591389983120252		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.18591389983120252 | validation: 0.22317516203088292]
	TIME [epoch: 6.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20856197575316976		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.20856197575316976 | validation: 0.32488255649536274]
	TIME [epoch: 6.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28486316738368156		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.28486316738368156 | validation: 0.32659070320715844]
	TIME [epoch: 6.43 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24032831172249236		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.24032831172249236 | validation: 0.32802563468590584]
	TIME [epoch: 6.4 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2405659078805383		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.2405659078805383 | validation: 0.21398560811275943]
	TIME [epoch: 6.4 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17726428894787138		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.17726428894787138 | validation: 0.22324534364502746]
	TIME [epoch: 6.39 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18853034132045926		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.18853034132045926 | validation: 0.17319325010860936]
	TIME [epoch: 6.39 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17029448128981467		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.17029448128981467 | validation: 0.16647331411002]
	TIME [epoch: 6.39 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16871849064185312		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.16871849064185312 | validation: 0.15696055950089446]
	TIME [epoch: 6.39 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17521305626452077		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.17521305626452077 | validation: 0.16413425901121453]
	TIME [epoch: 6.43 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712228334175381		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.1712228334175381 | validation: 0.16856257716789755]
	TIME [epoch: 6.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15380064014346273		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.15380064014346273 | validation: 0.1858886171066529]
	TIME [epoch: 6.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1844650008085718		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.1844650008085718 | validation: 0.15656377439761401]
	TIME [epoch: 6.4 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21250303033205942		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.21250303033205942 | validation: 0.15945155210709253]
	TIME [epoch: 6.4 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.184487853516078		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.184487853516078 | validation: 0.2063547248932815]
	TIME [epoch: 6.39 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2010554262530137		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.2010554262530137 | validation: 0.23286480855284664]
	TIME [epoch: 6.39 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19913738083460286		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.19913738083460286 | validation: 0.23557160197619006]
	TIME [epoch: 6.42 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19106335661490637		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.19106335661490637 | validation: 0.19655514284545958]
	TIME [epoch: 6.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593756833886797		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.1593756833886797 | validation: 0.21186721353471946]
	TIME [epoch: 6.39 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1717635157369093		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.1717635157369093 | validation: 0.16359836256443797]
	TIME [epoch: 6.39 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15397872606620894		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.15397872606620894 | validation: 0.21535554298432044]
	TIME [epoch: 6.39 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17268678440033625		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.17268678440033625 | validation: 0.21347369797871948]
	TIME [epoch: 6.39 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572401616304773		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.1572401616304773 | validation: 0.1814841160269692]
	TIME [epoch: 6.4 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1870014491001418		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.1870014491001418 | validation: 0.14882477618092507]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_428.pth
	Model improved!!!
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14179987728013005		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.14179987728013005 | validation: 0.2579279750304601]
	TIME [epoch: 6.41 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22582759765298396		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.22582759765298396 | validation: 0.19265278038954242]
	TIME [epoch: 6.39 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16939352523514178		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.16939352523514178 | validation: 0.1664993688086482]
	TIME [epoch: 6.39 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1720671819452181		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.1720671819452181 | validation: 0.1973377850684596]
	TIME [epoch: 6.39 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15104567235131955		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.15104567235131955 | validation: 0.19511767652483783]
	TIME [epoch: 6.39 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.178113896153708		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.178113896153708 | validation: 0.2425029884423747]
	TIME [epoch: 6.39 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2072996485802851		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.2072996485802851 | validation: 0.2756151835158875]
	TIME [epoch: 6.41 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2381559105373861		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.2381559105373861 | validation: 0.21742878691424136]
	TIME [epoch: 6.42 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2212282352876932		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.2212282352876932 | validation: 0.18775331539188414]
	TIME [epoch: 6.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19363424640025495		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.19363424640025495 | validation: 0.20069775807307555]
	TIME [epoch: 6.4 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20726767681017835		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.20726767681017835 | validation: 0.20730491588963482]
	TIME [epoch: 6.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17212359536934593		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.17212359536934593 | validation: 0.18108094620228815]
	TIME [epoch: 6.4 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16137878159557464		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.16137878159557464 | validation: 0.15297251890126434]
	TIME [epoch: 6.39 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15880386613785574		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.15880386613785574 | validation: 0.16770876047887817]
	TIME [epoch: 6.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689233572927448		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.1689233572927448 | validation: 0.18632051062955682]
	TIME [epoch: 6.42 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1940606261005291		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.1940606261005291 | validation: 0.1450938131223963]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_444.pth
	Model improved!!!
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19665750934594517		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.19665750934594517 | validation: 0.25217680531042375]
	TIME [epoch: 6.39 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20506955549987074		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.20506955549987074 | validation: 0.2064645742896911]
	TIME [epoch: 6.39 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18771457665414554		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.18771457665414554 | validation: 0.15048783142748678]
	TIME [epoch: 6.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14248979385308078		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.14248979385308078 | validation: 0.19606845065586542]
	TIME [epoch: 6.39 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17680299919732284		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.17680299919732284 | validation: 0.19412336836441363]
	TIME [epoch: 6.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1512663603585639		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1512663603585639 | validation: 0.1964824792781784]
	TIME [epoch: 6.42 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17502365192257952		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.17502365192257952 | validation: 0.1605574327250864]
	TIME [epoch: 6.4 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17515461805206223		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.17515461805206223 | validation: 0.16647097099613536]
	TIME [epoch: 6.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2233944223321974		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.2233944223321974 | validation: 0.2910702222046862]
	TIME [epoch: 6.39 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20096946349554795		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.20096946349554795 | validation: 0.14844733430850535]
	TIME [epoch: 6.39 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14771100859829606		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.14771100859829606 | validation: 0.1611880900606354]
	TIME [epoch: 6.39 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14649628274078008		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.14649628274078008 | validation: 0.14983786250869496]
	TIME [epoch: 6.39 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663827606634892		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.1663827606634892 | validation: 0.1610173164333889]
	TIME [epoch: 6.43 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16718614672712354		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.16718614672712354 | validation: 0.16704253812801312]
	TIME [epoch: 6.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17208342903200713		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.17208342903200713 | validation: 0.15693090225180886]
	TIME [epoch: 6.4 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17952934461921913		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.17952934461921913 | validation: 0.1400343248343963]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137314584129777		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.137314584129777 | validation: 0.17279914561970486]
	TIME [epoch: 6.4 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14145871166052135		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.14145871166052135 | validation: 0.2035927821735538]
	TIME [epoch: 6.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18352688573288148		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.18352688573288148 | validation: 0.18286139467960127]
	TIME [epoch: 6.4 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18065773680669064		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.18065773680669064 | validation: 0.13962682527293613]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16675478452276413		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.16675478452276413 | validation: 0.17347335670702912]
	TIME [epoch: 6.4 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15690790553795525		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.15690790553795525 | validation: 0.177668766408287]
	TIME [epoch: 6.39 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14280394220934017		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.14280394220934017 | validation: 0.18730870929906523]
	TIME [epoch: 6.39 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15761351852029123		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.15761351852029123 | validation: 0.22686165685628312]
	TIME [epoch: 6.39 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28412331004818536		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.28412331004818536 | validation: 0.39518409703389573]
	TIME [epoch: 6.39 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21565467407939803		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.21565467407939803 | validation: 0.1557482177496028]
	TIME [epoch: 6.39 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16444406822928728		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.16444406822928728 | validation: 0.17650062149417878]
	TIME [epoch: 6.41 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19795727029000723		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.19795727029000723 | validation: 0.15476802545500135]
	TIME [epoch: 6.41 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1492874183902625		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.1492874183902625 | validation: 0.17095566693578312]
	TIME [epoch: 6.39 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146336528583695		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.146336528583695 | validation: 0.16028040713732455]
	TIME [epoch: 6.4 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17582645953493362		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.17582645953493362 | validation: 0.14659566040429103]
	TIME [epoch: 6.39 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12813525757404065		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.12813525757404065 | validation: 0.1688678659406179]
	TIME [epoch: 6.39 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16257105326902582		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.16257105326902582 | validation: 0.1982944461571884]
	TIME [epoch: 6.39 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16483926997413212		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.16483926997413212 | validation: 0.16444535474562294]
	TIME [epoch: 6.41 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553978379697798		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.1553978379697798 | validation: 0.23262774709196618]
	TIME [epoch: 6.41 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1710388365586308		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.1710388365586308 | validation: 0.14125936602833045]
	TIME [epoch: 6.39 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067091487967647		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.13067091487967647 | validation: 0.20767211261227667]
	TIME [epoch: 6.39 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17133415700023857		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.17133415700023857 | validation: 0.15995371108502188]
	TIME [epoch: 6.39 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14946932976868482		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.14946932976868482 | validation: 0.29867677877225485]
	TIME [epoch: 6.39 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20194473321514372		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.20194473321514372 | validation: 0.19219248472936123]
	TIME [epoch: 6.39 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1571631924651861		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1571631924651861 | validation: 0.2406582130340482]
	TIME [epoch: 6.39 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1465699605956897		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.1465699605956897 | validation: 0.1727047065291152]
	TIME [epoch: 6.42 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17893476601573832		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.17893476601573832 | validation: 0.1517880686982088]
	TIME [epoch: 6.39 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16807532637734843		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.16807532637734843 | validation: 0.1582653329255369]
	TIME [epoch: 6.39 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13887175965993098		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.13887175965993098 | validation: 0.1665281972393114]
	TIME [epoch: 6.39 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13179545797707637		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.13179545797707637 | validation: 0.17759918691426366]
	TIME [epoch: 6.39 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14602854073351626		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.14602854073351626 | validation: 0.27309050632538556]
	TIME [epoch: 6.39 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24225567650439167		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.24225567650439167 | validation: 0.21948336626620446]
	TIME [epoch: 6.39 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1669898745539496		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.1669898745539496 | validation: 0.17637317518328652]
	TIME [epoch: 6.42 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14689577391554332		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.14689577391554332 | validation: 0.13336636986422387]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15817558044265204		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15817558044265204 | validation: 0.13099953742301157]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_495.pth
	Model improved!!!
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409803542872136		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.1409803542872136 | validation: 0.12214108450245945]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15994923396534613		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.15994923396534613 | validation: 0.15818016906934368]
	TIME [epoch: 6.4 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16741612695513997		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.16741612695513997 | validation: 0.17709924147980857]
	TIME [epoch: 6.4 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15590300262967097		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.15590300262967097 | validation: 0.1371044245919439]
	TIME [epoch: 6.4 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15719418588086623		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.15719418588086623 | validation: 0.16591848995308253]
	TIME [epoch: 6.43 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354066126844629		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.1354066126844629 | validation: 0.137515153020771]
	TIME [epoch: 6.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15992206328694436		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.15992206328694436 | validation: 0.15302164990552147]
	TIME [epoch: 6.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526703826384418		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.1526703826384418 | validation: 0.14608287174777482]
	TIME [epoch: 6.4 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584154907981001		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.2584154907981001 | validation: 0.1391354690962634]
	TIME [epoch: 6.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14765462568148616		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.14765462568148616 | validation: 0.1674830398659817]
	TIME [epoch: 6.4 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16760726538528123		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.16760726538528123 | validation: 0.12938562765738135]
	TIME [epoch: 6.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302602110336738		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.1302602110336738 | validation: 0.13690374399030358]
	TIME [epoch: 6.43 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14105202833555305		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.14105202833555305 | validation: 0.2711501486108323]
	TIME [epoch: 6.41 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17637021815542434		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.17637021815542434 | validation: 0.13049709260657497]
	TIME [epoch: 6.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13918631796117914		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.13918631796117914 | validation: 0.18128795432454176]
	TIME [epoch: 6.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14813082272106062		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.14813082272106062 | validation: 0.1874441052290461]
	TIME [epoch: 6.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16376762712008963		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.16376762712008963 | validation: 0.1761627207092409]
	TIME [epoch: 6.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13366753394035827		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.13366753394035827 | validation: 0.17419403190527574]
	TIME [epoch: 6.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14608675602549084		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.14608675602549084 | validation: 0.22593942678991666]
	TIME [epoch: 6.42 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16622176902814007		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.16622176902814007 | validation: 0.18177989599847247]
	TIME [epoch: 6.42 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15228589002696333		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.15228589002696333 | validation: 0.19085623078707004]
	TIME [epoch: 6.41 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14872036693522905		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.14872036693522905 | validation: 0.14175999703951814]
	TIME [epoch: 6.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14960085400560652		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.14960085400560652 | validation: 0.25007898820271424]
	TIME [epoch: 6.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1965276831077057		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.1965276831077057 | validation: 0.20387342684583976]
	TIME [epoch: 6.4 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14474229985421555		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.14474229985421555 | validation: 0.19998618690964684]
	TIME [epoch: 6.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1445406506470619		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.1445406506470619 | validation: 0.15567109026307643]
	TIME [epoch: 6.42 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13055615246045524		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.13055615246045524 | validation: 0.15348256825444287]
	TIME [epoch: 6.42 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393147926840847		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.1393147926840847 | validation: 0.16583261701767046]
	TIME [epoch: 6.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17904922067523932		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.17904922067523932 | validation: 0.15546547969396676]
	TIME [epoch: 6.4 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16478131431470727		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.16478131431470727 | validation: 0.14198935024277373]
	TIME [epoch: 6.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14860623755742328		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.14860623755742328 | validation: 0.19075366684179657]
	TIME [epoch: 6.4 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368995622055172		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.1368995622055172 | validation: 0.14334186543172447]
	TIME [epoch: 6.4 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11478848093032662		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.11478848093032662 | validation: 0.10914151966096945]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378749122364477		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.1378749122364477 | validation: 0.23214034528445737]
	TIME [epoch: 6.43 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567291773291413		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.1567291773291413 | validation: 0.145847845240835]
	TIME [epoch: 6.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557558416051701		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.1557558416051701 | validation: 0.24357410473599864]
	TIME [epoch: 6.4 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1684223186442169		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.1684223186442169 | validation: 0.20331139750055965]
	TIME [epoch: 6.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530896207834801		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.1530896207834801 | validation: 0.1391134924361109]
	TIME [epoch: 6.4 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13522757874944147		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.13522757874944147 | validation: 0.20446106439859757]
	TIME [epoch: 6.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1216046340866171		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1216046340866171 | validation: 0.11218760537711486]
	TIME [epoch: 6.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11310383559481935		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.11310383559481935 | validation: 0.15360784073298667]
	TIME [epoch: 6.43 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14400176194816255		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.14400176194816255 | validation: 0.135402817931641]
	TIME [epoch: 6.4 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14566134204694506		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.14566134204694506 | validation: 0.14256160793635497]
	TIME [epoch: 6.4 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15428656448019393		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.15428656448019393 | validation: 0.19261362330018514]
	TIME [epoch: 6.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17825836812350834		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.17825836812350834 | validation: 0.24176649413682433]
	TIME [epoch: 6.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17254233419943993		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.17254233419943993 | validation: 0.1798293752941383]
	TIME [epoch: 6.39 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13460071575982668		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.13460071575982668 | validation: 0.11866399298164881]
	TIME [epoch: 6.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12056262450193117		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.12056262450193117 | validation: 0.14633721316887555]
	TIME [epoch: 6.43 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11574183276077969		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.11574183276077969 | validation: 0.13127451027774734]
	TIME [epoch: 6.41 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318850703570907		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1318850703570907 | validation: 0.12752753206851927]
	TIME [epoch: 6.41 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15670477357850637		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.15670477357850637 | validation: 0.27108643605208554]
	TIME [epoch: 6.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17295584140600456		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.17295584140600456 | validation: 0.17081773768841899]
	TIME [epoch: 6.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650478291093327		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.1650478291093327 | validation: 0.1274102123870653]
	TIME [epoch: 6.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15321154074043614		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.15321154074043614 | validation: 0.17937109797025744]
	TIME [epoch: 6.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14039137496758694		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.14039137496758694 | validation: 0.14048862448837496]
	TIME [epoch: 6.42 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15064000803301014		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.15064000803301014 | validation: 0.13153404779440253]
	TIME [epoch: 6.42 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14628428200481824		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.14628428200481824 | validation: 0.12162121089253215]
	TIME [epoch: 6.41 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13734359734292412		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.13734359734292412 | validation: 0.2165219163458042]
	TIME [epoch: 6.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21013601355910352		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.21013601355910352 | validation: 0.3153914945993763]
	TIME [epoch: 6.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18015457437201005		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.18015457437201005 | validation: 0.14219136589628242]
	TIME [epoch: 6.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14170054281169472		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.14170054281169472 | validation: 0.17418515250087682]
	TIME [epoch: 6.41 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13457491813736525		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.13457491813736525 | validation: 0.12583094504535416]
	TIME [epoch: 6.43 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12010962876127189		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.12010962876127189 | validation: 0.11733713832875851]
	TIME [epoch: 6.42 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13189172385026154		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.13189172385026154 | validation: 0.1989636265862751]
	TIME [epoch: 6.41 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14857701248563307		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.14857701248563307 | validation: 0.1603976042142912]
	TIME [epoch: 6.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368144808662098		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.1368144808662098 | validation: 0.18925408029833068]
	TIME [epoch: 6.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491332591983333		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1491332591983333 | validation: 0.13928898984879234]
	TIME [epoch: 6.4 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612165982101923		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.1612165982101923 | validation: 0.20154109501080747]
	TIME [epoch: 6.4 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13863382451040826		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.13863382451040826 | validation: 0.11933692740949275]
	TIME [epoch: 6.41 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15279831932326393		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.15279831932326393 | validation: 0.12412112399828884]
	TIME [epoch: 6.44 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14603841553297442		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.14603841553297442 | validation: 0.18814207282699755]
	TIME [epoch: 6.41 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18300547291228939		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.18300547291228939 | validation: 0.12410924609580251]
	TIME [epoch: 6.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12722895612412666		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.12722895612412666 | validation: 0.19523478619878842]
	TIME [epoch: 6.41 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16307672683069122		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.16307672683069122 | validation: 0.13352519706571156]
	TIME [epoch: 6.4 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13644837486472725		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.13644837486472725 | validation: 0.16828060572716091]
	TIME [epoch: 6.41 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13213299455472413		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.13213299455472413 | validation: 0.2142475635056558]
	TIME [epoch: 6.41 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1458770396124194		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.1458770396124194 | validation: 0.18449490264277757]
	TIME [epoch: 6.44 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14182986910708137		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.14182986910708137 | validation: 0.16876783805312937]
	TIME [epoch: 6.41 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13232491356943993		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.13232491356943993 | validation: 0.20073780536265198]
	TIME [epoch: 6.41 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14353197110290034		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.14353197110290034 | validation: 0.13717587382004795]
	TIME [epoch: 6.4 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125208751198754		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.125208751198754 | validation: 0.11451762045272648]
	TIME [epoch: 6.41 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12104859844336649		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.12104859844336649 | validation: 0.15184274816742996]
	TIME [epoch: 6.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793786211563488		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.12793786211563488 | validation: 0.1500154797473604]
	TIME [epoch: 6.41 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14470721525525593		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.14470721525525593 | validation: 0.1104273625949702]
	TIME [epoch: 6.44 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10362381642867487		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.10362381642867487 | validation: 0.17060722892497532]
	TIME [epoch: 6.42 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12300237845916091		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.12300237845916091 | validation: 0.13420504158636987]
	TIME [epoch: 6.41 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15394181987589212		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.15394181987589212 | validation: 0.10667398080644652]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10708327491392951		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.10708327491392951 | validation: 0.17090291258726048]
	TIME [epoch: 6.4 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24746292144342197		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.24746292144342197 | validation: 0.18611917925613533]
	TIME [epoch: 6.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11942776332799045		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.11942776332799045 | validation: 0.1370996707955448]
	TIME [epoch: 6.41 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11966477877841399		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.11966477877841399 | validation: 0.11695651418824156]
	TIME [epoch: 6.44 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10277356235092228		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.10277356235092228 | validation: 0.1112814603659833]
	TIME [epoch: 6.41 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12598764860281544		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.12598764860281544 | validation: 0.11286438627723158]
	TIME [epoch: 6.41 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1233714664175199		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.1233714664175199 | validation: 0.13718685758034155]
	TIME [epoch: 6.41 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12307768820578667		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.12307768820578667 | validation: 0.14836125183466284]
	TIME [epoch: 6.41 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11957490569367853		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.11957490569367853 | validation: 0.1273998023945458]
	TIME [epoch: 6.41 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09977649102238224		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.09977649102238224 | validation: 0.14709971991384288]
	TIME [epoch: 6.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12401105825588171		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.12401105825588171 | validation: 0.15190866415476367]
	TIME [epoch: 6.42 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13130812267625297		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.13130812267625297 | validation: 0.15315021513941035]
	TIME [epoch: 6.42 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11875404239813217		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.11875404239813217 | validation: 0.16883753028372497]
	TIME [epoch: 6.41 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15281140052600578		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.15281140052600578 | validation: 0.11976717253499271]
	TIME [epoch: 6.41 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10133836628988477		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.10133836628988477 | validation: 0.11923075289689944]
	TIME [epoch: 6.4 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10659482580372756		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.10659482580372756 | validation: 0.16342584039582325]
	TIME [epoch: 6.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12981857142433267		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.12981857142433267 | validation: 0.13188442653018764]
	TIME [epoch: 6.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21904483347835693		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.21904483347835693 | validation: 0.3621691908785211]
	TIME [epoch: 6.41 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2683508404556826		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.2683508404556826 | validation: 0.11921952920960235]
	TIME [epoch: 6.42 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12853343387213506		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.12853343387213506 | validation: 0.1064196944522318]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_602.pth
	Model improved!!!
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073172946934295		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.1073172946934295 | validation: 0.14225006729920783]
	TIME [epoch: 6.41 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13190978886029858		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.13190978886029858 | validation: 0.14857971278946525]
	TIME [epoch: 6.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1164665413538965		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.1164665413538965 | validation: 0.1125913052052278]
	TIME [epoch: 6.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11030048275372673		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.11030048275372673 | validation: 0.12900572402557411]
	TIME [epoch: 6.41 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.151875703451757		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.151875703451757 | validation: 0.11486206991684457]
	TIME [epoch: 6.41 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383648434633038		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.1383648434633038 | validation: 0.1378901162073941]
	TIME [epoch: 6.43 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13626999085687952		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.13626999085687952 | validation: 0.17807584576890545]
	TIME [epoch: 6.41 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12292468214813806		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.12292468214813806 | validation: 0.10180870544170768]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_610.pth
	Model improved!!!
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402024771945771		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.1402024771945771 | validation: 0.14655165857863536]
	TIME [epoch: 6.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1716484011343767		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.1716484011343767 | validation: 0.345462890093564]
	TIME [epoch: 6.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19525740836030925		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.19525740836030925 | validation: 0.17859997779127182]
	TIME [epoch: 6.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1135130649947771		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.1135130649947771 | validation: 0.10191193956823717]
	TIME [epoch: 6.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10054543093184166		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.10054543093184166 | validation: 0.10903032495462422]
	TIME [epoch: 6.43 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11345382209744852		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.11345382209744852 | validation: 0.11815498420071943]
	TIME [epoch: 6.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1148440196531828		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.1148440196531828 | validation: 0.16371408121248884]
	TIME [epoch: 6.39 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793797568966364		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.12793797568966364 | validation: 0.10895737182847404]
	TIME [epoch: 6.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09647431566037712		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.09647431566037712 | validation: 0.10960384333428135]
	TIME [epoch: 6.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13251928099378618		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.13251928099378618 | validation: 0.11927613833169154]
	TIME [epoch: 6.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12604993054336666		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.12604993054336666 | validation: 0.11906741758374896]
	TIME [epoch: 6.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10058141291580697		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.10058141291580697 | validation: 0.10669464158920366]
	TIME [epoch: 6.43 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12595797435490735		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.12595797435490735 | validation: 0.1552612338480112]
	TIME [epoch: 6.41 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15089828693150428		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.15089828693150428 | validation: 0.13957202945481625]
	TIME [epoch: 6.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11536254684845673		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.11536254684845673 | validation: 0.12163094733985219]
	TIME [epoch: 6.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104140993305097		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.1104140993305097 | validation: 0.09975156273899828]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12227717238788738		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.12227717238788738 | validation: 0.11781418929823424]
	TIME [epoch: 6.41 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11327786325791414		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.11327786325791414 | validation: 0.14640539224256013]
	TIME [epoch: 6.41 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12021236382292738		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.12021236382292738 | validation: 0.16106977753025217]
	TIME [epoch: 6.44 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1209661304187645		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.1209661304187645 | validation: 0.11830728061993163]
	TIME [epoch: 6.41 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11243317976792083		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.11243317976792083 | validation: 0.12440966182960773]
	TIME [epoch: 6.41 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09343324594744448		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.09343324594744448 | validation: 0.11276280613195404]
	TIME [epoch: 6.41 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09589879506637838		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.09589879506637838 | validation: 0.12176655405162752]
	TIME [epoch: 6.41 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09340189911438421		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.09340189911438421 | validation: 0.12325231385002416]
	TIME [epoch: 6.41 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490509386183691		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.10490509386183691 | validation: 0.1325446757539781]
	TIME [epoch: 6.41 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11460856520867467		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.11460856520867467 | validation: 0.13829824855550998]
	TIME [epoch: 6.43 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14378125127432753		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.14378125127432753 | validation: 0.11594231951836452]
	TIME [epoch: 6.43 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09628973645115448		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.09628973645115448 | validation: 0.11267589400475923]
	TIME [epoch: 6.41 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0971464937037819		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.0971464937037819 | validation: 0.11517125701343778]
	TIME [epoch: 6.41 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392341955863309		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.12392341955863309 | validation: 0.10755612995471654]
	TIME [epoch: 6.41 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12326057448999245		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.12326057448999245 | validation: 0.12519836094986372]
	TIME [epoch: 6.41 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10962360382591493		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.10962360382591493 | validation: 0.09899351760087884]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09900858853843188		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.09900858853843188 | validation: 0.12027573901469225]
	TIME [epoch: 6.42 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09703921362052612		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.09703921362052612 | validation: 0.13427226160758354]
	TIME [epoch: 6.43 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14805167074919476		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.14805167074919476 | validation: 0.1741268655870509]
	TIME [epoch: 6.41 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10570084324424718		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.10570084324424718 | validation: 0.0973410345889382]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_646.pth
	Model improved!!!
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10384829661123966		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.10384829661123966 | validation: 0.12484041722400119]
	TIME [epoch: 6.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12314667225022519		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.12314667225022519 | validation: 0.19138856997411682]
	TIME [epoch: 6.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1101086763709603		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.1101086763709603 | validation: 0.11890120180984981]
	TIME [epoch: 6.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181493712097151		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.1181493712097151 | validation: 0.17476112004883035]
	TIME [epoch: 6.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14925913849584505		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.14925913849584505 | validation: 0.0888984242929376]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_651.pth
	Model improved!!!
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12718536789688512		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.12718536789688512 | validation: 0.11482125440325701]
	TIME [epoch: 6.41 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1061266972624394		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.1061266972624394 | validation: 0.09789262752365926]
	TIME [epoch: 6.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13378050283827317		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.13378050283827317 | validation: 0.11747708190962311]
	TIME [epoch: 6.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09860416325260846		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.09860416325260846 | validation: 0.12756305068784968]
	TIME [epoch: 6.41 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11036266637546557		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.11036266637546557 | validation: 0.08321841156299206]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_656.pth
	Model improved!!!
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09118460873802609		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.09118460873802609 | validation: 0.10064034054003546]
	TIME [epoch: 6.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10843078858267155		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.10843078858267155 | validation: 0.20078380879115243]
	TIME [epoch: 6.43 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14293314529		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.14293314529 | validation: 0.09125238428939951]
	TIME [epoch: 6.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10076276136417345		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.10076276136417345 | validation: 0.13530442007993335]
	TIME [epoch: 6.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15845733481961427		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.15845733481961427 | validation: 0.1554800072517177]
	TIME [epoch: 6.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11500384499527533		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.11500384499527533 | validation: 0.11807708420505025]
	TIME [epoch: 6.39 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014939141626534		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.1014939141626534 | validation: 0.10180831967387441]
	TIME [epoch: 6.4 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207260203154407		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.10207260203154407 | validation: 0.10494608729737408]
	TIME [epoch: 6.4 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909194975630365		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.08909194975630365 | validation: 0.12992851860631355]
	TIME [epoch: 6.44 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1648577533492793		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.1648577533492793 | validation: 0.13133911559775854]
	TIME [epoch: 6.4 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971442728255316		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.08971442728255316 | validation: 0.11259313112325384]
	TIME [epoch: 6.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09070646536457998		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.09070646536457998 | validation: 0.08595821634768569]
	TIME [epoch: 6.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10957944532340406		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.10957944532340406 | validation: 0.10949044915893402]
	TIME [epoch: 6.4 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11199394962494028		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.11199394962494028 | validation: 0.10805762378024017]
	TIME [epoch: 6.39 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09508831682412376		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.09508831682412376 | validation: 0.10961298804413946]
	TIME [epoch: 6.4 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12551216602483042		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.12551216602483042 | validation: 0.08286641123917506]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_672.pth
	Model improved!!!
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09252399611300394		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.09252399611300394 | validation: 0.11841927381409115]
	TIME [epoch: 6.41 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09695656102469999		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.09695656102469999 | validation: 0.1095161863539034]
	TIME [epoch: 6.4 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09756271938284558		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.09756271938284558 | validation: 0.09414539978835197]
	TIME [epoch: 6.41 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10565195326230967		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.10565195326230967 | validation: 0.12642268349327337]
	TIME [epoch: 6.41 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1075870079034141		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.1075870079034141 | validation: 0.16116648934866185]
	TIME [epoch: 6.41 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178185466990551		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1178185466990551 | validation: 0.12699848135234784]
	TIME [epoch: 6.41 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10489683352400744		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.10489683352400744 | validation: 0.11740346299130221]
	TIME [epoch: 6.43 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09132580519692754		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.09132580519692754 | validation: 0.10462634789936395]
	TIME [epoch: 6.41 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114001969401727		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.1114001969401727 | validation: 0.13981042125531057]
	TIME [epoch: 6.41 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12152284975491452		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.12152284975491452 | validation: 0.08435096724091828]
	TIME [epoch: 6.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08476130223788693		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.08476130223788693 | validation: 0.12077973956024363]
	TIME [epoch: 6.41 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1126041014097471		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.1126041014097471 | validation: 0.16358833970502304]
	TIME [epoch: 6.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11360504373204698		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.11360504373204698 | validation: 0.1024538991121221]
	TIME [epoch: 6.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09399340040394119		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.09399340040394119 | validation: 0.10067038483952544]
	TIME [epoch: 6.42 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09905585551716455		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.09905585551716455 | validation: 0.12560479752444006]
	TIME [epoch: 6.42 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10241717911097231		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.10241717911097231 | validation: 0.11849465742630062]
	TIME [epoch: 6.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11281327923713744		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.11281327923713744 | validation: 0.0991701454764048]
	TIME [epoch: 6.4 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09275573196440405		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.09275573196440405 | validation: 0.1242688052184853]
	TIME [epoch: 6.4 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09360962092209553		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.09360962092209553 | validation: 0.10885082848778599]
	TIME [epoch: 6.4 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08480905612928401		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.08480905612928401 | validation: 0.09421538873935703]
	TIME [epoch: 6.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0988376148534646		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.0988376148534646 | validation: 0.10137544454251306]
	TIME [epoch: 6.41 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12261332927611533		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.12261332927611533 | validation: 0.12529165799877326]
	TIME [epoch: 6.44 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828124273284749		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.08828124273284749 | validation: 0.0985252086617877]
	TIME [epoch: 6.41 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11047211412375257		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.11047211412375257 | validation: 0.1082340706754281]
	TIME [epoch: 6.41 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10292976582506946		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.10292976582506946 | validation: 0.12340115400726227]
	TIME [epoch: 6.41 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13792374749630823		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.13792374749630823 | validation: 0.14932627584704003]
	TIME [epoch: 6.41 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10474636659843752		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.10474636659843752 | validation: 0.12711258753325855]
	TIME [epoch: 6.41 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0898509688566014		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.0898509688566014 | validation: 0.12851798487095292]
	TIME [epoch: 6.41 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11950584443844775		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.11950584443844775 | validation: 0.09782582100538033]
	TIME [epoch: 6.44 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08876290102896182		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.08876290102896182 | validation: 0.13672449748826376]
	TIME [epoch: 6.41 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09691882982381195		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.09691882982381195 | validation: 0.10873102717782772]
	TIME [epoch: 6.41 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10779085695941606		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.10779085695941606 | validation: 0.10741908908970334]
	TIME [epoch: 6.41 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09051173664820013		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.09051173664820013 | validation: 0.10477434974567677]
	TIME [epoch: 6.41 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09198262297701588		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.09198262297701588 | validation: 0.10201745408956292]
	TIME [epoch: 6.41 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09262466559891368		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.09262466559891368 | validation: 0.10540536470273239]
	TIME [epoch: 6.41 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831076185902381		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.08831076185902381 | validation: 0.0810232330324392]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_708.pth
	Model improved!!!
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10481240756940911		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.10481240756940911 | validation: 0.10424217508681259]
	TIME [epoch: 6.41 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09329906399289829		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.09329906399289829 | validation: 0.1056648024307037]
	TIME [epoch: 6.41 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08486838495087512		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.08486838495087512 | validation: 0.09525569079371725]
	TIME [epoch: 6.41 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09644973050693136		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.09644973050693136 | validation: 0.11245462121050417]
	TIME [epoch: 6.41 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10256084634015111		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.10256084634015111 | validation: 0.0989126018485359]
	TIME [epoch: 6.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08589715149253344		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.08589715149253344 | validation: 0.1277092310636018]
	TIME [epoch: 6.41 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08478314040728671		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.08478314040728671 | validation: 0.0949318771716322]
	TIME [epoch: 6.44 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08919258470141725		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.08919258470141725 | validation: 0.12115166939702608]
	TIME [epoch: 6.42 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09728612301714976		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.09728612301714976 | validation: 0.08467125903225593]
	TIME [epoch: 6.41 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10503387626194535		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.10503387626194535 | validation: 0.13033468386145314]
	TIME [epoch: 6.41 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12988615655400032		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.12988615655400032 | validation: 0.09499572011664693]
	TIME [epoch: 6.41 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08307413044976837		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.08307413044976837 | validation: 0.09958164429360718]
	TIME [epoch: 6.41 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08300754030972401		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.08300754030972401 | validation: 0.1010704956195113]
	TIME [epoch: 6.41 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08352296817863111		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.08352296817863111 | validation: 0.13175476506326203]
	TIME [epoch: 6.43 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09467719256451876		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.09467719256451876 | validation: 0.09626398894812382]
	TIME [epoch: 6.43 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11440732392467964		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.11440732392467964 | validation: 0.08396125674481197]
	TIME [epoch: 6.41 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08942590305293066		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.08942590305293066 | validation: 0.08072794191279424]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08719371986523655		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.08719371986523655 | validation: 0.09845527503749205]
	TIME [epoch: 6.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13917749529041984		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.13917749529041984 | validation: 0.12115425637444319]
	TIME [epoch: 6.4 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1015456138532957		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1015456138532957 | validation: 0.1477494216060293]
	TIME [epoch: 6.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11010683108473497		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.11010683108473497 | validation: 0.09673088057844859]
	TIME [epoch: 6.52 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09437084802479428		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.09437084802479428 | validation: 0.12511290537760056]
	TIME [epoch: 6.42 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08358790722895013		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.08358790722895013 | validation: 0.12289768183685755]
	TIME [epoch: 6.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09775143687364013		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.09775143687364013 | validation: 0.09509481546209049]
	TIME [epoch: 6.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08161200442667886		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.08161200442667886 | validation: 0.13164912592862893]
	TIME [epoch: 6.41 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09416489280819473		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.09416489280819473 | validation: 0.12202714892683553]
	TIME [epoch: 6.41 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08865359005678432		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.08865359005678432 | validation: 0.14403980452572618]
	TIME [epoch: 6.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10143274587678552		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.10143274587678552 | validation: 0.08744706083478902]
	TIME [epoch: 6.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861855711593308		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.0861855711593308 | validation: 0.12546008138697728]
	TIME [epoch: 6.43 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09048009937555296		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.09048009937555296 | validation: 0.0993237835311192]
	TIME [epoch: 6.41 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07745105584442934		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.07745105584442934 | validation: 0.09151490660482953]
	TIME [epoch: 6.41 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07751899236786676		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.07751899236786676 | validation: 0.10221275686459706]
	TIME [epoch: 6.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09611436232285331		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.09611436232285331 | validation: 0.125786531422636]
	TIME [epoch: 6.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08370583170331275		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.08370583170331275 | validation: 0.08452286455991948]
	TIME [epoch: 6.41 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07701888389460283		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.07701888389460283 | validation: 0.10939124832953351]
	TIME [epoch: 6.41 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944867991677148		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.0944867991677148 | validation: 0.0828186859326485]
	TIME [epoch: 6.43 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740548784730314		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.07740548784730314 | validation: 0.08230702968343376]
	TIME [epoch: 6.41 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08033367697301054		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.08033367697301054 | validation: 0.08856020819702304]
	TIME [epoch: 6.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08766812550646541		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.08766812550646541 | validation: 0.10940980746623677]
	TIME [epoch: 6.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09708509995056595		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.09708509995056595 | validation: 0.1222645883307175]
	TIME [epoch: 6.4 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10855636431637758		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.10855636431637758 | validation: 0.09891327356032419]
	TIME [epoch: 6.4 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755313790542089		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.0755313790542089 | validation: 0.08957019796812102]
	TIME [epoch: 6.41 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07688983230707384		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.07688983230707384 | validation: 0.09049726224944443]
	TIME [epoch: 6.44 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08676299708358774		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.08676299708358774 | validation: 0.09957048583127692]
	TIME [epoch: 6.41 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09619482722836503		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.09619482722836503 | validation: 0.13535046126803693]
	TIME [epoch: 6.41 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10568858759937574		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.10568858759937574 | validation: 0.09295060114755949]
	TIME [epoch: 6.4 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07467656047113409		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.07467656047113409 | validation: 0.09184560483593936]
	TIME [epoch: 6.41 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702573083486506		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.08702573083486506 | validation: 0.14537772951202763]
	TIME [epoch: 6.41 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11804137575056547		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.11804137575056547 | validation: 0.12707826231533825]
	TIME [epoch: 6.41 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09840138965296487		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.09840138965296487 | validation: 0.08715019532557576]
	TIME [epoch: 6.44 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07406325779326256		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.07406325779326256 | validation: 0.08514540329816082]
	TIME [epoch: 6.41 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07471899372729027		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.07471899372729027 | validation: 0.09062200155984458]
	TIME [epoch: 6.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08148836497659916		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.08148836497659916 | validation: 0.11214465869221327]
	TIME [epoch: 6.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08878508257639009		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.08878508257639009 | validation: 0.14464879977386544]
	TIME [epoch: 6.4 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11250706680291114		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.11250706680291114 | validation: 0.13032380901222]
	TIME [epoch: 6.4 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10920278702886638		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.10920278702886638 | validation: 0.08457849310802054]
	TIME [epoch: 6.4 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07463224809330878		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.07463224809330878 | validation: 0.08277097983397096]
	TIME [epoch: 6.42 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0743689689240642		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.0743689689240642 | validation: 0.09296188077157883]
	TIME [epoch: 6.42 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948627021919544		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.07948627021919544 | validation: 0.08562484509352705]
	TIME [epoch: 6.41 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08952921637302641		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.08952921637302641 | validation: 0.11856814727029263]
	TIME [epoch: 6.41 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167472642894144		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.10167472642894144 | validation: 0.15582409488653967]
	TIME [epoch: 6.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10612724115621253		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.10612724115621253 | validation: 0.09077479353410549]
	TIME [epoch: 6.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08159589970226236		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.08159589970226236 | validation: 0.07788553951584323]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_771.pth
	Model improved!!!
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08627014605857505		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.08627014605857505 | validation: 0.11654240457216616]
	TIME [epoch: 6.42 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847076847480619		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.0847076847480619 | validation: 0.1469871130044205]
	TIME [epoch: 6.42 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13409918952373523		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.13409918952373523 | validation: 0.09648281947332629]
	TIME [epoch: 6.4 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07597303118086587		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.07597303118086587 | validation: 0.13284796932773665]
	TIME [epoch: 6.41 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08829418356337777		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.08829418356337777 | validation: 0.09830180086726192]
	TIME [epoch: 6.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09418964563219955		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.09418964563219955 | validation: 0.08200358092854364]
	TIME [epoch: 6.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1404262153466206		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.1404262153466206 | validation: 0.19297651395382504]
	TIME [epoch: 6.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14227148793314875		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.14227148793314875 | validation: 0.0862137809778573]
	TIME [epoch: 6.41 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11664361509108492		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.11664361509108492 | validation: 0.1514709543133157]
	TIME [epoch: 6.43 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365916472264017		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.1365916472264017 | validation: 0.08074423019269102]
	TIME [epoch: 6.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753831076143103		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.0753831076143103 | validation: 0.10319389995208612]
	TIME [epoch: 6.4 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07636555050228123		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.07636555050228123 | validation: 0.07528521371921632]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_783.pth
	Model improved!!!
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08331915747648305		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.08331915747648305 | validation: 0.09673499120019351]
	TIME [epoch: 6.39 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07604323915477501		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.07604323915477501 | validation: 0.09505375012457404]
	TIME [epoch: 6.39 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07509882909520715		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.07509882909520715 | validation: 0.10029255985264289]
	TIME [epoch: 6.39 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08062326998830266		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.08062326998830266 | validation: 0.07817967256254545]
	TIME [epoch: 6.42 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09353100037288621		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.09353100037288621 | validation: 0.09878618332450874]
	TIME [epoch: 6.39 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09334137100145554		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.09334137100145554 | validation: 0.1383492750413573]
	TIME [epoch: 6.39 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10445936911619204		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.10445936911619204 | validation: 0.08327127159619513]
	TIME [epoch: 6.39 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07000352145292414		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.07000352145292414 | validation: 0.0831476462363026]
	TIME [epoch: 6.39 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07659837304451836		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.07659837304451836 | validation: 0.09985490654525349]
	TIME [epoch: 6.39 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10624691191146123		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.10624691191146123 | validation: 0.10342865947896802]
	TIME [epoch: 6.39 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07986868021319438		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.07986868021319438 | validation: 0.08248076574123062]
	TIME [epoch: 6.42 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834154631286375		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.07834154631286375 | validation: 0.08633781544207597]
	TIME [epoch: 6.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08284677933736836		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.08284677933736836 | validation: 0.10765821458521029]
	TIME [epoch: 6.39 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08115714587774747		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.08115714587774747 | validation: 0.08709735035416365]
	TIME [epoch: 6.39 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09631423950559911		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.09631423950559911 | validation: 0.0962749021889426]
	TIME [epoch: 6.39 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0691995296667586		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.0691995296667586 | validation: 0.09668928364848567]
	TIME [epoch: 6.39 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07900209399828861		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.07900209399828861 | validation: 0.08948828970731879]
	TIME [epoch: 6.39 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08419190178949741		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.08419190178949741 | validation: 0.07875066507840629]
	TIME [epoch: 6.41 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08540840413600173		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.08540840413600173 | validation: 0.15123683574620395]
	TIME [epoch: 6.41 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251925432387943		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.1251925432387943 | validation: 0.08792182491661431]
	TIME [epoch: 6.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07161653138552013		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.07161653138552013 | validation: 0.09369829173973222]
	TIME [epoch: 6.4 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07392436854285168		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.07392436854285168 | validation: 0.09766626199509679]
	TIME [epoch: 6.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07613776112795632		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.07613776112795632 | validation: 0.12829415234074878]
	TIME [epoch: 6.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09305453847147926		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.09305453847147926 | validation: 0.11625745831175648]
	TIME [epoch: 6.4 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09125840160120924		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.09125840160120924 | validation: 0.126316501238052]
	TIME [epoch: 6.42 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11335626875023036		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.11335626875023036 | validation: 0.08468697093447965]
	TIME [epoch: 6.42 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06797900176966813		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.06797900176966813 | validation: 0.08261228844978012]
	TIME [epoch: 6.41 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09007148710910388		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.09007148710910388 | validation: 0.1015789628279347]
	TIME [epoch: 6.4 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07225100944810034		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.07225100944810034 | validation: 0.08432433527862875]
	TIME [epoch: 6.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07385529228542971		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.07385529228542971 | validation: 0.10094213832793383]
	TIME [epoch: 6.4 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07731784414734119		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.07731784414734119 | validation: 0.09622419863090353]
	TIME [epoch: 6.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07597055602886105		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.07597055602886105 | validation: 0.08071040855117435]
	TIME [epoch: 6.41 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06579646799704617		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.06579646799704617 | validation: 0.07199068004582816]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_816.pth
	Model improved!!!
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07392977106595507		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.07392977106595507 | validation: 0.0988911803790621]
	TIME [epoch: 6.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08497353626031122		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.08497353626031122 | validation: 0.0814699933059845]
	TIME [epoch: 6.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07122810607440647		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.07122810607440647 | validation: 0.09812705036027305]
	TIME [epoch: 6.4 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07300844799220765		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.07300844799220765 | validation: 0.08640769909413543]
	TIME [epoch: 6.4 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0775990638193148		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.0775990638193148 | validation: 0.11237205343943746]
	TIME [epoch: 6.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09743140791849345		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.09743140791849345 | validation: 0.11851168994625785]
	TIME [epoch: 6.39 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09438867835003734		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.09438867835003734 | validation: 0.08190141016903224]
	TIME [epoch: 6.43 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641945489986707		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.06641945489986707 | validation: 0.08259820609119649]
	TIME [epoch: 6.4 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0759036680205896		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0759036680205896 | validation: 0.09448317973114076]
	TIME [epoch: 6.4 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07314203738569111		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.07314203738569111 | validation: 0.0969131494919211]
	TIME [epoch: 6.4 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09294224938788756		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.09294224938788756 | validation: 0.09040172967652584]
	TIME [epoch: 6.39 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07389515435827998		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.07389515435827998 | validation: 0.10123771600727896]
	TIME [epoch: 6.4 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07639135926327154		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.07639135926327154 | validation: 0.08260437260413038]
	TIME [epoch: 6.4 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07317035598033192		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.07317035598033192 | validation: 0.0968367341505347]
	TIME [epoch: 6.44 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07561087388679534		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.07561087388679534 | validation: 0.0814797288780704]
	TIME [epoch: 6.4 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07102520008358182		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.07102520008358182 | validation: 0.09037416548117808]
	TIME [epoch: 6.39 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07291862714043401		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.07291862714043401 | validation: 0.08564259921506544]
	TIME [epoch: 6.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07186953316302588		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.07186953316302588 | validation: 0.11145620417604626]
	TIME [epoch: 6.4 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08095489239100416		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.08095489239100416 | validation: 0.09820827461548826]
	TIME [epoch: 6.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07125388413455766		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.07125388413455766 | validation: 0.08463609236643879]
	TIME [epoch: 6.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07071435374864171		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.07071435374864171 | validation: 0.08402028079792088]
	TIME [epoch: 6.43 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513647086174457		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.06513647086174457 | validation: 0.08841887144506601]
	TIME [epoch: 6.4 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07890820206776222		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.07890820206776222 | validation: 0.09428473738700296]
	TIME [epoch: 6.4 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08681533544549645		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.08681533544549645 | validation: 0.08695651667348141]
	TIME [epoch: 6.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06525633930826005		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.06525633930826005 | validation: 0.08463205302199747]
	TIME [epoch: 6.4 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877109490684293		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.07877109490684293 | validation: 0.11272607471790921]
	TIME [epoch: 6.4 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13184548716802322		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.13184548716802322 | validation: 0.07674900406665668]
	TIME [epoch: 6.4 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06481414146350514		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.06481414146350514 | validation: 0.09111672176423553]
	TIME [epoch: 6.42 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08078110514647785		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08078110514647785 | validation: 0.14200762705930745]
	TIME [epoch: 6.42 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09175937645045901		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.09175937645045901 | validation: 0.07991796478685943]
	TIME [epoch: 6.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07450038341988748		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.07450038341988748 | validation: 0.09565858134304632]
	TIME [epoch: 6.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07845791263391177		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.07845791263391177 | validation: 0.11195625130754035]
	TIME [epoch: 6.4 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06969886981365861		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.06969886981365861 | validation: 0.10320271052600155]
	TIME [epoch: 6.4 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0758274667843953		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.0758274667843953 | validation: 0.1133290812381604]
	TIME [epoch: 6.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08688556173047018		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.08688556173047018 | validation: 0.08991185561478159]
	TIME [epoch: 6.4 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10085455056906673		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.10085455056906673 | validation: 0.08255821421004182]
	TIME [epoch: 6.43 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0890722322529765		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.0890722322529765 | validation: 0.12293411096488853]
	TIME [epoch: 6.41 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08394427395365515		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.08394427395365515 | validation: 0.078986708908719]
	TIME [epoch: 6.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670825628610166		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.0670825628610166 | validation: 0.07841083367216807]
	TIME [epoch: 6.41 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07176272162531819		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.07176272162531819 | validation: 0.08557829267862793]
	TIME [epoch: 6.4 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07117352728288125		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.07117352728288125 | validation: 0.09706875766674714]
	TIME [epoch: 6.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0700407289818268		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.0700407289818268 | validation: 0.10695503889094955]
	TIME [epoch: 6.41 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07984916642722964		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.07984916642722964 | validation: 0.07530089624444668]
	TIME [epoch: 6.44 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08031948252688934		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.08031948252688934 | validation: 0.09417103154897244]
	TIME [epoch: 6.41 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07639678344319469		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.07639678344319469 | validation: 0.07941631300740581]
	TIME [epoch: 6.41 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06906304716981082		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.06906304716981082 | validation: 0.0914506361392536]
	TIME [epoch: 6.41 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08550511733815684		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.08550511733815684 | validation: 0.08623679275719338]
	TIME [epoch: 6.41 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06907730114626268		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.06907730114626268 | validation: 0.10200398311302511]
	TIME [epoch: 6.41 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11143513704249842		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.11143513704249842 | validation: 0.08537757242330393]
	TIME [epoch: 6.41 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07798344706383678		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.07798344706383678 | validation: 0.0840042405731895]
	TIME [epoch: 6.44 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07750011078465717		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.07750011078465717 | validation: 0.07015964333096562]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08240542941486917		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.08240542941486917 | validation: 0.08828239626010548]
	TIME [epoch: 6.41 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07489279466318349		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.07489279466318349 | validation: 0.07907266748387365]
	TIME [epoch: 6.41 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493399150564072		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.06493399150564072 | validation: 0.0879664803060097]
	TIME [epoch: 6.41 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07800579283949327		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.07800579283949327 | validation: 0.11091054675770728]
	TIME [epoch: 6.4 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07520730024777335		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.07520730024777335 | validation: 0.09748629559159824]
	TIME [epoch: 6.41 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06747401565884001		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.06747401565884001 | validation: 0.08402471972091652]
	TIME [epoch: 6.43 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07372311310340907		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.07372311310340907 | validation: 0.09667921881985801]
	TIME [epoch: 6.41 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07590198677051832		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.07590198677051832 | validation: 0.07649277326694756]
	TIME [epoch: 6.41 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07523768996503763		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.07523768996503763 | validation: 0.11389152454173603]
	TIME [epoch: 6.41 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143197192866924		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.08143197192866924 | validation: 0.0744916831736818]
	TIME [epoch: 6.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06912290895243338		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.06912290895243338 | validation: 0.09741312327714746]
	TIME [epoch: 6.41 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08309629602008921		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.08309629602008921 | validation: 0.06906768047801577]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06695005407134139		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.06695005407134139 | validation: 0.08484886543542106]
	TIME [epoch: 6.43 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07145683335633564		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.07145683335633564 | validation: 0.08310168721520948]
	TIME [epoch: 6.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07016893575542306		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.07016893575542306 | validation: 0.07121062742103551]
	TIME [epoch: 6.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0797193944272984		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.0797193944272984 | validation: 0.1218894722062969]
	TIME [epoch: 6.4 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09069438428963056		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.09069438428963056 | validation: 0.07762627544892478]
	TIME [epoch: 6.4 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07262991709224695		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.07262991709224695 | validation: 0.09408419280971955]
	TIME [epoch: 6.41 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07714148459722177		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.07714148459722177 | validation: 0.07484737790784364]
	TIME [epoch: 6.4 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09495159646389269		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.09495159646389269 | validation: 0.11037125324167875]
	TIME [epoch: 6.42 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07748001837165508		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.07748001837165508 | validation: 0.09004287613129802]
	TIME [epoch: 6.42 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07262048054061104		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.07262048054061104 | validation: 0.09518597551135209]
	TIME [epoch: 6.4 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08036193165471098		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.08036193165471098 | validation: 0.09174024970652805]
	TIME [epoch: 6.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07790450939423411		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.07790450939423411 | validation: 0.09616626756500476]
	TIME [epoch: 6.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07079730182150368		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.07079730182150368 | validation: 0.08614047266947367]
	TIME [epoch: 6.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06830299809091231		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.06830299809091231 | validation: 0.08992070584091275]
	TIME [epoch: 6.4 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127214801354456		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.08127214801354456 | validation: 0.10328340911543911]
	TIME [epoch: 6.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09960102187170322		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.09960102187170322 | validation: 0.08432644407207462]
	TIME [epoch: 6.42 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717281791552923		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.0717281791552923 | validation: 0.09130112907116071]
	TIME [epoch: 6.41 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07165642227961425		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.07165642227961425 | validation: 0.0706723378644727]
	TIME [epoch: 6.4 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062227475624437284		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.062227475624437284 | validation: 0.0827102079985586]
	TIME [epoch: 6.41 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07693245817412465		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.07693245817412465 | validation: 0.09240168743783779]
	TIME [epoch: 6.4 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07405649342213237		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.07405649342213237 | validation: 0.08788812865195941]
	TIME [epoch: 6.41 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06751043741921145		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.06751043741921145 | validation: 0.07563399764913738]
	TIME [epoch: 6.41 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09221114580280954		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.09221114580280954 | validation: 0.1488252924151334]
	TIME [epoch: 6.44 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09283398206335362		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.09283398206335362 | validation: 0.07958368135355018]
	TIME [epoch: 6.41 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06181153379771993		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.06181153379771993 | validation: 0.08240339490434416]
	TIME [epoch: 6.41 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07128455297990363		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.07128455297990363 | validation: 0.07711044481233588]
	TIME [epoch: 6.41 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07310686845389508		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.07310686845389508 | validation: 0.07585646416765894]
	TIME [epoch: 6.41 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07859623711411409		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.07859623711411409 | validation: 0.08750528415913614]
	TIME [epoch: 6.41 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765100054246029		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.0765100054246029 | validation: 0.06790249518063073]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_908.pth
	Model improved!!!
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06732466479574642		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.06732466479574642 | validation: 0.08539527896518873]
	TIME [epoch: 6.44 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05942983636520197		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.05942983636520197 | validation: 0.08345018964349703]
	TIME [epoch: 6.42 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07596268832848191		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.07596268832848191 | validation: 0.09351379982504121]
	TIME [epoch: 6.41 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08301113636593252		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.08301113636593252 | validation: 0.10134690232960498]
	TIME [epoch: 6.4 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07190378904827548		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.07190378904827548 | validation: 0.07272725416278332]
	TIME [epoch: 6.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06323498435437618		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.06323498435437618 | validation: 0.07393114774715556]
	TIME [epoch: 6.41 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07203602551240126		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.07203602551240126 | validation: 0.08220165311893887]
	TIME [epoch: 6.4 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06362978294959962		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.06362978294959962 | validation: 0.07725475267942745]
	TIME [epoch: 6.44 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06965246333249227		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.06965246333249227 | validation: 0.08008632602603973]
	TIME [epoch: 6.41 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0766315407455074		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.0766315407455074 | validation: 0.10097594639699424]
	TIME [epoch: 6.41 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10397326092745621		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.10397326092745621 | validation: 0.09520619867240307]
	TIME [epoch: 6.41 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09029197319742989		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.09029197319742989 | validation: 0.09621570828615238]
	TIME [epoch: 6.41 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08014114164979501		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.08014114164979501 | validation: 0.07601959408038328]
	TIME [epoch: 6.4 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06451670019214634		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.06451670019214634 | validation: 0.07014440551762423]
	TIME [epoch: 6.41 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06062549771637044		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.06062549771637044 | validation: 0.07872159840707676]
	TIME [epoch: 6.43 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05879530910041979		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.05879530910041979 | validation: 0.06789943401143017]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_924.pth
	Model improved!!!
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07643259463275529		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.07643259463275529 | validation: 0.0831595592187173]
	TIME [epoch: 6.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09211526148141422		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.09211526148141422 | validation: 0.10414719288154022]
	TIME [epoch: 6.4 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09473854489706189		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.09473854489706189 | validation: 0.07408521323236757]
	TIME [epoch: 6.4 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269101802713128		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.06269101802713128 | validation: 0.08517406431781342]
	TIME [epoch: 6.4 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05968777005263069		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.05968777005263069 | validation: 0.07354394288780201]
	TIME [epoch: 6.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05670913249743159		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.05670913249743159 | validation: 0.0818869567771478]
	TIME [epoch: 6.42 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058724519231238906		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.058724519231238906 | validation: 0.07995811876205305]
	TIME [epoch: 6.42 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07979174746345936		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.07979174746345936 | validation: 0.12329540283636205]
	TIME [epoch: 6.41 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08526582929065159		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.08526582929065159 | validation: 0.09223347330530057]
	TIME [epoch: 6.41 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06814096320989335		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.06814096320989335 | validation: 0.08691392226251363]
	TIME [epoch: 6.41 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0630349228264651		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.0630349228264651 | validation: 0.07128215140506432]
	TIME [epoch: 6.41 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06432967326856529		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.06432967326856529 | validation: 0.08540951630725775]
	TIME [epoch: 6.41 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06480569831817934		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.06480569831817934 | validation: 0.07604496446309586]
	TIME [epoch: 6.41 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059733244683099256		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.059733244683099256 | validation: 0.06471653426503034]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_938.pth
	Model improved!!!
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05561975230492034		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.05561975230492034 | validation: 0.06967169266709174]
	TIME [epoch: 6.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059298443861572736		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.059298443861572736 | validation: 0.0782676594000386]
	TIME [epoch: 6.41 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06482449910553113		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.06482449910553113 | validation: 0.0873289935371472]
	TIME [epoch: 6.4 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0692451465346278		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.0692451465346278 | validation: 0.08379758000043891]
	TIME [epoch: 6.4 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060586164878662266		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.060586164878662266 | validation: 0.06915652118548744]
	TIME [epoch: 6.4 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06753921354898333		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.06753921354898333 | validation: 0.07081309647299025]
	TIME [epoch: 6.41 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06545004263438331		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.06545004263438331 | validation: 0.07869106874066527]
	TIME [epoch: 6.43 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0715403925312951		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0715403925312951 | validation: 0.0757689996365723]
	TIME [epoch: 6.41 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06867006820649339		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.06867006820649339 | validation: 0.08977323548226966]
	TIME [epoch: 6.41 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06116369165492116		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.06116369165492116 | validation: 0.06662017422588963]
	TIME [epoch: 6.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061360440915222		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.061360440915222 | validation: 0.07351910455527644]
	TIME [epoch: 6.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06699901272891898		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.06699901272891898 | validation: 0.07668348471659715]
	TIME [epoch: 6.4 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060640771807657215		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.060640771807657215 | validation: 0.07712096545198532]
	TIME [epoch: 6.4 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06042191776764898		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.06042191776764898 | validation: 0.07659267813659144]
	TIME [epoch: 6.44 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06590402831634433		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.06590402831634433 | validation: 0.08856469813702791]
	TIME [epoch: 6.41 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07913147324651765		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.07913147324651765 | validation: 0.09539919509039255]
	TIME [epoch: 6.4 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06834154818167233		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.06834154818167233 | validation: 0.06924703198967769]
	TIME [epoch: 6.41 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056739993988180006		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.056739993988180006 | validation: 0.07296673913158708]
	TIME [epoch: 6.41 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05998227060681623		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.05998227060681623 | validation: 0.07940302053272878]
	TIME [epoch: 6.4 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06779720353387657		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.06779720353387657 | validation: 0.07815884854393663]
	TIME [epoch: 6.41 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06032581476308228		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.06032581476308228 | validation: 0.07915230080784834]
	TIME [epoch: 6.43 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0711962442854431		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.0711962442854431 | validation: 0.09806269447431804]
	TIME [epoch: 6.41 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06782319591910371		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.06782319591910371 | validation: 0.06646138815236581]
	TIME [epoch: 6.4 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05988712926309928		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.05988712926309928 | validation: 0.07584302344117182]
	TIME [epoch: 6.4 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07817125729167018		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.07817125729167018 | validation: 0.07587860681115971]
	TIME [epoch: 6.4 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06819581653756313		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.06819581653756313 | validation: 0.06919908334612007]
	TIME [epoch: 6.41 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06978153718542626		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.06978153718542626 | validation: 0.0988407951631353]
	TIME [epoch: 6.4 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08308714182576256		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.08308714182576256 | validation: 0.12297856150860682]
	TIME [epoch: 6.42 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09177355362966436		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.09177355362966436 | validation: 0.08960205982381222]
	TIME [epoch: 6.42 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06979584102966394		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.06979584102966394 | validation: 0.06527703373673373]
	TIME [epoch: 6.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060083566916303004		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.060083566916303004 | validation: 0.07488298576102037]
	TIME [epoch: 6.4 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06238983547261869		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.06238983547261869 | validation: 0.08681826544521584]
	TIME [epoch: 6.4 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06945125463112281		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.06945125463112281 | validation: 0.06606721674929603]
	TIME [epoch: 6.4 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059027619324397276		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.059027619324397276 | validation: 0.06468494146803312]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_972.pth
	Model improved!!!
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06159657129227335		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.06159657129227335 | validation: 0.09126774820487202]
	TIME [epoch: 6.42 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06960694379661422		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.06960694379661422 | validation: 0.06949228529742271]
	TIME [epoch: 6.42 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057139243322735546		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.057139243322735546 | validation: 0.07225373739593487]
	TIME [epoch: 6.41 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07878090174647545		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.07878090174647545 | validation: 0.0824905616236335]
	TIME [epoch: 6.4 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061745112854448295		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.061745112854448295 | validation: 0.0807594549079778]
	TIME [epoch: 6.41 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06495266701675423		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.06495266701675423 | validation: 0.06086723376785214]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_978.pth
	Model improved!!!
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06893654397129638		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.06893654397129638 | validation: 0.0611705862718875]
	TIME [epoch: 6.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0576122103482664		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.0576122103482664 | validation: 0.06408155520549483]
	TIME [epoch: 6.43 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0595429741752988		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0595429741752988 | validation: 0.10040925142834622]
	TIME [epoch: 6.43 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832710801783252		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.0832710801783252 | validation: 0.08833980241662441]
	TIME [epoch: 6.41 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07139825243293424		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.07139825243293424 | validation: 0.06999739921424392]
	TIME [epoch: 6.41 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316997360166923		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.06316997360166923 | validation: 0.09150671205177158]
	TIME [epoch: 6.4 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0641108246116766		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.0641108246116766 | validation: 0.08749347988460976]
	TIME [epoch: 6.41 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07352415138764995		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.07352415138764995 | validation: 0.07334347177640708]
	TIME [epoch: 6.4 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07149925450673782		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.07149925450673782 | validation: 0.07282370181770767]
	TIME [epoch: 6.41 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07130944110162683		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.07130944110162683 | validation: 0.0738460324341873]
	TIME [epoch: 6.44 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06471719956564057		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.06471719956564057 | validation: 0.089452859528032]
	TIME [epoch: 6.41 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07006443160347056		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.07006443160347056 | validation: 0.07269831434744821]
	TIME [epoch: 6.41 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06188196529199716		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.06188196529199716 | validation: 0.0707124488368515]
	TIME [epoch: 6.41 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060793749498946545		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.060793749498946545 | validation: 0.0758779115257424]
	TIME [epoch: 6.41 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06354978987110821		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.06354978987110821 | validation: 0.0765731975362862]
	TIME [epoch: 6.41 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06693346725638395		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.06693346725638395 | validation: 0.0653272736186]
	TIME [epoch: 6.41 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06371297531307082		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.06371297531307082 | validation: 0.0730224413007695]
	TIME [epoch: 6.44 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08620155227903384		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.08620155227903384 | validation: 0.07295007916818369]
	TIME [epoch: 6.41 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390513121026986		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.06390513121026986 | validation: 0.06702452250829559]
	TIME [epoch: 6.41 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054619734564141625		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.054619734564141625 | validation: 0.0608703232911327]
	TIME [epoch: 6.41 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642294282109731		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.0642294282109731 | validation: 0.06970616958864997]
	TIME [epoch: 6.41 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0614710438429972		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.0614710438429972 | validation: 0.06567775369712289]
	TIME [epoch: 6.41 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05527651271832532		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.05527651271832532 | validation: 0.07154156742772567]
	TIME [epoch: 6.41 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06896903933334705		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.06896903933334705 | validation: 0.08516645965788175]
	TIME [epoch: 6.44 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0671393059963559		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0671393059963559 | validation: 0.06412153785265556]
	TIME [epoch: 6.42 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062224922429097156		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.062224922429097156 | validation: 0.0889077055273636]
	TIME [epoch: 6.41 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356182540336724		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.06356182540336724 | validation: 0.09053957197637874]
	TIME [epoch: 6.41 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07252193351382402		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.07252193351382402 | validation: 0.11011325056324647]
	TIME [epoch: 6.41 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07882054408784102		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.07882054408784102 | validation: 0.08362671565539938]
	TIME [epoch: 6.41 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06454338594686197		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.06454338594686197 | validation: 0.06624575026589087]
	TIME [epoch: 6.41 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062399339776511735		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.062399339776511735 | validation: 0.08115621972377646]
	TIME [epoch: 6.43 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06007021013173569		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.06007021013173569 | validation: 0.07185326420588754]
	TIME [epoch: 6.43 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06576855172129244		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.06576855172129244 | validation: 0.07818883090985261]
	TIME [epoch: 6.41 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06396439401631278		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.06396439401631278 | validation: 0.06297836126829838]
	TIME [epoch: 6.41 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0585223408329278		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.0585223408329278 | validation: 0.0737718916325389]
	TIME [epoch: 6.41 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06850705097775711		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.06850705097775711 | validation: 0.07302279392788157]
	TIME [epoch: 6.41 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06591788335499642		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.06591788335499642 | validation: 0.06886642179958244]
	TIME [epoch: 6.41 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06351285715857465		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.06351285715857465 | validation: 0.07228193318345112]
	TIME [epoch: 6.43 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059927704189226494		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.059927704189226494 | validation: 0.07917976686152399]
	TIME [epoch: 6.43 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07077628818636997		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.07077628818636997 | validation: 0.09480553743720208]
	TIME [epoch: 6.41 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07308350758663536		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.07308350758663536 | validation: 0.060755889343331405]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_1019.pth
	Model improved!!!
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05411736862624242		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.05411736862624242 | validation: 0.0541999751406068]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_1020.pth
	Model improved!!!
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05954453919992614		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.05954453919992614 | validation: 0.07458308687360128]
	TIME [epoch: 6.4 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05683797718050337		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.05683797718050337 | validation: 0.0809597196629988]
	TIME [epoch: 6.4 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468835541915544		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.06468835541915544 | validation: 0.07653542517321087]
	TIME [epoch: 6.42 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06305944785476691		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.06305944785476691 | validation: 0.06378374354848626]
	TIME [epoch: 6.42 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06218379850811991		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.06218379850811991 | validation: 0.0761836251890173]
	TIME [epoch: 6.41 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645954267035361		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.0645954267035361 | validation: 0.08924844843157026]
	TIME [epoch: 6.4 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789307210935404		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.0789307210935404 | validation: 0.06520345604902597]
	TIME [epoch: 6.4 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059638623094104184		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.059638623094104184 | validation: 0.07743807140104812]
	TIME [epoch: 6.4 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06291369877208992		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.06291369877208992 | validation: 0.07278516891877324]
	TIME [epoch: 6.4 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06429839003709643		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.06429839003709643 | validation: 0.07875935822491983]
	TIME [epoch: 6.41 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07189050487707516		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.07189050487707516 | validation: 0.09270641553437453]
	TIME [epoch: 6.44 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06645143193154937		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.06645143193154937 | validation: 0.07116696793201305]
	TIME [epoch: 6.41 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062290878232739856		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.062290878232739856 | validation: 0.06539171427119199]
	TIME [epoch: 6.41 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06414538826989447		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.06414538826989447 | validation: 0.07028708908994642]
	TIME [epoch: 6.4 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06213131728655857		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.06213131728655857 | validation: 0.06542527321908252]
	TIME [epoch: 6.41 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05698594655086622		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.05698594655086622 | validation: 0.05770954188370616]
	TIME [epoch: 6.4 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05642956202802372		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.05642956202802372 | validation: 0.06331898849266439]
	TIME [epoch: 6.41 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06415848898398219		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.06415848898398219 | validation: 0.06878242227875493]
	TIME [epoch: 6.44 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06711558980840746		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.06711558980840746 | validation: 0.07083821159678659]
	TIME [epoch: 6.41 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06675518218081809		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.06675518218081809 | validation: 0.08812116075561231]
	TIME [epoch: 6.4 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07259781659614996		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.07259781659614996 | validation: 0.0673808729700265]
	TIME [epoch: 6.4 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08241134529456917		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.08241134529456917 | validation: 0.07644446815951317]
	TIME [epoch: 6.4 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07011461171061749		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.07011461171061749 | validation: 0.0658196590672884]
	TIME [epoch: 6.4 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06374581630261303		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.06374581630261303 | validation: 0.0701843870204358]
	TIME [epoch: 6.4 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05351915917552197		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.05351915917552197 | validation: 0.07456002973444649]
	TIME [epoch: 6.44 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05880327173436732		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.05880327173436732 | validation: 0.07279169341386052]
	TIME [epoch: 6.41 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0613761001238749		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.0613761001238749 | validation: 0.06255815794810883]
	TIME [epoch: 6.41 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058213673644389355		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.058213673644389355 | validation: 0.07167495914355895]
	TIME [epoch: 6.41 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057051602006448925		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.057051602006448925 | validation: 0.07478020533007393]
	TIME [epoch: 6.41 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0692167352973104		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.0692167352973104 | validation: 0.0739240733486981]
	TIME [epoch: 6.4 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468413009917723		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.06468413009917723 | validation: 0.0850474924477746]
	TIME [epoch: 6.4 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06521388495188081		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.06521388495188081 | validation: 0.07393129050908981]
	TIME [epoch: 6.42 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05788471337492588		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.05788471337492588 | validation: 0.07117293395465554]
	TIME [epoch: 6.42 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05622036555912766		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.05622036555912766 | validation: 0.06307650566244855]
	TIME [epoch: 6.41 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0551832459559449		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.0551832459559449 | validation: 0.06228250541134154]
	TIME [epoch: 6.41 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060021330136089165		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.060021330136089165 | validation: 0.06432599321709671]
	TIME [epoch: 6.41 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05450684088426545		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.05450684088426545 | validation: 0.06883141420773921]
	TIME [epoch: 6.41 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05925264423879385		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.05925264423879385 | validation: 0.07149277385575335]
	TIME [epoch: 6.41 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05535949466224762		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.05535949466224762 | validation: 0.06767285735335993]
	TIME [epoch: 6.43 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06705013475072694		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.06705013475072694 | validation: 0.07091759489768044]
	TIME [epoch: 6.43 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05655457651471565		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.05655457651471565 | validation: 0.06554974125718468]
	TIME [epoch: 6.41 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054644047442436006		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.054644047442436006 | validation: 0.0807502715786375]
	TIME [epoch: 6.41 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060265568702409886		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.060265568702409886 | validation: 0.08611196796730887]
	TIME [epoch: 6.41 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05770961059230195		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.05770961059230195 | validation: 0.06705544579123231]
	TIME [epoch: 6.4 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062331458028185585		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.062331458028185585 | validation: 0.08044856997302091]
	TIME [epoch: 6.41 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08060983241711327		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.08060983241711327 | validation: 0.07121692902877089]
	TIME [epoch: 6.41 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05595380632422053		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.05595380632422053 | validation: 0.06185796861901751]
	TIME [epoch: 6.44 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05372586601673414		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.05372586601673414 | validation: 0.06814618310630659]
	TIME [epoch: 6.41 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053941638847711096		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.053941638847711096 | validation: 0.066771100397186]
	TIME [epoch: 6.41 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054175165266084555		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.054175165266084555 | validation: 0.0646998982450198]
	TIME [epoch: 6.41 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057827122735936806		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.057827122735936806 | validation: 0.06967560631278664]
	TIME [epoch: 6.41 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0528879093827809		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.0528879093827809 | validation: 0.06590454100069933]
	TIME [epoch: 6.41 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05956612395384732		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.05956612395384732 | validation: 0.060823876886602624]
	TIME [epoch: 6.41 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052719976782646005		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.052719976782646005 | validation: 0.06821762731113734]
	TIME [epoch: 6.44 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057399573532537655		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.057399573532537655 | validation: 0.06908106530070171]
	TIME [epoch: 6.41 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061293844939952366		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.061293844939952366 | validation: 0.07323417727800861]
	TIME [epoch: 6.41 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053519554162201936		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.053519554162201936 | validation: 0.06258542975647535]
	TIME [epoch: 6.41 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057735520399217546		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.057735520399217546 | validation: 0.06350264713081087]
	TIME [epoch: 6.41 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06749056935149599		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.06749056935149599 | validation: 0.07680279859626479]
	TIME [epoch: 6.41 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06772586065419614		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.06772586065419614 | validation: 0.06430733649080242]
	TIME [epoch: 6.4 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0573614254143726		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.0573614254143726 | validation: 0.06724708319733155]
	TIME [epoch: 6.44 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05629902731170031		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.05629902731170031 | validation: 0.07741488043690171]
	TIME [epoch: 6.41 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06371799189980148		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.06371799189980148 | validation: 0.07985496453969697]
	TIME [epoch: 6.41 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259483305297002		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.06259483305297002 | validation: 0.066602175555643]
	TIME [epoch: 6.41 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05288675078993581		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.05288675078993581 | validation: 0.06729204924560829]
	TIME [epoch: 6.41 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05559854278398348		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.05559854278398348 | validation: 0.06974919795579936]
	TIME [epoch: 6.41 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0563839874643603		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.0563839874643603 | validation: 0.07287448613936195]
	TIME [epoch: 6.41 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06416244712977293		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.06416244712977293 | validation: 0.06616293737997474]
	TIME [epoch: 6.44 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05814251293697587		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.05814251293697587 | validation: 0.07327968926174834]
	TIME [epoch: 6.42 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07239635286315371		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.07239635286315371 | validation: 0.07094775845616556]
	TIME [epoch: 6.41 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05660662936619386		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.05660662936619386 | validation: 0.061960869890120805]
	TIME [epoch: 6.41 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052227162672889536		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.052227162672889536 | validation: 0.07594157967784992]
	TIME [epoch: 6.41 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565339978087564		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.05565339978087564 | validation: 0.08339444839209825]
	TIME [epoch: 6.41 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07141722452644378		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.07141722452644378 | validation: 0.08739135861691061]
	TIME [epoch: 6.41 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06513957417296502		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.06513957417296502 | validation: 0.07568708504289155]
	TIME [epoch: 6.43 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050885025084578185		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.050885025084578185 | validation: 0.055893674593916434]
	TIME [epoch: 6.43 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059435324526542044		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.059435324526542044 | validation: 0.06431389701496264]
	TIME [epoch: 6.41 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05754366218472417		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.05754366218472417 | validation: 0.0837807271626577]
	TIME [epoch: 6.41 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07886376899138847		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.07886376899138847 | validation: 0.07444799256927372]
	TIME [epoch: 6.41 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05769728169905924		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.05769728169905924 | validation: 0.0751984688460859]
	TIME [epoch: 6.41 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05379343199385785		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.05379343199385785 | validation: 0.0808483000460732]
	TIME [epoch: 6.41 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06503322599320363		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.06503322599320363 | validation: 0.07174909179235209]
	TIME [epoch: 6.41 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06492779435110152		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.06492779435110152 | validation: 0.07705742566042424]
	TIME [epoch: 6.44 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667651720711952		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.0667651720711952 | validation: 0.06729497681441321]
	TIME [epoch: 6.41 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05328451094315262		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.05328451094315262 | validation: 0.07291568887585624]
	TIME [epoch: 6.41 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056050232707952605		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.056050232707952605 | validation: 0.06480202314405002]
	TIME [epoch: 6.41 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05362457490313684		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.05362457490313684 | validation: 0.07234024761706415]
	TIME [epoch: 6.41 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05270605442407908		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.05270605442407908 | validation: 0.06819629021859537]
	TIME [epoch: 6.41 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05405696454203701		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.05405696454203701 | validation: 0.06396984284024436]
	TIME [epoch: 6.42 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06442428117493718		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.06442428117493718 | validation: 0.07733060888056732]
	TIME [epoch: 6.44 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06009549951522726		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.06009549951522726 | validation: 0.07072010720432961]
	TIME [epoch: 6.42 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05883001689770241		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.05883001689770241 | validation: 0.05579588507443934]
	TIME [epoch: 6.41 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06032981892995447		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.06032981892995447 | validation: 0.06536863906670912]
	TIME [epoch: 6.41 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523793820911051		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.05523793820911051 | validation: 0.06293184904661162]
	TIME [epoch: 6.41 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054791539897175626		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.054791539897175626 | validation: 0.06715837108786948]
	TIME [epoch: 6.41 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05865802335676539		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.05865802335676539 | validation: 0.07569624254056997]
	TIME [epoch: 6.41 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0570152357731802		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.0570152357731802 | validation: 0.061588851876244015]
	TIME [epoch: 6.45 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05674148857407183		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.05674148857407183 | validation: 0.06905950791595522]
	TIME [epoch: 6.42 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057933646663321875		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.057933646663321875 | validation: 0.07285677890197344]
	TIME [epoch: 6.41 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975832326125966		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.06975832326125966 | validation: 0.07622214680533972]
	TIME [epoch: 6.41 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06066380440373644		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.06066380440373644 | validation: 0.06716724691950089]
	TIME [epoch: 6.41 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05829139735796858		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.05829139735796858 | validation: 0.06982865264371126]
	TIME [epoch: 6.41 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055936198113661385		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.055936198113661385 | validation: 0.059935155871611474]
	TIME [epoch: 6.41 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0598045517738556		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.0598045517738556 | validation: 0.07044272054255184]
	TIME [epoch: 6.44 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059215709388078866		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.059215709388078866 | validation: 0.08008414530883017]
	TIME [epoch: 6.41 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06709825165255015		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.06709825165255015 | validation: 0.07304461763292841]
	TIME [epoch: 6.41 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293108727436415		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.06293108727436415 | validation: 0.07325482386003775]
	TIME [epoch: 6.41 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0570569704627664		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0570569704627664 | validation: 0.061250466780759884]
	TIME [epoch: 6.41 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07302617340690766		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.07302617340690766 | validation: 0.06364734807162732]
	TIME [epoch: 6.41 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05770735961324976		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.05770735961324976 | validation: 0.06784868187630465]
	TIME [epoch: 6.41 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05880471556194114		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.05880471556194114 | validation: 0.06246009910389891]
	TIME [epoch: 6.43 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05471688388197093		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.05471688388197093 | validation: 0.068991461450237]
	TIME [epoch: 6.43 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052574434052497274		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.052574434052497274 | validation: 0.07034514711841557]
	TIME [epoch: 6.41 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056596361236038104		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.056596361236038104 | validation: 0.07738859284709591]
	TIME [epoch: 6.41 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055888516800792765		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.055888516800792765 | validation: 0.07962146711807455]
	TIME [epoch: 6.41 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889092205763276		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.05889092205763276 | validation: 0.07826200288903569]
	TIME [epoch: 6.41 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060983185453404254		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.060983185453404254 | validation: 0.07105099795386381]
	TIME [epoch: 6.41 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0547459408131664		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.0547459408131664 | validation: 0.06081735018736348]
	TIME [epoch: 6.43 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05075189699614171		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.05075189699614171 | validation: 0.060946080307636354]
	TIME [epoch: 6.43 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057163905564984754		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.057163905564984754 | validation: 0.0781782397640942]
	TIME [epoch: 6.41 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07035103714839067		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.07035103714839067 | validation: 0.06202789941968227]
	TIME [epoch: 6.41 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055071211327336084		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.055071211327336084 | validation: 0.056387853711852606]
	TIME [epoch: 6.41 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051876713529500934		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.051876713529500934 | validation: 0.06708018996701574]
	TIME [epoch: 6.41 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05935494220083107		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.05935494220083107 | validation: 0.06736584494968514]
	TIME [epoch: 6.41 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059457572377327746		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.059457572377327746 | validation: 0.06910474137120512]
	TIME [epoch: 6.41 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05158836236629959		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.05158836236629959 | validation: 0.07564183970307353]
	TIME [epoch: 6.44 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05590996791132359		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.05590996791132359 | validation: 0.06147085406862404]
	TIME [epoch: 6.41 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05655727095812333		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.05655727095812333 | validation: 0.06679819217696985]
	TIME [epoch: 6.4 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056246319286250804		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.056246319286250804 | validation: 0.07695917916375182]
	TIME [epoch: 6.41 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05432552583637647		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.05432552583637647 | validation: 0.07290931538315278]
	TIME [epoch: 6.41 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05739316420235955		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.05739316420235955 | validation: 0.06990179772906914]
	TIME [epoch: 6.41 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056541888089007626		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.056541888089007626 | validation: 0.06063980777261968]
	TIME [epoch: 6.42 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05254159023786019		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.05254159023786019 | validation: 0.07263056978169936]
	TIME [epoch: 6.44 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053657696888909506		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.053657696888909506 | validation: 0.0674255613350753]
	TIME [epoch: 6.42 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05501211180578311		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.05501211180578311 | validation: 0.0703159383593054]
	TIME [epoch: 6.41 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495196625319789		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.05495196625319789 | validation: 0.07453425693899506]
	TIME [epoch: 6.41 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05656916804960814		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.05656916804960814 | validation: 0.07307283094382377]
	TIME [epoch: 6.41 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05698814092122694		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.05698814092122694 | validation: 0.05812616366329441]
	TIME [epoch: 6.41 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051031926788714536		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.051031926788714536 | validation: 0.06963467935534703]
	TIME [epoch: 6.41 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05226043924555319		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.05226043924555319 | validation: 0.059826216130895365]
	TIME [epoch: 6.44 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059181256328768105		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.059181256328768105 | validation: 0.07103014248357123]
	TIME [epoch: 6.41 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05557675234685794		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.05557675234685794 | validation: 0.07065336741708583]
	TIME [epoch: 6.41 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061311897179653234		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.061311897179653234 | validation: 0.07676893322005506]
	TIME [epoch: 6.41 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05779870813200533		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.05779870813200533 | validation: 0.06858146525136354]
	TIME [epoch: 6.41 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05703164833950095		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.05703164833950095 | validation: 0.06851383907430815]
	TIME [epoch: 6.41 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053803123054007		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.053803123054007 | validation: 0.07293774070074437]
	TIME [epoch: 6.41 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05280961671602897		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.05280961671602897 | validation: 0.06714369107684438]
	TIME [epoch: 6.42 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05269726675738766		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.05269726675738766 | validation: 0.07076698960457745]
	TIME [epoch: 6.43 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448898001545827		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.05448898001545827 | validation: 0.07156513815376017]
	TIME [epoch: 6.41 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05650777492808082		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.05650777492808082 | validation: 0.06338782960255998]
	TIME [epoch: 6.41 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05677333958859082		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.05677333958859082 | validation: 0.07273849599930914]
	TIME [epoch: 6.4 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056852830872212566		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.056852830872212566 | validation: 0.07283428929867745]
	TIME [epoch: 6.4 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053435147055941136		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.053435147055941136 | validation: 0.08315778397965394]
	TIME [epoch: 6.4 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057147251428243645		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.057147251428243645 | validation: 0.08011863498976787]
	TIME [epoch: 6.42 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05530814937507182		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.05530814937507182 | validation: 0.07223124785922569]
	TIME [epoch: 6.42 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05754053119602972		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.05754053119602972 | validation: 0.08109503032439241]
	TIME [epoch: 6.41 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574370901932964		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.0574370901932964 | validation: 0.06822994792127389]
	TIME [epoch: 6.41 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06346196091762304		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.06346196091762304 | validation: 0.08741367905487925]
	TIME [epoch: 6.41 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06607397889614862		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.06607397889614862 | validation: 0.0634820995094144]
	TIME [epoch: 6.41 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05583651509242964		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.05583651509242964 | validation: 0.06230755626446873]
	TIME [epoch: 6.4 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05457244951290496		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.05457244951290496 | validation: 0.054986369128480005]
	TIME [epoch: 6.41 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05752886483985786		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.05752886483985786 | validation: 0.07070009858146623]
	TIME [epoch: 6.43 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04730622109615383		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.04730622109615383 | validation: 0.0703257237321023]
	TIME [epoch: 6.41 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578512153345336		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.05578512153345336 | validation: 0.0726144527968904]
	TIME [epoch: 6.4 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05430923377020031		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.05430923377020031 | validation: 0.0743812746372668]
	TIME [epoch: 6.4 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059723388671217154		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.059723388671217154 | validation: 0.07507014273068188]
	TIME [epoch: 6.41 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06201148826779518		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.06201148826779518 | validation: 0.07207968791104724]
	TIME [epoch: 6.4 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05123636725109751		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.05123636725109751 | validation: 0.06679978765279042]
	TIME [epoch: 6.4 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05345964502549236		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.05345964502549236 | validation: 0.06111461159321079]
	TIME [epoch: 6.44 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050899440982940726		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.050899440982940726 | validation: 0.061532615138129756]
	TIME [epoch: 6.4 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05346852597478124		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.05346852597478124 | validation: 0.06479113302722354]
	TIME [epoch: 6.4 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0556678809867799		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.0556678809867799 | validation: 0.07010190939886968]
	TIME [epoch: 6.41 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06185088104694782		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.06185088104694782 | validation: 0.07060586173969532]
	TIME [epoch: 6.4 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05946582492566165		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.05946582492566165 | validation: 0.0644721196992147]
	TIME [epoch: 6.41 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056707478657957		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.056707478657957 | validation: 0.07058901917451142]
	TIME [epoch: 6.4 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055419584157624345		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.055419584157624345 | validation: 0.06743313188599963]
	TIME [epoch: 6.44 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048974721430396995		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.048974721430396995 | validation: 0.06617642619401387]
	TIME [epoch: 6.41 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057829002711971		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.057829002711971 | validation: 0.06717432894119506]
	TIME [epoch: 6.4 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122121233485587		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.05122121233485587 | validation: 0.06711866910352453]
	TIME [epoch: 6.4 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05171472378222915		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.05171472378222915 | validation: 0.05590168025113163]
	TIME [epoch: 6.4 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05063655914860822		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.05063655914860822 | validation: 0.06666385367184308]
	TIME [epoch: 6.4 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05430317021102186		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.05430317021102186 | validation: 0.07352563246028437]
	TIME [epoch: 6.4 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058157723630532204		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.058157723630532204 | validation: 0.07080009010579301]
	TIME [epoch: 6.44 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801610793163532		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.05801610793163532 | validation: 0.06663516842215081]
	TIME [epoch: 6.41 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04843102007386922		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.04843102007386922 | validation: 0.05653776814175696]
	TIME [epoch: 6.41 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051717105214019295		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.051717105214019295 | validation: 0.053826425892610164]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_1206.pth
	Model improved!!!
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053304510028193246		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.053304510028193246 | validation: 0.05986602755477346]
	TIME [epoch: 6.41 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495490473315967		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.05495490473315967 | validation: 0.06324841775429209]
	TIME [epoch: 6.41 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05942432594541315		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.05942432594541315 | validation: 0.08726740115643455]
	TIME [epoch: 6.41 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06927740094376107		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.06927740094376107 | validation: 0.08667589368027205]
	TIME [epoch: 6.43 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07294448827029751		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.07294448827029751 | validation: 0.08712612601989747]
	TIME [epoch: 6.43 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07132257595119465		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.07132257595119465 | validation: 0.07873324539166263]
	TIME [epoch: 6.41 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0655388670658698		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.0655388670658698 | validation: 0.060545636171903325]
	TIME [epoch: 6.41 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05643877669692479		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.05643877669692479 | validation: 0.06333455274637279]
	TIME [epoch: 6.41 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05695607394843613		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.05695607394843613 | validation: 0.06735588188498087]
	TIME [epoch: 6.41 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04857763970267087		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.04857763970267087 | validation: 0.06889334127909438]
	TIME [epoch: 6.42 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051267389151482955		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.051267389151482955 | validation: 0.06288081454238373]
	TIME [epoch: 6.43 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05259759145028821		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.05259759145028821 | validation: 0.05909964159846764]
	TIME [epoch: 6.43 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050247488055903955		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.050247488055903955 | validation: 0.06211354292559053]
	TIME [epoch: 6.41 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049511531281438696		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.049511531281438696 | validation: 0.05539093014866096]
	TIME [epoch: 6.41 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050313843523721154		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.050313843523721154 | validation: 0.06654347004208715]
	TIME [epoch: 6.41 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05443509533195161		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.05443509533195161 | validation: 0.0704281620427674]
	TIME [epoch: 6.41 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05919780699302039		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.05919780699302039 | validation: 0.06068620900755825]
	TIME [epoch: 6.41 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05075426391304228		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.05075426391304228 | validation: 0.05797051956513721]
	TIME [epoch: 6.42 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052580504847241555		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.052580504847241555 | validation: 0.062208087959726995]
	TIME [epoch: 6.44 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05048756082479104		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.05048756082479104 | validation: 0.06201911574762242]
	TIME [epoch: 6.41 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04959056117672721		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.04959056117672721 | validation: 0.06380734140096898]
	TIME [epoch: 6.41 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05435702612784678		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.05435702612784678 | validation: 0.07021694919296197]
	TIME [epoch: 6.41 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06255606351567025		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.06255606351567025 | validation: 0.08355639279185852]
	TIME [epoch: 6.4 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06970747487573847		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.06970747487573847 | validation: 0.0837222376146397]
	TIME [epoch: 6.41 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06755469583157644		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.06755469583157644 | validation: 0.07758092336095049]
	TIME [epoch: 6.41 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0541747966667735		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.0541747966667735 | validation: 0.0644784550765558]
	TIME [epoch: 6.44 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04913708108956094		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.04913708108956094 | validation: 0.06549150433100291]
	TIME [epoch: 6.41 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05759992835246472		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.05759992835246472 | validation: 0.07104167825639258]
	TIME [epoch: 6.41 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05355021882480664		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.05355021882480664 | validation: 0.07327144076779132]
	TIME [epoch: 6.41 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05759708727568865		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.05759708727568865 | validation: 0.07579373976706592]
	TIME [epoch: 6.4 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05865779892417099		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.05865779892417099 | validation: 0.07169205944302055]
	TIME [epoch: 6.41 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459701428003083		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.05459701428003083 | validation: 0.06779744120361114]
	TIME [epoch: 6.4 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051481673009244874		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.051481673009244874 | validation: 0.06005037778812624]
	TIME [epoch: 6.43 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04950956168025512		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.04950956168025512 | validation: 0.06569844839705928]
	TIME [epoch: 6.41 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049606087504770656		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.049606087504770656 | validation: 0.06150697090738504]
	TIME [epoch: 6.4 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048247228008596016		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.048247228008596016 | validation: 0.0651518321272186]
	TIME [epoch: 6.4 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0525009242241587		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.0525009242241587 | validation: 0.0597071823618024]
	TIME [epoch: 6.4 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056851559096139884		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.056851559096139884 | validation: 0.06242161788784812]
	TIME [epoch: 6.4 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04980288686660933		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.04980288686660933 | validation: 0.0603926706959384]
	TIME [epoch: 6.4 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04653381915027138		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.04653381915027138 | validation: 0.055097532438496466]
	TIME [epoch: 6.42 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04953876954498279		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.04953876954498279 | validation: 0.056943039825532775]
	TIME [epoch: 6.41 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0576832364825996		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.0576832364825996 | validation: 0.0749159746550305]
	TIME [epoch: 6.4 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05583760225725891		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.05583760225725891 | validation: 0.05838992580187685]
	TIME [epoch: 6.41 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048368727625225066		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.048368727625225066 | validation: 0.055673108044219786]
	TIME [epoch: 6.4 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053604326037402165		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.053604326037402165 | validation: 0.06317009142534524]
	TIME [epoch: 6.41 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051679550587691914		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.051679550587691914 | validation: 0.05627915765575866]
	TIME [epoch: 6.4 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05759966543951765		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.05759966543951765 | validation: 0.0667247754797236]
	TIME [epoch: 6.42 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0527821200895409		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.0527821200895409 | validation: 0.05559346737836643]
	TIME [epoch: 6.42 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05075245939990362		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.05075245939990362 | validation: 0.05774741668084302]
	TIME [epoch: 6.4 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05142027790236065		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.05142027790236065 | validation: 0.07188672006292546]
	TIME [epoch: 6.4 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05283208870482429		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.05283208870482429 | validation: 0.05723999534771936]
	TIME [epoch: 6.41 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048603828273375976		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.048603828273375976 | validation: 0.058151482054641795]
	TIME [epoch: 6.4 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049035294791996295		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.049035294791996295 | validation: 0.061241596965403676]
	TIME [epoch: 6.4 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05038454126147501		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.05038454126147501 | validation: 0.06240408870954136]
	TIME [epoch: 6.4 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050858751901143924		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.050858751901143924 | validation: 0.047019119345145716]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_1261.pth
	Model improved!!!
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05354558537704314		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.05354558537704314 | validation: 0.06125942710444177]
	TIME [epoch: 6.4 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429541434406709		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.05429541434406709 | validation: 0.06274502332112714]
	TIME [epoch: 6.4 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0459812443955143		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.0459812443955143 | validation: 0.059631051527362436]
	TIME [epoch: 6.4 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053355023162418955		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.053355023162418955 | validation: 0.0681774857872959]
	TIME [epoch: 6.4 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04950079793552209		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.04950079793552209 | validation: 0.06355798007450911]
	TIME [epoch: 6.4 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05061335099466376		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.05061335099466376 | validation: 0.062490326838162566]
	TIME [epoch: 6.41 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05207328997775691		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.05207328997775691 | validation: 0.06313972649056755]
	TIME [epoch: 6.43 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054262964377297974		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.054262964377297974 | validation: 0.06207753085503484]
	TIME [epoch: 6.4 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056945626483716795		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.056945626483716795 | validation: 0.0802608676371911]
	TIME [epoch: 6.4 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05929927972269578		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.05929927972269578 | validation: 0.07259138037764765]
	TIME [epoch: 6.4 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05380162848855069		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.05380162848855069 | validation: 0.06256046052355077]
	TIME [epoch: 6.4 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05613303205251875		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.05613303205251875 | validation: 0.057550372186571615]
	TIME [epoch: 6.4 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04958875039268129		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.04958875039268129 | validation: 0.06134586830764246]
	TIME [epoch: 6.4 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048684024655610614		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.048684024655610614 | validation: 0.05930776447349637]
	TIME [epoch: 6.44 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0517891361756511		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.0517891361756511 | validation: 0.07089218523281442]
	TIME [epoch: 6.41 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04832841399801423		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.04832841399801423 | validation: 0.05948822732068087]
	TIME [epoch: 6.41 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049242761969172585		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.049242761969172585 | validation: 0.06469103830628031]
	TIME [epoch: 6.41 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050999411272575505		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.050999411272575505 | validation: 0.06282943574564534]
	TIME [epoch: 6.41 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05218355979759298		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.05218355979759298 | validation: 0.05282771356157616]
	TIME [epoch: 6.41 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05160326523385017		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.05160326523385017 | validation: 0.07533975477505374]
	TIME [epoch: 6.41 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04791535673421401		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.04791535673421401 | validation: 0.0700474900093237]
	TIME [epoch: 6.44 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05076546825305475		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.05076546825305475 | validation: 0.0604030927258262]
	TIME [epoch: 6.41 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05063975164596922		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.05063975164596922 | validation: 0.07306164946044384]
	TIME [epoch: 6.41 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05273798017085886		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.05273798017085886 | validation: 0.06748699765921536]
	TIME [epoch: 6.42 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052391242362768785		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.052391242362768785 | validation: 0.061407368046780667]
	TIME [epoch: 6.41 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05620151519941387		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.05620151519941387 | validation: 0.06810264600800665]
	TIME [epoch: 6.41 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0626113190693253		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.0626113190693253 | validation: 0.07489567956457306]
	TIME [epoch: 6.41 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06222754151180433		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.06222754151180433 | validation: 0.07862770424353492]
	TIME [epoch: 6.43 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06076289993209205		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.06076289993209205 | validation: 0.060875612191803076]
	TIME [epoch: 6.43 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050932349554084044		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.050932349554084044 | validation: 0.060321691057574775]
	TIME [epoch: 6.41 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057832871527901855		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.057832871527901855 | validation: 0.06556218044489083]
	TIME [epoch: 6.41 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05494720183518146		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.05494720183518146 | validation: 0.058745947545338864]
	TIME [epoch: 6.41 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051067044054836946		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.051067044054836946 | validation: 0.06026433006588718]
	TIME [epoch: 6.41 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053901429940509824		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.053901429940509824 | validation: 0.05833105267557033]
	TIME [epoch: 6.41 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04816530541707762		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.04816530541707762 | validation: 0.06357906797460706]
	TIME [epoch: 6.43 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05479539757113565		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.05479539757113565 | validation: 0.07212411355248641]
	TIME [epoch: 6.43 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0611239798914298		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.0611239798914298 | validation: 0.06241854617716736]
	TIME [epoch: 6.41 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122913413241868		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.05122913413241868 | validation: 0.05795960986396459]
	TIME [epoch: 6.41 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04950699839773161		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.04950699839773161 | validation: 0.06600011635492158]
	TIME [epoch: 6.41 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051450793565538326		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.051450793565538326 | validation: 0.05145369685140536]
	TIME [epoch: 6.41 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0460017677881515		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.0460017677881515 | validation: 0.0597450591907361]
	TIME [epoch: 6.41 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050812987572188634		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.050812987572188634 | validation: 0.0619324501615691]
	TIME [epoch: 6.41 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04882065869770781		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.04882065869770781 | validation: 0.06498780143445573]
	TIME [epoch: 6.44 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05932126310327361		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.05932126310327361 | validation: 0.08067469097969482]
	TIME [epoch: 6.41 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015628762508279		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.06015628762508279 | validation: 0.08669384313392914]
	TIME [epoch: 6.41 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05944650056312886		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.05944650056312886 | validation: 0.06664357020860326]
	TIME [epoch: 6.41 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05167423754465189		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.05167423754465189 | validation: 0.05935472369247975]
	TIME [epoch: 6.41 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04915129631582646		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.04915129631582646 | validation: 0.05494785375803406]
	TIME [epoch: 6.41 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05498040908603573		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.05498040908603573 | validation: 0.06369904816705686]
	TIME [epoch: 6.41 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05275610733134869		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.05275610733134869 | validation: 0.06809884686082267]
	TIME [epoch: 6.44 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05408907176881686		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.05408907176881686 | validation: 0.06706883192155783]
	TIME [epoch: 6.41 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051501508073860836		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.051501508073860836 | validation: 0.05570738363873632]
	TIME [epoch: 6.41 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05299386738918981		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.05299386738918981 | validation: 0.04988167905990652]
	TIME [epoch: 6.41 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053052780468726315		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.053052780468726315 | validation: 0.06729329279546717]
	TIME [epoch: 6.41 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05661126218976361		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.05661126218976361 | validation: 0.07019842465337525]
	TIME [epoch: 6.41 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05593218672618399		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.05593218672618399 | validation: 0.06858688883147222]
	TIME [epoch: 6.41 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05221041944260201		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.05221041944260201 | validation: 0.0619262754343446]
	TIME [epoch: 6.44 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04763090494959321		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.04763090494959321 | validation: 0.057571566192649824]
	TIME [epoch: 6.42 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04736093348902895		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.04736093348902895 | validation: 0.0608991826882269]
	TIME [epoch: 6.41 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05528834388376003		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.05528834388376003 | validation: 0.061983312932577514]
	TIME [epoch: 6.41 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0539367272319061		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.0539367272319061 | validation: 0.06623442368856831]
	TIME [epoch: 6.41 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05065683916699734		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.05065683916699734 | validation: 0.06286399142159697]
	TIME [epoch: 6.41 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048217128744835476		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.048217128744835476 | validation: 0.06526362161768107]
	TIME [epoch: 6.41 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05233725930748213		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.05233725930748213 | validation: 0.06699199303404603]
	TIME [epoch: 6.44 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05096244040959266		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.05096244040959266 | validation: 0.06549174052597938]
	TIME [epoch: 6.42 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05843360701697668		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.05843360701697668 | validation: 0.06512308197630298]
	TIME [epoch: 6.42 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055563444603764646		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.055563444603764646 | validation: 0.06385292253017852]
	TIME [epoch: 6.41 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05318778463894563		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.05318778463894563 | validation: 0.06234120059021893]
	TIME [epoch: 6.41 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052019340744061685		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.052019340744061685 | validation: 0.05938919295152512]
	TIME [epoch: 6.41 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05218204968499897		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.05218204968499897 | validation: 0.06380795588597289]
	TIME [epoch: 6.41 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04927392142476601		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.04927392142476601 | validation: 0.06346885560005956]
	TIME [epoch: 6.43 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048774748908538924		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.048774748908538924 | validation: 0.056343009212688776]
	TIME [epoch: 6.43 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0462144843081857		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.0462144843081857 | validation: 0.058763991190180616]
	TIME [epoch: 6.41 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048421807414980644		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.048421807414980644 | validation: 0.06349893013017775]
	TIME [epoch: 6.41 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05654943185407775		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.05654943185407775 | validation: 0.06371551186484511]
	TIME [epoch: 6.41 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05539310918974325		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.05539310918974325 | validation: 0.06257768475497108]
	TIME [epoch: 6.41 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050360908213031665		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.050360908213031665 | validation: 0.06564886748211916]
	TIME [epoch: 6.41 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05210638932838314		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.05210638932838314 | validation: 0.053359980023917924]
	TIME [epoch: 6.41 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05053111464506724		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.05053111464506724 | validation: 0.05344984157186859]
	TIME [epoch: 6.44 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046606088863597336		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.046606088863597336 | validation: 0.05705051971295386]
	TIME [epoch: 6.41 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05278550228798591		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.05278550228798591 | validation: 0.06325938784425014]
	TIME [epoch: 6.41 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050140686101544006		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.050140686101544006 | validation: 0.05531662847745437]
	TIME [epoch: 6.41 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04839588241360704		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.04839588241360704 | validation: 0.057831200492192314]
	TIME [epoch: 6.41 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04772233743631296		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.04772233743631296 | validation: 0.057458478811373094]
	TIME [epoch: 6.41 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056109232558355406		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.056109232558355406 | validation: 0.07278758940880717]
	TIME [epoch: 6.41 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0604589225147762		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.0604589225147762 | validation: 0.05955733835386349]
	TIME [epoch: 6.45 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05559865137684047		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.05559865137684047 | validation: 0.06725086829533376]
	TIME [epoch: 6.42 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053950009219815034		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.053950009219815034 | validation: 0.06154629589323909]
	TIME [epoch: 6.41 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04833863938598556		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.04833863938598556 | validation: 0.058944679674743025]
	TIME [epoch: 6.41 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05125170126020963		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.05125170126020963 | validation: 0.06768591963196363]
	TIME [epoch: 6.41 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048160403562705394		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.048160403562705394 | validation: 0.07049176852106392]
	TIME [epoch: 6.41 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052435573330012815		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.052435573330012815 | validation: 0.07605957948000695]
	TIME [epoch: 6.41 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053532907819050395		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.053532907819050395 | validation: 0.08293775067069593]
	TIME [epoch: 6.45 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05534658407250581		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.05534658407250581 | validation: 0.0630800609195363]
	TIME [epoch: 6.41 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0552296814298845		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.0552296814298845 | validation: 0.05668348870384216]
	TIME [epoch: 6.41 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048985341184491674		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.048985341184491674 | validation: 0.06072480359659051]
	TIME [epoch: 6.41 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0513200153648723		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.0513200153648723 | validation: 0.06703081403524853]
	TIME [epoch: 6.41 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049896474763881885		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.049896474763881885 | validation: 0.0634615168945343]
	TIME [epoch: 6.4 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047402122616774		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.047402122616774 | validation: 0.06752012810850949]
	TIME [epoch: 6.41 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04768660365657977		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.04768660365657977 | validation: 0.0696538800878398]
	TIME [epoch: 6.44 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04955096561356878		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.04955096561356878 | validation: 0.0685986361999474]
	TIME [epoch: 6.41 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05180133845916467		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.05180133845916467 | validation: 0.0635171441435114]
	TIME [epoch: 6.41 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049185770989080606		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.049185770989080606 | validation: 0.060595820121526804]
	TIME [epoch: 6.41 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04639481869190588		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.04639481869190588 | validation: 0.0571824190544803]
	TIME [epoch: 6.41 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04742224714837044		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.04742224714837044 | validation: 0.05662491724212858]
	TIME [epoch: 6.41 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048711409824459546		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.048711409824459546 | validation: 0.06430744140748469]
	TIME [epoch: 6.41 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731835103840159		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.04731835103840159 | validation: 0.06500917428700823]
	TIME [epoch: 6.42 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04689003368875207		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.04689003368875207 | validation: 0.06754513998631019]
	TIME [epoch: 6.42 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045575793744884276		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.045575793744884276 | validation: 0.06302068876440015]
	TIME [epoch: 6.41 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046760440494153115		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.046760440494153115 | validation: 0.06536686477853698]
	TIME [epoch: 6.41 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04857471472173605		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.04857471472173605 | validation: 0.060685535851972325]
	TIME [epoch: 6.41 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04575631288937626		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.04575631288937626 | validation: 0.06164611778259872]
	TIME [epoch: 6.4 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05146494133647678		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.05146494133647678 | validation: 0.06439885073506321]
	TIME [epoch: 6.41 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054797396023897924		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.054797396023897924 | validation: 0.06013905204442113]
	TIME [epoch: 6.43 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05259926254313969		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.05259926254313969 | validation: 0.061991491891265675]
	TIME [epoch: 6.42 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04729260394699927		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.04729260394699927 | validation: 0.06884272035397712]
	TIME [epoch: 6.41 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04883887690839202		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.04883887690839202 | validation: 0.06590842760298578]
	TIME [epoch: 6.41 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05088507659822542		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.05088507659822542 | validation: 0.06480723558131805]
	TIME [epoch: 6.41 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05194211815870352		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.05194211815870352 | validation: 0.055721463414505235]
	TIME [epoch: 6.41 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05065833734491755		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.05065833734491755 | validation: 0.06582309284625684]
	TIME [epoch: 6.41 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05499515394800648		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.05499515394800648 | validation: 0.07136904738258457]
	TIME [epoch: 6.41 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05035748403973099		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.05035748403973099 | validation: 0.06974512727118219]
	TIME [epoch: 6.44 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050513833567302976		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.050513833567302976 | validation: 0.0481670641706264]
	TIME [epoch: 6.41 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04727250980743643		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.04727250980743643 | validation: 0.05699701717329247]
	TIME [epoch: 6.41 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05104704683885269		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.05104704683885269 | validation: 0.06215071757269732]
	TIME [epoch: 6.41 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05043956535977586		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.05043956535977586 | validation: 0.052184702672600725]
	TIME [epoch: 6.41 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050808477254322346		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.050808477254322346 | validation: 0.056692058227291925]
	TIME [epoch: 6.41 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05165195407091247		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.05165195407091247 | validation: 0.061241014820978566]
	TIME [epoch: 6.41 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04816888290523255		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.04816888290523255 | validation: 0.06056886116710161]
	TIME [epoch: 6.44 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04631000341122542		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.04631000341122542 | validation: 0.051219387349712965]
	TIME [epoch: 6.41 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04969851416155146		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.04969851416155146 | validation: 0.06245394903835972]
	TIME [epoch: 6.41 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053123811546489215		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.053123811546489215 | validation: 0.06433435077501519]
	TIME [epoch: 6.41 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05081487403311054		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.05081487403311054 | validation: 0.05935438827609302]
	TIME [epoch: 6.41 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04354083344192123		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.04354083344192123 | validation: 0.056130117832360965]
	TIME [epoch: 6.41 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05064663770702603		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.05064663770702603 | validation: 0.062145198431170716]
	TIME [epoch: 6.41 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04976961351188511		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.04976961351188511 | validation: 0.05661769149104078]
	TIME [epoch: 6.44 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049421913048195695		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.049421913048195695 | validation: 0.07148924624989855]
	TIME [epoch: 6.42 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0453997574057067		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.0453997574057067 | validation: 0.06033930635479803]
	TIME [epoch: 6.41 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05260354084701148		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.05260354084701148 | validation: 0.06119784404517928]
	TIME [epoch: 6.41 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048835021362519555		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.048835021362519555 | validation: 0.05416457052060435]
	TIME [epoch: 6.41 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048608039260186316		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.048608039260186316 | validation: 0.06586312988382026]
	TIME [epoch: 6.41 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05185672741327665		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.05185672741327665 | validation: 0.052434063119539805]
	TIME [epoch: 6.41 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04827035235169789		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.04827035235169789 | validation: 0.05887444829891285]
	TIME [epoch: 6.44 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0475652524294917		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.0475652524294917 | validation: 0.05755267402669633]
	TIME [epoch: 6.42 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04922758736674061		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.04922758736674061 | validation: 0.06276710857499712]
	TIME [epoch: 6.41 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05341961637024263		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.05341961637024263 | validation: 0.06182821467578984]
	TIME [epoch: 6.41 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051601912298643776		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.051601912298643776 | validation: 0.05884464464469744]
	TIME [epoch: 6.41 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04923130024958695		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.04923130024958695 | validation: 0.058438796074811034]
	TIME [epoch: 6.41 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04830377186074049		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.04830377186074049 | validation: 0.05259861872852342]
	TIME [epoch: 6.41 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048602592017371264		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.048602592017371264 | validation: 0.05129974468448967]
	TIME [epoch: 6.43 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05071357534781597		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.05071357534781597 | validation: 0.05941446489687669]
	TIME [epoch: 6.43 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04749034194106429		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.04749034194106429 | validation: 0.05861720986231994]
	TIME [epoch: 6.41 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04822151591027334		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.04822151591027334 | validation: 0.051100569072757715]
	TIME [epoch: 6.41 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049505519990015893		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.049505519990015893 | validation: 0.06441567172326598]
	TIME [epoch: 6.41 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05176402942861598		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.05176402942861598 | validation: 0.054622145030786044]
	TIME [epoch: 6.41 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050160546490632375		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.050160546490632375 | validation: 0.0554897314458467]
	TIME [epoch: 6.41 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047539204038212476		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.047539204038212476 | validation: 0.055684522886446576]
	TIME [epoch: 6.42 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04439624375049799		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.04439624375049799 | validation: 0.06096398288425433]
	TIME [epoch: 6.44 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05282931390414834		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.05282931390414834 | validation: 0.06218843309773821]
	TIME [epoch: 6.41 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04955063930858489		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.04955063930858489 | validation: 0.05670821253053233]
	TIME [epoch: 6.41 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049946316059630826		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.049946316059630826 | validation: 0.05697349365115129]
	TIME [epoch: 6.41 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04973989854152207		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.04973989854152207 | validation: 0.06321086395591732]
	TIME [epoch: 6.41 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048171465483062496		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.048171465483062496 | validation: 0.056138890280609796]
	TIME [epoch: 6.41 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04453390263107981		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.04453390263107981 | validation: 0.05475783435171776]
	TIME [epoch: 6.42 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0518013570971734		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.0518013570971734 | validation: 0.0685261418809335]
	TIME [epoch: 6.44 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05383585610012626		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.05383585610012626 | validation: 0.07168850978059096]
	TIME [epoch: 6.41 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05491373290242165		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.05491373290242165 | validation: 0.05941440026538565]
	TIME [epoch: 6.41 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05653064083633909		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.05653064083633909 | validation: 0.0779959428847073]
	TIME [epoch: 6.41 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06200435748097835		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.06200435748097835 | validation: 0.07758145960901996]
	TIME [epoch: 6.41 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061161450747219945		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.061161450747219945 | validation: 0.06825589586134972]
	TIME [epoch: 6.41 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06067970951603181		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.06067970951603181 | validation: 0.05876417302396373]
	TIME [epoch: 6.41 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06154117821521382		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.06154117821521382 | validation: 0.06394002996894681]
	TIME [epoch: 6.44 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05557632918094555		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.05557632918094555 | validation: 0.06039829212278301]
	TIME [epoch: 6.41 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045407508804995986		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.045407508804995986 | validation: 0.059864362908485784]
	TIME [epoch: 6.41 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050503493259112284		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.050503493259112284 | validation: 0.06346040809356947]
	TIME [epoch: 6.41 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046937208195795235		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.046937208195795235 | validation: 0.06044671237712761]
	TIME [epoch: 6.41 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04660379627262998		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.04660379627262998 | validation: 0.059793025884636926]
	TIME [epoch: 6.41 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046617836017913666		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.046617836017913666 | validation: 0.06178811580024253]
	TIME [epoch: 6.41 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049637994467352134		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.049637994467352134 | validation: 0.05430963756430707]
	TIME [epoch: 6.44 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04791321082886053		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.04791321082886053 | validation: 0.06191640948526136]
	TIME [epoch: 6.42 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04684075865599881		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.04684075865599881 | validation: 0.049366873063100905]
	TIME [epoch: 6.41 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050120181379418136		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.050120181379418136 | validation: 0.058887001029532586]
	TIME [epoch: 6.41 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05039330737829339		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.05039330737829339 | validation: 0.061065228111045596]
	TIME [epoch: 6.41 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047553337521262166		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.047553337521262166 | validation: 0.05704332771269382]
	TIME [epoch: 6.41 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05231967475240111		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.05231967475240111 | validation: 0.06118168032605005]
	TIME [epoch: 6.41 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04763808985546235		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.04763808985546235 | validation: 0.05266593681441542]
	TIME [epoch: 6.42 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04658183111827887		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.04658183111827887 | validation: 0.05206519962666847]
	TIME [epoch: 6.43 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04962372941761496		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.04962372941761496 | validation: 0.05863420986122335]
	TIME [epoch: 6.41 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048473364699791216		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.048473364699791216 | validation: 0.05827347614466254]
	TIME [epoch: 6.41 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04987251426461192		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.04987251426461192 | validation: 0.05891606383846378]
	TIME [epoch: 6.41 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05068572382513099		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.05068572382513099 | validation: 0.060884076809308914]
	TIME [epoch: 6.41 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04980064081845601		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.04980064081845601 | validation: 0.05585466729809906]
	TIME [epoch: 6.4 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05638481837317219		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.05638481837317219 | validation: 0.06692521123334474]
	TIME [epoch: 6.42 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051553223829740216		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.051553223829740216 | validation: 0.05744674962522483]
	TIME [epoch: 6.42 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04569779111832194		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.04569779111832194 | validation: 0.051308659176253546]
	TIME [epoch: 6.41 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046697076992696554		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.046697076992696554 | validation: 0.05724402684613923]
	TIME [epoch: 6.41 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04959192371615427		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.04959192371615427 | validation: 0.05751028141422235]
	TIME [epoch: 6.41 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0494988597133283		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.0494988597133283 | validation: 0.05944419176231472]
	TIME [epoch: 6.4 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04718699147583574		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.04718699147583574 | validation: 0.05045066646789205]
	TIME [epoch: 6.41 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04855491584167086		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.04855491584167086 | validation: 0.060984126792420615]
	TIME [epoch: 6.41 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05415106577931157		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.05415106577931157 | validation: 0.06168815627858014]
	TIME [epoch: 6.44 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04900817628506373		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.04900817628506373 | validation: 0.06527114715595539]
	TIME [epoch: 6.41 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04646257390513697		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.04646257390513697 | validation: 0.058980961773541035]
	TIME [epoch: 6.41 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048758808430252855		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.048758808430252855 | validation: 0.05911499946212752]
	TIME [epoch: 6.4 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046226182938342415		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.046226182938342415 | validation: 0.06319721661122508]
	TIME [epoch: 6.41 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0466470402958027		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.0466470402958027 | validation: 0.06560710300088843]
	TIME [epoch: 6.4 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05046854670083881		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.05046854670083881 | validation: 0.06566502924015863]
	TIME [epoch: 6.4 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046109305991050696		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.046109305991050696 | validation: 0.058626783752400984]
	TIME [epoch: 6.43 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04860499333065464		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.04860499333065464 | validation: 0.06438221886043868]
	TIME [epoch: 6.4 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052244297759721045		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.052244297759721045 | validation: 0.05908094039177662]
	TIME [epoch: 6.4 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047243446699996666		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.047243446699996666 | validation: 0.05602014225754244]
	TIME [epoch: 6.4 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045248671897788806		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.045248671897788806 | validation: 0.05796689187404191]
	TIME [epoch: 6.4 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04845008059827333		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.04845008059827333 | validation: 0.05916734389327055]
	TIME [epoch: 6.41 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04678283920877156		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.04678283920877156 | validation: 0.060237894354338906]
	TIME [epoch: 6.41 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05018647893770365		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.05018647893770365 | validation: 0.06247643618486815]
	TIME [epoch: 6.44 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048596201491243954		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.048596201491243954 | validation: 0.05560238632322347]
	TIME [epoch: 6.41 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04796714494219095		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.04796714494219095 | validation: 0.05317423246112712]
	TIME [epoch: 6.41 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858196755139469		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.04858196755139469 | validation: 0.05693906385108962]
	TIME [epoch: 6.4 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05072425710406306		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.05072425710406306 | validation: 0.05871910196774767]
	TIME [epoch: 6.4 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04685661229555719		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.04685661229555719 | validation: 0.05391446201080115]
	TIME [epoch: 6.41 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04708169946168075		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.04708169946168075 | validation: 0.058144935588919186]
	TIME [epoch: 6.41 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04595944073084706		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.04595944073084706 | validation: 0.06124607041239551]
	TIME [epoch: 6.44 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04703804630837856		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.04703804630837856 | validation: 0.06608238424873114]
	TIME [epoch: 6.41 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04690593881789765		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.04690593881789765 | validation: 0.05998616209838729]
	TIME [epoch: 6.41 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04803969049170084		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.04803969049170084 | validation: 0.05400117280366434]
	TIME [epoch: 6.4 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043544619211676364		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.043544619211676364 | validation: 0.05234544824218944]
	TIME [epoch: 6.4 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04864982326387646		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.04864982326387646 | validation: 0.05827534920730296]
	TIME [epoch: 6.4 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04785946289089617		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.04785946289089617 | validation: 0.05962194762031908]
	TIME [epoch: 6.4 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0494956553002004		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.0494956553002004 | validation: 0.05979665512430474]
	TIME [epoch: 6.42 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05100812214721073		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.05100812214721073 | validation: 0.06350372804971839]
	TIME [epoch: 6.42 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048365445148707956		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.048365445148707956 | validation: 0.05436926930611776]
	TIME [epoch: 6.41 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04683579248932601		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.04683579248932601 | validation: 0.05910337816031342]
	TIME [epoch: 6.41 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047839450015553786		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.047839450015553786 | validation: 0.05642517046603841]
	TIME [epoch: 6.41 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04439692194684934		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.04439692194684934 | validation: 0.059886887412874706]
	TIME [epoch: 6.4 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04749526730543112		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.04749526730543112 | validation: 0.05490631993063989]
	TIME [epoch: 6.4 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045623167846866125		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.045623167846866125 | validation: 0.0581997263110515]
	TIME [epoch: 6.41 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04943142997493454		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.04943142997493454 | validation: 0.06086893299836711]
	TIME [epoch: 6.44 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04784937879950898		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.04784937879950898 | validation: 0.06163682994163571]
	TIME [epoch: 6.41 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0479109976791171		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.0479109976791171 | validation: 0.05808280329371035]
	TIME [epoch: 6.41 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05135121802784315		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.05135121802784315 | validation: 0.06286937563537082]
	TIME [epoch: 6.41 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052598307957794535		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.052598307957794535 | validation: 0.051728759321419376]
	TIME [epoch: 6.41 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050537691324540106		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.050537691324540106 | validation: 0.0645676428745095]
	TIME [epoch: 6.41 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050830459413962206		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.050830459413962206 | validation: 0.066938963558677]
	TIME [epoch: 6.41 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05634855626750672		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.05634855626750672 | validation: 0.06332458496427547]
	TIME [epoch: 6.44 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05840443616324863		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.05840443616324863 | validation: 0.0675968233149911]
	TIME [epoch: 6.41 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05075097339930768		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.05075097339930768 | validation: 0.06252452577878534]
	TIME [epoch: 6.41 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05476098199579065		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.05476098199579065 | validation: 0.06790797709820709]
	TIME [epoch: 6.41 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05017896211386822		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.05017896211386822 | validation: 0.06978349472188794]
	TIME [epoch: 6.41 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053173893193430244		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.053173893193430244 | validation: 0.05782230013852676]
	TIME [epoch: 6.41 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0503627105775474		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.0503627105775474 | validation: 0.058973166569366735]
	TIME [epoch: 6.41 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05054838054864454		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.05054838054864454 | validation: 0.05082112294334318]
	TIME [epoch: 6.44 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0486161634767389		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.0486161634767389 | validation: 0.06332944426041114]
	TIME [epoch: 6.41 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04811690147635336		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.04811690147635336 | validation: 0.05433045891946892]
	TIME [epoch: 6.41 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04986998258711238		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.04986998258711238 | validation: 0.06223713987476478]
	TIME [epoch: 6.41 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04675013685991501		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.04675013685991501 | validation: 0.05683955394901849]
	TIME [epoch: 6.41 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04941731339114894		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.04941731339114894 | validation: 0.06056064523345539]
	TIME [epoch: 6.41 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04816929798819222		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.04816929798819222 | validation: 0.05086300053936549]
	TIME [epoch: 6.41 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049937614591598664		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.049937614591598664 | validation: 0.06265677690339927]
	TIME [epoch: 6.44 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04541141711182177		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.04541141711182177 | validation: 0.06238759977194564]
	TIME [epoch: 6.41 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05036936223393054		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.05036936223393054 | validation: 0.0588168659423539]
	TIME [epoch: 6.41 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047110136527727484		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.047110136527727484 | validation: 0.06280771942283005]
	TIME [epoch: 6.41 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047844751236824995		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.047844751236824995 | validation: 0.0528880138057043]
	TIME [epoch: 6.4 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451870044123		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.0451870044123 | validation: 0.06457550124854448]
	TIME [epoch: 6.41 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0475473413225439		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.0475473413225439 | validation: 0.05160008215966608]
	TIME [epoch: 6.41 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047854090020275006		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.047854090020275006 | validation: 0.054034324356112315]
	TIME [epoch: 6.42 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04542424739027958		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.04542424739027958 | validation: 0.05401315193652678]
	TIME [epoch: 6.43 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04752965540498921		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.04752965540498921 | validation: 0.059478952504654375]
	TIME [epoch: 6.41 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043798711451160766		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.043798711451160766 | validation: 0.05754454048468027]
	TIME [epoch: 6.41 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04311826313043226		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.04311826313043226 | validation: 0.05716964654037076]
	TIME [epoch: 6.4 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04863939136911576		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.04863939136911576 | validation: 0.05127015553428356]
	TIME [epoch: 6.4 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0500896205219492		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.0500896205219492 | validation: 0.057083708472000484]
	TIME [epoch: 6.41 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04698305678036443		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.04698305678036443 | validation: 0.06470557847769146]
	TIME [epoch: 6.42 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04766850249345026		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.04766850249345026 | validation: 0.06341797880662185]
	TIME [epoch: 6.43 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04790337214966402		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.04790337214966402 | validation: 0.0575354968131889]
	TIME [epoch: 6.41 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04626465101165862		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.04626465101165862 | validation: 0.052436061689531924]
	TIME [epoch: 6.41 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047427411160752345		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.047427411160752345 | validation: 0.06611804652226667]
	TIME [epoch: 6.4 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049018518534065414		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.049018518534065414 | validation: 0.05707596675551889]
	TIME [epoch: 6.4 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04793878747386191		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.04793878747386191 | validation: 0.057308265208967736]
	TIME [epoch: 6.41 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04748357582813395		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.04748357582813395 | validation: 0.05378094176536597]
	TIME [epoch: 6.41 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04567273716128622		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.04567273716128622 | validation: 0.06054318452080493]
	TIME [epoch: 6.43 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04974650285567653		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.04974650285567653 | validation: 0.05888370424438588]
	TIME [epoch: 6.41 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04905177202074587		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.04905177202074587 | validation: 0.06153060698114654]
	TIME [epoch: 6.41 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04826771590039335		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.04826771590039335 | validation: 0.05152928503189314]
	TIME [epoch: 6.41 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04896625072509298		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.04896625072509298 | validation: 0.05748923449504977]
	TIME [epoch: 6.41 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05493891675207073		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.05493891675207073 | validation: 0.04630073518714824]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_1546.pth
	Model improved!!!
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04638688718500682		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.04638688718500682 | validation: 0.0520167541593842]
	TIME [epoch: 6.41 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0481229143641867		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.0481229143641867 | validation: 0.049837096716009645]
	TIME [epoch: 6.44 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04754487595318122		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.04754487595318122 | validation: 0.059322805112639605]
	TIME [epoch: 6.41 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04673045939365808		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.04673045939365808 | validation: 0.053267250441257005]
	TIME [epoch: 6.41 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047876443952948926		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.047876443952948926 | validation: 0.06428009389937542]
	TIME [epoch: 6.41 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04764248568814053		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.04764248568814053 | validation: 0.06454229637907032]
	TIME [epoch: 6.41 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04499069200335444		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.04499069200335444 | validation: 0.05668122266060628]
	TIME [epoch: 6.41 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045722716552234866		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.045722716552234866 | validation: 0.058912464170855224]
	TIME [epoch: 6.41 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0476143259475719		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.0476143259475719 | validation: 0.05905962957220213]
	TIME [epoch: 6.44 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487349677508213		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.0487349677508213 | validation: 0.06366205282304344]
	TIME [epoch: 6.41 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05171836655032022		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.05171836655032022 | validation: 0.05318468430458289]
	TIME [epoch: 6.41 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523850464289725		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.05523850464289725 | validation: 0.04635688545708421]
	TIME [epoch: 6.41 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04442353218692119		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.04442353218692119 | validation: 0.06120664922857785]
	TIME [epoch: 6.41 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04843166547493562		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.04843166547493562 | validation: 0.060169612512849295]
	TIME [epoch: 6.41 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04568420050653267		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.04568420050653267 | validation: 0.05381977031055093]
	TIME [epoch: 6.41 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04886063638211873		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.04886063638211873 | validation: 0.052429241897727547]
	TIME [epoch: 6.44 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0438714504234859		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.0438714504234859 | validation: 0.05353625428486746]
	TIME [epoch: 6.41 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04746424551359251		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.04746424551359251 | validation: 0.06297980653129631]
	TIME [epoch: 6.41 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04884625587811873		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.04884625587811873 | validation: 0.054509932575066575]
	TIME [epoch: 6.41 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04786514961028054		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.04786514961028054 | validation: 0.04976795064654816]
	TIME [epoch: 6.41 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047892738852182544		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.047892738852182544 | validation: 0.05521342493783761]
	TIME [epoch: 6.41 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049331894842931955		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.049331894842931955 | validation: 0.055035215234428725]
	TIME [epoch: 6.41 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045698000671718295		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.045698000671718295 | validation: 0.05180571229373892]
	TIME [epoch: 6.43 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045101014945581955		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.045101014945581955 | validation: 0.06060085198014791]
	TIME [epoch: 6.42 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04711882057971829		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.04711882057971829 | validation: 0.06515704474436906]
	TIME [epoch: 6.41 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04609284762174399		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.04609284762174399 | validation: 0.06084343807508329]
	TIME [epoch: 6.41 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045917407172712484		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.045917407172712484 | validation: 0.06394646636219331]
	TIME [epoch: 6.41 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04899211023408571		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.04899211023408571 | validation: 0.056671408274315715]
	TIME [epoch: 6.41 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051041880720933554		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.051041880720933554 | validation: 0.060487439103253986]
	TIME [epoch: 6.41 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047952298758020914		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.047952298758020914 | validation: 0.05544426551851675]
	TIME [epoch: 6.43 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04660168525228278		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.04660168525228278 | validation: 0.06187008425358845]
	TIME [epoch: 6.43 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048676341918793845		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.048676341918793845 | validation: 0.06231688012635276]
	TIME [epoch: 6.41 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484309411894497		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.0484309411894497 | validation: 0.06398562418967411]
	TIME [epoch: 6.41 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047658129466454896		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.047658129466454896 | validation: 0.04905907692326027]
	TIME [epoch: 6.41 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047950347989460164		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.047950347989460164 | validation: 0.058675360887654744]
	TIME [epoch: 6.41 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566140776251458		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.04566140776251458 | validation: 0.05625998572730595]
	TIME [epoch: 6.41 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04169215225358526		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.04169215225358526 | validation: 0.05363998119891738]
	TIME [epoch: 6.42 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04474802777722818		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.04474802777722818 | validation: 0.05125659589802796]
	TIME [epoch: 6.43 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04746451560697973		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.04746451560697973 | validation: 0.06322348544715574]
	TIME [epoch: 6.41 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04545981326976614		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.04545981326976614 | validation: 0.059880797104316416]
	TIME [epoch: 6.41 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046396350539851895		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.046396350539851895 | validation: 0.057922038139645304]
	TIME [epoch: 6.4 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04883284898839671		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.04883284898839671 | validation: 0.056688683257828124]
	TIME [epoch: 6.4 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048136796557954956		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.048136796557954956 | validation: 0.06439247735371102]
	TIME [epoch: 6.4 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048361591152887975		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.048361591152887975 | validation: 0.053398216850586405]
	TIME [epoch: 6.4 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04496729802475173		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.04496729802475173 | validation: 0.055637841974663475]
	TIME [epoch: 6.43 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046936516794924124		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.046936516794924124 | validation: 0.055693624842697784]
	TIME [epoch: 6.4 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048549038342237366		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.048549038342237366 | validation: 0.05860523505198165]
	TIME [epoch: 6.4 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04757654776765328		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.04757654776765328 | validation: 0.05919962703527821]
	TIME [epoch: 6.4 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047903262477727665		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.047903262477727665 | validation: 0.05765130431702859]
	TIME [epoch: 6.4 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05085220951064095		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.05085220951064095 | validation: 0.055085646309485904]
	TIME [epoch: 6.4 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0485668425901061		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.0485668425901061 | validation: 0.06750471476449685]
	TIME [epoch: 6.41 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04836506363372779		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.04836506363372779 | validation: 0.05311182218137992]
	TIME [epoch: 6.44 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04555328220104293		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.04555328220104293 | validation: 0.06318397012596871]
	TIME [epoch: 6.41 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0508081763772397		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.0508081763772397 | validation: 0.06763790888861725]
	TIME [epoch: 6.41 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04576943277610222		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.04576943277610222 | validation: 0.05608186793799945]
	TIME [epoch: 6.41 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04867884206423704		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.04867884206423704 | validation: 0.05699760708123496]
	TIME [epoch: 6.41 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049122354906826544		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.049122354906826544 | validation: 0.06162283804575545]
	TIME [epoch: 6.41 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04915204925036737		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.04915204925036737 | validation: 0.06490255643070607]
	TIME [epoch: 6.41 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0450124223746969		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.0450124223746969 | validation: 0.05556346138030963]
	TIME [epoch: 6.45 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044238885092507244		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.044238885092507244 | validation: 0.056287225191081036]
	TIME [epoch: 6.42 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04526676724316013		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.04526676724316013 | validation: 0.05912527810571977]
	TIME [epoch: 6.42 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05160118943846307		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.05160118943846307 | validation: 0.06560028048267762]
	TIME [epoch: 6.41 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04994580716516531		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.04994580716516531 | validation: 0.05947458815002779]
	TIME [epoch: 6.41 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042721888112815506		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.042721888112815506 | validation: 0.06114358261588652]
	TIME [epoch: 6.41 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046848175168710385		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.046848175168710385 | validation: 0.05614999072086446]
	TIME [epoch: 6.41 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040200144505802435		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.040200144505802435 | validation: 0.05812343639022758]
	TIME [epoch: 6.43 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05013094952164479		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.05013094952164479 | validation: 0.06527456754440392]
	TIME [epoch: 6.43 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045839806456460415		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.045839806456460415 | validation: 0.06524333548777239]
	TIME [epoch: 6.41 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048628121137430466		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.048628121137430466 | validation: 0.05180762286808212]
	TIME [epoch: 6.41 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04710250480202874		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.04710250480202874 | validation: 0.06372914088331638]
	TIME [epoch: 6.41 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048591344455807345		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.048591344455807345 | validation: 0.05146419645153324]
	TIME [epoch: 6.41 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04775146348900257		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.04775146348900257 | validation: 0.05681975791411902]
	TIME [epoch: 6.41 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04786266165773643		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.04786266165773643 | validation: 0.05781621101550252]
	TIME [epoch: 6.43 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04742572843327885		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.04742572843327885 | validation: 0.05996007084387753]
	TIME [epoch: 6.43 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04687050453738867		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.04687050453738867 | validation: 0.06280432707741955]
	TIME [epoch: 6.41 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052076617906793354		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.052076617906793354 | validation: 0.055245531166775316]
	TIME [epoch: 6.41 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040520554760111224		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.040520554760111224 | validation: 0.052632889698068175]
	TIME [epoch: 6.41 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04876346301839246		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.04876346301839246 | validation: 0.06125556908480006]
	TIME [epoch: 6.41 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524206900117092		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.04524206900117092 | validation: 0.053905470763431114]
	TIME [epoch: 6.41 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0483154278601051		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.0483154278601051 | validation: 0.051084391849872735]
	TIME [epoch: 6.41 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048708018542483605		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.048708018542483605 | validation: 0.05366256750712738]
	TIME [epoch: 6.44 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549408321555326		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.04549408321555326 | validation: 0.06035884898166735]
	TIME [epoch: 6.41 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04853581778421252		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.04853581778421252 | validation: 0.05314935634463614]
	TIME [epoch: 6.41 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04757095725267425		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.04757095725267425 | validation: 0.06090457359536654]
	TIME [epoch: 6.41 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0479603138435543		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.0479603138435543 | validation: 0.05515623811682391]
	TIME [epoch: 6.41 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04761064033725356		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.04761064033725356 | validation: 0.058149683087042325]
	TIME [epoch: 6.41 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815736210791005		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.04815736210791005 | validation: 0.05526387038032178]
	TIME [epoch: 6.4 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044436752115286055		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.044436752115286055 | validation: 0.047088975858437604]
	TIME [epoch: 6.44 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04487129838801308		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.04487129838801308 | validation: 0.054721457718030775]
	TIME [epoch: 6.41 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04563143647915675		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.04563143647915675 | validation: 0.054153016882231356]
	TIME [epoch: 6.4 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04765676145592359		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.04765676145592359 | validation: 0.05970142737541432]
	TIME [epoch: 6.4 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04741419084631165		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.04741419084631165 | validation: 0.05517464923432111]
	TIME [epoch: 6.4 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04648975541620313		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.04648975541620313 | validation: 0.05994688416747112]
	TIME [epoch: 6.4 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045123048914331304		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.045123048914331304 | validation: 0.062323183401776054]
	TIME [epoch: 6.4 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04541618150720332		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.04541618150720332 | validation: 0.0564645879225864]
	TIME [epoch: 6.43 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045397779131840975		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.045397779131840975 | validation: 0.04952938949708141]
	TIME [epoch: 6.41 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04773873071396162		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.04773873071396162 | validation: 0.05409880812929837]
	TIME [epoch: 6.4 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04923039235700876		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.04923039235700876 | validation: 0.06096868763725976]
	TIME [epoch: 6.4 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050900572095068035		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.050900572095068035 | validation: 0.057514942915704206]
	TIME [epoch: 6.41 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04606110576117431		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.04606110576117431 | validation: 0.055554132026550365]
	TIME [epoch: 6.41 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452507824918683		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.0452507824918683 | validation: 0.05511869952213738]
	TIME [epoch: 6.41 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044185337888885345		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.044185337888885345 | validation: 0.05626612838303822]
	TIME [epoch: 6.43 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04381180426922414		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.04381180426922414 | validation: 0.05633821515873673]
	TIME [epoch: 6.41 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0460784516195373		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.0460784516195373 | validation: 0.05332419846104263]
	TIME [epoch: 6.41 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049992144597557		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.049992144597557 | validation: 0.061673921867757386]
	TIME [epoch: 6.4 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0445700878363865		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.0445700878363865 | validation: 0.061388288933590565]
	TIME [epoch: 6.41 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04460805179513058		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.04460805179513058 | validation: 0.059237182302362454]
	TIME [epoch: 6.41 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04729595408579245		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.04729595408579245 | validation: 0.05687329661738332]
	TIME [epoch: 6.4 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04599048782261356		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.04599048782261356 | validation: 0.051998524654788846]
	TIME [epoch: 6.42 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047689471135457566		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.047689471135457566 | validation: 0.058254544633850616]
	TIME [epoch: 6.42 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04951432633880078		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.04951432633880078 | validation: 0.056124313401352044]
	TIME [epoch: 6.41 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0456661892906217		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.0456661892906217 | validation: 0.059737574493234094]
	TIME [epoch: 6.41 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048051464299396995		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.048051464299396995 | validation: 0.05645604969912125]
	TIME [epoch: 6.4 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04922650853063813		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.04922650853063813 | validation: 0.055628987201677325]
	TIME [epoch: 6.4 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04737644961980568		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.04737644961980568 | validation: 0.0553488998256848]
	TIME [epoch: 6.41 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049007687204644164		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.049007687204644164 | validation: 0.053448531729922436]
	TIME [epoch: 6.41 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047495972247948305		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.047495972247948305 | validation: 0.06219352977079067]
	TIME [epoch: 6.43 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047140785823374325		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.047140785823374325 | validation: 0.05376061122547489]
	TIME [epoch: 6.41 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04645655386066335		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.04645655386066335 | validation: 0.059429000905161504]
	TIME [epoch: 6.41 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04841757112778648		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.04841757112778648 | validation: 0.05883826620154155]
	TIME [epoch: 6.4 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04879818891897236		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.04879818891897236 | validation: 0.05938563135119714]
	TIME [epoch: 6.41 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04889651337109556		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.04889651337109556 | validation: 0.04939699291621286]
	TIME [epoch: 6.41 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04897999177021868		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.04897999177021868 | validation: 0.05544013613184172]
	TIME [epoch: 6.41 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048842986299389615		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.048842986299389615 | validation: 0.05706514524532711]
	TIME [epoch: 6.44 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047824494230119266		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.047824494230119266 | validation: 0.05825171539711177]
	TIME [epoch: 6.41 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04684467895308667		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.04684467895308667 | validation: 0.05027956500010606]
	TIME [epoch: 6.41 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04811502723524337		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.04811502723524337 | validation: 0.05516505111788546]
	TIME [epoch: 6.41 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0468727063024871		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.0468727063024871 | validation: 0.05108922851439744]
	TIME [epoch: 6.4 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04670492256236576		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.04670492256236576 | validation: 0.057525223969794766]
	TIME [epoch: 6.4 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04543538651611263		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.04543538651611263 | validation: 0.06064741930133576]
	TIME [epoch: 6.41 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04813635907222446		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.04813635907222446 | validation: 0.05602787858313535]
	TIME [epoch: 6.44 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043978358701050775		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.043978358701050775 | validation: 0.059753010289213426]
	TIME [epoch: 6.4 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047394506406537265		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.047394506406537265 | validation: 0.061449536269417626]
	TIME [epoch: 6.4 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04556448976021303		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.04556448976021303 | validation: 0.06004624958532064]
	TIME [epoch: 6.4 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047832580013352055		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.047832580013352055 | validation: 0.05526242174678285]
	TIME [epoch: 6.4 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04480770541072686		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.04480770541072686 | validation: 0.06015555615806479]
	TIME [epoch: 6.4 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04726945996781702		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.04726945996781702 | validation: 0.05817084127765659]
	TIME [epoch: 6.4 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042832817219324366		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.042832817219324366 | validation: 0.05096107621212798]
	TIME [epoch: 6.43 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484462930350134		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.0484462930350134 | validation: 0.05714461520927992]
	TIME [epoch: 6.4 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04647945123866769		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.04647945123866769 | validation: 0.05358189172261251]
	TIME [epoch: 6.4 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04402036013108475		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.04402036013108475 | validation: 0.05498493729066428]
	TIME [epoch: 6.4 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047927274252902656		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.047927274252902656 | validation: 0.051061428293753375]
	TIME [epoch: 6.4 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044155794502737024		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.044155794502737024 | validation: 0.061323560184892115]
	TIME [epoch: 6.4 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04619261796479143		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.04619261796479143 | validation: 0.05509462705628545]
	TIME [epoch: 6.4 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0465799824982955		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.0465799824982955 | validation: 0.05849647975875422]
	TIME [epoch: 6.42 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04386586633255053		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.04386586633255053 | validation: 0.050352194909852016]
	TIME [epoch: 6.42 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04718459197298238		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.04718459197298238 | validation: 0.05268127568224391]
	TIME [epoch: 6.4 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04509098790292736		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.04509098790292736 | validation: 0.0582272394804827]
	TIME [epoch: 6.4 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0466582240456138		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.0466582240456138 | validation: 0.06058600381236157]
	TIME [epoch: 6.4 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047061054135295384		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.047061054135295384 | validation: 0.04816698980788742]
	TIME [epoch: 6.41 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04585640617865854		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.04585640617865854 | validation: 0.06706753073042813]
	TIME [epoch: 6.41 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046195510489047256		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.046195510489047256 | validation: 0.059661395017401794]
	TIME [epoch: 6.43 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04702939539132893		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.04702939539132893 | validation: 0.05694711740914608]
	TIME [epoch: 6.44 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733751098155625		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.04733751098155625 | validation: 0.051208194207500925]
	TIME [epoch: 6.42 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04429065012167009		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.04429065012167009 | validation: 0.056672684550940815]
	TIME [epoch: 6.42 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04724198889385519		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.04724198889385519 | validation: 0.0504918696359254]
	TIME [epoch: 6.42 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04595945030026185		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.04595945030026185 | validation: 0.06418756369240451]
	TIME [epoch: 6.42 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048577728994781216		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.048577728994781216 | validation: 0.05644396859759532]
	TIME [epoch: 6.41 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045113428729592994		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.045113428729592994 | validation: 0.05790795886972016]
	TIME [epoch: 6.42 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043539940604423746		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.043539940604423746 | validation: 0.05289431826413634]
	TIME [epoch: 6.45 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048270243885981876		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.048270243885981876 | validation: 0.06967196111433421]
	TIME [epoch: 6.42 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04637148198426542		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.04637148198426542 | validation: 0.059519905240854314]
	TIME [epoch: 6.42 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04579258046329761		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.04579258046329761 | validation: 0.056914744847378414]
	TIME [epoch: 6.41 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047085103566004816		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.047085103566004816 | validation: 0.057336820122359335]
	TIME [epoch: 6.41 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04572413837271169		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.04572413837271169 | validation: 0.06558340871730503]
	TIME [epoch: 6.41 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04882338863420772		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.04882338863420772 | validation: 0.05558700531097328]
	TIME [epoch: 6.42 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048727482377063154		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.048727482377063154 | validation: 0.05280581226324764]
	TIME [epoch: 6.45 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04379804199389947		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.04379804199389947 | validation: 0.051208123259489424]
	TIME [epoch: 6.42 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046283425837788064		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.046283425837788064 | validation: 0.05968522924448808]
	TIME [epoch: 6.41 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04664016562878634		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.04664016562878634 | validation: 0.06082991269802575]
	TIME [epoch: 6.41 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04563448190464571		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.04563448190464571 | validation: 0.06600521631626217]
	TIME [epoch: 6.41 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04715295270633098		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.04715295270633098 | validation: 0.05321195619616478]
	TIME [epoch: 6.41 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046430166016034446		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.046430166016034446 | validation: 0.05938099547671108]
	TIME [epoch: 6.41 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048863903708338124		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.048863903708338124 | validation: 0.047066389929400404]
	TIME [epoch: 6.44 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04760124262176245		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.04760124262176245 | validation: 0.05730714804129608]
	TIME [epoch: 6.41 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04748592337120707		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.04748592337120707 | validation: 0.05451462796111652]
	TIME [epoch: 6.41 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04726595509283072		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.04726595509283072 | validation: 0.05160981942455617]
	TIME [epoch: 6.41 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0468148903034017		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.0468148903034017 | validation: 0.0628867475544352]
	TIME [epoch: 6.41 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858196529550747		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.04858196529550747 | validation: 0.05949569241476809]
	TIME [epoch: 6.41 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04403981320090341		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.04403981320090341 | validation: 0.05152019322605133]
	TIME [epoch: 6.41 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048238110230387		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.048238110230387 | validation: 0.051412792631171184]
	TIME [epoch: 6.44 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04499295331676674		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.04499295331676674 | validation: 0.05365503300991451]
	TIME [epoch: 6.41 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047097343338248596		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.047097343338248596 | validation: 0.057846352937313494]
	TIME [epoch: 6.4 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04655194855391619		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.04655194855391619 | validation: 0.05039545250485565]
	TIME [epoch: 6.41 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04161262526859563		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.04161262526859563 | validation: 0.051658193327846165]
	TIME [epoch: 6.4 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04550203211044081		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.04550203211044081 | validation: 0.05436097099843973]
	TIME [epoch: 6.4 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04758047373228823		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.04758047373228823 | validation: 0.05393292231948653]
	TIME [epoch: 6.4 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04485434187206824		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.04485434187206824 | validation: 0.052063992600429466]
	TIME [epoch: 6.42 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043064895621007696		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.043064895621007696 | validation: 0.056733249025039977]
	TIME [epoch: 6.43 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044373072927726624		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.044373072927726624 | validation: 0.054742144377491975]
	TIME [epoch: 6.4 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04279726075197118		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.04279726075197118 | validation: 0.06302673021086375]
	TIME [epoch: 6.4 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0438738031023349		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.0438738031023349 | validation: 0.05272055434740656]
	TIME [epoch: 6.4 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04592663632814924		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.04592663632814924 | validation: 0.06230872409406631]
	TIME [epoch: 6.4 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04454785620109991		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.04454785620109991 | validation: 0.05686699893444112]
	TIME [epoch: 6.41 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04830725519234643		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.04830725519234643 | validation: 0.059039538587441404]
	TIME [epoch: 6.42 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04678231147565098		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.04678231147565098 | validation: 0.05794249871627173]
	TIME [epoch: 6.42 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048232056903644335		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.048232056903644335 | validation: 0.049300357263652235]
	TIME [epoch: 6.4 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04769523125349232		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.04769523125349232 | validation: 0.06446073280566542]
	TIME [epoch: 6.4 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04622343438499856		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.04622343438499856 | validation: 0.04421737250402738]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_1745.pth
	Model improved!!!
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047606628116262435		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.047606628116262435 | validation: 0.048553928785603]
	TIME [epoch: 6.4 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048330344706236504		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.048330344706236504 | validation: 0.057519832195455346]
	TIME [epoch: 6.4 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04455956493558188		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.04455956493558188 | validation: 0.061360812954386806]
	TIME [epoch: 6.4 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043325520301551845		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.043325520301551845 | validation: 0.05843533668257123]
	TIME [epoch: 6.43 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04980828332203273		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.04980828332203273 | validation: 0.05901759737979882]
	TIME [epoch: 6.4 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0449283475366908		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.0449283475366908 | validation: 0.06032356555603899]
	TIME [epoch: 6.4 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04472378863722358		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.04472378863722358 | validation: 0.051700734367807526]
	TIME [epoch: 6.4 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04793645548932312		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.04793645548932312 | validation: 0.06269471732238863]
	TIME [epoch: 6.4 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049990763386955336		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.049990763386955336 | validation: 0.05134306085609163]
	TIME [epoch: 6.4 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04337508695459966		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.04337508695459966 | validation: 0.06029363168080829]
	TIME [epoch: 6.4 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047322323909638794		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.047322323909638794 | validation: 0.05800281184792018]
	TIME [epoch: 6.44 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0440393989874073		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.0440393989874073 | validation: 0.058224688219570025]
	TIME [epoch: 6.4 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04545462124962932		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.04545462124962932 | validation: 0.05833481565407783]
	TIME [epoch: 6.4 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051983378196296004		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.051983378196296004 | validation: 0.06512289726392854]
	TIME [epoch: 6.41 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04771650969689418		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.04771650969689418 | validation: 0.06041102063786426]
	TIME [epoch: 6.41 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04849508459518667		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.04849508459518667 | validation: 0.05627316702081829]
	TIME [epoch: 6.41 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566721883644506		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.04566721883644506 | validation: 0.05350568629204494]
	TIME [epoch: 6.41 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047996164318342596		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.047996164318342596 | validation: 0.06079649811419365]
	TIME [epoch: 6.45 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0450170015863202		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.0450170015863202 | validation: 0.05547767152688422]
	TIME [epoch: 6.41 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487453075775542		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.0487453075775542 | validation: 0.04823552818675386]
	TIME [epoch: 6.41 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05093910856677032		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.05093910856677032 | validation: 0.06707555221998597]
	TIME [epoch: 6.41 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04596753111695485		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.04596753111695485 | validation: 0.06324575660376634]
	TIME [epoch: 6.41 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05073025640031614		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.05073025640031614 | validation: 0.05943795948215619]
	TIME [epoch: 6.41 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04977632322612053		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.04977632322612053 | validation: 0.05900772103851823]
	TIME [epoch: 6.42 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04667169052634685		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.04667169052634685 | validation: 0.05335675697933409]
	TIME [epoch: 6.45 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04791180027860677		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.04791180027860677 | validation: 0.054612256296299774]
	TIME [epoch: 6.42 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04662682451999839		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.04662682451999839 | validation: 0.06005270876669256]
	TIME [epoch: 6.41 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04569109164525673		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.04569109164525673 | validation: 0.06448032767015975]
	TIME [epoch: 6.42 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0505441066284842		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.0505441066284842 | validation: 0.054602000845238995]
	TIME [epoch: 6.42 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04851425610174877		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.04851425610174877 | validation: 0.04947635121466698]
	TIME [epoch: 6.42 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046921420073905026		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.046921420073905026 | validation: 0.06581351385229944]
	TIME [epoch: 6.42 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0521171120083681		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.0521171120083681 | validation: 0.05645360637854915]
	TIME [epoch: 6.43 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05207181900894207		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.05207181900894207 | validation: 0.06136244132397087]
	TIME [epoch: 6.43 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05074581542963204		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.05074581542963204 | validation: 0.06325833134771582]
	TIME [epoch: 6.41 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04854269501902523		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.04854269501902523 | validation: 0.05572911918009361]
	TIME [epoch: 6.41 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05035559999954117		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.05035559999954117 | validation: 0.0578183437130777]
	TIME [epoch: 6.41 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04822313441422153		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.04822313441422153 | validation: 0.0637710329656975]
	TIME [epoch: 6.41 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049824640441898105		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.049824640441898105 | validation: 0.061654444197593646]
	TIME [epoch: 6.41 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051944770308961746		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.051944770308961746 | validation: 0.056684673877946706]
	TIME [epoch: 6.43 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04829083746378496		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.04829083746378496 | validation: 0.060784322138989766]
	TIME [epoch: 6.43 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04720029774198662		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.04720029774198662 | validation: 0.05596480994618915]
	TIME [epoch: 6.42 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046660263719305366		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.046660263719305366 | validation: 0.058228467703058916]
	TIME [epoch: 6.42 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04773195510248654		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.04773195510248654 | validation: 0.05429425245361083]
	TIME [epoch: 6.42 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04739176571361069		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.04739176571361069 | validation: 0.05854025213314589]
	TIME [epoch: 6.42 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0496037929657989		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.0496037929657989 | validation: 0.0544261255925747]
	TIME [epoch: 6.42 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04983731958857668		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.04983731958857668 | validation: 0.060268380773119114]
	TIME [epoch: 6.42 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04626837624098342		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.04626837624098342 | validation: 0.05544058587046406]
	TIME [epoch: 6.45 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0486138447809359		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.0486138447809359 | validation: 0.0532734650313801]
	TIME [epoch: 6.42 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04670472164166682		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.04670472164166682 | validation: 0.06537268461873842]
	TIME [epoch: 6.42 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04589056373271261		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.04589056373271261 | validation: 0.055036437857407354]
	TIME [epoch: 6.41 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045289381936824774		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.045289381936824774 | validation: 0.053155723923838806]
	TIME [epoch: 6.41 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858480731975965		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.04858480731975965 | validation: 0.059810269344384784]
	TIME [epoch: 6.41 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04406475584685766		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.04406475584685766 | validation: 0.07525577561802399]
	TIME [epoch: 6.42 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04709567832774579		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.04709567832774579 | validation: 0.055830273257728415]
	TIME [epoch: 6.44 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04610890346052609		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.04610890346052609 | validation: 0.054498030967793]
	TIME [epoch: 6.42 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0447866711147512		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.0447866711147512 | validation: 0.06135715890553181]
	TIME [epoch: 6.41 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04543995113461775		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.04543995113461775 | validation: 0.05702477505925054]
	TIME [epoch: 6.41 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04683603239802833		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.04683603239802833 | validation: 0.0613803911927044]
	TIME [epoch: 6.41 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04303768275639548		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.04303768275639548 | validation: 0.05372409772007993]
	TIME [epoch: 6.41 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04368676130558852		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.04368676130558852 | validation: 0.05313814965539577]
	TIME [epoch: 6.42 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04437793456819357		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.04437793456819357 | validation: 0.05486013752745837]
	TIME [epoch: 6.45 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04586184191642613		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.04586184191642613 | validation: 0.057424255860178304]
	TIME [epoch: 6.41 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04648842979008908		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.04648842979008908 | validation: 0.063014112577917]
	TIME [epoch: 6.41 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04509393593815555		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.04509393593815555 | validation: 0.06496550131903424]
	TIME [epoch: 6.42 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047644938820891825		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.047644938820891825 | validation: 0.05733613462842556]
	TIME [epoch: 6.41 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04725376454017002		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.04725376454017002 | validation: 0.05197616162450945]
	TIME [epoch: 6.41 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04364976800344172		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.04364976800344172 | validation: 0.05713255865960651]
	TIME [epoch: 6.41 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045516334786080484		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.045516334786080484 | validation: 0.05119922934953863]
	TIME [epoch: 6.45 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04525870736602356		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.04525870736602356 | validation: 0.062122708397267475]
	TIME [epoch: 6.42 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046221792526678816		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.046221792526678816 | validation: 0.062087358215981665]
	TIME [epoch: 6.41 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043845278816974614		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.043845278816974614 | validation: 0.05236833180166125]
	TIME [epoch: 6.41 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044851887207486826		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.044851887207486826 | validation: 0.06145515520044427]
	TIME [epoch: 6.41 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04607378817311354		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.04607378817311354 | validation: 0.051065337819968325]
	TIME [epoch: 6.42 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0446708845835173		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.0446708845835173 | validation: 0.054748327054067056]
	TIME [epoch: 6.41 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04895415901937386		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.04895415901937386 | validation: 0.055856741635897114]
	TIME [epoch: 6.44 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04859770063281028		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.04859770063281028 | validation: 0.0630131331120686]
	TIME [epoch: 6.43 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04783160750757697		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.04783160750757697 | validation: 0.05202684170068533]
	TIME [epoch: 6.41 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044357177381536564		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.044357177381536564 | validation: 0.056914170334548306]
	TIME [epoch: 6.41 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590312997950575		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.04590312997950575 | validation: 0.061796254567732925]
	TIME [epoch: 6.41 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04484736992349979		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.04484736992349979 | validation: 0.0573134332280528]
	TIME [epoch: 6.41 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04593291409967065		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.04593291409967065 | validation: 0.0571330621619382]
	TIME [epoch: 6.41 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04726828332558991		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.04726828332558991 | validation: 0.05396528526922718]
	TIME [epoch: 6.43 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04755003526233409		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.04755003526233409 | validation: 0.06051104676004848]
	TIME [epoch: 6.43 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048631170965588374		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.048631170965588374 | validation: 0.058498099730847776]
	TIME [epoch: 6.42 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049768739730630424		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.049768739730630424 | validation: 0.04997589216008506]
	TIME [epoch: 6.41 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045914962902433534		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.045914962902433534 | validation: 0.06315735599282597]
	TIME [epoch: 6.41 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047729265202242535		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.047729265202242535 | validation: 0.0619833327131445]
	TIME [epoch: 6.41 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04774316434311908		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.04774316434311908 | validation: 0.054086374393344946]
	TIME [epoch: 6.41 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04769079833897444		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.04769079833897444 | validation: 0.0558148201946706]
	TIME [epoch: 6.42 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04476278960559897		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.04476278960559897 | validation: 0.05474673299168009]
	TIME [epoch: 6.44 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04931520555808065		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.04931520555808065 | validation: 0.053235776450171496]
	TIME [epoch: 6.41 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04531633016540496		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.04531633016540496 | validation: 0.060141837011578075]
	TIME [epoch: 6.41 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04485621998800811		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.04485621998800811 | validation: 0.060130884044253013]
	TIME [epoch: 6.41 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046087345483349244		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.046087345483349244 | validation: 0.05382119087798735]
	TIME [epoch: 6.41 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048103997916259716		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.048103997916259716 | validation: 0.05527050090963874]
	TIME [epoch: 6.42 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04837932390805668		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.04837932390805668 | validation: 0.05679692220067114]
	TIME [epoch: 6.42 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04558061482230148		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.04558061482230148 | validation: 0.05428864648521833]
	TIME [epoch: 6.44 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04462831602862212		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.04462831602862212 | validation: 0.05880375286505931]
	TIME [epoch: 6.41 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04777562004941269		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.04777562004941269 | validation: 0.05254447162638759]
	TIME [epoch: 6.41 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04492430845096371		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.04492430845096371 | validation: 0.06034258166136342]
	TIME [epoch: 6.41 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04726498601992146		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.04726498601992146 | validation: 0.05587498618238129]
	TIME [epoch: 6.41 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04869833342539873		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.04869833342539873 | validation: 0.05831458847461088]
	TIME [epoch: 6.42 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04461693962004171		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.04461693962004171 | validation: 0.05694618532158667]
	TIME [epoch: 6.41 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524211218697263		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.04524211218697263 | validation: 0.05335691721151866]
	TIME [epoch: 6.45 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046117393963903505		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.046117393963903505 | validation: 0.05444390643523512]
	TIME [epoch: 6.42 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04434006813878535		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.04434006813878535 | validation: 0.05185342709070702]
	TIME [epoch: 6.42 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04781143558405105		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.04781143558405105 | validation: 0.05878990308924733]
	TIME [epoch: 6.41 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04403700759865932		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.04403700759865932 | validation: 0.06122888850118426]
	TIME [epoch: 6.42 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047308102944677		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.047308102944677 | validation: 0.055572967827292166]
	TIME [epoch: 6.42 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048032671346270026		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.048032671346270026 | validation: 0.059560379532011515]
	TIME [epoch: 6.42 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04709937393339332		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.04709937393339332 | validation: 0.06230355646327101]
	TIME [epoch: 6.44 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04580508735473948		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.04580508735473948 | validation: 0.061364228331585426]
	TIME [epoch: 6.42 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04493177643008485		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.04493177643008485 | validation: 0.05150967671928815]
	TIME [epoch: 6.41 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04632320689966793		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.04632320689966793 | validation: 0.053288112859958194]
	TIME [epoch: 6.42 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04699129390625813		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.04699129390625813 | validation: 0.059189254293853695]
	TIME [epoch: 6.41 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04419816012934687		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.04419816012934687 | validation: 0.057021340667763244]
	TIME [epoch: 6.41 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04796340121156118		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.04796340121156118 | validation: 0.061711250471359363]
	TIME [epoch: 6.41 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0491728415898781		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.0491728415898781 | validation: 0.057296966787986695]
	TIME [epoch: 6.43 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04568562690895923		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.04568562690895923 | validation: 0.05780860044001962]
	TIME [epoch: 6.43 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0454563483946573		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.0454563483946573 | validation: 0.05270263266019356]
	TIME [epoch: 6.42 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04726735778687033		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.04726735778687033 | validation: 0.05908893056629172]
	TIME [epoch: 6.41 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044739248907103145		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.044739248907103145 | validation: 0.052741057846344114]
	TIME [epoch: 6.42 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043630000507468694		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.043630000507468694 | validation: 0.05908951953100383]
	TIME [epoch: 6.42 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04530094107079776		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.04530094107079776 | validation: 0.05816124500736147]
	TIME [epoch: 6.42 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04822512377431611		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.04822512377431611 | validation: 0.05513254002223475]
	TIME [epoch: 6.44 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045252665166483394		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.045252665166483394 | validation: 0.04950560485146866]
	TIME [epoch: 6.44 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04728119814179463		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.04728119814179463 | validation: 0.05994130685806485]
	TIME [epoch: 6.42 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042362973605528154		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.042362973605528154 | validation: 0.052061107838727846]
	TIME [epoch: 6.41 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05006857025605175		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.05006857025605175 | validation: 0.043788883820871795]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r0_20240309_135628/states/model_tr_study2_1874.pth
	Model improved!!!
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04953411745604638		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.04953411745604638 | validation: 0.055718109439093395]
	TIME [epoch: 6.41 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04554779368758009		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.04554779368758009 | validation: 0.05891729358274876]
	TIME [epoch: 6.41 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04769305278658296		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.04769305278658296 | validation: 0.05246790962094563]
	TIME [epoch: 6.43 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04626965465457824		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.04626965465457824 | validation: 0.06774279754050044]
	TIME [epoch: 6.43 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0470914705790979		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.0470914705790979 | validation: 0.05148359923333512]
	TIME [epoch: 6.41 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04376410726668753		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.04376410726668753 | validation: 0.05590069923997504]
	TIME [epoch: 6.41 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04758097199215403		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.04758097199215403 | validation: 0.05849415561515304]
	TIME [epoch: 6.41 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04477898761001653		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.04477898761001653 | validation: 0.05470144107292385]
	TIME [epoch: 6.41 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04791907973472574		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.04791907973472574 | validation: 0.05289398544721714]
	TIME [epoch: 6.41 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04207443173784201		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.04207443173784201 | validation: 0.0621382122381081]
	TIME [epoch: 6.42 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04327802961768648		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.04327802961768648 | validation: 0.05565180408542727]
	TIME [epoch: 6.44 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04845920967104333		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.04845920967104333 | validation: 0.054624476532969556]
	TIME [epoch: 6.41 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04825056650935099		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.04825056650935099 | validation: 0.055077379847170926]
	TIME [epoch: 6.41 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047443952981207106		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.047443952981207106 | validation: 0.06175394346979754]
	TIME [epoch: 6.41 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051706418270367795		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.051706418270367795 | validation: 0.057411668615894494]
	TIME [epoch: 6.41 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524799930513095		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.04524799930513095 | validation: 0.051545083335943785]
	TIME [epoch: 6.41 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04482679038181012		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.04482679038181012 | validation: 0.05266468427722609]
	TIME [epoch: 6.41 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045850003589697694		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.045850003589697694 | validation: 0.057600282189198264]
	TIME [epoch: 6.45 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04661076862393594		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.04661076862393594 | validation: 0.05285764553142127]
	TIME [epoch: 6.42 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046481666285836956		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.046481666285836956 | validation: 0.05284689208826426]
	TIME [epoch: 6.41 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04703762346102702		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.04703762346102702 | validation: 0.057366528177947906]
	TIME [epoch: 6.41 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045684679885093823		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.045684679885093823 | validation: 0.05604861088957753]
	TIME [epoch: 6.41 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05120736203770843		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.05120736203770843 | validation: 0.05666706623548131]
	TIME [epoch: 6.42 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047367319137261735		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.047367319137261735 | validation: 0.052708747942171]
	TIME [epoch: 6.41 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044496588086138364		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.044496588086138364 | validation: 0.058705374688467885]
	TIME [epoch: 6.45 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04693885559364661		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.04693885559364661 | validation: 0.04819214282147847]
	TIME [epoch: 6.42 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04762450350521065		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.04762450350521065 | validation: 0.05173434989289332]
	TIME [epoch: 6.41 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04912483798817188		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.04912483798817188 | validation: 0.06029405139696129]
	TIME [epoch: 6.41 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046631104093599655		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.046631104093599655 | validation: 0.0614120834503331]
	TIME [epoch: 6.42 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04294618722261348		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.04294618722261348 | validation: 0.049995943521423065]
	TIME [epoch: 6.42 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04236940407576835		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.04236940407576835 | validation: 0.050134004075350944]
	TIME [epoch: 6.42 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04657687201045682		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.04657687201045682 | validation: 0.0516068496956034]
	TIME [epoch: 6.45 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0455845296391258		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.0455845296391258 | validation: 0.052445955667368496]
	TIME [epoch: 6.42 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04307448306265061		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.04307448306265061 | validation: 0.05688917050221976]
	TIME [epoch: 6.42 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048126975750648074		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.048126975750648074 | validation: 0.06133839298806366]
	TIME [epoch: 6.41 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04727478799804889		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.04727478799804889 | validation: 0.056224870282128275]
	TIME [epoch: 6.41 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04746088342314386		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.04746088342314386 | validation: 0.0587440640899423]
	TIME [epoch: 6.41 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04484601098501369		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.04484601098501369 | validation: 0.05228343540452054]
	TIME [epoch: 6.41 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044589781628957076		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.044589781628957076 | validation: 0.05803260723189343]
	TIME [epoch: 6.43 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04896165804523979		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.04896165804523979 | validation: 0.06151127207257746]
	TIME [epoch: 6.43 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04284633779430591		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.04284633779430591 | validation: 0.05481279596228493]
	TIME [epoch: 6.42 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04505584725576341		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.04505584725576341 | validation: 0.060780708831194206]
	TIME [epoch: 6.41 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04554550474257353		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.04554550474257353 | validation: 0.06122781517625121]
	TIME [epoch: 6.42 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048375256018720364		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.048375256018720364 | validation: 0.05814824451756356]
	TIME [epoch: 6.41 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04431224225629088		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.04431224225629088 | validation: 0.05754032721537743]
	TIME [epoch: 6.42 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04617071056641343		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.04617071056641343 | validation: 0.05121398497454734]
	TIME [epoch: 6.43 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04351972107724662		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.04351972107724662 | validation: 0.060178401528080454]
	TIME [epoch: 6.43 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0447848522907727		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.0447848522907727 | validation: 0.04952206607691192]
	TIME [epoch: 6.42 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04570241447258086		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.04570241447258086 | validation: 0.0522717284140625]
	TIME [epoch: 6.41 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044959428472206235		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.044959428472206235 | validation: 0.05379765048948475]
	TIME [epoch: 6.41 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04535909410968142		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.04535909410968142 | validation: 0.05548962492788542]
	TIME [epoch: 6.42 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04608302236300438		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.04608302236300438 | validation: 0.05218719902108233]
	TIME [epoch: 6.41 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043990457532283304		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.043990457532283304 | validation: 0.05341079251028395]
	TIME [epoch: 6.42 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048067095725251974		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.048067095725251974 | validation: 0.0619265804951797]
	TIME [epoch: 6.45 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04829871328609801		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.04829871328609801 | validation: 0.053290710502896604]
	TIME [epoch: 6.42 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04637929049343906		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.04637929049343906 | validation: 0.05284858886575032]
	TIME [epoch: 6.41 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051280064445824156		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.051280064445824156 | validation: 0.060375217791257936]
	TIME [epoch: 6.42 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04356963909255322		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.04356963909255322 | validation: 0.058607343901154386]
	TIME [epoch: 6.41 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590168131152435		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.04590168131152435 | validation: 0.05334770118511421]
	TIME [epoch: 6.41 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045173379071146186		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.045173379071146186 | validation: 0.05915260581160941]
	TIME [epoch: 6.41 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04582560008598811		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.04582560008598811 | validation: 0.05529944600713126]
	TIME [epoch: 6.44 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045621539564540604		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.045621539564540604 | validation: 0.04561674740365934]
	TIME [epoch: 6.42 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04414459559579034		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.04414459559579034 | validation: 0.058140204106483254]
	TIME [epoch: 6.41 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044558934383250356		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.044558934383250356 | validation: 0.06330273530139711]
	TIME [epoch: 6.41 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04680413930990933		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.04680413930990933 | validation: 0.06543593909386207]
	TIME [epoch: 6.42 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04424234176020871		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.04424234176020871 | validation: 0.05865642682116254]
	TIME [epoch: 6.41 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04737789489385175		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.04737789489385175 | validation: 0.06282501340046281]
	TIME [epoch: 6.41 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04546280902287237		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.04546280902287237 | validation: 0.056177844636817194]
	TIME [epoch: 6.45 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347207093863161		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.04347207093863161 | validation: 0.05178013425110329]
	TIME [epoch: 6.41 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04580423522286322		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.04580423522286322 | validation: 0.06001684447822992]
	TIME [epoch: 6.41 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042782528248244814		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.042782528248244814 | validation: 0.05831581457063471]
	TIME [epoch: 6.41 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045707451785724294		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.045707451785724294 | validation: 0.05606659943290561]
	TIME [epoch: 6.41 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04784055160257271		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.04784055160257271 | validation: 0.05759626040187622]
	TIME [epoch: 6.41 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047966761420574336		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.047966761420574336 | validation: 0.058305803326901114]
	TIME [epoch: 6.41 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043160240896621176		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.043160240896621176 | validation: 0.0613679260354375]
	TIME [epoch: 6.44 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04519251886555554		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.04519251886555554 | validation: 0.05676982504689377]
	TIME [epoch: 6.42 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0463109340054981		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.0463109340054981 | validation: 0.051975315872337564]
	TIME [epoch: 6.41 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414330482597726		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.0414330482597726 | validation: 0.05219077693086718]
	TIME [epoch: 6.41 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04502856437360873		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.04502856437360873 | validation: 0.051695062375770054]
	TIME [epoch: 6.42 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731195956599008		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.04731195956599008 | validation: 0.059667819675505135]
	TIME [epoch: 6.42 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047588274891574675		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.047588274891574675 | validation: 0.0568957088532202]
	TIME [epoch: 6.42 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04506410538161106		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.04506410538161106 | validation: 0.058052983648131974]
	TIME [epoch: 6.43 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04771653275790724		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.04771653275790724 | validation: 0.06436467621555339]
	TIME [epoch: 6.43 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04436646255213253		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.04436646255213253 | validation: 0.05879856942784331]
	TIME [epoch: 6.42 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043517134957524996		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.043517134957524996 | validation: 0.05770011137330215]
	TIME [epoch: 6.42 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046431176345142225		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.046431176345142225 | validation: 0.05239280370053582]
	TIME [epoch: 6.41 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309459330730819		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.04309459330730819 | validation: 0.054555095386172925]
	TIME [epoch: 6.41 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04372908836434927		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.04372908836434927 | validation: 0.06005908821643233]
	TIME [epoch: 6.41 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04562534641502929		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.04562534641502929 | validation: 0.05388370011158699]
	TIME [epoch: 6.43 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04509464855704459		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.04509464855704459 | validation: 0.05499174016282289]
	TIME [epoch: 6.43 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045701568441954464		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.045701568441954464 | validation: 0.055146215360536745]
	TIME [epoch: 6.42 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05050258970199502		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.05050258970199502 | validation: 0.05568304820760215]
	TIME [epoch: 6.41 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04207891729228174		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.04207891729228174 | validation: 0.05467324994349351]
	TIME [epoch: 6.41 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0436589661937857		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.0436589661937857 | validation: 0.057254254360240855]
	TIME [epoch: 6.42 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04730761677088485		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.04730761677088485 | validation: 0.05654410285223858]
	TIME [epoch: 6.42 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044051998264918714		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.044051998264918714 | validation: 0.05848705905601444]
	TIME [epoch: 6.42 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04761028651611687		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.04761028651611687 | validation: 0.05675597050870348]
	TIME [epoch: 6.45 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04431200210221432		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.04431200210221432 | validation: 0.06549487118636374]
	TIME [epoch: 6.42 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045909874246797926		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.045909874246797926 | validation: 0.06212745022130619]
	TIME [epoch: 6.42 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04256448196834614		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.04256448196834614 | validation: 0.05221680662028427]
	TIME [epoch: 6.41 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0457444763316639		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.0457444763316639 | validation: 0.0577706155028779]
	TIME [epoch: 6.42 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04639380122059073		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.04639380122059073 | validation: 0.05828159008379061]
	TIME [epoch: 6.41 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04399204938377589		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.04399204938377589 | validation: 0.057028216952008215]
	TIME [epoch: 6.42 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04789238904388151		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.04789238904388151 | validation: 0.05509387578782865]
	TIME [epoch: 6.44 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04823369487632008		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.04823369487632008 | validation: 0.05683885760298857]
	TIME [epoch: 6.42 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04721058379490367		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.04721058379490367 | validation: 0.061389091754534324]
	TIME [epoch: 6.42 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04675939691866014		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.04675939691866014 | validation: 0.058793835556441874]
	TIME [epoch: 6.41 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045002396478228915		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.045002396478228915 | validation: 0.049582213582116966]
	TIME [epoch: 6.42 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047696335330690655		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.047696335330690655 | validation: 0.05711253843372889]
	TIME [epoch: 6.42 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04695276089976337		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.04695276089976337 | validation: 0.060136310869787706]
	TIME [epoch: 6.42 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04682453842102383		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.04682453842102383 | validation: 0.05922053429409374]
	TIME [epoch: 6.45 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347825880218892		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.04347825880218892 | validation: 0.058954959432984996]
	TIME [epoch: 6.42 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04746021515346559		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.04746021515346559 | validation: 0.06121140449795718]
	TIME [epoch: 6.42 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044929975238676485		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.044929975238676485 | validation: 0.05596009908597642]
	TIME [epoch: 6.41 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044668158050166634		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.044668158050166634 | validation: 0.05507483981641853]
	TIME [epoch: 6.42 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048304148138054226		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.048304148138054226 | validation: 0.05171928699211573]
	TIME [epoch: 6.41 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044820575684791475		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.044820575684791475 | validation: 0.04859423055911382]
	TIME [epoch: 6.42 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046149669530159934		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.046149669530159934 | validation: 0.05838232858157178]
	TIME [epoch: 6.45 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04288687442915916		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.04288687442915916 | validation: 0.0580607359166251]
	TIME [epoch: 6.42 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048110451032700015		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.048110451032700015 | validation: 0.05808584949726206]
	TIME [epoch: 6.41 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04248370868121203		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.04248370868121203 | validation: 0.0520184547926311]
	TIME [epoch: 6.41 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0456300909623814		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.0456300909623814 | validation: 0.05351036790629154]
	TIME [epoch: 6.41 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04509299976064468		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.04509299976064468 | validation: 0.0596999396506497]
	TIME [epoch: 6.42 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04239902747457166		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.04239902747457166 | validation: 0.06112867196169516]
	TIME [epoch: 6.41 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04834412984114378		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.04834412984114378 | validation: 0.05844228018609611]
	TIME [epoch: 6.44 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046725689783001526		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.046725689783001526 | validation: 0.057498854972770984]
	TIME [epoch: 6.42 sec]
Finished training in 13011.579 seconds.
