Args:
Namespace(name='model_tr_study201', outdir='out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5', training_data='data/transition_rate_studies/tr_study201/tr_study201_training/r5', validation_data='data/transition_rate_studies/tr_study201/tr_study201_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 900373043

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.704027325748264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.704027325748264 | validation: 11.714460156266451]
	TIME [epoch: 93 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.316547539208292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.316547539208292 | validation: 12.254219578337038]
	TIME [epoch: 5.74 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.775563079371569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.775563079371569 | validation: 11.48672288146784]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.602267165459926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.602267165459926 | validation: 10.966234882636583]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.357071065811835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.357071065811835 | validation: 9.249457270481212]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.248114788266625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.248114788266625 | validation: 8.944641104426676]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.681984658479953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.681984658479953 | validation: 8.716884202063023]
	TIME [epoch: 5.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.566983674294267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.566983674294267 | validation: 8.401292564227365]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.964136879809997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.964136879809997 | validation: 6.037022623675173]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72951800846334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.72951800846334 | validation: 5.839153347172166]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.89616726891413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.89616726891413 | validation: 5.572292567710799]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7368420929963335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7368420929963335 | validation: 6.339031751130982]
	TIME [epoch: 5.71 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.665130486087734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.665130486087734 | validation: 6.150086309481858]
	TIME [epoch: 5.7 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.787738691722856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.787738691722856 | validation: 5.747049116249946]
	TIME [epoch: 5.7 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8006632006246805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8006632006246805 | validation: 5.643450482184988]
	TIME [epoch: 5.75 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.585388666842538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.585388666842538 | validation: 5.150905016589047]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.34510118792993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.34510118792993 | validation: 5.017904764028383]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.446726832221855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.446726832221855 | validation: 4.87141891513577]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.372198967599324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.372198967599324 | validation: 4.786776902062167]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.458356117473217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.458356117473217 | validation: 4.97293464703899]
	TIME [epoch: 5.71 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.561413911424842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.561413911424842 | validation: 5.128517707936526]
	TIME [epoch: 5.75 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.420652738231152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.420652738231152 | validation: 5.357882745260574]
	TIME [epoch: 5.72 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.315942571158464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.315942571158464 | validation: 5.462852464048572]
	TIME [epoch: 5.71 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.444058167534372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.444058167534372 | validation: 4.867860041509316]
	TIME [epoch: 5.71 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2154624070681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2154624070681 | validation: 4.785024003912607]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.289488258868312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.289488258868312 | validation: 4.704002455537825]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.272262616847527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.272262616847527 | validation: 4.9294805209849]
	TIME [epoch: 5.74 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.066288421416177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.066288421416177 | validation: 5.203354679821946]
	TIME [epoch: 5.72 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.065068888782196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.065068888782196 | validation: 5.230786765923117]
	TIME [epoch: 5.71 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.200530629809209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.200530629809209 | validation: 4.538320213634126]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.873482507291771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.873482507291771 | validation: 4.664916074028198]
	TIME [epoch: 5.71 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.97822324591301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.97822324591301 | validation: 4.712024071162851]
	TIME [epoch: 5.71 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.868501434338805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.868501434338805 | validation: 4.228219040698634]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.648993323629516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.648993323629516 | validation: 4.655553753027469]
	TIME [epoch: 5.74 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.747851553155771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.747851553155771 | validation: 4.316020658425141]
	TIME [epoch: 5.71 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.671818403453873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.671818403453873 | validation: 5.006850382240836]
	TIME [epoch: 5.72 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.576117900391914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.576117900391914 | validation: 3.666185258057618]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0196523940458695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0196523940458695 | validation: 3.752072595502523]
	TIME [epoch: 5.72 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.962331329301747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.962331329301747 | validation: 3.629975323747104]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.187402987083801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.187402987083801 | validation: 4.031244007288645]
	TIME [epoch: 5.74 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.393988653225574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.393988653225574 | validation: 3.94074700187227]
	TIME [epoch: 5.7 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7691657739313973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7691657739313973 | validation: 3.2966162835792137]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.476609747563666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.476609747563666 | validation: 3.0498499369358734]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2550418189637944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2550418189637944 | validation: 3.3780460372935677]
	TIME [epoch: 5.71 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3383973568451575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3383973568451575 | validation: 3.236640256294161]
	TIME [epoch: 5.72 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.998757500166122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.998757500166122 | validation: 3.0992361634958026]
	TIME [epoch: 5.74 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3176678196434084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3176678196434084 | validation: 2.6781455780237855]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1547585737365553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1547585737365553 | validation: 2.5888760089177754]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1412257205310508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1412257205310508 | validation: 3.317688262472027]
	TIME [epoch: 5.72 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.400697654765283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.400697654765283 | validation: 2.655066488286702]
	TIME [epoch: 5.71 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.977183171357378		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.977183171357378 | validation: 3.230859220256767]
	TIME [epoch: 5.73 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.948778873787285		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.948778873787285 | validation: 2.5521181985880395]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.653040175874721		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.653040175874721 | validation: 2.408861813513941]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7819043362460247		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.7819043362460247 | validation: 2.1393421907199404]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8011115287570556		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.8011115287570556 | validation: 2.3252027997911995]
	TIME [epoch: 5.72 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9984694713773523		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.9984694713773523 | validation: 1.9777963267320797]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5894254101035092		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.5894254101035092 | validation: 3.578469198800413]
	TIME [epoch: 5.75 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6254129396780996		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.6254129396780996 | validation: 3.1222208516101873]
	TIME [epoch: 5.72 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6537805486824837		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.6537805486824837 | validation: 2.2941282144234054]
	TIME [epoch: 5.71 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5318063677047853		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.5318063677047853 | validation: 1.8927531309485368]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4396603596246345		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.4396603596246345 | validation: 1.7099849977092039]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3021395931546147		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.3021395931546147 | validation: 3.2550035640292014]
	TIME [epoch: 5.71 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7605858155368592		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.7605858155368592 | validation: 1.7111763696514521]
	TIME [epoch: 5.76 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.46368523790865		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.46368523790865 | validation: 1.7084369772966472]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.662921936794212		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.662921936794212 | validation: 2.9979148734899934]
	TIME [epoch: 5.72 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4540278829517437		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.4540278829517437 | validation: 2.6453671348431236]
	TIME [epoch: 5.72 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.308327584807609		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.308327584807609 | validation: 2.855055158153638]
	TIME [epoch: 5.72 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.666518932163782		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.666518932163782 | validation: 1.7941915902018446]
	TIME [epoch: 5.72 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2475801561136453		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.2475801561136453 | validation: 2.011401174091568]
	TIME [epoch: 5.76 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3329837577281523		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.3329837577281523 | validation: 2.191663052237188]
	TIME [epoch: 5.72 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2019392109772986		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.2019392109772986 | validation: 3.020985831470918]
	TIME [epoch: 5.72 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.470924779871458		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.470924779871458 | validation: 2.0194032172682936]
	TIME [epoch: 5.72 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2188806616072037		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.2188806616072037 | validation: 2.145209309815952]
	TIME [epoch: 5.72 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3999662797078987		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.3999662797078987 | validation: 1.8966954107029046]
	TIME [epoch: 5.72 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248252739768347		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.248252739768347 | validation: 2.1834749000606504]
	TIME [epoch: 5.76 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060154826973248		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.060154826973248 | validation: 2.532936747776015]
	TIME [epoch: 5.72 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.237110804939629		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.237110804939629 | validation: 1.6774330102071202]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4458247366675954		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.4458247366675954 | validation: 1.6164429227977375]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9230435685768827		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.9230435685768827 | validation: 2.4089687048462474]
	TIME [epoch: 5.72 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.222274078736964		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.222274078736964 | validation: 1.713494018171635]
	TIME [epoch: 5.73 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.035442446034335		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.035442446034335 | validation: 2.929482530472531]
	TIME [epoch: 5.74 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2664511021658416		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.2664511021658416 | validation: 2.2404812518328843]
	TIME [epoch: 5.72 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1252963369718723		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.1252963369718723 | validation: 1.6765892067258643]
	TIME [epoch: 5.72 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0449644434144543		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.0449644434144543 | validation: 1.8739296575112872]
	TIME [epoch: 5.71 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066815669459616		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.066815669459616 | validation: 1.7082380116228129]
	TIME [epoch: 5.71 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8702619267486578		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.8702619267486578 | validation: 2.1904362994187987]
	TIME [epoch: 5.73 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.224200360284354		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.224200360284354 | validation: 4.573179705618241]
	TIME [epoch: 5.74 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.536909089246865		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.536909089246865 | validation: 2.5979939311290874]
	TIME [epoch: 5.72 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2229941722533875		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.2229941722533875 | validation: 1.6462010810300354]
	TIME [epoch: 5.72 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0263801785910927		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.0263801785910927 | validation: 2.6833032889935238]
	TIME [epoch: 5.72 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1306029898317647		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.1306029898317647 | validation: 1.7367689178101233]
	TIME [epoch: 5.72 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2188802868217756		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.2188802868217756 | validation: 1.5535821574794437]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7195753419299042		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.7195753419299042 | validation: 2.517790291799813]
	TIME [epoch: 5.75 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.896222737692664		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.896222737692664 | validation: 2.6087488136774084]
	TIME [epoch: 5.72 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2563620469061028		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.2563620469061028 | validation: 1.9785665820282692]
	TIME [epoch: 5.71 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9444491929192913		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.9444491929192913 | validation: 1.98646798518713]
	TIME [epoch: 5.71 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0287238405151298		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.0287238405151298 | validation: 2.240499868818453]
	TIME [epoch: 5.71 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8803366776428305		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.8803366776428305 | validation: 1.9472635376469203]
	TIME [epoch: 5.73 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9195417197728701		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.9195417197728701 | validation: 2.5650667958283897]
	TIME [epoch: 5.74 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1843033404419354		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.1843033404419354 | validation: 1.5661446016422673]
	TIME [epoch: 5.72 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8525155989480742		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.8525155989480742 | validation: 1.7049952841696863]
	TIME [epoch: 5.72 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149813493237884		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.149813493237884 | validation: 1.7901905900712973]
	TIME [epoch: 5.71 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0264483894580763		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.0264483894580763 | validation: 1.9291965576914438]
	TIME [epoch: 5.71 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9672543318098248		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.9672543318098248 | validation: 1.8635585707000706]
	TIME [epoch: 5.73 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.14331909896841		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.14331909896841 | validation: 2.1166497364362487]
	TIME [epoch: 5.74 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9040386288093971		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.9040386288093971 | validation: 1.3716557404081133]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6735063715225085		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.6735063715225085 | validation: 1.588770611918301]
	TIME [epoch: 5.71 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0129231420907785		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.0129231420907785 | validation: 1.6090679570696478]
	TIME [epoch: 5.71 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.844397826428459		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.844397826428459 | validation: 1.1792606355810262]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.945721131476753		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.945721131476753 | validation: 2.752211304773764]
	TIME [epoch: 5.72 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31696927477604		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.31696927477604 | validation: 2.018462150886159]
	TIME [epoch: 5.74 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.814998330415504		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.814998330415504 | validation: 1.7919366491178834]
	TIME [epoch: 5.71 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7041226176972668		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.7041226176972668 | validation: 3.5676747957846136]
	TIME [epoch: 5.71 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2137467329187475		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.2137467329187475 | validation: 1.507639262509978]
	TIME [epoch: 5.71 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8389010588960404		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.8389010588960404 | validation: 1.7584645440829518]
	TIME [epoch: 5.71 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.898256754218404		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.898256754218404 | validation: 1.4818395739632433]
	TIME [epoch: 5.72 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5972239117089224		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.5972239117089224 | validation: 1.3659749901366045]
	TIME [epoch: 5.74 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6239357572804431		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.6239357572804431 | validation: 2.1111850126226597]
	TIME [epoch: 5.71 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9362313972907388		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.9362313972907388 | validation: 1.638262527111331]
	TIME [epoch: 5.71 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7995040327125882		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.7995040327125882 | validation: 1.9451375471439434]
	TIME [epoch: 5.71 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0008234772431246		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.0008234772431246 | validation: 1.5468623496240854]
	TIME [epoch: 5.71 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6064692915209682		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.6064692915209682 | validation: 2.2372476119349183]
	TIME [epoch: 5.72 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.901116849333272		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.901116849333272 | validation: 1.3535403100031034]
	TIME [epoch: 5.74 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.557659507269419		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.557659507269419 | validation: 1.2880925046742784]
	TIME [epoch: 5.72 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9455879656909747		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.9455879656909747 | validation: 1.7503651113350591]
	TIME [epoch: 5.71 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7627583190968006		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.7627583190968006 | validation: 1.1706267973104212]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7565490242598318		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.7565490242598318 | validation: 1.9491806293111176]
	TIME [epoch: 5.72 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6191080541774765		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.6191080541774765 | validation: 1.6095176273282343]
	TIME [epoch: 5.73 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8206625099207838		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.8206625099207838 | validation: 1.208473390771577]
	TIME [epoch: 5.73 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3240168424069623		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.3240168424069623 | validation: 1.2559235803213376]
	TIME [epoch: 5.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2334240516508563		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.2334240516508563 | validation: 1.5520364677584484]
	TIME [epoch: 5.71 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.937279023285535		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.937279023285535 | validation: 1.164145959482737]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.718049411033736		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.718049411033736 | validation: 1.63590911414749]
	TIME [epoch: 5.71 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.824364583307526		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.824364583307526 | validation: 1.3253767498736488]
	TIME [epoch: 5.73 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0247541477382693		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.0247541477382693 | validation: 1.1111604250733842]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5923113735519274		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.5923113735519274 | validation: 1.9383388016243424]
	TIME [epoch: 5.71 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6792642693486157		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.6792642693486157 | validation: 1.1757839478770147]
	TIME [epoch: 5.71 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.75535874461892		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.75535874461892 | validation: 1.3247706598262636]
	TIME [epoch: 5.71 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5648409718994434		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.5648409718994434 | validation: 1.6303673346623355]
	TIME [epoch: 5.71 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6522942391136604		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.6522942391136604 | validation: 2.4568323728630213]
	TIME [epoch: 5.74 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0097394119326664		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.0097394119326664 | validation: 1.7034713129713033]
	TIME [epoch: 5.72 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.665814030501744		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.665814030501744 | validation: 1.15203676088967]
	TIME [epoch: 5.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.831101683882914		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.831101683882914 | validation: 1.2423375341399459]
	TIME [epoch: 5.71 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.563068277099767		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.563068277099767 | validation: 1.2977783406763792]
	TIME [epoch: 5.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.681963127507038		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.681963127507038 | validation: 1.2847673125703682]
	TIME [epoch: 5.71 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4468388352455133		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.4468388352455133 | validation: 2.1043794262381907]
	TIME [epoch: 5.73 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.638265060577801		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.638265060577801 | validation: 1.1835914309915467]
	TIME [epoch: 5.72 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.523744721186404		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.523744721186404 | validation: 1.5522182715212076]
	TIME [epoch: 5.71 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6271172646008039		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.6271172646008039 | validation: 1.099207178510971]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.837482734165317		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.837482734165317 | validation: 1.2153160417387732]
	TIME [epoch: 5.72 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.750859291564134		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.750859291564134 | validation: 1.5467266666541764]
	TIME [epoch: 5.72 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6309058525051365		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.6309058525051365 | validation: 4.134782709097244]
	TIME [epoch: 5.75 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325954183635283		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.325954183635283 | validation: 2.16248298004684]
	TIME [epoch: 5.73 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7121440800471717		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.7121440800471717 | validation: 1.1796056505841086]
	TIME [epoch: 5.72 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7125909993066537		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.7125909993066537 | validation: 2.097021987176083]
	TIME [epoch: 5.72 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6572685975501602		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.6572685975501602 | validation: 1.1914999623581226]
	TIME [epoch: 5.72 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5774911581089137		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.5774911581089137 | validation: 1.9163494130267276]
	TIME [epoch: 5.72 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6612095919785603		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.6612095919785603 | validation: 1.9284208964185683]
	TIME [epoch: 5.75 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5769327642073356		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.5769327642073356 | validation: 1.5257727926204225]
	TIME [epoch: 5.73 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.433777978292328		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.433777978292328 | validation: 1.8000372859741698]
	TIME [epoch: 5.72 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7191426832946188		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.7191426832946188 | validation: 1.04132179550811]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3873705275482893		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.3873705275482893 | validation: 2.227829799048054]
	TIME [epoch: 5.72 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.673329255166025		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.673329255166025 | validation: 1.9799017911992576]
	TIME [epoch: 5.71 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6724668451554607		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.6724668451554607 | validation: 1.325618748225958]
	TIME [epoch: 5.74 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.46467975262323		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.46467975262323 | validation: 1.6900605812345038]
	TIME [epoch: 5.72 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5655375673307534		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.5655375673307534 | validation: 1.3428376556781603]
	TIME [epoch: 5.72 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4892925736325098		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.4892925736325098 | validation: 1.1548653644605744]
	TIME [epoch: 5.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3635407232047494		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.3635407232047494 | validation: 1.418456622550658]
	TIME [epoch: 5.71 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7506151601113458		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.7506151601113458 | validation: 1.2151142456247335]
	TIME [epoch: 5.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4370749763330921		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.4370749763330921 | validation: 1.379018059885019]
	TIME [epoch: 5.75 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4505283487865994		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.4505283487865994 | validation: 2.6971957115189555]
	TIME [epoch: 5.73 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9666560275806426		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.9666560275806426 | validation: 2.0417472320788455]
	TIME [epoch: 5.71 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.555549066421255		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.555549066421255 | validation: 1.28293474675464]
	TIME [epoch: 5.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3273936183450123		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.3273936183450123 | validation: 1.324856910202944]
	TIME [epoch: 5.71 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4029434817759165		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.4029434817759165 | validation: 2.798535528768517]
	TIME [epoch: 5.72 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.939740068416548		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.939740068416548 | validation: 1.5037520900957544]
	TIME [epoch: 5.74 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.623120076958261		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.623120076958261 | validation: 0.9460098768428046]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.425981158542225		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.425981158542225 | validation: 1.2413691323517484]
	TIME [epoch: 5.74 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4633827499344483		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.4633827499344483 | validation: 1.0360993912064413]
	TIME [epoch: 5.72 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.356512092693552		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.356512092693552 | validation: 1.2260972536804944]
	TIME [epoch: 5.72 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4509028311455838		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.4509028311455838 | validation: 1.1243564396332528]
	TIME [epoch: 5.72 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.477550283693251		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.477550283693251 | validation: 1.510197980437424]
	TIME [epoch: 5.75 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.369361846634204		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.369361846634204 | validation: 1.751026826025887]
	TIME [epoch: 5.73 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5754548422444368		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.5754548422444368 | validation: 1.0033578451587561]
	TIME [epoch: 5.72 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2787307957074243		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.2787307957074243 | validation: 1.583064044137223]
	TIME [epoch: 5.71 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6082939663075684		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.6082939663075684 | validation: 1.655675539155443]
	TIME [epoch: 5.72 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4321037457128918		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.4321037457128918 | validation: 1.0807826084383836]
	TIME [epoch: 5.72 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4979532818659071		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.4979532818659071 | validation: 0.9927754738657422]
	TIME [epoch: 5.75 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2059439628333333		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.2059439628333333 | validation: 1.0911234927654296]
	TIME [epoch: 5.73 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3763567084575739		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.3763567084575739 | validation: 1.0699752036334493]
	TIME [epoch: 5.72 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4259100899924		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.4259100899924 | validation: 0.991069673558269]
	TIME [epoch: 5.72 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2718806026815606		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.2718806026815606 | validation: 1.106835742657025]
	TIME [epoch: 5.72 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4236189406851443		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.4236189406851443 | validation: 1.37370824642373]
	TIME [epoch: 5.72 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3222498721102616		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.3222498721102616 | validation: 1.2914061717074208]
	TIME [epoch: 5.74 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3881029240382052		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.3881029240382052 | validation: 0.9574824802683761]
	TIME [epoch: 5.73 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3176559233343408		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.3176559233343408 | validation: 2.2865663710040924]
	TIME [epoch: 5.71 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6477093813879193		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.6477093813879193 | validation: 0.8661896464761156]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4456197986919328		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.4456197986919328 | validation: 0.899888882663677]
	TIME [epoch: 5.71 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2818217591928307		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.2818217591928307 | validation: 1.1237747826823412]
	TIME [epoch: 5.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3118201076083595		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.3118201076083595 | validation: 1.0861171038819268]
	TIME [epoch: 5.74 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4202988960874041		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.4202988960874041 | validation: 0.7715427108715815]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.453410238699468		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.453410238699468 | validation: 1.0410070559637148]
	TIME [epoch: 5.71 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4085081532531039		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.4085081532531039 | validation: 1.1895505092101215]
	TIME [epoch: 5.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4966570576522704		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.4966570576522704 | validation: 0.9274131480448995]
	TIME [epoch: 5.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5438336093802687		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.5438336093802687 | validation: 0.9151820940180185]
	TIME [epoch: 5.71 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5070875401056516		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.5070875401056516 | validation: 1.0641149227331068]
	TIME [epoch: 5.74 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.339973191732585		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.339973191732585 | validation: 1.2821594974455541]
	TIME [epoch: 5.72 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2959740813879062		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.2959740813879062 | validation: 2.005388555172255]
	TIME [epoch: 5.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5490932252399572		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.5490932252399572 | validation: 1.2880491588578176]
	TIME [epoch: 5.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3783929306885871		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.3783929306885871 | validation: 1.3760458003021467]
	TIME [epoch: 5.71 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3428733500165189		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.3428733500165189 | validation: 1.016265952427545]
	TIME [epoch: 5.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2860630576816554		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.2860630576816554 | validation: 1.4374413185972321]
	TIME [epoch: 5.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2777264751587314		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.2777264751587314 | validation: 1.180957136181177]
	TIME [epoch: 5.73 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2488884906086968		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.2488884906086968 | validation: 2.254981861696842]
	TIME [epoch: 5.71 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0190381917865796		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.0190381917865796 | validation: 2.1930745289455706]
	TIME [epoch: 5.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5369765230787042		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.5369765230787042 | validation: 0.9669257684987096]
	TIME [epoch: 5.71 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2440728679557136		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.2440728679557136 | validation: 1.1159755315378885]
	TIME [epoch: 5.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4325094913683674		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.4325094913683674 | validation: 0.8719896836550959]
	TIME [epoch: 5.74 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3040673818721609		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.3040673818721609 | validation: 1.009910844024714]
	TIME [epoch: 5.71 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4347495577730691		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.4347495577730691 | validation: 1.3886096579240275]
	TIME [epoch: 5.71 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4331257805501347		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.4331257805501347 | validation: 0.8298263104894185]
	TIME [epoch: 5.72 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3141871456604197		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.3141871456604197 | validation: 1.613724207237623]
	TIME [epoch: 5.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3661090394281592		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.3661090394281592 | validation: 0.7773128893761809]
	TIME [epoch: 5.71 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2865730156421495		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.2865730156421495 | validation: 0.9461913415211312]
	TIME [epoch: 5.73 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3427285931325479		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.3427285931325479 | validation: 2.2157549168405177]
	TIME [epoch: 5.71 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4590424839572111		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.4590424839572111 | validation: 1.387440907208468]
	TIME [epoch: 5.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2601454802626906		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.2601454802626906 | validation: 1.1007059333577376]
	TIME [epoch: 5.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181231657480952		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.181231657480952 | validation: 0.9584904535090693]
	TIME [epoch: 5.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2581448000326962		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.2581448000326962 | validation: 0.7673193475997816]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0696439968368412		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.0696439968368412 | validation: 1.0483823059798243]
	TIME [epoch: 5.75 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3580455611285647		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.3580455611285647 | validation: 0.8996443827382309]
	TIME [epoch: 5.72 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1661396274713893		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.1661396274713893 | validation: 0.9350290697605789]
	TIME [epoch: 5.72 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1213575359407144		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.1213575359407144 | validation: 2.1889828719017697]
	TIME [epoch: 5.71 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2630392855753905		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.2630392855753905 | validation: 0.8608833199035252]
	TIME [epoch: 5.71 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.649988084286241		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.649988084286241 | validation: 0.8347803203166017]
	TIME [epoch: 5.72 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.734907137405556		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.734907137405556 | validation: 0.8224560593073573]
	TIME [epoch: 5.75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4360454512533893		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.4360454512533893 | validation: 1.0614742427990789]
	TIME [epoch: 5.73 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.637764658828059		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.637764658828059 | validation: 0.8774566320744873]
	TIME [epoch: 5.71 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6651395586116622		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.6651395586116622 | validation: 0.9169295264598373]
	TIME [epoch: 5.72 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7205634348809058		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.7205634348809058 | validation: 1.2447253703454708]
	TIME [epoch: 5.72 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5101928687686146		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.5101928687686146 | validation: 0.9891486631451233]
	TIME [epoch: 5.71 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3588421780771536		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.3588421780771536 | validation: 1.1416169997058878]
	TIME [epoch: 5.74 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7139667058518473		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.7139667058518473 | validation: 1.8391239234473966]
	TIME [epoch: 5.73 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5204801987858718		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.5204801987858718 | validation: 1.1902953072445033]
	TIME [epoch: 5.72 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1645147265305718		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.1645147265305718 | validation: 1.679341439245757]
	TIME [epoch: 5.72 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2833356607145907		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.2833356607145907 | validation: 0.8913288874584102]
	TIME [epoch: 5.71 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1458333335713557		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.1458333335713557 | validation: 1.0396635250595385]
	TIME [epoch: 5.71 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1905687108533156		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.1905687108533156 | validation: 1.1063219183638417]
	TIME [epoch: 5.74 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3289166996428408		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.3289166996428408 | validation: 3.0363435460334585]
	TIME [epoch: 5.72 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7804162542353685		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.7804162542353685 | validation: 1.928863534799698]
	TIME [epoch: 5.71 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4956520705169005		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.4956520705169005 | validation: 1.532935594769088]
	TIME [epoch: 5.71 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.414161435584851		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.414161435584851 | validation: 1.7357790280576673]
	TIME [epoch: 5.71 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5320291678526443		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.5320291678526443 | validation: 1.1113881647131896]
	TIME [epoch: 5.71 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1645114023785537		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.1645114023785537 | validation: 1.1088344422713978]
	TIME [epoch: 5.74 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4625519497863384		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.4625519497863384 | validation: 0.803961175051316]
	TIME [epoch: 5.72 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1099127056164855		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.1099127056164855 | validation: 0.802544834215193]
	TIME [epoch: 5.71 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0613741446302085		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.0613741446302085 | validation: 1.6264549659377432]
	TIME [epoch: 5.71 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2151586857028749		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.2151586857028749 | validation: 1.0913621301787735]
	TIME [epoch: 5.71 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2074028639620844		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.2074028639620844 | validation: 0.9325021635933286]
	TIME [epoch: 5.71 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1733613713214894		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.1733613713214894 | validation: 1.1044060903001407]
	TIME [epoch: 5.74 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1502174957006575		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.1502174957006575 | validation: 0.8295203542783881]
	TIME [epoch: 5.73 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025454950384585		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.025454950384585 | validation: 1.022381869454835]
	TIME [epoch: 5.72 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1297775117210143		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.1297775117210143 | validation: 0.7382718648588746]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0842473598637141		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.0842473598637141 | validation: 0.8865922957018809]
	TIME [epoch: 5.71 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2018635733249783		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.2018635733249783 | validation: 0.9708930279874589]
	TIME [epoch: 5.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1159856495140323		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.1159856495140323 | validation: 0.9445164562899767]
	TIME [epoch: 5.75 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021919360952743		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.021919360952743 | validation: 0.8116948632873547]
	TIME [epoch: 5.71 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9855936900036555		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.9855936900036555 | validation: 0.9064327425290665]
	TIME [epoch: 5.71 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3011226663842976		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.3011226663842976 | validation: 0.6909500809625827]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6049900679376963		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.6049900679376963 | validation: 1.0674314323697278]
	TIME [epoch: 5.71 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.454229138360855		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.454229138360855 | validation: 0.8311134006877895]
	TIME [epoch: 5.72 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3411238696388463		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.3411238696388463 | validation: 0.797291833777778]
	TIME [epoch: 5.75 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2285025585354736		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.2285025585354736 | validation: 0.7137036575699327]
	TIME [epoch: 5.73 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1979420474352052		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.1979420474352052 | validation: 1.094657814160415]
	TIME [epoch: 5.72 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0194985628733284		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.0194985628733284 | validation: 1.0866248677518047]
	TIME [epoch: 5.71 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.210260272933882		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.210260272933882 | validation: 0.9012501050002663]
	TIME [epoch: 5.71 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082015401020845		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.082015401020845 | validation: 1.138481307546279]
	TIME [epoch: 5.71 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0410549061932661		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.0410549061932661 | validation: 1.103505655196807]
	TIME [epoch: 5.74 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9940608925112502		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.9940608925112502 | validation: 1.9947217834467414]
	TIME [epoch: 5.73 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.569500559047336		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.569500559047336 | validation: 2.0670176159807427]
	TIME [epoch: 5.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.324447158007806		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.324447158007806 | validation: 2.3409726335926844]
	TIME [epoch: 5.71 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3669877641919463		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.3669877641919463 | validation: 1.6965052843966384]
	TIME [epoch: 5.71 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2680795761118937		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.2680795761118937 | validation: 1.2222223848672424]
	TIME [epoch: 5.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1151911011529365		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.1151911011529365 | validation: 1.2431823454572015]
	TIME [epoch: 5.75 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1473304823330541		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.1473304823330541 | validation: 1.6190333423423815]
	TIME [epoch: 5.72 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1198195315716544		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.1198195315716544 | validation: 0.6764992131931152]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086675585113912		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.086675585113912 | validation: 0.7528221861158536]
	TIME [epoch: 5.71 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0964195119149074		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.0964195119149074 | validation: 0.7071163042288725]
	TIME [epoch: 5.71 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1983268306379196		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.1983268306379196 | validation: 1.061809022021857]
	TIME [epoch: 5.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.964821281084732		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.964821281084732 | validation: 0.6401284481043636]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9921520985621483		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.9921520985621483 | validation: 0.6456629592304488]
	TIME [epoch: 5.71 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9572125353819274		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.9572125353819274 | validation: 0.8159070128381253]
	TIME [epoch: 5.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0342494254243262		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.0342494254243262 | validation: 1.2814210054482744]
	TIME [epoch: 5.71 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1478825977706695		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.1478825977706695 | validation: 1.237295827284963]
	TIME [epoch: 5.71 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.08449924855013		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.08449924855013 | validation: 0.6297139129488166]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9135519981734697		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.9135519981734697 | validation: 2.5633213949458353]
	TIME [epoch: 5.75 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5753099377869377		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.5753099377869377 | validation: 1.483999921871415]
	TIME [epoch: 5.73 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2536016537372483		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.2536016537372483 | validation: 0.8239112275724619]
	TIME [epoch: 5.72 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0005320701206548		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.0005320701206548 | validation: 1.4754354152382474]
	TIME [epoch: 5.72 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2713342698552568		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.2713342698552568 | validation: 0.8232850702522914]
	TIME [epoch: 5.72 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0052752867098895		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.0052752867098895 | validation: 1.487396588695625]
	TIME [epoch: 5.72 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2849486258138894		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.2849486258138894 | validation: 0.8317002458187333]
	TIME [epoch: 5.75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9526841100745643		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.9526841100745643 | validation: 1.0093528939808576]
	TIME [epoch: 5.74 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9084969965363301		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.9084969965363301 | validation: 1.080372613279054]
	TIME [epoch: 5.73 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.947150651387378		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.947150651387378 | validation: 0.847374097896554]
	TIME [epoch: 5.72 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0466982427538547		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.0466982427538547 | validation: 1.4199466136437278]
	TIME [epoch: 5.72 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1413661908043207		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.1413661908043207 | validation: 0.6392015001855856]
	TIME [epoch: 5.72 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8973534482060394		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.8973534482060394 | validation: 0.7414460978467932]
	TIME [epoch: 5.72 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9696078102315691		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.9696078102315691 | validation: 0.9149963238979508]
	TIME [epoch: 5.76 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0591510987885744		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.0591510987885744 | validation: 0.6196638766725491]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1314801312964213		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.1314801312964213 | validation: 0.6753142838216813]
	TIME [epoch: 5.72 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9211581046502961		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.9211581046502961 | validation: 0.743267635201983]
	TIME [epoch: 5.72 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9520497859936139		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.9520497859936139 | validation: 0.9038227821698341]
	TIME [epoch: 5.72 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.130450578031285		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.130450578031285 | validation: 0.6804716126828827]
	TIME [epoch: 5.72 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.208363108485126		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.208363108485126 | validation: 0.6263223249183516]
	TIME [epoch: 5.75 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2740587309721663		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.2740587309721663 | validation: 0.734208783031465]
	TIME [epoch: 5.73 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1063245905159151		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.1063245905159151 | validation: 0.7408571164643712]
	TIME [epoch: 5.72 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8706633176725103		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.8706633176725103 | validation: 0.7324660442521522]
	TIME [epoch: 5.72 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9834342590980034		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.9834342590980034 | validation: 0.615587129432764]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8499179488418881		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.8499179488418881 | validation: 0.8118416730568366]
	TIME [epoch: 5.71 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9822360500199868		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.9822360500199868 | validation: 0.7841636386578011]
	TIME [epoch: 5.72 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.149102908491923		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.149102908491923 | validation: 0.6913115057944191]
	TIME [epoch: 5.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.253430871501806		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.253430871501806 | validation: 1.2275432562820296]
	TIME [epoch: 5.71 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1414811842335877		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.1414811842335877 | validation: 0.6031965854463196]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8984738218208166		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8984738218208166 | validation: 0.7263062035769318]
	TIME [epoch: 5.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8766138407834982		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.8766138407834982 | validation: 0.8039532517485958]
	TIME [epoch: 5.71 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9406338314911659		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.9406338314911659 | validation: 0.6781952250246001]
	TIME [epoch: 5.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9927052722081342		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9927052722081342 | validation: 0.5410725446641097]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4630354443453546		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.4630354443453546 | validation: 0.833824081687033]
	TIME [epoch: 5.71 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0440627796701023		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.0440627796701023 | validation: 0.6361107050686955]
	TIME [epoch: 5.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9656938860651652		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.9656938860651652 | validation: 1.3616265245226264]
	TIME [epoch: 5.71 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0484759412938094		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.0484759412938094 | validation: 0.6153172022006368]
	TIME [epoch: 5.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8970944201356941		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.8970944201356941 | validation: 0.892315455502098]
	TIME [epoch: 5.71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9118380680523607		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.9118380680523607 | validation: 0.6872999928889619]
	TIME [epoch: 5.72 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9165984966894994		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.9165984966894994 | validation: 0.6536573657867183]
	TIME [epoch: 5.74 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7995575827592749		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.7995575827592749 | validation: 0.7065800833652287]
	TIME [epoch: 5.71 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8586665466632664		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.8586665466632664 | validation: 0.7274172638615326]
	TIME [epoch: 5.71 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8307574827160855		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.8307574827160855 | validation: 0.7094325411798735]
	TIME [epoch: 5.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9804419320220683		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.9804419320220683 | validation: 0.7986016948173185]
	TIME [epoch: 5.71 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8607157890412173		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.8607157890412173 | validation: 0.7063693403317544]
	TIME [epoch: 5.71 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9173178659403093		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.9173178659403093 | validation: 0.6224616476777441]
	TIME [epoch: 5.73 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9646822447353138		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.9646822447353138 | validation: 0.49479273951783004]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8881899419642869		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.8881899419642869 | validation: 0.7387398902419788]
	TIME [epoch: 5.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8164153707432851		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.8164153707432851 | validation: 0.4729258977332968]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181404788511923		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.181404788511923 | validation: 0.7260469776861795]
	TIME [epoch: 5.71 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2217945014410803		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.2217945014410803 | validation: 0.9529622133678458]
	TIME [epoch: 5.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9426956476158534		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.9426956476158534 | validation: 0.602144988769158]
	TIME [epoch: 5.73 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8166079409384532		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.8166079409384532 | validation: 0.8077300296864227]
	TIME [epoch: 5.71 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8055896362192564		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.8055896362192564 | validation: 1.1367240904916256]
	TIME [epoch: 5.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1636423265361107		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.1636423265361107 | validation: 2.1927868153333296]
	TIME [epoch: 5.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.486613174731907		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.486613174731907 | validation: 1.073787346414384]
	TIME [epoch: 5.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9555963122847148		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.9555963122847148 | validation: 0.6931912576348133]
	TIME [epoch: 5.71 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7848528917303255		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.7848528917303255 | validation: 1.214508357308034]
	TIME [epoch: 5.72 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0005862428932035		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.0005862428932035 | validation: 0.7920490612906038]
	TIME [epoch: 5.74 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.86466045757519		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.86466045757519 | validation: 0.8123316735154801]
	TIME [epoch: 5.71 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8695477133747253		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.8695477133747253 | validation: 0.5389504967627395]
	TIME [epoch: 5.71 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8431144962432031		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.8431144962432031 | validation: 0.7661607976790552]
	TIME [epoch: 5.71 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8141480384796539		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.8141480384796539 | validation: 0.47519801000813156]
	TIME [epoch: 5.71 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8879673167372308		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.8879673167372308 | validation: 0.5430374585621871]
	TIME [epoch: 5.71 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9779452445853067		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.9779452445853067 | validation: 0.5192510258445421]
	TIME [epoch: 5.74 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221536681234562		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.7221536681234562 | validation: 0.5633276407460913]
	TIME [epoch: 5.73 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9491505491255438		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.9491505491255438 | validation: 0.4514301581124974]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8193853472118344		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.8193853472118344 | validation: 0.6795329171555002]
	TIME [epoch: 5.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8242531319511393		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.8242531319511393 | validation: 1.0044255305603411]
	TIME [epoch: 5.71 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8567573092296209		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.8567573092296209 | validation: 0.6679195405271685]
	TIME [epoch: 5.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8209522516833363		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.8209522516833363 | validation: 0.7750785831394087]
	TIME [epoch: 5.71 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8691116891247465		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.8691116891247465 | validation: 0.49934701505207185]
	TIME [epoch: 5.75 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8976985059132355		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.8976985059132355 | validation: 0.44145818837160206]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7593409689391013		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.7593409689391013 | validation: 0.6797471979612919]
	TIME [epoch: 5.71 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7716169586947693		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7716169586947693 | validation: 0.5245699175345622]
	TIME [epoch: 5.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257952069531077		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.7257952069531077 | validation: 0.5311223837060155]
	TIME [epoch: 5.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3122011632239419		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.3122011632239419 | validation: 1.0226855354053386]
	TIME [epoch: 5.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0105494373816257		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.0105494373816257 | validation: 0.5365634806269789]
	TIME [epoch: 5.72 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1517849745669007		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.1517849745669007 | validation: 0.6273151130605119]
	TIME [epoch: 5.71 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9724458743922427		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.9724458743922427 | validation: 0.5028707950163396]
	TIME [epoch: 5.71 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2103522346112427		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.2103522346112427 | validation: 0.6504809403990349]
	TIME [epoch: 5.71 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.093916486794766		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.093916486794766 | validation: 0.677213882756347]
	TIME [epoch: 5.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8280505026952543		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.8280505026952543 | validation: 0.5477903445493125]
	TIME [epoch: 5.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7667837298656502		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.7667837298656502 | validation: 0.5509916447840294]
	TIME [epoch: 5.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8055137797598846		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.8055137797598846 | validation: 0.471676306071534]
	TIME [epoch: 5.74 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0460483814790833		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.0460483814790833 | validation: 0.6025310987107123]
	TIME [epoch: 5.71 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1378275300165779		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.1378275300165779 | validation: 0.7506898009414471]
	TIME [epoch: 5.72 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8809604418889959		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.8809604418889959 | validation: 0.9972343565679407]
	TIME [epoch: 5.71 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.844188985907304		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.844188985907304 | validation: 0.484442728631295]
	TIME [epoch: 5.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7874492838942542		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.7874492838942542 | validation: 0.7202478034431095]
	TIME [epoch: 5.71 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7755272522324906		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.7755272522324906 | validation: 0.7427812226142058]
	TIME [epoch: 5.73 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7680829067432071		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.7680829067432071 | validation: 0.5810262123228425]
	TIME [epoch: 5.72 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.846189865171612		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.846189865171612 | validation: 1.0641673043883217]
	TIME [epoch: 5.72 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.041964143003098		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.041964143003098 | validation: 0.5377527426105054]
	TIME [epoch: 5.71 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7775392477171529		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.7775392477171529 | validation: 1.1754881663456431]
	TIME [epoch: 5.71 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8805689327990593		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.8805689327990593 | validation: 1.1258643560908494]
	TIME [epoch: 5.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9063723564696111		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.9063723564696111 | validation: 1.622315222988884]
	TIME [epoch: 5.72 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9978538814295943		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.9978538814295943 | validation: 0.5272912268983033]
	TIME [epoch: 5.76 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7182807393345711		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7182807393345711 | validation: 0.5987593709142662]
	TIME [epoch: 5.71 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9314303254294577		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.9314303254294577 | validation: 0.5859937173364003]
	TIME [epoch: 5.71 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1281599844075134		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.1281599844075134 | validation: 1.33631205881179]
	TIME [epoch: 5.72 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.940639195031447		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.940639195031447 | validation: 0.5309736606478808]
	TIME [epoch: 5.71 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9198827511890091		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.9198827511890091 | validation: 0.6867633927877593]
	TIME [epoch: 5.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8542953077612014		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.8542953077612014 | validation: 0.6560584519682863]
	TIME [epoch: 5.73 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7864478845222422		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.7864478845222422 | validation: 0.7392002715304108]
	TIME [epoch: 5.73 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7389997071282925		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.7389997071282925 | validation: 0.4757371135871674]
	TIME [epoch: 5.71 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825403614856813		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.6825403614856813 | validation: 0.6304265519894451]
	TIME [epoch: 5.71 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6996295354954355		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.6996295354954355 | validation: 1.023239158076089]
	TIME [epoch: 5.71 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8605058450104787		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.8605058450104787 | validation: 0.6104813389852123]
	TIME [epoch: 5.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.939022579878519		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.939022579878519 | validation: 0.6985596617626968]
	TIME [epoch: 5.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8057404433586455		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.8057404433586455 | validation: 0.5264987476821762]
	TIME [epoch: 5.75 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8949775610895754		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.8949775610895754 | validation: 0.4476485839367503]
	TIME [epoch: 5.72 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7045546892093394		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.7045546892093394 | validation: 0.4226235942967715]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.936750990154608		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.936750990154608 | validation: 0.5478696382373938]
	TIME [epoch: 5.72 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866691843524084		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.866691843524084 | validation: 0.7469191128696171]
	TIME [epoch: 5.71 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6700980091823575		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.6700980091823575 | validation: 0.7242417700239662]
	TIME [epoch: 5.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7609972168649782		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.7609972168649782 | validation: 0.6568866956826342]
	TIME [epoch: 5.73 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8142592645998774		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.8142592645998774 | validation: 0.4704557639826313]
	TIME [epoch: 5.72 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6445962231616527		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6445962231616527 | validation: 0.5253943888400775]
	TIME [epoch: 5.71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7094030257765		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7094030257765 | validation: 0.6896272926090024]
	TIME [epoch: 5.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333197353675098		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.7333197353675098 | validation: 0.8220227715394424]
	TIME [epoch: 5.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210138604852039		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.7210138604852039 | validation: 0.8375480691053497]
	TIME [epoch: 5.71 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7996351275452016		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.7996351275452016 | validation: 0.8592968015346522]
	TIME [epoch: 5.71 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7664673382778111		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.7664673382778111 | validation: 1.1077202240687214]
	TIME [epoch: 5.76 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8035142855026134		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.8035142855026134 | validation: 0.6703449529320468]
	TIME [epoch: 5.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278582385868853		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.7278582385868853 | validation: 0.5931014302237035]
	TIME [epoch: 5.71 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9893078649689097		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.9893078649689097 | validation: 0.7553241212431447]
	TIME [epoch: 5.72 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8759364463363186		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.8759364463363186 | validation: 0.5915583718716888]
	TIME [epoch: 5.72 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685624879144993		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.685624879144993 | validation: 0.43822403122726955]
	TIME [epoch: 5.72 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.641110446194018		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.641110446194018 | validation: 2.023121821398092]
	TIME [epoch: 5.72 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.083662677290837		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.083662677290837 | validation: 0.42338780034903184]
	TIME [epoch: 5.75 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3351741383660833		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.3351741383660833 | validation: 0.5294603956204507]
	TIME [epoch: 5.71 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247393427311948		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.7247393427311948 | validation: 0.47975427378879715]
	TIME [epoch: 5.72 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5935618721293369		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.5935618721293369 | validation: 0.6211312864273901]
	TIME [epoch: 5.71 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7338856441046736		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.7338856441046736 | validation: 1.495381426575541]
	TIME [epoch: 5.71 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0164237907766835		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.0164237907766835 | validation: 0.6624109662652404]
	TIME [epoch: 5.72 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6754120047946761		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.6754120047946761 | validation: 1.0747969202793592]
	TIME [epoch: 5.76 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8091995082742702		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.8091995082742702 | validation: 0.5549003944833725]
	TIME [epoch: 5.72 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7588464016894748		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7588464016894748 | validation: 1.3246509399254416]
	TIME [epoch: 5.71 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9653854361224765		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.9653854361224765 | validation: 0.5336671627026235]
	TIME [epoch: 5.72 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6185332776027365		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.6185332776027365 | validation: 0.42521078285093195]
	TIME [epoch: 5.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8445853010660795		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.8445853010660795 | validation: 0.6535425112043205]
	TIME [epoch: 5.71 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8432866591460976		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.8432866591460976 | validation: 0.43069118250727384]
	TIME [epoch: 5.71 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5881091440323748		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.5881091440323748 | validation: 0.9386322027205896]
	TIME [epoch: 5.74 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956028406157706		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.6956028406157706 | validation: 0.6391008847643387]
	TIME [epoch: 5.72 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7113126739798921		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7113126739798921 | validation: 0.7090769297187623]
	TIME [epoch: 5.71 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7920100967615074		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.7920100967615074 | validation: 0.6418739938971979]
	TIME [epoch: 5.71 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8534210374089743		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.8534210374089743 | validation: 0.46906890492250014]
	TIME [epoch: 5.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8689370302059536		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.8689370302059536 | validation: 0.6773001862632488]
	TIME [epoch: 5.71 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484552804170074		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.7484552804170074 | validation: 0.39189349752303865]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8983130734306499		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.8983130734306499 | validation: 0.6294398137545502]
	TIME [epoch: 5.71 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819782041746534		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.6819782041746534 | validation: 0.41963438788258023]
	TIME [epoch: 5.72 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641222197512361		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.5641222197512361 | validation: 0.4156436387843057]
	TIME [epoch: 5.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6270304366527057		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.6270304366527057 | validation: 0.8024437274181265]
	TIME [epoch: 5.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6748139296842163		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.6748139296842163 | validation: 0.36566483292973573]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199075295548429		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.7199075295548429 | validation: 0.39339178346280923]
	TIME [epoch: 5.73 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8309753272975795		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.8309753272975795 | validation: 0.40781174943478493]
	TIME [epoch: 5.72 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7672420760929846		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.7672420760929846 | validation: 0.43650781417921075]
	TIME [epoch: 5.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5915460929308654		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.5915460929308654 | validation: 0.47710894829435363]
	TIME [epoch: 5.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9106125197689188		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.9106125197689188 | validation: 0.6518261711665491]
	TIME [epoch: 5.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.806612903650408		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.806612903650408 | validation: 0.43215396248746074]
	TIME [epoch: 5.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7775294735385432		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.7775294735385432 | validation: 0.4757214941504708]
	TIME [epoch: 5.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7632871809658471		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.7632871809658471 | validation: 0.49223835255319354]
	TIME [epoch: 5.74 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6012739119175863		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.6012739119175863 | validation: 0.5022888162149437]
	TIME [epoch: 5.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956148989570647		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.6956148989570647 | validation: 0.5730507509429466]
	TIME [epoch: 5.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6101969192121828		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.6101969192121828 | validation: 0.8293085946797463]
	TIME [epoch: 5.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171408316103661		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.7171408316103661 | validation: 0.989725214717405]
	TIME [epoch: 5.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7409230312186316		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.7409230312186316 | validation: 0.3824834719301486]
	TIME [epoch: 5.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.654017960835085		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.654017960835085 | validation: 0.5024946429054948]
	TIME [epoch: 5.73 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.112678682762031		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.112678682762031 | validation: 1.9124644602256191]
	TIME [epoch: 5.71 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3083808176024367		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.3083808176024367 | validation: 0.5028536109625099]
	TIME [epoch: 5.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.804399481497631		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.804399481497631 | validation: 0.3881406454801243]
	TIME [epoch: 5.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8337778849371689		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.8337778849371689 | validation: 0.6699704656879399]
	TIME [epoch: 5.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7871527378896114		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.7871527378896114 | validation: 0.6095784359415994]
	TIME [epoch: 5.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6186588316322504		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6186588316322504 | validation: 0.5911068198258712]
	TIME [epoch: 5.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870632200642326		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6870632200642326 | validation: 0.3633894600406763]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6276914580694422		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.6276914580694422 | validation: 0.60791453873317]
	TIME [epoch: 5.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7727471242111005		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7727471242111005 | validation: 0.7477687874404151]
	TIME [epoch: 5.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6484054635581		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.6484054635581 | validation: 0.639325641266831]
	TIME [epoch: 5.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028866004938223		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.7028866004938223 | validation: 0.6832243756713265]
	TIME [epoch: 5.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6722757264047128		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.6722757264047128 | validation: 0.8312516413499426]
	TIME [epoch: 5.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243522266039673		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.7243522266039673 | validation: 0.900767502952883]
	TIME [epoch: 5.72 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717632754556564		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.717632754556564 | validation: 0.470163699647957]
	TIME [epoch: 5.71 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5807358352783226		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.5807358352783226 | validation: 0.5021668559799547]
	TIME [epoch: 5.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8268049941909357		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.8268049941909357 | validation: 0.5053892032662346]
	TIME [epoch: 5.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6067056477815302		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.6067056477815302 | validation: 0.4222205066047326]
	TIME [epoch: 5.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6658962341505918		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.6658962341505918 | validation: 0.4444609707380019]
	TIME [epoch: 5.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5401609826906045		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5401609826906045 | validation: 0.619463553146836]
	TIME [epoch: 5.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322863011557033		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.7322863011557033 | validation: 0.4944912242107856]
	TIME [epoch: 5.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073324558887852		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.7073324558887852 | validation: 0.4552998446567281]
	TIME [epoch: 5.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399103232090917		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.5399103232090917 | validation: 0.5332666524086082]
	TIME [epoch: 5.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7009661741108842		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.7009661741108842 | validation: 0.369258441831638]
	TIME [epoch: 5.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5940483459223042		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5940483459223042 | validation: 0.4510889572083312]
	TIME [epoch: 5.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269369799133037		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.5269369799133037 | validation: 0.7445653033675191]
	TIME [epoch: 5.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7682225377059888		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.7682225377059888 | validation: 0.7373656524976151]
	TIME [epoch: 5.71 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70669662680817		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.70669662680817 | validation: 0.490768493832594]
	TIME [epoch: 5.73 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7321523243969663		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.7321523243969663 | validation: 0.5407383767441883]
	TIME [epoch: 5.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6503989898492235		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.6503989898492235 | validation: 0.3738663953107843]
	TIME [epoch: 5.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8733105421562561		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.8733105421562561 | validation: 1.085387619864157]
	TIME [epoch: 5.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7493229810905817		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.7493229810905817 | validation: 0.46241860547562696]
	TIME [epoch: 5.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5366649393252751		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.5366649393252751 | validation: 0.49487233783091295]
	TIME [epoch: 5.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6284314096739254		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6284314096739254 | validation: 0.5930435449354036]
	TIME [epoch: 5.73 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5783847938038806		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.5783847938038806 | validation: 1.152857735934083]
	TIME [epoch: 5.71 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7673045973581055		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.7673045973581055 | validation: 0.569896523655167]
	TIME [epoch: 5.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8771498392628376		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.8771498392628376 | validation: 0.797648698303803]
	TIME [epoch: 5.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246638801292457		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.7246638801292457 | validation: 0.37857921617658885]
	TIME [epoch: 5.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6411936417959352		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.6411936417959352 | validation: 0.4447910412536706]
	TIME [epoch: 5.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6347570726363474		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.6347570726363474 | validation: 0.6257414816998554]
	TIME [epoch: 5.71 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744296072484299		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.744296072484299 | validation: 0.5761385965797239]
	TIME [epoch: 5.73 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6010171133305243		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.6010171133305243 | validation: 0.5200240507086283]
	TIME [epoch: 5.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5494377290533761		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.5494377290533761 | validation: 0.4441106854378928]
	TIME [epoch: 5.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5778217719627836		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.5778217719627836 | validation: 0.36702274528132606]
	TIME [epoch: 5.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7954571125809984		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.7954571125809984 | validation: 0.4317090613714817]
	TIME [epoch: 5.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7882131201328575		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.7882131201328575 | validation: 0.5891258319673132]
	TIME [epoch: 5.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706112562712174		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.6706112562712174 | validation: 0.4049561226131988]
	TIME [epoch: 5.73 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5487883727990318		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5487883727990318 | validation: 0.40969549454853654]
	TIME [epoch: 5.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5985924535173128		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.5985924535173128 | validation: 0.391208334942952]
	TIME [epoch: 5.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6719409761429209		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.6719409761429209 | validation: 0.48715237200209927]
	TIME [epoch: 5.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5892325069921069		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.5892325069921069 | validation: 0.34429624017607674]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5044571105372395		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.5044571105372395 | validation: 0.513109044964333]
	TIME [epoch: 5.71 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5386042830988345		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.5386042830988345 | validation: 0.43357281311966217]
	TIME [epoch: 5.72 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6015008214869901		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.6015008214869901 | validation: 0.5199645609487166]
	TIME [epoch: 5.73 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6992477166829081		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.6992477166829081 | validation: 0.48537563590045396]
	TIME [epoch: 5.71 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.693417689743449		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.693417689743449 | validation: 0.763643761956685]
	TIME [epoch: 5.71 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7825241833501917		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.7825241833501917 | validation: 0.43550978041182875]
	TIME [epoch: 5.71 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138234624510672		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5138234624510672 | validation: 0.5853254125377528]
	TIME [epoch: 5.71 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.553165863635767		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.553165863635767 | validation: 0.5585109014739225]
	TIME [epoch: 5.71 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6167314009091501		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.6167314009091501 | validation: 0.7339247015993787]
	TIME [epoch: 5.75 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7078807420078448		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.7078807420078448 | validation: 0.8849033099808686]
	TIME [epoch: 5.72 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8364446139328974		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.8364446139328974 | validation: 0.5948365063872743]
	TIME [epoch: 5.71 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6380221074767256		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.6380221074767256 | validation: 0.34088145541370396]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_526.pth
	Model improved!!!
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.620434237847802		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.620434237847802 | validation: 0.3678526842657673]
	TIME [epoch: 5.72 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5716279603784055		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.5716279603784055 | validation: 1.289346880016823]
	TIME [epoch: 5.71 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.783256492383063		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.783256492383063 | validation: 0.7463915722123778]
	TIME [epoch: 5.73 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6234498051404891		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.6234498051404891 | validation: 0.6965127809043545]
	TIME [epoch: 5.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086364447916413		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6086364447916413 | validation: 0.3410147464386221]
	TIME [epoch: 5.71 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5611344737136952		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.5611344737136952 | validation: 0.4715070465064343]
	TIME [epoch: 5.71 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526372198712665		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.526372198712665 | validation: 0.3631705817712057]
	TIME [epoch: 5.71 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48265458607841427		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.48265458607841427 | validation: 0.5916888655494884]
	TIME [epoch: 5.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6082775127584523		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.6082775127584523 | validation: 0.3280378624059623]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5900264200895575		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5900264200895575 | validation: 0.3182227580486712]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4757177618909487		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.4757177618909487 | validation: 0.3221787032661112]
	TIME [epoch: 5.71 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753703856015597		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.4753703856015597 | validation: 0.5806956799705746]
	TIME [epoch: 5.71 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5074818331679422		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.5074818331679422 | validation: 0.5610720590255389]
	TIME [epoch: 5.71 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590457093103353		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.590457093103353 | validation: 1.5918402272495658]
	TIME [epoch: 5.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1078340745542616		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.1078340745542616 | validation: 0.49165932650201755]
	TIME [epoch: 5.71 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6076208386545814		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.6076208386545814 | validation: 0.40984958598516913]
	TIME [epoch: 5.73 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6211399502616083		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.6211399502616083 | validation: 0.4871078386687489]
	TIME [epoch: 5.72 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5769280712235545		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.5769280712235545 | validation: 0.409774372327411]
	TIME [epoch: 5.71 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311910598551987		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.5311910598551987 | validation: 0.3590557000561456]
	TIME [epoch: 5.71 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6971161749820589		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.6971161749820589 | validation: 0.42658408537207726]
	TIME [epoch: 5.71 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6478939179325874		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.6478939179325874 | validation: 0.4417667155513857]
	TIME [epoch: 5.71 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47428112235955855		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.47428112235955855 | validation: 0.3484029732280591]
	TIME [epoch: 5.71 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4626631000631315		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.4626631000631315 | validation: 0.34969420637362986]
	TIME [epoch: 5.75 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.502987711794409		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.502987711794409 | validation: 0.5788979358152365]
	TIME [epoch: 5.71 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118230429060429		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.7118230429060429 | validation: 0.5288373925293081]
	TIME [epoch: 5.71 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590723532443287		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.5590723532443287 | validation: 0.4773921737311611]
	TIME [epoch: 5.71 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7261009977012378		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7261009977012378 | validation: 0.44756596873338567]
	TIME [epoch: 5.71 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600506438379529		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.5600506438379529 | validation: 0.3060970160451966]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541814535496177		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.541814535496177 | validation: 0.6643541767033357]
	TIME [epoch: 5.74 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5434795011565308		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.5434795011565308 | validation: 0.38263112787458675]
	TIME [epoch: 5.73 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5496597590557175		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.5496597590557175 | validation: 0.33852695318524734]
	TIME [epoch: 5.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47226180771848125		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.47226180771848125 | validation: 0.37810622733253213]
	TIME [epoch: 5.72 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.517329343131567		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.517329343131567 | validation: 0.4440561214820212]
	TIME [epoch: 5.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4267963959038506		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.4267963959038506 | validation: 0.5381570236920097]
	TIME [epoch: 5.71 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238368171143943		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.5238368171143943 | validation: 0.43017923163931154]
	TIME [epoch: 5.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4773436674599757		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.4773436674599757 | validation: 0.8976041395959601]
	TIME [epoch: 5.76 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6201351023661089		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.6201351023661089 | validation: 0.5015733682367028]
	TIME [epoch: 5.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5806720092148384		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5806720092148384 | validation: 0.4110699846303736]
	TIME [epoch: 5.72 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960670572256891		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.5960670572256891 | validation: 0.41233082701653234]
	TIME [epoch: 5.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7888347983852315		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.7888347983852315 | validation: 0.39105599819310444]
	TIME [epoch: 5.71 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6083290854505934		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.6083290854505934 | validation: 0.7110549433045835]
	TIME [epoch: 5.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5028221725203593		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.5028221725203593 | validation: 0.43141550384573124]
	TIME [epoch: 5.73 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224283798252601		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.5224283798252601 | validation: 0.5166579796332207]
	TIME [epoch: 5.71 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5614506632607775		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.5614506632607775 | validation: 0.9361216782933923]
	TIME [epoch: 5.71 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.659289355582088		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.659289355582088 | validation: 0.5067328676161089]
	TIME [epoch: 5.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5518318167924277		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.5518318167924277 | validation: 0.5549526561008049]
	TIME [epoch: 5.71 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5436042936750686		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.5436042936750686 | validation: 0.4100217359959345]
	TIME [epoch: 5.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507844963284068		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.5507844963284068 | validation: 0.5332175686158541]
	TIME [epoch: 5.71 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.595866136339635		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.595866136339635 | validation: 0.4754369808571118]
	TIME [epoch: 5.76 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5761443300365661		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.5761443300365661 | validation: 0.4111160240655516]
	TIME [epoch: 5.71 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4845421355126024		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.4845421355126024 | validation: 0.5037098411562558]
	TIME [epoch: 5.71 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5248498174555578		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5248498174555578 | validation: 0.5268951316623547]
	TIME [epoch: 5.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5045240525823252		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.5045240525823252 | validation: 0.4233492734659825]
	TIME [epoch: 5.71 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707306437163845		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.4707306437163845 | validation: 0.5054765644434441]
	TIME [epoch: 5.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112491729836822		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5112491729836822 | validation: 0.5098246676570405]
	TIME [epoch: 5.73 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5461078452325893		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.5461078452325893 | validation: 0.3157307963346285]
	TIME [epoch: 5.72 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6039671740012422		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6039671740012422 | validation: 0.3499177396514358]
	TIME [epoch: 5.71 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047005842036102		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.5047005842036102 | validation: 0.28536035395076564]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5250733195454907		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5250733195454907 | validation: 0.307509289945189]
	TIME [epoch: 5.72 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5766952102512041		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.5766952102512041 | validation: 0.4327651567088856]
	TIME [epoch: 5.72 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579064260581788		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.5579064260581788 | validation: 0.4292256867652442]
	TIME [epoch: 5.71 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290790881895118		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.5290790881895118 | validation: 0.34723423226800093]
	TIME [epoch: 5.75 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5638274794711684		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.5638274794711684 | validation: 0.33396739837428685]
	TIME [epoch: 5.71 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43359327386033886		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.43359327386033886 | validation: 0.4237494407564412]
	TIME [epoch: 5.72 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45044515588644174		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.45044515588644174 | validation: 0.4123589028184447]
	TIME [epoch: 5.72 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7140207170771489		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.7140207170771489 | validation: 0.4211464198146075]
	TIME [epoch: 5.71 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4934100424829678		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.4934100424829678 | validation: 0.38189530120894044]
	TIME [epoch: 5.71 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4933491971357149		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.4933491971357149 | validation: 0.38327693240778543]
	TIME [epoch: 5.73 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5672532310501346		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.5672532310501346 | validation: 0.38713445892124015]
	TIME [epoch: 5.72 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504912472173681		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.504912472173681 | validation: 0.6336112063700748]
	TIME [epoch: 5.71 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5935932669568091		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.5935932669568091 | validation: 0.5874711784191478]
	TIME [epoch: 5.71 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4928471196081501		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.4928471196081501 | validation: 0.3042090406953641]
	TIME [epoch: 5.72 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49623161525050485		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.49623161525050485 | validation: 0.4310710174501037]
	TIME [epoch: 5.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4806887971728907		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.4806887971728907 | validation: 0.5692961182161669]
	TIME [epoch: 5.72 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44857023572786914		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.44857023572786914 | validation: 0.36942578063816706]
	TIME [epoch: 5.74 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.556213390672682		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.556213390672682 | validation: 0.47211079332691863]
	TIME [epoch: 5.71 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4761665904534031		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.4761665904534031 | validation: 0.29696266199215676]
	TIME [epoch: 5.71 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46907797686499153		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.46907797686499153 | validation: 0.4107104346294133]
	TIME [epoch: 5.71 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47909939568498117		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.47909939568498117 | validation: 0.375312028112334]
	TIME [epoch: 5.71 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4150776733897832		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.4150776733897832 | validation: 0.3129517667918325]
	TIME [epoch: 5.71 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44361028750382553		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.44361028750382553 | validation: 0.296417578458787]
	TIME [epoch: 5.74 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41348139543400186		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.41348139543400186 | validation: 0.2639786308458376]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39777313895895056		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.39777313895895056 | validation: 0.697324986904006]
	TIME [epoch: 5.72 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5204875013465092		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.5204875013465092 | validation: 0.40928890700656356]
	TIME [epoch: 5.71 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45850381157201126		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.45850381157201126 | validation: 0.7370386102411084]
	TIME [epoch: 5.72 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6208934041303706		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.6208934041303706 | validation: 0.41868407214404846]
	TIME [epoch: 5.72 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215018852448524		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.4215018852448524 | validation: 0.2674795631513873]
	TIME [epoch: 5.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990883089488646		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.3990883089488646 | validation: 0.3466775416888773]
	TIME [epoch: 5.75 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5440426112914772		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.5440426112914772 | validation: 0.5839086652962301]
	TIME [epoch: 5.72 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47349032662767104		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.47349032662767104 | validation: 0.3775535604361058]
	TIME [epoch: 5.72 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46358286626254386		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.46358286626254386 | validation: 0.2859179012407037]
	TIME [epoch: 5.72 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49427203127371305		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.49427203127371305 | validation: 0.324629054184151]
	TIME [epoch: 5.71 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4236131897812705		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.4236131897812705 | validation: 1.5308382737426394]
	TIME [epoch: 5.72 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.868818073698101		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.868818073698101 | validation: 0.6110711682560016]
	TIME [epoch: 5.74 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46311135239348633		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.46311135239348633 | validation: 0.2457705687775057]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4869067500364918		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.4869067500364918 | validation: 0.31116813672312094]
	TIME [epoch: 5.72 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47916630121890175		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.47916630121890175 | validation: 0.3810235936068891]
	TIME [epoch: 5.71 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47449124961178113		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.47449124961178113 | validation: 0.35194705236005275]
	TIME [epoch: 5.71 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39070564865407703		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.39070564865407703 | validation: 0.29943788923172115]
	TIME [epoch: 5.71 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779518281574491		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.3779518281574491 | validation: 0.29364213286698554]
	TIME [epoch: 5.71 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39536957027506703		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.39536957027506703 | validation: 0.3820013128533728]
	TIME [epoch: 5.75 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3987711858815351		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.3987711858815351 | validation: 0.4503755628702429]
	TIME [epoch: 5.72 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45568782706015964		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.45568782706015964 | validation: 0.3021570121647965]
	TIME [epoch: 5.72 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3890693813112332		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.3890693813112332 | validation: 0.6444890601506188]
	TIME [epoch: 5.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4895918083944819		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.4895918083944819 | validation: 0.2812002518874452]
	TIME [epoch: 5.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38933274821669417		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.38933274821669417 | validation: 0.4829840413124111]
	TIME [epoch: 5.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4654592604578413		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.4654592604578413 | validation: 0.3341079995681929]
	TIME [epoch: 5.74 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44721481350416137		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.44721481350416137 | validation: 0.39693526082577363]
	TIME [epoch: 5.72 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42533266703909045		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.42533266703909045 | validation: 0.7413855558501378]
	TIME [epoch: 5.72 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5098467526977445		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.5098467526977445 | validation: 0.44124166308848617]
	TIME [epoch: 5.71 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49952261240473866		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.49952261240473866 | validation: 0.31970973001507025]
	TIME [epoch: 5.71 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5660605333554491		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.5660605333554491 | validation: 0.4475214625890064]
	TIME [epoch: 5.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49041813235546994		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.49041813235546994 | validation: 0.4068243736263956]
	TIME [epoch: 5.71 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41114157845765054		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.41114157845765054 | validation: 0.3193978837816197]
	TIME [epoch: 5.74 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35965662614711846		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.35965662614711846 | validation: 0.3657136078846658]
	TIME [epoch: 5.72 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5044821331100093		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.5044821331100093 | validation: 0.4337260857111913]
	TIME [epoch: 5.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5305343641107431		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5305343641107431 | validation: 0.42895867884718786]
	TIME [epoch: 5.71 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4952120923158113		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.4952120923158113 | validation: 0.35765632477115]
	TIME [epoch: 5.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4495340100947275		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.4495340100947275 | validation: 0.27262801308255596]
	TIME [epoch: 5.71 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3759640360801586		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.3759640360801586 | validation: 0.3019174055448856]
	TIME [epoch: 5.73 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.404814004096944		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.404814004096944 | validation: 0.31616088227158606]
	TIME [epoch: 5.73 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.385828860162303		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.385828860162303 | validation: 0.31058039512626395]
	TIME [epoch: 5.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.508512943496909		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.508512943496909 | validation: 0.33042079953250025]
	TIME [epoch: 5.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4100068035639131		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.4100068035639131 | validation: 0.4810447859567873]
	TIME [epoch: 5.71 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068499412591506		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.4068499412591506 | validation: 0.28230596488684895]
	TIME [epoch: 5.71 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4026814173406661		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.4026814173406661 | validation: 0.42628937808040973]
	TIME [epoch: 5.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43045589805076395		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.43045589805076395 | validation: 0.36088300079542424]
	TIME [epoch: 5.74 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.401174347745477		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.401174347745477 | validation: 0.49696806614072214]
	TIME [epoch: 5.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.372188853541991		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.372188853541991 | validation: 0.27885283406836586]
	TIME [epoch: 5.71 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3808024898639275		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.3808024898639275 | validation: 0.6102467375088066]
	TIME [epoch: 5.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5312943504247387		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.5312943504247387 | validation: 0.3974448091283432]
	TIME [epoch: 5.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41094989679652927		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.41094989679652927 | validation: 0.3751825400139482]
	TIME [epoch: 5.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3801986808235628		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.3801986808235628 | validation: 0.33784499862252565]
	TIME [epoch: 5.73 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3718399435962473		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.3718399435962473 | validation: 0.24573166242105385]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_660.pth
	Model improved!!!
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40770961794250904		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.40770961794250904 | validation: 0.32626850316844724]
	TIME [epoch: 5.72 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36970028601972726		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.36970028601972726 | validation: 0.2882825681924061]
	TIME [epoch: 5.72 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5105247677555235		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.5105247677555235 | validation: 0.48027545758393303]
	TIME [epoch: 5.72 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183881661703962		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.4183881661703962 | validation: 0.2552935539949844]
	TIME [epoch: 5.72 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4401689076316144		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.4401689076316144 | validation: 0.35801740812390265]
	TIME [epoch: 5.72 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43766412607444527		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.43766412607444527 | validation: 0.5424246443579565]
	TIME [epoch: 5.76 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4041007644503777		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.4041007644503777 | validation: 0.4836898828728286]
	TIME [epoch: 5.72 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39505896307814103		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.39505896307814103 | validation: 0.5336213306664882]
	TIME [epoch: 5.72 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46608577768872933		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.46608577768872933 | validation: 0.39375885415951106]
	TIME [epoch: 5.72 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4580321536730126		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.4580321536730126 | validation: 0.345129904283171]
	TIME [epoch: 5.72 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38229153623311424		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.38229153623311424 | validation: 0.27627712641173047]
	TIME [epoch: 5.72 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3708555774536698		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.3708555774536698 | validation: 0.28273545674673317]
	TIME [epoch: 5.75 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40856206469994966		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.40856206469994966 | validation: 0.33013059220265084]
	TIME [epoch: 5.73 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37539444524444854		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.37539444524444854 | validation: 0.24562836293400545]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_674.pth
	Model improved!!!
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40092519499103224		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.40092519499103224 | validation: 0.32303775005475616]
	TIME [epoch: 5.71 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3858157876763024		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.3858157876763024 | validation: 0.24495191292372676]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_676.pth
	Model improved!!!
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3878316948704744		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.3878316948704744 | validation: 0.22801729044923588]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41628394916999545		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.41628394916999545 | validation: 0.29975691696027346]
	TIME [epoch: 5.73 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.351381094471958		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.351381094471958 | validation: 0.3664914139535962]
	TIME [epoch: 5.74 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4545112223480102		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.4545112223480102 | validation: 0.35331151081966494]
	TIME [epoch: 5.72 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35222199239378915		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.35222199239378915 | validation: 0.26956347368718503]
	TIME [epoch: 5.71 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36425963129011985		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.36425963129011985 | validation: 0.31707550750406266]
	TIME [epoch: 5.71 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5370535882998565		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.5370535882998565 | validation: 0.3045001247084735]
	TIME [epoch: 5.71 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4286590299486035		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.4286590299486035 | validation: 0.2515160875979351]
	TIME [epoch: 5.71 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5393892891234808		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.5393892891234808 | validation: 0.2432513448932982]
	TIME [epoch: 5.75 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39430145891882373		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.39430145891882373 | validation: 0.6484972484995702]
	TIME [epoch: 5.72 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48707659759593447		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.48707659759593447 | validation: 0.42920598868378323]
	TIME [epoch: 5.71 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3846439730587682		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.3846439730587682 | validation: 0.2784579070209045]
	TIME [epoch: 5.71 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43109706921455293		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.43109706921455293 | validation: 0.3287526777252286]
	TIME [epoch: 5.71 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38438293133532486		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.38438293133532486 | validation: 0.3708610400007491]
	TIME [epoch: 5.71 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36354982597396457		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.36354982597396457 | validation: 0.2688082788589136]
	TIME [epoch: 5.73 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41020669474290045		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.41020669474290045 | validation: 0.3036889404405154]
	TIME [epoch: 5.74 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3399824855025979		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.3399824855025979 | validation: 0.4710127993658641]
	TIME [epoch: 5.72 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4009541768740206		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.4009541768740206 | validation: 0.3196501989184034]
	TIME [epoch: 5.71 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3565563034704536		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.3565563034704536 | validation: 0.35856434764394934]
	TIME [epoch: 5.71 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37086764128164973		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.37086764128164973 | validation: 0.3043158031602874]
	TIME [epoch: 5.71 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37007545688037596		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.37007545688037596 | validation: 0.34176559691807235]
	TIME [epoch: 5.71 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34539841067584953		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.34539841067584953 | validation: 0.5333584810396734]
	TIME [epoch: 5.75 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4126076916035652		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.4126076916035652 | validation: 0.26921943431176426]
	TIME [epoch: 5.72 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47498123448702123		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.47498123448702123 | validation: 0.2768529341453026]
	TIME [epoch: 5.71 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36160910608737906		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.36160910608737906 | validation: 0.23955426182880132]
	TIME [epoch: 5.71 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3633175961074401		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.3633175961074401 | validation: 0.2510193696403091]
	TIME [epoch: 5.71 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4224522012297984		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.4224522012297984 | validation: 0.4716586535086214]
	TIME [epoch: 5.71 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4637388938364412		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.4637388938364412 | validation: 0.33631357558894615]
	TIME [epoch: 5.72 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389958584810401		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.389958584810401 | validation: 0.29556571806422294]
	TIME [epoch: 5.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331049017200455		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.331049017200455 | validation: 0.34681005089320166]
	TIME [epoch: 5.72 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652190499380468		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.3652190499380468 | validation: 0.285397021315031]
	TIME [epoch: 5.71 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563618325262409		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.3563618325262409 | validation: 0.24196623052500835]
	TIME [epoch: 5.71 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534383726880394		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.3534383726880394 | validation: 0.35028786764406067]
	TIME [epoch: 5.71 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32846726911394875		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.32846726911394875 | validation: 0.2735440522816925]
	TIME [epoch: 5.71 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3840555574754979		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.3840555574754979 | validation: 0.28528308515945616]
	TIME [epoch: 5.75 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36323243671822825		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.36323243671822825 | validation: 0.2734064135308775]
	TIME [epoch: 5.72 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307989281499422		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.3307989281499422 | validation: 0.5604624250635597]
	TIME [epoch: 5.71 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4595160430441053		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.4595160430441053 | validation: 0.31049461957556257]
	TIME [epoch: 5.71 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38572481249147433		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.38572481249147433 | validation: 0.2611309348391788]
	TIME [epoch: 5.71 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3852858308684779		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.3852858308684779 | validation: 0.34163479579859696]
	TIME [epoch: 5.71 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40797013285310435		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.40797013285310435 | validation: 0.36297330188518595]
	TIME [epoch: 5.72 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36312560307668523		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.36312560307668523 | validation: 0.2782630068000352]
	TIME [epoch: 5.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3968448275818245		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.3968448275818245 | validation: 0.26272508813532486]
	TIME [epoch: 5.72 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3784514290721278		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.3784514290721278 | validation: 0.3458636198323727]
	TIME [epoch: 5.71 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37730904794554104		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.37730904794554104 | validation: 0.4787863479791112]
	TIME [epoch: 5.71 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4535598357109522		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.4535598357109522 | validation: 0.25051477044616544]
	TIME [epoch: 5.71 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696564267058489		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.3696564267058489 | validation: 0.2904405575284121]
	TIME [epoch: 5.71 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35048499333336447		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.35048499333336447 | validation: 0.43154820495621227]
	TIME [epoch: 5.75 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4292807444378249		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.4292807444378249 | validation: 0.35348073107871303]
	TIME [epoch: 5.72 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35331756083380134		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.35331756083380134 | validation: 0.6291104155995839]
	TIME [epoch: 5.71 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48009830921401014		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.48009830921401014 | validation: 0.2700579127352115]
	TIME [epoch: 5.71 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721134737663692		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.3721134737663692 | validation: 0.2726647707086696]
	TIME [epoch: 5.71 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36080574079080463		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.36080574079080463 | validation: 0.23044010497812953]
	TIME [epoch: 5.71 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3328005138287672		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.3328005138287672 | validation: 0.3214552364899582]
	TIME [epoch: 5.73 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3478927520766976		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.3478927520766976 | validation: 0.6969940318109648]
	TIME [epoch: 5.74 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43378897695236923		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.43378897695236923 | validation: 0.3096946557293389]
	TIME [epoch: 5.72 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490091665866741		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.3490091665866741 | validation: 0.4558042027455319]
	TIME [epoch: 5.71 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4227637615348625		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.4227637615348625 | validation: 0.30338297239495815]
	TIME [epoch: 5.71 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34244011773028515		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.34244011773028515 | validation: 0.2653581893602027]
	TIME [epoch: 5.72 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45509350388377084		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.45509350388377084 | validation: 0.2722096838755061]
	TIME [epoch: 5.72 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38986319350819676		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.38986319350819676 | validation: 0.23352187873168093]
	TIME [epoch: 5.75 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3762430457131728		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.3762430457131728 | validation: 0.502716789907985]
	TIME [epoch: 5.72 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39215218436246013		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.39215218436246013 | validation: 0.2861949043743345]
	TIME [epoch: 5.72 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3662038700495573		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.3662038700495573 | validation: 0.19552686654008647]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_740.pth
	Model improved!!!
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3152728400448095		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.3152728400448095 | validation: 0.22713351265146947]
	TIME [epoch: 5.71 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34258000194029675		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.34258000194029675 | validation: 0.37363178988153734]
	TIME [epoch: 5.71 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35402065868241017		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.35402065868241017 | validation: 0.24666584747186232]
	TIME [epoch: 5.72 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3774304754201086		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.3774304754201086 | validation: 0.3066943097315867]
	TIME [epoch: 5.74 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3249604746549284		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.3249604746549284 | validation: 0.35283569423736155]
	TIME [epoch: 5.72 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321521446235848		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.3321521446235848 | validation: 0.3053233647845525]
	TIME [epoch: 5.71 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33971895479410885		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.33971895479410885 | validation: 0.25131888383993733]
	TIME [epoch: 5.71 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37163600901238064		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.37163600901238064 | validation: 0.2494956581685029]
	TIME [epoch: 5.71 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31056282566353555		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.31056282566353555 | validation: 0.30430855203825985]
	TIME [epoch: 5.71 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31773898052319416		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.31773898052319416 | validation: 0.24848473238426402]
	TIME [epoch: 5.75 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44784571410005003		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.44784571410005003 | validation: 0.23435394425690312]
	TIME [epoch: 5.72 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3204705977183844		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.3204705977183844 | validation: 0.2158176958253638]
	TIME [epoch: 5.71 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3606262303226465		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.3606262303226465 | validation: 0.21000090802809296]
	TIME [epoch: 5.71 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907147537971474		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.2907147537971474 | validation: 0.28888789972233503]
	TIME [epoch: 5.71 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33326756050078743		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.33326756050078743 | validation: 0.3163537432224656]
	TIME [epoch: 5.71 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33061226749381845		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.33061226749381845 | validation: 0.2628328189110839]
	TIME [epoch: 5.72 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33147433137229143		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.33147433137229143 | validation: 0.285073316555152]
	TIME [epoch: 5.74 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35574313988288536		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.35574313988288536 | validation: 0.330694785877969]
	TIME [epoch: 5.72 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4005572857565102		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4005572857565102 | validation: 0.20165437339504355]
	TIME [epoch: 5.71 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34749086132498563		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.34749086132498563 | validation: 0.33304440386336637]
	TIME [epoch: 5.71 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2982448801067418		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.2982448801067418 | validation: 0.20574768236462476]
	TIME [epoch: 5.71 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32318916981641765		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.32318916981641765 | validation: 0.28156341981747296]
	TIME [epoch: 5.71 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3636317837995273		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.3636317837995273 | validation: 0.2963584498661071]
	TIME [epoch: 5.75 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29726111282199297		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.29726111282199297 | validation: 0.2939604308427362]
	TIME [epoch: 5.72 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352230328671565		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.352230328671565 | validation: 0.23334992514523137]
	TIME [epoch: 5.71 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3375950131433687		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.3375950131433687 | validation: 0.289185645308936]
	TIME [epoch: 5.71 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3821898739606758		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.3821898739606758 | validation: 0.2809274920494708]
	TIME [epoch: 5.71 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35479327390533744		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.35479327390533744 | validation: 0.32576421356578905]
	TIME [epoch: 5.71 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33527343957032524		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.33527343957032524 | validation: 0.25096213245079335]
	TIME [epoch: 5.72 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931576440335162		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.2931576440335162 | validation: 0.28754340054963723]
	TIME [epoch: 5.74 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3155400278517674		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.3155400278517674 | validation: 0.2427560357685013]
	TIME [epoch: 5.72 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33534353453776905		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.33534353453776905 | validation: 0.33993150705885]
	TIME [epoch: 5.71 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5178628161237371		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.5178628161237371 | validation: 0.7430333682880175]
	TIME [epoch: 5.71 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47356992491086625		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.47356992491086625 | validation: 0.2941700386811758]
	TIME [epoch: 5.71 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.341726287259402		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.341726287259402 | validation: 0.24571296563109285]
	TIME [epoch: 5.72 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32687564404474073		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.32687564404474073 | validation: 0.21372452632974528]
	TIME [epoch: 5.75 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008239434391345		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.3008239434391345 | validation: 0.7052213846029151]
	TIME [epoch: 5.72 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4501925276507872		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.4501925276507872 | validation: 0.21138367210999298]
	TIME [epoch: 5.71 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.327569215189814		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.327569215189814 | validation: 0.39909911430470657]
	TIME [epoch: 5.71 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363832263121791		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.363832263121791 | validation: 0.3565574415117125]
	TIME [epoch: 5.71 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37707284975121336		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.37707284975121336 | validation: 0.20887237271474185]
	TIME [epoch: 5.71 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442085505651161		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.3442085505651161 | validation: 0.41835767345052205]
	TIME [epoch: 5.72 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3368950373645785		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.3368950373645785 | validation: 0.23369634608332882]
	TIME [epoch: 5.74 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3055832293231693		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.3055832293231693 | validation: 0.22990967279528945]
	TIME [epoch: 5.72 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32779556686035416		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.32779556686035416 | validation: 0.27265111497598155]
	TIME [epoch: 5.71 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686003519157265		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.2686003519157265 | validation: 0.3111427207818652]
	TIME [epoch: 5.71 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2849563636696337		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.2849563636696337 | validation: 0.3786249992181327]
	TIME [epoch: 5.71 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.343402109945023		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.343402109945023 | validation: 0.294731228167973]
	TIME [epoch: 5.72 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5529065145656755		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.5529065145656755 | validation: 0.3257948301294616]
	TIME [epoch: 5.75 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3210083924503065		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.3210083924503065 | validation: 0.2263603106050474]
	TIME [epoch: 5.72 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29657361308053065		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.29657361308053065 | validation: 0.19535061551712032]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_791.pth
	Model improved!!!
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25110283945109774		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.25110283945109774 | validation: 0.21394840021360914]
	TIME [epoch: 5.71 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29451200431389224		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.29451200431389224 | validation: 0.23359097848300686]
	TIME [epoch: 5.71 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35721781450984036		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.35721781450984036 | validation: 0.2019720225438487]
	TIME [epoch: 5.71 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28976282223166033		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.28976282223166033 | validation: 0.220934353397412]
	TIME [epoch: 5.72 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27182020749016494		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.27182020749016494 | validation: 0.24464249804267935]
	TIME [epoch: 5.74 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2978953778862908		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.2978953778862908 | validation: 0.24468394563057957]
	TIME [epoch: 5.71 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576460526158184		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3576460526158184 | validation: 0.22232791696882495]
	TIME [epoch: 5.71 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.302853857978602		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.302853857978602 | validation: 0.22571631429238254]
	TIME [epoch: 5.71 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949748672209785		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.2949748672209785 | validation: 0.3309199144130036]
	TIME [epoch: 5.71 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3564266072856811		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.3564266072856811 | validation: 0.19632012473883062]
	TIME [epoch: 5.71 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083894267745187		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.5083894267745187 | validation: 0.210068577917181]
	TIME [epoch: 5.75 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3173893021142911		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.3173893021142911 | validation: 0.22687553227976934]
	TIME [epoch: 5.72 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709064269216732		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.2709064269216732 | validation: 0.3777320985528547]
	TIME [epoch: 5.71 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385707762134754		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.3385707762134754 | validation: 0.19748110583638542]
	TIME [epoch: 5.71 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27320817271729836		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.27320817271729836 | validation: 0.2053467168504492]
	TIME [epoch: 5.71 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26746697902973227		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.26746697902973227 | validation: 0.21414214678633214]
	TIME [epoch: 5.71 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038118752541095		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.3038118752541095 | validation: 0.3039581457268533]
	TIME [epoch: 5.72 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32603368539833893		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.32603368539833893 | validation: 0.19940618511041358]
	TIME [epoch: 5.74 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28584992025367645		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.28584992025367645 | validation: 0.24089528746930214]
	TIME [epoch: 5.71 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27692973668267296		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.27692973668267296 | validation: 0.17538069019049587]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_811.pth
	Model improved!!!
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27302703129276207		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.27302703129276207 | validation: 0.24038361219793966]
	TIME [epoch: 5.71 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681260985727502		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.2681260985727502 | validation: 0.20389137490751183]
	TIME [epoch: 5.71 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26742885058690447		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.26742885058690447 | validation: 0.25618259701009366]
	TIME [epoch: 5.71 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898590744047294		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.2898590744047294 | validation: 0.30300374849922185]
	TIME [epoch: 5.75 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26334674681381726		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.26334674681381726 | validation: 0.26117949971379434]
	TIME [epoch: 5.72 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26896570462134606		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.26896570462134606 | validation: 0.23949224493008076]
	TIME [epoch: 5.71 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29752164882642723		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.29752164882642723 | validation: 0.5679431992663149]
	TIME [epoch: 5.71 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41889631980410547		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.41889631980410547 | validation: 0.252718624587876]
	TIME [epoch: 5.71 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28119258877892606		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.28119258877892606 | validation: 0.2475982074466452]
	TIME [epoch: 5.71 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3050350415798938		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.3050350415798938 | validation: 0.24097264527900364]
	TIME [epoch: 5.72 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2818723254870182		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.2818723254870182 | validation: 0.1702654435420466]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_822.pth
	Model improved!!!
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27601407039328185		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.27601407039328185 | validation: 0.2295339862851826]
	TIME [epoch: 5.71 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3160682190316495		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.3160682190316495 | validation: 0.19762977563036938]
	TIME [epoch: 5.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32657853707023043		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.32657853707023043 | validation: 0.2529170767190426]
	TIME [epoch: 5.71 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24653913666171537		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.24653913666171537 | validation: 0.5295775215229286]
	TIME [epoch: 5.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3941988276958037		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.3941988276958037 | validation: 0.24867587418573067]
	TIME [epoch: 5.71 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29203899344419165		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.29203899344419165 | validation: 0.23256642206006203]
	TIME [epoch: 5.74 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24939741263376544		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.24939741263376544 | validation: 0.17731078542330558]
	TIME [epoch: 5.71 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24728875238922016		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.24728875238922016 | validation: 0.16534457689639112]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_830.pth
	Model improved!!!
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505751612338886		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.2505751612338886 | validation: 0.2232396890347536]
	TIME [epoch: 5.71 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28751304949256773		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.28751304949256773 | validation: 0.2031829354737906]
	TIME [epoch: 5.71 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2957036902401811		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.2957036902401811 | validation: 0.3260377376711116]
	TIME [epoch: 5.71 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3045288713708211		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.3045288713708211 | validation: 0.20457031313798735]
	TIME [epoch: 5.72 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709198540579063		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.2709198540579063 | validation: 0.1774855055016072]
	TIME [epoch: 5.71 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2561088358422553		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.2561088358422553 | validation: 0.2869216063839496]
	TIME [epoch: 5.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34221589677879394		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.34221589677879394 | validation: 0.22854709892462968]
	TIME [epoch: 5.69 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24514536281494198		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.24514536281494198 | validation: 0.3155174536650892]
	TIME [epoch: 5.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3002364946936433		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.3002364946936433 | validation: 0.3392869451142111]
	TIME [epoch: 5.69 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29217572583845763		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.29217572583845763 | validation: 0.25618073001011965]
	TIME [epoch: 5.69 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2588695346044413		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.2588695346044413 | validation: 0.18430233880205463]
	TIME [epoch: 5.73 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626414185050585		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.2626414185050585 | validation: 0.2375528145869436]
	TIME [epoch: 5.71 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4003069312869747		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.4003069312869747 | validation: 0.1707695181739028]
	TIME [epoch: 5.69 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2780796974587793		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.2780796974587793 | validation: 0.1861531145703981]
	TIME [epoch: 5.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25535074161908133		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.25535074161908133 | validation: 0.19613696755095333]
	TIME [epoch: 5.69 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694462035116287		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.2694462035116287 | validation: 0.20117143483199487]
	TIME [epoch: 5.69 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28129826322404117		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.28129826322404117 | validation: 0.17393587232002047]
	TIME [epoch: 5.71 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3203208677553073		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.3203208677553073 | validation: 0.23946263781062802]
	TIME [epoch: 5.72 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26946376000077715		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.26946376000077715 | validation: 0.17847831474299228]
	TIME [epoch: 5.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23933768404136724		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.23933768404136724 | validation: 0.20588429590731067]
	TIME [epoch: 5.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24803167999373293		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.24803167999373293 | validation: 0.20587959414395815]
	TIME [epoch: 5.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785049586143371		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.2785049586143371 | validation: 0.2079106246602148]
	TIME [epoch: 5.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510269099493791		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2510269099493791 | validation: 0.20530159213138036]
	TIME [epoch: 5.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28951436038519346		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.28951436038519346 | validation: 0.33492662229211895]
	TIME [epoch: 5.73 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29366430631714846		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.29366430631714846 | validation: 0.19808082421241766]
	TIME [epoch: 5.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23865142023953867		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.23865142023953867 | validation: 0.1827904007766876]
	TIME [epoch: 5.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26821085889290397		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.26821085889290397 | validation: 0.20041488558504894]
	TIME [epoch: 5.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602019443845886		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.2602019443845886 | validation: 0.24944083771044384]
	TIME [epoch: 5.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29501776735241486		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.29501776735241486 | validation: 0.3481381179756349]
	TIME [epoch: 5.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27774827543019304		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.27774827543019304 | validation: 0.18429809370449132]
	TIME [epoch: 5.72 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2555057190844338		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.2555057190844338 | validation: 0.2584916760782997]
	TIME [epoch: 5.72 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2564026068551105		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.2564026068551105 | validation: 0.2802104201257693]
	TIME [epoch: 5.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2702150599212695		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.2702150599212695 | validation: 0.19779020828639232]
	TIME [epoch: 5.71 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2308489023095784		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.2308489023095784 | validation: 0.30065817428302966]
	TIME [epoch: 5.69 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26212507575163485		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.26212507575163485 | validation: 0.21997133524502022]
	TIME [epoch: 5.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923044332166822		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.2923044332166822 | validation: 0.2735477434182689]
	TIME [epoch: 5.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2577110022723169		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.2577110022723169 | validation: 0.1791021934570842]
	TIME [epoch: 5.74 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23114416655830733		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.23114416655830733 | validation: 0.19067867937387717]
	TIME [epoch: 5.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890448778549694		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.2890448778549694 | validation: 0.16241226163345515]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_869.pth
	Model improved!!!
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27322599521500057		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.27322599521500057 | validation: 0.18894188977719267]
	TIME [epoch: 5.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22893481312726754		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.22893481312726754 | validation: 0.20553779483464193]
	TIME [epoch: 5.71 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25933329376790415		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.25933329376790415 | validation: 0.1584044968403577]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_872.pth
	Model improved!!!
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23517852060701666		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.23517852060701666 | validation: 0.20706069163691762]
	TIME [epoch: 5.74 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538212621981921		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.3538212621981921 | validation: 0.20576061952870034]
	TIME [epoch: 5.73 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22911909030009034		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.22911909030009034 | validation: 0.18937360897696154]
	TIME [epoch: 5.72 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21682289157099072		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.21682289157099072 | validation: 0.20813340018043697]
	TIME [epoch: 5.71 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25555783123781034		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.25555783123781034 | validation: 0.22970082298658745]
	TIME [epoch: 5.71 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2412497912566646		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.2412497912566646 | validation: 0.19759769851383535]
	TIME [epoch: 5.71 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22825141290127915		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.22825141290127915 | validation: 0.1790142735987544]
	TIME [epoch: 5.72 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29089739379570306		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.29089739379570306 | validation: 0.16947656448047646]
	TIME [epoch: 5.76 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25308467218752234		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.25308467218752234 | validation: 0.19269879650135402]
	TIME [epoch: 5.72 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2718006403726425		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.2718006403726425 | validation: 0.2216164741122966]
	TIME [epoch: 5.72 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23930109824902127		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.23930109824902127 | validation: 0.17124278335211762]
	TIME [epoch: 5.72 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22878454815294863		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.22878454815294863 | validation: 0.16273396708600985]
	TIME [epoch: 5.72 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22801177292915098		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.22801177292915098 | validation: 0.22518636345416837]
	TIME [epoch: 5.72 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24840306192537984		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.24840306192537984 | validation: 0.1925683643721153]
	TIME [epoch: 5.75 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22838505416598587		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.22838505416598587 | validation: 0.17734856600707347]
	TIME [epoch: 5.73 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2454344197322746		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.2454344197322746 | validation: 0.20738132548258173]
	TIME [epoch: 5.72 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24447773588540567		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.24447773588540567 | validation: 0.17457731878945779]
	TIME [epoch: 5.72 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24168797035729722		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.24168797035729722 | validation: 0.23576625772714443]
	TIME [epoch: 5.72 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24616567193695627		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.24616567193695627 | validation: 0.2943930088019022]
	TIME [epoch: 5.72 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2550507528409836		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.2550507528409836 | validation: 0.17083327572611373]
	TIME [epoch: 5.72 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2397414824411569		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.2397414824411569 | validation: 0.2196057812315329]
	TIME [epoch: 5.76 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25822595055668257		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.25822595055668257 | validation: 0.22586025974076784]
	TIME [epoch: 5.72 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26344624890581636		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.26344624890581636 | validation: 0.21301398479778094]
	TIME [epoch: 5.72 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519188260042155		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.2519188260042155 | validation: 0.19112252344179886]
	TIME [epoch: 5.72 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2968138291039518		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.2968138291039518 | validation: 0.2959207647122974]
	TIME [epoch: 5.72 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738874596761639		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.2738874596761639 | validation: 0.39845146159612915]
	TIME [epoch: 5.72 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28477652703822526		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.28477652703822526 | validation: 0.2789705837877273]
	TIME [epoch: 5.75 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2542701447558209		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.2542701447558209 | validation: 0.18487763997352288]
	TIME [epoch: 5.73 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22500509499555213		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.22500509499555213 | validation: 0.19244715715050587]
	TIME [epoch: 5.72 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22829737368745961		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.22829737368745961 | validation: 0.16981248700577686]
	TIME [epoch: 5.72 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20966858284716908		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.20966858284716908 | validation: 0.23905588353031676]
	TIME [epoch: 5.72 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23209798276238722		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.23209798276238722 | validation: 0.1995578809699279]
	TIME [epoch: 5.72 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22712295595143844		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.22712295595143844 | validation: 0.18943637294728333]
	TIME [epoch: 5.72 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19954929768813978		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.19954929768813978 | validation: 0.25216719799454407]
	TIME [epoch: 5.76 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22693736661635683		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.22693736661635683 | validation: 0.25501722751906547]
	TIME [epoch: 5.72 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2341320798492111		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.2341320798492111 | validation: 0.15861554822015683]
	TIME [epoch: 5.72 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22384116250243857		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.22384116250243857 | validation: 0.16258829755078064]
	TIME [epoch: 5.72 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20585094192667663		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.20585094192667663 | validation: 0.1612159225982739]
	TIME [epoch: 5.72 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23394899974394615		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.23394899974394615 | validation: 0.185280885422175]
	TIME [epoch: 5.72 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20946477302152255		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.20946477302152255 | validation: 0.1729534348167806]
	TIME [epoch: 5.75 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2300578940335936		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.2300578940335936 | validation: 0.17855490976057872]
	TIME [epoch: 5.73 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23389804043272247		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.23389804043272247 | validation: 0.19776540641899001]
	TIME [epoch: 5.72 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20839260060392134		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.20839260060392134 | validation: 0.28422498682749703]
	TIME [epoch: 5.72 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26801016999041627		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.26801016999041627 | validation: 0.1644378392174167]
	TIME [epoch: 5.72 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692285586725619		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.2692285586725619 | validation: 0.22341809150131994]
	TIME [epoch: 5.72 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23670310401659508		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.23670310401659508 | validation: 0.165899079935269]
	TIME [epoch: 5.72 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21597373366049005		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.21597373366049005 | validation: 0.17300130618451387]
	TIME [epoch: 5.76 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200403703239062		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.200403703239062 | validation: 0.17501299437841827]
	TIME [epoch: 5.72 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22911079060200604		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.22911079060200604 | validation: 0.19118082997380306]
	TIME [epoch: 5.72 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23897875745912		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.23897875745912 | validation: 0.158568847997967]
	TIME [epoch: 5.72 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2305120936805072		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.2305120936805072 | validation: 0.15315016886991]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_923.pth
	Model improved!!!
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22282783099291043		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.22282783099291043 | validation: 0.14407410642415044]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_924.pth
	Model improved!!!
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2392244331411493		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.2392244331411493 | validation: 0.22893328274164973]
	TIME [epoch: 5.75 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2542744506334622		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.2542744506334622 | validation: 0.16823196159894915]
	TIME [epoch: 5.71 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21654701979558585		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.21654701979558585 | validation: 0.16252959898181332]
	TIME [epoch: 5.71 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25913152501889575		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.25913152501889575 | validation: 0.20841604763417956]
	TIME [epoch: 5.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758187912035641		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.2758187912035641 | validation: 0.18934379332273843]
	TIME [epoch: 5.71 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2470268124400874		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.2470268124400874 | validation: 0.17655387171911793]
	TIME [epoch: 5.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655077951310376		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.2655077951310376 | validation: 0.20615663756820687]
	TIME [epoch: 5.72 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2649055014553281		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.2649055014553281 | validation: 0.1766195012464125]
	TIME [epoch: 5.73 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2286653897530251		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.2286653897530251 | validation: 0.23453077436460987]
	TIME [epoch: 5.71 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24239922579482082		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.24239922579482082 | validation: 0.18719898993819192]
	TIME [epoch: 5.71 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23997631068179542		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.23997631068179542 | validation: 0.17402570364841782]
	TIME [epoch: 5.71 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24073358950248025		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.24073358950248025 | validation: 0.29508650429528543]
	TIME [epoch: 5.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616139334872098		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.2616139334872098 | validation: 0.2569690032017782]
	TIME [epoch: 5.71 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3271144533764767		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.3271144533764767 | validation: 0.2325089633573441]
	TIME [epoch: 5.73 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.233699725866939		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.233699725866939 | validation: 0.2255724440522591]
	TIME [epoch: 5.72 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22467905830194537		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.22467905830194537 | validation: 0.17878115846527867]
	TIME [epoch: 5.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22801390751851291		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.22801390751851291 | validation: 0.1767144797753114]
	TIME [epoch: 5.71 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20197506580195684		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.20197506580195684 | validation: 0.1655755659459198]
	TIME [epoch: 5.71 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2348877756265057		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.2348877756265057 | validation: 0.17390843635178982]
	TIME [epoch: 5.71 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27324581058424047		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.27324581058424047 | validation: 0.20450674455907952]
	TIME [epoch: 5.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22063549805839155		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.22063549805839155 | validation: 0.19114121147429836]
	TIME [epoch: 5.74 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20739963724380975		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.20739963724380975 | validation: 0.19106580617508948]
	TIME [epoch: 5.71 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22576322988660963		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.22576322988660963 | validation: 0.18007153750851995]
	TIME [epoch: 5.71 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2169624885208099		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.2169624885208099 | validation: 0.16048937567034824]
	TIME [epoch: 5.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2057820286070271		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.2057820286070271 | validation: 0.1877298033167123]
	TIME [epoch: 5.71 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23505683004858086		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.23505683004858086 | validation: 0.17390475286348156]
	TIME [epoch: 5.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20900816075870277		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.20900816075870277 | validation: 0.22131302914473586]
	TIME [epoch: 5.73 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22519380876666326		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.22519380876666326 | validation: 0.34346164628787795]
	TIME [epoch: 5.71 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26589639099254775		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.26589639099254775 | validation: 0.46738396584507413]
	TIME [epoch: 5.71 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3131437520538937		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.3131437520538937 | validation: 0.1903379142332377]
	TIME [epoch: 5.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22807143406753125		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.22807143406753125 | validation: 0.20123740089649098]
	TIME [epoch: 5.71 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21551710527081402		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.21551710527081402 | validation: 0.2099795027019977]
	TIME [epoch: 5.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21283052221542414		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.21283052221542414 | validation: 0.15008649396520915]
	TIME [epoch: 5.71 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2019303399079136		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.2019303399079136 | validation: 0.18696425964822666]
	TIME [epoch: 5.74 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2474368581798987		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.2474368581798987 | validation: 0.2246441853401234]
	TIME [epoch: 5.71 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24247606001255742		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.24247606001255742 | validation: 0.2536155444083977]
	TIME [epoch: 5.71 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2561220789740411		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.2561220789740411 | validation: 0.2766100733801015]
	TIME [epoch: 5.71 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22909775766747353		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.22909775766747353 | validation: 0.20102298030351787]
	TIME [epoch: 5.71 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2354271146595221		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.2354271146595221 | validation: 0.25761667991645887]
	TIME [epoch: 5.71 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22808476332979838		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.22808476332979838 | validation: 0.15732930622987343]
	TIME [epoch: 5.73 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19038901351476106		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.19038901351476106 | validation: 0.1774177185335735]
	TIME [epoch: 5.73 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20706396836770527		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.20706396836770527 | validation: 0.19035401514315822]
	TIME [epoch: 5.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19543694547037144		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.19543694547037144 | validation: 0.16818407523945786]
	TIME [epoch: 5.71 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19741464166069045		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.19741464166069045 | validation: 0.22303346121911538]
	TIME [epoch: 5.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21827548011176506		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.21827548011176506 | validation: 0.2411541569917307]
	TIME [epoch: 5.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21430290014812384		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.21430290014812384 | validation: 0.16768806129632693]
	TIME [epoch: 5.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22972725356498958		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.22972725356498958 | validation: 0.26232302482682923]
	TIME [epoch: 5.75 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21675949737068384		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.21675949737068384 | validation: 0.1726975562032353]
	TIME [epoch: 5.71 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958777023807916		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.1958777023807916 | validation: 0.21971298024718497]
	TIME [epoch: 5.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20134036913323816		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.20134036913323816 | validation: 0.20277379032202503]
	TIME [epoch: 5.71 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21428444876400007		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.21428444876400007 | validation: 0.14694988996517772]
	TIME [epoch: 5.71 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20886446567654748		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.20886446567654748 | validation: 0.1848782102408668]
	TIME [epoch: 5.71 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27227516836063675		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.27227516836063675 | validation: 0.23419986845654875]
	TIME [epoch: 5.73 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2093967327846562		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.2093967327846562 | validation: 0.216057917049937]
	TIME [epoch: 5.72 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23090421112370646		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.23090421112370646 | validation: 0.16597290548003676]
	TIME [epoch: 5.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21263934039779292		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.21263934039779292 | validation: 0.2282973129113271]
	TIME [epoch: 5.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24718050617269743		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.24718050617269743 | validation: 0.18882096134566045]
	TIME [epoch: 5.71 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20402322008983795		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.20402322008983795 | validation: 0.2574758033700343]
	TIME [epoch: 5.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22994522676314327		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.22994522676314327 | validation: 0.1328624357707307]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_983.pth
	Model improved!!!
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1827122562280979		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.1827122562280979 | validation: 0.1849019429812062]
	TIME [epoch: 5.75 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.203132995601495		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.203132995601495 | validation: 0.17355951491611912]
	TIME [epoch: 5.71 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19839182441754968		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.19839182441754968 | validation: 0.149021457748359]
	TIME [epoch: 5.71 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2070315021722688		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.2070315021722688 | validation: 0.14226183372973894]
	TIME [epoch: 5.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19373784536114202		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.19373784536114202 | validation: 0.145394754841064]
	TIME [epoch: 5.71 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19217472817973177		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.19217472817973177 | validation: 0.14572900922535753]
	TIME [epoch: 5.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21883693504963253		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.21883693504963253 | validation: 0.16991712949028148]
	TIME [epoch: 5.73 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20947747645266523		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.20947747645266523 | validation: 0.14626574502956788]
	TIME [epoch: 5.72 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26727529973935493		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.26727529973935493 | validation: 0.1635955828892443]
	TIME [epoch: 5.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19999002161531834		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.19999002161531834 | validation: 0.2992065921222715]
	TIME [epoch: 5.71 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24202068449181408		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.24202068449181408 | validation: 0.23484855201157231]
	TIME [epoch: 5.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20683634319170927		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.20683634319170927 | validation: 0.14501845571256305]
	TIME [epoch: 5.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22252312841833974		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.22252312841833974 | validation: 0.17736270506244883]
	TIME [epoch: 5.71 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19789463480118785		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.19789463480118785 | validation: 0.24225029597693798]
	TIME [epoch: 5.75 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20099781181106904		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.20099781181106904 | validation: 0.20956663645135654]
	TIME [epoch: 5.71 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19468362391276525		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.19468362391276525 | validation: 0.17688401538662227]
	TIME [epoch: 5.69 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20159178991373544		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.20159178991373544 | validation: 0.16180034715076289]
	TIME [epoch: 5.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899831708584136		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.1899831708584136 | validation: 0.18218045510012523]
	TIME [epoch: 5.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29297406833741013		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.29297406833741013 | validation: 0.1494388094861518]
	TIME [epoch: 5.71 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20096328713900374		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.20096328713900374 | validation: 0.16787866816914598]
	TIME [epoch: 5.72 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838609682170563		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.2838609682170563 | validation: 0.16393532224038412]
	TIME [epoch: 5.71 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22455671014698436		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.22455671014698436 | validation: 0.17254266425146023]
	TIME [epoch: 5.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23031384319152248		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.23031384319152248 | validation: 0.1363256860066914]
	TIME [epoch: 5.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19827644264648492		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.19827644264648492 | validation: 0.13490576247428995]
	TIME [epoch: 5.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1798825726330934		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.1798825726330934 | validation: 0.2205106693381162]
	TIME [epoch: 5.71 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1907187343037403		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.1907187343037403 | validation: 0.1838545632993077]
	TIME [epoch: 5.71 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1904932286584484		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.1904932286584484 | validation: 0.1416373882717409]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18735975737625538		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.18735975737625538 | validation: 0.17558130805389213]
	TIME [epoch: 5.71 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19417923280376623		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.19417923280376623 | validation: 0.27074429223051627]
	TIME [epoch: 5.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2297622181178864		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.2297622181178864 | validation: 0.26217559267518675]
	TIME [epoch: 5.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125588260827929		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.2125588260827929 | validation: 0.1696353862749151]
	TIME [epoch: 5.71 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19600486007700768		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.19600486007700768 | validation: 0.1568163123903308]
	TIME [epoch: 5.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18809713956389973		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.18809713956389973 | validation: 0.15011351274370005]
	TIME [epoch: 5.73 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20481909095321665		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.20481909095321665 | validation: 0.1583091553939027]
	TIME [epoch: 5.72 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20128576405347673		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.20128576405347673 | validation: 0.23307319032093254]
	TIME [epoch: 5.71 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2397288427571239		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.2397288427571239 | validation: 0.1694936897066487]
	TIME [epoch: 5.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18810926945325723		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.18810926945325723 | validation: 0.1283913409509963]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1020.pth
	Model improved!!!
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18331168011430568		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.18331168011430568 | validation: 0.15634976833516004]
	TIME [epoch: 5.71 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20448805186057428		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.20448805186057428 | validation: 0.1354445545371363]
	TIME [epoch: 5.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2195253084807528		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.2195253084807528 | validation: 0.1730666795932926]
	TIME [epoch: 5.74 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20248288808274606		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.20248288808274606 | validation: 0.1595897359077286]
	TIME [epoch: 5.71 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23904600217065192		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.23904600217065192 | validation: 0.1737316570707209]
	TIME [epoch: 5.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1984769632420702		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.1984769632420702 | validation: 0.13579864066743402]
	TIME [epoch: 5.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1691623760358393		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.1691623760358393 | validation: 0.1353453329560605]
	TIME [epoch: 5.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972741545957127		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.1972741545957127 | validation: 0.12883664564579178]
	TIME [epoch: 5.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19876275304380325		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.19876275304380325 | validation: 0.26442129301053174]
	TIME [epoch: 5.73 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2319569520631437		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.2319569520631437 | validation: 0.16634389731437252]
	TIME [epoch: 5.72 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1928498838958643		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.1928498838958643 | validation: 0.1651189190372031]
	TIME [epoch: 5.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2169186435616236		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.2169186435616236 | validation: 0.20109426415871626]
	TIME [epoch: 5.69 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18609564057123792		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.18609564057123792 | validation: 0.15945161108945557]
	TIME [epoch: 5.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19720316323276493		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.19720316323276493 | validation: 0.17894762037711937]
	TIME [epoch: 5.71 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.195008440609863		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.195008440609863 | validation: 0.12729621634542845]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1035.pth
	Model improved!!!
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18376410067219787		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.18376410067219787 | validation: 0.17334039266576853]
	TIME [epoch: 5.73 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19911748355615436		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.19911748355615436 | validation: 0.16036185479551188]
	TIME [epoch: 5.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18722967414887115		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.18722967414887115 | validation: 0.1377983068198148]
	TIME [epoch: 5.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19035561054706793		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.19035561054706793 | validation: 0.14896339786009388]
	TIME [epoch: 5.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22253817923220112		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.22253817923220112 | validation: 0.16644330832630602]
	TIME [epoch: 5.69 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23243661589976866		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.23243661589976866 | validation: 0.14612438434201705]
	TIME [epoch: 5.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19800292453498408		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.19800292453498408 | validation: 0.1833280215775659]
	TIME [epoch: 5.72 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20024010078734528		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.20024010078734528 | validation: 0.14324773865224621]
	TIME [epoch: 5.71 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1852402496347476		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.1852402496347476 | validation: 0.3559216310022626]
	TIME [epoch: 5.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23923174936696978		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.23923174936696978 | validation: 0.16430531397428952]
	TIME [epoch: 5.69 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19610921526162045		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.19610921526162045 | validation: 0.17706349524941323]
	TIME [epoch: 5.71 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19133917420235214		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.19133917420235214 | validation: 0.1500645285735818]
	TIME [epoch: 5.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20667405493638075		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.20667405493638075 | validation: 0.15751840250152002]
	TIME [epoch: 5.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17026399188807506		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.17026399188807506 | validation: 0.17997267734326486]
	TIME [epoch: 5.73 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18419068799474328		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.18419068799474328 | validation: 0.18061834318634673]
	TIME [epoch: 5.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2099151796518245		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.2099151796518245 | validation: 0.13754755110253708]
	TIME [epoch: 5.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18982284814698602		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.18982284814698602 | validation: 0.18736004380627416]
	TIME [epoch: 5.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1925952363391713		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.1925952363391713 | validation: 0.18889342212129076]
	TIME [epoch: 5.69 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18556189201122913		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.18556189201122913 | validation: 0.1697391117927504]
	TIME [epoch: 5.69 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19244648478196758		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.19244648478196758 | validation: 0.31012810071146935]
	TIME [epoch: 5.72 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21952569371065686		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.21952569371065686 | validation: 0.3213187003971227]
	TIME [epoch: 5.71 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24200105658507007		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.24200105658507007 | validation: 0.15881631069209456]
	TIME [epoch: 5.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17657862338263872		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.17657862338263872 | validation: 0.1576420781966724]
	TIME [epoch: 5.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20074156408076846		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.20074156408076846 | validation: 0.1606428579687051]
	TIME [epoch: 5.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18751060483486182		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.18751060483486182 | validation: 0.19208323710340516]
	TIME [epoch: 5.71 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24228234715758196		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.24228234715758196 | validation: 0.17675699566345812]
	TIME [epoch: 5.69 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18211608817295089		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.18211608817295089 | validation: 0.13918119904571327]
	TIME [epoch: 5.74 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1802573684985101		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.1802573684985101 | validation: 0.15193347783219055]
	TIME [epoch: 5.69 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917907292223692		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.1917907292223692 | validation: 0.1301124206093737]
	TIME [epoch: 5.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17752992929609313		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.17752992929609313 | validation: 0.16026757024353244]
	TIME [epoch: 5.69 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18480023476042504		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.18480023476042504 | validation: 0.13512334069882095]
	TIME [epoch: 5.69 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726648475879575		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.1726648475879575 | validation: 0.13937633118791865]
	TIME [epoch: 5.69 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19667099668846313		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.19667099668846313 | validation: 0.14978423368953628]
	TIME [epoch: 5.72 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1956863956892716		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.1956863956892716 | validation: 0.15009399610587004]
	TIME [epoch: 5.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18049532739492397		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.18049532739492397 | validation: 0.1286930588012945]
	TIME [epoch: 5.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1875565186368392		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.1875565186368392 | validation: 0.18297972072726393]
	TIME [epoch: 5.69 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18540286840822834		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.18540286840822834 | validation: 0.12186741973524415]
	TIME [epoch: 5.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1072.pth
	Model improved!!!
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16806805640156172		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.16806805640156172 | validation: 0.12356466089948154]
	TIME [epoch: 5.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17870170808995967		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.17870170808995967 | validation: 0.13421311032087502]
	TIME [epoch: 5.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1661451424714037		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.1661451424714037 | validation: 0.1433800473602083]
	TIME [epoch: 5.73 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20131561252973246		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.20131561252973246 | validation: 0.1743757163284591]
	TIME [epoch: 5.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20348848320743002		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.20348848320743002 | validation: 0.1630391174741886]
	TIME [epoch: 5.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19579354859360182		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.19579354859360182 | validation: 0.19928369656507922]
	TIME [epoch: 5.7 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1824114367127194		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.1824114367127194 | validation: 0.13263850841191283]
	TIME [epoch: 5.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17924639875336723		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.17924639875336723 | validation: 0.11868927924509493]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1080.pth
	Model improved!!!
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16914404386350027		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.16914404386350027 | validation: 0.16054902651113181]
	TIME [epoch: 5.75 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2151739710577737		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.2151739710577737 | validation: 0.19273469586329392]
	TIME [epoch: 5.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18379834955493166		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.18379834955493166 | validation: 0.16155529608175756]
	TIME [epoch: 5.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17662981469988986		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.17662981469988986 | validation: 0.16014085192375965]
	TIME [epoch: 5.71 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.178717379204109		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.178717379204109 | validation: 0.1602687919100926]
	TIME [epoch: 5.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18727362396108876		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.18727362396108876 | validation: 0.1529268483713537]
	TIME [epoch: 5.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19226337273762195		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.19226337273762195 | validation: 0.1994692520595715]
	TIME [epoch: 5.71 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18904397611132945		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.18904397611132945 | validation: 0.1582196922017539]
	TIME [epoch: 5.73 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16429097015218436		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.16429097015218436 | validation: 0.14272719358445726]
	TIME [epoch: 5.71 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19734107956204192		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.19734107956204192 | validation: 0.1845248804082967]
	TIME [epoch: 5.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19504788880763027		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.19504788880763027 | validation: 0.1418036978422783]
	TIME [epoch: 5.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22124617448722228		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.22124617448722228 | validation: 0.17598502201014213]
	TIME [epoch: 5.71 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18102291705111956		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.18102291705111956 | validation: 0.14271999995080167]
	TIME [epoch: 5.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17558552294838675		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.17558552294838675 | validation: 0.13583415885513425]
	TIME [epoch: 5.73 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18829013097171912		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.18829013097171912 | validation: 0.16693482963887768]
	TIME [epoch: 5.72 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17619336275894995		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.17619336275894995 | validation: 0.1488423991546658]
	TIME [epoch: 5.71 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17963942339499978		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.17963942339499978 | validation: 0.13640544859787185]
	TIME [epoch: 5.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16500341494819504		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.16500341494819504 | validation: 0.13232091354076653]
	TIME [epoch: 5.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1748375086094407		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.1748375086094407 | validation: 0.12456963614179828]
	TIME [epoch: 5.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1754439292262711		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.1754439292262711 | validation: 0.16274089146643297]
	TIME [epoch: 5.71 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23971471942237935		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.23971471942237935 | validation: 0.1666620528717314]
	TIME [epoch: 5.74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17788752464277538		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.17788752464277538 | validation: 0.1294084516167623]
	TIME [epoch: 5.71 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16751541960063707		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.16751541960063707 | validation: 0.1622487519404826]
	TIME [epoch: 5.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1807334994841432		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.1807334994841432 | validation: 0.14586588193457087]
	TIME [epoch: 5.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17633709067875622		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.17633709067875622 | validation: 0.1435652326503071]
	TIME [epoch: 5.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19172082555634878		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.19172082555634878 | validation: 0.14226775406718328]
	TIME [epoch: 5.71 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17222650613925056		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.17222650613925056 | validation: 0.17111433789140065]
	TIME [epoch: 5.74 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21274703631447855		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.21274703631447855 | validation: 0.14474112302712644]
	TIME [epoch: 5.72 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17097574108595953		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.17097574108595953 | validation: 0.11754772992685446]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1109.pth
	Model improved!!!
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612103754720962		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.1612103754720962 | validation: 0.1386599914883412]
	TIME [epoch: 5.71 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19403713499938743		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.19403713499938743 | validation: 0.14682239973232786]
	TIME [epoch: 5.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1684440921598687		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.1684440921598687 | validation: 0.15229555346032064]
	TIME [epoch: 5.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17353119506692669		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.17353119506692669 | validation: 0.1640741099141296]
	TIME [epoch: 5.73 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1934275504607271		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.1934275504607271 | validation: 0.1420355904472038]
	TIME [epoch: 5.73 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16538488993236358		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.16538488993236358 | validation: 0.12281062625462863]
	TIME [epoch: 5.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15506113899209178		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.15506113899209178 | validation: 0.1324237215359155]
	TIME [epoch: 5.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15922047196369957		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.15922047196369957 | validation: 0.18272906488301977]
	TIME [epoch: 5.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19077437671078779		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.19077437671078779 | validation: 0.18461512314019018]
	TIME [epoch: 5.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21025615950285337		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.21025615950285337 | validation: 0.1624138774600165]
	TIME [epoch: 5.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18734836699891888		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.18734836699891888 | validation: 0.12254976544346585]
	TIME [epoch: 5.74 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17494802010055183		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.17494802010055183 | validation: 0.1379952918161336]
	TIME [epoch: 5.71 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16989166097296926		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.16989166097296926 | validation: 0.17235671054199495]
	TIME [epoch: 5.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18407648045695182		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.18407648045695182 | validation: 0.21665541737986985]
	TIME [epoch: 5.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796574093906533		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.1796574093906533 | validation: 0.11507983989283396]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1124.pth
	Model improved!!!
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17167973024586247		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.17167973024586247 | validation: 0.1562672059009496]
	TIME [epoch: 5.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17025464979321112		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.17025464979321112 | validation: 0.12257178963981845]
	TIME [epoch: 5.71 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16423280434127926		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.16423280434127926 | validation: 0.1533710795464814]
	TIME [epoch: 5.73 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18490784456320275		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.18490784456320275 | validation: 0.13764357402234714]
	TIME [epoch: 5.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17351965644980666		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.17351965644980666 | validation: 0.12514219753855693]
	TIME [epoch: 5.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.161174557963286		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.161174557963286 | validation: 0.13556913450964828]
	TIME [epoch: 5.69 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701429713395189		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.1701429713395189 | validation: 0.16162181286216942]
	TIME [epoch: 5.69 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18003017470511712		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.18003017470511712 | validation: 0.14907044758797627]
	TIME [epoch: 5.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20029359854370876		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.20029359854370876 | validation: 0.13810690593678307]
	TIME [epoch: 5.73 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15578665055284804		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.15578665055284804 | validation: 0.17400441193786417]
	TIME [epoch: 5.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1795411405542553		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.1795411405542553 | validation: 0.13980691695902134]
	TIME [epoch: 5.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17689201956182926		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.17689201956182926 | validation: 0.11870957513045421]
	TIME [epoch: 5.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16732784871634104		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.16732784871634104 | validation: 0.13295156438509023]
	TIME [epoch: 5.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16728165842399675		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.16728165842399675 | validation: 0.13495649229448345]
	TIME [epoch: 5.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17293203156891054		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.17293203156891054 | validation: 0.13098382964485278]
	TIME [epoch: 5.71 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2080047891926054		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.2080047891926054 | validation: 0.20034339147505315]
	TIME [epoch: 5.72 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18127956961264022		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.18127956961264022 | validation: 0.2038027531855736]
	TIME [epoch: 5.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17513239329306277		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.17513239329306277 | validation: 0.1191892358082755]
	TIME [epoch: 5.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16169044881482325		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.16169044881482325 | validation: 0.14755933853403633]
	TIME [epoch: 5.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1787812422441551		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.1787812422441551 | validation: 0.1623725811698985]
	TIME [epoch: 5.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17838474650611164		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.17838474650611164 | validation: 0.2664268135143229]
	TIME [epoch: 5.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20646876527499128		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.20646876527499128 | validation: 0.14759225074771729]
	TIME [epoch: 5.73 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15868857928764055		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.15868857928764055 | validation: 0.139613863075994]
	TIME [epoch: 5.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16424345867028906		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.16424345867028906 | validation: 0.13530484323336484]
	TIME [epoch: 5.69 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1720263849332258		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.1720263849332258 | validation: 0.13366173442010423]
	TIME [epoch: 5.69 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16807109191328726		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.16807109191328726 | validation: 0.14738000989299999]
	TIME [epoch: 5.71 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1785318975631005		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.1785318975631005 | validation: 0.1527938982490806]
	TIME [epoch: 5.69 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16577634693877988		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.16577634693877988 | validation: 0.135022383218352]
	TIME [epoch: 5.71 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16412432607705094		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.16412432607705094 | validation: 0.18526981206524618]
	TIME [epoch: 5.72 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1833155409187468		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.1833155409187468 | validation: 0.15616628377951547]
	TIME [epoch: 5.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17070170026085257		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.17070170026085257 | validation: 0.1546856568429695]
	TIME [epoch: 5.69 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16323226426621365		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.16323226426621365 | validation: 0.14018731702684253]
	TIME [epoch: 5.69 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16302082348610158		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.16302082348610158 | validation: 0.14170867936677664]
	TIME [epoch: 5.69 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1839880320967047		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.1839880320967047 | validation: 0.1447738208915799]
	TIME [epoch: 5.69 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17113613869765779		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.17113613869765779 | validation: 0.11966837232453421]
	TIME [epoch: 5.73 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16173330814750836		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.16173330814750836 | validation: 0.12593437473489835]
	TIME [epoch: 5.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16099950115526024		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.16099950115526024 | validation: 0.133795707587498]
	TIME [epoch: 5.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689382340341533		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.1689382340341533 | validation: 0.1237284697720305]
	TIME [epoch: 5.69 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16242289601532583		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.16242289601532583 | validation: 0.14504864549978186]
	TIME [epoch: 5.69 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1720557070782498		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.1720557070782498 | validation: 0.12318243023802751]
	TIME [epoch: 5.69 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17428618198102427		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.17428618198102427 | validation: 0.11826023003904794]
	TIME [epoch: 5.71 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171386130724001		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.171386130724001 | validation: 0.1296933408599531]
	TIME [epoch: 5.73 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15904292726906916		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.15904292726906916 | validation: 0.12341641073892141]
	TIME [epoch: 5.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15526588803161062		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.15526588803161062 | validation: 0.12566865864316987]
	TIME [epoch: 5.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498516467114142		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.1498516467114142 | validation: 0.12489203219556858]
	TIME [epoch: 5.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15781264171034798		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.15781264171034798 | validation: 0.14787710210504146]
	TIME [epoch: 5.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16498615056836924		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.16498615056836924 | validation: 0.13701354792472642]
	TIME [epoch: 5.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17946734863829011		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.17946734863829011 | validation: 0.17445436510720833]
	TIME [epoch: 5.73 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1703979440467782		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.1703979440467782 | validation: 0.13870108952208107]
	TIME [epoch: 5.71 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16714187510760586		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.16714187510760586 | validation: 0.13568274591190577]
	TIME [epoch: 5.7 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15804604023336374		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.15804604023336374 | validation: 0.10822535460434907]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1175.pth
	Model improved!!!
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15266292111229693		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.15266292111229693 | validation: 0.117710944994582]
	TIME [epoch: 5.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16396720107535273		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.16396720107535273 | validation: 0.14603369821037354]
	TIME [epoch: 5.7 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18047670230323254		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.18047670230323254 | validation: 0.1353684171062681]
	TIME [epoch: 5.71 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15121625038662181		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.15121625038662181 | validation: 0.12352892670024104]
	TIME [epoch: 5.73 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16407063813422157		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.16407063813422157 | validation: 0.24609305682226676]
	TIME [epoch: 5.7 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2052929161328196		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.2052929161328196 | validation: 0.12238183297139416]
	TIME [epoch: 5.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646576514920287		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.1646576514920287 | validation: 0.13338122264974583]
	TIME [epoch: 5.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16751924839650745		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.16751924839650745 | validation: 0.13810618146773146]
	TIME [epoch: 5.7 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16798537838897498		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.16798537838897498 | validation: 0.1760261215761718]
	TIME [epoch: 5.7 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17273844794218152		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.17273844794218152 | validation: 0.13367186310558565]
	TIME [epoch: 5.73 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15426808785661414		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.15426808785661414 | validation: 0.12475490296217472]
	TIME [epoch: 5.71 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16823423533241516		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.16823423533241516 | validation: 0.1333333587822641]
	TIME [epoch: 5.7 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1688968916907506		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.1688968916907506 | validation: 0.12161208404159403]
	TIME [epoch: 5.7 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15011653856965484		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.15011653856965484 | validation: 0.12153612599439864]
	TIME [epoch: 5.7 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15580350341834293		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.15580350341834293 | validation: 0.12258576084358612]
	TIME [epoch: 5.7 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19241405170117715		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.19241405170117715 | validation: 0.2882016923480708]
	TIME [epoch: 5.71 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21946117021894485		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.21946117021894485 | validation: 0.12752008576097204]
	TIME [epoch: 5.72 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477138348460092		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.1477138348460092 | validation: 0.1258194951866876]
	TIME [epoch: 5.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15408739943373026		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.15408739943373026 | validation: 0.1325139313513496]
	TIME [epoch: 5.7 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796044651319338		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.1796044651319338 | validation: 0.1448678400159026]
	TIME [epoch: 5.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621420786328201		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.1621420786328201 | validation: 0.12586881068561068]
	TIME [epoch: 5.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16752950349922724		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.16752950349922724 | validation: 0.13156118549347717]
	TIME [epoch: 5.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15001186248845264		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.15001186248845264 | validation: 0.1417962560736092]
	TIME [epoch: 5.73 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16716862958602952		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.16716862958602952 | validation: 0.12789112609692227]
	TIME [epoch: 5.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15519480739561936		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.15519480739561936 | validation: 0.14419926578851505]
	TIME [epoch: 5.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17390677123479187		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.17390677123479187 | validation: 0.14231002104760326]
	TIME [epoch: 5.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15971689842326725		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.15971689842326725 | validation: 0.17575292675657575]
	TIME [epoch: 5.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1700077277845196		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.1700077277845196 | validation: 0.15260555693283173]
	TIME [epoch: 5.71 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16670742819389667		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.16670742819389667 | validation: 0.11694565920219209]
	TIME [epoch: 5.71 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570914059747764		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.1570914059747764 | validation: 0.12621986400448948]
	TIME [epoch: 5.73 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15301185347845428		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.15301185347845428 | validation: 0.1234834175816857]
	TIME [epoch: 5.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1604644579387684		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.1604644579387684 | validation: 0.14772324164230832]
	TIME [epoch: 5.71 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15581029843758254		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.15581029843758254 | validation: 0.12809759669807988]
	TIME [epoch: 5.71 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17160605246052155		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.17160605246052155 | validation: 0.11688752510259807]
	TIME [epoch: 5.7 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16089564956791697		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.16089564956791697 | validation: 0.11936070681588518]
	TIME [epoch: 5.71 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522094105134911		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.1522094105134911 | validation: 0.1309013742606999]
	TIME [epoch: 5.74 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15532729704594134		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.15532729704594134 | validation: 0.13600498960235646]
	TIME [epoch: 5.71 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17304443903367986		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.17304443903367986 | validation: 0.2052112876508135]
	TIME [epoch: 5.71 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19379700631212443		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.19379700631212443 | validation: 0.1325779420444096]
	TIME [epoch: 5.71 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15497974726249908		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.15497974726249908 | validation: 0.13750141652062234]
	TIME [epoch: 5.71 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17525698291546304		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.17525698291546304 | validation: 0.1706560993693255]
	TIME [epoch: 5.71 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16801538028742946		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.16801538028742946 | validation: 0.14276210053233232]
	TIME [epoch: 5.72 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15702746360630232		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.15702746360630232 | validation: 0.12286235610179787]
	TIME [epoch: 5.73 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1595161228534713		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.1595161228534713 | validation: 0.15273433695882582]
	TIME [epoch: 5.71 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17895495507991188		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.17895495507991188 | validation: 0.15651850693036756]
	TIME [epoch: 5.71 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15905152367862063		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.15905152367862063 | validation: 0.145975819718725]
	TIME [epoch: 5.71 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17942681849431333		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.17942681849431333 | validation: 0.15427210908413166]
	TIME [epoch: 5.71 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15072114768934405		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.15072114768934405 | validation: 0.14142570565991563]
	TIME [epoch: 5.71 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676401322763309		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.1676401322763309 | validation: 0.16575476361948205]
	TIME [epoch: 5.74 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16458316616750795		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.16458316616750795 | validation: 0.13014568779733984]
	TIME [epoch: 5.71 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1731237470279056		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.1731237470279056 | validation: 0.171734008767464]
	TIME [epoch: 5.7 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16788036954472957		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.16788036954472957 | validation: 0.141300966467477]
	TIME [epoch: 5.71 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584510139533584		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.1584510139533584 | validation: 0.14185606256994304]
	TIME [epoch: 5.71 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18537766505407968		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.18537766505407968 | validation: 0.153642525248675]
	TIME [epoch: 5.71 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17551408542751465		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.17551408542751465 | validation: 0.1364918307090798]
	TIME [epoch: 5.7 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1631974450028329		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.1631974450028329 | validation: 0.17265159190485502]
	TIME [epoch: 5.73 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1619928503872755		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.1619928503872755 | validation: 0.1311017451361945]
	TIME [epoch: 5.71 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15396679585191173		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.15396679585191173 | validation: 0.1376794648349644]
	TIME [epoch: 5.71 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15088001731820572		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.15088001731820572 | validation: 0.12849452154515692]
	TIME [epoch: 5.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14575472535377731		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.14575472535377731 | validation: 0.12873149519957308]
	TIME [epoch: 5.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14913014973908323		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.14913014973908323 | validation: 0.13416387083315162]
	TIME [epoch: 5.7 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1641795159059361		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.1641795159059361 | validation: 0.12570691232532796]
	TIME [epoch: 5.73 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1578675584646102		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.1578675584646102 | validation: 0.1314109160252402]
	TIME [epoch: 5.72 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15120616408854393		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.15120616408854393 | validation: 0.16269884958085318]
	TIME [epoch: 5.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16967000939998897		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.16967000939998897 | validation: 0.16137831508551878]
	TIME [epoch: 5.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19311890485409958		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.19311890485409958 | validation: 0.13573485168581167]
	TIME [epoch: 5.71 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15959901590052267		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.15959901590052267 | validation: 0.16379991133960928]
	TIME [epoch: 5.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16011388151817743		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.16011388151817743 | validation: 0.14687572086080306]
	TIME [epoch: 5.71 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15731261034342364		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.15731261034342364 | validation: 0.15182372169438957]
	TIME [epoch: 5.73 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17775162025360902		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.17775162025360902 | validation: 0.13488175600117122]
	TIME [epoch: 5.71 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15833840158939289		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.15833840158939289 | validation: 0.13255712510310955]
	TIME [epoch: 5.71 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1607884734651661		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.1607884734651661 | validation: 0.1312015335644772]
	TIME [epoch: 5.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15169643110488631		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.15169643110488631 | validation: 0.12893078154399792]
	TIME [epoch: 5.71 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15289556134818533		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.15289556134818533 | validation: 0.13087141213711634]
	TIME [epoch: 5.7 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15874525040996743		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.15874525040996743 | validation: 0.18182990808780075]
	TIME [epoch: 5.74 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17319797702761722		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.17319797702761722 | validation: 0.15227785773899163]
	TIME [epoch: 5.72 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17707142964466419		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.17707142964466419 | validation: 0.1479309563034542]
	TIME [epoch: 5.7 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15986635592252274		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.15986635592252274 | validation: 0.11262943673459054]
	TIME [epoch: 5.69 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15303401722006307		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.15303401722006307 | validation: 0.1434113240635191]
	TIME [epoch: 5.7 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16530157533745943		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.16530157533745943 | validation: 0.13141534685727652]
	TIME [epoch: 5.71 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1602195240762676		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.1602195240762676 | validation: 0.14838996170106222]
	TIME [epoch: 5.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1624135177708907		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.1624135177708907 | validation: 0.12037533833423147]
	TIME [epoch: 5.74 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15017124718032443		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.15017124718032443 | validation: 0.12822800920514096]
	TIME [epoch: 5.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16032409513099952		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.16032409513099952 | validation: 0.1341283538925019]
	TIME [epoch: 5.72 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15088959642766858		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.15088959642766858 | validation: 0.12174765031310003]
	TIME [epoch: 5.69 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15066498484093369		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.15066498484093369 | validation: 0.11877620725613852]
	TIME [epoch: 5.71 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14915655783905965		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.14915655783905965 | validation: 0.11828233984429234]
	TIME [epoch: 5.69 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585550886967572		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.1585550886967572 | validation: 0.1821445729605369]
	TIME [epoch: 5.74 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1780401096620444		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.1780401096620444 | validation: 0.12814419660652568]
	TIME [epoch: 5.7 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14585213943480385		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.14585213943480385 | validation: 0.13640709018428518]
	TIME [epoch: 5.71 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15759615122898876		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.15759615122898876 | validation: 0.14332867826019438]
	TIME [epoch: 5.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15530224303931264		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.15530224303931264 | validation: 0.1378341306867499]
	TIME [epoch: 5.71 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577559860770062		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.1577559860770062 | validation: 0.14431737874204806]
	TIME [epoch: 5.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622898306573216		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.1622898306573216 | validation: 0.12565163971380724]
	TIME [epoch: 5.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15102655780579366		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.15102655780579366 | validation: 0.1351994624068873]
	TIME [epoch: 5.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15361434692242243		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.15361434692242243 | validation: 0.11806293045590571]
	TIME [epoch: 5.71 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14723275092566576		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.14723275092566576 | validation: 0.1509508466912965]
	TIME [epoch: 5.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506689289858523		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.1506689289858523 | validation: 0.12178489483765076]
	TIME [epoch: 5.69 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15703790933846848		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.15703790933846848 | validation: 0.20465014377042734]
	TIME [epoch: 5.7 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18603293614346758		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.18603293614346758 | validation: 0.1646156609525627]
	TIME [epoch: 5.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16473243898055634		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.16473243898055634 | validation: 0.12758279561092598]
	TIME [epoch: 5.73 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16630169002896467		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.16630169002896467 | validation: 0.12741470710925476]
	TIME [epoch: 5.71 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14798446134573978		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.14798446134573978 | validation: 0.13899636857834258]
	TIME [epoch: 5.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566332177027985		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.1566332177027985 | validation: 0.11943081850546908]
	TIME [epoch: 5.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543207596091492		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.1543207596091492 | validation: 0.11558148053554955]
	TIME [epoch: 5.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14950839090741028		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.14950839090741028 | validation: 0.12834946932877572]
	TIME [epoch: 5.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16097293138248436		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.16097293138248436 | validation: 0.16127540407865165]
	TIME [epoch: 5.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16257717211940792		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.16257717211940792 | validation: 0.14230802003265758]
	TIME [epoch: 5.74 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524083941340658		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.1524083941340658 | validation: 0.14690472802249535]
	TIME [epoch: 5.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15310683862732727		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.15310683862732727 | validation: 0.1136191076094471]
	TIME [epoch: 5.7 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570700267443104		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.1570700267443104 | validation: 0.11754316869538917]
	TIME [epoch: 5.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14150405561826607		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.14150405561826607 | validation: 0.11302951329356407]
	TIME [epoch: 5.7 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14654481949220574		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.14654481949220574 | validation: 0.12535713593813447]
	TIME [epoch: 5.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555031573280447		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.1555031573280447 | validation: 0.1127243494801872]
	TIME [epoch: 5.73 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14776980656017386		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.14776980656017386 | validation: 0.11593114459479399]
	TIME [epoch: 5.72 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16348209142883346		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.16348209142883346 | validation: 0.12548094850424288]
	TIME [epoch: 5.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15947280089789942		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.15947280089789942 | validation: 0.11098880091068594]
	TIME [epoch: 5.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14480613179641894		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.14480613179641894 | validation: 0.12101265825873402]
	TIME [epoch: 5.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527206579746034		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.1527206579746034 | validation: 0.12372628502700388]
	TIME [epoch: 5.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15404999921132398		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.15404999921132398 | validation: 0.11267663462010351]
	TIME [epoch: 5.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15271875742189833		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.15271875742189833 | validation: 0.12482846879094343]
	TIME [epoch: 5.74 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15345726028433587		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.15345726028433587 | validation: 0.11776773692472021]
	TIME [epoch: 5.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14175807999776371		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.14175807999776371 | validation: 0.1178742746552729]
	TIME [epoch: 5.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14855903748349575		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.14855903748349575 | validation: 0.1290126128129342]
	TIME [epoch: 5.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15342762854139735		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.15342762854139735 | validation: 0.1068324936350027]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1300.pth
	Model improved!!!
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15177734613606653		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.15177734613606653 | validation: 0.14703912059907548]
	TIME [epoch: 5.72 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796736135188757		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.1796736135188757 | validation: 0.12082187858575591]
	TIME [epoch: 5.75 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14804675375434195		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.14804675375434195 | validation: 0.1303607202933366]
	TIME [epoch: 5.71 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15775852221486758		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.15775852221486758 | validation: 0.11213147500784863]
	TIME [epoch: 5.72 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15512583101711994		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.15512583101711994 | validation: 0.12100075966134842]
	TIME [epoch: 5.73 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14198107063673454		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.14198107063673454 | validation: 0.12175792189932721]
	TIME [epoch: 5.71 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462677109145464		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.1462677109145464 | validation: 0.13032497267411827]
	TIME [epoch: 5.71 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1456874549316178		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.1456874549316178 | validation: 0.11647352501557631]
	TIME [epoch: 5.72 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14940220214049907		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.14940220214049907 | validation: 0.14578399684671736]
	TIME [epoch: 5.74 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16024367006846987		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.16024367006846987 | validation: 0.12584618004835335]
	TIME [epoch: 5.71 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14617008571209897		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.14617008571209897 | validation: 0.11739601271906622]
	TIME [epoch: 5.71 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14890494375878333		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.14890494375878333 | validation: 0.13636971838261613]
	TIME [epoch: 5.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15184718134249292		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.15184718134249292 | validation: 0.11779840058717266]
	TIME [epoch: 5.71 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14889055117177108		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.14889055117177108 | validation: 0.1250185079030339]
	TIME [epoch: 5.72 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14047919255134464		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.14047919255134464 | validation: 0.119444504725301]
	TIME [epoch: 5.76 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14439808068254883		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.14439808068254883 | validation: 0.11506755088531058]
	TIME [epoch: 5.72 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14514673739964426		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.14514673739964426 | validation: 0.17424975359157774]
	TIME [epoch: 5.71 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18094612227430495		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.18094612227430495 | validation: 0.12212236447106749]
	TIME [epoch: 5.71 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14743543226254596		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.14743543226254596 | validation: 0.11957579435011485]
	TIME [epoch: 5.71 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14834398785052205		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.14834398785052205 | validation: 0.12138356661225919]
	TIME [epoch: 5.7 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515433813996256		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.1515433813996256 | validation: 0.11909183924459996]
	TIME [epoch: 5.71 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14649353786596156		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.14649353786596156 | validation: 0.11131835770147769]
	TIME [epoch: 5.73 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14058586213027954		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.14058586213027954 | validation: 0.10976793482696025]
	TIME [epoch: 5.71 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14327744022500571		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.14327744022500571 | validation: 0.11976218330703792]
	TIME [epoch: 5.7 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14356246461764982		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.14356246461764982 | validation: 0.1493456881602761]
	TIME [epoch: 5.7 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16445032266684262		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.16445032266684262 | validation: 0.11999673147210071]
	TIME [epoch: 5.7 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14177082246218337		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.14177082246218337 | validation: 0.11634639380518091]
	TIME [epoch: 5.7 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153422647076281		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.153422647076281 | validation: 0.11325329884188463]
	TIME [epoch: 5.74 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1596739907871854		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.1596739907871854 | validation: 0.11381404696016077]
	TIME [epoch: 5.71 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14560074771577036		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.14560074771577036 | validation: 0.12633366464790094]
	TIME [epoch: 5.7 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14254510290782021		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.14254510290782021 | validation: 0.1294685836745458]
	TIME [epoch: 5.7 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14625592098210288		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.14625592098210288 | validation: 0.11968694235580211]
	TIME [epoch: 5.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15297433169763575		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.15297433169763575 | validation: 0.14511140272052594]
	TIME [epoch: 5.7 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15270868780212543		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.15270868780212543 | validation: 0.12777310031145434]
	TIME [epoch: 5.7 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14867243462885346		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.14867243462885346 | validation: 0.13414125556712767]
	TIME [epoch: 5.74 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455632257954456		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.1455632257954456 | validation: 0.11421570853678667]
	TIME [epoch: 5.71 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14076969880422516		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.14076969880422516 | validation: 0.1237642768301531]
	TIME [epoch: 5.7 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145991779264031		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.145991779264031 | validation: 0.12817835257163257]
	TIME [epoch: 5.7 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15393954991561917		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.15393954991561917 | validation: 0.1348508965872609]
	TIME [epoch: 5.7 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1547072046888048		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.1547072046888048 | validation: 0.12504018551974086]
	TIME [epoch: 5.7 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15237395897021422		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.15237395897021422 | validation: 0.14219477203882033]
	TIME [epoch: 5.73 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15647231028921335		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.15647231028921335 | validation: 0.11504231355533051]
	TIME [epoch: 5.7 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13966235903337335		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.13966235903337335 | validation: 0.10835727475282853]
	TIME [epoch: 5.7 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14527861189097896		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.14527861189097896 | validation: 0.10554302266343141]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1344.pth
	Model improved!!!
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14545998989874898		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.14545998989874898 | validation: 0.1225348904422575]
	TIME [epoch: 5.71 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14703957845864546		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.14703957845864546 | validation: 0.10763952356526847]
	TIME [epoch: 5.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13882010309412587		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.13882010309412587 | validation: 0.12050145566764839]
	TIME [epoch: 5.71 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14018086409185043		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.14018086409185043 | validation: 0.11599657319518014]
	TIME [epoch: 5.72 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14535455520086618		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.14535455520086618 | validation: 0.14683310650152628]
	TIME [epoch: 5.71 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15730488390859118		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.15730488390859118 | validation: 0.15404697579803206]
	TIME [epoch: 5.71 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15460150124575456		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.15460150124575456 | validation: 0.1199114085448923]
	TIME [epoch: 5.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14711979584485402		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.14711979584485402 | validation: 0.1225345092942126]
	TIME [epoch: 5.7 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15529241543545153		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.15529241543545153 | validation: 0.12543018175957593]
	TIME [epoch: 5.7 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15232791594539905		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.15232791594539905 | validation: 0.12212478781229597]
	TIME [epoch: 5.74 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14841064628009168		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.14841064628009168 | validation: 0.11524236131600744]
	TIME [epoch: 5.71 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14494050485221238		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.14494050485221238 | validation: 0.1184531086605482]
	TIME [epoch: 5.7 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143806926461292		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.143806926461292 | validation: 0.13749122184556126]
	TIME [epoch: 5.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15249413730457242		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.15249413730457242 | validation: 0.12176288920344319]
	TIME [epoch: 5.7 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15256144961565798		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.15256144961565798 | validation: 0.1264226886344803]
	TIME [epoch: 5.7 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14734357307929696		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.14734357307929696 | validation: 0.12537990467274168]
	TIME [epoch: 5.72 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16221494267528916		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.16221494267528916 | validation: 0.10892040581305618]
	TIME [epoch: 5.74 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429528631399721		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.1429528631399721 | validation: 0.10253950719919377]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1362.pth
	Model improved!!!
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14027144444831666		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.14027144444831666 | validation: 0.11274802468710515]
	TIME [epoch: 5.69 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14794149583665867		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.14794149583665867 | validation: 0.12476181136560723]
	TIME [epoch: 5.69 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15142592191631657		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.15142592191631657 | validation: 0.11208377289911732]
	TIME [epoch: 5.7 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14260083923426492		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.14260083923426492 | validation: 0.11495212907122832]
	TIME [epoch: 5.7 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13736661342176976		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.13736661342176976 | validation: 0.11416146547898975]
	TIME [epoch: 5.73 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398898211710013		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.1398898211710013 | validation: 0.1195129237412219]
	TIME [epoch: 5.7 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14250748270853505		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.14250748270853505 | validation: 0.11029897429876595]
	TIME [epoch: 5.69 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13972006630107453		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.13972006630107453 | validation: 0.12037958590990462]
	TIME [epoch: 5.71 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15049597887322574		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.15049597887322574 | validation: 0.12570201064555078]
	TIME [epoch: 5.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15429645048854965		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.15429645048854965 | validation: 0.1198196868026557]
	TIME [epoch: 5.69 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14687095903112193		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.14687095903112193 | validation: 0.1162069107840296]
	TIME [epoch: 5.71 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13847441078027803		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.13847441078027803 | validation: 0.13185322299236205]
	TIME [epoch: 5.73 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14973088824405317		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.14973088824405317 | validation: 0.11987225395902819]
	TIME [epoch: 5.7 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14416538577479016		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.14416538577479016 | validation: 0.13001071272839046]
	TIME [epoch: 5.71 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1456869833260487		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.1456869833260487 | validation: 0.13322701817250157]
	TIME [epoch: 5.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143554039222931		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.143554039222931 | validation: 0.13302769098287634]
	TIME [epoch: 5.7 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1470676507429404		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.1470676507429404 | validation: 0.123560073007897]
	TIME [epoch: 5.7 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14289148083673292		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.14289148083673292 | validation: 0.12492492442202888]
	TIME [epoch: 5.74 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16425174685297445		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.16425174685297445 | validation: 0.11729328141958817]
	TIME [epoch: 5.69 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14277435291704493		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.14277435291704493 | validation: 0.1148767579154223]
	TIME [epoch: 5.69 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13783070014064852		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.13783070014064852 | validation: 0.11860548397985782]
	TIME [epoch: 5.7 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14519094249983738		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.14519094249983738 | validation: 0.1208962036033082]
	TIME [epoch: 5.7 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14670046359444258		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.14670046359444258 | validation: 0.12926420123233126]
	TIME [epoch: 5.7 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13766434091286459		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.13766434091286459 | validation: 0.11813775792688852]
	TIME [epoch: 5.71 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14224240229653107		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.14224240229653107 | validation: 0.11640491013461594]
	TIME [epoch: 5.73 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15796365672982624		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.15796365672982624 | validation: 0.14666208923681182]
	TIME [epoch: 5.7 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474898046878184		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.1474898046878184 | validation: 0.11477504361803822]
	TIME [epoch: 5.7 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13532063231626687		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.13532063231626687 | validation: 0.1128391968084903]
	TIME [epoch: 5.7 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138867928456994		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.138867928456994 | validation: 0.11942841240032817]
	TIME [epoch: 5.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13989884280354728		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.13989884280354728 | validation: 0.10491506482897105]
	TIME [epoch: 5.69 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13685682710190195		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.13685682710190195 | validation: 0.12074138409146015]
	TIME [epoch: 5.74 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14558461263188976		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.14558461263188976 | validation: 0.1157059233690167]
	TIME [epoch: 5.71 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1407837065363906		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.1407837065363906 | validation: 0.1123194607136854]
	TIME [epoch: 5.7 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339829547790664		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.1339829547790664 | validation: 0.1179271972540982]
	TIME [epoch: 5.7 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13882296382189666		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.13882296382189666 | validation: 0.10982447308327864]
	TIME [epoch: 5.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13758888780128598		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.13758888780128598 | validation: 0.12232928775391946]
	TIME [epoch: 5.7 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13553401797679396		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.13553401797679396 | validation: 0.10942569270564947]
	TIME [epoch: 5.71 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371782530780007		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.1371782530780007 | validation: 0.12917593923881782]
	TIME [epoch: 5.73 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1552626277077194		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.1552626277077194 | validation: 0.16153360606344394]
	TIME [epoch: 5.71 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15036050344153687		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.15036050344153687 | validation: 0.11144682254670471]
	TIME [epoch: 5.7 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14816698368803152		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.14816698368803152 | validation: 0.12529550736752895]
	TIME [epoch: 5.7 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502588931802307		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.1502588931802307 | validation: 0.12360949183555361]
	TIME [epoch: 5.7 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398680215982551		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.1398680215982551 | validation: 0.11921506650095698]
	TIME [epoch: 5.7 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451074001400867		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.1451074001400867 | validation: 0.10931574818593054]
	TIME [epoch: 5.73 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360968540274832		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.1360968540274832 | validation: 0.11818445123357023]
	TIME [epoch: 5.71 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1405024916449092		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.1405024916449092 | validation: 0.1292032958569145]
	TIME [epoch: 5.7 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366258212000839		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.1366258212000839 | validation: 0.10667400112015958]
	TIME [epoch: 5.7 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374777615505906		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.1374777615505906 | validation: 0.11504239155660902]
	TIME [epoch: 5.7 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14208625282626067		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.14208625282626067 | validation: 0.12879569864614152]
	TIME [epoch: 5.7 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15829600822319775		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.15829600822319775 | validation: 0.12278797437808806]
	TIME [epoch: 5.71 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14454115613466745		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.14454115613466745 | validation: 0.11904106682972712]
	TIME [epoch: 5.73 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14200826945246078		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.14200826945246078 | validation: 0.1321858725505695]
	TIME [epoch: 5.7 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1563337105024079		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.1563337105024079 | validation: 0.12091594310300532]
	TIME [epoch: 5.69 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14134113762764627		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.14134113762764627 | validation: 0.12327225091631155]
	TIME [epoch: 5.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422194412324759		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.1422194412324759 | validation: 0.11178720980561839]
	TIME [epoch: 5.7 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14113256879404432		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.14113256879404432 | validation: 0.1470837340440734]
	TIME [epoch: 5.7 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15930736055755562		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.15930736055755562 | validation: 0.11739386640228143]
	TIME [epoch: 5.74 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13622437268698015		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.13622437268698015 | validation: 0.11497586836708347]
	TIME [epoch: 5.71 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13788461342071534		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.13788461342071534 | validation: 0.13290220609405165]
	TIME [epoch: 5.69 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14811808869232218		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.14811808869232218 | validation: 0.13331712056753117]
	TIME [epoch: 5.7 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13876069419737816		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.13876069419737816 | validation: 0.12097977595815364]
	TIME [epoch: 5.71 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14308038149546823		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.14308038149546823 | validation: 0.12116905672654056]
	TIME [epoch: 5.7 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403391082962318		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.1403391082962318 | validation: 0.11677056309363262]
	TIME [epoch: 5.71 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14089496040341762		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.14089496040341762 | validation: 0.10764059970537979]
	TIME [epoch: 5.73 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394608956423392		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.1394608956423392 | validation: 0.10456487412326648]
	TIME [epoch: 5.71 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13737377684208343		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.13737377684208343 | validation: 0.10919926825735203]
	TIME [epoch: 5.71 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14119180931660696		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.14119180931660696 | validation: 0.11952388327983485]
	TIME [epoch: 5.7 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1519613071266517		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.1519613071266517 | validation: 0.139671407499927]
	TIME [epoch: 5.69 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15417373662108555		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.15417373662108555 | validation: 0.12295944490624199]
	TIME [epoch: 5.71 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14489824653764766		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.14489824653764766 | validation: 0.12272654360773323]
	TIME [epoch: 5.75 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14775026218970244		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.14775026218970244 | validation: 0.12851521193574242]
	TIME [epoch: 5.71 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14281914039444474		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.14281914039444474 | validation: 0.1248748148215638]
	TIME [epoch: 5.7 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14217024382208227		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.14217024382208227 | validation: 0.12867967570991326]
	TIME [epoch: 5.69 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13893233848840233		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.13893233848840233 | validation: 0.11356397677481135]
	TIME [epoch: 5.7 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397750471956548		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.1397750471956548 | validation: 0.11380344832449814]
	TIME [epoch: 5.7 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518658255984146		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.1518658255984146 | validation: 0.16376460466357984]
	TIME [epoch: 5.71 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15046126639602247		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.15046126639602247 | validation: 0.11830181710581122]
	TIME [epoch: 5.74 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13201937977930786		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.13201937977930786 | validation: 0.11591501954863925]
	TIME [epoch: 5.7 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13984787990454306		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.13984787990454306 | validation: 0.12676491804415424]
	TIME [epoch: 5.7 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555315001418151		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.1555315001418151 | validation: 0.11519333465387792]
	TIME [epoch: 5.71 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14301865018007498		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.14301865018007498 | validation: 0.11872017556196288]
	TIME [epoch: 5.69 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14793369542341037		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.14793369542341037 | validation: 0.12642539659179972]
	TIME [epoch: 5.7 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13799986429379132		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.13799986429379132 | validation: 0.10471814676439056]
	TIME [epoch: 5.74 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14242157385700804		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.14242157385700804 | validation: 0.13124157109439355]
	TIME [epoch: 5.7 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15011599486122582		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.15011599486122582 | validation: 0.13072683729692922]
	TIME [epoch: 5.7 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14516420707777547		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.14516420707777547 | validation: 0.11506904069765478]
	TIME [epoch: 5.7 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13826621958465113		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.13826621958465113 | validation: 0.11163786051162548]
	TIME [epoch: 5.7 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14528247952525963		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.14528247952525963 | validation: 0.12261942520539654]
	TIME [epoch: 5.7 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13899343846989753		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.13899343846989753 | validation: 0.10932559533751174]
	TIME [epoch: 5.71 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409440334189362		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.1409440334189362 | validation: 0.11810299741939292]
	TIME [epoch: 5.73 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14128820669815625		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.14128820669815625 | validation: 0.11501354443330598]
	TIME [epoch: 5.7 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13657728012303216		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.13657728012303216 | validation: 0.10612992047249639]
	TIME [epoch: 5.7 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13216157043442578		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.13216157043442578 | validation: 0.10456178330801542]
	TIME [epoch: 5.7 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13363833315957171		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.13363833315957171 | validation: 0.10780388774653105]
	TIME [epoch: 5.7 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390373617938491		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.1390373617938491 | validation: 0.12858971193911964]
	TIME [epoch: 5.7 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13922004892242884		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.13922004892242884 | validation: 0.11087131473408059]
	TIME [epoch: 5.74 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398671291457189		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.1398671291457189 | validation: 0.11770512399953414]
	TIME [epoch: 5.71 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13566843991321334		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.13566843991321334 | validation: 0.11422919522009334]
	TIME [epoch: 5.7 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379784418545326		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.1379784418545326 | validation: 0.10948939262808241]
	TIME [epoch: 5.7 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13538040398067425		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.13538040398067425 | validation: 0.11013316260927447]
	TIME [epoch: 5.7 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13258716727233394		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.13258716727233394 | validation: 0.11589785024082896]
	TIME [epoch: 5.71 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350246496310308		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.1350246496310308 | validation: 0.11673512737414479]
	TIME [epoch: 5.71 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370624022703117		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.1370624022703117 | validation: 0.11243891503753252]
	TIME [epoch: 5.74 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14957280523062658		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.14957280523062658 | validation: 0.11002807660336882]
	TIME [epoch: 5.7 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13888663424525127		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.13888663424525127 | validation: 0.11204129258836389]
	TIME [epoch: 5.7 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14276739230688407		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.14276739230688407 | validation: 0.1218897730573627]
	TIME [epoch: 5.69 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14297037475873386		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.14297037475873386 | validation: 0.11622190825482459]
	TIME [epoch: 5.69 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390014598939992		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.1390014598939992 | validation: 0.12123063833135196]
	TIME [epoch: 5.7 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366985899849567		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.1366985899849567 | validation: 0.12403567970825982]
	TIME [epoch: 5.73 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1367951493422345		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.1367951493422345 | validation: 0.1299764343224643]
	TIME [epoch: 5.7 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1405565277810521		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.1405565277810521 | validation: 0.12008145855851698]
	TIME [epoch: 5.7 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13656903682778124		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.13656903682778124 | validation: 0.11639852202169733]
	TIME [epoch: 5.7 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391772461431554		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.1391772461431554 | validation: 0.10972089883651269]
	TIME [epoch: 5.7 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365086837288201		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.1365086837288201 | validation: 0.10979485513800746]
	TIME [epoch: 5.7 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14293459055918076		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.14293459055918076 | validation: 0.10651319597509563]
	TIME [epoch: 5.71 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13461585098855017		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.13461585098855017 | validation: 0.11107565781530201]
	TIME [epoch: 5.73 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396194839444815		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.1396194839444815 | validation: 0.12796835358071107]
	TIME [epoch: 5.7 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437071674281719		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.1437071674281719 | validation: 0.11622948848911403]
	TIME [epoch: 5.7 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14496229349018264		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.14496229349018264 | validation: 0.11434662781001116]
	TIME [epoch: 5.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13311017441483888		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.13311017441483888 | validation: 0.11080870236151913]
	TIME [epoch: 5.71 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13883600895887485		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.13883600895887485 | validation: 0.1151560315795546]
	TIME [epoch: 5.7 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13720524226261077		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.13720524226261077 | validation: 0.12395228842495297]
	TIME [epoch: 5.75 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14567745410606267		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.14567745410606267 | validation: 0.11677189125749797]
	TIME [epoch: 5.7 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13777864220212202		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.13777864220212202 | validation: 0.11063547865447007]
	TIME [epoch: 5.71 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13597384220657396		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.13597384220657396 | validation: 0.10236174081068584]
	TIME [epoch: 5.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1487.pth
	Model improved!!!
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13641176504106872		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.13641176504106872 | validation: 0.11403847415861748]
	TIME [epoch: 5.7 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13354644389019643		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.13354644389019643 | validation: 0.10919382129698599]
	TIME [epoch: 5.7 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13577390575643683		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.13577390575643683 | validation: 0.10648531451627896]
	TIME [epoch: 5.71 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.135654253632246		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.135654253632246 | validation: 0.10778608543772553]
	TIME [epoch: 5.73 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13866462215436767		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.13866462215436767 | validation: 0.12367146547690056]
	TIME [epoch: 5.7 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14342439858131084		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.14342439858131084 | validation: 0.13751839379564806]
	TIME [epoch: 5.7 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15064798043243455		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.15064798043243455 | validation: 0.10803023775339055]
	TIME [epoch: 5.69 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378663981130368		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.1378663981130368 | validation: 0.1259469362433751]
	TIME [epoch: 5.71 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1395111695344488		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.1395111695344488 | validation: 0.11376282165001333]
	TIME [epoch: 5.71 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13650869041280972		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.13650869041280972 | validation: 0.106854314420967]
	TIME [epoch: 5.75 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13548037646034253		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.13548037646034253 | validation: 0.10886198662691253]
	TIME [epoch: 5.7 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13384628425443099		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.13384628425443099 | validation: 0.10091089231573054]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1499.pth
	Model improved!!!
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13157949228198826		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.13157949228198826 | validation: 0.11493651148586648]
	TIME [epoch: 5.7 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13568278848745036		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.13568278848745036 | validation: 0.11548597887100187]
	TIME [epoch: 5.69 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14284285127965918		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.14284285127965918 | validation: 0.11224158773197992]
	TIME [epoch: 5.7 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14695110923232932		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.14695110923232932 | validation: 0.12545138333543057]
	TIME [epoch: 5.73 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14849008163690114		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.14849008163690114 | validation: 0.1027027396111483]
	TIME [epoch: 5.71 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13636281014014268		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.13636281014014268 | validation: 0.11783097286295947]
	TIME [epoch: 5.71 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384208097906858		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.1384208097906858 | validation: 0.10842710559883995]
	TIME [epoch: 5.7 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13348872330908812		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.13348872330908812 | validation: 0.10079565574433674]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1507.pth
	Model improved!!!
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13586517379190355		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.13586517379190355 | validation: 0.11295385655189702]
	TIME [epoch: 5.7 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13748017394487483		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.13748017394487483 | validation: 0.11294800879949841]
	TIME [epoch: 5.69 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14141210381138533		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.14141210381138533 | validation: 0.12216711497177843]
	TIME [epoch: 5.75 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422459897595253		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.1422459897595253 | validation: 0.11379831209459472]
	TIME [epoch: 5.7 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844633506463827		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.13844633506463827 | validation: 0.1073949798500028]
	TIME [epoch: 5.7 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13504413844338836		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.13504413844338836 | validation: 0.11858844124699335]
	TIME [epoch: 5.7 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13872660452971955		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.13872660452971955 | validation: 0.10757625346993262]
	TIME [epoch: 5.7 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14533240931856461		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.14533240931856461 | validation: 0.10983735922978188]
	TIME [epoch: 5.69 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13823559715773592		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.13823559715773592 | validation: 0.11688069293148512]
	TIME [epoch: 5.72 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13412138387040234		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.13412138387040234 | validation: 0.11611799891756873]
	TIME [epoch: 5.71 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13021277300704615		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.13021277300704615 | validation: 0.1140542324659454]
	TIME [epoch: 5.7 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13713166809183228		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.13713166809183228 | validation: 0.1082143396663688]
	TIME [epoch: 5.69 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13578310689186654		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.13578310689186654 | validation: 0.10876522845044853]
	TIME [epoch: 5.69 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13514751212364867		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.13514751212364867 | validation: 0.1243630649894255]
	TIME [epoch: 5.71 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13922180542992618		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.13922180542992618 | validation: 0.11298066001393332]
	TIME [epoch: 5.7 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13724545367114227		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.13724545367114227 | validation: 0.11918066773917677]
	TIME [epoch: 5.74 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12942649653804966		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.12942649653804966 | validation: 0.10586095436916917]
	TIME [epoch: 5.7 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13290198460117936		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.13290198460117936 | validation: 0.1073437723683075]
	TIME [epoch: 5.69 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13628061805030292		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.13628061805030292 | validation: 0.10411261595508109]
	TIME [epoch: 5.7 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306916878524436		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.1306916878524436 | validation: 0.11031318234780324]
	TIME [epoch: 5.7 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381754615417493		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.1381754615417493 | validation: 0.10732954363064533]
	TIME [epoch: 5.7 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13179159707256385		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.13179159707256385 | validation: 0.10031515939429786]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1529.pth
	Model improved!!!
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13476279741580754		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.13476279741580754 | validation: 0.10343480096339622]
	TIME [epoch: 5.71 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13157834598578733		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.13157834598578733 | validation: 0.11339210702339798]
	TIME [epoch: 5.7 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353676773822642		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.1353676773822642 | validation: 0.10524048567317426]
	TIME [epoch: 5.7 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13452141562158704		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.13452141562158704 | validation: 0.11078417212997625]
	TIME [epoch: 5.7 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13044983460704823		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.13044983460704823 | validation: 0.10664216557475581]
	TIME [epoch: 5.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339175932271156		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.1339175932271156 | validation: 0.11769782780724257]
	TIME [epoch: 5.7 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.134605327679241		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.134605327679241 | validation: 0.11344480817688762]
	TIME [epoch: 5.74 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13591207608670486		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.13591207608670486 | validation: 0.11787566616637793]
	TIME [epoch: 5.7 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13380005031135744		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.13380005031135744 | validation: 0.10573440293368677]
	TIME [epoch: 5.7 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13214955756071373		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.13214955756071373 | validation: 0.11207987535237506]
	TIME [epoch: 5.7 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13380880801604167		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.13380880801604167 | validation: 0.12143594436849842]
	TIME [epoch: 5.69 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415157272489281		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.1415157272489281 | validation: 0.11148031553536186]
	TIME [epoch: 5.7 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338154402053132		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.1338154402053132 | validation: 0.10993320536469402]
	TIME [epoch: 5.73 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14670253616893228		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.14670253616893228 | validation: 0.11214204715715634]
	TIME [epoch: 5.71 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139105727176344		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.139105727176344 | validation: 0.1269071514237841]
	TIME [epoch: 5.71 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14441276562998123		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.14441276562998123 | validation: 0.11392506796377706]
	TIME [epoch: 5.71 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13338001476713537		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.13338001476713537 | validation: 0.11101636973302553]
	TIME [epoch: 5.7 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12918886388779394		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.12918886388779394 | validation: 0.11992067600918707]
	TIME [epoch: 5.7 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1399216476300461		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.1399216476300461 | validation: 0.1062630030816753]
	TIME [epoch: 5.71 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365884507861154		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.1365884507861154 | validation: 0.10726697144773802]
	TIME [epoch: 5.74 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13599745774440244		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.13599745774440244 | validation: 0.10601683735790135]
	TIME [epoch: 5.7 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13821790450224086		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.13821790450224086 | validation: 0.12473210962426232]
	TIME [epoch: 5.7 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384597931017551		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.1384597931017551 | validation: 0.11340278976183987]
	TIME [epoch: 5.7 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13330100894851923		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.13330100894851923 | validation: 0.12016944318050879]
	TIME [epoch: 5.7 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357257548384322		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.1357257548384322 | validation: 0.10814764570285064]
	TIME [epoch: 5.7 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331927617229501		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.1331927617229501 | validation: 0.10952146852271928]
	TIME [epoch: 5.72 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130795742344298		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.130795742344298 | validation: 0.10365511667218842]
	TIME [epoch: 5.71 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13211695325506825		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.13211695325506825 | validation: 0.10982732709345637]
	TIME [epoch: 5.71 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13385359332610625		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.13385359332610625 | validation: 0.10755766520634436]
	TIME [epoch: 5.71 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13675779595754944		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.13675779595754944 | validation: 0.11272249004372885]
	TIME [epoch: 5.71 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324178451398681		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.1324178451398681 | validation: 0.11233432476970638]
	TIME [epoch: 5.7 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13534019087742513		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.13534019087742513 | validation: 0.11134594454415973]
	TIME [epoch: 5.7 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340626197898548		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.1340626197898548 | validation: 0.11635899378009587]
	TIME [epoch: 5.74 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355640400421004		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.1355640400421004 | validation: 0.1188880536710456]
	TIME [epoch: 5.71 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13680417745549067		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.13680417745549067 | validation: 0.11436001597337585]
	TIME [epoch: 5.71 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13415849292661922		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.13415849292661922 | validation: 0.11058690242095147]
	TIME [epoch: 5.71 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13970779548312232		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.13970779548312232 | validation: 0.11292662546675512]
	TIME [epoch: 5.7 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341298241999842		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.1341298241999842 | validation: 0.11446337493297376]
	TIME [epoch: 5.7 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13190614806039966		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.13190614806039966 | validation: 0.11930839071551322]
	TIME [epoch: 5.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13929874546340845		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.13929874546340845 | validation: 0.12580876036140648]
	TIME [epoch: 5.71 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13417216874948373		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.13417216874948373 | validation: 0.1170449174299256]
	TIME [epoch: 5.7 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14351292248555192		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.14351292248555192 | validation: 0.13101180568068668]
	TIME [epoch: 5.7 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13453495203443006		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.13453495203443006 | validation: 0.1144587709604279]
	TIME [epoch: 5.7 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13527817486494198		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.13527817486494198 | validation: 0.11984823426128079]
	TIME [epoch: 5.7 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13643032513518896		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.13643032513518896 | validation: 0.1138046762093841]
	TIME [epoch: 5.7 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13912623611749514		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.13912623611749514 | validation: 0.13095688063845212]
	TIME [epoch: 5.74 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386583844763693		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.1386583844763693 | validation: 0.11084717608469365]
	TIME [epoch: 5.7 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13343620597113592		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.13343620597113592 | validation: 0.11306638400773517]
	TIME [epoch: 5.7 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13269272232276802		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.13269272232276802 | validation: 0.10536672313775361]
	TIME [epoch: 5.7 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361769315037925		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.1361769315037925 | validation: 0.1146668337221625]
	TIME [epoch: 5.7 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13723370036330645		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.13723370036330645 | validation: 0.11224814897743009]
	TIME [epoch: 5.7 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14034200413330594		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.14034200413330594 | validation: 0.11893917434575862]
	TIME [epoch: 5.72 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14000108312834988		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.14000108312834988 | validation: 0.12027970655114269]
	TIME [epoch: 5.71 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13914861938721357		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.13914861938721357 | validation: 0.11788957118961779]
	TIME [epoch: 5.7 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14020389450404497		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.14020389450404497 | validation: 0.12326528457646374]
	TIME [epoch: 5.7 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314998342264036		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.1314998342264036 | validation: 0.10812526228938389]
	TIME [epoch: 5.7 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320464048781472		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.1320464048781472 | validation: 0.11496738398215954]
	TIME [epoch: 5.7 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362587242557971		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.1362587242557971 | validation: 0.12132736526964387]
	TIME [epoch: 5.7 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15068995618774736		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.15068995618774736 | validation: 0.13687876620912431]
	TIME [epoch: 5.74 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14868184206197277		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.14868184206197277 | validation: 0.10746631570866287]
	TIME [epoch: 5.7 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332695342947221		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.1332695342947221 | validation: 0.11319207381641733]
	TIME [epoch: 5.7 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13674616747198165		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.13674616747198165 | validation: 0.11973204786691255]
	TIME [epoch: 5.7 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13953928727886844		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.13953928727886844 | validation: 0.11559822354177988]
	TIME [epoch: 5.7 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13430300581209084		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.13430300581209084 | validation: 0.10929303899880849]
	TIME [epoch: 5.7 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340647744959711		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.1340647744959711 | validation: 0.10752781704101154]
	TIME [epoch: 5.72 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14414909430008516		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.14414909430008516 | validation: 0.11815642649194122]
	TIME [epoch: 5.71 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13385536342908927		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.13385536342908927 | validation: 0.11360255952165847]
	TIME [epoch: 5.7 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13827554519354043		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.13827554519354043 | validation: 0.1095089879849844]
	TIME [epoch: 5.7 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13195853639938318		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.13195853639938318 | validation: 0.10124049671497776]
	TIME [epoch: 5.7 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341291735676504		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.1341291735676504 | validation: 0.1183929223131541]
	TIME [epoch: 5.7 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14158388474340317		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.14158388474340317 | validation: 0.12432717405181937]
	TIME [epoch: 5.7 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13489576732761968		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.13489576732761968 | validation: 0.10579051308657945]
	TIME [epoch: 5.74 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13140854363304164		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.13140854363304164 | validation: 0.11539372686538336]
	TIME [epoch: 5.7 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13186279076680021		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.13186279076680021 | validation: 0.1191272868437413]
	TIME [epoch: 5.7 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13698123746559066		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.13698123746559066 | validation: 0.11178063330870334]
	TIME [epoch: 5.7 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328715406966662		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.1328715406966662 | validation: 0.10986020005050849]
	TIME [epoch: 5.7 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067522249481422		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.13067522249481422 | validation: 0.10954000227634883]
	TIME [epoch: 5.7 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13377337475952614		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.13377337475952614 | validation: 0.11361710123271919]
	TIME [epoch: 5.72 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13033399717942962		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.13033399717942962 | validation: 0.108362160393979]
	TIME [epoch: 5.71 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13837497953290506		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.13837497953290506 | validation: 0.11342178731948778]
	TIME [epoch: 5.7 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278922026586215		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.1278922026586215 | validation: 0.10567205316112566]
	TIME [epoch: 5.7 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12850339728065555		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.12850339728065555 | validation: 0.11109449614814217]
	TIME [epoch: 5.7 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13076938069135002		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.13076938069135002 | validation: 0.1120372546446563]
	TIME [epoch: 5.7 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13210277507685783		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.13210277507685783 | validation: 0.1176374392117555]
	TIME [epoch: 5.7 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13839902703936352		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.13839902703936352 | validation: 0.1299522982751088]
	TIME [epoch: 5.73 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14382390809258572		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.14382390809258572 | validation: 0.12552880088645677]
	TIME [epoch: 5.7 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14139038382385455		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.14139038382385455 | validation: 0.11474950642833597]
	TIME [epoch: 5.7 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13285845185473016		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.13285845185473016 | validation: 0.09867534811113107]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1617.pth
	Model improved!!!
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13246247111922727		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.13246247111922727 | validation: 0.1183755716145304]
	TIME [epoch: 5.7 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13965763370960171		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.13965763370960171 | validation: 0.12916113634810863]
	TIME [epoch: 5.7 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14379687077310052		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.14379687077310052 | validation: 0.11634100205389487]
	TIME [epoch: 5.73 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13377258922199348		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.13377258922199348 | validation: 0.11400542809230281]
	TIME [epoch: 5.7 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12713235442283657		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.12713235442283657 | validation: 0.110183339643994]
	TIME [epoch: 5.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297552525039406		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.1297552525039406 | validation: 0.11711576297062448]
	TIME [epoch: 5.7 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13325090663019304		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.13325090663019304 | validation: 0.10666660759431057]
	TIME [epoch: 5.7 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13046906121215357		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.13046906121215357 | validation: 0.11215970855802805]
	TIME [epoch: 5.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13121900473422532		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.13121900473422532 | validation: 0.09733310338080259]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1626.pth
	Model improved!!!
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371422101886467		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.1371422101886467 | validation: 0.1204682266157339]
	TIME [epoch: 5.75 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13548642824526885		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.13548642824526885 | validation: 0.11094832389415184]
	TIME [epoch: 5.71 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13685064223708793		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.13685064223708793 | validation: 0.10252536828916675]
	TIME [epoch: 5.72 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13240019122630195		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.13240019122630195 | validation: 0.10992124150294537]
	TIME [epoch: 5.72 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13151912876158922		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.13151912876158922 | validation: 0.1098794578296311]
	TIME [epoch: 5.71 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12822804248280345		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.12822804248280345 | validation: 0.10301862903668826]
	TIME [epoch: 5.72 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13542878080968074		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.13542878080968074 | validation: 0.11191145345689803]
	TIME [epoch: 5.75 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727440705224675		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.13727440705224675 | validation: 0.12603277553575218]
	TIME [epoch: 5.72 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327229922855714		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.1327229922855714 | validation: 0.11186497975089815]
	TIME [epoch: 5.72 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13108439774164005		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.13108439774164005 | validation: 0.10657815723207276]
	TIME [epoch: 5.72 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308011435782731		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.1308011435782731 | validation: 0.10411190867488543]
	TIME [epoch: 5.72 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14122879366824675		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.14122879366824675 | validation: 0.11061385508785339]
	TIME [epoch: 5.72 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12823604602339087		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.12823604602339087 | validation: 0.11679108294958969]
	TIME [epoch: 5.73 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13424917634468952		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.13424917634468952 | validation: 0.11355909020094124]
	TIME [epoch: 5.74 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13136728107029502		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.13136728107029502 | validation: 0.10264395806422552]
	TIME [epoch: 5.72 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286339328482725		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.1286339328482725 | validation: 0.11185830555712008]
	TIME [epoch: 5.72 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13168846779327095		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.13168846779327095 | validation: 0.1127386566710818]
	TIME [epoch: 5.71 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384947846654547		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.1384947846654547 | validation: 0.1090154588652199]
	TIME [epoch: 5.71 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13423609160471936		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.13423609160471936 | validation: 0.1138205210280038]
	TIME [epoch: 5.72 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13129257961318375		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.13129257961318375 | validation: 0.12302946725219109]
	TIME [epoch: 5.75 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13322796621162425		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.13322796621162425 | validation: 0.10260808889816059]
	TIME [epoch: 5.72 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12952950195678614		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.12952950195678614 | validation: 0.10178441753195905]
	TIME [epoch: 5.71 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12763222716683567		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.12763222716683567 | validation: 0.11818372880070033]
	TIME [epoch: 5.71 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13091553806552775		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.13091553806552775 | validation: 0.10958977092566297]
	TIME [epoch: 5.71 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13244963017338865		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.13244963017338865 | validation: 0.11374980473472837]
	TIME [epoch: 5.71 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13090335917169177		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.13090335917169177 | validation: 0.10774260760479482]
	TIME [epoch: 5.72 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13442998204543335		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.13442998204543335 | validation: 0.12566392028601653]
	TIME [epoch: 5.74 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13944339310375944		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.13944339310375944 | validation: 0.11288163704679093]
	TIME [epoch: 5.72 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13427946514833727		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.13427946514833727 | validation: 0.12661184165699046]
	TIME [epoch: 5.71 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14242449036897512		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.14242449036897512 | validation: 0.11478648050671617]
	TIME [epoch: 5.72 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14273368601827433		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.14273368601827433 | validation: 0.11670829314957831]
	TIME [epoch: 5.71 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13155190692324226		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.13155190692324226 | validation: 0.10395210379639412]
	TIME [epoch: 5.72 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13078513964145813		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.13078513964145813 | validation: 0.12074787923379222]
	TIME [epoch: 5.75 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13309250108202975		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.13309250108202975 | validation: 0.12081469654259427]
	TIME [epoch: 5.72 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13066661946130081		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.13066661946130081 | validation: 0.11779791698817882]
	TIME [epoch: 5.72 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13258446851150651		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.13258446851150651 | validation: 0.11355522265574655]
	TIME [epoch: 5.71 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13037551006433606		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.13037551006433606 | validation: 0.12812795618374623]
	TIME [epoch: 5.72 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13436813717673943		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.13436813717673943 | validation: 0.11218775084756305]
	TIME [epoch: 5.71 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12937949526601705		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.12937949526601705 | validation: 0.11331102477520542]
	TIME [epoch: 5.74 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12857182416194599		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.12857182416194599 | validation: 0.10688482493634986]
	TIME [epoch: 5.73 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309905444547405		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.1309905444547405 | validation: 0.10645171343005766]
	TIME [epoch: 5.72 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316980847947453		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.1316980847947453 | validation: 0.11095090066513741]
	TIME [epoch: 5.71 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12778272319399958		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.12778272319399958 | validation: 0.10530861175987002]
	TIME [epoch: 5.71 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324930359037042		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.1324930359037042 | validation: 0.11250075517684643]
	TIME [epoch: 5.71 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13223877380472415		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.13223877380472415 | validation: 0.11340767029845777]
	TIME [epoch: 5.72 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13507970399179392		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.13507970399179392 | validation: 0.1058538965426525]
	TIME [epoch: 5.75 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13208183758586012		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.13208183758586012 | validation: 0.10959698955083547]
	TIME [epoch: 5.72 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12786162564204806		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.12786162564204806 | validation: 0.11160789902994563]
	TIME [epoch: 5.71 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297074344693453		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.1297074344693453 | validation: 0.10577677195100638]
	TIME [epoch: 5.71 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13168812099387361		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.13168812099387361 | validation: 0.10788139366120557]
	TIME [epoch: 5.71 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12989515198237592		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.12989515198237592 | validation: 0.1098993870643862]
	TIME [epoch: 5.71 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13076430819530027		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.13076430819530027 | validation: 0.11213755894755063]
	TIME [epoch: 5.74 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13627881415945303		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.13627881415945303 | validation: 0.1084855255584039]
	TIME [epoch: 5.73 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12697096514885509		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.12697096514885509 | validation: 0.11160884417601011]
	TIME [epoch: 5.71 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12841505564182917		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.12841505564182917 | validation: 0.10131075318122341]
	TIME [epoch: 5.71 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286036166696833		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.1286036166696833 | validation: 0.11608791591972989]
	TIME [epoch: 5.71 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291705436034418		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.1291705436034418 | validation: 0.117434179156473]
	TIME [epoch: 5.71 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13298742681112968		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.13298742681112968 | validation: 0.12098350336467743]
	TIME [epoch: 5.71 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13138789043748636		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.13138789043748636 | validation: 0.11766563464345678]
	TIME [epoch: 5.75 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13282335023724567		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.13282335023724567 | validation: 0.1172080581938607]
	TIME [epoch: 5.72 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346301657166703		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.1346301657166703 | validation: 0.11684067129114838]
	TIME [epoch: 5.71 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13768269258208296		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.13768269258208296 | validation: 0.1213712305844556]
	TIME [epoch: 5.71 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13632519405520718		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.13632519405520718 | validation: 0.10788689300808699]
	TIME [epoch: 5.71 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12948574270728685		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.12948574270728685 | validation: 0.10386172658836586]
	TIME [epoch: 5.71 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13170976810922003		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.13170976810922003 | validation: 0.10891895650517806]
	TIME [epoch: 5.74 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306128363241067		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.1306128363241067 | validation: 0.10929208672145152]
	TIME [epoch: 5.73 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13377543998353153		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.13377543998353153 | validation: 0.10372434858011984]
	TIME [epoch: 5.72 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13244694354499384		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.13244694354499384 | validation: 0.10751103122796427]
	TIME [epoch: 5.71 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13365111132575985		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.13365111132575985 | validation: 0.10878118729823688]
	TIME [epoch: 5.71 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295164476580114		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.1295164476580114 | validation: 0.10231368485210635]
	TIME [epoch: 5.71 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13328031517628638		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.13328031517628638 | validation: 0.1135029799009174]
	TIME [epoch: 5.71 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13978998718473393		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.13978998718473393 | validation: 0.11101329446913633]
	TIME [epoch: 5.75 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13377550357342632		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.13377550357342632 | validation: 0.1079493361900808]
	TIME [epoch: 5.72 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332374687445276		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.1332374687445276 | validation: 0.11040932113226795]
	TIME [epoch: 5.71 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12752169951658338		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.12752169951658338 | validation: 0.11147820308348455]
	TIME [epoch: 5.71 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13127782901058702		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.13127782901058702 | validation: 0.11328821607945803]
	TIME [epoch: 5.71 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13220450434610537		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.13220450434610537 | validation: 0.11966169172116342]
	TIME [epoch: 5.71 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13575895562110485		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.13575895562110485 | validation: 0.11480783681234166]
	TIME [epoch: 5.74 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13414493379277978		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.13414493379277978 | validation: 0.10746269760431129]
	TIME [epoch: 5.73 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12976260454405764		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.12976260454405764 | validation: 0.10882451358523133]
	TIME [epoch: 5.71 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13401498460718503		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.13401498460718503 | validation: 0.1149310806901858]
	TIME [epoch: 5.71 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13424616913090825		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.13424616913090825 | validation: 0.10511915074370959]
	TIME [epoch: 5.71 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13008644374291745		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.13008644374291745 | validation: 0.10836195054945126]
	TIME [epoch: 5.71 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13133720696402926		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.13133720696402926 | validation: 0.11448253104698417]
	TIME [epoch: 5.71 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13337436798863622		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.13337436798863622 | validation: 0.13132505326937766]
	TIME [epoch: 5.75 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13803122108965427		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.13803122108965427 | validation: 0.1231323426333698]
	TIME [epoch: 5.71 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13406325129544577		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.13406325129544577 | validation: 0.10848392167535555]
	TIME [epoch: 5.71 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13488407002844394		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.13488407002844394 | validation: 0.1047607263745343]
	TIME [epoch: 5.71 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019427972923525		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.13019427972923525 | validation: 0.10501735784077716]
	TIME [epoch: 5.71 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1299560275560971		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.1299560275560971 | validation: 0.1115043158286823]
	TIME [epoch: 5.71 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344350534972485		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.1344350534972485 | validation: 0.11353455927486909]
	TIME [epoch: 5.74 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1299244956023129		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.1299244956023129 | validation: 0.11621135459093339]
	TIME [epoch: 5.73 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13079824047732846		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.13079824047732846 | validation: 0.11353161020674589]
	TIME [epoch: 5.71 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12770302061850677		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.12770302061850677 | validation: 0.11556579064654152]
	TIME [epoch: 5.71 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12926455716046334		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.12926455716046334 | validation: 0.10702947575214003]
	TIME [epoch: 5.71 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317302494226676		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.1317302494226676 | validation: 0.11390220846204377]
	TIME [epoch: 5.71 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13149209267954481		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.13149209267954481 | validation: 0.11765287972381437]
	TIME [epoch: 5.71 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13682969860434122		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.13682969860434122 | validation: 0.11604532575060601]
	TIME [epoch: 5.75 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13358964901072878		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.13358964901072878 | validation: 0.11553885670644651]
	TIME [epoch: 5.71 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13059584816685574		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.13059584816685574 | validation: 0.10688990278329566]
	TIME [epoch: 5.71 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287390085755472		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.1287390085755472 | validation: 0.11245687789203604]
	TIME [epoch: 5.71 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13094640709707073		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.13094640709707073 | validation: 0.10706186675341331]
	TIME [epoch: 5.71 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13029107497811737		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.13029107497811737 | validation: 0.0975885747442704]
	TIME [epoch: 5.71 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12462691252904025		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.12462691252904025 | validation: 0.10531128060335371]
	TIME [epoch: 5.74 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12925947388435233		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.12925947388435233 | validation: 0.11263810204067323]
	TIME [epoch: 5.73 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13677985045745003		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.13677985045745003 | validation: 0.11649437693465245]
	TIME [epoch: 5.71 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13138024992847405		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.13138024992847405 | validation: 0.11200264165555127]
	TIME [epoch: 5.71 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317664079737642		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.1317664079737642 | validation: 0.11139613833627778]
	TIME [epoch: 5.71 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317753638500437		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.1317753638500437 | validation: 0.11187472813117247]
	TIME [epoch: 5.71 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13274802577605216		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.13274802577605216 | validation: 0.1052122242672416]
	TIME [epoch: 5.71 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13107428408000218		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.13107428408000218 | validation: 0.10906936289123975]
	TIME [epoch: 5.75 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13086057461185568		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.13086057461185568 | validation: 0.10151955082991482]
	TIME [epoch: 5.72 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13174649996787072		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.13174649996787072 | validation: 0.10570938016777992]
	TIME [epoch: 5.71 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13510341597580006		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.13510341597580006 | validation: 0.11242948127618735]
	TIME [epoch: 5.71 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338475144476049		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.1338475144476049 | validation: 0.10561620968986653]
	TIME [epoch: 5.71 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12519897796907384		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.12519897796907384 | validation: 0.11438095386834922]
	TIME [epoch: 5.71 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280215393270992		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.1280215393270992 | validation: 0.10828406342867894]
	TIME [epoch: 5.74 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13177805310745144		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.13177805310745144 | validation: 0.11114209907411901]
	TIME [epoch: 5.73 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191358600948708		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.13191358600948708 | validation: 0.11524921356415718]
	TIME [epoch: 5.72 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12649390280839293		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.12649390280839293 | validation: 0.11328583205617353]
	TIME [epoch: 5.71 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13589978732776603		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.13589978732776603 | validation: 0.11265844776633864]
	TIME [epoch: 5.71 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13470185309802513		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.13470185309802513 | validation: 0.11263450653156097]
	TIME [epoch: 5.71 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286211703833739		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.1286211703833739 | validation: 0.10264611220754744]
	TIME [epoch: 5.72 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289128312730579		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.1289128312730579 | validation: 0.11374132091499192]
	TIME [epoch: 5.75 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12834221787822514		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.12834221787822514 | validation: 0.12008642892137336]
	TIME [epoch: 5.72 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12746674441306793		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.12746674441306793 | validation: 0.10848572497669726]
	TIME [epoch: 5.71 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12969578990791722		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.12969578990791722 | validation: 0.11066640637534494]
	TIME [epoch: 5.71 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12749101528490447		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.12749101528490447 | validation: 0.11180874854190767]
	TIME [epoch: 5.71 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132735192235314		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.132735192235314 | validation: 0.10634050470238235]
	TIME [epoch: 5.71 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12964398727768853		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.12964398727768853 | validation: 0.10865234151636294]
	TIME [epoch: 5.74 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12472950327862148		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.12472950327862148 | validation: 0.10544689484563996]
	TIME [epoch: 5.72 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12860088384207308		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.12860088384207308 | validation: 0.10893338968213122]
	TIME [epoch: 5.71 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130462033032339		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.130462033032339 | validation: 0.11059580461735409]
	TIME [epoch: 5.72 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12434419075732375		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.12434419075732375 | validation: 0.1036002783843708]
	TIME [epoch: 5.71 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12975765048450452		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.12975765048450452 | validation: 0.10487863334863322]
	TIME [epoch: 5.71 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12681592380460427		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.12681592380460427 | validation: 0.10189904860507723]
	TIME [epoch: 5.71 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12598323216926605		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.12598323216926605 | validation: 0.10056117506590019]
	TIME [epoch: 5.75 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129054276045304		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.129054276045304 | validation: 0.10598586406751079]
	TIME [epoch: 5.71 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12559349355729815		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.12559349355729815 | validation: 0.10347822234496175]
	TIME [epoch: 5.72 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12724596468285754		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.12724596468285754 | validation: 0.10009687600984458]
	TIME [epoch: 5.71 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12990395130674598		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.12990395130674598 | validation: 0.11094070642724735]
	TIME [epoch: 5.71 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12979839948222532		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.12979839948222532 | validation: 0.09500991176826137]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1768.pth
	Model improved!!!
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286259280523346		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.1286259280523346 | validation: 0.11637232317111802]
	TIME [epoch: 5.74 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737327703703355		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.12737327703703355 | validation: 0.10922817977101222]
	TIME [epoch: 5.71 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301239252452644		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.1301239252452644 | validation: 0.10880721100325513]
	TIME [epoch: 5.71 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13412822247077316		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.13412822247077316 | validation: 0.10587779618481567]
	TIME [epoch: 5.71 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294360737905088		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.1294360737905088 | validation: 0.1081881356853296]
	TIME [epoch: 5.71 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12969059057690097		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.12969059057690097 | validation: 0.10969268712221997]
	TIME [epoch: 5.71 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12685578618924784		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.12685578618924784 | validation: 0.10625105676670915]
	TIME [epoch: 5.72 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13286010616210597		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.13286010616210597 | validation: 0.1027701143274976]
	TIME [epoch: 5.73 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191152588904642		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.13191152588904642 | validation: 0.1161940348409047]
	TIME [epoch: 5.71 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894927699531727		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.12894927699531727 | validation: 0.10696686179651871]
	TIME [epoch: 5.71 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13023535545836956		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.13023535545836956 | validation: 0.09889743993704492]
	TIME [epoch: 5.71 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13120743701968085		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.13120743701968085 | validation: 0.11039150901942296]
	TIME [epoch: 5.71 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13177043001878652		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.13177043001878652 | validation: 0.10487914468800162]
	TIME [epoch: 5.71 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12599301587623604		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.12599301587623604 | validation: 0.09567548243383735]
	TIME [epoch: 5.74 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12840822468123933		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.12840822468123933 | validation: 0.09656134696314266]
	TIME [epoch: 5.71 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12395770219564073		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.12395770219564073 | validation: 0.10262387014652136]
	TIME [epoch: 5.71 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12813486118188228		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.12813486118188228 | validation: 0.10860946816829796]
	TIME [epoch: 5.71 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327710929237167		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.1327710929237167 | validation: 0.09678459646395685]
	TIME [epoch: 5.71 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12574517048554612		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.12574517048554612 | validation: 0.09793184135017842]
	TIME [epoch: 5.71 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12859163616047117		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.12859163616047117 | validation: 0.11044676929372886]
	TIME [epoch: 5.72 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12847539128328622		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.12847539128328622 | validation: 0.11301453640361371]
	TIME [epoch: 5.73 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12487726275212423		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.12487726275212423 | validation: 0.1149496610677788]
	TIME [epoch: 5.71 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310592904239275		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.1310592904239275 | validation: 0.11325257577081776]
	TIME [epoch: 5.71 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13006035643435288		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.13006035643435288 | validation: 0.10668987656747003]
	TIME [epoch: 5.71 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12705077786490088		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.12705077786490088 | validation: 0.105861440305246]
	TIME [epoch: 5.71 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12913362287277827		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.12913362287277827 | validation: 0.11067633288778311]
	TIME [epoch: 5.71 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468499545309591		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.12468499545309591 | validation: 0.11575598670321624]
	TIME [epoch: 5.73 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13289630448537515		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.13289630448537515 | validation: 0.12622571384331693]
	TIME [epoch: 5.71 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13479871924052986		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.13479871924052986 | validation: 0.11237284626970817]
	TIME [epoch: 5.71 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13463065135658706		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.13463065135658706 | validation: 0.11085640737163126]
	TIME [epoch: 5.71 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273581162931645		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.1273581162931645 | validation: 0.09919306971007208]
	TIME [epoch: 5.71 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13121693536513465		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.13121693536513465 | validation: 0.10198985562549337]
	TIME [epoch: 5.71 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12336735692825221		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.12336735692825221 | validation: 0.0998611174878318]
	TIME [epoch: 5.72 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12646957112053717		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.12646957112053717 | validation: 0.09450547459016745]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r5_20240310_014358/states/model_tr_study201_1802.pth
	Model improved!!!
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293172762595184		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.1293172762595184 | validation: 0.10039386385697208]
	TIME [epoch: 5.7 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12743877930087993		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.12743877930087993 | validation: 0.10359618225320542]
	TIME [epoch: 5.7 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12801871505903376		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.12801871505903376 | validation: 0.10188901371811923]
	TIME [epoch: 5.71 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12991189073194548		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.12991189073194548 | validation: 0.10988510734078721]
	TIME [epoch: 5.71 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919426299420383		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.12919426299420383 | validation: 0.1026597294709621]
	TIME [epoch: 5.71 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294056393218208		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.1294056393218208 | validation: 0.10250540474555819]
	TIME [epoch: 5.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12937622471894553		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.12937622471894553 | validation: 0.10525575155647152]
	TIME [epoch: 5.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12850670170276057		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.12850670170276057 | validation: 0.10865736664182127]
	TIME [epoch: 5.71 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12881769696134585		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.12881769696134585 | validation: 0.0961990457710019]
	TIME [epoch: 5.7 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12779177285268978		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.12779177285268978 | validation: 0.10624614202449202]
	TIME [epoch: 5.71 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12587428802713238		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.12587428802713238 | validation: 0.10056153201059825]
	TIME [epoch: 5.71 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12769681628199336		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.12769681628199336 | validation: 0.10436937942008649]
	TIME [epoch: 5.73 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12683789355406855		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.12683789355406855 | validation: 0.10825862324049994]
	TIME [epoch: 5.72 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282770119562669		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.1282770119562669 | validation: 0.10145743320966773]
	TIME [epoch: 5.71 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12715261889847496		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.12715261889847496 | validation: 0.10382478690729109]
	TIME [epoch: 5.71 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13085836205500012		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.13085836205500012 | validation: 0.1123366313964641]
	TIME [epoch: 5.7 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12805057276824727		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.12805057276824727 | validation: 0.09938333907934449]
	TIME [epoch: 5.71 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12789659414799592		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.12789659414799592 | validation: 0.10604402141388575]
	TIME [epoch: 5.71 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12954945020844189		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.12954945020844189 | validation: 0.10931531259925116]
	TIME [epoch: 5.74 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286698788157973		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.1286698788157973 | validation: 0.10847495829846959]
	TIME [epoch: 5.71 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269886910210583		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.1269886910210583 | validation: 0.10448061919601315]
	TIME [epoch: 5.71 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12778773226928583		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.12778773226928583 | validation: 0.10068746857876842]
	TIME [epoch: 5.7 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12107902675648177		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.12107902675648177 | validation: 0.1091837069161019]
	TIME [epoch: 5.7 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12712851596800415		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.12712851596800415 | validation: 0.10778151968584791]
	TIME [epoch: 5.7 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12915352032619892		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.12915352032619892 | validation: 0.10499566039394134]
	TIME [epoch: 5.73 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12738862764558184		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.12738862764558184 | validation: 0.11303532713685786]
	TIME [epoch: 5.71 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12613606488377543		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.12613606488377543 | validation: 0.10860796156172171]
	TIME [epoch: 5.7 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13319982993555352		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.13319982993555352 | validation: 0.12276044196736048]
	TIME [epoch: 5.71 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13012089561645515		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.13012089561645515 | validation: 0.11361592393080436]
	TIME [epoch: 5.7 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290476306128862		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.1290476306128862 | validation: 0.10602521037039023]
	TIME [epoch: 5.7 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293618608267545		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.1293618608267545 | validation: 0.11108046511603252]
	TIME [epoch: 5.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12577526597522617		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.12577526597522617 | validation: 0.11155519598397985]
	TIME [epoch: 5.74 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576256853368112		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.12576256853368112 | validation: 0.10682092564928697]
	TIME [epoch: 5.7 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12706563536085486		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.12706563536085486 | validation: 0.10024465773053043]
	TIME [epoch: 5.7 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265338725704308		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.1265338725704308 | validation: 0.09909427387433196]
	TIME [epoch: 5.7 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268149619374084		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.1268149619374084 | validation: 0.10034351968020336]
	TIME [epoch: 5.7 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13079237804296093		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.13079237804296093 | validation: 0.10440739850400066]
	TIME [epoch: 5.7 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12883649930484192		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.12883649930484192 | validation: 0.11353957575520784]
	TIME [epoch: 5.72 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12930497571775623		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.12930497571775623 | validation: 0.10773456104217272]
	TIME [epoch: 5.71 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12985880194109423		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.12985880194109423 | validation: 0.10421371885453658]
	TIME [epoch: 5.7 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12856413420346458		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.12856413420346458 | validation: 0.10895961425691944]
	TIME [epoch: 5.7 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12593278955151357		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.12593278955151357 | validation: 0.11423505533064664]
	TIME [epoch: 5.7 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13045858373164182		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.13045858373164182 | validation: 0.10342712126240713]
	TIME [epoch: 5.7 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273056746120907		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.1273056746120907 | validation: 0.1105618388043116]
	TIME [epoch: 5.7 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12946371481107039		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.12946371481107039 | validation: 0.09981962053451589]
	TIME [epoch: 5.74 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13340646909650605		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.13340646909650605 | validation: 0.10398191465101839]
	TIME [epoch: 5.71 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13091666323530426		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.13091666323530426 | validation: 0.10353475549828664]
	TIME [epoch: 5.7 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12420547263445939		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.12420547263445939 | validation: 0.10286085129510118]
	TIME [epoch: 5.7 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268676977208663		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.1268676977208663 | validation: 0.11127839634797532]
	TIME [epoch: 5.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127499323762511		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.127499323762511 | validation: 0.10381579034868538]
	TIME [epoch: 5.7 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12140487297541566		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.12140487297541566 | validation: 0.10458262707542586]
	TIME [epoch: 5.73 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12867009856936484		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.12867009856936484 | validation: 0.09922389169737757]
	TIME [epoch: 5.71 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12885140312834578		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.12885140312834578 | validation: 0.10589702122813639]
	TIME [epoch: 5.7 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12869043732055835		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.12869043732055835 | validation: 0.11223325411258303]
	TIME [epoch: 5.7 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13091722186352173		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.13091722186352173 | validation: 0.0994551207091823]
	TIME [epoch: 5.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12680640862011208		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.12680640862011208 | validation: 0.1086752699433832]
	TIME [epoch: 5.72 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12395635870223316		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.12395635870223316 | validation: 0.10708711016232077]
	TIME [epoch: 5.7 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12835208912963517		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.12835208912963517 | validation: 0.09869842444300435]
	TIME [epoch: 5.74 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12542856969136884		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.12542856969136884 | validation: 0.10546167455216292]
	TIME [epoch: 5.7 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12635248354820505		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.12635248354820505 | validation: 0.09809778696219716]
	TIME [epoch: 5.7 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12862861435408574		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.12862861435408574 | validation: 0.10362154018400688]
	TIME [epoch: 5.7 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12398335769937642		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.12398335769937642 | validation: 0.10543978877689802]
	TIME [epoch: 5.7 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13044991550663276		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.13044991550663276 | validation: 0.1046213063043472]
	TIME [epoch: 5.7 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12801752415136008		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.12801752415136008 | validation: 0.10249851300732957]
	TIME [epoch: 5.73 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295197025843296		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.1295197025843296 | validation: 0.10090498833437121]
	TIME [epoch: 5.71 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268852361761327		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.1268852361761327 | validation: 0.11024276150907909]
	TIME [epoch: 5.7 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12978292700329544		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.12978292700329544 | validation: 0.10864204101830272]
	TIME [epoch: 5.7 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12736360962497645		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.12736360962497645 | validation: 0.109338020040589]
	TIME [epoch: 5.7 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12507295979162303		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.12507295979162303 | validation: 0.10194226806709042]
	TIME [epoch: 5.7 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289985892521074		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.1289985892521074 | validation: 0.10275737889536002]
	TIME [epoch: 5.7 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12953564738461854		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.12953564738461854 | validation: 0.10389375034692226]
	TIME [epoch: 5.73 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12983009575554416		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.12983009575554416 | validation: 0.10464625155309275]
	TIME [epoch: 5.7 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283297691140733		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.1283297691140733 | validation: 0.10979373938536952]
	TIME [epoch: 5.69 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13036263719696978		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.13036263719696978 | validation: 0.11545269562688074]
	TIME [epoch: 5.7 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12999607766554322		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.12999607766554322 | validation: 0.11502310572981285]
	TIME [epoch: 5.7 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314970902450082		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.1314970902450082 | validation: 0.1096944934937347]
	TIME [epoch: 5.71 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13175396987510807		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.13175396987510807 | validation: 0.11226657686253695]
	TIME [epoch: 5.72 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12634191833147082		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.12634191833147082 | validation: 0.09678485530423901]
	TIME [epoch: 5.71 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12553700293147674		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.12553700293147674 | validation: 0.11181942041697993]
	TIME [epoch: 5.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13331834514165364		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.13331834514165364 | validation: 0.10928883524152888]
	TIME [epoch: 5.69 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13055861349254538		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.13055861349254538 | validation: 0.10525858958911113]
	TIME [epoch: 5.7 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12852491848274372		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.12852491848274372 | validation: 0.10564056566633223]
	TIME [epoch: 5.7 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12998042218128197		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.12998042218128197 | validation: 0.1016890433733731]
	TIME [epoch: 5.7 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256922965953127		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.1256922965953127 | validation: 0.11218672506992271]
	TIME [epoch: 5.74 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12829106972974602		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.12829106972974602 | validation: 0.10693595088330056]
	TIME [epoch: 5.7 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310965320423505		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.1310965320423505 | validation: 0.10533434265411515]
	TIME [epoch: 5.7 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284184005039723		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.1284184005039723 | validation: 0.10118984494659784]
	TIME [epoch: 5.71 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13065067233830607		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.13065067233830607 | validation: 0.11396887724440305]
	TIME [epoch: 5.7 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306077086312078		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.1306077086312078 | validation: 0.11559265219234612]
	TIME [epoch: 5.7 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129060792919252		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.129060792919252 | validation: 0.11440537558957642]
	TIME [epoch: 5.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089821065237656		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.13089821065237656 | validation: 0.10591769406128569]
	TIME [epoch: 5.71 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1258104657561537		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.1258104657561537 | validation: 0.10662235757592076]
	TIME [epoch: 5.7 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282423920076478		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.1282423920076478 | validation: 0.10421041682553855]
	TIME [epoch: 5.71 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12843968603887493		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.12843968603887493 | validation: 0.11238599091705219]
	TIME [epoch: 5.69 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304681468616099		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.1304681468616099 | validation: 0.11208989493088188]
	TIME [epoch: 5.7 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271014717137347		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.1271014717137347 | validation: 0.11072998038210503]
	TIME [epoch: 5.69 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12953466265537203		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.12953466265537203 | validation: 0.1068356499178421]
	TIME [epoch: 5.74 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276455058605949		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.1276455058605949 | validation: 0.12183744238195676]
	TIME [epoch: 5.7 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275634707686546		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.1275634707686546 | validation: 0.11001777785319419]
	TIME [epoch: 5.7 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13301209513694845		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.13301209513694845 | validation: 0.12324477161574628]
	TIME [epoch: 5.69 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344176433049081		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.1344176433049081 | validation: 0.12169251989689968]
	TIME [epoch: 5.69 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13196302857407882		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.13196302857407882 | validation: 0.11148720279211558]
	TIME [epoch: 5.69 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12992329980526685		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.12992329980526685 | validation: 0.11916172582843328]
	TIME [epoch: 5.73 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340968720492929		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.1340968720492929 | validation: 0.11821247382456694]
	TIME [epoch: 5.71 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12804469946699298		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.12804469946699298 | validation: 0.11079717177874773]
	TIME [epoch: 5.7 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320988377745304		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.1320988377745304 | validation: 0.09694685091308239]
	TIME [epoch: 5.7 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325901165373933		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.1325901165373933 | validation: 0.11443876156073056]
	TIME [epoch: 5.69 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13275415992111456		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.13275415992111456 | validation: 0.10650933115782867]
	TIME [epoch: 5.7 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12720146555206793		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.12720146555206793 | validation: 0.10665612629182886]
	TIME [epoch: 5.7 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12620918394358172		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.12620918394358172 | validation: 0.11426579147187042]
	TIME [epoch: 5.75 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282968055069958		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.1282968055069958 | validation: 0.10690096210580069]
	TIME [epoch: 5.71 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12670757584222594		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.12670757584222594 | validation: 0.10247790806925876]
	TIME [epoch: 5.69 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1215894705527494		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.1215894705527494 | validation: 0.10608121445204936]
	TIME [epoch: 5.7 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1299163079597866		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.1299163079597866 | validation: 0.11017509374160468]
	TIME [epoch: 5.69 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12840185585934139		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.12840185585934139 | validation: 0.100395211609003]
	TIME [epoch: 5.69 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793829698610754		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.12793829698610754 | validation: 0.10321540633269848]
	TIME [epoch: 5.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13020087606846106		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.13020087606846106 | validation: 0.10500568728168898]
	TIME [epoch: 5.71 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13012515162256777		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.13012515162256777 | validation: 0.10409019078771987]
	TIME [epoch: 5.7 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281467219095238		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.1281467219095238 | validation: 0.10602388233954407]
	TIME [epoch: 5.69 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12698716280572664		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.12698716280572664 | validation: 0.10922616143183975]
	TIME [epoch: 5.7 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12648189948624305		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.12648189948624305 | validation: 0.10269602617145104]
	TIME [epoch: 5.71 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128836085251058		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.128836085251058 | validation: 0.10948078096172367]
	TIME [epoch: 5.7 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13353368448673722		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.13353368448673722 | validation: 0.11169927666108191]
	TIME [epoch: 5.74 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277146071998614		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.1277146071998614 | validation: 0.12038232865840605]
	TIME [epoch: 5.71 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12664716882375038		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.12664716882375038 | validation: 0.10843987998690528]
	TIME [epoch: 5.71 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277859691642751		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.1277859691642751 | validation: 0.11262069460923183]
	TIME [epoch: 5.71 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12877892203390362		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.12877892203390362 | validation: 0.10168396158790666]
	TIME [epoch: 5.7 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13119715130561851		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.13119715130561851 | validation: 0.09993834100763443]
	TIME [epoch: 5.69 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12759068053747846		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.12759068053747846 | validation: 0.10978297475658642]
	TIME [epoch: 5.73 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12762026554084135		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.12762026554084135 | validation: 0.09837006821177074]
	TIME [epoch: 5.71 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12802610484149146		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.12802610484149146 | validation: 0.10789906123115522]
	TIME [epoch: 5.7 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12549668458474295		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.12549668458474295 | validation: 0.11444642847025734]
	TIME [epoch: 5.71 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275201754617857		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.1275201754617857 | validation: 0.12224622852948151]
	TIME [epoch: 5.7 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316154817976205		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.1316154817976205 | validation: 0.12471747399978464]
	TIME [epoch: 5.7 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12901519060557892		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.12901519060557892 | validation: 0.11730572969115045]
	TIME [epoch: 5.7 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326874247536564		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.1326874247536564 | validation: 0.11524654125621626]
	TIME [epoch: 5.73 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13119469783036983		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.13119469783036983 | validation: 0.11289005034521597]
	TIME [epoch: 5.7 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12782094083894321		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.12782094083894321 | validation: 0.1098739647604885]
	TIME [epoch: 5.69 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12671987389050443		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.12671987389050443 | validation: 0.10446446854526613]
	TIME [epoch: 5.7 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12868985400006716		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.12868985400006716 | validation: 0.11098556545086838]
	TIME [epoch: 5.69 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281637401354012		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.1281637401354012 | validation: 0.1026379293291371]
	TIME [epoch: 5.7 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12518465907311396		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.12518465907311396 | validation: 0.11404078258054881]
	TIME [epoch: 5.74 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12530721817202542		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.12530721817202542 | validation: 0.11189901702769056]
	TIME [epoch: 5.71 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13038382626155978		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.13038382626155978 | validation: 0.10363322169829067]
	TIME [epoch: 5.7 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12714205489123193		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.12714205489123193 | validation: 0.10623411336534783]
	TIME [epoch: 5.69 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12463710676713328		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.12463710676713328 | validation: 0.10587321344074123]
	TIME [epoch: 5.7 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12616514598863265		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.12616514598863265 | validation: 0.10257288491625448]
	TIME [epoch: 5.71 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12768327339852742		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.12768327339852742 | validation: 0.11786168951700013]
	TIME [epoch: 5.7 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12862920736560302		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.12862920736560302 | validation: 0.10407191017511794]
	TIME [epoch: 5.74 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12931564917454036		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.12931564917454036 | validation: 0.11053067409456788]
	TIME [epoch: 5.7 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13030713898699514		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.13030713898699514 | validation: 0.11738282071850094]
	TIME [epoch: 5.7 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12893419900134057		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.12893419900134057 | validation: 0.11534408285403522]
	TIME [epoch: 5.7 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13433837062011564		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.13433837062011564 | validation: 0.11113744630423815]
	TIME [epoch: 5.69 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13002410804128545		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.13002410804128545 | validation: 0.10712924603097902]
	TIME [epoch: 5.7 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13186376275550765		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.13186376275550765 | validation: 0.10401033392713256]
	TIME [epoch: 5.74 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319092513693033		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.1319092513693033 | validation: 0.10719323670334047]
	TIME [epoch: 5.72 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13472807271151888		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.13472807271151888 | validation: 0.1134006030131757]
	TIME [epoch: 5.71 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13462015863025398		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.13462015863025398 | validation: 0.11012012632207985]
	TIME [epoch: 5.7 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13582288832633255		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.13582288832633255 | validation: 0.11021535356969342]
	TIME [epoch: 5.71 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337698055610222		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.1337698055610222 | validation: 0.11176787406602232]
	TIME [epoch: 5.71 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853272890983476		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.13853272890983476 | validation: 0.11082360281595367]
	TIME [epoch: 5.69 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13645723283345929		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.13645723283345929 | validation: 0.1135331003554064]
	TIME [epoch: 5.74 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13222266218585946		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.13222266218585946 | validation: 0.109295495991543]
	TIME [epoch: 5.71 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12944036336993064		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.12944036336993064 | validation: 0.10783481401660323]
	TIME [epoch: 5.7 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13159642533733368		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.13159642533733368 | validation: 0.11046477669653051]
	TIME [epoch: 5.7 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12337722060217354		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.12337722060217354 | validation: 0.10517456107727557]
	TIME [epoch: 5.69 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13351536986416576		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.13351536986416576 | validation: 0.10231115609143551]
	TIME [epoch: 5.71 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12672134973501287		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.12672134973501287 | validation: 0.10672590142869437]
	TIME [epoch: 5.73 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12311866829028245		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.12311866829028245 | validation: 0.10483068931864234]
	TIME [epoch: 5.7 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12862567640570272		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.12862567640570272 | validation: 0.10356741975182882]
	TIME [epoch: 5.7 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12799171652163063		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.12799171652163063 | validation: 0.1083255407136212]
	TIME [epoch: 5.7 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12898711732021592		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.12898711732021592 | validation: 0.10250464484977984]
	TIME [epoch: 5.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419420808906517		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.12419420808906517 | validation: 0.1088195110340467]
	TIME [epoch: 5.7 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251645979509845		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.1251645979509845 | validation: 0.11171709237301684]
	TIME [epoch: 5.7 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12586130174871965		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.12586130174871965 | validation: 0.10973382834107191]
	TIME [epoch: 5.73 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12423675207147172		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.12423675207147172 | validation: 0.10740378279795315]
	TIME [epoch: 5.71 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13048091880256185		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.13048091880256185 | validation: 0.11403666202670328]
	TIME [epoch: 5.7 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12962727723896056		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.12962727723896056 | validation: 0.09817124189756253]
	TIME [epoch: 5.7 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13081193378991218		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.13081193378991218 | validation: 0.10975915845862474]
	TIME [epoch: 5.7 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12815111485125144		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.12815111485125144 | validation: 0.10606940560890266]
	TIME [epoch: 5.7 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1235010198564453		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.1235010198564453 | validation: 0.10577487856852233]
	TIME [epoch: 5.73 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12659403090517357		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.12659403090517357 | validation: 0.09979180514923208]
	TIME [epoch: 5.7 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12570768922220912		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.12570768922220912 | validation: 0.10267500268212086]
	TIME [epoch: 5.69 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263741249320282		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.1263741249320282 | validation: 0.10211202089340919]
	TIME [epoch: 5.7 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12675126141929854		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.12675126141929854 | validation: 0.11000574194766138]
	TIME [epoch: 5.7 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286827961187006		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.1286827961187006 | validation: 0.09970434003440427]
	TIME [epoch: 5.71 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12417756232193672		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.12417756232193672 | validation: 0.10358152952117734]
	TIME [epoch: 5.73 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12660316973093316		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.12660316973093316 | validation: 0.09565508470920774]
	TIME [epoch: 5.73 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255906024867869		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.1255906024867869 | validation: 0.10297823696850805]
	TIME [epoch: 5.7 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12506993475406025		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.12506993475406025 | validation: 0.10846539638429623]
	TIME [epoch: 5.7 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543696262110954		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.12543696262110954 | validation: 0.11250322726776851]
	TIME [epoch: 5.69 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291502845486183		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.1291502845486183 | validation: 0.10898737122684693]
	TIME [epoch: 5.7 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12700096906634514		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.12700096906634514 | validation: 0.11255762024953693]
	TIME [epoch: 5.7 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255457419014214		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.1255457419014214 | validation: 0.09855255830144205]
	TIME [epoch: 5.73 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12984223850770496		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.12984223850770496 | validation: 0.11114271956130725]
	TIME [epoch: 5.71 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13042685275087026		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.13042685275087026 | validation: 0.11279248526597314]
	TIME [epoch: 5.71 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262023264084521		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.1262023264084521 | validation: 0.10794378951019477]
	TIME [epoch: 5.71 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12780441000937925		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.12780441000937925 | validation: 0.103913820338072]
	TIME [epoch: 5.71 sec]
Finished training in 11691.093 seconds.
