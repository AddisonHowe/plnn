Args:
Namespace(name='model_tr_study201', outdir='out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0', training_data='data/transition_rate_studies/tr_study201/tr_study201_training/r0', validation_data='data/transition_rate_studies/tr_study201/tr_study201_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3605982288

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.752182543765816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.752182543765816 | validation: 10.419018579539625]
	TIME [epoch: 92.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.426831366092339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.426831366092339 | validation: 8.921021461649081]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.459508463061507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.459508463061507 | validation: 7.962665747772966]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.521067941210351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.521067941210351 | validation: 8.50786090502315]
	TIME [epoch: 5.73 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.010525244587603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.010525244587603 | validation: 6.217526258168463]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.834003113412795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.834003113412795 | validation: 4.553873919257324]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.753032803563899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.753032803563899 | validation: 4.336188898228272]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.325747804280235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.325747804280235 | validation: 3.6664736193286958]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.184800451705407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.184800451705407 | validation: 3.7710763574143273]
	TIME [epoch: 5.76 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9866725548387163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9866725548387163 | validation: 3.4341890488445683]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.916220636003084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.916220636003084 | validation: 3.1381087145749946]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.097729585033885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.097729585033885 | validation: 3.126332242271293]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7061184071166524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7061184071166524 | validation: 5.5834827427930165]
	TIME [epoch: 5.71 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.209961511256446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.209961511256446 | validation: 4.296046302471165]
	TIME [epoch: 5.7 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.079622783649734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.079622783649734 | validation: 3.3602638502535287]
	TIME [epoch: 5.72 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.41392766902956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.41392766902956 | validation: 3.001290846235006]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.458987152418674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.458987152418674 | validation: 2.7657059282409127]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.276437113771127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.276437113771127 | validation: 3.680765640464013]
	TIME [epoch: 5.71 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7230713403038234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7230713403038234 | validation: 2.8042008404014576]
	TIME [epoch: 5.71 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.421879536472175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.421879536472175 | validation: 2.688622046547205]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4292679048758594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4292679048758594 | validation: 2.8051411777939017]
	TIME [epoch: 5.71 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.329034624346035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.329034624346035 | validation: 2.838193916300589]
	TIME [epoch: 5.75 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.182522004921794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.182522004921794 | validation: 2.676163478098797]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1809880298709934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1809880298709934 | validation: 2.9355717102979257]
	TIME [epoch: 5.71 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.17212614697973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.17212614697973 | validation: 2.647913984086523]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2573793147448162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2573793147448162 | validation: 3.309836415028916]
	TIME [epoch: 5.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5332922249054315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5332922249054315 | validation: 2.551468885218976]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0626205493815988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0626205493815988 | validation: 4.276899341983815]
	TIME [epoch: 5.72 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.724066267738177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.724066267738177 | validation: 2.5368255157508477]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.165094631212796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.165094631212796 | validation: 2.7794469673597453]
	TIME [epoch: 5.73 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.057669238662809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.057669238662809 | validation: 2.875230466030565]
	TIME [epoch: 5.7 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0681897723918765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0681897723918765 | validation: 2.910183957113134]
	TIME [epoch: 5.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.988038955282035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.988038955282035 | validation: 2.838334690959216]
	TIME [epoch: 5.71 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.408199965926143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.408199965926143 | validation: 3.6269274334738624]
	TIME [epoch: 5.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5400486034489744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5400486034489744 | validation: 3.3856242610033247]
	TIME [epoch: 5.72 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3025696750858304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3025696750858304 | validation: 2.330141657757977]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0477540225178514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0477540225178514 | validation: 2.3346092815583996]
	TIME [epoch: 5.72 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1227430161697587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1227430161697587 | validation: 3.593723302014025]
	TIME [epoch: 5.71 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3039930729388525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3039930729388525 | validation: 2.490703032112138]
	TIME [epoch: 5.71 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4808776476068424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4808776476068424 | validation: 2.5611830579356174]
	TIME [epoch: 5.71 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.967993353188339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.967993353188339 | validation: 2.8999097234792597]
	TIME [epoch: 5.71 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0108359782822705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0108359782822705 | validation: 3.260394441629265]
	TIME [epoch: 5.75 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.253011673998711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.253011673998711 | validation: 2.2806877701138406]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9212297269935217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9212297269935217 | validation: 2.6164377207590794]
	TIME [epoch: 5.71 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.02451410561756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.02451410561756 | validation: 3.6881147846526767]
	TIME [epoch: 5.71 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5896318292062617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5896318292062617 | validation: 4.001819151428147]
	TIME [epoch: 5.71 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3182619579598764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3182619579598764 | validation: 3.266233445577002]
	TIME [epoch: 5.71 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9498907477901524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9498907477901524 | validation: 3.0036104526303986]
	TIME [epoch: 5.72 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.336676122306391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.336676122306391 | validation: 2.7803375950100953]
	TIME [epoch: 5.74 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9872053631184365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9872053631184365 | validation: 3.095117365250782]
	TIME [epoch: 5.71 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.118129998873281		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.118129998873281 | validation: 2.782581887699008]
	TIME [epoch: 5.71 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0840536747196987		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.0840536747196987 | validation: 2.191536269073267]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0013794726400365		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.0013794726400365 | validation: 2.2124669277747104]
	TIME [epoch: 5.71 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9196422397444137		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.9196422397444137 | validation: 2.296315776979352]
	TIME [epoch: 5.71 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8184046417917625		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.8184046417917625 | validation: 2.614002848976885]
	TIME [epoch: 5.75 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9346604743054243		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.9346604743054243 | validation: 2.8978571946270235]
	TIME [epoch: 5.73 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.943620774620995		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.943620774620995 | validation: 2.405851414748518]
	TIME [epoch: 5.71 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9211599546899882		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.9211599546899882 | validation: 3.481068364913831]
	TIME [epoch: 5.71 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6324145834592017		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.6324145834592017 | validation: 2.1009262749788156]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.072465471181196		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.072465471181196 | validation: 2.0763568697856862]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6912944669158927		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.6912944669158927 | validation: 2.5624488326325694]
	TIME [epoch: 5.75 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6074039832078517		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.6074039832078517 | validation: 2.5615639835782704]
	TIME [epoch: 5.74 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.606919714406523		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.606919714406523 | validation: 2.9836740597393208]
	TIME [epoch: 5.71 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.534407243931265		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.534407243931265 | validation: 2.5806422260797386]
	TIME [epoch: 5.71 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5688359127009113		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.5688359127009113 | validation: 2.169539558727511]
	TIME [epoch: 5.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4150470541202966		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.4150470541202966 | validation: 2.248605087714198]
	TIME [epoch: 5.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0304961978678797		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.0304961978678797 | validation: 2.066752638703049]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7678419117847106		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.7678419117847106 | validation: 1.995916225343851]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.135973807838738		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.135973807838738 | validation: 1.9214514165634666]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9816245617553183		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.9816245617553183 | validation: 2.2030177792343593]
	TIME [epoch: 5.71 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.879331034641198		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.879331034641198 | validation: 2.1004635936839584]
	TIME [epoch: 5.72 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6386915379488594		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.6386915379488594 | validation: 1.8628145123174222]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4819807075014872		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.4819807075014872 | validation: 4.008251526408044]
	TIME [epoch: 5.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9035354656305317		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.9035354656305317 | validation: 2.236672827409469]
	TIME [epoch: 5.76 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.184059148203868		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.184059148203868 | validation: 2.9606593848408513]
	TIME [epoch: 5.71 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.745137026118735		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.745137026118735 | validation: 4.163001750114561]
	TIME [epoch: 5.71 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8921328245261275		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.8921328245261275 | validation: 3.3973236784200895]
	TIME [epoch: 5.71 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.824223806196913		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.824223806196913 | validation: 2.567471675433725]
	TIME [epoch: 5.72 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.535433753843976		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.535433753843976 | validation: 3.3030583397791453]
	TIME [epoch: 5.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8195505787514277		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.8195505787514277 | validation: 2.5174267136136494]
	TIME [epoch: 5.72 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.609171303083731		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.609171303083731 | validation: 2.7549673879268073]
	TIME [epoch: 5.74 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6240334276805712		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.6240334276805712 | validation: 2.721696326997667]
	TIME [epoch: 5.71 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.588294022079703		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.588294022079703 | validation: 2.4410461988398415]
	TIME [epoch: 5.71 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7917450080741317		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.7917450080741317 | validation: 3.1614035783998227]
	TIME [epoch: 5.71 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7312682482855544		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.7312682482855544 | validation: 1.8144264426010273]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3474419233041575		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.3474419233041575 | validation: 2.0250337897919084]
	TIME [epoch: 5.71 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3441605442553257		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.3441605442553257 | validation: 2.448151485501839]
	TIME [epoch: 5.75 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4206687947128036		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.4206687947128036 | validation: 1.645863702389936]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1999186055480093		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.1999186055480093 | validation: 1.7717595657698046]
	TIME [epoch: 5.71 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2512760653126254		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.2512760653126254 | validation: 2.174730014798368]
	TIME [epoch: 5.71 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.478690676654493		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.478690676654493 | validation: 1.6116379593929595]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2126058685635335		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.2126058685635335 | validation: 1.744894624552195]
	TIME [epoch: 5.71 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.144739324061015		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.144739324061015 | validation: 1.7217895104136056]
	TIME [epoch: 5.74 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.141262458660762		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.141262458660762 | validation: 1.5337184116512241]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090052668994728		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.090052668994728 | validation: 1.7496287132316173]
	TIME [epoch: 5.71 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1241992016919244		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.1241992016919244 | validation: 1.907587444310474]
	TIME [epoch: 5.71 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1644592130973987		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.1644592130973987 | validation: 1.9701756428736656]
	TIME [epoch: 5.71 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0754026432081196		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.0754026432081196 | validation: 1.4194120365203582]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.531722619186343		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.531722619186343 | validation: 1.4848162557921563]
	TIME [epoch: 5.72 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.843076510813063		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.843076510813063 | validation: 1.6285768297280436]
	TIME [epoch: 5.74 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.521857834366176		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.521857834366176 | validation: 1.550374629980975]
	TIME [epoch: 5.71 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.053205169138103		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.053205169138103 | validation: 4.250050296948956]
	TIME [epoch: 5.71 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6889468195714885		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.6889468195714885 | validation: 1.9497508182463197]
	TIME [epoch: 5.71 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.137700011678006		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.137700011678006 | validation: 2.0349205083704955]
	TIME [epoch: 5.71 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0445651675450285		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.0445651675450285 | validation: 2.0937785073785644]
	TIME [epoch: 5.71 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0894985979744956		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.0894985979744956 | validation: 1.9057662800844513]
	TIME [epoch: 5.75 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9981798218854765		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.9981798218854765 | validation: 2.1975045101700132]
	TIME [epoch: 5.72 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055661477235506		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.055661477235506 | validation: 1.77784791410022]
	TIME [epoch: 5.71 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1478989594737263		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.1478989594737263 | validation: 1.5981736136778182]
	TIME [epoch: 5.71 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293267174839804		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.293267174839804 | validation: 1.4741075974388653]
	TIME [epoch: 5.71 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9663033250512023		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.9663033250512023 | validation: 2.3116870710966073]
	TIME [epoch: 5.71 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281628356923858		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.281628356923858 | validation: 3.6060118571737623]
	TIME [epoch: 5.72 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.661504465050461		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.661504465050461 | validation: 3.3319457475514596]
	TIME [epoch: 5.75 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.447638885769741		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.447638885769741 | validation: 2.9088070214122537]
	TIME [epoch: 5.71 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2280237981850597		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.2280237981850597 | validation: 1.85455931967471]
	TIME [epoch: 5.71 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0879069220997195		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.0879069220997195 | validation: 2.0194814740676073]
	TIME [epoch: 5.71 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0216358869038116		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.0216358869038116 | validation: 1.9945739488693606]
	TIME [epoch: 5.71 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9977129390899662		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.9977129390899662 | validation: 2.6576782409349415]
	TIME [epoch: 5.71 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1612763792304417		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.1612763792304417 | validation: 2.998434212738961]
	TIME [epoch: 5.75 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.863459122090239		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.863459122090239 | validation: 2.2444597258189023]
	TIME [epoch: 5.72 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.870396708814566		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.870396708814566 | validation: 2.324105050018226]
	TIME [epoch: 5.71 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344357462834357		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.344357462834357 | validation: 3.1948114390099103]
	TIME [epoch: 5.71 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7898166013318026		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.7898166013318026 | validation: 2.3294261237136316]
	TIME [epoch: 5.71 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3214535044100852		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.3214535044100852 | validation: 1.9910271866158749]
	TIME [epoch: 5.71 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4814939818176978		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.4814939818176978 | validation: 2.065319277800435]
	TIME [epoch: 5.71 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2765322570607833		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.2765322570607833 | validation: 1.5770380362283607]
	TIME [epoch: 5.75 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1206427647318185		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.1206427647318185 | validation: 1.70991465833743]
	TIME [epoch: 5.71 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9784600547231515		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.9784600547231515 | validation: 1.6667110414057198]
	TIME [epoch: 5.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1964673549137386		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.1964673549137386 | validation: 1.3351745159938548]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8802752358002586		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.8802752358002586 | validation: 1.9288052282319348]
	TIME [epoch: 5.71 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1273260636520197		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.1273260636520197 | validation: 1.3226424805113441]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8739164870541098		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.8739164870541098 | validation: 1.3842850209403883]
	TIME [epoch: 5.75 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1101234383821845		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.1101234383821845 | validation: 1.297367889925576]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8455317776363964		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.8455317776363964 | validation: 2.083795702577539]
	TIME [epoch: 5.71 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4728243849987575		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.4728243849987575 | validation: 1.5260910656243392]
	TIME [epoch: 5.71 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2787729573794278		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.2787729573794278 | validation: 1.4043354866196591]
	TIME [epoch: 5.71 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8118558684701944		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.8118558684701944 | validation: 1.4931352184393916]
	TIME [epoch: 5.71 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2049416859512445		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.2049416859512445 | validation: 1.4120528219272155]
	TIME [epoch: 5.72 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.432901425920593		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.432901425920593 | validation: 1.5316072314070546]
	TIME [epoch: 5.74 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.363650252235213		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.363650252235213 | validation: 1.857144890722507]
	TIME [epoch: 5.71 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1913920394014372		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.1913920394014372 | validation: 2.0841205787510217]
	TIME [epoch: 5.71 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1817802354198785		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.1817802354198785 | validation: 1.797176227595026]
	TIME [epoch: 5.71 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2511897734106294		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.2511897734106294 | validation: 2.3352022260213237]
	TIME [epoch: 5.71 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1285245362542957		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.1285245362542957 | validation: 1.3575331240429938]
	TIME [epoch: 5.71 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.797476485755455		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.797476485755455 | validation: 1.601861683412888]
	TIME [epoch: 5.75 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8121373738171993		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.8121373738171993 | validation: 2.4137829969598026]
	TIME [epoch: 5.72 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9957191316277394		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.9957191316277394 | validation: 1.6489268392009608]
	TIME [epoch: 5.71 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7953887351625868		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.7953887351625868 | validation: 1.3066970896668266]
	TIME [epoch: 5.71 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.76173436677609		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.76173436677609 | validation: 1.3524710227721728]
	TIME [epoch: 5.71 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739197459811011		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.739197459811011 | validation: 1.3917946992430026]
	TIME [epoch: 5.71 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.755667787625626		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.755667787625626 | validation: 1.207556674387651]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6997214637666387		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.6997214637666387 | validation: 1.2737702721856594]
	TIME [epoch: 5.75 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7137968798485055		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.7137968798485055 | validation: 2.4841394443636973]
	TIME [epoch: 5.71 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.645380418804097		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.645380418804097 | validation: 1.7332757362696891]
	TIME [epoch: 5.71 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273897230526939		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.273897230526939 | validation: 1.8038422359960773]
	TIME [epoch: 5.71 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8503981961809646		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.8503981961809646 | validation: 1.454060801239131]
	TIME [epoch: 5.71 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7858886939992398		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.7858886939992398 | validation: 1.3886792685649993]
	TIME [epoch: 5.71 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6385778234888044		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.6385778234888044 | validation: 1.3026168026565672]
	TIME [epoch: 5.75 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8821154662266273		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.8821154662266273 | validation: 1.3762062088829705]
	TIME [epoch: 5.72 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0005830097975568		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.0005830097975568 | validation: 3.3822321771362738]
	TIME [epoch: 5.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5074212600167267		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.5074212600167267 | validation: 1.4621649257508689]
	TIME [epoch: 5.71 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8473017657799242		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.8473017657799242 | validation: 2.797053675184705]
	TIME [epoch: 5.71 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360157806469514		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.360157806469514 | validation: 1.4373541943622312]
	TIME [epoch: 5.71 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1740480216649		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.1740480216649 | validation: 1.4143345538862926]
	TIME [epoch: 5.72 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9941979654191795		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.9941979654191795 | validation: 1.5881261539853604]
	TIME [epoch: 5.74 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8854033340670813		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.8854033340670813 | validation: 1.5258086999763365]
	TIME [epoch: 5.71 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7448237602651377		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.7448237602651377 | validation: 1.1317437595990947]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735063600090211		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.735063600090211 | validation: 2.879042826854734]
	TIME [epoch: 5.71 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5141188350591324		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.5141188350591324 | validation: 2.043999549843458]
	TIME [epoch: 5.71 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0199750048167213		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.0199750048167213 | validation: 2.6020718794610467]
	TIME [epoch: 5.71 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0691552430675797		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.0691552430675797 | validation: 2.0830633423865392]
	TIME [epoch: 5.75 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260126913221809		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.260126913221809 | validation: 1.573672819609055]
	TIME [epoch: 5.71 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7406636058894356		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.7406636058894356 | validation: 1.938479280728031]
	TIME [epoch: 5.71 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7753103221053523		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.7753103221053523 | validation: 2.0207241693376488]
	TIME [epoch: 5.71 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.39062816230511		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.39062816230511 | validation: 2.0836031917609588]
	TIME [epoch: 5.71 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.180168836392126		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.180168836392126 | validation: 1.8449440100637424]
	TIME [epoch: 5.71 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.009016305547367		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.009016305547367 | validation: 2.02526987888865]
	TIME [epoch: 5.72 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8907415687873053		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.8907415687873053 | validation: 2.4518310825910525]
	TIME [epoch: 5.74 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1177603681905777		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.1177603681905777 | validation: 1.2235384982210402]
	TIME [epoch: 5.71 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5805414516766787		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.5805414516766787 | validation: 1.8201803472272382]
	TIME [epoch: 5.71 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6481017120964538		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.6481017120964538 | validation: 1.5073674734307827]
	TIME [epoch: 5.71 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6275082053913867		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.6275082053913867 | validation: 1.4251028156330765]
	TIME [epoch: 5.71 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5626146547644508		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.5626146547644508 | validation: 1.3731746382876282]
	TIME [epoch: 5.71 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5881016194691255		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.5881016194691255 | validation: 2.2768022577695994]
	TIME [epoch: 5.75 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8127977915030604		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.8127977915030604 | validation: 2.221922217661629]
	TIME [epoch: 5.72 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8049039582486535		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.8049039582486535 | validation: 2.0485009752753407]
	TIME [epoch: 5.71 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8058647909852954		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.8058647909852954 | validation: 2.1450649462438345]
	TIME [epoch: 5.71 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7039604730899622		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.7039604730899622 | validation: 1.6305536839290158]
	TIME [epoch: 5.71 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.65023826312221		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.65023826312221 | validation: 1.27818682349387]
	TIME [epoch: 5.71 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8185059223022244		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.8185059223022244 | validation: 1.245624128885217]
	TIME [epoch: 5.72 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06126054691185		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.06126054691185 | validation: 1.5811935299307238]
	TIME [epoch: 5.74 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8465215603944798		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.8465215603944798 | validation: 1.2102939214889572]
	TIME [epoch: 5.71 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9017341554369813		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.9017341554369813 | validation: 1.6446725078657174]
	TIME [epoch: 5.71 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1060667915563367		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.1060667915563367 | validation: 1.5690344966344723]
	TIME [epoch: 5.71 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2792111508384543		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.2792111508384543 | validation: 1.3449185877596677]
	TIME [epoch: 5.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1836165366055402		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.1836165366055402 | validation: 1.3788182040905101]
	TIME [epoch: 5.71 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.138978637855309		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.138978637855309 | validation: 1.7339810154699542]
	TIME [epoch: 5.75 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0369576738002713		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.0369576738002713 | validation: 1.3408199122960565]
	TIME [epoch: 5.72 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0642885647199485		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.0642885647199485 | validation: 1.4368976210411555]
	TIME [epoch: 5.71 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.025668299858758		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.025668299858758 | validation: 1.3079514565864563]
	TIME [epoch: 5.71 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7851016889361981		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.7851016889361981 | validation: 1.3676009955134079]
	TIME [epoch: 5.71 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.78195684404583		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.78195684404583 | validation: 1.1570054152047247]
	TIME [epoch: 5.71 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8786189422736732		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.8786189422736732 | validation: 1.2421880469276623]
	TIME [epoch: 5.72 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.952252136898631		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.952252136898631 | validation: 1.2459923609115737]
	TIME [epoch: 5.75 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8720745443254279		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.8720745443254279 | validation: 1.2255553390812701]
	TIME [epoch: 5.71 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8128846489693018		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.8128846489693018 | validation: 1.1664145789653813]
	TIME [epoch: 5.71 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9985612819685799		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.9985612819685799 | validation: 1.4232303999049816]
	TIME [epoch: 5.71 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8902903497922827		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.8902903497922827 | validation: 1.262943274503863]
	TIME [epoch: 5.71 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8418434801830519		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.8418434801830519 | validation: 1.1793718097567412]
	TIME [epoch: 5.71 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8220631764139124		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.8220631764139124 | validation: 1.3064551011633843]
	TIME [epoch: 5.75 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5398157377863133		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.5398157377863133 | validation: 1.786096521312059]
	TIME [epoch: 5.72 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0382860060677985		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.0382860060677985 | validation: 1.4321725844541688]
	TIME [epoch: 5.71 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.766131172981408		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.766131172981408 | validation: 1.5701964971491338]
	TIME [epoch: 5.71 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8930209289243427		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.8930209289243427 | validation: 1.5443816611338281]
	TIME [epoch: 5.71 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.714549325720101		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.714549325720101 | validation: 2.1368900533956894]
	TIME [epoch: 5.71 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9733269883135367		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.9733269883135367 | validation: 1.7396473770754042]
	TIME [epoch: 5.72 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7764555754266502		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.7764555754266502 | validation: 2.0838088038386644]
	TIME [epoch: 5.74 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9159050283221672		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.9159050283221672 | validation: 1.8927187420961593]
	TIME [epoch: 5.72 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8805563835551184		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.8805563835551184 | validation: 1.331489851125948]
	TIME [epoch: 5.71 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.003413425906849		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.003413425906849 | validation: 1.8874618388722268]
	TIME [epoch: 5.71 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7059910590202816		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.7059910590202816 | validation: 1.2129560238738117]
	TIME [epoch: 5.71 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4969355042713905		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.4969355042713905 | validation: 1.411460444134287]
	TIME [epoch: 5.71 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6514574415098344		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.6514574415098344 | validation: 0.9969731985274259]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.483584969790274		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.483584969790274 | validation: 1.0608592124733016]
	TIME [epoch: 5.72 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4551810516034511		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.4551810516034511 | validation: 1.1971901426360168]
	TIME [epoch: 5.71 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4981168799021651		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.4981168799021651 | validation: 1.0999277934083278]
	TIME [epoch: 5.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.680281744922827		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.680281744922827 | validation: 1.0171077207166968]
	TIME [epoch: 5.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.958820517396057		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.958820517396057 | validation: 1.8966036074580621]
	TIME [epoch: 5.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9660476988282407		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.9660476988282407 | validation: 1.3957618427126088]
	TIME [epoch: 5.72 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8260343589058596		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.8260343589058596 | validation: 1.2480261808824036]
	TIME [epoch: 5.74 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7747850328676722		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.7747850328676722 | validation: 1.9934961379723473]
	TIME [epoch: 5.72 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9837532774769975		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.9837532774769975 | validation: 1.2718019242957248]
	TIME [epoch: 5.71 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.504775766981587		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.504775766981587 | validation: 1.9789349996098184]
	TIME [epoch: 5.71 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.09668522216824		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.09668522216824 | validation: 1.6152448195724387]
	TIME [epoch: 5.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.030408531076871		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.030408531076871 | validation: 1.6838153238774942]
	TIME [epoch: 5.71 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8166816692962808		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.8166816692962808 | validation: 1.4657298723109455]
	TIME [epoch: 5.75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.551285235154457		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.551285235154457 | validation: 1.121842925846085]
	TIME [epoch: 5.72 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.595532564132887		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.595532564132887 | validation: 1.1718862280007343]
	TIME [epoch: 5.71 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6900760894722673		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.6900760894722673 | validation: 1.138754192000263]
	TIME [epoch: 5.71 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8474149350071447		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.8474149350071447 | validation: 1.2461058127572553]
	TIME [epoch: 5.71 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7021453614979383		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.7021453614979383 | validation: 1.0835158652610968]
	TIME [epoch: 5.71 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7288417521373878		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.7288417521373878 | validation: 1.08873667762896]
	TIME [epoch: 5.71 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7445191705725065		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.7445191705725065 | validation: 1.232452569890853]
	TIME [epoch: 5.75 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8620707774606644		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.8620707774606644 | validation: 1.2429853341754575]
	TIME [epoch: 5.71 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9928000473927532		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.9928000473927532 | validation: 1.2011089816077631]
	TIME [epoch: 5.72 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9093924106602214		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.9093924106602214 | validation: 1.1946574755584596]
	TIME [epoch: 5.71 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8106130624138967		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.8106130624138967 | validation: 1.3907994346717905]
	TIME [epoch: 5.71 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8990399786417445		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.8990399786417445 | validation: 1.265625104476685]
	TIME [epoch: 5.71 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281203203818003		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.7281203203818003 | validation: 1.2433245075814605]
	TIME [epoch: 5.73 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6278551164455939		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.6278551164455939 | validation: 1.0601140394732205]
	TIME [epoch: 5.73 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7855591244379214		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.7855591244379214 | validation: 1.5494037544810295]
	TIME [epoch: 5.71 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6518576721125835		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.6518576721125835 | validation: 1.095512946270409]
	TIME [epoch: 5.71 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7747063734650852		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.7747063734650852 | validation: 1.2735420351112183]
	TIME [epoch: 5.71 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9119839984631035		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.9119839984631035 | validation: 1.2150908047021627]
	TIME [epoch: 5.71 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8692031435743042		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.8692031435743042 | validation: 1.1618452710248872]
	TIME [epoch: 5.72 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8099538566771876		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.8099538566771876 | validation: 1.189706155813286]
	TIME [epoch: 5.76 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8490966451434785		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.8490966451434785 | validation: 1.373812987864016]
	TIME [epoch: 5.71 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8296545025456958		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.8296545025456958 | validation: 1.2294717949262401]
	TIME [epoch: 5.71 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.716973607665906		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.716973607665906 | validation: 1.315281275422455]
	TIME [epoch: 5.71 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6795791957694233		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.6795791957694233 | validation: 1.2297196747140793]
	TIME [epoch: 5.71 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.69246502600302		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.69246502600302 | validation: 1.1399128725753709]
	TIME [epoch: 5.71 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5470957214126226		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.5470957214126226 | validation: 1.1678477777006588]
	TIME [epoch: 5.74 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7068829987811547		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.7068829987811547 | validation: 1.319722738955611]
	TIME [epoch: 5.73 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7128579126733612		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.7128579126733612 | validation: 1.0811327078202404]
	TIME [epoch: 5.72 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5520012677392567		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.5520012677392567 | validation: 1.0978090518898507]
	TIME [epoch: 5.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9064495260887027		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.9064495260887027 | validation: 1.791271262353752]
	TIME [epoch: 5.71 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6952813288659438		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.6952813288659438 | validation: 1.0982478871180588]
	TIME [epoch: 5.72 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7315614584475325		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.7315614584475325 | validation: 1.2278789885133865]
	TIME [epoch: 5.71 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7943806404532983		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.7943806404532983 | validation: 1.180360488347897]
	TIME [epoch: 5.76 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7370369989823686		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.7370369989823686 | validation: 1.214511574412252]
	TIME [epoch: 5.72 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6476526849889188		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.6476526849889188 | validation: 1.024075486337856]
	TIME [epoch: 5.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1345863165539445		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.1345863165539445 | validation: 2.3613944228679338]
	TIME [epoch: 5.71 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.696268374194744		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.696268374194744 | validation: 1.418233573549446]
	TIME [epoch: 5.71 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4887859342740322		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.4887859342740322 | validation: 1.440637976678903]
	TIME [epoch: 5.72 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0097759715461745		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.0097759715461745 | validation: 1.2746964908583602]
	TIME [epoch: 5.74 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6063390626061849		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.6063390626061849 | validation: 1.8666833484414076]
	TIME [epoch: 5.74 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7764436610966614		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.7764436610966614 | validation: 1.5661535820030492]
	TIME [epoch: 5.72 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6326075734340029		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.6326075734340029 | validation: 1.332246435035221]
	TIME [epoch: 5.71 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.573639893523812		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.573639893523812 | validation: 1.068671046315792]
	TIME [epoch: 5.71 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.472450171170645		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.472450171170645 | validation: 0.9905401683405978]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.424857105846299		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.424857105846299 | validation: 1.1448182915397938]
	TIME [epoch: 5.72 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.533983345739229		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.533983345739229 | validation: 0.9937123107764374]
	TIME [epoch: 5.75 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.869021274438011		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.869021274438011 | validation: 1.1173371799799452]
	TIME [epoch: 5.71 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7009811394298113		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.7009811394298113 | validation: 1.2017693273950818]
	TIME [epoch: 5.71 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6569936430018235		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.6569936430018235 | validation: 1.028760046573693]
	TIME [epoch: 5.71 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7276612332553		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.7276612332553 | validation: 1.1000272670191802]
	TIME [epoch: 5.71 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7587194309662932		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.7587194309662932 | validation: 1.2359903809039536]
	TIME [epoch: 5.71 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6948436745885864		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.6948436745885864 | validation: 1.1516473589498157]
	TIME [epoch: 5.73 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6289297338828104		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.6289297338828104 | validation: 1.1041205706190114]
	TIME [epoch: 5.72 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7062922327433374		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.7062922327433374 | validation: 1.1951555392237574]
	TIME [epoch: 5.71 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.587600740734465		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.587600740734465 | validation: 1.0087699962133387]
	TIME [epoch: 5.71 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7683203440509425		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.7683203440509425 | validation: 1.4817574783294243]
	TIME [epoch: 5.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6049852387363546		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.6049852387363546 | validation: 1.2049445344315095]
	TIME [epoch: 5.71 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7666018664535956		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.7666018664535956 | validation: 1.206931000426288]
	TIME [epoch: 5.71 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6505181591264133		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.6505181591264133 | validation: 1.108719589653051]
	TIME [epoch: 5.75 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6293803512104672		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.6293803512104672 | validation: 1.0972773621361982]
	TIME [epoch: 5.71 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7197111550244157		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.7197111550244157 | validation: 1.0342416520303175]
	TIME [epoch: 5.71 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4298987704084676		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.4298987704084676 | validation: 1.3126455295721382]
	TIME [epoch: 5.71 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.621325186520854		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.621325186520854 | validation: 1.1092551553291548]
	TIME [epoch: 5.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6910271238884573		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.6910271238884573 | validation: 1.2354739120741087]
	TIME [epoch: 5.71 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6891095069735809		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.6891095069735809 | validation: 1.4617530918961088]
	TIME [epoch: 5.74 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5333028122095091		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.5333028122095091 | validation: 1.2886376429405213]
	TIME [epoch: 5.73 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5633099110801167		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.5633099110801167 | validation: 1.137551990078561]
	TIME [epoch: 5.72 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4990529150305272		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.4990529150305272 | validation: 1.1423935079461434]
	TIME [epoch: 5.71 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.407164750809784		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.407164750809784 | validation: 1.0404683147286886]
	TIME [epoch: 5.71 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.388960365182453		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.388960365182453 | validation: 1.0381923456853546]
	TIME [epoch: 5.71 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4607887839431375		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.4607887839431375 | validation: 0.9908853716607019]
	TIME [epoch: 5.71 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3322217708782986		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.3322217708782986 | validation: 1.3353861755664644]
	TIME [epoch: 5.76 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4106572999241023		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.4106572999241023 | validation: 1.1740971089653447]
	TIME [epoch: 5.72 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.359669846528285		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.359669846528285 | validation: 1.004633124451316]
	TIME [epoch: 5.71 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3310755973131765		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.3310755973131765 | validation: 1.059506523155404]
	TIME [epoch: 5.71 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3068177437840376		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.3068177437840376 | validation: 1.0221693477654017]
	TIME [epoch: 5.71 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3616297100094412		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.3616297100094412 | validation: 1.0895025717148292]
	TIME [epoch: 5.71 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4473740948428402		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.4473740948428402 | validation: 1.1015646484727382]
	TIME [epoch: 5.72 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5749143009597497		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.5749143009597497 | validation: 1.0972671055657248]
	TIME [epoch: 5.75 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.536986689272198		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.536986689272198 | validation: 0.945176448377886]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7356842869263052		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.7356842869263052 | validation: 1.0747042221973353]
	TIME [epoch: 5.72 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5668219142630018		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.5668219142630018 | validation: 1.074716873909906]
	TIME [epoch: 5.71 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5470694491338026		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.5470694491338026 | validation: 1.01818525935963]
	TIME [epoch: 5.71 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.395819562626991		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.395819562626991 | validation: 1.0327097221812858]
	TIME [epoch: 5.71 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3452658494052172		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.3452658494052172 | validation: 1.0404370864987644]
	TIME [epoch: 5.76 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4545378835397846		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.4545378835397846 | validation: 0.9362468371098501]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_322.pth
	Model improved!!!
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3485102585039888		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.3485102585039888 | validation: 1.069229726060684]
	TIME [epoch: 5.71 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3228158145056932		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.3228158145056932 | validation: 1.038682738156443]
	TIME [epoch: 5.72 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.363722540578541		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.363722540578541 | validation: 0.9265853650698367]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3058028830326878		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.3058028830326878 | validation: 2.299903748433026]
	TIME [epoch: 5.71 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8784910001646762		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.8784910001646762 | validation: 1.7207342437122615]
	TIME [epoch: 5.75 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4952203161204585		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.4952203161204585 | validation: 2.2112196623224665]
	TIME [epoch: 5.72 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3582263874813356		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.3582263874813356 | validation: 1.5147136247047228]
	TIME [epoch: 5.71 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5575159367774354		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.5575159367774354 | validation: 1.6187404407061923]
	TIME [epoch: 5.71 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5170143742827347		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.5170143742827347 | validation: 1.6566615243189426]
	TIME [epoch: 5.71 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5373736032919831		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.5373736032919831 | validation: 1.1566359296476518]
	TIME [epoch: 5.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4282876723789495		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.4282876723789495 | validation: 1.3308820876247962]
	TIME [epoch: 5.72 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4193206225221375		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.4193206225221375 | validation: 1.737684987332656]
	TIME [epoch: 5.74 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.514639677131133		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.514639677131133 | validation: 1.6682181723587999]
	TIME [epoch: 5.71 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4968347920790834		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.4968347920790834 | validation: 1.3751528654550171]
	TIME [epoch: 5.71 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5019245408902786		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.5019245408902786 | validation: 1.0979843766760409]
	TIME [epoch: 5.71 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3260415931056464		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.3260415931056464 | validation: 1.2561259221048515]
	TIME [epoch: 5.71 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4219548009193026		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.4219548009193026 | validation: 2.077891693403082]
	TIME [epoch: 5.71 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6078476536876154		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.6078476536876154 | validation: 1.5370594923965724]
	TIME [epoch: 5.74 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5072302518625285		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.5072302518625285 | validation: 1.2929237774547577]
	TIME [epoch: 5.73 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4513336741048433		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.4513336741048433 | validation: 0.9353946773147346]
	TIME [epoch: 5.71 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3820471404475514		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.3820471404475514 | validation: 1.0110850681806336]
	TIME [epoch: 5.71 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.370945218832635		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.370945218832635 | validation: 1.3932397483820866]
	TIME [epoch: 5.71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4603924072178223		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.4603924072178223 | validation: 1.0729951508199254]
	TIME [epoch: 5.71 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3355185790443886		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.3355185790443886 | validation: 1.1259517044326928]
	TIME [epoch: 5.71 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5313530912531594		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.5313530912531594 | validation: 1.0083909418067654]
	TIME [epoch: 5.76 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.516221759326111		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.516221759326111 | validation: 0.9441699302200988]
	TIME [epoch: 5.72 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4455806560010227		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.4455806560010227 | validation: 1.313590193410464]
	TIME [epoch: 5.72 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4466106538733041		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.4466106538733041 | validation: 0.9878282316799838]
	TIME [epoch: 5.71 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4810779494313924		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.4810779494313924 | validation: 1.2849676710692302]
	TIME [epoch: 5.71 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4138663809041145		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.4138663809041145 | validation: 1.5155106348638947]
	TIME [epoch: 5.71 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3480972073909834		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.3480972073909834 | validation: 0.9011950774982128]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338374089124822		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.2338374089124822 | validation: 0.9838431064890963]
	TIME [epoch: 5.73 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3256152681075148		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.3256152681075148 | validation: 1.672168243158576]
	TIME [epoch: 5.71 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5269279560068765		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.5269279560068765 | validation: 1.1790917415574094]
	TIME [epoch: 5.71 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.370188042191062		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.370188042191062 | validation: 1.7614568334183343]
	TIME [epoch: 5.71 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5661304057170389		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.5661304057170389 | validation: 0.9654680765092386]
	TIME [epoch: 5.71 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2496760623607979		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.2496760623607979 | validation: 0.940593804529726]
	TIME [epoch: 5.72 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2781908667980144		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.2781908667980144 | validation: 1.7331729183175042]
	TIME [epoch: 5.75 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7377956246757036		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.7377956246757036 | validation: 1.1401777102625663]
	TIME [epoch: 5.71 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4244509575528508		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.4244509575528508 | validation: 1.5842106362268007]
	TIME [epoch: 5.71 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.490388529412995		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.490388529412995 | validation: 1.4461827773610796]
	TIME [epoch: 5.71 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4949038478143692		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.4949038478143692 | validation: 1.5151411047214165]
	TIME [epoch: 5.71 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5295865337841323		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.5295865337841323 | validation: 1.3684307847477115]
	TIME [epoch: 5.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4305490663336253		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.4305490663336253 | validation: 1.5621968178149181]
	TIME [epoch: 5.74 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4795899009721416		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.4795899009721416 | validation: 1.383481162704347]
	TIME [epoch: 5.73 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4328095462994423		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.4328095462994423 | validation: 1.1580989517803835]
	TIME [epoch: 5.71 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3362438230055151		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.3362438230055151 | validation: 1.4149148608867492]
	TIME [epoch: 5.71 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4111919760054281		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.4111919760054281 | validation: 1.3334594402026716]
	TIME [epoch: 5.71 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4348909554276617		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.4348909554276617 | validation: 1.1687469465684364]
	TIME [epoch: 5.71 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.371778042426845		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.371778042426845 | validation: 1.6679495864726885]
	TIME [epoch: 5.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4336907836379764		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.4336907836379764 | validation: 1.6459286055318787]
	TIME [epoch: 5.75 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.60231331015292		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.60231331015292 | validation: 1.1637094203294356]
	TIME [epoch: 5.72 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4424469612612971		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.4424469612612971 | validation: 1.4678345545024376]
	TIME [epoch: 5.71 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4391179035896486		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.4391179035896486 | validation: 1.545077183773684]
	TIME [epoch: 5.71 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.339709030678979		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.339709030678979 | validation: 1.1444123886178386]
	TIME [epoch: 5.71 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2595368129474604		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.2595368129474604 | validation: 0.9996180844961253]
	TIME [epoch: 5.71 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2849415482321191		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.2849415482321191 | validation: 0.9403725177776333]
	TIME [epoch: 5.73 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.266786585642587		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.266786585642587 | validation: 1.0252282739852874]
	TIME [epoch: 5.72 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2362860001178484		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.2362860001178484 | validation: 1.142202281769546]
	TIME [epoch: 5.71 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3575540981239391		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.3575540981239391 | validation: 1.157398326331832]
	TIME [epoch: 5.71 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4168993292505754		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.4168993292505754 | validation: 1.2181727164312304]
	TIME [epoch: 5.71 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3103988136878257		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.3103988136878257 | validation: 1.0205819247435817]
	TIME [epoch: 5.71 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242259954866585		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.242259954866585 | validation: 0.9455654535418083]
	TIME [epoch: 5.72 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4658318958877619		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.4658318958877619 | validation: 1.1913711128634035]
	TIME [epoch: 5.76 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3592251832209261		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.3592251832209261 | validation: 0.8902874702843449]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_387.pth
	Model improved!!!
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.397795917434392		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.397795917434392 | validation: 0.9946071320506681]
	TIME [epoch: 5.72 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2481215833119617		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.2481215833119617 | validation: 1.1489921752852539]
	TIME [epoch: 5.71 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2607118315623573		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.2607118315623573 | validation: 1.0995365482858224]
	TIME [epoch: 5.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2293625190544568		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.2293625190544568 | validation: 1.1211886863306006]
	TIME [epoch: 5.71 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3965961457571465		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.3965961457571465 | validation: 1.0135635348519991]
	TIME [epoch: 5.74 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5273671206254307		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.5273671206254307 | validation: 1.0958567072214551]
	TIME [epoch: 5.73 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.361240998613495		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.361240998613495 | validation: 0.925346070934095]
	TIME [epoch: 5.71 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5420642978674701		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.5420642978674701 | validation: 0.9886253388789414]
	TIME [epoch: 5.71 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3324239330286887		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.3324239330286887 | validation: 0.940846765531804]
	TIME [epoch: 5.72 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4204986238836883		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.4204986238836883 | validation: 1.0752574612619383]
	TIME [epoch: 5.71 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4485276401028397		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.4485276401028397 | validation: 1.1365320960469973]
	TIME [epoch: 5.71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.368792770278802		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.368792770278802 | validation: 1.1063791379131045]
	TIME [epoch: 5.76 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.420808861418737		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.420808861418737 | validation: 0.9644610557133863]
	TIME [epoch: 5.71 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.346833915500948		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.346833915500948 | validation: 1.316338531312615]
	TIME [epoch: 5.71 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.464000182294813		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.464000182294813 | validation: 1.1585975212270347]
	TIME [epoch: 5.71 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.354262303321474		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.354262303321474 | validation: 1.2880085689606415]
	TIME [epoch: 5.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4199327476758985		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.4199327476758985 | validation: 1.0561428288805752]
	TIME [epoch: 5.71 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5290974005029279		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.5290974005029279 | validation: 1.5475538979802543]
	TIME [epoch: 5.73 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3363082898294814		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.3363082898294814 | validation: 0.9765004989024206]
	TIME [epoch: 5.72 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.396337053172159		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.396337053172159 | validation: 1.4213357764744148]
	TIME [epoch: 5.71 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3218552451455716		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.3218552451455716 | validation: 1.3642355720447592]
	TIME [epoch: 5.72 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.299192724692657		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.299192724692657 | validation: 1.2195359794972287]
	TIME [epoch: 5.71 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3281964009064215		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.3281964009064215 | validation: 1.1628603358721354]
	TIME [epoch: 5.71 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3067866879757186		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.3067866879757186 | validation: 1.620658975155779]
	TIME [epoch: 5.71 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5430255486695925		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.5430255486695925 | validation: 1.1204044580825505]
	TIME [epoch: 5.76 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3332251782218192		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.3332251782218192 | validation: 1.1557365885907047]
	TIME [epoch: 5.71 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.333238225044478		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.333238225044478 | validation: 1.045962399676318]
	TIME [epoch: 5.71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3788476747766543		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.3788476747766543 | validation: 1.7021106163479869]
	TIME [epoch: 5.72 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5052626828972642		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.5052626828972642 | validation: 1.0227488958238997]
	TIME [epoch: 5.71 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2165843490025292		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.2165843490025292 | validation: 1.0284015829108688]
	TIME [epoch: 5.71 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3142834016678488		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.3142834016678488 | validation: 1.4029207040383693]
	TIME [epoch: 5.74 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.38411040469235		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.38411040469235 | validation: 1.2066996534527343]
	TIME [epoch: 5.73 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2688482934284875		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.2688482934284875 | validation: 0.8786228791531328]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_420.pth
	Model improved!!!
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.283702989076707		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.283702989076707 | validation: 0.8492596084964528]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2013791734149595		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.2013791734149595 | validation: 0.9529734725678632]
	TIME [epoch: 5.71 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2134703100229502		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.2134703100229502 | validation: 1.5280371363747696]
	TIME [epoch: 5.71 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3895583822307647		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.3895583822307647 | validation: 1.0907068534647706]
	TIME [epoch: 5.72 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3111393572994159		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.3111393572994159 | validation: 0.8442867304895403]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2828346228915137		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.2828346228915137 | validation: 1.2541329772659078]
	TIME [epoch: 5.72 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3473039092326156		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.3473039092326156 | validation: 1.1945863037229358]
	TIME [epoch: 5.72 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.305858509297988		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.305858509297988 | validation: 0.9495604387035786]
	TIME [epoch: 5.71 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2650268500786988		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.2650268500786988 | validation: 1.7785139643447139]
	TIME [epoch: 5.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4606484278826395		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.4606484278826395 | validation: 1.3486776897273018]
	TIME [epoch: 5.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3569263992701068		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.3569263992701068 | validation: 1.0270390429339855]
	TIME [epoch: 5.74 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3440710094875234		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.3440710094875234 | validation: 0.944574385437829]
	TIME [epoch: 5.72 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2118754132815366		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.2118754132815366 | validation: 1.2112721246446723]
	TIME [epoch: 5.71 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3394375100597917		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.3394375100597917 | validation: 1.0182024501898799]
	TIME [epoch: 5.71 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.315162022887617		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.315162022887617 | validation: 0.9175752830273766]
	TIME [epoch: 5.71 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3438466275265366		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.3438466275265366 | validation: 1.2236667709774502]
	TIME [epoch: 5.71 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2938406641793148		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.2938406641793148 | validation: 1.057807543748223]
	TIME [epoch: 5.72 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2273588673584428		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.2273588673584428 | validation: 1.068282107113414]
	TIME [epoch: 5.74 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1921444280182627		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.1921444280182627 | validation: 0.9518058209432187]
	TIME [epoch: 5.71 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1764971122866168		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.1764971122866168 | validation: 1.2188853694590582]
	TIME [epoch: 5.71 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2214388129063367		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.2214388129063367 | validation: 1.0542397176111111]
	TIME [epoch: 5.71 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4606237252819478		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.4606237252819478 | validation: 0.8619348925388137]
	TIME [epoch: 5.71 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3168707493114433		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.3168707493114433 | validation: 0.8634672206290718]
	TIME [epoch: 5.71 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1933457434573829		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.1933457434573829 | validation: 0.8758767480910884]
	TIME [epoch: 5.75 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1838890517516052		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.1838890517516052 | validation: 0.8334821932224]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.252205272865835		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.252205272865835 | validation: 1.0618712068686822]
	TIME [epoch: 5.71 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242664631668345		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.242664631668345 | validation: 0.9120266048076792]
	TIME [epoch: 5.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3234669950551934		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.3234669950551934 | validation: 1.027211536779097]
	TIME [epoch: 5.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2734914666275792		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.2734914666275792 | validation: 1.3115791515478987]
	TIME [epoch: 5.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2874560712455345		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.2874560712455345 | validation: 0.8513009349714631]
	TIME [epoch: 5.72 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.156821510468923		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.156821510468923 | validation: 0.9665536312316961]
	TIME [epoch: 5.74 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2933283779262426		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.2933283779262426 | validation: 1.0567317767612265]
	TIME [epoch: 5.72 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2740619997215825		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.2740619997215825 | validation: 0.8451646013911802]
	TIME [epoch: 5.71 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2779246047604829		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.2779246047604829 | validation: 0.9302030094347193]
	TIME [epoch: 5.71 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.214577162728707		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.214577162728707 | validation: 0.8409290121080195]
	TIME [epoch: 5.72 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4680103348148346		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.4680103348148346 | validation: 0.9253458148442916]
	TIME [epoch: 5.71 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3068572088525292		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.3068572088525292 | validation: 1.0825931253633807]
	TIME [epoch: 5.74 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2464324472812396		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.2464324472812396 | validation: 0.8947833503915013]
	TIME [epoch: 5.71 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3319345544643961		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.3319345544643961 | validation: 1.0010977882950827]
	TIME [epoch: 5.71 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2469262777140253		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.2469262777140253 | validation: 1.1687850952261343]
	TIME [epoch: 5.71 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3690707119341154		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.3690707119341154 | validation: 1.0879650111142665]
	TIME [epoch: 5.71 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2201982970139569		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.2201982970139569 | validation: 1.2154553308193852]
	TIME [epoch: 5.71 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2446174470697065		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.2446174470697065 | validation: 1.197229757084931]
	TIME [epoch: 5.71 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2616153883872723		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.2616153883872723 | validation: 1.0743298280153653]
	TIME [epoch: 5.74 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257330531649026		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.257330531649026 | validation: 1.299201498200098]
	TIME [epoch: 5.71 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3092155445612457		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.3092155445612457 | validation: 0.9813400216623017]
	TIME [epoch: 5.71 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1604891127332846		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.1604891127332846 | validation: 0.9204232788411711]
	TIME [epoch: 5.71 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1990082278054959		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.1990082278054959 | validation: 0.8700553930504871]
	TIME [epoch: 5.71 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2444825074235615		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.2444825074235615 | validation: 0.8858142540910938]
	TIME [epoch: 5.71 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2732456808994994		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.2732456808994994 | validation: 0.9437090278920729]
	TIME [epoch: 5.75 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2306999775698144		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.2306999775698144 | validation: 1.0176873488862677]
	TIME [epoch: 5.71 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1975612142053385		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.1975612142053385 | validation: 1.4694954308624484]
	TIME [epoch: 5.71 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3275149576088008		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.3275149576088008 | validation: 1.1914133835422942]
	TIME [epoch: 5.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3003512589612989		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.3003512589612989 | validation: 1.1332115151618831]
	TIME [epoch: 5.71 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3032656694683271		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.3032656694683271 | validation: 1.1627864107884132]
	TIME [epoch: 5.71 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8946049816653314		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.8946049816653314 | validation: 1.234908958066493]
	TIME [epoch: 5.72 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230946110255083		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.230946110255083 | validation: 0.9490501035869972]
	TIME [epoch: 5.75 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2239100136015675		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.2239100136015675 | validation: 0.8747152639851024]
	TIME [epoch: 5.72 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2438391620277833		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.2438391620277833 | validation: 0.8841931209890145]
	TIME [epoch: 5.72 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2820181854555517		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.2820181854555517 | validation: 0.8568090765747434]
	TIME [epoch: 5.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.194028165966744		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.194028165966744 | validation: 0.8960089840372136]
	TIME [epoch: 5.71 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2126629113818992		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.2126629113818992 | validation: 0.8825209838105795]
	TIME [epoch: 5.71 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.221270383085644		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.221270383085644 | validation: 0.8782885591646593]
	TIME [epoch: 5.73 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3023258132035933		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.3023258132035933 | validation: 1.1199831735736776]
	TIME [epoch: 5.73 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2085826048732027		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.2085826048732027 | validation: 0.9888332207472117]
	TIME [epoch: 5.72 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1601705633850767		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.1601705633850767 | validation: 0.9295831769409825]
	TIME [epoch: 5.72 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.15042089355343		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.15042089355343 | validation: 0.899752974486405]
	TIME [epoch: 5.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2001763497117268		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.2001763497117268 | validation: 0.8493754971269241]
	TIME [epoch: 5.72 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.205748339620252		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.205748339620252 | validation: 0.8597167639027815]
	TIME [epoch: 5.71 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3741313729966276		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.3741313729966276 | validation: 1.1193304703423335]
	TIME [epoch: 5.75 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.323751583881669		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.323751583881669 | validation: 0.9264594657678868]
	TIME [epoch: 5.71 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2689449101130639		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.2689449101130639 | validation: 1.075752818082854]
	TIME [epoch: 5.71 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2099696042489738		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.2099696042489738 | validation: 0.9004035556564159]
	TIME [epoch: 5.71 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1729883946051638		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.1729883946051638 | validation: 1.0739521918427075]
	TIME [epoch: 5.71 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2557171711909734		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.2557171711909734 | validation: 0.8538815309627478]
	TIME [epoch: 5.71 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.116920900577526		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.116920900577526 | validation: 1.0136390081883146]
	TIME [epoch: 5.73 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150210148308383		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.150210148308383 | validation: 1.1356967912043028]
	TIME [epoch: 5.72 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1621901041573321		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.1621901041573321 | validation: 0.9249267371931744]
	TIME [epoch: 5.71 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1212421007219282		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.1212421007219282 | validation: 0.9346065987102067]
	TIME [epoch: 5.71 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.120218455861192		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.120218455861192 | validation: 0.9003653032092376]
	TIME [epoch: 5.71 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1404553165256595		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.1404553165256595 | validation: 1.0859716973817155]
	TIME [epoch: 5.71 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2573711357850335		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.2573711357850335 | validation: 0.9688338421847451]
	TIME [epoch: 5.72 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2730043478820765		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.2730043478820765 | validation: 0.9338900687115976]
	TIME [epoch: 5.75 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1878369362839376		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.1878369362839376 | validation: 1.0781374245475153]
	TIME [epoch: 5.71 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1494647735805223		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.1494647735805223 | validation: 0.8924171085103353]
	TIME [epoch: 5.72 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1321181430057918		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.1321181430057918 | validation: 1.5862057428177088]
	TIME [epoch: 5.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4482296210803667		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.4482296210803667 | validation: 0.8557956035274397]
	TIME [epoch: 5.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1947325192549494		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.1947325192549494 | validation: 1.5130215396944875]
	TIME [epoch: 5.71 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3544768398395626		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.3544768398395626 | validation: 0.9204179362327477]
	TIME [epoch: 5.74 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1656305223247008		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.1656305223247008 | validation: 0.9880698788137025]
	TIME [epoch: 5.73 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1798606346135596		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.1798606346135596 | validation: 0.8792089740317097]
	TIME [epoch: 5.71 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1608799723068226		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.1608799723068226 | validation: 0.994895150264782]
	TIME [epoch: 5.71 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1498022899371192		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.1498022899371192 | validation: 0.881289706897638]
	TIME [epoch: 5.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.198466592124068		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.198466592124068 | validation: 0.8650390502094486]
	TIME [epoch: 5.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1605661639729132		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.1605661639729132 | validation: 1.6848938357243703]
	TIME [epoch: 5.71 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.454674179763489		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.454674179763489 | validation: 0.947912173944261]
	TIME [epoch: 5.76 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2595526675216313		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.2595526675216313 | validation: 0.8785813617027443]
	TIME [epoch: 5.72 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1921738977793657		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.1921738977793657 | validation: 1.0097626404331659]
	TIME [epoch: 5.71 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.399119067197399		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.399119067197399 | validation: 0.8582339560591312]
	TIME [epoch: 5.71 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1342852491251343		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.1342852491251343 | validation: 0.9770031244129266]
	TIME [epoch: 5.72 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1839217306270582		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.1839217306270582 | validation: 0.9388901802967928]
	TIME [epoch: 5.71 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2039744266961203		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.2039744266961203 | validation: 0.9416450700314226]
	TIME [epoch: 5.73 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1662836805355625		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.1662836805355625 | validation: 0.8500987325003874]
	TIME [epoch: 5.72 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1501617747469903		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.1501617747469903 | validation: 0.8551491995126225]
	TIME [epoch: 5.71 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2434344966920252		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.2434344966920252 | validation: 1.2160585218402893]
	TIME [epoch: 5.71 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2029836902372346		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.2029836902372346 | validation: 1.1053623407181312]
	TIME [epoch: 5.71 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2216454944576567		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.2216454944576567 | validation: 1.2002151798628342]
	TIME [epoch: 5.71 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1927519932502002		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.1927519932502002 | validation: 0.9922735298465568]
	TIME [epoch: 5.71 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1374129801676758		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.1374129801676758 | validation: 1.0509513880683]
	TIME [epoch: 5.75 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2095481573952231		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.2095481573952231 | validation: 1.00247777713233]
	TIME [epoch: 5.71 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1384738911630607		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.1384738911630607 | validation: 1.0942827711932213]
	TIME [epoch: 5.71 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2173779562771783		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.2173779562771783 | validation: 1.005929087709195]
	TIME [epoch: 5.71 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1812367880481995		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.1812367880481995 | validation: 1.040594030379774]
	TIME [epoch: 5.71 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181853007280164		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.181853007280164 | validation: 1.2948741553326988]
	TIME [epoch: 5.71 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3802637198734922		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.3802637198734922 | validation: 1.1469019131204645]
	TIME [epoch: 5.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2657162409496316		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 1.2657162409496316 | validation: 0.9353722950440883]
	TIME [epoch: 5.73 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.170864726268688		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 1.170864726268688 | validation: 0.935394689062282]
	TIME [epoch: 5.71 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1516759198360402		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 1.1516759198360402 | validation: 0.8752981848275352]
	TIME [epoch: 5.71 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.163695590494671		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 1.163695590494671 | validation: 1.3392832152606775]
	TIME [epoch: 5.71 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.25220960407752		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.25220960407752 | validation: 0.9313361134794172]
	TIME [epoch: 5.71 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.183701706309237		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.183701706309237 | validation: 0.8314090493918812]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_541.pth
	Model improved!!!
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1435126834657845		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 1.1435126834657845 | validation: 1.0211948966197735]
	TIME [epoch: 5.75 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2182064865312312		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.2182064865312312 | validation: 0.8295952952097478]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_543.pth
	Model improved!!!
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1966030029532009		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 1.1966030029532009 | validation: 1.111689869440875]
	TIME [epoch: 5.71 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1557279428767935		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.1557279428767935 | validation: 0.9338836115426605]
	TIME [epoch: 5.71 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1163795070404992		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.1163795070404992 | validation: 0.8820609705665967]
	TIME [epoch: 5.71 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234570200573687		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.234570200573687 | validation: 1.0028058199937908]
	TIME [epoch: 5.71 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.188315153613731		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.188315153613731 | validation: 0.8836089110344592]
	TIME [epoch: 5.74 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1604013299191758		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.1604013299191758 | validation: 0.8256070389118793]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2115732681096052		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.2115732681096052 | validation: 0.8976780507236152]
	TIME [epoch: 5.72 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1395876301759955		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.1395876301759955 | validation: 0.963098010061794]
	TIME [epoch: 5.72 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1733256778120607		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 1.1733256778120607 | validation: 0.8789587014066274]
	TIME [epoch: 5.72 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1558239348910053		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.1558239348910053 | validation: 0.905314306760492]
	TIME [epoch: 5.71 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1692968038828773		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 1.1692968038828773 | validation: 1.19795778386927]
	TIME [epoch: 5.72 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1801078355389483		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.1801078355389483 | validation: 1.0117294609906748]
	TIME [epoch: 5.74 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1473710942383886		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.1473710942383886 | validation: 0.9949008821169657]
	TIME [epoch: 5.72 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1615378243981795		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 1.1615378243981795 | validation: 0.9527425404257887]
	TIME [epoch: 5.72 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1249982137096826		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.1249982137096826 | validation: 0.8593334236413087]
	TIME [epoch: 5.71 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.142820436485553		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.142820436485553 | validation: 0.8420835634470051]
	TIME [epoch: 5.72 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1563040705923426		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.1563040705923426 | validation: 0.8457310870985656]
	TIME [epoch: 5.71 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1589916467604842		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 1.1589916467604842 | validation: 0.8591068359311231]
	TIME [epoch: 5.75 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1866646305295547		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.1866646305295547 | validation: 0.8177966718603247]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1902170302149115		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 1.1902170302149115 | validation: 0.8403082073034868]
	TIME [epoch: 5.72 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161520380508697		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 1.161520380508697 | validation: 0.866006129184125]
	TIME [epoch: 5.71 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1283650609630866		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.1283650609630866 | validation: 0.8311303448772529]
	TIME [epoch: 5.71 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2626684657861085		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.2626684657861085 | validation: 0.8314021952847943]
	TIME [epoch: 5.71 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1315706800392022		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.1315706800392022 | validation: 0.8498623761778472]
	TIME [epoch: 5.71 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1837063636777383		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.1837063636777383 | validation: 0.8677607821278609]
	TIME [epoch: 5.74 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1213238942421488		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.1213238942421488 | validation: 0.9983615485789118]
	TIME [epoch: 5.71 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1503663080501754		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.1503663080501754 | validation: 1.11511263850891]
	TIME [epoch: 5.71 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2005224145683229		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.2005224145683229 | validation: 0.8088817418745805]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1686775317414608		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.1686775317414608 | validation: 0.8904104030653227]
	TIME [epoch: 5.72 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1247627200644024		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.1247627200644024 | validation: 1.2357164054918337]
	TIME [epoch: 5.71 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2229436750159675		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 1.2229436750159675 | validation: 1.0485367966486348]
	TIME [epoch: 5.75 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1867599218895455		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 1.1867599218895455 | validation: 0.8416612205365572]
	TIME [epoch: 5.72 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1791285449010478		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 1.1791285449010478 | validation: 0.9332897982474614]
	TIME [epoch: 5.71 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.125434597092374		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 1.125434597092374 | validation: 0.8761916963764182]
	TIME [epoch: 5.71 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1420393284524273		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 1.1420393284524273 | validation: 1.0685690735374755]
	TIME [epoch: 5.71 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.262054466730486		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 1.262054466730486 | validation: 0.9015702116775017]
	TIME [epoch: 5.71 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2181311436519608		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.2181311436519608 | validation: 0.9931252420500198]
	TIME [epoch: 5.72 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2553345179786133		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 1.2553345179786133 | validation: 0.8913914836342564]
	TIME [epoch: 5.74 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1242298870345169		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.1242298870345169 | validation: 0.8264281786700473]
	TIME [epoch: 5.72 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1622708349680315		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 1.1622708349680315 | validation: 0.8760349416105173]
	TIME [epoch: 5.71 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1188927077160473		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 1.1188927077160473 | validation: 0.9034237631106621]
	TIME [epoch: 5.71 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1477242283190563		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.1477242283190563 | validation: 0.9349586607718047]
	TIME [epoch: 5.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2062960183947573		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 1.2062960183947573 | validation: 0.8888138510696226]
	TIME [epoch: 5.71 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.122211382445191		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 1.122211382445191 | validation: 1.0465485495232034]
	TIME [epoch: 5.75 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.182386364989159		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.182386364989159 | validation: 0.8692101233970181]
	TIME [epoch: 5.72 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1958194880157218		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.1958194880157218 | validation: 0.8264508194316329]
	TIME [epoch: 5.71 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1592556538270558		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 1.1592556538270558 | validation: 0.880962618294729]
	TIME [epoch: 5.71 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2018081858417011		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.2018081858417011 | validation: 0.8158038609510458]
	TIME [epoch: 5.71 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1065486026062188		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 1.1065486026062188 | validation: 0.8230885564874442]
	TIME [epoch: 5.71 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1277900334659097		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 1.1277900334659097 | validation: 0.9014067702887527]
	TIME [epoch: 5.72 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1696456720711883		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.1696456720711883 | validation: 0.8716393144308352]
	TIME [epoch: 5.74 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135147966202743		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 1.135147966202743 | validation: 0.8777997879769338]
	TIME [epoch: 5.71 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1459534100034792		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 1.1459534100034792 | validation: 0.953885919352647]
	TIME [epoch: 5.71 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1544146289548245		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 1.1544146289548245 | validation: 0.8571955423904108]
	TIME [epoch: 5.71 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2089705371563624		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.2089705371563624 | validation: 1.075523517826253]
	TIME [epoch: 5.71 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1716992096171537		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.1716992096171537 | validation: 0.8310360996725331]
	TIME [epoch: 5.72 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1175174986483867		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 1.1175174986483867 | validation: 0.879452651005629]
	TIME [epoch: 5.75 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1496238122033509		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.1496238122033509 | validation: 0.8176846711809052]
	TIME [epoch: 5.72 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1211527160619228		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 1.1211527160619228 | validation: 0.8602516058378308]
	TIME [epoch: 5.71 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.126240746036		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 1.126240746036 | validation: 0.8865498502649851]
	TIME [epoch: 5.71 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1810298686209557		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 1.1810298686209557 | validation: 0.8660514442514581]
	TIME [epoch: 5.71 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1328792349909824		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 1.1328792349909824 | validation: 0.8287450869702804]
	TIME [epoch: 5.72 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1396007086078512		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.1396007086078512 | validation: 0.9306436154854404]
	TIME [epoch: 5.73 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1747915917793283		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 1.1747915917793283 | validation: 0.981417981671526]
	TIME [epoch: 5.75 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1343126535495147		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 1.1343126535495147 | validation: 0.8753880916224615]
	TIME [epoch: 5.72 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1450700548718635		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 1.1450700548718635 | validation: 0.8703645491593948]
	TIME [epoch: 5.72 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1126622192446274		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 1.1126622192446274 | validation: 0.9011063235115703]
	TIME [epoch: 5.72 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0918013244703104		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 1.0918013244703104 | validation: 0.9640808504961718]
	TIME [epoch: 5.71 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2169162186413636		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 1.2169162186413636 | validation: 1.1797037169631346]
	TIME [epoch: 5.71 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1928528618324932		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 1.1928528618324932 | validation: 0.9323941987319891]
	TIME [epoch: 5.75 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.104070951747431		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 1.104070951747431 | validation: 0.8657277378015258]
	TIME [epoch: 5.72 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.105180650654888		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 1.105180650654888 | validation: 0.8385538190512142]
	TIME [epoch: 5.72 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0894354017867827		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 1.0894354017867827 | validation: 0.8412780662213045]
	TIME [epoch: 5.72 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1274528877020082		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 1.1274528877020082 | validation: 0.8578752981663632]
	TIME [epoch: 5.73 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.096936460400275		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 1.096936460400275 | validation: 0.8019586037338527]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307126801861605		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 1.2307126801861605 | validation: 0.8328982009714397]
	TIME [epoch: 5.72 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.176340178919511		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 1.176340178919511 | validation: 0.8466506731885504]
	TIME [epoch: 5.76 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1590421069146808		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 1.1590421069146808 | validation: 0.831598058181316]
	TIME [epoch: 5.71 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1261588726154186		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 1.1261588726154186 | validation: 0.8425661069841774]
	TIME [epoch: 5.71 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1397207495049781		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.1397207495049781 | validation: 0.8769024079559375]
	TIME [epoch: 5.71 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1636358545501149		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 1.1636358545501149 | validation: 0.8896958915599796]
	TIME [epoch: 5.71 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405491525029225		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 1.1405491525029225 | validation: 0.881848120725639]
	TIME [epoch: 5.71 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136523060029797		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 1.136523060029797 | validation: 0.8477340070269839]
	TIME [epoch: 5.75 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0965547559696005		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 1.0965547559696005 | validation: 0.8638847512076825]
	TIME [epoch: 5.72 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1556074008582522		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.1556074008582522 | validation: 0.9494607046398309]
	TIME [epoch: 5.71 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1546674294789347		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 1.1546674294789347 | validation: 0.8263149281351911]
	TIME [epoch: 5.71 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1190825974467837		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.1190825974467837 | validation: 0.8853072882820111]
	TIME [epoch: 5.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1029398176975787		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 1.1029398176975787 | validation: 0.8852627351912088]
	TIME [epoch: 5.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1334691022115833		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 1.1334691022115833 | validation: 1.0248781513565917]
	TIME [epoch: 5.71 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423950157271676		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 1.1423950157271676 | validation: 0.8419721499033314]
	TIME [epoch: 5.74 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0822098043333894		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 1.0822098043333894 | validation: 1.0005824179351113]
	TIME [epoch: 5.72 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1344319795512328		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 1.1344319795512328 | validation: 0.8398288927991868]
	TIME [epoch: 5.71 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139218683029086		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 1.139218683029086 | validation: 0.8934370986627215]
	TIME [epoch: 5.71 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1312057164114984		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 1.1312057164114984 | validation: 0.9863035586393756]
	TIME [epoch: 5.72 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.166387072427179		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 1.166387072427179 | validation: 0.9084388224848232]
	TIME [epoch: 5.71 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.196668689315125		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.196668689315125 | validation: 0.9530183933564521]
	TIME [epoch: 5.75 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1340305898709189		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.1340305898709189 | validation: 0.8281827000746751]
	TIME [epoch: 5.71 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0879476282671385		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.0879476282671385 | validation: 0.8428882691730357]
	TIME [epoch: 5.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1357888183210227		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 1.1357888183210227 | validation: 0.9346202837802059]
	TIME [epoch: 5.71 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0977113372875835		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 1.0977113372875835 | validation: 0.8279253094689625]
	TIME [epoch: 5.71 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0768979778357926		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.0768979778357926 | validation: 0.8317744142656852]
	TIME [epoch: 5.71 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.095532107177264		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.095532107177264 | validation: 0.8570012701073202]
	TIME [epoch: 5.73 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1069753400510534		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 1.1069753400510534 | validation: 0.8770060183127178]
	TIME [epoch: 5.75 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1439283795046356		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 1.1439283795046356 | validation: 0.8331953468905653]
	TIME [epoch: 5.71 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146166088159158		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.146166088159158 | validation: 0.8472658812698457]
	TIME [epoch: 5.72 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1754067781553017		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.1754067781553017 | validation: 0.9688919057710377]
	TIME [epoch: 5.71 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1594339073706421		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 1.1594339073706421 | validation: 0.8201240902742913]
	TIME [epoch: 5.71 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1016097048255835		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 1.1016097048255835 | validation: 0.9356110435943257]
	TIME [epoch: 5.71 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.110777727804964		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 1.110777727804964 | validation: 0.8817154608375201]
	TIME [epoch: 5.74 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1075731637266142		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 1.1075731637266142 | validation: 0.7983246303138922]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.104676322953988		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 1.104676322953988 | validation: 0.8103886389448275]
	TIME [epoch: 5.71 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0727126369641455		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 1.0727126369641455 | validation: 0.8816056674166055]
	TIME [epoch: 5.71 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0640784351371522		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 1.0640784351371522 | validation: 0.8393413811033011]
	TIME [epoch: 5.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1453627469648662		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 1.1453627469648662 | validation: 0.8312634545358435]
	TIME [epoch: 5.71 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1686389093552085		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 1.1686389093552085 | validation: 0.8092427078291354]
	TIME [epoch: 5.73 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0973238886605619		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 1.0973238886605619 | validation: 0.8299166892571179]
	TIME [epoch: 5.74 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.109083045894		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 1.109083045894 | validation: 0.847377257876908]
	TIME [epoch: 5.71 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0963259134835677		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 1.0963259134835677 | validation: 0.8312415185989869]
	TIME [epoch: 5.71 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0897080283381777		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 1.0897080283381777 | validation: 0.8323117069078358]
	TIME [epoch: 5.71 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1126545479403274		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 1.1126545479403274 | validation: 0.8733361186027999]
	TIME [epoch: 5.71 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1280998433607745		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.1280998433607745 | validation: 0.8153156567886778]
	TIME [epoch: 5.71 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1091627781239064		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 1.1091627781239064 | validation: 1.135089084085371]
	TIME [epoch: 5.75 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146884190710409		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 1.146884190710409 | validation: 0.893273571608233]
	TIME [epoch: 5.72 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1092316052097266		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 1.1092316052097266 | validation: 0.855564075516314]
	TIME [epoch: 5.71 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.106797180452563		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 1.106797180452563 | validation: 0.8898583841240401]
	TIME [epoch: 5.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1570975801481325		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 1.1570975801481325 | validation: 0.8474034012852582]
	TIME [epoch: 5.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0861586072803773		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 1.0861586072803773 | validation: 0.9127773166559965]
	TIME [epoch: 5.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1172943669353916		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 1.1172943669353916 | validation: 0.9155309910019415]
	TIME [epoch: 5.71 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1575937557186111		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 1.1575937557186111 | validation: 0.848891688704233]
	TIME [epoch: 5.74 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.093904061030134		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 1.093904061030134 | validation: 0.8316208151557598]
	TIME [epoch: 5.71 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.103855333063415		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 1.103855333063415 | validation: 0.8042493545786468]
	TIME [epoch: 5.72 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0827781865289334		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 1.0827781865289334 | validation: 0.7932003839992777]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0685167190199225		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 1.0685167190199225 | validation: 0.8623898834020453]
	TIME [epoch: 5.71 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1499376069624145		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 1.1499376069624145 | validation: 0.878378966906095]
	TIME [epoch: 5.72 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1925156711631095		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 1.1925156711631095 | validation: 0.8014461625584066]
	TIME [epoch: 5.74 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.094267409974071		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 1.094267409974071 | validation: 0.7794244329464565]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_679.pth
	Model improved!!!
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102733334671579		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 1.102733334671579 | validation: 0.810284578172236]
	TIME [epoch: 5.71 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0817430101973418		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 1.0817430101973418 | validation: 0.8535760031501765]
	TIME [epoch: 5.71 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0834529522609455		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 1.0834529522609455 | validation: 0.8544297835374719]
	TIME [epoch: 5.71 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1103272020677126		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 1.1103272020677126 | validation: 0.9276074071701359]
	TIME [epoch: 5.71 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.188126391527939		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.188126391527939 | validation: 0.8568622086341908]
	TIME [epoch: 5.74 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0784533388589832		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 1.0784533388589832 | validation: 0.9147221133663418]
	TIME [epoch: 5.73 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1157051392189916		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.1157051392189916 | validation: 0.8454282993157511]
	TIME [epoch: 5.71 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1403786115375936		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 1.1403786115375936 | validation: 0.8276374828585056]
	TIME [epoch: 5.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1195746660042336		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 1.1195746660042336 | validation: 0.8260111634406455]
	TIME [epoch: 5.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0739012361469986		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 1.0739012361469986 | validation: 0.7748298954632016]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_689.pth
	Model improved!!!
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0801211816663743		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 1.0801211816663743 | validation: 0.7998174651331473]
	TIME [epoch: 5.71 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082273589786459		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 1.082273589786459 | validation: 0.8644366846901178]
	TIME [epoch: 5.75 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1257733385648392		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 1.1257733385648392 | validation: 0.8040232104482757]
	TIME [epoch: 5.72 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1168762761805606		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 1.1168762761805606 | validation: 0.8505710541643058]
	TIME [epoch: 5.71 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0787022824549415		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 1.0787022824549415 | validation: 1.0774222360414945]
	TIME [epoch: 5.72 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1253381377484035		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 1.1253381377484035 | validation: 0.8454109076749288]
	TIME [epoch: 5.72 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0581249055269835		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 1.0581249055269835 | validation: 0.9555322244869009]
	TIME [epoch: 5.71 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1531996322916689		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 1.1531996322916689 | validation: 0.8221202175217691]
	TIME [epoch: 5.73 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0756598691623906		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 1.0756598691623906 | validation: 0.8080020997205024]
	TIME [epoch: 5.73 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1046788096702862		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 1.1046788096702862 | validation: 0.8206340222689253]
	TIME [epoch: 5.71 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0784039962538046		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 1.0784039962538046 | validation: 0.9506062550776165]
	TIME [epoch: 5.72 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1323259324101125		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 1.1323259324101125 | validation: 0.7984565383728485]
	TIME [epoch: 5.71 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086694900463378		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 1.086694900463378 | validation: 0.8661608722881422]
	TIME [epoch: 5.71 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0916092382468099		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 1.0916092382468099 | validation: 0.8291857722544521]
	TIME [epoch: 5.72 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102707519656441		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 1.102707519656441 | validation: 0.9718859467248074]
	TIME [epoch: 5.76 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.110097546290883		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 1.110097546290883 | validation: 0.8196719001820665]
	TIME [epoch: 5.71 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1066292639909678		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 1.1066292639909678 | validation: 0.7898484791968388]
	TIME [epoch: 5.71 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161901604177057		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 1.161901604177057 | validation: 0.7839460953550003]
	TIME [epoch: 5.71 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0536866074677893		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 1.0536866074677893 | validation: 0.8776582872905928]
	TIME [epoch: 5.71 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0746438879739681		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 1.0746438879739681 | validation: 0.8668881004593025]
	TIME [epoch: 5.71 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0893349811277588		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 1.0893349811277588 | validation: 0.85413941107743]
	TIME [epoch: 5.74 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0845708136801941		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 1.0845708136801941 | validation: 0.7977591139816216]
	TIME [epoch: 5.73 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0510348198302146		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 1.0510348198302146 | validation: 0.86794178922204]
	TIME [epoch: 5.72 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0775728314563764		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 1.0775728314563764 | validation: 0.8913979753573827]
	TIME [epoch: 5.72 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0859324537484742		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 1.0859324537484742 | validation: 0.9647851859421559]
	TIME [epoch: 5.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385792848670229		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 1.1385792848670229 | validation: 1.058744568436273]
	TIME [epoch: 5.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1477226309644148		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 1.1477226309644148 | validation: 0.7934759662965243]
	TIME [epoch: 5.71 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068901141717905		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 1.068901141717905 | validation: 0.8409548273818557]
	TIME [epoch: 5.75 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1110014997127566		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 1.1110014997127566 | validation: 0.8896717876975927]
	TIME [epoch: 5.71 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.120788486416654		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 1.120788486416654 | validation: 0.8075011347455123]
	TIME [epoch: 5.71 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0654442171707788		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 1.0654442171707788 | validation: 0.8238243948481473]
	TIME [epoch: 5.71 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1257010822675895		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 1.1257010822675895 | validation: 0.890399960105851]
	TIME [epoch: 5.71 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0780651979316207		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 1.0780651979316207 | validation: 0.8213139524400067]
	TIME [epoch: 5.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1092275380921435		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 1.1092275380921435 | validation: 0.8248932835283692]
	TIME [epoch: 5.73 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.094631923403787		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 1.094631923403787 | validation: 0.846104255642974]
	TIME [epoch: 5.72 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160987336554741		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 1.160987336554741 | validation: 0.9020933860428025]
	TIME [epoch: 5.71 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1099695178470435		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 1.1099695178470435 | validation: 0.8404780890657486]
	TIME [epoch: 5.71 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1578673564546555		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 1.1578673564546555 | validation: 0.7991201018377012]
	TIME [epoch: 5.71 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066571597143756		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 1.066571597143756 | validation: 0.9042272241722167]
	TIME [epoch: 5.71 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174795319045581		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 1.174795319045581 | validation: 0.9800391765690349]
	TIME [epoch: 5.71 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1093651660432229		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 1.1093651660432229 | validation: 0.8547094028382358]
	TIME [epoch: 5.75 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0817337731541161		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 1.0817337731541161 | validation: 0.8428826082153024]
	TIME [epoch: 5.71 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.095780082810782		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 1.095780082810782 | validation: 0.9319568481536262]
	TIME [epoch: 5.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1017441411319169		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 1.1017441411319169 | validation: 0.8205607745037008]
	TIME [epoch: 5.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0587984328784887		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 1.0587984328784887 | validation: 0.7974195920204014]
	TIME [epoch: 5.71 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0700930203682975		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 1.0700930203682975 | validation: 0.7922434883967463]
	TIME [epoch: 5.71 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.090874484478773		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 1.090874484478773 | validation: 0.819624108247997]
	TIME [epoch: 5.72 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1037609760110536		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 1.1037609760110536 | validation: 0.9270090851931387]
	TIME [epoch: 5.74 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1407320403954835		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 1.1407320403954835 | validation: 0.9094232073248736]
	TIME [epoch: 5.71 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0992702554663185		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 1.0992702554663185 | validation: 0.8597623166649198]
	TIME [epoch: 5.71 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0767065129523554		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 1.0767065129523554 | validation: 0.8940466040932985]
	TIME [epoch: 5.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0841850977617362		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 1.0841850977617362 | validation: 0.8028575726579328]
	TIME [epoch: 5.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0503871667885825		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 1.0503871667885825 | validation: 0.8493895137086921]
	TIME [epoch: 5.71 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0940999354804166		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 1.0940999354804166 | validation: 0.8170724106949624]
	TIME [epoch: 5.76 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1454092432091723		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 1.1454092432091723 | validation: 0.8710622873541972]
	TIME [epoch: 5.72 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0961055676736704		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 1.0961055676736704 | validation: 0.9096227326788793]
	TIME [epoch: 5.72 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1258375414259847		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 1.1258375414259847 | validation: 0.9356989264364981]
	TIME [epoch: 5.71 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0735860803792048		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 1.0735860803792048 | validation: 0.7845945943423235]
	TIME [epoch: 5.71 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0648912294773616		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 1.0648912294773616 | validation: 0.8321965874884475]
	TIME [epoch: 5.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0760122380892185		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 1.0760122380892185 | validation: 0.7921915424925378]
	TIME [epoch: 5.72 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0622885497589099		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 1.0622885497589099 | validation: 0.8218733018715014]
	TIME [epoch: 5.75 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0846786302790075		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 1.0846786302790075 | validation: 0.863554074051285]
	TIME [epoch: 5.72 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0716420401854618		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 1.0716420401854618 | validation: 0.9577403714415488]
	TIME [epoch: 5.71 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1003333708823442		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 1.1003333708823442 | validation: 0.8742756471768064]
	TIME [epoch: 5.71 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081309755583058		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 1.081309755583058 | validation: 0.8598231534287751]
	TIME [epoch: 5.71 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0833896897037691		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 1.0833896897037691 | validation: 0.9633925048901881]
	TIME [epoch: 5.72 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.096202525871015		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 1.096202525871015 | validation: 0.8089384602350641]
	TIME [epoch: 5.74 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059556268380345		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 1.059556268380345 | validation: 0.8118931336980323]
	TIME [epoch: 5.71 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063701233321925		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 1.063701233321925 | validation: 0.7927116683204237]
	TIME [epoch: 5.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1012538956375728		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 1.1012538956375728 | validation: 1.0277069130616183]
	TIME [epoch: 5.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1108921746249076		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 1.1108921746249076 | validation: 0.809088077565706]
	TIME [epoch: 5.71 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075624877262522		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 1.075624877262522 | validation: 0.8152745735401722]
	TIME [epoch: 5.71 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1344550205641393		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 1.1344550205641393 | validation: 0.8095841671714845]
	TIME [epoch: 5.72 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0691078875008944		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 1.0691078875008944 | validation: 0.8444328397648037]
	TIME [epoch: 5.75 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0903212347544293		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 1.0903212347544293 | validation: 0.7943108461927548]
	TIME [epoch: 5.72 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0844781210283114		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 1.0844781210283114 | validation: 0.8316540665010448]
	TIME [epoch: 5.71 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0772560853623157		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 1.0772560853623157 | validation: 0.8250760163505989]
	TIME [epoch: 5.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1157441083802095		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 1.1157441083802095 | validation: 0.813127569506255]
	TIME [epoch: 5.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061759263868206		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 1.061759263868206 | validation: 0.8979741341241456]
	TIME [epoch: 5.71 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1199738568351585		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 1.1199738568351585 | validation: 0.8979250351598492]
	TIME [epoch: 5.75 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1081097103567787		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 1.1081097103567787 | validation: 0.79557715089977]
	TIME [epoch: 5.72 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0740816950425767		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 1.0740816950425767 | validation: 0.8733953204456752]
	TIME [epoch: 5.71 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0914540590754094		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 1.0914540590754094 | validation: 0.777892728492787]
	TIME [epoch: 5.71 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059411450386619		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 1.059411450386619 | validation: 0.7804313049365149]
	TIME [epoch: 5.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0662716881947283		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 1.0662716881947283 | validation: 0.7982143096470148]
	TIME [epoch: 5.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0595099633876373		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 1.0595099633876373 | validation: 0.835669211057056]
	TIME [epoch: 5.71 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.21676518217745		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 1.21676518217745 | validation: 0.8886209969856826]
	TIME [epoch: 5.74 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0945405786551254		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 1.0945405786551254 | validation: 0.7841349263881877]
	TIME [epoch: 5.71 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0794691398165526		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 1.0794691398165526 | validation: 0.830011508988415]
	TIME [epoch: 5.71 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1190971525798756		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 1.1190971525798756 | validation: 0.8312578313171958]
	TIME [epoch: 5.71 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1807765660341587		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 1.1807765660341587 | validation: 0.8190571232883339]
	TIME [epoch: 5.71 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065746925369939		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 1.065746925369939 | validation: 0.85012691579779]
	TIME [epoch: 5.71 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0847467352763507		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 1.0847467352763507 | validation: 0.9506890387509822]
	TIME [epoch: 5.75 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1102802757908075		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 1.1102802757908075 | validation: 0.8044451059654902]
	TIME [epoch: 5.71 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618513946505268		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 1.0618513946505268 | validation: 0.8098832889125939]
	TIME [epoch: 5.71 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0695812473893784		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 1.0695812473893784 | validation: 0.8406898758757174]
	TIME [epoch: 5.71 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0904525133754825		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 1.0904525133754825 | validation: 0.8280833472865021]
	TIME [epoch: 5.71 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0555053783255595		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 1.0555053783255595 | validation: 0.8249797135183724]
	TIME [epoch: 5.71 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0859528298807342		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 1.0859528298807342 | validation: 0.8077937403999096]
	TIME [epoch: 5.72 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0993357491229865		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 1.0993357491229865 | validation: 0.9041436931527141]
	TIME [epoch: 5.74 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0664721882069461		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 1.0664721882069461 | validation: 0.8753363247427204]
	TIME [epoch: 5.72 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.072873597135785		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 1.072873597135785 | validation: 0.8710375285900667]
	TIME [epoch: 5.71 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0843915797043362		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 1.0843915797043362 | validation: 0.7919818935475742]
	TIME [epoch: 5.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0868738655311145		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 1.0868738655311145 | validation: 0.8088697774794474]
	TIME [epoch: 5.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060250346940722		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 1.060250346940722 | validation: 0.8084722462338002]
	TIME [epoch: 5.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0699991730071654		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 1.0699991730071654 | validation: 0.7998758930572655]
	TIME [epoch: 5.74 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0452954034495356		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 1.0452954034495356 | validation: 0.8869578143214113]
	TIME [epoch: 5.72 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0768721338423848		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 1.0768721338423848 | validation: 0.848145284789158]
	TIME [epoch: 5.71 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081242854408133		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 1.081242854408133 | validation: 0.9191102566809537]
	TIME [epoch: 5.71 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0985021291332244		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 1.0985021291332244 | validation: 0.8213597307707571]
	TIME [epoch: 5.71 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0614176945609186		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 1.0614176945609186 | validation: 0.851521637947219]
	TIME [epoch: 5.71 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0492269484035606		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 1.0492269484035606 | validation: 0.8817497014307499]
	TIME [epoch: 5.71 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.084953066372719		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 1.084953066372719 | validation: 0.9030505748563841]
	TIME [epoch: 5.73 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.083307181417542		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 1.083307181417542 | validation: 0.8043887503181405]
	TIME [epoch: 5.71 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0540404268219752		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 1.0540404268219752 | validation: 0.8185160713415067]
	TIME [epoch: 5.71 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0586919095026375		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 1.0586919095026375 | validation: 0.7854309687580711]
	TIME [epoch: 5.71 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.049455717480245		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 1.049455717480245 | validation: 0.8238692432024307]
	TIME [epoch: 5.71 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0729249685471653		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 1.0729249685471653 | validation: 0.8599900435655667]
	TIME [epoch: 5.71 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.077066060728987		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 1.077066060728987 | validation: 0.8282968377028883]
	TIME [epoch: 5.74 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051018220243076		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 1.051018220243076 | validation: 0.8254725378491335]
	TIME [epoch: 5.72 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0755344712769688		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 1.0755344712769688 | validation: 0.8527070198476124]
	TIME [epoch: 5.71 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053141724918485		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 1.053141724918485 | validation: 0.882710313089008]
	TIME [epoch: 5.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053513777665109		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 1.053513777665109 | validation: 0.8713360693727167]
	TIME [epoch: 5.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0610449911667539		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 1.0610449911667539 | validation: 0.8020387254259047]
	TIME [epoch: 5.71 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.134469344934808		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 1.134469344934808 | validation: 0.8264192179550657]
	TIME [epoch: 5.71 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.069358118037289		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 1.069358118037289 | validation: 0.7934942729606804]
	TIME [epoch: 5.75 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0574176303322895		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 1.0574176303322895 | validation: 0.8099437946782958]
	TIME [epoch: 5.71 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.070407032670928		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 1.070407032670928 | validation: 0.7898029191235549]
	TIME [epoch: 5.71 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0745014152719925		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 1.0745014152719925 | validation: 0.8018329149189402]
	TIME [epoch: 5.71 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0677316190421555		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 1.0677316190421555 | validation: 0.8127951254518021]
	TIME [epoch: 5.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059068448599061		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 1.059068448599061 | validation: 0.8029760709088823]
	TIME [epoch: 5.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632214506083457		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 1.0632214506083457 | validation: 0.872395232881553]
	TIME [epoch: 5.73 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0718568530975012		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 1.0718568530975012 | validation: 0.8452117596948362]
	TIME [epoch: 5.72 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0695663852805906		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 1.0695663852805906 | validation: 0.8117357903793853]
	TIME [epoch: 5.71 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0629297453279638		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 1.0629297453279638 | validation: 0.8406999753488431]
	TIME [epoch: 5.71 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1049135600661943		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 1.1049135600661943 | validation: 0.7888671722392695]
	TIME [epoch: 5.71 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0466119813565338		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 1.0466119813565338 | validation: 0.7903366564939613]
	TIME [epoch: 5.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0666638710814356		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 1.0666638710814356 | validation: 0.7855216607519839]
	TIME [epoch: 5.71 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0489998031516088		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 1.0489998031516088 | validation: 0.8125471940243085]
	TIME [epoch: 5.76 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0672577722919314		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 1.0672577722919314 | validation: 0.8203360441678641]
	TIME [epoch: 5.71 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0482005255156492		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 1.0482005255156492 | validation: 0.8785456179170186]
	TIME [epoch: 5.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.091777995438098		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 1.091777995438098 | validation: 0.7949334735768779]
	TIME [epoch: 5.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0812308936201074		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 1.0812308936201074 | validation: 0.8102314542778097]
	TIME [epoch: 5.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0464727469703539		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 1.0464727469703539 | validation: 0.8265290099984008]
	TIME [epoch: 5.71 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067118035335741		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 1.067118035335741 | validation: 0.8005646143890586]
	TIME [epoch: 5.74 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0426026580445062		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 1.0426026580445062 | validation: 0.8340612945361153]
	TIME [epoch: 5.73 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0493879926007355		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 1.0493879926007355 | validation: 0.83009838615078]
	TIME [epoch: 5.71 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0846476800379137		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 1.0846476800379137 | validation: 0.9036328685022159]
	TIME [epoch: 5.71 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.121490087793824		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 1.121490087793824 | validation: 0.8367012147428474]
	TIME [epoch: 5.71 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0691582671002167		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 1.0691582671002167 | validation: 0.8293396825649864]
	TIME [epoch: 5.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0504510184918534		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 1.0504510184918534 | validation: 0.8104667595718942]
	TIME [epoch: 5.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0594169654883374		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 1.0594169654883374 | validation: 0.792446570947595]
	TIME [epoch: 5.74 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0539457412604303		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 1.0539457412604303 | validation: 0.8278145118348951]
	TIME [epoch: 5.71 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0899214393954695		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 1.0899214393954695 | validation: 0.8084053284825925]
	TIME [epoch: 5.71 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0565603390601772		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 1.0565603390601772 | validation: 0.7899284455968035]
	TIME [epoch: 5.71 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065331951206444		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 1.065331951206444 | validation: 0.7844959954372468]
	TIME [epoch: 5.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051246655134627		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 1.051246655134627 | validation: 0.9369801876307503]
	TIME [epoch: 5.71 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0806285302290486		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 1.0806285302290486 | validation: 0.7942476521956513]
	TIME [epoch: 5.74 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0530230797341575		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 1.0530230797341575 | validation: 0.8075227411220545]
	TIME [epoch: 5.72 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0783293337625584		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 1.0783293337625584 | validation: 0.7992337247930351]
	TIME [epoch: 5.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0552606907047353		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 1.0552606907047353 | validation: 0.7985797644364954]
	TIME [epoch: 5.71 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.045959150034877		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 1.045959150034877 | validation: 0.807802741331269]
	TIME [epoch: 5.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.074184915003901		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 1.074184915003901 | validation: 0.7951658512122495]
	TIME [epoch: 5.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0512004199007448		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 1.0512004199007448 | validation: 0.8428395243207788]
	TIME [epoch: 5.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.079460981849669		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 1.079460981849669 | validation: 0.7944873151597136]
	TIME [epoch: 5.75 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0473350202308411		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 1.0473350202308411 | validation: 0.8020289852218779]
	TIME [epoch: 5.71 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0492906649723928		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 1.0492906649723928 | validation: 0.9554252592658594]
	TIME [epoch: 5.71 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0845428525100334		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 1.0845428525100334 | validation: 0.825970056521534]
	TIME [epoch: 5.71 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0647385159778262		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 1.0647385159778262 | validation: 0.8622336295727334]
	TIME [epoch: 5.71 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0932667623304146		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 1.0932667623304146 | validation: 0.8291196071374358]
	TIME [epoch: 5.71 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051580343457129		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 1.051580343457129 | validation: 0.8065213808114479]
	TIME [epoch: 5.73 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0502368804563351		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 1.0502368804563351 | validation: 0.8424312474208149]
	TIME [epoch: 5.72 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0501031216584356		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 1.0501031216584356 | validation: 0.7896354096060815]
	TIME [epoch: 5.71 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0449000783952638		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 1.0449000783952638 | validation: 0.7991068255312961]
	TIME [epoch: 5.71 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0578571007593802		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 1.0578571007593802 | validation: 0.8232256340084121]
	TIME [epoch: 5.71 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0490053463363194		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 1.0490053463363194 | validation: 0.840023115704585]
	TIME [epoch: 5.71 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06757330125138		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 1.06757330125138 | validation: 0.8446834207163424]
	TIME [epoch: 5.71 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0732573916225996		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 1.0732573916225996 | validation: 0.8227820196581824]
	TIME [epoch: 5.75 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.047998123902433		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 1.047998123902433 | validation: 0.8215697465384875]
	TIME [epoch: 5.71 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0620104511290263		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 1.0620104511290263 | validation: 0.7945345111885667]
	TIME [epoch: 5.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0530994634982038		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 1.0530994634982038 | validation: 0.8162571341745796]
	TIME [epoch: 5.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0595952775945952		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 1.0595952775945952 | validation: 0.7834321878460991]
	TIME [epoch: 5.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0571487892168494		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 1.0571487892168494 | validation: 0.8315828101174475]
	TIME [epoch: 5.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0450265165548314		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 1.0450265165548314 | validation: 0.798163276588834]
	TIME [epoch: 5.74 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.055395608306342		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 1.055395608306342 | validation: 0.8418223216211618]
	TIME [epoch: 5.72 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0493191107514193		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 1.0493191107514193 | validation: 0.8289080810286887]
	TIME [epoch: 5.71 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0536589356088808		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 1.0536589356088808 | validation: 0.7890300274710401]
	TIME [epoch: 5.71 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053933334925717		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 1.053933334925717 | validation: 0.8314336577835283]
	TIME [epoch: 5.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0547161895449086		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 1.0547161895449086 | validation: 0.8219892014055253]
	TIME [epoch: 5.71 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061544051062618		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 1.061544051062618 | validation: 0.7853968734046654]
	TIME [epoch: 5.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0670208692607508		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 1.0670208692607508 | validation: 0.8435855727952222]
	TIME [epoch: 5.74 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0637771504186273		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 1.0637771504186273 | validation: 0.8020514011844162]
	TIME [epoch: 5.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0494275773958708		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 1.0494275773958708 | validation: 0.7878420178618092]
	TIME [epoch: 5.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0436580777341		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 1.0436580777341 | validation: 0.784250803915218]
	TIME [epoch: 5.71 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0662469172003388		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 1.0662469172003388 | validation: 0.8201392360523728]
	TIME [epoch: 5.71 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0579737854912736		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 1.0579737854912736 | validation: 0.7935305385412378]
	TIME [epoch: 5.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.147242645031929		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 1.147242645031929 | validation: 0.7648638599286163]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_886.pth
	Model improved!!!
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1289823420834557		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 1.1289823420834557 | validation: 0.7881177633893683]
	TIME [epoch: 5.72 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0524054976016641		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 1.0524054976016641 | validation: 0.7710667516297454]
	TIME [epoch: 5.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060354968258688		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 1.060354968258688 | validation: 0.7905369684290993]
	TIME [epoch: 5.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0637994449604433		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 1.0637994449604433 | validation: 0.7829513322544509]
	TIME [epoch: 5.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0418852971212846		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 1.0418852971212846 | validation: 0.7918217094040547]
	TIME [epoch: 5.71 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.050295918663898		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 1.050295918663898 | validation: 0.7859633867692404]
	TIME [epoch: 5.71 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0482513679807148		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 1.0482513679807148 | validation: 0.7866423488034744]
	TIME [epoch: 5.75 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056662028681274		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 1.056662028681274 | validation: 0.7899098827827523]
	TIME [epoch: 5.71 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.043651289600095		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 1.043651289600095 | validation: 0.8276987539713259]
	TIME [epoch: 5.71 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0622073109662362		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 1.0622073109662362 | validation: 0.7885780461522981]
	TIME [epoch: 5.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0462483198294925		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 1.0462483198294925 | validation: 0.7767804664220193]
	TIME [epoch: 5.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0438714017479083		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 1.0438714017479083 | validation: 0.7747364311627868]
	TIME [epoch: 5.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0896169368941186		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 1.0896169368941186 | validation: 0.8422349156374523]
	TIME [epoch: 5.73 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601756040006816		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 1.0601756040006816 | validation: 0.7773951138533033]
	TIME [epoch: 5.72 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0575957802590523		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 1.0575957802590523 | validation: 0.7913617675055729]
	TIME [epoch: 5.71 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0774847276937822		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 1.0774847276937822 | validation: 1.143415217826322]
	TIME [epoch: 5.71 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.193179224393642		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 1.193179224393642 | validation: 0.793694473162754]
	TIME [epoch: 5.71 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0800691240387297		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 1.0800691240387297 | validation: 0.7767281180157463]
	TIME [epoch: 5.71 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0715203087290868		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 1.0715203087290868 | validation: 0.7860913534123484]
	TIME [epoch: 5.71 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075384961945478		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 1.075384961945478 | validation: 0.7950828358721479]
	TIME [epoch: 5.75 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.096164171773167		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 1.096164171773167 | validation: 0.8051890598535237]
	TIME [epoch: 5.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0699749871523345		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 1.0699749871523345 | validation: 0.8274978778676274]
	TIME [epoch: 5.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0552818456417183		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 1.0552818456417183 | validation: 0.8058897320908822]
	TIME [epoch: 5.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0465799535525877		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 1.0465799535525877 | validation: 0.7988302782557462]
	TIME [epoch: 5.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0448612740273768		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 1.0448612740273768 | validation: 0.9202737548494657]
	TIME [epoch: 5.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1411383617867676		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 1.1411383617867676 | validation: 0.7929367151846826]
	TIME [epoch: 5.73 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0558238868547993		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 1.0558238868547993 | validation: 0.782397903989564]
	TIME [epoch: 5.72 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0465455688173506		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 1.0465455688173506 | validation: 0.7808404142542545]
	TIME [epoch: 5.71 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0403909713551363		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 1.0403909713551363 | validation: 0.7944074934615387]
	TIME [epoch: 5.71 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0462728230459168		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 1.0462728230459168 | validation: 0.8523577195317078]
	TIME [epoch: 5.71 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0633098345299965		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 1.0633098345299965 | validation: 0.8262510341142177]
	TIME [epoch: 5.7 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.104715258626891		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 1.104715258626891 | validation: 0.8279940989043516]
	TIME [epoch: 5.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0728702330591369		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 1.0728702330591369 | validation: 0.8563570753381697]
	TIME [epoch: 5.74 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0501857129615635		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 1.0501857129615635 | validation: 0.7975786443944364]
	TIME [epoch: 5.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0443600308866419		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 1.0443600308866419 | validation: 0.8365495379928813]
	TIME [epoch: 5.71 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048768262068475		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 1.048768262068475 | validation: 0.8075433402464893]
	TIME [epoch: 5.71 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0495299602998498		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 1.0495299602998498 | validation: 0.8197128523277557]
	TIME [epoch: 5.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0684766367202947		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 1.0684766367202947 | validation: 0.8066338442274074]
	TIME [epoch: 5.71 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0500865153226537		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 1.0500865153226537 | validation: 0.8184046137308291]
	TIME [epoch: 5.74 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.052238233812466		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 1.052238233812466 | validation: 0.8134486591758711]
	TIME [epoch: 5.72 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0522838991002608		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 1.0522838991002608 | validation: 0.8034970158289391]
	TIME [epoch: 5.71 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0837130202361807		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 1.0837130202361807 | validation: 0.8174085781411278]
	TIME [epoch: 5.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0529244809493206		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 1.0529244809493206 | validation: 0.8552486611668038]
	TIME [epoch: 5.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0474590648894178		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 1.0474590648894178 | validation: 0.8610965022257524]
	TIME [epoch: 5.71 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061522109775561		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 1.061522109775561 | validation: 0.8157405721473316]
	TIME [epoch: 5.71 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601698003239561		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 1.0601698003239561 | validation: 0.794629156019341]
	TIME [epoch: 5.75 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0763790421735762		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 1.0763790421735762 | validation: 0.8003791381411941]
	TIME [epoch: 5.71 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0633197111679178		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 1.0633197111679178 | validation: 0.7907994624636571]
	TIME [epoch: 5.71 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584169262858283		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 1.0584169262858283 | validation: 0.817108083785522]
	TIME [epoch: 5.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0671056170984459		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 1.0671056170984459 | validation: 0.7810751069357921]
	TIME [epoch: 5.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.070228400035484		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 1.070228400035484 | validation: 0.8209437154454002]
	TIME [epoch: 5.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0607595505238359		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 1.0607595505238359 | validation: 0.776553071535268]
	TIME [epoch: 5.71 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0670384921982485		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 1.0670384921982485 | validation: 0.7918721133306593]
	TIME [epoch: 5.73 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0543392217041112		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 1.0543392217041112 | validation: 0.8024149928960964]
	TIME [epoch: 5.71 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0806888883107506		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 1.0806888883107506 | validation: 0.8762722924914801]
	TIME [epoch: 5.71 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0586201016114964		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 1.0586201016114964 | validation: 0.8036903749047533]
	TIME [epoch: 5.71 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0428769131369686		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 1.0428769131369686 | validation: 0.8148810896941566]
	TIME [epoch: 5.71 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0473193890625248		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 1.0473193890625248 | validation: 0.797515725804005]
	TIME [epoch: 5.71 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0539440256726587		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 1.0539440256726587 | validation: 0.7733788751245843]
	TIME [epoch: 5.75 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0539091119362276		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 1.0539091119362276 | validation: 0.7925138573078083]
	TIME [epoch: 5.71 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0390563122673977		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 1.0390563122673977 | validation: 0.7944565247992667]
	TIME [epoch: 5.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0390355079595979		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 1.0390355079595979 | validation: 0.8606994810295726]
	TIME [epoch: 5.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0705508402518982		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 1.0705508402518982 | validation: 0.7921215700043203]
	TIME [epoch: 5.7 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0479551278167478		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 1.0479551278167478 | validation: 0.8290293174829384]
	TIME [epoch: 5.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058004988847416		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 1.058004988847416 | validation: 0.8144427024470813]
	TIME [epoch: 5.72 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.036534101620752		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 1.036534101620752 | validation: 0.837698934141869]
	TIME [epoch: 5.74 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0554209469759692		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 1.0554209469759692 | validation: 0.8109027193585433]
	TIME [epoch: 5.71 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.046355243051324		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 1.046355243051324 | validation: 0.8764467866280526]
	TIME [epoch: 5.71 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0537037945149064		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 1.0537037945149064 | validation: 0.8154924457322703]
	TIME [epoch: 5.71 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0509331455690287		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 1.0509331455690287 | validation: 0.8209386894211035]
	TIME [epoch: 5.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0510224204863245		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 1.0510224204863245 | validation: 0.804654978110996]
	TIME [epoch: 5.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0370593375363293		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 1.0370593375363293 | validation: 0.7931554279923323]
	TIME [epoch: 5.74 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0504337960796943		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 1.0504337960796943 | validation: 0.8116608797636744]
	TIME [epoch: 5.71 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0482078525409566		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 1.0482078525409566 | validation: 0.8132777102097961]
	TIME [epoch: 5.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0522277248677983		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 1.0522277248677983 | validation: 0.7892437723696654]
	TIME [epoch: 5.71 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0464281263347126		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 1.0464281263347126 | validation: 0.7957374675181892]
	TIME [epoch: 5.71 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0672227999452304		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 1.0672227999452304 | validation: 0.7879529405805303]
	TIME [epoch: 5.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0548484974923755		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 1.0548484974923755 | validation: 0.886397238094286]
	TIME [epoch: 5.72 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059918035319148		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 1.059918035319148 | validation: 0.822307293292441]
	TIME [epoch: 5.74 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0486942479642645		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 1.0486942479642645 | validation: 0.8486731231823962]
	TIME [epoch: 5.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.046195588589799		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 1.046195588589799 | validation: 0.7959045967427397]
	TIME [epoch: 5.7 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04164125794277		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 1.04164125794277 | validation: 0.802620142602496]
	TIME [epoch: 5.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0458303274142902		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 1.0458303274142902 | validation: 0.8627732695539062]
	TIME [epoch: 5.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048787751945044		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 1.048787751945044 | validation: 0.8758097054149135]
	TIME [epoch: 5.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0680207081638469		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 1.0680207081638469 | validation: 0.800657094970747]
	TIME [epoch: 5.75 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0603440051511017		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 1.0603440051511017 | validation: 0.7942990698336837]
	TIME [epoch: 5.71 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04784479034262		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 1.04784479034262 | validation: 0.8465460695259044]
	TIME [epoch: 5.71 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0515766855835569		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 1.0515766855835569 | validation: 0.8208289758678899]
	TIME [epoch: 5.71 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0407131924372544		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 1.0407131924372544 | validation: 0.8250836240042871]
	TIME [epoch: 5.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035905467460319		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 1.035905467460319 | validation: 0.7943770099563138]
	TIME [epoch: 5.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0371458037150296		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 1.0371458037150296 | validation: 0.8003175361864644]
	TIME [epoch: 5.71 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0504094830419817		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 1.0504094830419817 | validation: 0.8370710978075903]
	TIME [epoch: 5.73 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0459902548347837		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 1.0459902548347837 | validation: 0.8311663354531621]
	TIME [epoch: 5.71 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.042430376565725		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 1.042430376565725 | validation: 0.8076618720868273]
	TIME [epoch: 5.71 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0511385764198367		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 1.0511385764198367 | validation: 0.8257578903609256]
	TIME [epoch: 5.71 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0421479376471101		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 1.0421479376471101 | validation: 0.7997384472462661]
	TIME [epoch: 5.71 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0460065822060758		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 1.0460065822060758 | validation: 0.816229945692838]
	TIME [epoch: 5.71 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0418928452885434		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 1.0418928452885434 | validation: 0.799817263300304]
	TIME [epoch: 5.75 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.043719067573926		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 1.043719067573926 | validation: 0.8396353690329654]
	TIME [epoch: 5.71 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0443306613279018		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 1.0443306613279018 | validation: 0.8265741509930118]
	TIME [epoch: 5.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576054982859435		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 1.0576054982859435 | validation: 0.7784839798951222]
	TIME [epoch: 5.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0339626393184385		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 1.0339626393184385 | validation: 0.7979557967140619]
	TIME [epoch: 5.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0467836880894963		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 1.0467836880894963 | validation: 0.799794890457376]
	TIME [epoch: 5.71 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063354637013309		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 1.063354637013309 | validation: 0.812570897084627]
	TIME [epoch: 5.71 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0562002586459096		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 1.0562002586459096 | validation: 0.787197517100959]
	TIME [epoch: 5.74 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0336451639973818		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 1.0336451639973818 | validation: 0.7963654103262033]
	TIME [epoch: 5.71 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0903565372828836		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 1.0903565372828836 | validation: 0.8190533024132438]
	TIME [epoch: 5.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0441592457327011		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 1.0441592457327011 | validation: 0.8609283642780188]
	TIME [epoch: 5.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0538632488679858		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 1.0538632488679858 | validation: 0.8023774546452941]
	TIME [epoch: 5.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0354049494792341		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 1.0354049494792341 | validation: 0.7993176243059239]
	TIME [epoch: 5.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0381057294696188		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 1.0381057294696188 | validation: 0.7830470834946018]
	TIME [epoch: 5.75 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0464722320701338		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 1.0464722320701338 | validation: 0.7756415232647337]
	TIME [epoch: 5.72 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625860487449656		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 1.0625860487449656 | validation: 0.7859194841875086]
	TIME [epoch: 5.71 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0332345746749216		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 1.0332345746749216 | validation: 0.7959230706934518]
	TIME [epoch: 5.71 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0520597294240697		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 1.0520597294240697 | validation: 0.7970450783259441]
	TIME [epoch: 5.71 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0777950484477223		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 1.0777950484477223 | validation: 0.8469199073104298]
	TIME [epoch: 5.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0506531612353434		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 1.0506531612353434 | validation: 0.7847973697336363]
	TIME [epoch: 5.71 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0421878870299053		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 1.0421878870299053 | validation: 0.799926762646802]
	TIME [epoch: 5.73 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0401177699974344		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 1.0401177699974344 | validation: 0.7927806879587632]
	TIME [epoch: 5.71 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0337263519858757		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 1.0337263519858757 | validation: 0.7846462520681332]
	TIME [epoch: 5.71 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0388158371441476		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 1.0388158371441476 | validation: 0.8249987527450355]
	TIME [epoch: 5.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0581553657728164		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 1.0581553657728164 | validation: 0.799302398012989]
	TIME [epoch: 5.71 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.050037912271051		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 1.050037912271051 | validation: 0.8883781483037447]
	TIME [epoch: 5.71 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07163300301989		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 1.07163300301989 | validation: 0.8767711818849379]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0536251393154097		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 1.0536251393154097 | validation: 0.7921136993819238]
	TIME [epoch: 5.71 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0339802702295688		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 1.0339802702295688 | validation: 0.8275718669762391]
	TIME [epoch: 5.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.050538104322384		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 1.050538104322384 | validation: 0.9451809866348698]
	TIME [epoch: 5.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1042554484757385		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 1.1042554484757385 | validation: 0.8011401554796157]
	TIME [epoch: 5.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0391744492292454		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 1.0391744492292454 | validation: 0.862113961306155]
	TIME [epoch: 5.71 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0830855358857594		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 1.0830855358857594 | validation: 0.8583544287815426]
	TIME [epoch: 5.72 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0527393470737025		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 1.0527393470737025 | validation: 0.8133254519006019]
	TIME [epoch: 5.74 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0356096134559114		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 1.0356096134559114 | validation: 0.8442824305533528]
	TIME [epoch: 5.71 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0528713440565336		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 1.0528713440565336 | validation: 0.8087723580257449]
	TIME [epoch: 5.71 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0462784179557767		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 1.0462784179557767 | validation: 0.7988948455900563]
	TIME [epoch: 5.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0393667786922696		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 1.0393667786922696 | validation: 0.7831008749698516]
	TIME [epoch: 5.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0469495793762633		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 1.0469495793762633 | validation: 0.8161133791412993]
	TIME [epoch: 5.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.042735825964168		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 1.042735825964168 | validation: 0.8294139398857145]
	TIME [epoch: 5.74 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0723913582254563		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 1.0723913582254563 | validation: 0.8137279766504982]
	TIME [epoch: 5.71 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0440691613003419		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 1.0440691613003419 | validation: 0.8648236604578121]
	TIME [epoch: 5.71 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0478936899833409		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 1.0478936899833409 | validation: 0.8308868445734103]
	TIME [epoch: 5.71 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0683861781096944		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 1.0683861781096944 | validation: 0.7763439289740832]
	TIME [epoch: 5.71 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0366180335740887		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 1.0366180335740887 | validation: 0.7809221100854814]
	TIME [epoch: 5.71 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0390080137482605		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 1.0390080137482605 | validation: 0.872904579794415]
	TIME [epoch: 5.71 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.088696909358568		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 1.088696909358568 | validation: 0.7971898341265339]
	TIME [epoch: 5.75 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0361304186623521		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 1.0361304186623521 | validation: 0.8235294425620532]
	TIME [epoch: 5.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0373319741001623		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 1.0373319741001623 | validation: 0.7906387413744699]
	TIME [epoch: 5.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0577583462763307		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 1.0577583462763307 | validation: 0.8021299049712229]
	TIME [epoch: 5.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0510217292228474		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 1.0510217292228474 | validation: 0.789795318238186]
	TIME [epoch: 5.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0526500273115413		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 1.0526500273115413 | validation: 0.8303931340093266]
	TIME [epoch: 5.71 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.046377099346364		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 1.046377099346364 | validation: 0.7806987926723429]
	TIME [epoch: 5.73 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0335105223863519		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 1.0335105223863519 | validation: 0.8227503142402581]
	TIME [epoch: 5.72 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0535018585502216		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 1.0535018585502216 | validation: 0.7908305992030239]
	TIME [epoch: 5.71 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051486017292206		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 1.051486017292206 | validation: 0.801163857886513]
	TIME [epoch: 5.71 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0406761023686595		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 1.0406761023686595 | validation: 0.8081330136223653]
	TIME [epoch: 5.71 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0374038041313771		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 1.0374038041313771 | validation: 0.8069766047063405]
	TIME [epoch: 5.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0644645221184694		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 1.0644645221184694 | validation: 0.8226985628328969]
	TIME [epoch: 5.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0365759103791852		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 1.0365759103791852 | validation: 0.8076912800378042]
	TIME [epoch: 5.74 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0344269057442717		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 1.0344269057442717 | validation: 0.8229416004267524]
	TIME [epoch: 5.71 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056490148381733		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 1.056490148381733 | validation: 0.8742439795848658]
	TIME [epoch: 5.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060067959227323		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 1.060067959227323 | validation: 0.8090302541670777]
	TIME [epoch: 5.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0389422380646813		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 1.0389422380646813 | validation: 0.8350563326889835]
	TIME [epoch: 5.71 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0405885816833627		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 1.0405885816833627 | validation: 0.7728207882014367]
	TIME [epoch: 5.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0412867400470518		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 1.0412867400470518 | validation: 0.7822650358761228]
	TIME [epoch: 5.73 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0359123110960988		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 1.0359123110960988 | validation: 0.7846884265202004]
	TIME [epoch: 5.72 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028055184671863		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 1.028055184671863 | validation: 0.7974964535060933]
	TIME [epoch: 5.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0465521325962823		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 1.0465521325962823 | validation: 0.8079164281460635]
	TIME [epoch: 5.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0350123828646516		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 1.0350123828646516 | validation: 0.787369098092666]
	TIME [epoch: 5.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0278876681898939		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 1.0278876681898939 | validation: 0.7907093655370117]
	TIME [epoch: 5.71 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0394470675777838		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 1.0394470675777838 | validation: 0.8125080280007668]
	TIME [epoch: 5.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0380842661406557		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 1.0380842661406557 | validation: 0.7957617677965552]
	TIME [epoch: 5.75 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0551263305873038		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 1.0551263305873038 | validation: 0.8394696644832231]
	TIME [epoch: 5.71 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.039735837840142		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 1.039735837840142 | validation: 0.7975336602542106]
	TIME [epoch: 5.71 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.052729872070205		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 1.052729872070205 | validation: 0.7887314699997328]
	TIME [epoch: 5.71 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0648607465300826		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 1.0648607465300826 | validation: 0.7957723221928873]
	TIME [epoch: 5.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0335569701006426		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 1.0335569701006426 | validation: 0.8229082332573967]
	TIME [epoch: 5.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0381996330845673		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 1.0381996330845673 | validation: 0.7844925224015304]
	TIME [epoch: 5.73 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0397732803281985		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 1.0397732803281985 | validation: 0.7990675619142991]
	TIME [epoch: 5.72 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0340517580304995		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 1.0340517580304995 | validation: 0.7804259645546153]
	TIME [epoch: 5.71 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0323968334348852		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 1.0323968334348852 | validation: 0.7742171318207494]
	TIME [epoch: 5.71 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035801155901547		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 1.035801155901547 | validation: 0.8033291786169032]
	TIME [epoch: 5.71 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.046801648704787		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 1.046801648704787 | validation: 0.7892867904683858]
	TIME [epoch: 5.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0380932721527163		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 1.0380932721527163 | validation: 0.784574665128196]
	TIME [epoch: 5.71 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0463815606599096		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 1.0463815606599096 | validation: 0.8026751124015712]
	TIME [epoch: 5.75 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0512066434064677		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 1.0512066434064677 | validation: 0.7878519402257425]
	TIME [epoch: 5.71 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0347348886256253		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 1.0347348886256253 | validation: 0.8024100650572067]
	TIME [epoch: 5.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0411575328367508		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 1.0411575328367508 | validation: 0.7822119493339724]
	TIME [epoch: 5.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0355932609612604		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 1.0355932609612604 | validation: 0.7982577960061994]
	TIME [epoch: 5.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033181742870434		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 1.033181742870434 | validation: 0.7934272448931475]
	TIME [epoch: 5.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0390790378405381		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 1.0390790378405381 | validation: 0.7827235902465318]
	TIME [epoch: 5.74 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0561095555415745		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 1.0561095555415745 | validation: 0.7928238529014152]
	TIME [epoch: 5.72 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0452274046152148		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 1.0452274046152148 | validation: 0.7796154998348552]
	TIME [epoch: 5.71 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0319432065837204		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 1.0319432065837204 | validation: 0.7750447637475486]
	TIME [epoch: 5.71 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.040000888367995		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 1.040000888367995 | validation: 0.827583927678985]
	TIME [epoch: 5.71 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632823118960895		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 1.0632823118960895 | validation: 0.7867670648244669]
	TIME [epoch: 5.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0475052746586022		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 1.0475052746586022 | validation: 0.7813019094058286]
	TIME [epoch: 5.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.039241064494582		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 1.039241064494582 | validation: 0.7953282435459155]
	TIME [epoch: 5.75 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035260606465636		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 1.035260606465636 | validation: 0.7989334966215494]
	TIME [epoch: 5.71 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0523465559595468		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 1.0523465559595468 | validation: 0.8627277430304321]
	TIME [epoch: 5.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051850705801374		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 1.051850705801374 | validation: 0.8407381586532452]
	TIME [epoch: 5.71 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0381157397972252		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 1.0381157397972252 | validation: 0.8104644437704651]
	TIME [epoch: 5.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0386196444460416		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 1.0386196444460416 | validation: 0.7858445238576459]
	TIME [epoch: 5.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0442674413294455		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 1.0442674413294455 | validation: 0.8312943000593046]
	TIME [epoch: 5.73 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0441490255993144		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 1.0441490255993144 | validation: 0.8324570211641122]
	TIME [epoch: 5.72 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.043390870862366		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 1.043390870862366 | validation: 0.7924838531360149]
	TIME [epoch: 5.71 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0323868551939244		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 1.0323868551939244 | validation: 0.8255447213213833]
	TIME [epoch: 5.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0498913491062094		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 1.0498913491062094 | validation: 0.7925275488781324]
	TIME [epoch: 5.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0333049565011965		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 1.0333049565011965 | validation: 0.7867167031153945]
	TIME [epoch: 5.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023088723832147		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 1.023088723832147 | validation: 0.7880550973038953]
	TIME [epoch: 5.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023206980532881		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 1.023206980532881 | validation: 0.7830167510881353]
	TIME [epoch: 5.75 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249333310070632		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 1.0249333310070632 | validation: 0.8181943842118813]
	TIME [epoch: 5.71 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0478928284534397		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 1.0478928284534397 | validation: 0.8011975192470052]
	TIME [epoch: 5.71 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0480111748249028		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 1.0480111748249028 | validation: 0.7908895153391893]
	TIME [epoch: 5.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028203863527851		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 1.028203863527851 | validation: 0.7900044091240447]
	TIME [epoch: 5.71 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04243421648798		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 1.04243421648798 | validation: 0.8071359565793773]
	TIME [epoch: 5.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0390424615472984		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 1.0390424615472984 | validation: 0.8504973802897107]
	TIME [epoch: 5.73 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0413266636646141		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 1.0413266636646141 | validation: 0.7932178921779071]
	TIME [epoch: 5.72 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0365249783952788		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 1.0365249783952788 | validation: 0.8310954959290154]
	TIME [epoch: 5.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0340574481815736		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 1.0340574481815736 | validation: 0.7966623982149846]
	TIME [epoch: 5.71 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0398003809046388		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 1.0398003809046388 | validation: 0.79989289091169]
	TIME [epoch: 5.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0302437815618641		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 1.0302437815618641 | validation: 0.8342543050108071]
	TIME [epoch: 5.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0344842643697634		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 1.0344842643697634 | validation: 0.8118887548947942]
	TIME [epoch: 5.71 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0693932714739032		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 1.0693932714739032 | validation: 0.7957557124013157]
	TIME [epoch: 5.75 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0305323761746052		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 1.0305323761746052 | validation: 0.8062134855056471]
	TIME [epoch: 5.71 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0551334527277485		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 1.0551334527277485 | validation: 0.8429539847824432]
	TIME [epoch: 5.71 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0434039583538384		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 1.0434039583538384 | validation: 0.7893326754578042]
	TIME [epoch: 5.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0460931255828159		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 1.0460931255828159 | validation: 0.805332098468166]
	TIME [epoch: 5.71 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0495743473376151		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 1.0495743473376151 | validation: 0.8307641159852571]
	TIME [epoch: 5.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0345920254210235		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 1.0345920254210235 | validation: 0.8161642979780465]
	TIME [epoch: 5.73 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0368527401228458		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 1.0368527401228458 | validation: 0.8087964567641368]
	TIME [epoch: 5.72 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0335189507229194		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 1.0335189507229194 | validation: 0.7901401897842945]
	TIME [epoch: 5.71 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0377454474943262		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 1.0377454474943262 | validation: 0.7965006660815327]
	TIME [epoch: 5.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0305309374208311		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 1.0305309374208311 | validation: 0.8014354306635716]
	TIME [epoch: 5.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066284927799734		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 1.066284927799734 | validation: 0.8155764765159365]
	TIME [epoch: 5.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056722189175351		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 1.056722189175351 | validation: 0.8168407730997647]
	TIME [epoch: 5.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.030504543007953		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 1.030504543007953 | validation: 0.8044974995372851]
	TIME [epoch: 5.75 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0317311681252934		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 1.0317311681252934 | validation: 0.7981519513069318]
	TIME [epoch: 5.71 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0352240019911227		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 1.0352240019911227 | validation: 0.8036473313110949]
	TIME [epoch: 5.71 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0352597832184443		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 1.0352597832184443 | validation: 0.7864122979800016]
	TIME [epoch: 5.71 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0373422275734363		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 1.0373422275734363 | validation: 0.7979748908893555]
	TIME [epoch: 5.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0480208478986741		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 1.0480208478986741 | validation: 0.7969368411183532]
	TIME [epoch: 5.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0381707135823575		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 1.0381707135823575 | validation: 0.784430276541209]
	TIME [epoch: 5.73 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0351882806867303		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 1.0351882806867303 | validation: 0.7879100726122381]
	TIME [epoch: 5.72 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0341812001800275		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 1.0341812001800275 | validation: 0.806423469121404]
	TIME [epoch: 5.71 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0570791749014612		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 1.0570791749014612 | validation: 0.7781662312245484]
	TIME [epoch: 5.71 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031798316602701		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 1.031798316602701 | validation: 0.8046094946806568]
	TIME [epoch: 5.71 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.039530089879434		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 1.039530089879434 | validation: 0.8038575373308895]
	TIME [epoch: 5.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0445116897639857		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 1.0445116897639857 | validation: 0.780683049415516]
	TIME [epoch: 5.71 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056717110980894		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 1.056717110980894 | validation: 0.7907953932476209]
	TIME [epoch: 5.75 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0328943358722866		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 1.0328943358722866 | validation: 0.8177977370417366]
	TIME [epoch: 5.71 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0525944623088308		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 1.0525944623088308 | validation: 0.8351743756543395]
	TIME [epoch: 5.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.047680182761156		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 1.047680182761156 | validation: 0.8116043942635173]
	TIME [epoch: 5.71 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0333323727043846		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 1.0333323727043846 | validation: 0.8371116245172076]
	TIME [epoch: 5.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.036034254619792		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 1.036034254619792 | validation: 0.803051779276457]
	TIME [epoch: 5.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025037960666776		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 1.025037960666776 | validation: 0.8104149533619587]
	TIME [epoch: 5.73 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0347396430357632		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 1.0347396430357632 | validation: 0.8513023298051826]
	TIME [epoch: 5.72 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04347375168602		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 1.04347375168602 | validation: 0.7913436287288026]
	TIME [epoch: 5.71 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.030388830725221		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 1.030388830725221 | validation: 0.788676263681206]
	TIME [epoch: 5.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589684438795364		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 1.0589684438795364 | validation: 0.809314773564106]
	TIME [epoch: 5.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0337054889711452		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 1.0337054889711452 | validation: 0.8145821348869374]
	TIME [epoch: 5.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0310234368276463		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 1.0310234368276463 | validation: 0.7904273613285006]
	TIME [epoch: 5.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0310728329822372		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 1.0310728329822372 | validation: 0.7930421184303748]
	TIME [epoch: 5.74 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0274440026391878		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 1.0274440026391878 | validation: 0.8281082674987116]
	TIME [epoch: 5.71 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0496235751132772		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 1.0496235751132772 | validation: 0.8073544972885012]
	TIME [epoch: 5.71 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0388998094225659		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 1.0388998094225659 | validation: 0.7853139074232423]
	TIME [epoch: 5.71 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0433850084235872		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 1.0433850084235872 | validation: 0.8327614210389862]
	TIME [epoch: 5.71 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0350737640533902		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 1.0350737640533902 | validation: 0.7665334309764219]
	TIME [epoch: 5.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0309483908487724		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 1.0309483908487724 | validation: 0.7983000626457044]
	TIME [epoch: 5.72 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0384605864704435		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 1.0384605864704435 | validation: 0.7918529768269861]
	TIME [epoch: 5.73 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0285623511905806		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 1.0285623511905806 | validation: 0.8085885875745917]
	TIME [epoch: 5.71 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0414390285899815		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 1.0414390285899815 | validation: 0.7709508637077696]
	TIME [epoch: 5.71 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0260909301316747		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 1.0260909301316747 | validation: 0.7944773246637696]
	TIME [epoch: 5.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0362372810647185		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 1.0362372810647185 | validation: 0.8005757657546004]
	TIME [epoch: 5.71 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053960494382299		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 1.053960494382299 | validation: 0.8307317784137933]
	TIME [epoch: 5.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.071330822808844		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 1.071330822808844 | validation: 0.7945818873491325]
	TIME [epoch: 5.74 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0326057850835568		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 1.0326057850835568 | validation: 0.7961596132155125]
	TIME [epoch: 5.71 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0403294149370659		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 1.0403294149370659 | validation: 0.807630533488719]
	TIME [epoch: 5.71 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.039445268423893		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 1.039445268423893 | validation: 0.7926746847419102]
	TIME [epoch: 5.7 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0438819934136956		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 1.0438819934136956 | validation: 0.8127371016187448]
	TIME [epoch: 5.71 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0353206747196464		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 1.0353206747196464 | validation: 0.8048986864032511]
	TIME [epoch: 5.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0563164246497916		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 1.0563164246497916 | validation: 0.777563535373001]
	TIME [epoch: 5.71 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0289421707703443		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 1.0289421707703443 | validation: 0.7866024925598346]
	TIME [epoch: 5.73 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0317242953464145		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 1.0317242953464145 | validation: 0.7865200305386943]
	TIME [epoch: 5.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0309095057007807		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 1.0309095057007807 | validation: 0.7788435835004889]
	TIME [epoch: 5.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033914044921837		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 1.033914044921837 | validation: 0.7836587970969103]
	TIME [epoch: 5.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.041697070980122		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 1.041697070980122 | validation: 0.8046681638240172]
	TIME [epoch: 5.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0465008379631882		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 1.0465008379631882 | validation: 0.7951358748919014]
	TIME [epoch: 5.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0531889116635664		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 1.0531889116635664 | validation: 0.8084357362370886]
	TIME [epoch: 5.74 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0394438632361904		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 1.0394438632361904 | validation: 0.8038050386403656]
	TIME [epoch: 5.71 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293698257729118		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 1.0293698257729118 | validation: 0.8265242122838012]
	TIME [epoch: 5.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0313326983925513		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 1.0313326983925513 | validation: 0.7876269597649295]
	TIME [epoch: 5.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0349004119054388		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 1.0349004119054388 | validation: 0.8035159287626623]
	TIME [epoch: 5.7 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0348857207897477		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 1.0348857207897477 | validation: 0.8081969687180464]
	TIME [epoch: 5.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032934887204354		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 1.032934887204354 | validation: 0.8196002029311389]
	TIME [epoch: 5.71 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606070058854755		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 1.0606070058854755 | validation: 0.8070024224228658]
	TIME [epoch: 5.74 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0295258734475439		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 1.0295258734475439 | validation: 0.7931822804521593]
	TIME [epoch: 5.71 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029493668784497		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 1.029493668784497 | validation: 0.7961889497285876]
	TIME [epoch: 5.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0335734676647934		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 1.0335734676647934 | validation: 0.7857525618108028]
	TIME [epoch: 5.7 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0320680905204578		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 1.0320680905204578 | validation: 0.808180398342249]
	TIME [epoch: 5.7 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0376532372755376		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 1.0376532372755376 | validation: 0.8449046979726116]
	TIME [epoch: 5.7 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033352720032533		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 1.033352720032533 | validation: 0.7887872119995742]
	TIME [epoch: 5.74 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0382335357977825		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 1.0382335357977825 | validation: 0.7954674602810451]
	TIME [epoch: 5.71 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.040997173738105		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 1.040997173738105 | validation: 0.7933208038391086]
	TIME [epoch: 5.7 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0321531443713967		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 1.0321531443713967 | validation: 0.8122791246808041]
	TIME [epoch: 5.7 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02934791505335		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 1.02934791505335 | validation: 0.7873351849401545]
	TIME [epoch: 5.7 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0315464052247971		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 1.0315464052247971 | validation: 0.8242512144785816]
	TIME [epoch: 5.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0438430132482852		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 1.0438430132482852 | validation: 0.843630928316002]
	TIME [epoch: 5.71 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033441980412614		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 1.033441980412614 | validation: 0.7870766484023761]
	TIME [epoch: 5.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0678730101574343		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 1.0678730101574343 | validation: 0.8023418074156734]
	TIME [epoch: 5.71 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0343459485867217		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 1.0343459485867217 | validation: 0.807212723912407]
	TIME [epoch: 5.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.043180870419003		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 1.043180870419003 | validation: 0.8025423710509598]
	TIME [epoch: 5.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033126259521356		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 1.033126259521356 | validation: 0.849544764032967]
	TIME [epoch: 5.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0469263507146271		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 1.0469263507146271 | validation: 0.7994374326524419]
	TIME [epoch: 5.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0286579753051317		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 1.0286579753051317 | validation: 0.8142966957358333]
	TIME [epoch: 5.74 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0264009458037526		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 1.0264009458037526 | validation: 0.7947214383090913]
	TIME [epoch: 5.71 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0322911848851175		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 1.0322911848851175 | validation: 0.8030957081739497]
	TIME [epoch: 5.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.044435213541714		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 1.044435213541714 | validation: 0.8032796894753331]
	TIME [epoch: 5.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.038352849329471		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 1.038352849329471 | validation: 0.7849091772182927]
	TIME [epoch: 5.7 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0319259836489303		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 1.0319259836489303 | validation: 0.7964710595766502]
	TIME [epoch: 5.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0398658101864189		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 1.0398658101864189 | validation: 0.7941748762791118]
	TIME [epoch: 5.71 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0308528458866413		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 1.0308528458866413 | validation: 0.8032915822996131]
	TIME [epoch: 5.74 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0287988502935432		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 1.0287988502935432 | validation: 0.8002927152157691]
	TIME [epoch: 5.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0237138158921744		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 1.0237138158921744 | validation: 0.7936761915037653]
	TIME [epoch: 5.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035080613532659		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 1.035080613532659 | validation: 0.7923604371550781]
	TIME [epoch: 5.7 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.044027510017118		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 1.044027510017118 | validation: 0.7947941069102086]
	TIME [epoch: 5.7 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033857396859949		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 1.033857396859949 | validation: 0.8311709117128884]
	TIME [epoch: 5.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0375548373126298		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 1.0375548373126298 | validation: 0.8197012280987448]
	TIME [epoch: 5.74 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0460996867268686		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 1.0460996867268686 | validation: 0.8089853405331076]
	TIME [epoch: 5.71 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035747968415399		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 1.035747968415399 | validation: 0.8128901040378845]
	TIME [epoch: 5.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0329274754407092		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 1.0329274754407092 | validation: 0.7918484163901762]
	TIME [epoch: 5.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.037317970432724		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 1.037317970432724 | validation: 0.7846878167568585]
	TIME [epoch: 5.7 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031972331571586		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 1.031972331571586 | validation: 0.8304297931624341]
	TIME [epoch: 5.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0361143164105524		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 1.0361143164105524 | validation: 0.8025017043304729]
	TIME [epoch: 5.71 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0295058581953596		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 1.0295058581953596 | validation: 0.8344345283056037]
	TIME [epoch: 5.73 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0280018303515297		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 1.0280018303515297 | validation: 0.793294667190647]
	TIME [epoch: 5.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0374183021232066		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 1.0374183021232066 | validation: 0.8093562884557634]
	TIME [epoch: 5.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0368614220795767		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 1.0368614220795767 | validation: 0.8012168599284405]
	TIME [epoch: 5.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0288876363008073		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 1.0288876363008073 | validation: 0.791309392754888]
	TIME [epoch: 5.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0307122317616502		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 1.0307122317616502 | validation: 0.8205925730554188]
	TIME [epoch: 5.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.037203767804325		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 1.037203767804325 | validation: 0.7962899468726555]
	TIME [epoch: 5.74 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026075465474677		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 1.026075465474677 | validation: 0.8098414096542718]
	TIME [epoch: 5.71 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0310731825455863		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 1.0310731825455863 | validation: 0.7852384088256368]
	TIME [epoch: 5.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0340193658193257		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 1.0340193658193257 | validation: 0.7881384724599564]
	TIME [epoch: 5.71 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0281064543100884		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 1.0281064543100884 | validation: 0.8047654524342562]
	TIME [epoch: 5.7 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0304501158107326		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 1.0304501158107326 | validation: 0.7858444770949526]
	TIME [epoch: 5.7 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0312755610634279		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 1.0312755610634279 | validation: 0.7972565418703192]
	TIME [epoch: 5.71 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.038736538436463		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 1.038736538436463 | validation: 0.7944337841348107]
	TIME [epoch: 5.74 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029583066171409		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 1.029583066171409 | validation: 0.8076647253670477]
	TIME [epoch: 5.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0466398602169318		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 1.0466398602169318 | validation: 0.8156105778465986]
	TIME [epoch: 5.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0296428799899144		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 1.0296428799899144 | validation: 0.7873987942203567]
	TIME [epoch: 5.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026457634719974		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 1.026457634719974 | validation: 0.7890198714069121]
	TIME [epoch: 5.7 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0327874593439361		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 1.0327874593439361 | validation: 0.7979883177141309]
	TIME [epoch: 5.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0470264337777535		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 1.0470264337777535 | validation: 0.8190911548617261]
	TIME [epoch: 5.74 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.034313330310881		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 1.034313330310881 | validation: 0.7941311568127251]
	TIME [epoch: 5.71 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253014996895873		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 1.0253014996895873 | validation: 0.802104485056766]
	TIME [epoch: 5.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0265575304735481		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 1.0265575304735481 | validation: 0.7924893616872086]
	TIME [epoch: 5.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0358659099893777		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 1.0358659099893777 | validation: 0.8046472371784641]
	TIME [epoch: 5.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031499797159855		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 1.031499797159855 | validation: 0.787608524789805]
	TIME [epoch: 5.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0285897022487271		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 1.0285897022487271 | validation: 0.7896015919296906]
	TIME [epoch: 5.71 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033332514141566		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 1.033332514141566 | validation: 0.7825574176229347]
	TIME [epoch: 5.73 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0252476469396283		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 1.0252476469396283 | validation: 0.799768463183566]
	TIME [epoch: 5.71 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0476360925302042		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 1.0476360925302042 | validation: 0.8277052817242043]
	TIME [epoch: 5.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0507264902381752		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 1.0507264902381752 | validation: 0.7760569165409033]
	TIME [epoch: 5.7 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0387889441416673		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 1.0387889441416673 | validation: 0.7864540017351042]
	TIME [epoch: 5.7 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033313713975863		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 1.033313713975863 | validation: 0.7788965565850181]
	TIME [epoch: 5.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0328817951994496		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 1.0328817951994496 | validation: 0.7858273613720858]
	TIME [epoch: 5.74 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0437854091404963		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 1.0437854091404963 | validation: 0.8029412703678511]
	TIME [epoch: 5.71 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.03771859496588		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 1.03771859496588 | validation: 0.7847901691016738]
	TIME [epoch: 5.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0317051019175243		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 1.0317051019175243 | validation: 0.7887404558180111]
	TIME [epoch: 5.7 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025880804700753		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 1.025880804700753 | validation: 0.7846711546627873]
	TIME [epoch: 5.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244549881482263		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 1.0244549881482263 | validation: 0.791003256542571]
	TIME [epoch: 5.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253293930491072		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 1.0253293930491072 | validation: 0.8125845080986659]
	TIME [epoch: 5.71 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0263011758403078		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 1.0263011758403078 | validation: 0.8038533919517238]
	TIME [epoch: 5.74 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0277350230424864		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 1.0277350230424864 | validation: 0.7770379252297912]
	TIME [epoch: 5.71 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0305498821202819		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 1.0305498821202819 | validation: 0.8089375791151153]
	TIME [epoch: 5.7 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0254860737698959		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 1.0254860737698959 | validation: 0.7828709813599233]
	TIME [epoch: 5.7 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0307165670538088		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 1.0307165670538088 | validation: 0.7932155367921934]
	TIME [epoch: 5.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0247435589831428		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 1.0247435589831428 | validation: 0.7796686792820947]
	TIME [epoch: 5.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02737666420172		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 1.02737666420172 | validation: 0.7908041162161195]
	TIME [epoch: 5.73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0272578078373436		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 1.0272578078373436 | validation: 0.7794973913675147]
	TIME [epoch: 5.72 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0275209434458885		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 1.0275209434458885 | validation: 0.7912120910435101]
	TIME [epoch: 5.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027843947411074		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 1.027843947411074 | validation: 0.7840247812693448]
	TIME [epoch: 5.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0266251963212123		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 1.0266251963212123 | validation: 0.8058490129302959]
	TIME [epoch: 5.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0273865906944872		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 1.0273865906944872 | validation: 0.7917550047330804]
	TIME [epoch: 5.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0266389399897198		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 1.0266389399897198 | validation: 0.7795563330404898]
	TIME [epoch: 5.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253297853528704		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 1.0253297853528704 | validation: 0.8077531744494713]
	TIME [epoch: 5.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.043992239546351		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 1.043992239546351 | validation: 0.8153675657764663]
	TIME [epoch: 5.71 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0319964225640696		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 1.0319964225640696 | validation: 0.7789427960368386]
	TIME [epoch: 5.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0322049497181154		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 1.0322049497181154 | validation: 0.7866301651931755]
	TIME [epoch: 5.7 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029665748900148		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 1.029665748900148 | validation: 0.7887439876689917]
	TIME [epoch: 5.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029190336780993		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 1.029190336780993 | validation: 0.8186278786669396]
	TIME [epoch: 5.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0409345864412587		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 1.0409345864412587 | validation: 0.8256566587278431]
	TIME [epoch: 5.73 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0381111727214147		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 1.0381111727214147 | validation: 0.8020390536298376]
	TIME [epoch: 5.71 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0287398197070219		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 1.0287398197070219 | validation: 0.8306452748992981]
	TIME [epoch: 5.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033603567916106		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 1.033603567916106 | validation: 0.7841517391516314]
	TIME [epoch: 5.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0275881101394568		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 1.0275881101394568 | validation: 0.7899803630531039]
	TIME [epoch: 5.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0309077513009024		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 1.0309077513009024 | validation: 0.81723641949639]
	TIME [epoch: 5.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0276531264388542		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 1.0276531264388542 | validation: 0.7893836535990087]
	TIME [epoch: 5.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0298943547866708		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 1.0298943547866708 | validation: 0.8273328473092145]
	TIME [epoch: 5.74 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0337016862553439		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 1.0337016862553439 | validation: 0.7877347777254857]
	TIME [epoch: 5.71 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0324718158674968		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 1.0324718158674968 | validation: 0.7969096808704503]
	TIME [epoch: 5.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0300247361801067		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 1.0300247361801067 | validation: 0.8013305952042756]
	TIME [epoch: 5.7 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0299235527210637		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 1.0299235527210637 | validation: 0.7918927717946841]
	TIME [epoch: 5.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032985380971747		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 1.032985380971747 | validation: 0.789940591360426]
	TIME [epoch: 5.7 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026344373618379		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 1.026344373618379 | validation: 0.7888538245433664]
	TIME [epoch: 5.72 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0318283262066208		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 1.0318283262066208 | validation: 0.8005429885255254]
	TIME [epoch: 5.72 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0380416828820578		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 1.0380416828820578 | validation: 0.834863050842357]
	TIME [epoch: 5.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0456473865427358		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 1.0456473865427358 | validation: 0.8120129555628708]
	TIME [epoch: 5.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0308614378694498		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 1.0308614378694498 | validation: 0.7840840367559702]
	TIME [epoch: 5.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245994141072394		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 1.0245994141072394 | validation: 0.7828605539277613]
	TIME [epoch: 5.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0418830904660812		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 1.0418830904660812 | validation: 0.7860677223264068]
	TIME [epoch: 5.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0305939000058757		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 1.0305939000058757 | validation: 0.7874008402290769]
	TIME [epoch: 5.74 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0283558552229537		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 1.0283558552229537 | validation: 0.7861954345950963]
	TIME [epoch: 5.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0289178802305647		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 1.0289178802305647 | validation: 0.783198517660117]
	TIME [epoch: 5.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0271645775421678		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 1.0271645775421678 | validation: 0.7907865632352354]
	TIME [epoch: 5.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0345190804868707		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 1.0345190804868707 | validation: 0.7877638668334922]
	TIME [epoch: 5.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250422344538435		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 1.0250422344538435 | validation: 0.785736871048743]
	TIME [epoch: 5.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239483277724648		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 1.0239483277724648 | validation: 0.7881395626126232]
	TIME [epoch: 5.73 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0241300809240825		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 1.0241300809240825 | validation: 0.7988178132065809]
	TIME [epoch: 5.72 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0423251486866194		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 1.0423251486866194 | validation: 0.8236380892687305]
	TIME [epoch: 5.71 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0467979764945645		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 1.0467979764945645 | validation: 0.7889574053526275]
	TIME [epoch: 5.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029039552403728		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 1.029039552403728 | validation: 0.7791072730396047]
	TIME [epoch: 5.7 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0304913654837444		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 1.0304913654837444 | validation: 0.7958840404012597]
	TIME [epoch: 5.7 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023953079015497		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 1.023953079015497 | validation: 0.7886359467767315]
	TIME [epoch: 5.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0309892429049248		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 1.0309892429049248 | validation: 0.7883872830620999]
	TIME [epoch: 5.74 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0297874852769482		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 1.0297874852769482 | validation: 0.776708338114463]
	TIME [epoch: 5.7 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0370935330336488		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 1.0370935330336488 | validation: 0.7896438031635805]
	TIME [epoch: 5.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0313961224964814		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 1.0313961224964814 | validation: 0.7760814571891362]
	TIME [epoch: 5.7 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0215964247863691		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 1.0215964247863691 | validation: 0.8079569078172881]
	TIME [epoch: 5.7 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0320301457912036		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 1.0320301457912036 | validation: 0.794108192675223]
	TIME [epoch: 5.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028211966866905		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 1.028211966866905 | validation: 0.7757108318551827]
	TIME [epoch: 5.73 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244824913550556		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 1.0244824913550556 | validation: 0.8019293796770075]
	TIME [epoch: 5.72 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0273862614726998		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 1.0273862614726998 | validation: 0.7794129247949566]
	TIME [epoch: 5.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0297968308744252		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 1.0297968308744252 | validation: 0.7868386036409118]
	TIME [epoch: 5.7 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023626149803411		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 1.023626149803411 | validation: 0.7811938537034061]
	TIME [epoch: 5.7 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0234973238660388		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 1.0234973238660388 | validation: 0.7955480921063136]
	TIME [epoch: 5.7 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027145310106874		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 1.027145310106874 | validation: 0.775170498281407]
	TIME [epoch: 5.7 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0270054030471765		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 1.0270054030471765 | validation: 0.7724606587214495]
	TIME [epoch: 5.75 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0233161408753775		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 1.0233161408753775 | validation: 0.7844252455778622]
	TIME [epoch: 5.7 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258790218236276		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 1.0258790218236276 | validation: 0.7806495465118615]
	TIME [epoch: 5.7 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0303137940217177		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 1.0303137940217177 | validation: 0.7951532709939255]
	TIME [epoch: 5.7 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0222912622795528		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 1.0222912622795528 | validation: 0.7745569424438071]
	TIME [epoch: 5.7 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0291837465224345		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 1.0291837465224345 | validation: 0.7913590046807714]
	TIME [epoch: 5.7 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026364705991201		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 1.026364705991201 | validation: 0.7972876401261465]
	TIME [epoch: 5.73 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0389003627600668		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 1.0389003627600668 | validation: 0.8113775615472812]
	TIME [epoch: 5.72 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0280255684946382		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 1.0280255684946382 | validation: 0.7934329931625894]
	TIME [epoch: 5.7 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293987601707268		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 1.0293987601707268 | validation: 0.8090820505522485]
	TIME [epoch: 5.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027310503180194		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 1.027310503180194 | validation: 0.7935578663502235]
	TIME [epoch: 5.7 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242657440725285		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 1.0242657440725285 | validation: 0.7946163052381102]
	TIME [epoch: 5.7 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033498870430808		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 1.033498870430808 | validation: 0.8011993055734377]
	TIME [epoch: 5.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623471540596863		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 1.0623471540596863 | validation: 0.7997211231858957]
	TIME [epoch: 5.75 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0291548748712127		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 1.0291548748712127 | validation: 0.7944104995435362]
	TIME [epoch: 5.71 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0243612511379567		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 1.0243612511379567 | validation: 0.7890865288174601]
	TIME [epoch: 5.7 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249515728745031		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 1.0249515728745031 | validation: 0.7899883082239356]
	TIME [epoch: 5.7 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0296166752305695		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 1.0296166752305695 | validation: 0.803763530710141]
	TIME [epoch: 5.7 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029332685260634		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 1.029332685260634 | validation: 0.7990038657082909]
	TIME [epoch: 5.7 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0263939994391533		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 1.0263939994391533 | validation: 0.7842073202351404]
	TIME [epoch: 5.72 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0303217894205217		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 1.0303217894205217 | validation: 0.8416227778903782]
	TIME [epoch: 5.72 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0447590475288913		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 1.0447590475288913 | validation: 0.798122923383614]
	TIME [epoch: 5.7 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028409197678606		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 1.028409197678606 | validation: 0.8064968419787739]
	TIME [epoch: 5.7 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244740800791043		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 1.0244740800791043 | validation: 0.7789541669769215]
	TIME [epoch: 5.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031538290670909		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 1.031538290670909 | validation: 0.8046538317149171]
	TIME [epoch: 5.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0341696075541378		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 1.0341696075541378 | validation: 0.8023233083653506]
	TIME [epoch: 5.7 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0257593274012147		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 1.0257593274012147 | validation: 0.7898876267973002]
	TIME [epoch: 5.74 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0284371837782766		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 1.0284371837782766 | validation: 0.8109884273344693]
	TIME [epoch: 5.7 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0241271975854016		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 1.0241271975854016 | validation: 0.7861555725987736]
	TIME [epoch: 5.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031258172914735		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 1.031258172914735 | validation: 0.8075607741491792]
	TIME [epoch: 5.7 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0247869434410872		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 1.0247869434410872 | validation: 0.8000889311591584]
	TIME [epoch: 5.7 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0353569134573901		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 1.0353569134573901 | validation: 0.8188615199516022]
	TIME [epoch: 5.7 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0304630176495762		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 1.0304630176495762 | validation: 0.7935436017125307]
	TIME [epoch: 5.73 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0271364077283518		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 1.0271364077283518 | validation: 0.8053915238524287]
	TIME [epoch: 5.72 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0256701653789846		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 1.0256701653789846 | validation: 0.803113647834451]
	TIME [epoch: 5.71 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0294043421693742		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 1.0294043421693742 | validation: 0.788202178870196]
	TIME [epoch: 5.71 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029485366438863		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 1.029485366438863 | validation: 0.7971784222418381]
	TIME [epoch: 5.7 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0318077496556353		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 1.0318077496556353 | validation: 0.7787743000473836]
	TIME [epoch: 5.7 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0275359855157515		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 1.0275359855157515 | validation: 0.7871541462077005]
	TIME [epoch: 5.7 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0272140019807694		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 1.0272140019807694 | validation: 0.8015803062721324]
	TIME [epoch: 5.74 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0316204815690408		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 1.0316204815690408 | validation: 0.8019549272461256]
	TIME [epoch: 5.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0313032501254065		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 1.0313032501254065 | validation: 0.7920866245304801]
	TIME [epoch: 5.7 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032046021282415		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 1.032046021282415 | validation: 0.7901950987679627]
	TIME [epoch: 5.7 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0343426154983106		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 1.0343426154983106 | validation: 0.7833876818092327]
	TIME [epoch: 5.7 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0220881236247392		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 1.0220881236247392 | validation: 0.7786128477477618]
	TIME [epoch: 5.7 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0264793303547886		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 1.0264793303547886 | validation: 0.8032280896854807]
	TIME [epoch: 5.73 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0494797151470494		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 1.0494797151470494 | validation: 0.7927518863651126]
	TIME [epoch: 5.72 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0436904954761572		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 1.0436904954761572 | validation: 0.7900929704754881]
	TIME [epoch: 5.7 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0355198341912792		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 1.0355198341912792 | validation: 0.8093158687365147]
	TIME [epoch: 5.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029675292630011		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 1.029675292630011 | validation: 0.7845463057648769]
	TIME [epoch: 5.7 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028781613251164		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 1.028781613251164 | validation: 0.793825702320147]
	TIME [epoch: 5.7 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0341285785733743		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 1.0341285785733743 | validation: 0.7882615708331565]
	TIME [epoch: 5.7 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035688457581583		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 1.035688457581583 | validation: 0.7902977782033394]
	TIME [epoch: 5.75 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0324420411576876		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 1.0324420411576876 | validation: 0.800674456567363]
	TIME [epoch: 5.71 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.040272209526752		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 1.040272209526752 | validation: 0.7984625938521422]
	TIME [epoch: 5.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268757855467092		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 1.0268757855467092 | validation: 0.7882047699643288]
	TIME [epoch: 5.71 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0284897852543728		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 1.0284897852543728 | validation: 0.8251049530179415]
	TIME [epoch: 5.7 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0466135402993604		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 1.0466135402993604 | validation: 0.8394963118257852]
	TIME [epoch: 5.7 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0486758486158076		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 1.0486758486158076 | validation: 0.8376776934109768]
	TIME [epoch: 5.73 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0360930012738354		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 1.0360930012738354 | validation: 0.7928140422376914]
	TIME [epoch: 5.72 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0264423468354258		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 1.0264423468354258 | validation: 0.7821210602082488]
	TIME [epoch: 5.7 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027118418157283		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 1.027118418157283 | validation: 0.7860328760200851]
	TIME [epoch: 5.7 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027760255051736		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 1.027760255051736 | validation: 0.782660593991377]
	TIME [epoch: 5.7 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0342479836833278		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 1.0342479836833278 | validation: 0.7880700978046481]
	TIME [epoch: 5.7 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236131736994112		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 1.0236131736994112 | validation: 0.7997365154220616]
	TIME [epoch: 5.7 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0279670869147142		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 1.0279670869147142 | validation: 0.7885390426971904]
	TIME [epoch: 5.74 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250374045774253		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 1.0250374045774253 | validation: 0.8025290723172148]
	TIME [epoch: 5.71 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029379587073614		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 1.029379587073614 | validation: 0.7972641825946284]
	TIME [epoch: 5.7 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027812733739716		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 1.027812733739716 | validation: 0.7818844235867184]
	TIME [epoch: 5.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025482979007193		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 1.025482979007193 | validation: 0.7937041936176253]
	TIME [epoch: 5.7 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226838573584354		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 1.0226838573584354 | validation: 0.7998983511200746]
	TIME [epoch: 5.7 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.030014429375111		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 1.030014429375111 | validation: 0.784462599184821]
	TIME [epoch: 5.72 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0311540637687298		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 1.0311540637687298 | validation: 0.7846708583902594]
	TIME [epoch: 5.72 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293652038982506		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 1.0293652038982506 | validation: 0.7827653800476404]
	TIME [epoch: 5.7 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027565746062503		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 1.027565746062503 | validation: 0.782086190479327]
	TIME [epoch: 5.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0256069573206732		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 1.0256069573206732 | validation: 0.7829134790387743]
	TIME [epoch: 5.7 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0316874232366189		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 1.0316874232366189 | validation: 0.7883873759166883]
	TIME [epoch: 5.7 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0287359739270971		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 1.0287359739270971 | validation: 0.7956610649407896]
	TIME [epoch: 5.7 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028772225082231		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 1.028772225082231 | validation: 0.7803729016024877]
	TIME [epoch: 5.74 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240169211010839		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 1.0240169211010839 | validation: 0.7841772617505061]
	TIME [epoch: 5.7 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0275778937788698		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 1.0275778937788698 | validation: 0.7797034397152647]
	TIME [epoch: 5.7 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0276133362296072		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 1.0276133362296072 | validation: 0.7953115868571763]
	TIME [epoch: 5.7 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026360911654229		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 1.026360911654229 | validation: 0.7889579667801155]
	TIME [epoch: 5.7 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250845597895981		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 1.0250845597895981 | validation: 0.7840235787706528]
	TIME [epoch: 5.7 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025260341107654		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 1.025260341107654 | validation: 0.7919136428808428]
	TIME [epoch: 5.73 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028525959920299		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 1.028525959920299 | validation: 0.7866818782083445]
	TIME [epoch: 5.72 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.036867708246443		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 1.036867708246443 | validation: 0.7799946239404361]
	TIME [epoch: 5.76 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0319896599560905		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 1.0319896599560905 | validation: 0.7821165023861054]
	TIME [epoch: 5.7 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0271533392358831		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 1.0271533392358831 | validation: 0.7891616661947874]
	TIME [epoch: 5.7 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032107654234741		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 1.032107654234741 | validation: 0.803915248720777]
	TIME [epoch: 5.7 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0347959512049798		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 1.0347959512049798 | validation: 0.8081150772986291]
	TIME [epoch: 5.7 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0325662198833736		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 1.0325662198833736 | validation: 0.7917553400091805]
	TIME [epoch: 5.75 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248555714489547		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 1.0248555714489547 | validation: 0.8003321373711171]
	TIME [epoch: 5.7 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268496015265918		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 1.0268496015265918 | validation: 0.7833925100314935]
	TIME [epoch: 5.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0251639786344007		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 1.0251639786344007 | validation: 0.7801147975162858]
	TIME [epoch: 5.7 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0352998615468312		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 1.0352998615468312 | validation: 0.7942213012832354]
	TIME [epoch: 5.7 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0360017200263627		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 1.0360017200263627 | validation: 0.7797241684957461]
	TIME [epoch: 5.7 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248273078485406		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 1.0248273078485406 | validation: 0.7889761375238188]
	TIME [epoch: 5.72 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0310341105119352		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 1.0310341105119352 | validation: 0.7840420692355161]
	TIME [epoch: 5.72 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028209413953481		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 1.028209413953481 | validation: 0.7762323393579422]
	TIME [epoch: 5.7 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0288729263309495		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 1.0288729263309495 | validation: 0.7935561332740403]
	TIME [epoch: 5.7 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0345171244732136		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 1.0345171244732136 | validation: 0.7790118766361286]
	TIME [epoch: 5.7 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024594648801769		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 1.024594648801769 | validation: 0.773258923253828]
	TIME [epoch: 5.7 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0297012751775512		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 1.0297012751775512 | validation: 0.7818214040753998]
	TIME [epoch: 5.7 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0338775472818738		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 1.0338775472818738 | validation: 0.7828327403674651]
	TIME [epoch: 5.75 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0300683620787079		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 1.0300683620787079 | validation: 0.7863482704772763]
	TIME [epoch: 5.71 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239946286367703		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 1.0239946286367703 | validation: 0.7972452176905518]
	TIME [epoch: 5.7 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026213456059013		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 1.026213456059013 | validation: 0.791854156792849]
	TIME [epoch: 5.7 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0307065514638756		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 1.0307065514638756 | validation: 0.7794609065065751]
	TIME [epoch: 5.7 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0260572082430155		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 1.0260572082430155 | validation: 0.7866606753749935]
	TIME [epoch: 5.7 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0205662597645517		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 1.0205662597645517 | validation: 0.7721117933636427]
	TIME [epoch: 5.73 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021706716576764		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 1.021706716576764 | validation: 0.7791409677892435]
	TIME [epoch: 5.72 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268714414229292		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 1.0268714414229292 | validation: 0.7967157621196791]
	TIME [epoch: 5.71 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027321130236043		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 1.027321130236043 | validation: 0.7812444886297246]
	TIME [epoch: 5.7 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0310688316935561		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 1.0310688316935561 | validation: 0.7808248004592921]
	TIME [epoch: 5.7 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.030057513296434		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 1.030057513296434 | validation: 0.7855179355208075]
	TIME [epoch: 5.7 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0303100588591816		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 1.0303100588591816 | validation: 0.7858234955386837]
	TIME [epoch: 5.7 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033356645847118		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 1.033356645847118 | validation: 0.7941976388569151]
	TIME [epoch: 5.74 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0290465156861832		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 1.0290465156861832 | validation: 0.7862935107766629]
	TIME [epoch: 5.71 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0275127386662457		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 1.0275127386662457 | validation: 0.7968439412937266]
	TIME [epoch: 5.7 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0266177525129099		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 1.0266177525129099 | validation: 0.7801659227527822]
	TIME [epoch: 5.7 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.030495222806386		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 1.030495222806386 | validation: 0.7741199352096491]
	TIME [epoch: 5.7 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0265402858653487		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 1.0265402858653487 | validation: 0.7823810294098281]
	TIME [epoch: 5.71 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0259774690059609		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 1.0259774690059609 | validation: 0.7865850613503992]
	TIME [epoch: 5.71 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022901999585906		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 1.022901999585906 | validation: 0.7870126714622456]
	TIME [epoch: 5.74 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033825182789826		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 1.033825182789826 | validation: 0.7858403216989607]
	TIME [epoch: 5.71 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0283488462478418		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 1.0283488462478418 | validation: 0.7848969289463039]
	TIME [epoch: 5.7 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0251238799870697		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 1.0251238799870697 | validation: 0.781443149888272]
	TIME [epoch: 5.7 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0225329124201346		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 1.0225329124201346 | validation: 0.771381735611441]
	TIME [epoch: 5.7 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0215167890931545		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 1.0215167890931545 | validation: 0.785386406292771]
	TIME [epoch: 5.7 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0261486778416786		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 1.0261486778416786 | validation: 0.778565890999293]
	TIME [epoch: 5.74 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025722839971346		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 1.025722839971346 | validation: 0.7879333126131418]
	TIME [epoch: 5.71 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0247887867616485		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 1.0247887867616485 | validation: 0.7838229220068498]
	TIME [epoch: 5.7 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0261301719953748		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 1.0261301719953748 | validation: 0.7817577760402162]
	TIME [epoch: 5.7 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245734811111402		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 1.0245734811111402 | validation: 0.7770061396182891]
	TIME [epoch: 5.7 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245952031818955		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 1.0245952031818955 | validation: 0.7754378372758666]
	TIME [epoch: 5.7 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240885673053137		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 1.0240885673053137 | validation: 0.7754022509041594]
	TIME [epoch: 5.71 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0220037440775633		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 1.0220037440775633 | validation: 0.7804257308516884]
	TIME [epoch: 5.73 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250092482663762		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 1.0250092482663762 | validation: 0.7849266663039666]
	TIME [epoch: 5.71 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0199816645407227		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 1.0199816645407227 | validation: 0.7942736456373077]
	TIME [epoch: 5.7 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0283252171129353		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 1.0283252171129353 | validation: 0.8120676283119455]
	TIME [epoch: 5.7 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0307448677277269		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 1.0307448677277269 | validation: 0.795452586019433]
	TIME [epoch: 5.7 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0299160380903425		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 1.0299160380903425 | validation: 0.786760139809825]
	TIME [epoch: 5.7 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028696459311381		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 1.028696459311381 | validation: 0.7664710952854847]
	TIME [epoch: 5.74 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223616516935428		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 1.0223616516935428 | validation: 0.7730483176061788]
	TIME [epoch: 5.71 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0302472625740415		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 1.0302472625740415 | validation: 0.7732492337092916]
	TIME [epoch: 5.7 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0255901733421604		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 1.0255901733421604 | validation: 0.7774879976549345]
	TIME [epoch: 5.7 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0292908176123834		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 1.0292908176123834 | validation: 0.8041820228330319]
	TIME [epoch: 5.7 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268869208627638		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 1.0268869208627638 | validation: 0.7772841401434663]
	TIME [epoch: 5.7 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0272146322273665		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 1.0272146322273665 | validation: 0.7808488596999489]
	TIME [epoch: 5.71 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028425689342571		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 1.028425689342571 | validation: 0.7723164699016667]
	TIME [epoch: 5.74 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0203341451748413		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 1.0203341451748413 | validation: 0.7948010776177502]
	TIME [epoch: 5.71 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0287475323530981		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 1.0287475323530981 | validation: 0.770127593050725]
	TIME [epoch: 5.7 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253128702695395		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 1.0253128702695395 | validation: 0.7877888694605062]
	TIME [epoch: 5.7 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031138422084492		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 1.031138422084492 | validation: 0.7814100698652559]
	TIME [epoch: 5.7 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024694970280828		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 1.024694970280828 | validation: 0.7945631961791065]
	TIME [epoch: 5.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031981954893439		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 1.031981954893439 | validation: 0.7986755538855548]
	TIME [epoch: 5.74 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0269265400971481		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 1.0269265400971481 | validation: 0.78373968788908]
	TIME [epoch: 5.71 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213416712976697		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 1.0213416712976697 | validation: 0.7815433396513823]
	TIME [epoch: 5.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021840430202011		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 1.021840430202011 | validation: 0.793059728825816]
	TIME [epoch: 5.7 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226702015618407		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 1.0226702015618407 | validation: 0.7870166940846712]
	TIME [epoch: 5.7 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0267553991211658		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 1.0267553991211658 | validation: 0.7894604686102509]
	TIME [epoch: 5.7 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0280652363784297		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 1.0280652363784297 | validation: 0.7893054012228519]
	TIME [epoch: 5.71 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027096505279149		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 1.027096505279149 | validation: 0.7802016984959683]
	TIME [epoch: 5.73 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0261526151939617		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 1.0261526151939617 | validation: 0.7847350719917744]
	TIME [epoch: 6.01 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0260421574469352		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 1.0260421574469352 | validation: 0.7839168677329792]
	TIME [epoch: 5.71 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0247168091616703		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 1.0247168091616703 | validation: 0.7838790484730592]
	TIME [epoch: 5.71 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0272748051043405		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 1.0272748051043405 | validation: 0.777919091157888]
	TIME [epoch: 5.71 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024375735039527		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 1.024375735039527 | validation: 0.7832478130741796]
	TIME [epoch: 5.71 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0259020154634564		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 1.0259020154634564 | validation: 0.7750517188612053]
	TIME [epoch: 5.75 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0265370682807493		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 1.0265370682807493 | validation: 0.7914920574117973]
	TIME [epoch: 5.7 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033889933064199		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 1.033889933064199 | validation: 0.7813663205337688]
	TIME [epoch: 5.71 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0256522601825002		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 1.0256522601825002 | validation: 0.7780688504695519]
	TIME [epoch: 5.71 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0285068006636529		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 1.0285068006636529 | validation: 0.777723707624888]
	TIME [epoch: 5.7 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0238692179114717		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 1.0238692179114717 | validation: 0.7864131939356441]
	TIME [epoch: 5.71 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0267604046429473		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 1.0267604046429473 | validation: 0.7786313179112234]
	TIME [epoch: 5.73 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0225153188830087		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 1.0225153188830087 | validation: 0.786919245089543]
	TIME [epoch: 5.72 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0315056753839416		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 1.0315056753839416 | validation: 0.8086616316556046]
	TIME [epoch: 5.71 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0350085843598817		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 1.0350085843598817 | validation: 0.8253548215682356]
	TIME [epoch: 5.7 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0371361946107		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 1.0371361946107 | validation: 0.803051845726732]
	TIME [epoch: 5.7 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0284999092867007		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 1.0284999092867007 | validation: 0.7906630914769338]
	TIME [epoch: 5.71 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242671634236014		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 1.0242671634236014 | validation: 0.7761287917728862]
	TIME [epoch: 5.71 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242698429690176		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 1.0242698429690176 | validation: 0.7826667578556966]
	TIME [epoch: 5.76 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248870048823286		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 1.0248870048823286 | validation: 0.7824223600924455]
	TIME [epoch: 5.71 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032848442228442		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 1.032848442228442 | validation: 0.7802855808702285]
	TIME [epoch: 5.71 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.034096411559722		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 1.034096411559722 | validation: 0.7809905112872367]
	TIME [epoch: 5.71 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0290532735658136		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 1.0290532735658136 | validation: 0.7821864179363931]
	TIME [epoch: 5.71 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242394911848294		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 1.0242394911848294 | validation: 0.7867841009603268]
	TIME [epoch: 5.7 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0275130400761028		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 1.0275130400761028 | validation: 0.7885716147608101]
	TIME [epoch: 5.73 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0259049477381035		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 1.0259049477381035 | validation: 0.7983800962467841]
	TIME [epoch: 5.72 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258462020904997		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 1.0258462020904997 | validation: 0.7921919593075462]
	TIME [epoch: 5.7 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0235005994464934		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 1.0235005994464934 | validation: 0.7926994363357807]
	TIME [epoch: 5.71 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0260634965110194		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 1.0260634965110194 | validation: 0.7840648462780577]
	TIME [epoch: 5.71 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0167905376059938		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 1.0167905376059938 | validation: 0.7790005531903174]
	TIME [epoch: 5.7 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244784807641896		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 1.0244784807641896 | validation: 0.7890498526065216]
	TIME [epoch: 5.71 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0234965280455146		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 1.0234965280455146 | validation: 0.781374939105298]
	TIME [epoch: 5.76 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0241403121327386		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 1.0241403121327386 | validation: 0.782497577226046]
	TIME [epoch: 5.71 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0204496424813794		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 1.0204496424813794 | validation: 0.7880181129035766]
	TIME [epoch: 5.7 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0190025642198248		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 1.0190025642198248 | validation: 0.7862983196374594]
	TIME [epoch: 5.7 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0230624909383097		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 1.0230624909383097 | validation: 0.7837199000198439]
	TIME [epoch: 5.7 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0254911768128467		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 1.0254911768128467 | validation: 0.7856217009578945]
	TIME [epoch: 5.71 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020510900858001		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 1.020510900858001 | validation: 0.7917674396050964]
	TIME [epoch: 5.74 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0318931630267236		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 1.0318931630267236 | validation: 0.8002233742664637]
	TIME [epoch: 5.73 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258076039224122		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 1.0258076039224122 | validation: 0.7785879165915531]
	TIME [epoch: 5.71 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0265634144728		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 1.0265634144728 | validation: 0.7812047177840188]
	TIME [epoch: 5.71 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0251853190010212		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 1.0251853190010212 | validation: 0.7758626716976733]
	TIME [epoch: 5.7 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0262903525808598		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 1.0262903525808598 | validation: 0.7766827139546588]
	TIME [epoch: 5.71 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0283448830684296		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 1.0283448830684296 | validation: 0.7784508799121551]
	TIME [epoch: 5.71 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0251824733674244		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 1.0251824733674244 | validation: 0.779811046919256]
	TIME [epoch: 5.76 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0233433774579501		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 1.0233433774579501 | validation: 0.7844346031748424]
	TIME [epoch: 5.72 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0353884017806902		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 1.0353884017806902 | validation: 0.7897968038685146]
	TIME [epoch: 5.72 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0359899021442942		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 1.0359899021442942 | validation: 0.78204608609917]
	TIME [epoch: 5.71 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0266246140775688		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 1.0266246140775688 | validation: 0.7859450679678357]
	TIME [epoch: 5.71 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0243132511167157		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 1.0243132511167157 | validation: 0.7783676254925901]
	TIME [epoch: 5.72 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026458655407767		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 1.026458655407767 | validation: 0.7714419045104023]
	TIME [epoch: 5.73 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0225062532108289		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 1.0225062532108289 | validation: 0.7763709171031199]
	TIME [epoch: 5.73 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240784503271043		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 1.0240784503271043 | validation: 0.7719674898961577]
	TIME [epoch: 5.71 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221229373268517		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 1.0221229373268517 | validation: 0.789112046953382]
	TIME [epoch: 5.71 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0327187486703158		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 1.0327187486703158 | validation: 0.7924124317954859]
	TIME [epoch: 5.71 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027939556003279		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 1.027939556003279 | validation: 0.7846109145195219]
	TIME [epoch: 5.71 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0269296592855668		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 1.0269296592855668 | validation: 0.7748708684536761]
	TIME [epoch: 5.72 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024183552931174		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 1.024183552931174 | validation: 0.7798858106223093]
	TIME [epoch: 5.76 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0243034504851725		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 1.0243034504851725 | validation: 0.7913114643316068]
	TIME [epoch: 5.72 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0296590891943098		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 1.0296590891943098 | validation: 0.7897003161798517]
	TIME [epoch: 5.72 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268946539159554		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 1.0268946539159554 | validation: 0.7958417951310621]
	TIME [epoch: 5.71 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0391494204360505		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 1.0391494204360505 | validation: 0.8036007876829602]
	TIME [epoch: 5.71 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0277728444113043		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 1.0277728444113043 | validation: 0.7978872981952492]
	TIME [epoch: 5.71 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0254418650321044		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 1.0254418650321044 | validation: 0.7875296766758478]
	TIME [epoch: 5.74 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0326840991438622		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 1.0326840991438622 | validation: 0.7833183325625876]
	TIME [epoch: 5.74 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242369483484475		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 1.0242369483484475 | validation: 0.791435423046758]
	TIME [epoch: 5.72 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0262421352425912		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 1.0262421352425912 | validation: 0.7758613110040605]
	TIME [epoch: 5.71 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0294474734021295		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 1.0294474734021295 | validation: 0.7842860967611196]
	TIME [epoch: 5.72 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0254685479221726		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 1.0254685479221726 | validation: 0.7894682517872021]
	TIME [epoch: 5.71 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0207127530976077		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 1.0207127530976077 | validation: 0.7804544840912517]
	TIME [epoch: 5.71 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0230148506533663		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 1.0230148506533663 | validation: 0.7829180365524675]
	TIME [epoch: 5.75 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0237523372168031		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 1.0237523372168031 | validation: 0.7950450786907177]
	TIME [epoch: 5.71 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0322515682727544		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 1.0322515682727544 | validation: 0.778392254886672]
	TIME [epoch: 5.71 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249268844239379		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 1.0249268844239379 | validation: 0.7784578471532738]
	TIME [epoch: 5.71 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02242110763611		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 1.02242110763611 | validation: 0.7869688287835066]
	TIME [epoch: 5.72 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022731287715885		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 1.022731287715885 | validation: 0.7898840781797714]
	TIME [epoch: 5.72 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0196820337975152		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 1.0196820337975152 | validation: 0.7833988013698852]
	TIME [epoch: 5.74 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0243878047405615		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 1.0243878047405615 | validation: 0.7821683902546418]
	TIME [epoch: 5.73 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0238604415987647		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 1.0238604415987647 | validation: 0.7829345962508794]
	TIME [epoch: 5.72 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023609399922432		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 1.023609399922432 | validation: 0.7822062138597403]
	TIME [epoch: 5.71 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0217031911105712		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 1.0217031911105712 | validation: 0.7865971821534453]
	TIME [epoch: 5.71 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0246718813219966		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 1.0246718813219966 | validation: 0.7894345061127606]
	TIME [epoch: 5.71 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024509989323765		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 1.024509989323765 | validation: 0.7851023457270051]
	TIME [epoch: 5.71 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0266130702864984		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 1.0266130702864984 | validation: 0.7955005622657908]
	TIME [epoch: 5.76 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0313514548320644		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 1.0313514548320644 | validation: 0.804185438505342]
	TIME [epoch: 5.72 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0286236720348092		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 1.0286236720348092 | validation: 0.7919647110658343]
	TIME [epoch: 5.72 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258436375128257		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 1.0258436375128257 | validation: 0.7831140346875571]
	TIME [epoch: 5.71 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02253291276979		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 1.02253291276979 | validation: 0.7782192201247421]
	TIME [epoch: 5.71 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0312933917212792		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 1.0312933917212792 | validation: 0.7793966148331655]
	TIME [epoch: 5.72 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0276158751792615		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 1.0276158751792615 | validation: 0.7795901554567756]
	TIME [epoch: 5.73 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0270776743953225		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 1.0270776743953225 | validation: 0.7804019274730754]
	TIME [epoch: 5.73 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021965881698277		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 1.021965881698277 | validation: 0.7824624175790262]
	TIME [epoch: 5.71 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0247905153475907		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 1.0247905153475907 | validation: 0.78177186499687]
	TIME [epoch: 5.71 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0234321723328756		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 1.0234321723328756 | validation: 0.7784088300105769]
	TIME [epoch: 5.71 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226863010886658		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 1.0226863010886658 | validation: 0.7833553772285052]
	TIME [epoch: 5.71 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023750023202496		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 1.023750023202496 | validation: 0.7844360411069685]
	TIME [epoch: 5.71 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021893509244053		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 1.021893509244053 | validation: 0.794586878703219]
	TIME [epoch: 5.76 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025192334271881		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 1.025192334271881 | validation: 0.7790298104886725]
	TIME [epoch: 5.71 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244022988632429		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 1.0244022988632429 | validation: 0.7881866094732576]
	TIME [epoch: 5.7 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0266299174858693		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 1.0266299174858693 | validation: 0.7957740792264681]
	TIME [epoch: 5.7 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0308601716618138		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 1.0308601716618138 | validation: 0.7778821498950345]
	TIME [epoch: 5.71 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0295819944582378		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 1.0295819944582378 | validation: 0.7998574490777388]
	TIME [epoch: 5.71 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268984968027843		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 1.0268984968027843 | validation: 0.7863210229753808]
	TIME [epoch: 5.74 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240141389907154		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 1.0240141389907154 | validation: 0.7892984582400048]
	TIME [epoch: 5.73 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0210461088933076		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 1.0210461088933076 | validation: 0.7874590045613024]
	TIME [epoch: 5.72 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0252395558962486		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 1.0252395558962486 | validation: 0.7910408997801531]
	TIME [epoch: 5.71 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023651169591302		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 1.023651169591302 | validation: 0.7830267318774032]
	TIME [epoch: 5.71 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02526354580187		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 1.02526354580187 | validation: 0.7851680134198609]
	TIME [epoch: 5.71 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0238674553865186		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 1.0238674553865186 | validation: 0.7900498546505934]
	TIME [epoch: 5.71 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0265871492992578		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 1.0265871492992578 | validation: 0.7819568441116224]
	TIME [epoch: 5.76 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0277819438119826		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 1.0277819438119826 | validation: 0.7743833585836355]
	TIME [epoch: 5.72 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025643834780945		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 1.025643834780945 | validation: 0.7798510351059764]
	TIME [epoch: 5.71 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248698542556884		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 1.0248698542556884 | validation: 0.7843767473207519]
	TIME [epoch: 5.71 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02533577129378		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 1.02533577129378 | validation: 0.7995237879713394]
	TIME [epoch: 5.71 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258913236368417		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 1.0258913236368417 | validation: 0.7895869376237766]
	TIME [epoch: 5.71 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223644179067215		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 1.0223644179067215 | validation: 0.7839171197264818]
	TIME [epoch: 5.74 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0265872049317715		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 1.0265872049317715 | validation: 0.791913254379851]
	TIME [epoch: 5.73 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022318943338102		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 1.022318943338102 | validation: 0.7832778299175834]
	TIME [epoch: 5.71 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0224837954116084		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 1.0224837954116084 | validation: 0.7865951109464411]
	TIME [epoch: 5.71 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0224966914389657		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 1.0224966914389657 | validation: 0.7929330449507208]
	TIME [epoch: 5.71 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249787944832813		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 1.0249787944832813 | validation: 0.7821369644035311]
	TIME [epoch: 5.72 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0246103182851107		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 1.0246103182851107 | validation: 0.7843139122393802]
	TIME [epoch: 5.71 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221264014081533		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 1.0221264014081533 | validation: 0.775089910250213]
	TIME [epoch: 5.76 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0203105536917207		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 1.0203105536917207 | validation: 0.783055659782029]
	TIME [epoch: 5.72 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025890623074863		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 1.025890623074863 | validation: 0.7863938639273457]
	TIME [epoch: 5.72 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02493052718368		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 1.02493052718368 | validation: 0.780050639001493]
	TIME [epoch: 5.71 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250649990610239		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 1.0250649990610239 | validation: 0.7836998734913805]
	TIME [epoch: 5.71 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02576023265918		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 1.02576023265918 | validation: 0.778328689121407]
	TIME [epoch: 5.71 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250733763393725		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 1.0250733763393725 | validation: 0.7861583356326558]
	TIME [epoch: 5.74 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0282407848666537		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 1.0282407848666537 | validation: 0.7903318575556517]
	TIME [epoch: 5.73 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248760831756014		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 1.0248760831756014 | validation: 0.7779854933203073]
	TIME [epoch: 5.71 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226668993818244		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 1.0226668993818244 | validation: 0.7949215992144065]
	TIME [epoch: 5.71 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023342519292204		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 1.023342519292204 | validation: 0.7860383077023926]
	TIME [epoch: 5.71 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253958353638484		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 1.0253958353638484 | validation: 0.7824050796833042]
	TIME [epoch: 5.71 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0289214284119028		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 1.0289214284119028 | validation: 0.7840298938186456]
	TIME [epoch: 5.71 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0238997089249144		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 1.0238997089249144 | validation: 0.7815781771088861]
	TIME [epoch: 5.75 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223619359087983		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 1.0223619359087983 | validation: 0.7836167077343354]
	TIME [epoch: 5.72 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239438673071488		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 1.0239438673071488 | validation: 0.7694530766854315]
	TIME [epoch: 5.72 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0202465203000695		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 1.0202465203000695 | validation: 0.7793320347939533]
	TIME [epoch: 5.71 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0273273498967832		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 1.0273273498967832 | validation: 0.7769988627229045]
	TIME [epoch: 5.71 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0286780289179822		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 1.0286780289179822 | validation: 0.7765624808269342]
	TIME [epoch: 5.71 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0280838435660495		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 1.0280838435660495 | validation: 0.7839209155584087]
	TIME [epoch: 5.73 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02631217996079		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 1.02631217996079 | validation: 0.7753533911022364]
	TIME [epoch: 5.72 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0281586075336422		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 1.0281586075336422 | validation: 0.7750382186089348]
	TIME [epoch: 5.71 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027598217867281		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 1.027598217867281 | validation: 0.7798578715952598]
	TIME [epoch: 5.71 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0264216483071362		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 1.0264216483071362 | validation: 0.7762167423432562]
	TIME [epoch: 5.71 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0264782842263944		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 1.0264782842263944 | validation: 0.7748851991494564]
	TIME [epoch: 5.71 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028095270221743		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 1.028095270221743 | validation: 0.7844426887727043]
	TIME [epoch: 5.71 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221051412197926		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 1.0221051412197926 | validation: 0.7820242178770053]
	TIME [epoch: 5.76 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0256516015872705		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 1.0256516015872705 | validation: 0.7785216616949486]
	TIME [epoch: 5.72 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0205561239794263		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 1.0205561239794263 | validation: 0.7684548733532939]
	TIME [epoch: 5.71 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0218316824582727		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 1.0218316824582727 | validation: 0.7668106026330483]
	TIME [epoch: 5.71 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249107349026985		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 1.0249107349026985 | validation: 0.7787197625000328]
	TIME [epoch: 5.7 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0232827285647605		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 1.0232827285647605 | validation: 0.7855630929559143]
	TIME [epoch: 5.71 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0279288883335571		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 1.0279288883335571 | validation: 0.7904480292061362]
	TIME [epoch: 5.74 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0291143232044935		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 1.0291143232044935 | validation: 0.8052081646468121]
	TIME [epoch: 5.73 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032266866170248		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 1.032266866170248 | validation: 0.7968478697048289]
	TIME [epoch: 5.71 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02998203784299		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 1.02998203784299 | validation: 0.781396097728699]
	TIME [epoch: 5.71 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0228029438051889		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 1.0228029438051889 | validation: 0.7796165310302987]
	TIME [epoch: 5.71 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0284430234846444		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 1.0284430234846444 | validation: 0.7715683378881477]
	TIME [epoch: 5.71 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0199520407549816		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 1.0199520407549816 | validation: 0.7816391529266555]
	TIME [epoch: 5.71 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0237293117744097		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 1.0237293117744097 | validation: 0.7768740978955836]
	TIME [epoch: 5.75 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019805038288543		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 1.019805038288543 | validation: 0.7740237849325798]
	TIME [epoch: 5.71 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253290126245915		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 1.0253290126245915 | validation: 0.7806699547554365]
	TIME [epoch: 5.71 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0254305571112485		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 1.0254305571112485 | validation: 0.7824425539212186]
	TIME [epoch: 5.71 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.018673932689161		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 1.018673932689161 | validation: 0.7822391880411393]
	TIME [epoch: 5.71 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0232000661343807		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 1.0232000661343807 | validation: 0.7779589015550497]
	TIME [epoch: 5.71 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0224258371340549		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 1.0224258371340549 | validation: 0.7744720913226882]
	TIME [epoch: 5.73 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020609490745624		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 1.020609490745624 | validation: 0.778209984828405]
	TIME [epoch: 5.72 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0259436329426974		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 1.0259436329426974 | validation: 0.7940224768221161]
	TIME [epoch: 5.71 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023646491096546		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 1.023646491096546 | validation: 0.788646243669057]
	TIME [epoch: 5.71 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221552606675586		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 1.0221552606675586 | validation: 0.7966553698821172]
	TIME [epoch: 5.71 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253635876793776		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 1.0253635876793776 | validation: 0.7893166281872983]
	TIME [epoch: 5.71 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025308756940449		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 1.025308756940449 | validation: 0.7801105043897176]
	TIME [epoch: 5.71 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236560442134754		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 1.0236560442134754 | validation: 0.7874984748487116]
	TIME [epoch: 5.76 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208550394644003		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 1.0208550394644003 | validation: 0.7764178315611276]
	TIME [epoch: 5.72 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0222625235547618		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 1.0222625235547618 | validation: 0.7845421769429455]
	TIME [epoch: 5.71 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239179013464834		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 1.0239179013464834 | validation: 0.7831850093718582]
	TIME [epoch: 5.71 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022406578075052		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 1.022406578075052 | validation: 0.7885549170243676]
	TIME [epoch: 5.7 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0207627527521757		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 1.0207627527521757 | validation: 0.7745336372172148]
	TIME [epoch: 5.7 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242418297275717		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 1.0242418297275717 | validation: 0.7856189809083697]
	TIME [epoch: 5.74 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0230378393556268		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 1.0230378393556268 | validation: 0.7925298103837021]
	TIME [epoch: 5.74 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0204394823593248		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 1.0204394823593248 | validation: 0.7797128237796102]
	TIME [epoch: 5.73 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023844935460951		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 1.023844935460951 | validation: 0.7678206640864859]
	TIME [epoch: 5.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02237148660916		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 1.02237148660916 | validation: 0.7750719620521761]
	TIME [epoch: 5.71 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022225782378582		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 1.022225782378582 | validation: 0.7997063146384277]
	TIME [epoch: 5.71 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0229979585748479		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 1.0229979585748479 | validation: 0.7868411951533725]
	TIME [epoch: 5.72 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0280737680814214		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 1.0280737680814214 | validation: 0.7805569508546739]
	TIME [epoch: 5.75 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239097353648239		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 1.0239097353648239 | validation: 0.7866592032575973]
	TIME [epoch: 5.71 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0290978890813045		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 1.0290978890813045 | validation: 0.7670329233279456]
	TIME [epoch: 5.71 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0252992721808525		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 1.0252992721808525 | validation: 0.775887305976207]
	TIME [epoch: 5.71 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029201436267718		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 1.029201436267718 | validation: 0.7644699234899958]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study201/model_tr_study201_r0_20240310_010407/states/model_tr_study201_1678.pth
	Model improved!!!
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0234738162613608		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 1.0234738162613608 | validation: 0.779444775797011]
	TIME [epoch: 5.71 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0237577904889035		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 1.0237577904889035 | validation: 0.7776118633473246]
	TIME [epoch: 5.74 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021102668491484		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 1.021102668491484 | validation: 0.7731354147482581]
	TIME [epoch: 5.71 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0206630101997751		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 1.0206630101997751 | validation: 0.77579467488066]
	TIME [epoch: 5.71 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021084421168458		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 1.021084421168458 | validation: 0.790841354182496]
	TIME [epoch: 5.71 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0288121277389966		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 1.0288121277389966 | validation: 0.7796086132799251]
	TIME [epoch: 5.7 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022517389810512		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 1.022517389810512 | validation: 0.775575502353337]
	TIME [epoch: 5.71 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022510722988652		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 1.022510722988652 | validation: 0.7818665181200605]
	TIME [epoch: 5.72 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268484138466203		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 1.0268484138466203 | validation: 0.7775883077186557]
	TIME [epoch: 5.74 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025627356817426		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 1.025627356817426 | validation: 0.7732372828384925]
	TIME [epoch: 5.72 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245578705679743		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 1.0245578705679743 | validation: 0.7743201316865513]
	TIME [epoch: 5.72 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0263326795973515		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 1.0263326795973515 | validation: 0.7708318645242597]
	TIME [epoch: 5.71 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226080279892233		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 1.0226080279892233 | validation: 0.7812631571273915]
	TIME [epoch: 5.71 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0209788783452844		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 1.0209788783452844 | validation: 0.7796035767210887]
	TIME [epoch: 5.71 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208087142821556		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 1.0208087142821556 | validation: 0.7794603862408351]
	TIME [epoch: 5.73 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0234768227871835		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 1.0234768227871835 | validation: 0.7763056795104814]
	TIME [epoch: 5.71 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236026972026426		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 1.0236026972026426 | validation: 0.7668332523336773]
	TIME [epoch: 5.7 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0279751412898603		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 1.0279751412898603 | validation: 0.7817167315625188]
	TIME [epoch: 5.7 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021696470877309		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 1.021696470877309 | validation: 0.7792054839972513]
	TIME [epoch: 5.71 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0271719315025563		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 1.0271719315025563 | validation: 0.7833767915736423]
	TIME [epoch: 5.71 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020388231533487		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 1.020388231533487 | validation: 0.7777308683114632]
	TIME [epoch: 5.71 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0203478022536645		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 1.0203478022536645 | validation: 0.7800135400574268]
	TIME [epoch: 5.74 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0218652633108316		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 1.0218652633108316 | validation: 0.7841032990345508]
	TIME [epoch: 5.71 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0212889504962996		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 1.0212889504962996 | validation: 0.7859532838789588]
	TIME [epoch: 5.72 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0218558061292582		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 1.0218558061292582 | validation: 0.7809417096233711]
	TIME [epoch: 5.7 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0207732756921784		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 1.0207732756921784 | validation: 0.7807566536054387]
	TIME [epoch: 5.7 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0229693154377861		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 1.0229693154377861 | validation: 0.7743738677151748]
	TIME [epoch: 5.7 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021950145656949		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 1.021950145656949 | validation: 0.7732899541075738]
	TIME [epoch: 5.74 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0211877432628684		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 1.0211877432628684 | validation: 0.7856312671027641]
	TIME [epoch: 5.71 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213377032347002		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 1.0213377032347002 | validation: 0.7878385892327916]
	TIME [epoch: 5.71 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0182911917916353		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 1.0182911917916353 | validation: 0.7831964319501838]
	TIME [epoch: 5.71 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02378257434427		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 1.02378257434427 | validation: 0.7726027018924233]
	TIME [epoch: 5.7 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021690441941174		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 1.021690441941174 | validation: 0.7795005348659997]
	TIME [epoch: 5.71 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0199250121637504		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 1.0199250121637504 | validation: 0.7715944186540326]
	TIME [epoch: 5.72 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.028068812906172		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 1.028068812906172 | validation: 0.7771808947387088]
	TIME [epoch: 5.74 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0257368104877373		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 1.0257368104877373 | validation: 0.7877760232238725]
	TIME [epoch: 5.7 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0235464710988489		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 1.0235464710988489 | validation: 0.7861107248005444]
	TIME [epoch: 5.7 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249055222714478		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 1.0249055222714478 | validation: 0.7877288933826893]
	TIME [epoch: 5.7 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231191140114		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 1.0231191140114 | validation: 0.7851617054326571]
	TIME [epoch: 5.71 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0190674894418366		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 1.0190674894418366 | validation: 0.7935897713959844]
	TIME [epoch: 5.7 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0204270603023196		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 1.0204270603023196 | validation: 0.7849632802314979]
	TIME [epoch: 5.74 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0254178943554277		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 1.0254178943554277 | validation: 0.7786972093399973]
	TIME [epoch: 5.72 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231820304531583		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 1.0231820304531583 | validation: 0.7788540109310819]
	TIME [epoch: 5.7 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0216446980771121		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 1.0216446980771121 | validation: 0.7747897628771042]
	TIME [epoch: 5.7 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0188740515135237		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 1.0188740515135237 | validation: 0.7747799002062167]
	TIME [epoch: 5.7 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021792253543199		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 1.021792253543199 | validation: 0.7813549075423162]
	TIME [epoch: 5.7 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0201220635803305		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 1.0201220635803305 | validation: 0.7883030181299192]
	TIME [epoch: 5.73 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0230985400199033		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 1.0230985400199033 | validation: 0.783158055783]
	TIME [epoch: 5.75 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02369234145991		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 1.02369234145991 | validation: 0.7756051500095564]
	TIME [epoch: 5.72 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0266572678856591		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 1.0266572678856591 | validation: 0.7709691407579973]
	TIME [epoch: 5.71 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0222735341936786		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 1.0222735341936786 | validation: 0.7779410286103241]
	TIME [epoch: 5.71 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0212150296104923		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 1.0212150296104923 | validation: 0.7924011569744894]
	TIME [epoch: 5.71 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0233451978340415		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 1.0233451978340415 | validation: 0.7827262164161192]
	TIME [epoch: 5.71 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239480156117593		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 1.0239480156117593 | validation: 0.7909000444548454]
	TIME [epoch: 5.74 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0225872747404519		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 1.0225872747404519 | validation: 0.7940475949420273]
	TIME [epoch: 5.72 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253647393062584		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 1.0253647393062584 | validation: 0.7988615440844603]
	TIME [epoch: 5.71 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0235773683318845		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 1.0235773683318845 | validation: 0.7961350125878669]
	TIME [epoch: 5.71 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024591306902071		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 1.024591306902071 | validation: 0.7973721259962844]
	TIME [epoch: 5.71 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221595385793565		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 1.0221595385793565 | validation: 0.7940553779121055]
	TIME [epoch: 5.71 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0243679174258886		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 1.0243679174258886 | validation: 0.7794940311916646]
	TIME [epoch: 5.71 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0209554423972982		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 1.0209554423972982 | validation: 0.7810167280720114]
	TIME [epoch: 5.74 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025185678059893		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 1.025185678059893 | validation: 0.7975434352247577]
	TIME [epoch: 5.71 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0190840067675178		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 1.0190840067675178 | validation: 0.7949127223957632]
	TIME [epoch: 5.71 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0228017646565073		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 1.0228017646565073 | validation: 0.7733698400231046]
	TIME [epoch: 5.71 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239886269681306		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 1.0239886269681306 | validation: 0.7879051376887878]
	TIME [epoch: 5.71 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02604115354852		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 1.02604115354852 | validation: 0.7886380181040846]
	TIME [epoch: 5.71 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0269021741210458		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 1.0269021741210458 | validation: 0.781408578615873]
	TIME [epoch: 5.74 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023935525640923		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 1.023935525640923 | validation: 0.7820879039805536]
	TIME [epoch: 5.71 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248036196863708		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 1.0248036196863708 | validation: 0.7898822329337538]
	TIME [epoch: 5.7 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024738490968639		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 1.024738490968639 | validation: 0.782478482550226]
	TIME [epoch: 5.7 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208208216022112		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 1.0208208216022112 | validation: 0.7859345902425046]
	TIME [epoch: 5.7 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02360091827799		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 1.02360091827799 | validation: 0.7821654470195529]
	TIME [epoch: 5.7 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0227471292556534		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 1.0227471292556534 | validation: 0.7839732427431076]
	TIME [epoch: 5.72 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0206778035519632		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 1.0206778035519632 | validation: 0.7807713996073458]
	TIME [epoch: 5.74 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0205979068653872		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 1.0205979068653872 | validation: 0.7875396092806254]
	TIME [epoch: 5.71 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236399611979772		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 1.0236399611979772 | validation: 0.7904648771413985]
	TIME [epoch: 5.71 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023963975380484		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 1.023963975380484 | validation: 0.7811612627278142]
	TIME [epoch: 5.71 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221066616354904		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 1.0221066616354904 | validation: 0.7884549246885834]
	TIME [epoch: 5.7 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223679055702977		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 1.0223679055702977 | validation: 0.7742338817760901]
	TIME [epoch: 5.7 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0216184278604306		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 1.0216184278604306 | validation: 0.7776984854082574]
	TIME [epoch: 5.74 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0275593784113846		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 1.0275593784113846 | validation: 0.795370726999959]
	TIME [epoch: 5.71 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236272187256907		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 1.0236272187256907 | validation: 0.7952144934244456]
	TIME [epoch: 5.7 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024288983126348		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 1.024288983126348 | validation: 0.790362625111564]
	TIME [epoch: 5.71 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025548492892948		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 1.025548492892948 | validation: 0.7887180235115434]
	TIME [epoch: 5.7 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0219366031260402		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 1.0219366031260402 | validation: 0.7867649824977813]
	TIME [epoch: 5.71 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0220016770215228		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 1.0220016770215228 | validation: 0.7730826766144072]
	TIME [epoch: 5.72 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0214799775165375		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 1.0214799775165375 | validation: 0.7959783073271942]
	TIME [epoch: 5.73 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0197487543452157		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 1.0197487543452157 | validation: 0.7815135888622945]
	TIME [epoch: 5.7 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208636213675801		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 1.0208636213675801 | validation: 0.7813695538641858]
	TIME [epoch: 5.7 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019280907253035		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 1.019280907253035 | validation: 0.7839942089082585]
	TIME [epoch: 5.7 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0204000802095479		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 1.0204000802095479 | validation: 0.7770014247022576]
	TIME [epoch: 5.7 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231388076421426		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 1.0231388076421426 | validation: 0.7724668061979719]
	TIME [epoch: 5.71 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249092164850504		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 1.0249092164850504 | validation: 0.7797184656254593]
	TIME [epoch: 5.74 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239552902335138		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 1.0239552902335138 | validation: 0.7889682233094039]
	TIME [epoch: 5.71 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253348689554105		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 1.0253348689554105 | validation: 0.7812447274989373]
	TIME [epoch: 5.7 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0243675633900091		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 1.0243675633900091 | validation: 0.7816235720678938]
	TIME [epoch: 5.7 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248404076888944		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 1.0248404076888944 | validation: 0.7931891235199621]
	TIME [epoch: 5.7 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242426852827564		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 1.0242426852827564 | validation: 0.7882626674877031]
	TIME [epoch: 5.7 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226001437036456		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 1.0226001437036456 | validation: 0.7787632509608372]
	TIME [epoch: 5.71 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245289202491183		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 1.0245289202491183 | validation: 0.7769316175820098]
	TIME [epoch: 5.73 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025445790900547		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 1.025445790900547 | validation: 0.7828894842271563]
	TIME [epoch: 5.71 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0277714357243437		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 1.0277714357243437 | validation: 0.7792247057857339]
	TIME [epoch: 5.71 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021970335341071		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 1.021970335341071 | validation: 0.7820044263273954]
	TIME [epoch: 5.7 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0220575454463852		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 1.0220575454463852 | validation: 0.7810503239995649]
	TIME [epoch: 5.7 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022035898672742		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 1.022035898672742 | validation: 0.7776077615644762]
	TIME [epoch: 5.7 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208722506479426		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 1.0208722506479426 | validation: 0.7815890036821759]
	TIME [epoch: 5.74 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231145858214223		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 1.0231145858214223 | validation: 0.7790301526627471]
	TIME [epoch: 5.7 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0228108908559828		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 1.0228108908559828 | validation: 0.7830914759976946]
	TIME [epoch: 5.7 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0207356543231216		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 1.0207356543231216 | validation: 0.7829864245284739]
	TIME [epoch: 5.7 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0209704250874443		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 1.0209704250874443 | validation: 0.7826674010888127]
	TIME [epoch: 5.7 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0198164937884422		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 1.0198164937884422 | validation: 0.7710439369963777]
	TIME [epoch: 5.7 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221247807499847		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 1.0221247807499847 | validation: 0.7768698900769132]
	TIME [epoch: 5.71 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0228924185878603		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 1.0228924185878603 | validation: 0.792087635270307]
	TIME [epoch: 5.73 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0212890129317842		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 1.0212890129317842 | validation: 0.780123216648009]
	TIME [epoch: 5.71 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021498051792121		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 1.021498051792121 | validation: 0.7815914675541841]
	TIME [epoch: 5.71 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0238865729165796		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 1.0238865729165796 | validation: 0.7803604878829724]
	TIME [epoch: 5.7 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02096536782411		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 1.02096536782411 | validation: 0.7831113049123585]
	TIME [epoch: 5.7 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0227318641762793		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 1.0227318641762793 | validation: 0.7860845479008464]
	TIME [epoch: 5.7 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0200988333181151		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 1.0200988333181151 | validation: 0.7833943753481133]
	TIME [epoch: 5.74 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242699977472012		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 1.0242699977472012 | validation: 0.7779997876760472]
	TIME [epoch: 5.71 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0215235634829538		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 1.0215235634829538 | validation: 0.7830526987981946]
	TIME [epoch: 5.7 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025680750437063		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 1.025680750437063 | validation: 0.781633562603221]
	TIME [epoch: 5.7 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.017982220749663		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 1.017982220749663 | validation: 0.7772043176091924]
	TIME [epoch: 5.7 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0233556497787513		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 1.0233556497787513 | validation: 0.7780328107157308]
	TIME [epoch: 5.7 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0218703386014498		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 1.0218703386014498 | validation: 0.7764975641116613]
	TIME [epoch: 5.71 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019261314031913		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 1.019261314031913 | validation: 0.7769248802020228]
	TIME [epoch: 5.73 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245596392990173		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 1.0245596392990173 | validation: 0.7731456408631192]
	TIME [epoch: 5.7 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024055817406909		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 1.024055817406909 | validation: 0.776080011695142]
	TIME [epoch: 5.7 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023247246575935		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 1.023247246575935 | validation: 0.781826436329255]
	TIME [epoch: 5.7 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253901484906374		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 1.0253901484906374 | validation: 0.7810910364079209]
	TIME [epoch: 5.7 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0222404649532437		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 1.0222404649532437 | validation: 0.7821648508252858]
	TIME [epoch: 5.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0211004248435152		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 1.0211004248435152 | validation: 0.7815881934767487]
	TIME [epoch: 5.74 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0205249268588013		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 1.0205249268588013 | validation: 0.7774673478547289]
	TIME [epoch: 5.71 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0194658204943956		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 1.0194658204943956 | validation: 0.7802520086724388]
	TIME [epoch: 5.7 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0229897605254663		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 1.0229897605254663 | validation: 0.7775038429001748]
	TIME [epoch: 5.7 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020562829785812		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 1.020562829785812 | validation: 0.7861923424249312]
	TIME [epoch: 5.7 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231536606551241		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 1.0231536606551241 | validation: 0.7767284692193206]
	TIME [epoch: 5.7 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0214393884976039		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 1.0214393884976039 | validation: 0.7824846378000906]
	TIME [epoch: 5.71 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0260021680686637		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 1.0260021680686637 | validation: 0.7821582065011705]
	TIME [epoch: 5.73 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0241557314145608		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 1.0241557314145608 | validation: 0.7872029785884711]
	TIME [epoch: 5.71 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0184834791782889		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 1.0184834791782889 | validation: 0.772941522749478]
	TIME [epoch: 5.7 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236476441504023		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 1.0236476441504023 | validation: 0.7749266709573073]
	TIME [epoch: 5.7 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226304804237418		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 1.0226304804237418 | validation: 0.7843037169148706]
	TIME [epoch: 5.7 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0188951322942086		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 1.0188951322942086 | validation: 0.7911101890930208]
	TIME [epoch: 5.7 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0216341802072393		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 1.0216341802072393 | validation: 0.784411038871582]
	TIME [epoch: 5.73 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0222767275245037		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 1.0222767275245037 | validation: 0.7799079528169398]
	TIME [epoch: 5.7 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024963686619568		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 1.024963686619568 | validation: 0.7759416776190172]
	TIME [epoch: 5.7 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0225563020832167		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 1.0225563020832167 | validation: 0.7742774775813022]
	TIME [epoch: 5.7 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0252306883102393		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 1.0252306883102393 | validation: 0.7761487334059173]
	TIME [epoch: 5.7 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249564757668361		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 1.0249564757668361 | validation: 0.7801564987045412]
	TIME [epoch: 5.71 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0211803176498242		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 1.0211803176498242 | validation: 0.7785526248202516]
	TIME [epoch: 5.71 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0253181391350066		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 1.0253181391350066 | validation: 0.7771419381224689]
	TIME [epoch: 5.73 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022682972864154		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 1.022682972864154 | validation: 0.776443656456629]
	TIME [epoch: 5.71 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0205523877589666		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 1.0205523877589666 | validation: 0.7825444808214249]
	TIME [epoch: 5.71 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0218609251661281		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 1.0218609251661281 | validation: 0.7804402092059243]
	TIME [epoch: 5.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0191977825613867		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 1.0191977825613867 | validation: 0.7862793791802752]
	TIME [epoch: 5.7 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0211233699601618		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 1.0211233699601618 | validation: 0.7794707779775649]
	TIME [epoch: 5.7 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0212066365007155		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 1.0212066365007155 | validation: 0.7850498014405805]
	TIME [epoch: 5.74 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023104006891725		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 1.023104006891725 | validation: 0.7843263326568638]
	TIME [epoch: 5.71 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0190724193972187		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 1.0190724193972187 | validation: 0.7829525266441296]
	TIME [epoch: 5.7 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208190815323346		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 1.0208190815323346 | validation: 0.7904677331384358]
	TIME [epoch: 5.71 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0268036130598095		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 1.0268036130598095 | validation: 0.7927807880922042]
	TIME [epoch: 5.71 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0235755537519242		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 1.0235755537519242 | validation: 0.7857545832714129]
	TIME [epoch: 5.7 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244319086124483		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 1.0244319086124483 | validation: 0.7856831732786099]
	TIME [epoch: 5.71 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019774351908668		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 1.019774351908668 | validation: 0.7870021563342913]
	TIME [epoch: 5.73 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0238168350898196		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 1.0238168350898196 | validation: 0.778886499152423]
	TIME [epoch: 5.7 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223686371706175		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 1.0223686371706175 | validation: 0.7821768515287171]
	TIME [epoch: 5.71 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024130327338157		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 1.024130327338157 | validation: 0.783429404530102]
	TIME [epoch: 5.7 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0243501103285282		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 1.0243501103285282 | validation: 0.7830675253244218]
	TIME [epoch: 5.71 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025033878531227		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 1.025033878531227 | validation: 0.7856846872393439]
	TIME [epoch: 5.7 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023188773175738		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 1.023188773175738 | validation: 0.7934606652304046]
	TIME [epoch: 5.74 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0251828274651082		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 1.0251828274651082 | validation: 0.7941862328078901]
	TIME [epoch: 5.71 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022819873209052		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 1.022819873209052 | validation: 0.783167224278036]
	TIME [epoch: 5.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258264032441093		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 1.0258264032441093 | validation: 0.7825474415866052]
	TIME [epoch: 5.7 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023731786711254		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 1.023731786711254 | validation: 0.7784594266417574]
	TIME [epoch: 5.7 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239558880596173		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 1.0239558880596173 | validation: 0.77931523241823]
	TIME [epoch: 5.7 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242129899007988		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 1.0242129899007988 | validation: 0.7762985464545858]
	TIME [epoch: 5.71 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0212058679875178		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 1.0212058679875178 | validation: 0.7815359641865263]
	TIME [epoch: 5.73 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221966144912313		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 1.0221966144912313 | validation: 0.776611246906477]
	TIME [epoch: 5.71 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0192531258476165		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 1.0192531258476165 | validation: 0.7803513726390082]
	TIME [epoch: 5.7 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0238244256450468		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 1.0238244256450468 | validation: 0.7773289932708025]
	TIME [epoch: 5.7 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.027270964523256		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 1.027270964523256 | validation: 0.7834789516444564]
	TIME [epoch: 5.7 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022063227055111		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 1.022063227055111 | validation: 0.7762112332977357]
	TIME [epoch: 5.7 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022485760105714		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 1.022485760105714 | validation: 0.7797271376971655]
	TIME [epoch: 5.73 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240018975081393		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 1.0240018975081393 | validation: 0.7785224175950949]
	TIME [epoch: 5.7 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0247649731859407		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 1.0247649731859407 | validation: 0.7812354009304656]
	TIME [epoch: 5.7 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020830469841964		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 1.020830469841964 | validation: 0.780149600229924]
	TIME [epoch: 5.7 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0243123929930693		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 1.0243123929930693 | validation: 0.7832873351107824]
	TIME [epoch: 5.7 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226448388756741		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 1.0226448388756741 | validation: 0.7944277455389355]
	TIME [epoch: 5.7 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0212157205327925		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 1.0212157205327925 | validation: 0.7751832902818871]
	TIME [epoch: 5.71 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0243815333420085		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 1.0243815333420085 | validation: 0.7665690525983007]
	TIME [epoch: 5.73 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0266366775821458		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 1.0266366775821458 | validation: 0.7800177127537171]
	TIME [epoch: 5.71 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223220896604621		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 1.0223220896604621 | validation: 0.7822815660293497]
	TIME [epoch: 5.7 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0204717749899503		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 1.0204717749899503 | validation: 0.7815361987591607]
	TIME [epoch: 5.7 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221743701471313		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 1.0221743701471313 | validation: 0.777763988134959]
	TIME [epoch: 5.7 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208467967109704		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 1.0208467967109704 | validation: 0.7812603390106193]
	TIME [epoch: 5.7 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0251565793924835		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 1.0251565793924835 | validation: 0.7775408597495279]
	TIME [epoch: 5.74 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0217011970935215		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 1.0217011970935215 | validation: 0.7753517338863429]
	TIME [epoch: 5.71 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021366143004903		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 1.021366143004903 | validation: 0.7774062030825616]
	TIME [epoch: 5.71 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023599589721161		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 1.023599589721161 | validation: 0.7835802390141442]
	TIME [epoch: 5.71 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023543231712394		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 1.023543231712394 | validation: 0.7789976137175376]
	TIME [epoch: 5.71 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0182512223320566		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 1.0182512223320566 | validation: 0.7752923156727318]
	TIME [epoch: 5.71 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022541180202804		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 1.022541180202804 | validation: 0.781694526227912]
	TIME [epoch: 5.71 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213300653530484		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 1.0213300653530484 | validation: 0.7860518477336043]
	TIME [epoch: 5.73 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0226080833004465		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 1.0226080833004465 | validation: 0.7833911246177985]
	TIME [epoch: 5.7 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021371081646408		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 1.021371081646408 | validation: 0.7790647396720553]
	TIME [epoch: 5.7 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0228137412215326		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 1.0228137412215326 | validation: 0.786762949393319]
	TIME [epoch: 5.7 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0193341643636018		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 1.0193341643636018 | validation: 0.7818697002714342]
	TIME [epoch: 5.7 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0205553889701955		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 1.0205553889701955 | validation: 0.7749094672153248]
	TIME [epoch: 5.7 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0228366548468697		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 1.0228366548468697 | validation: 0.7753649439727707]
	TIME [epoch: 5.74 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221652521700113		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 1.0221652521700113 | validation: 0.7787256213625692]
	TIME [epoch: 5.7 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0216371887972608		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 1.0216371887972608 | validation: 0.7843089081051429]
	TIME [epoch: 5.7 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0198137949243367		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 1.0198137949243367 | validation: 0.7787613773988952]
	TIME [epoch: 5.7 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021499866526891		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 1.021499866526891 | validation: 0.7877019469686241]
	TIME [epoch: 5.7 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0199389335057452		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 1.0199389335057452 | validation: 0.7837127050512472]
	TIME [epoch: 5.7 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0211839544930355		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 1.0211839544930355 | validation: 0.7812538801759824]
	TIME [epoch: 5.73 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019251352683537		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 1.019251352683537 | validation: 0.7866778574545632]
	TIME [epoch: 5.72 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249026788771662		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 1.0249026788771662 | validation: 0.7747935047214697]
	TIME [epoch: 5.7 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0237775758637322		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 1.0237775758637322 | validation: 0.7794331283999655]
	TIME [epoch: 5.7 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0233229862675497		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 1.0233229862675497 | validation: 0.7765895317727797]
	TIME [epoch: 5.7 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0238072001349376		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 1.0238072001349376 | validation: 0.7875187166035292]
	TIME [epoch: 5.7 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0259733374657716		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 1.0259733374657716 | validation: 0.7880716062057803]
	TIME [epoch: 5.7 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0248690526316016		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 1.0248690526316016 | validation: 0.7717605544166114]
	TIME [epoch: 5.74 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213512330301449		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 1.0213512330301449 | validation: 0.7901998417992507]
	TIME [epoch: 5.7 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0204921170172474		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 1.0204921170172474 | validation: 0.7828766239387437]
	TIME [epoch: 5.7 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024321776580822		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 1.024321776580822 | validation: 0.7869191562139543]
	TIME [epoch: 5.7 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0200814152935815		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 1.0200814152935815 | validation: 0.7779317209318082]
	TIME [epoch: 5.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213751080204387		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 1.0213751080204387 | validation: 0.7774354268940917]
	TIME [epoch: 5.7 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231117663121398		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 1.0231117663121398 | validation: 0.7819895436230868]
	TIME [epoch: 5.72 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0214883118412477		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 1.0214883118412477 | validation: 0.7856033780321345]
	TIME [epoch: 5.72 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0273407216843555		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 1.0273407216843555 | validation: 0.7824064897754486]
	TIME [epoch: 5.7 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0254235571278123		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 1.0254235571278123 | validation: 0.7807651001857336]
	TIME [epoch: 5.7 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0216957912392095		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 1.0216957912392095 | validation: 0.7809027217460554]
	TIME [epoch: 5.7 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0260032020762933		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 1.0260032020762933 | validation: 0.7745235580857918]
	TIME [epoch: 5.7 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023378423548437		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 1.023378423548437 | validation: 0.7718336191522494]
	TIME [epoch: 5.7 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0229029393298958		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 1.0229029393298958 | validation: 0.7843998419264648]
	TIME [epoch: 5.74 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02547983895103		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 1.02547983895103 | validation: 0.7745868381360017]
	TIME [epoch: 5.71 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022391324424384		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 1.022391324424384 | validation: 0.7796873972675644]
	TIME [epoch: 5.7 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231672546252943		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 1.0231672546252943 | validation: 0.7709385321639155]
	TIME [epoch: 5.7 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0261939514911402		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 1.0261939514911402 | validation: 0.7860979762200059]
	TIME [epoch: 5.7 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0179583119032234		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 1.0179583119032234 | validation: 0.7929696981438281]
	TIME [epoch: 5.7 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0262550670476078		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 1.0262550670476078 | validation: 0.7756080314396598]
	TIME [epoch: 5.73 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021246640917832		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 1.021246640917832 | validation: 0.7896595747929817]
	TIME [epoch: 5.71 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022436165212961		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 1.022436165212961 | validation: 0.7905468484386375]
	TIME [epoch: 5.7 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213737575590387		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 1.0213737575590387 | validation: 0.7809196226282807]
	TIME [epoch: 5.7 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022292562648427		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 1.022292562648427 | validation: 0.7855001114611301]
	TIME [epoch: 5.7 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022513679963889		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 1.022513679963889 | validation: 0.7775907585074614]
	TIME [epoch: 5.7 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0231725428125897		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 1.0231725428125897 | validation: 0.7771301379553259]
	TIME [epoch: 5.7 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250588561453309		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 1.0250588561453309 | validation: 0.784972235379613]
	TIME [epoch: 5.74 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221673552482538		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 1.0221673552482538 | validation: 0.7911276956850819]
	TIME [epoch: 5.7 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0246046320908648		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 1.0246046320908648 | validation: 0.7727370538731514]
	TIME [epoch: 5.7 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021273824703143		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 1.021273824703143 | validation: 0.7840218338826767]
	TIME [epoch: 5.7 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.018035163942648		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 1.018035163942648 | validation: 0.7891530862719861]
	TIME [epoch: 5.7 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025145699013465		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 1.025145699013465 | validation: 0.7855719289163346]
	TIME [epoch: 5.7 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0195646338331907		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 1.0195646338331907 | validation: 0.7819681415146522]
	TIME [epoch: 5.72 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0209951296321191		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 1.0209951296321191 | validation: 0.7739407546778949]
	TIME [epoch: 5.71 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213772346893015		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 1.0213772346893015 | validation: 0.7728468856672465]
	TIME [epoch: 5.71 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0236433518942234		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 1.0236433518942234 | validation: 0.7842509604603426]
	TIME [epoch: 5.7 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221116454052652		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 1.0221116454052652 | validation: 0.7839001323327323]
	TIME [epoch: 5.7 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020731438023697		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 1.020731438023697 | validation: 0.7893387659170571]
	TIME [epoch: 5.7 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0176709903446075		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 1.0176709903446075 | validation: 0.784402024067906]
	TIME [epoch: 5.7 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021283171901971		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 1.021283171901971 | validation: 0.7833708887966941]
	TIME [epoch: 5.74 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0187022742571008		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 1.0187022742571008 | validation: 0.7753274343387804]
	TIME [epoch: 5.7 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0220529096096396		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 1.0220529096096396 | validation: 0.7842684192712948]
	TIME [epoch: 5.7 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0184763216115784		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 1.0184763216115784 | validation: 0.7839409446198624]
	TIME [epoch: 5.7 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0241328742264282		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 1.0241328742264282 | validation: 0.785339381966117]
	TIME [epoch: 5.7 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0216034065454864		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 1.0216034065454864 | validation: 0.7812434131020412]
	TIME [epoch: 5.7 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.017796838034054		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 1.017796838034054 | validation: 0.7822154101545402]
	TIME [epoch: 5.72 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0205214545539354		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 1.0205214545539354 | validation: 0.7722791762110086]
	TIME [epoch: 5.72 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239390887140711		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 1.0239390887140711 | validation: 0.7764932844774746]
	TIME [epoch: 5.7 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0194624252313649		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 1.0194624252313649 | validation: 0.7954396550645296]
	TIME [epoch: 5.7 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0206904591619637		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 1.0206904591619637 | validation: 0.7666981851930436]
	TIME [epoch: 5.7 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223327222414789		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 1.0223327222414789 | validation: 0.7870568075669385]
	TIME [epoch: 5.7 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024120041218638		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 1.024120041218638 | validation: 0.7874864498256582]
	TIME [epoch: 5.7 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0223761085263017		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 1.0223761085263017 | validation: 0.798652607984607]
	TIME [epoch: 5.74 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0246812168227644		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 1.0246812168227644 | validation: 0.784035720437753]
	TIME [epoch: 5.71 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0229633991450364		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 1.0229633991450364 | validation: 0.7892964561216212]
	TIME [epoch: 5.7 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0203506518471908		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 1.0203506518471908 | validation: 0.7950804673054187]
	TIME [epoch: 5.7 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0232641770777713		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 1.0232641770777713 | validation: 0.7914151289674596]
	TIME [epoch: 5.7 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0299866130562836		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 1.0299866130562836 | validation: 0.7982238878615203]
	TIME [epoch: 5.7 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0270182549325897		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 1.0270182549325897 | validation: 0.7927357733816298]
	TIME [epoch: 5.72 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024655024549596		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 1.024655024549596 | validation: 0.7922289426641982]
	TIME [epoch: 5.72 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0234191077307322		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 1.0234191077307322 | validation: 0.7940104219304388]
	TIME [epoch: 5.7 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213542146425594		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 1.0213542146425594 | validation: 0.7894772050406321]
	TIME [epoch: 5.7 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0230993031185966		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 1.0230993031185966 | validation: 0.7847705867677829]
	TIME [epoch: 5.7 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249106473477934		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 1.0249106473477934 | validation: 0.7768045770688541]
	TIME [epoch: 5.7 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023492656003056		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 1.023492656003056 | validation: 0.787297203194654]
	TIME [epoch: 5.7 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0216003468370831		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 1.0216003468370831 | validation: 0.7883532855032275]
	TIME [epoch: 5.74 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258014135309435		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 1.0258014135309435 | validation: 0.787769768280649]
	TIME [epoch: 5.7 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221404023643073		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 1.0221404023643073 | validation: 0.7887305587346813]
	TIME [epoch: 5.71 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213338758225003		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 1.0213338758225003 | validation: 0.7820042222990401]
	TIME [epoch: 5.7 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0230532238243044		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 1.0230532238243044 | validation: 0.7791589198795843]
	TIME [epoch: 5.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020894335028365		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 1.020894335028365 | validation: 0.7962547434042104]
	TIME [epoch: 5.7 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0202530983425449		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 1.0202530983425449 | validation: 0.7886395887797688]
	TIME [epoch: 5.73 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0230411463405884		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 1.0230411463405884 | validation: 0.7895927933575044]
	TIME [epoch: 5.72 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022222128195527		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 1.022222128195527 | validation: 0.7899389318236424]
	TIME [epoch: 5.71 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0233903316985316		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 1.0233903316985316 | validation: 0.7895553744444663]
	TIME [epoch: 5.7 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0241868548179314		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 1.0241868548179314 | validation: 0.7903266784763627]
	TIME [epoch: 5.7 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0214031022110912		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 1.0214031022110912 | validation: 0.7848057902439355]
	TIME [epoch: 5.7 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0263330145854708		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 1.0263330145854708 | validation: 0.7919311651181202]
	TIME [epoch: 5.7 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250187836469329		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 1.0250187836469329 | validation: 0.7882705337072051]
	TIME [epoch: 5.74 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0232655399293362		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 1.0232655399293362 | validation: 0.7851816147834351]
	TIME [epoch: 5.71 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0219832818019603		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 1.0219832818019603 | validation: 0.7873751224876585]
	TIME [epoch: 5.7 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0200018191608766		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 1.0200018191608766 | validation: 0.7868435270620441]
	TIME [epoch: 5.7 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0186080315816526		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 1.0186080315816526 | validation: 0.787175239512914]
	TIME [epoch: 5.7 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208449837972227		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 1.0208449837972227 | validation: 0.7887230861044404]
	TIME [epoch: 5.7 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02329524175711		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 1.02329524175711 | validation: 0.7741654585182254]
	TIME [epoch: 5.72 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023813441499924		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 1.023813441499924 | validation: 0.7822292110756784]
	TIME [epoch: 5.72 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0198945418351486		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 1.0198945418351486 | validation: 0.7856394750348312]
	TIME [epoch: 5.7 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0199162651205653		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 1.0199162651205653 | validation: 0.7841296481902146]
	TIME [epoch: 5.7 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0197951052075211		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 1.0197951052075211 | validation: 0.7828183090264057]
	TIME [epoch: 5.7 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022792450733866		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 1.022792450733866 | validation: 0.7893583409864323]
	TIME [epoch: 5.7 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245483975252498		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 1.0245483975252498 | validation: 0.7735882603548148]
	TIME [epoch: 5.7 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024985696920446		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 1.024985696920446 | validation: 0.7769048614788062]
	TIME [epoch: 5.74 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0193020079569437		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 1.0193020079569437 | validation: 0.789149998834052]
	TIME [epoch: 5.71 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0225995008650954		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 1.0225995008650954 | validation: 0.7783838302166644]
	TIME [epoch: 5.7 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020473599268525		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 1.020473599268525 | validation: 0.7810052126701428]
	TIME [epoch: 5.7 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0190320426285808		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 1.0190320426285808 | validation: 0.7715453022828538]
	TIME [epoch: 5.7 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0230992240805836		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 1.0230992240805836 | validation: 0.7809805142781595]
	TIME [epoch: 5.7 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0188362320151767		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 1.0188362320151767 | validation: 0.7737490865946708]
	TIME [epoch: 5.72 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0277365700716676		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 1.0277365700716676 | validation: 0.779226682845042]
	TIME [epoch: 5.71 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0219435332370983		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 1.0219435332370983 | validation: 0.7821040679489204]
	TIME [epoch: 5.71 sec]
Finished training in 11623.684 seconds.
