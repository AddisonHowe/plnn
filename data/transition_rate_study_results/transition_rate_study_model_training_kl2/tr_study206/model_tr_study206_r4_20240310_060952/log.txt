Args:
Namespace(name='model_tr_study206', outdir='out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4', training_data='data/transition_rate_studies/tr_study206/tr_study206_training/r4', validation_data='data/transition_rate_studies/tr_study206/tr_study206_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1690187789

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.24171053153689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.24171053153689 | validation: 10.706983697038675]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.932843797514508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.932843797514508 | validation: 12.196150663783083]
	TIME [epoch: 25 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.93882771517991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.93882771517991 | validation: 11.014980968898968]
	TIME [epoch: 24.9 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.835029016290232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.835029016290232 | validation: 10.054585566657641]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.99140307242445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.99140307242445 | validation: 8.985485236095528]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.46424454685098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.46424454685098 | validation: 9.203476618591198]
	TIME [epoch: 24.9 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.516389662696865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.516389662696865 | validation: 8.020787340763226]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.28675158083344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.28675158083344 | validation: 6.473299804396791]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.415890533871934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.415890533871934 | validation: 8.542856365706168]
	TIME [epoch: 25 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.046336138106649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.046336138106649 | validation: 5.987928042736751]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.99494500869105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.99494500869105 | validation: 6.2357828625041645]
	TIME [epoch: 25 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.900900423031723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.900900423031723 | validation: 5.788678957953291]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.68420056178809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.68420056178809 | validation: 5.991237833865443]
	TIME [epoch: 25 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.855545600016265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.855545600016265 | validation: 5.805712189878261]
	TIME [epoch: 25 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.672179552075065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.672179552075065 | validation: 5.46553365894372]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.706477024983199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.706477024983199 | validation: 5.487025739092978]
	TIME [epoch: 25 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6200376281457665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6200376281457665 | validation: 5.448547683558535]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.680390053509824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.680390053509824 | validation: 5.449829607956647]
	TIME [epoch: 24.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.531193105270256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.531193105270256 | validation: 5.961183284973536]
	TIME [epoch: 25.2 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.768903677973416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.768903677973416 | validation: 5.662161285315412]
	TIME [epoch: 25 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4336057687074355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4336057687074355 | validation: 5.592861743780627]
	TIME [epoch: 25 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.556188401967804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.556188401967804 | validation: 5.333393145320411]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.610170487937731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.610170487937731 | validation: 5.621472369020906]
	TIME [epoch: 25 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.391219779620213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.391219779620213 | validation: 5.345964190924746]
	TIME [epoch: 25 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.350679921839822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.350679921839822 | validation: 5.762584670588247]
	TIME [epoch: 25 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.540788936447498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.540788936447498 | validation: 5.539245202802411]
	TIME [epoch: 25 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.38897963334812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.38897963334812 | validation: 5.802915489858378]
	TIME [epoch: 25 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.721472073390673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.721472073390673 | validation: 5.420245405422008]
	TIME [epoch: 25 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.33316431378625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.33316431378625 | validation: 5.32738853093403]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.778459660987935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.778459660987935 | validation: 5.957023086272911]
	TIME [epoch: 25 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.454101525527298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.454101525527298 | validation: 5.288139774605315]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.291654321786343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.291654321786343 | validation: 5.2471028062702185]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.382745102182914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.382745102182914 | validation: 5.7696863946145776]
	TIME [epoch: 25 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.28380484919167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.28380484919167 | validation: 5.171395975016733]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.262917249934427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.262917249934427 | validation: 5.308099563798063]
	TIME [epoch: 25 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.211936890532277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.211936890532277 | validation: 5.120781902879828]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.478465069315474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.478465069315474 | validation: 5.2022537774739295]
	TIME [epoch: 25 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.235174385658983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.235174385658983 | validation: 5.3561090002712]
	TIME [epoch: 25 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.249868812482081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.249868812482081 | validation: 5.170383074267213]
	TIME [epoch: 25 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.306412154102916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.306412154102916 | validation: 5.122076846293436]
	TIME [epoch: 25 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.066629769678775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.066629769678775 | validation: 5.488948549390043]
	TIME [epoch: 25 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.333717098122996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.333717098122996 | validation: 5.375380897108191]
	TIME [epoch: 25 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.311796222466662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.311796222466662 | validation: 5.139888824322606]
	TIME [epoch: 25 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.26449918151773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.26449918151773 | validation: 5.1215435066723884]
	TIME [epoch: 25 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.079143917610227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.079143917610227 | validation: 5.113134073810443]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.032797251880749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.032797251880749 | validation: 5.695154108603601]
	TIME [epoch: 25 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.507107039151308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.507107039151308 | validation: 5.463439924903936]
	TIME [epoch: 25 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.139422635400129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.139422635400129 | validation: 5.053623166471065]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2399072287225685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2399072287225685 | validation: 5.184075792788489]
	TIME [epoch: 25 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.249154073366315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.249154073366315 | validation: 5.053784764186674]
	TIME [epoch: 24.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.205356148410711		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.205356148410711 | validation: 5.206346129614308]
	TIME [epoch: 25 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1512477000108285		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.1512477000108285 | validation: 5.36510451267918]
	TIME [epoch: 25 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.203883171516843		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.203883171516843 | validation: 5.11731179926577]
	TIME [epoch: 24.9 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.021953725403336		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.021953725403336 | validation: 5.099283215975525]
	TIME [epoch: 25 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.175800002531555		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.175800002531555 | validation: 5.219685239572833]
	TIME [epoch: 25 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.132473391517942		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.132473391517942 | validation: 5.017185601387815]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.022371593158614		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.022371593158614 | validation: 4.977707605205699]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.973991278970808		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.973991278970808 | validation: 5.98535406558616]
	TIME [epoch: 25 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.226152830349832		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.226152830349832 | validation: 5.233129651001043]
	TIME [epoch: 25 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.169157752373476		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.169157752373476 | validation: 5.371272808670745]
	TIME [epoch: 25 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.357255718198989		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.357255718198989 | validation: 5.047299559366498]
	TIME [epoch: 24.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.990474826171003		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.990474826171003 | validation: 5.01342862983317]
	TIME [epoch: 25 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.955269599652738		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.955269599652738 | validation: 4.974034388865483]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.16266231679948		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.16266231679948 | validation: 5.165633819099457]
	TIME [epoch: 25 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.083962361452395		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.083962361452395 | validation: 5.412877060516461]
	TIME [epoch: 25 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.044316239154758		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.044316239154758 | validation: 5.147428341421899]
	TIME [epoch: 25 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.067385765605822		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 5.067385765605822 | validation: 4.952153712012102]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.958017500625918		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.958017500625918 | validation: 5.109401080087406]
	TIME [epoch: 25 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.942450509966268		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.942450509966268 | validation: 5.02501225290923]
	TIME [epoch: 25 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.00669341715845		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.00669341715845 | validation: 5.279527770189759]
	TIME [epoch: 25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.132110744759506		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 5.132110744759506 | validation: 5.141195278030564]
	TIME [epoch: 25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.014607455594006		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 5.014607455594006 | validation: 5.08047853681929]
	TIME [epoch: 25 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.956411853007856		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.956411853007856 | validation: 5.47570448160828]
	TIME [epoch: 25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.172860323803423		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 5.172860323803423 | validation: 4.959302315319736]
	TIME [epoch: 25 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.981633667380782		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.981633667380782 | validation: 4.957428789080066]
	TIME [epoch: 25 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.016225075018948		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 5.016225075018948 | validation: 5.1007917924787245]
	TIME [epoch: 25 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.981483585712349		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.981483585712349 | validation: 5.042536764981451]
	TIME [epoch: 25 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.947211590449618		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.947211590449618 | validation: 4.9025339216975246]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.964224383092904		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.964224383092904 | validation: 4.924660911021914]
	TIME [epoch: 25 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.049598593123091		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 5.049598593123091 | validation: 4.905225505926616]
	TIME [epoch: 25 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.865110822260764		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.865110822260764 | validation: 5.160415694897064]
	TIME [epoch: 25 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.997547619698194		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.997547619698194 | validation: 4.9534342715963]
	TIME [epoch: 25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.970538603316821		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.970538603316821 | validation: 4.9228260151883125]
	TIME [epoch: 25 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.975823545594879		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.975823545594879 | validation: 5.100441660536277]
	TIME [epoch: 25 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.904333212466087		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.904333212466087 | validation: 4.94523611227037]
	TIME [epoch: 25 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.974464010779501		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.974464010779501 | validation: 5.245832947009671]
	TIME [epoch: 25 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.952704612528375		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.952704612528375 | validation: 4.842035140707194]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.887519128030934		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.887519128030934 | validation: 5.109291911337659]
	TIME [epoch: 25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.056261879064668		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 5.056261879064668 | validation: 4.885047345066141]
	TIME [epoch: 25 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.936498564985763		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.936498564985763 | validation: 4.930250400774031]
	TIME [epoch: 24.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.898016006767929		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.898016006767929 | validation: 4.899326458986529]
	TIME [epoch: 25 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.875762325764454		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.875762325764454 | validation: 5.13662967649394]
	TIME [epoch: 25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.972907883643005		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.972907883643005 | validation: 5.147426824722787]
	TIME [epoch: 25 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.941392192274052		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.941392192274052 | validation: 4.954814198623559]
	TIME [epoch: 25 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.888042035809214		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.888042035809214 | validation: 4.96614031889164]
	TIME [epoch: 25 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.907311553966333		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.907311553966333 | validation: 4.955682813251867]
	TIME [epoch: 24.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.974446646486673		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.974446646486673 | validation: 4.999180434670353]
	TIME [epoch: 25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9039795175494305		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 4.9039795175494305 | validation: 4.964373985591682]
	TIME [epoch: 25 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.989871593674339		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 4.989871593674339 | validation: 4.941446667594146]
	TIME [epoch: 25 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.952845982106169		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.952845982106169 | validation: 4.978086702310937]
	TIME [epoch: 25 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.878796125220829		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 4.878796125220829 | validation: 5.022447108992592]
	TIME [epoch: 25 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.880315587092859		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.880315587092859 | validation: 4.930968901916162]
	TIME [epoch: 24.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8806803234545235		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.8806803234545235 | validation: 5.271201057364919]
	TIME [epoch: 25 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.064522844577118		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 5.064522844577118 | validation: 4.850488523003313]
	TIME [epoch: 25 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.826951335160882		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 4.826951335160882 | validation: 4.933987693733702]
	TIME [epoch: 24.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.842040465746759		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.842040465746759 | validation: 4.951849896922984]
	TIME [epoch: 25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.900490540133392		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 4.900490540133392 | validation: 4.854413564333778]
	TIME [epoch: 25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.897468369053144		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.897468369053144 | validation: 5.025620927321933]
	TIME [epoch: 24.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8833155121229925		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.8833155121229925 | validation: 4.8753235572818925]
	TIME [epoch: 25 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.916305952178181		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 4.916305952178181 | validation: 4.850253157811447]
	TIME [epoch: 25 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.847368689078869		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 4.847368689078869 | validation: 4.973474277618688]
	TIME [epoch: 24.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.866746180713214		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 4.866746180713214 | validation: 4.961349989881236]
	TIME [epoch: 25 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.918933277405959		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 4.918933277405959 | validation: 4.829531736615417]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.879253301986138		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.879253301986138 | validation: 4.909911054887762]
	TIME [epoch: 24.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8360587235528545		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.8360587235528545 | validation: 5.084597656256916]
	TIME [epoch: 24.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.907620227741403		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.907620227741403 | validation: 4.909383522827599]
	TIME [epoch: 25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.86558503833051		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.86558503833051 | validation: 4.862284778540254]
	TIME [epoch: 24.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.865495068341695		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 4.865495068341695 | validation: 5.153670632796489]
	TIME [epoch: 25 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.934294585014587		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.934294585014587 | validation: 4.981732804877011]
	TIME [epoch: 25 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.83333704956391		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 4.83333704956391 | validation: 4.834268520679378]
	TIME [epoch: 25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.767249932720107		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 4.767249932720107 | validation: 4.937119071950664]
	TIME [epoch: 25 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.925608627556079		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.925608627556079 | validation: 4.994473035813171]
	TIME [epoch: 25 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.876394352789578		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 4.876394352789578 | validation: 4.820453127607229]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7974139377014415		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 4.7974139377014415 | validation: 5.129386976165545]
	TIME [epoch: 24.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.92192230647578		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.92192230647578 | validation: 4.828982397538014]
	TIME [epoch: 25 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.799980424932095		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.799980424932095 | validation: 4.924064671100372]
	TIME [epoch: 25 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.182161674962462		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 5.182161674962462 | validation: 5.613471668279902]
	TIME [epoch: 24.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.095849132583225		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 5.095849132583225 | validation: 4.888416092030311]
	TIME [epoch: 25 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.803990367220572		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.803990367220572 | validation: 4.867972268394309]
	TIME [epoch: 25 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8429060291318144		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.8429060291318144 | validation: 4.941417010646391]
	TIME [epoch: 25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.815406732797856		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 4.815406732797856 | validation: 4.883204768095198]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.785561464312435		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 4.785561464312435 | validation: 4.917762520338887]
	TIME [epoch: 25 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.807662955764936		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.807662955764936 | validation: 4.972009564278875]
	TIME [epoch: 25 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.877563312623657		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.877563312623657 | validation: 4.772540839188947]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7994902902173076		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 4.7994902902173076 | validation: 4.889848972402994]
	TIME [epoch: 25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7652570178502405		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 4.7652570178502405 | validation: 4.795738878025886]
	TIME [epoch: 25 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.784279595788189		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 4.784279595788189 | validation: 5.105867515052346]
	TIME [epoch: 25 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.904540640326409		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 4.904540640326409 | validation: 4.782353529559379]
	TIME [epoch: 24.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.76601559471257		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 4.76601559471257 | validation: 4.839263373978762]
	TIME [epoch: 25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.805998053226143		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 4.805998053226143 | validation: 4.761691603755093]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.981326953562697		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 4.981326953562697 | validation: 4.722265129989922]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8012462773976194		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 4.8012462773976194 | validation: 4.895796395105849]
	TIME [epoch: 25 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.771565407024446		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 4.771565407024446 | validation: 4.799056875802263]
	TIME [epoch: 25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8229080932524955		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 4.8229080932524955 | validation: 4.75171694121283]
	TIME [epoch: 25 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.798834011688292		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 4.798834011688292 | validation: 4.821720336690763]
	TIME [epoch: 24.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.831304259903457		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 4.831304259903457 | validation: 4.96940928433824]
	TIME [epoch: 25 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.825409446586202		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 4.825409446586202 | validation: 4.757181896325181]
	TIME [epoch: 25 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.769714565019606		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 4.769714565019606 | validation: 4.86940417532808]
	TIME [epoch: 25 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.779683045995968		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 4.779683045995968 | validation: 4.7946761440956776]
	TIME [epoch: 24.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.729304418214895		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 4.729304418214895 | validation: 4.710173950132807]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.945397429742947		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 4.945397429742947 | validation: 4.851398697616577]
	TIME [epoch: 25 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.828200929601372		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 4.828200929601372 | validation: 4.745446464683799]
	TIME [epoch: 24.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.782097548371857		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 4.782097548371857 | validation: 4.853908975190402]
	TIME [epoch: 24.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.849505625074621		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 4.849505625074621 | validation: 4.942775679004594]
	TIME [epoch: 25 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.859484086320405		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 4.859484086320405 | validation: 4.711790814199496]
	TIME [epoch: 25 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.788044767708469		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 4.788044767708469 | validation: 4.764228187791043]
	TIME [epoch: 24.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.785748954034182		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 4.785748954034182 | validation: 4.816983483929296]
	TIME [epoch: 25 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.768701134698997		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 4.768701134698997 | validation: 4.87997149475651]
	TIME [epoch: 25 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.791116528958369		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 4.791116528958369 | validation: 4.80616418527315]
	TIME [epoch: 24.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7448215557508515		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 4.7448215557508515 | validation: 4.770338395955804]
	TIME [epoch: 24.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.718596265515011		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 4.718596265515011 | validation: 4.773809435780732]
	TIME [epoch: 25 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.859468083676475		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 4.859468083676475 | validation: 4.753902702539466]
	TIME [epoch: 25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7383916678098705		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 4.7383916678098705 | validation: 4.785713743598211]
	TIME [epoch: 24.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7389035771199755		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 4.7389035771199755 | validation: 4.763260832604168]
	TIME [epoch: 25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.778116769801664		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 4.778116769801664 | validation: 4.697025083657565]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7268710238052005		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 4.7268710238052005 | validation: 4.812860134514671]
	TIME [epoch: 25 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.771619920325595		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 4.771619920325595 | validation: 4.876318035614357]
	TIME [epoch: 25 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.862581930647357		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 4.862581930647357 | validation: 4.733869726160763]
	TIME [epoch: 25 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.738739891967438		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 4.738739891967438 | validation: 4.766017657554475]
	TIME [epoch: 25 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.727815815143096		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 4.727815815143096 | validation: 4.786662747870783]
	TIME [epoch: 24.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.762654869836494		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 4.762654869836494 | validation: 4.676344765812969]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.105618201349308		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 5.105618201349308 | validation: 4.788245377943759]
	TIME [epoch: 25 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.709915600867514		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 4.709915600867514 | validation: 4.734302366696161]
	TIME [epoch: 25 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.709515157612934		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 4.709515157612934 | validation: 4.817632920259414]
	TIME [epoch: 25 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.731245842024679		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 4.731245842024679 | validation: 4.717553545039378]
	TIME [epoch: 25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6851569976733565		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 4.6851569976733565 | validation: 4.776224092183513]
	TIME [epoch: 25 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.753608011913246		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 4.753608011913246 | validation: 4.689263274303958]
	TIME [epoch: 25 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.702103177528507		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 4.702103177528507 | validation: 4.675193230042959]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.701307299047843		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 4.701307299047843 | validation: 4.690949575782242]
	TIME [epoch: 25 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.757037074891886		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 4.757037074891886 | validation: 4.661175953627414]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.680206071017269		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 4.680206071017269 | validation: 4.67822004078803]
	TIME [epoch: 25 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.714121293520066		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 4.714121293520066 | validation: 4.655621458807586]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.73005326479613		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 4.73005326479613 | validation: 4.763460226979582]
	TIME [epoch: 25 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7184684727537825		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 4.7184684727537825 | validation: 4.739890126217242]
	TIME [epoch: 25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.713925196300517		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 4.713925196300517 | validation: 4.722810802942616]
	TIME [epoch: 25 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.938916287084037		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 4.938916287084037 | validation: 4.759945707623151]
	TIME [epoch: 25 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.694649726691349		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 4.694649726691349 | validation: 4.71450826938351]
	TIME [epoch: 25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.737907685407871		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 4.737907685407871 | validation: 4.690579871041043]
	TIME [epoch: 25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7183920528303425		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 4.7183920528303425 | validation: 4.803349960822032]
	TIME [epoch: 25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.804151213274151		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 4.804151213274151 | validation: 4.800051597958867]
	TIME [epoch: 25 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.707597705781021		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 4.707597705781021 | validation: 4.6687862313753]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.726023840586258		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 4.726023840586258 | validation: 4.781663536417276]
	TIME [epoch: 25 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.734723271794768		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 4.734723271794768 | validation: 4.6592011476841435]
	TIME [epoch: 25 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.698478285348474		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 4.698478285348474 | validation: 4.696615998670659]
	TIME [epoch: 25 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.679961259387262		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 4.679961259387262 | validation: 4.914696827288852]
	TIME [epoch: 25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.763343114683957		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 4.763343114683957 | validation: 4.680327308045393]
	TIME [epoch: 25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.725053090534884		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 4.725053090534884 | validation: 4.67706131743737]
	TIME [epoch: 25 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.719073021374926		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 4.719073021374926 | validation: 4.6924334457875725]
	TIME [epoch: 25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.802367228813905		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 4.802367228813905 | validation: 4.681036466293981]
	TIME [epoch: 25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7255115961114615		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 4.7255115961114615 | validation: 4.655366412899825]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.662393906153737		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 4.662393906153737 | validation: 4.7377226318793815]
	TIME [epoch: 25 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.714396692049704		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 4.714396692049704 | validation: 4.662312162149083]
	TIME [epoch: 24.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.667188997731225		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 4.667188997731225 | validation: 4.784034470628296]
	TIME [epoch: 25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.709417814256041		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 4.709417814256041 | validation: 4.85358961728222]
	TIME [epoch: 25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.71303349875512		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 4.71303349875512 | validation: 4.656452854280639]
	TIME [epoch: 24.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.685646433299724		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 4.685646433299724 | validation: 4.693422633148946]
	TIME [epoch: 25 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.679767915898912		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 4.679767915898912 | validation: 4.801979365926141]
	TIME [epoch: 25 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.76105510472002		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 4.76105510472002 | validation: 4.712712378198002]
	TIME [epoch: 24.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.702720400754007		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 4.702720400754007 | validation: 4.673446113333947]
	TIME [epoch: 25 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.745273333065816		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 4.745273333065816 | validation: 4.68462716304284]
	TIME [epoch: 25 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.711121592838909		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 4.711121592838909 | validation: 4.646265583530009]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.643054624744159		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 4.643054624744159 | validation: 4.668689668829821]
	TIME [epoch: 25 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.686999863673999		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 4.686999863673999 | validation: 4.645827546966496]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7471651473568155		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 4.7471651473568155 | validation: 4.644461482147216]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.628381862713551		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 4.628381862713551 | validation: 4.7767399162798085]
	TIME [epoch: 25 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.696913083344005		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 4.696913083344005 | validation: 4.772365063463112]
	TIME [epoch: 25 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.667880443310812		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 4.667880443310812 | validation: 4.8798548842232075]
	TIME [epoch: 24.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.695907061953531		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 4.695907061953531 | validation: 4.650457366225194]
	TIME [epoch: 25 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.676425599067094		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 4.676425599067094 | validation: 4.635990805282495]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.642711509671057		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 4.642711509671057 | validation: 4.873484181848532]
	TIME [epoch: 25 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.796418175780321		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 4.796418175780321 | validation: 4.748028453456618]
	TIME [epoch: 24.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.649904507558763		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 4.649904507558763 | validation: 4.683095439213085]
	TIME [epoch: 25 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.672180239149893		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 4.672180239149893 | validation: 4.835442526190591]
	TIME [epoch: 25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.746509814312912		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 4.746509814312912 | validation: 4.603705427711873]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.679120867781164		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 4.679120867781164 | validation: 4.609100806805449]
	TIME [epoch: 25 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.634090145568545		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 4.634090145568545 | validation: 4.639519344121424]
	TIME [epoch: 25 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.628633918312682		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 4.628633918312682 | validation: 4.622616434511163]
	TIME [epoch: 25 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.630827091490947		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 4.630827091490947 | validation: 4.66469885216198]
	TIME [epoch: 25 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.653853855572905		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 4.653853855572905 | validation: 4.625078298548514]
	TIME [epoch: 25 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.667579233203618		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 4.667579233203618 | validation: 4.706858769839608]
	TIME [epoch: 25 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.647207231115282		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 4.647207231115282 | validation: 4.6316209024620765]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.639109889156275		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 4.639109889156275 | validation: 4.613573775717815]
	TIME [epoch: 25 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6342472530669365		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 4.6342472530669365 | validation: 4.735163308803326]
	TIME [epoch: 25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.681550298349841		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 4.681550298349841 | validation: 4.714463439698162]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.740376563624706		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 4.740376563624706 | validation: 4.738326646720173]
	TIME [epoch: 24.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.668127289545005		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 4.668127289545005 | validation: 4.747590438962615]
	TIME [epoch: 25 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7440583536266905		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 4.7440583536266905 | validation: 4.615957529932861]
	TIME [epoch: 25 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.733877149519753		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 4.733877149519753 | validation: 4.860439156100454]
	TIME [epoch: 25 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.681897356869497		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 4.681897356869497 | validation: 4.637898651925566]
	TIME [epoch: 25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.636729719756919		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 4.636729719756919 | validation: 4.603982657281401]
	TIME [epoch: 25 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.597716086790161		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 4.597716086790161 | validation: 4.681715169879111]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.62728199850849		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 4.62728199850849 | validation: 4.583619532574736]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.61637262556271		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 4.61637262556271 | validation: 4.780486419166494]
	TIME [epoch: 25 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.671568136697708		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 4.671568136697708 | validation: 4.6001477746443005]
	TIME [epoch: 25 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6773463442908625		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 4.6773463442908625 | validation: 5.113358606375759]
	TIME [epoch: 24.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.854219350907334		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 4.854219350907334 | validation: 4.740484524412719]
	TIME [epoch: 24.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.696471140909367		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 4.696471140909367 | validation: 4.636794442282269]
	TIME [epoch: 25 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.612920991359189		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 4.612920991359189 | validation: 4.704815672853056]
	TIME [epoch: 24.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.621778949554278		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 4.621778949554278 | validation: 4.627456235367951]
	TIME [epoch: 25 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.604938689357518		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 4.604938689357518 | validation: 4.715051896865049]
	TIME [epoch: 25 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.638099774666532		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 4.638099774666532 | validation: 4.713331849418637]
	TIME [epoch: 25 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6442136560142675		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 4.6442136560142675 | validation: 4.5815777396937385]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.600785785320252		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 4.600785785320252 | validation: 4.615798772036766]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.603284460841659		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 4.603284460841659 | validation: 4.592637248230282]
	TIME [epoch: 25 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.631786759824331		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 4.631786759824331 | validation: 4.7700843642155535]
	TIME [epoch: 25 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.688607200920207		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 4.688607200920207 | validation: 4.6184134433433295]
	TIME [epoch: 25 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6265848776565806		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 4.6265848776565806 | validation: 4.577075607484513]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.627939379004387		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 4.627939379004387 | validation: 4.593810894094392]
	TIME [epoch: 25 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.638248778359565		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 4.638248778359565 | validation: 4.605692826812521]
	TIME [epoch: 25 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.583616066453512		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 4.583616066453512 | validation: 4.621381369399289]
	TIME [epoch: 25 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6222279138937665		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 4.6222279138937665 | validation: 4.723163267985896]
	TIME [epoch: 25 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.647288247021519		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 4.647288247021519 | validation: 4.65003538659549]
	TIME [epoch: 25 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.637505844171608		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 4.637505844171608 | validation: 4.63724002941426]
	TIME [epoch: 25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.693245510787602		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 4.693245510787602 | validation: 4.783249261311612]
	TIME [epoch: 25 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6989341790554455		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 4.6989341790554455 | validation: 4.597805166213603]
	TIME [epoch: 25 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.614912946989532		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 4.614912946989532 | validation: 4.620368230375269]
	TIME [epoch: 25 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.620417095557078		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 4.620417095557078 | validation: 4.580672606099461]
	TIME [epoch: 25 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.587629396339331		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 4.587629396339331 | validation: 4.586822035963502]
	TIME [epoch: 25 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.60595488119095		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 4.60595488119095 | validation: 4.576071895968138]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.583293339412615		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 4.583293339412615 | validation: 4.598633841741388]
	TIME [epoch: 25 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.586400883093677		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 4.586400883093677 | validation: 4.6788308678140975]
	TIME [epoch: 25 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.719483190332361		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 4.719483190332361 | validation: 4.585412973311624]
	TIME [epoch: 25 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.580596526881295		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 4.580596526881295 | validation: 4.625892777139805]
	TIME [epoch: 25 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.622280789932647		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 4.622280789932647 | validation: 4.78880576744943]
	TIME [epoch: 25 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.689564932877376		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 4.689564932877376 | validation: 4.6563905386253595]
	TIME [epoch: 25 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.636499793434583		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 4.636499793434583 | validation: 4.613022377958564]
	TIME [epoch: 25 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.61274398739649		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 4.61274398739649 | validation: 4.6089369535599864]
	TIME [epoch: 25 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.595520435784593		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 4.595520435784593 | validation: 4.566070301472614]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.711860977115102		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 4.711860977115102 | validation: 4.576885249283686]
	TIME [epoch: 25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.590668604564469		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 4.590668604564469 | validation: 4.578088540467189]
	TIME [epoch: 25 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.619382573294184		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 4.619382573294184 | validation: 4.58122839134714]
	TIME [epoch: 25 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.583301275851751		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 4.583301275851751 | validation: 4.577764760531533]
	TIME [epoch: 25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.619479196685211		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 4.619479196685211 | validation: 4.629142274698398]
	TIME [epoch: 25 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6095722915095925		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 4.6095722915095925 | validation: 4.572946928456156]
	TIME [epoch: 25 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.579400837708957		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 4.579400837708957 | validation: 4.558785673062145]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.614014015469207		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 4.614014015469207 | validation: 4.595259191620478]
	TIME [epoch: 25 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.590047781138221		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 4.590047781138221 | validation: 4.603114313490755]
	TIME [epoch: 24.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.627937507383154		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 4.627937507383154 | validation: 4.823165789461229]
	TIME [epoch: 25 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.685444803064172		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 4.685444803064172 | validation: 4.59538608097497]
	TIME [epoch: 25 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.636022207205502		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 4.636022207205502 | validation: 4.630274750478349]
	TIME [epoch: 25 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.621352602649721		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 4.621352602649721 | validation: 4.596115007243759]
	TIME [epoch: 25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5871928372119495		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 4.5871928372119495 | validation: 4.610715700662693]
	TIME [epoch: 25 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.604331755332621		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 4.604331755332621 | validation: 4.57035076402454]
	TIME [epoch: 25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.609765483607909		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 4.609765483607909 | validation: 4.594944791422036]
	TIME [epoch: 25 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.624145025004059		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 4.624145025004059 | validation: 4.579170270551547]
	TIME [epoch: 25 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6243096138857895		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 4.6243096138857895 | validation: 4.675665593627457]
	TIME [epoch: 25 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.595325488889109		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 4.595325488889109 | validation: 4.566444543245673]
	TIME [epoch: 25 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.567868281519775		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 4.567868281519775 | validation: 4.587506093944056]
	TIME [epoch: 25 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6369639216798895		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 4.6369639216798895 | validation: 4.633192167654924]
	TIME [epoch: 25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.587755909682057		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 4.587755909682057 | validation: 4.599018982554582]
	TIME [epoch: 25 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.613903674946691		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 4.613903674946691 | validation: 4.5947004118665165]
	TIME [epoch: 25 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.686220136979571		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 4.686220136979571 | validation: 4.649671051177349]
	TIME [epoch: 25 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.635760937901606		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 4.635760937901606 | validation: 4.6098235668506735]
	TIME [epoch: 25 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.607485910261342		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 4.607485910261342 | validation: 4.630831754757163]
	TIME [epoch: 25 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.604416557155053		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 4.604416557155053 | validation: 4.587428937692302]
	TIME [epoch: 24.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5746477828863075		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 4.5746477828863075 | validation: 4.639318009238653]
	TIME [epoch: 25 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.690456155832559		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 4.690456155832559 | validation: 4.602831477592504]
	TIME [epoch: 25 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.621956657517018		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 4.621956657517018 | validation: 4.593279231241628]
	TIME [epoch: 25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.632702587002028		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 4.632702587002028 | validation: 4.595854626148538]
	TIME [epoch: 25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.594887737125626		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 4.594887737125626 | validation: 4.579216491537056]
	TIME [epoch: 25 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.61165201917598		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 4.61165201917598 | validation: 4.662666663877404]
	TIME [epoch: 25 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.596696812732511		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 4.596696812732511 | validation: 4.562926430519923]
	TIME [epoch: 25 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.561245869552087		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 4.561245869552087 | validation: 4.604957059286916]
	TIME [epoch: 25 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.61417900048917		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 4.61417900048917 | validation: 4.559514375081216]
	TIME [epoch: 25 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547808837321404		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 4.547808837321404 | validation: 4.566304069445983]
	TIME [epoch: 25 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.563757345773803		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 4.563757345773803 | validation: 4.588222426328867]
	TIME [epoch: 25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.594237390895818		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 4.594237390895818 | validation: 4.570106231955266]
	TIME [epoch: 25 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.605471267056666		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 4.605471267056666 | validation: 4.559783038050091]
	TIME [epoch: 25 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.565104605758736		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 4.565104605758736 | validation: 4.610456584338984]
	TIME [epoch: 25 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.58058366259598		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 4.58058366259598 | validation: 4.605423164722253]
	TIME [epoch: 24.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6114948135727305		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 4.6114948135727305 | validation: 4.546558481931796]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5912270200241		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 4.5912270200241 | validation: 4.576982887626]
	TIME [epoch: 24.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.557632805892526		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 4.557632805892526 | validation: 4.56824294818348]
	TIME [epoch: 24.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.564070029444559		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 4.564070029444559 | validation: 4.56804867579939]
	TIME [epoch: 24.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.593527089916808		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 4.593527089916808 | validation: 4.618331680012439]
	TIME [epoch: 24.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.611565698422766		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 4.611565698422766 | validation: 4.614508805706113]
	TIME [epoch: 24.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.574208012018528		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 4.574208012018528 | validation: 4.55437343944421]
	TIME [epoch: 25 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.609738725917788		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 4.609738725917788 | validation: 4.53981829393838]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.565602622037048		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 4.565602622037048 | validation: 4.547732058196651]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.55556921660828		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 4.55556921660828 | validation: 4.622102577328512]
	TIME [epoch: 24.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.565508309272509		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 4.565508309272509 | validation: 4.541776734861423]
	TIME [epoch: 24.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.570001558827066		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 4.570001558827066 | validation: 4.586179088818927]
	TIME [epoch: 24.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.565994214607645		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 4.565994214607645 | validation: 4.527208595963418]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_333.pth
	Model improved!!!
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.610054447251647		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 4.610054447251647 | validation: 4.629428088355943]
	TIME [epoch: 24.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.593331107511824		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 4.593331107511824 | validation: 4.541801946849796]
	TIME [epoch: 24.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.543811584550055		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 4.543811584550055 | validation: 4.555383527500172]
	TIME [epoch: 24.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.543098027979911		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 4.543098027979911 | validation: 4.596195801967901]
	TIME [epoch: 24.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.601927615011578		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 4.601927615011578 | validation: 4.571510546291104]
	TIME [epoch: 24.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.572000615729057		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 4.572000615729057 | validation: 4.596419847198295]
	TIME [epoch: 24.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.666432630334082		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 4.666432630334082 | validation: 4.554005564046775]
	TIME [epoch: 24.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.576227178903503		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 4.576227178903503 | validation: 4.560918752010198]
	TIME [epoch: 24.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5507100411529455		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 4.5507100411529455 | validation: 4.570631397710416]
	TIME [epoch: 25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.55618813372241		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 4.55618813372241 | validation: 4.568592764331138]
	TIME [epoch: 25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.539844366486458		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 4.539844366486458 | validation: 4.6285481052849455]
	TIME [epoch: 24.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.650902703515381		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 4.650902703515381 | validation: 4.644210581853395]
	TIME [epoch: 24.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.588171088498688		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 4.588171088498688 | validation: 4.605472014444594]
	TIME [epoch: 25 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.579987869261656		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 4.579987869261656 | validation: 4.625123991085822]
	TIME [epoch: 25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.597765262016953		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 4.597765262016953 | validation: 4.592671651116107]
	TIME [epoch: 25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.544782898116012		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 4.544782898116012 | validation: 4.582297335232668]
	TIME [epoch: 25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.596710729492775		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 4.596710729492775 | validation: 4.563192286753458]
	TIME [epoch: 24.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.586177880534949		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 4.586177880534949 | validation: 4.551483669745676]
	TIME [epoch: 24.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.574925956595513		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 4.574925956595513 | validation: 4.540226912966705]
	TIME [epoch: 24.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.564076608973156		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 4.564076608973156 | validation: 4.564551385505549]
	TIME [epoch: 24.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.581737497757393		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 4.581737497757393 | validation: 4.52143093505574]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_354.pth
	Model improved!!!
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.572500352034284		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 4.572500352034284 | validation: 4.529582916813722]
	TIME [epoch: 25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.535175374597177		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 4.535175374597177 | validation: 4.531085099102522]
	TIME [epoch: 25 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.553085384841486		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 4.553085384841486 | validation: 4.551941248746239]
	TIME [epoch: 25 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5577667807261495		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 4.5577667807261495 | validation: 4.559261867637815]
	TIME [epoch: 25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.575162676932892		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 4.575162676932892 | validation: 4.580244046688905]
	TIME [epoch: 25 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.590738997593388		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 4.590738997593388 | validation: 4.650731691758063]
	TIME [epoch: 25 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.711387798716244		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 4.711387798716244 | validation: 4.521370483012257]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.572377034117384		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 4.572377034117384 | validation: 4.539775284979465]
	TIME [epoch: 24.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5453577075155875		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 4.5453577075155875 | validation: 4.524400425752064]
	TIME [epoch: 25 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.53075216486655		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 4.53075216486655 | validation: 4.533762389828125]
	TIME [epoch: 25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.558447282895252		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 4.558447282895252 | validation: 4.537249576865263]
	TIME [epoch: 25 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.571615023270036		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 4.571615023270036 | validation: 4.624729495415033]
	TIME [epoch: 24.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.612096392435775		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 4.612096392435775 | validation: 4.535994207743377]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.604823672178729		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 4.604823672178729 | validation: 4.525891986214839]
	TIME [epoch: 24.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.639501733248563		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 4.639501733248563 | validation: 4.539180438639269]
	TIME [epoch: 25 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.549785340837712		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 4.549785340837712 | validation: 4.516597594405302]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.552719073612289		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 4.552719073612289 | validation: 4.6218646737976945]
	TIME [epoch: 25 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.573057693790107		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 4.573057693790107 | validation: 4.541830873476057]
	TIME [epoch: 25 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.548426825920782		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 4.548426825920782 | validation: 4.522009874465283]
	TIME [epoch: 24.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.545843215246282		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 4.545843215246282 | validation: 4.592111445978225]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.574669398254436		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 4.574669398254436 | validation: 4.53758613731085]
	TIME [epoch: 25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.568856869954562		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 4.568856869954562 | validation: 4.533924856895097]
	TIME [epoch: 25 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.550000228743489		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 4.550000228743489 | validation: 4.5240106293592275]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.530097753447557		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 4.530097753447557 | validation: 4.519180374740489]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.541217172835203		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 4.541217172835203 | validation: 4.603731794188268]
	TIME [epoch: 25 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547000517092715		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 4.547000517092715 | validation: 4.524785701831103]
	TIME [epoch: 25 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547110122701477		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 4.547110122701477 | validation: 4.6482381308963605]
	TIME [epoch: 25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.584243985971902		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 4.584243985971902 | validation: 4.557854711687116]
	TIME [epoch: 25 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.56095047520128		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 4.56095047520128 | validation: 4.535546828793035]
	TIME [epoch: 25 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.53587244738817		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 4.53587244738817 | validation: 4.538901927085885]
	TIME [epoch: 25 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.546342307986447		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 4.546342307986447 | validation: 4.576658844644651]
	TIME [epoch: 25 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.53158527617756		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 4.53158527617756 | validation: 4.546992812769596]
	TIME [epoch: 25 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525772873198661		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 4.525772873198661 | validation: 4.569621266419727]
	TIME [epoch: 24.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.59932122171967		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 4.59932122171967 | validation: 4.5435880335188665]
	TIME [epoch: 24.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.527971347637882		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 4.527971347637882 | validation: 4.561571827351874]
	TIME [epoch: 25 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.558997062380737		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 4.558997062380737 | validation: 4.5558604936596]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.527588282426099		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 4.527588282426099 | validation: 4.611586024150431]
	TIME [epoch: 25 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.569852540223329		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 4.569852540223329 | validation: 4.586888925396154]
	TIME [epoch: 24.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.558395959016816		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 4.558395959016816 | validation: 4.593134813725407]
	TIME [epoch: 24.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540341147215596		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 4.540341147215596 | validation: 4.6557908003387265]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.564277411662033		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 4.564277411662033 | validation: 4.518531878556916]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.54816087610914		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 4.54816087610914 | validation: 4.5272256673024955]
	TIME [epoch: 24.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522828460225491		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 4.522828460225491 | validation: 4.550535805794442]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.552607604077993		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 4.552607604077993 | validation: 4.523787322175855]
	TIME [epoch: 24.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.539607145810821		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 4.539607145810821 | validation: 4.567824739543254]
	TIME [epoch: 25 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6028134209605485		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 4.6028134209605485 | validation: 4.575858556925939]
	TIME [epoch: 25 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.585863777687693		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 4.585863777687693 | validation: 4.520964453353723]
	TIME [epoch: 24.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540828595125422		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 4.540828595125422 | validation: 4.505481460584802]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.590410456538423		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 4.590410456538423 | validation: 4.549833038748824]
	TIME [epoch: 25 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547533410750829		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 4.547533410750829 | validation: 4.5274525179382055]
	TIME [epoch: 25 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522983990123949		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 4.522983990123949 | validation: 4.566338148984927]
	TIME [epoch: 24.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.575993636400713		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 4.575993636400713 | validation: 4.516353489483857]
	TIME [epoch: 25 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.569579958357804		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 4.569579958357804 | validation: 4.5906893513353175]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.575553216733402		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 4.575553216733402 | validation: 4.787596467043185]
	TIME [epoch: 24.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.638256072128345		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 4.638256072128345 | validation: 4.692093483510962]
	TIME [epoch: 25 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.570805023839017		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 4.570805023839017 | validation: 4.556260738396541]
	TIME [epoch: 24.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540995526413447		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 4.540995526413447 | validation: 4.508222053181943]
	TIME [epoch: 24.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.528260890047294		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 4.528260890047294 | validation: 4.573969033248687]
	TIME [epoch: 25 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.537215395718848		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 4.537215395718848 | validation: 4.501848175798885]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.520535801981172		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 4.520535801981172 | validation: 4.518244698478926]
	TIME [epoch: 24.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.535485071337961		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 4.535485071337961 | validation: 4.516580328265854]
	TIME [epoch: 25 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.552701709035685		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 4.552701709035685 | validation: 4.493949985319973]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.507497329088672		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 4.507497329088672 | validation: 4.554031757328685]
	TIME [epoch: 24.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5408372666916526		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 4.5408372666916526 | validation: 4.532815126847194]
	TIME [epoch: 25 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.576694667361338		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 4.576694667361338 | validation: 4.50703823982436]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5893038135340145		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 4.5893038135340145 | validation: 4.519794635905422]
	TIME [epoch: 24.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5311681061007665		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 4.5311681061007665 | validation: 4.487306379542311]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.539321376159883		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 4.539321376159883 | validation: 4.726381574955038]
	TIME [epoch: 25 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.580855082847391		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 4.580855082847391 | validation: 4.542127012813785]
	TIME [epoch: 24.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.529611492386337		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 4.529611492386337 | validation: 4.496400896818929]
	TIME [epoch: 25 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518567380426267		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 4.518567380426267 | validation: 4.503941824968423]
	TIME [epoch: 25 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.526045269200568		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 4.526045269200568 | validation: 4.533473820654173]
	TIME [epoch: 24.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510704596470175		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 4.510704596470175 | validation: 4.559597555272959]
	TIME [epoch: 25 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525033046013254		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 4.525033046013254 | validation: 4.549190936039754]
	TIME [epoch: 25 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518137137063541		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 4.518137137063541 | validation: 4.502113345825485]
	TIME [epoch: 24.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540536740089642		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 4.540536740089642 | validation: 4.53310845701416]
	TIME [epoch: 25 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5276404947993205		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 4.5276404947993205 | validation: 4.516494736974635]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.520460216604784		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 4.520460216604784 | validation: 4.609447774984217]
	TIME [epoch: 24.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.562653178997704		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 4.562653178997704 | validation: 4.572083557203399]
	TIME [epoch: 24.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.545321854876795		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 4.545321854876795 | validation: 4.523497215069293]
	TIME [epoch: 24.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.543397370090391		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 4.543397370090391 | validation: 4.585904870125963]
	TIME [epoch: 24.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.542626898959579		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 4.542626898959579 | validation: 4.5054842893540705]
	TIME [epoch: 24.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.527764529424625		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 4.527764529424625 | validation: 4.514806809934842]
	TIME [epoch: 24.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.551196841159178		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 4.551196841159178 | validation: 4.509022558115715]
	TIME [epoch: 24.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.571756625758954		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 4.571756625758954 | validation: 4.593912606916503]
	TIME [epoch: 24.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.558898606898254		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 4.558898606898254 | validation: 4.572202775803957]
	TIME [epoch: 24.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.538681980553204		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 4.538681980553204 | validation: 4.597592654236125]
	TIME [epoch: 24.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.562672171665856		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 4.562672171665856 | validation: 4.508023731485611]
	TIME [epoch: 24.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547395265784266		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 4.547395265784266 | validation: 4.513116493802403]
	TIME [epoch: 24.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6511640638797855		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 4.6511640638797855 | validation: 4.543449278959165]
	TIME [epoch: 24.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.557877784111546		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 4.557877784111546 | validation: 4.523549204050566]
	TIME [epoch: 24.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.563103926410951		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 4.563103926410951 | validation: 4.519867682568048]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.516731160006669		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 4.516731160006669 | validation: 4.588414323910109]
	TIME [epoch: 24.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.562043791918118		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 4.562043791918118 | validation: 4.528087091140482]
	TIME [epoch: 24.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525302559604665		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 4.525302559604665 | validation: 4.557085464048166]
	TIME [epoch: 24.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517906323424724		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 4.517906323424724 | validation: 4.552519544064029]
	TIME [epoch: 24.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5142908110826365		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 4.5142908110826365 | validation: 4.527035133509466]
	TIME [epoch: 24.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510085564326671		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 4.510085564326671 | validation: 4.5285131611285845]
	TIME [epoch: 24.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.516711235479727		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 4.516711235479727 | validation: 4.484206304978235]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50078909137375		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 4.50078909137375 | validation: 4.504504077616101]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.546500042141917		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 4.546500042141917 | validation: 4.511462209658892]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531339232931544		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 4.531339232931544 | validation: 4.526075080775171]
	TIME [epoch: 24.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511564223644279		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 4.511564223644279 | validation: 4.636582882541672]
	TIME [epoch: 24.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.581661414393464		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 4.581661414393464 | validation: 4.491081735309693]
	TIME [epoch: 24.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.503806638265318		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 4.503806638265318 | validation: 4.5250351267029245]
	TIME [epoch: 24.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531280829495978		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 4.531280829495978 | validation: 4.506135624422487]
	TIME [epoch: 24.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511926044263446		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 4.511926044263446 | validation: 4.51576664111949]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.523622093773567		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 4.523622093773567 | validation: 4.500519179153159]
	TIME [epoch: 24.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5153510973561355		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 4.5153510973561355 | validation: 4.504627049676897]
	TIME [epoch: 24.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.521309449439262		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 4.521309449439262 | validation: 4.561417098981178]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515050686529386		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 4.515050686529386 | validation: 4.487108027610647]
	TIME [epoch: 24.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510458376354673		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 4.510458376354673 | validation: 4.4976480997012525]
	TIME [epoch: 24.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4981843131284185		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 4.4981843131284185 | validation: 4.514326312827334]
	TIME [epoch: 25 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.537027356420831		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 4.537027356420831 | validation: 4.610697571252147]
	TIME [epoch: 24.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540980807218222		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 4.540980807218222 | validation: 4.648275846084536]
	TIME [epoch: 25 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.579281983587033		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 4.579281983587033 | validation: 4.568021140400024]
	TIME [epoch: 24.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.539010435776021		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 4.539010435776021 | validation: 4.520792336946577]
	TIME [epoch: 24.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517386805005188		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 4.517386805005188 | validation: 4.488764386703296]
	TIME [epoch: 24.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4904710100552485		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 4.4904710100552485 | validation: 4.48424697444559]
	TIME [epoch: 24.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501589354981334		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 4.501589354981334 | validation: 4.511403586023419]
	TIME [epoch: 24.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5105761449966515		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 4.5105761449966515 | validation: 4.525358126873552]
	TIME [epoch: 24.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.509538792675268		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 4.509538792675268 | validation: 4.499563866073457]
	TIME [epoch: 24.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49537897903189		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 4.49537897903189 | validation: 4.495307426477738]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495138271439738		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 4.495138271439738 | validation: 4.535378729478736]
	TIME [epoch: 24.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.537117088344678		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 4.537117088344678 | validation: 4.599560361751961]
	TIME [epoch: 24.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.530304005002135		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 4.530304005002135 | validation: 4.546998218260274]
	TIME [epoch: 24.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517895577206008		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 4.517895577206008 | validation: 4.5549984882695735]
	TIME [epoch: 24.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.545477685028954		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 4.545477685028954 | validation: 4.540267444487869]
	TIME [epoch: 24.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.51657091938766		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 4.51657091938766 | validation: 4.879193411168484]
	TIME [epoch: 24.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.72736426975585		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 4.72736426975585 | validation: 4.493310172206512]
	TIME [epoch: 25 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506245098674306		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 4.506245098674306 | validation: 4.502319764887139]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.503667052306302		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 4.503667052306302 | validation: 4.488177224603005]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486551081458593		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 4.486551081458593 | validation: 4.588523099582643]
	TIME [epoch: 25 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5473509153419		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 4.5473509153419 | validation: 4.9348073524952625]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.787752405790576		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 4.787752405790576 | validation: 4.507094520681563]
	TIME [epoch: 24.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504011306300603		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 4.504011306300603 | validation: 4.490174370881333]
	TIME [epoch: 24.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497011189840584		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 4.497011189840584 | validation: 4.493111330329711]
	TIME [epoch: 24.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.535284926964171		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 4.535284926964171 | validation: 4.480061215450478]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.503403265395654		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 4.503403265395654 | validation: 4.546906466031875]
	TIME [epoch: 24.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.527946370784164		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 4.527946370784164 | validation: 4.542184616833172]
	TIME [epoch: 24.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.561712423984385		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 4.561712423984385 | validation: 4.545910460628152]
	TIME [epoch: 24.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.51383024062868		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 4.51383024062868 | validation: 4.49917947919565]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512350326575065		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 4.512350326575065 | validation: 4.503714004799177]
	TIME [epoch: 24.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49830631475389		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 4.49830631475389 | validation: 4.48778314593999]
	TIME [epoch: 24.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.507594181418186		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 4.507594181418186 | validation: 4.477456033873451]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.502219443925853		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 4.502219443925853 | validation: 4.499843082460524]
	TIME [epoch: 25 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5276183392388685		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 4.5276183392388685 | validation: 4.54293125360443]
	TIME [epoch: 24.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504664860344034		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 4.504664860344034 | validation: 4.487392619916388]
	TIME [epoch: 24.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494852254290681		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 4.494852254290681 | validation: 4.498486991627284]
	TIME [epoch: 25 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490041112002371		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 4.490041112002371 | validation: 4.550599878804692]
	TIME [epoch: 24.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.527931071619012		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 4.527931071619012 | validation: 4.494287231422553]
	TIME [epoch: 24.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496841029738034		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 4.496841029738034 | validation: 4.4928521401231185]
	TIME [epoch: 24.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47953499959825		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 4.47953499959825 | validation: 4.48081040505552]
	TIME [epoch: 24.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.53364930336023		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 4.53364930336023 | validation: 4.499821080754682]
	TIME [epoch: 25 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506404553852637		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 4.506404553852637 | validation: 4.5201013727274955]
	TIME [epoch: 24.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540786448309138		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 4.540786448309138 | validation: 4.525185248015339]
	TIME [epoch: 24.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510097937267078		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 4.510097937267078 | validation: 4.509935678426034]
	TIME [epoch: 24.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50197095347514		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 4.50197095347514 | validation: 4.500491972012854]
	TIME [epoch: 24.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504458404679882		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 4.504458404679882 | validation: 4.49282963178643]
	TIME [epoch: 24.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510196677574729		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 4.510196677574729 | validation: 4.48785190516147]
	TIME [epoch: 24.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485807163794155		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 4.485807163794155 | validation: 4.5859584853306785]
	TIME [epoch: 24.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.530726515273351		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 4.530726515273351 | validation: 4.52419841291761]
	TIME [epoch: 24.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49401282040255		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 4.49401282040255 | validation: 4.490628144555986]
	TIME [epoch: 24.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513021862004313		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 4.513021862004313 | validation: 4.510506528433774]
	TIME [epoch: 25 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506236278902033		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 4.506236278902033 | validation: 4.523084026960169]
	TIME [epoch: 24.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5267017705881045		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 4.5267017705881045 | validation: 4.5143866267534705]
	TIME [epoch: 24.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.53087321176862		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 4.53087321176862 | validation: 4.542443470057793]
	TIME [epoch: 25 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.551828543018236		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 4.551828543018236 | validation: 4.500941426896848]
	TIME [epoch: 24.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493451856880112		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 4.493451856880112 | validation: 4.485088628381297]
	TIME [epoch: 24.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501280431649239		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 4.501280431649239 | validation: 4.535326335742682]
	TIME [epoch: 25 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.520330689816033		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 4.520330689816033 | validation: 4.5343735454193315]
	TIME [epoch: 24.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513758103229028		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 4.513758103229028 | validation: 4.487816385850951]
	TIME [epoch: 25 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5136296995985274		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 4.5136296995985274 | validation: 4.505449375816402]
	TIME [epoch: 25 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513011854873691		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 4.513011854873691 | validation: 4.476286273606471]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487544838840359		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 4.487544838840359 | validation: 4.473392693070762]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.526061652939428		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 4.526061652939428 | validation: 4.570013816705212]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.534560611724941		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 4.534560611724941 | validation: 4.514941831370772]
	TIME [epoch: 24.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492141219283402		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 4.492141219283402 | validation: 4.478317720772536]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493140816114033		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 4.493140816114033 | validation: 4.492147976105806]
	TIME [epoch: 25 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.508804340922255		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 4.508804340922255 | validation: 4.491169569043266]
	TIME [epoch: 25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497514808889974		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 4.497514808889974 | validation: 4.494643632577301]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50352631275017		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 4.50352631275017 | validation: 4.5038070696543375]
	TIME [epoch: 25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.509978782556407		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 4.509978782556407 | validation: 4.613661986098395]
	TIME [epoch: 24.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.579881762526668		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 4.579881762526668 | validation: 4.49216177296512]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491588336996496		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 4.491588336996496 | validation: 4.51029533668775]
	TIME [epoch: 25 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494380869180285		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 4.494380869180285 | validation: 4.504173487686428]
	TIME [epoch: 24.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49158912016074		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 4.49158912016074 | validation: 4.472423918776116]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_541.pth
	Model improved!!!
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497101346143145		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 4.497101346143145 | validation: 4.492302160336272]
	TIME [epoch: 25 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4962768537956475		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 4.4962768537956475 | validation: 4.488485139117566]
	TIME [epoch: 25 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531012107548142		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 4.531012107548142 | validation: 4.497081853109326]
	TIME [epoch: 25 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.521399630657885		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 4.521399630657885 | validation: 4.55359414063906]
	TIME [epoch: 25 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.521012841780658		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 4.521012841780658 | validation: 4.547012889420638]
	TIME [epoch: 25 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.520085198744262		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 4.520085198744262 | validation: 4.508830686713011]
	TIME [epoch: 25 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512847400040694		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 4.512847400040694 | validation: 4.605180403902998]
	TIME [epoch: 25 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.54415097590893		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 4.54415097590893 | validation: 4.5436415574281535]
	TIME [epoch: 25 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.51463513480873		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 4.51463513480873 | validation: 4.490229605654543]
	TIME [epoch: 25 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498379113234388		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 4.498379113234388 | validation: 4.483371443272757]
	TIME [epoch: 25 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501993434700721		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 4.501993434700721 | validation: 4.483727372090366]
	TIME [epoch: 25 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494320638503212		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 4.494320638503212 | validation: 4.532416965314995]
	TIME [epoch: 25 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.552916976386112		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 4.552916976386112 | validation: 4.507515192666183]
	TIME [epoch: 25 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500396122254088		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 4.500396122254088 | validation: 4.506445674659675]
	TIME [epoch: 25 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.502364327931849		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 4.502364327931849 | validation: 4.484772048898359]
	TIME [epoch: 25 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511611548596554		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 4.511611548596554 | validation: 4.484799628461928]
	TIME [epoch: 25 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493216206436725		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 4.493216206436725 | validation: 4.481462542318707]
	TIME [epoch: 25 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.507773888222871		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 4.507773888222871 | validation: 4.617634302094331]
	TIME [epoch: 25 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.533300234689656		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 4.533300234689656 | validation: 4.496873938673509]
	TIME [epoch: 25 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497113876341108		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 4.497113876341108 | validation: 4.517177393343572]
	TIME [epoch: 25 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497980656979735		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 4.497980656979735 | validation: 4.517430913969234]
	TIME [epoch: 25 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485530725756323		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 4.485530725756323 | validation: 4.51914447080314]
	TIME [epoch: 25 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50879037713022		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 4.50879037713022 | validation: 4.581116841400884]
	TIME [epoch: 24.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5408047408001595		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 4.5408047408001595 | validation: 4.59544201155954]
	TIME [epoch: 24.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.532020130581779		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 4.532020130581779 | validation: 4.516961332239605]
	TIME [epoch: 25 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513111033272108		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 4.513111033272108 | validation: 4.484510549251029]
	TIME [epoch: 25 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480244989495018		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 4.480244989495018 | validation: 4.56380589193469]
	TIME [epoch: 25 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5324310601369096		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 4.5324310601369096 | validation: 4.509471123015879]
	TIME [epoch: 25 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50002967572705		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 4.50002967572705 | validation: 4.476017993230104]
	TIME [epoch: 24.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48279422687768		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 4.48279422687768 | validation: 4.4789870499468005]
	TIME [epoch: 25 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511779132855453		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 4.511779132855453 | validation: 4.502190965868189]
	TIME [epoch: 25 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5145481772796305		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 4.5145481772796305 | validation: 4.538682636501043]
	TIME [epoch: 25 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515697112247198		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 4.515697112247198 | validation: 4.544711382723106]
	TIME [epoch: 25 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.505918629554642		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 4.505918629554642 | validation: 4.508640665288202]
	TIME [epoch: 25 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491853204833827		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 4.491853204833827 | validation: 4.480980276642657]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.580242412516189		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 4.580242412516189 | validation: 4.82246738328829]
	TIME [epoch: 24.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.613135704072463		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 4.613135704072463 | validation: 4.497057927958726]
	TIME [epoch: 24.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518019040762713		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 4.518019040762713 | validation: 4.509226878696822]
	TIME [epoch: 24.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512760226745854		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 4.512760226745854 | validation: 4.487704994325189]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49548524709439		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 4.49548524709439 | validation: 4.515761003584415]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495179085788855		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 4.495179085788855 | validation: 4.489997928108602]
	TIME [epoch: 25 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531381089004895		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 4.531381089004895 | validation: 4.492160307114847]
	TIME [epoch: 25 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514601316697869		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 4.514601316697869 | validation: 4.482519681247424]
	TIME [epoch: 25 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500708367559462		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 4.500708367559462 | validation: 4.4704494323552035]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4847543984201215		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 4.4847543984201215 | validation: 4.482912269412494]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488691995337554		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 4.488691995337554 | validation: 4.470591296410202]
	TIME [epoch: 25 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4886527978305715		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 4.4886527978305715 | validation: 4.491414908094834]
	TIME [epoch: 25 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493758585211292		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 4.493758585211292 | validation: 4.487733019450705]
	TIME [epoch: 24.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491771942462248		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 4.491771942462248 | validation: 4.497217638048513]
	TIME [epoch: 25 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489852775103306		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 4.489852775103306 | validation: 4.475055869906226]
	TIME [epoch: 24.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500479425023774		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 4.500479425023774 | validation: 4.477361408493628]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475045408317726		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 4.475045408317726 | validation: 4.487464869895496]
	TIME [epoch: 25 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500980516183006		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 4.500980516183006 | validation: 4.498341147495457]
	TIME [epoch: 25 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.505805656798644		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 4.505805656798644 | validation: 4.524064929098222]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.499499496044962		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 4.499499496044962 | validation: 4.4772100354511055]
	TIME [epoch: 25 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489467238840644		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 4.489467238840644 | validation: 4.513210656630843]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497909432859556		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 4.497909432859556 | validation: 4.487204372974493]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480225325658153		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 4.480225325658153 | validation: 4.498295644916431]
	TIME [epoch: 25 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.503221254955198		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 4.503221254955198 | validation: 4.504930044443192]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.499886847171488		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 4.499886847171488 | validation: 4.478680059495218]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495573705760002		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 4.495573705760002 | validation: 4.484969884408522]
	TIME [epoch: 25 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479393051450775		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 4.479393051450775 | validation: 4.483591273485015]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4802595708365205		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 4.4802595708365205 | validation: 4.506567568394567]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.553039454143768		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 4.553039454143768 | validation: 4.503813680757068]
	TIME [epoch: 25 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515467874298139		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 4.515467874298139 | validation: 4.491371928540486]
	TIME [epoch: 24.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511507754416002		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 4.511507754416002 | validation: 4.4777442933287785]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486146896644876		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 4.486146896644876 | validation: 4.505682221046206]
	TIME [epoch: 25 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493170269658183		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 4.493170269658183 | validation: 4.475823640313756]
	TIME [epoch: 24.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483889088046505		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 4.483889088046505 | validation: 4.535271743777735]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496577477433499		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 4.496577477433499 | validation: 4.476172379035653]
	TIME [epoch: 25 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482547738746551		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 4.482547738746551 | validation: 4.484077911736971]
	TIME [epoch: 24.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482781640182068		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 4.482781640182068 | validation: 4.482590707896979]
	TIME [epoch: 24.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495896011933117		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 4.495896011933117 | validation: 4.503398674321735]
	TIME [epoch: 25 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498490887119873		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 4.498490887119873 | validation: 4.4745303753154335]
	TIME [epoch: 25 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47865925728533		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 4.47865925728533 | validation: 4.504351285349022]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491323232081935		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 4.491323232081935 | validation: 4.479650015797875]
	TIME [epoch: 25 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482931762296423		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 4.482931762296423 | validation: 4.486792281790517]
	TIME [epoch: 25 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487790502767935		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 4.487790502767935 | validation: 4.505023434649275]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490061244810783		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 4.490061244810783 | validation: 4.477802817157454]
	TIME [epoch: 25 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483880263770773		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 4.483880263770773 | validation: 4.481360825328835]
	TIME [epoch: 25 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506772115902896		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 4.506772115902896 | validation: 4.521839254568297]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500189626378013		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 4.500189626378013 | validation: 4.4958514225309445]
	TIME [epoch: 25 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484629725556914		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 4.484629725556914 | validation: 4.545240957536676]
	TIME [epoch: 25 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.521237590015056		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 4.521237590015056 | validation: 4.5233448731541435]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50520833271574		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 4.50520833271574 | validation: 4.5954257609106115]
	TIME [epoch: 25 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.541225166436883		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 4.541225166436883 | validation: 4.488286121712291]
	TIME [epoch: 25 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487098250427751		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 4.487098250427751 | validation: 4.481021133646315]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5049681001749695		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 4.5049681001749695 | validation: 4.5110316299085]
	TIME [epoch: 25 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497000318147685		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 4.497000318147685 | validation: 4.474973189212183]
	TIME [epoch: 24.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486704389344314		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 4.486704389344314 | validation: 4.532647376407692]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.519423544850074		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 4.519423544850074 | validation: 4.497582577595259]
	TIME [epoch: 25 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506677119767548		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 4.506677119767548 | validation: 4.4859980687775876]
	TIME [epoch: 25 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.523953493687632		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 4.523953493687632 | validation: 4.520286030009074]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510389423319269		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 4.510389423319269 | validation: 4.513898832549568]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500673470403146		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 4.500673470403146 | validation: 4.510301520784333]
	TIME [epoch: 25 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493459925704639		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 4.493459925704639 | validation: 4.479293796556568]
	TIME [epoch: 24.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492528183469309		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 4.492528183469309 | validation: 4.511960456781619]
	TIME [epoch: 25 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496008577726584		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 4.496008577726584 | validation: 4.566259137039008]
	TIME [epoch: 25 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.519344258497449		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 4.519344258497449 | validation: 4.545856752834414]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.516913156954352		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 4.516913156954352 | validation: 4.492482399473781]
	TIME [epoch: 25 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494748679956967		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 4.494748679956967 | validation: 4.497618331961127]
	TIME [epoch: 25 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495197584304031		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 4.495197584304031 | validation: 4.5264484064793225]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495545407220893		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 4.495545407220893 | validation: 4.51831168873431]
	TIME [epoch: 25 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511102492452384		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 4.511102492452384 | validation: 4.476895451515137]
	TIME [epoch: 25 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4805587257371355		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 4.4805587257371355 | validation: 4.526467824874374]
	TIME [epoch: 24.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.502338645384604		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 4.502338645384604 | validation: 4.510918627761884]
	TIME [epoch: 25 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501169646518068		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 4.501169646518068 | validation: 4.48468787010351]
	TIME [epoch: 25 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491598585903747		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 4.491598585903747 | validation: 4.495661818646727]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.509230318889585		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 4.509230318889585 | validation: 4.533800425917731]
	TIME [epoch: 25 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.509482161559238		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 4.509482161559238 | validation: 4.485771121776386]
	TIME [epoch: 25 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494842817519958		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 4.494842817519958 | validation: 4.4764206928642984]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484472567384508		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 4.484472567384508 | validation: 4.513423862067109]
	TIME [epoch: 25 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.524153429207084		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 4.524153429207084 | validation: 4.493449425336457]
	TIME [epoch: 25 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5022478617455794		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 4.5022478617455794 | validation: 4.51082038945823]
	TIME [epoch: 24.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485419968952676		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 4.485419968952676 | validation: 4.48432907163422]
	TIME [epoch: 25 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488130876965768		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 4.488130876965768 | validation: 4.50854036219742]
	TIME [epoch: 25 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492019464349809		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 4.492019464349809 | validation: 4.495375323838353]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.502320743479314		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 4.502320743479314 | validation: 4.499169808623657]
	TIME [epoch: 25 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5326907830057985		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 4.5326907830057985 | validation: 4.505835585324716]
	TIME [epoch: 25 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484155367081161		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 4.484155367081161 | validation: 4.494277292773087]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483723290763827		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 4.483723290763827 | validation: 4.480581165466219]
	TIME [epoch: 25 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506507635556689		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 4.506507635556689 | validation: 4.518449377618688]
	TIME [epoch: 25 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4970375478824485		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 4.4970375478824485 | validation: 4.546620973161565]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540974415026955		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 4.540974415026955 | validation: 4.507943366722023]
	TIME [epoch: 25 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501308084445673		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 4.501308084445673 | validation: 4.468963370202999]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486613394202136		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 4.486613394202136 | validation: 4.469397600499315]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496471013016301		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 4.496471013016301 | validation: 4.48842692573735]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491748234686249		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 4.491748234686249 | validation: 4.4672737714319934]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_669.pth
	Model improved!!!
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5145230116274		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 4.5145230116274 | validation: 4.481924906235795]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49538205959174		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 4.49538205959174 | validation: 4.483080955737788]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518776945203777		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 4.518776945203777 | validation: 4.4918372158634305]
	TIME [epoch: 25 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484342588473714		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 4.484342588473714 | validation: 4.503669650679484]
	TIME [epoch: 24.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489931419291391		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 4.489931419291391 | validation: 4.541067523371151]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510620988973206		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 4.510620988973206 | validation: 4.482356637364713]
	TIME [epoch: 25 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480664142065384		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 4.480664142065384 | validation: 4.471554452232175]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4974315510655325		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 4.4974315510655325 | validation: 4.490755753448179]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512096816525343		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 4.512096816525343 | validation: 4.497690921827782]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481825532713309		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 4.481825532713309 | validation: 4.487366263827772]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482271817046581		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 4.482271817046581 | validation: 4.479897323129079]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48120619142539		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 4.48120619142539 | validation: 4.496247521512328]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478935778012577		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 4.478935778012577 | validation: 4.4755183756102985]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.503915009329138		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 4.503915009329138 | validation: 4.5073670321858605]
	TIME [epoch: 25 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497913088735514		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 4.497913088735514 | validation: 4.51097832153285]
	TIME [epoch: 24.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48496309769865		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 4.48496309769865 | validation: 4.490123607367294]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49288867182713		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 4.49288867182713 | validation: 4.485530318110137]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479593271273405		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 4.479593271273405 | validation: 4.5190428311798625]
	TIME [epoch: 24.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495663631610962		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 4.495663631610962 | validation: 4.468591049970866]
	TIME [epoch: 24.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482205978278893		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 4.482205978278893 | validation: 4.527255725588956]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.523888246054338		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 4.523888246054338 | validation: 4.483066257038306]
	TIME [epoch: 25 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491791491435488		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 4.491791491435488 | validation: 4.500712682761239]
	TIME [epoch: 24.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491037635042468		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 4.491037635042468 | validation: 4.473873542685712]
	TIME [epoch: 24.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482319711334526		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 4.482319711334526 | validation: 4.476151596289125]
	TIME [epoch: 25 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47727321964129		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 4.47727321964129 | validation: 4.496465693131921]
	TIME [epoch: 24.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491579405051216		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 4.491579405051216 | validation: 4.491443348470004]
	TIME [epoch: 24.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479267643544068		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 4.479267643544068 | validation: 4.473920843014463]
	TIME [epoch: 25 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4855179081859635		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 4.4855179081859635 | validation: 4.504522929882353]
	TIME [epoch: 24.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504096351855856		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 4.504096351855856 | validation: 4.468148694532231]
	TIME [epoch: 24.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478043454348638		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 4.478043454348638 | validation: 4.4698817867908085]
	TIME [epoch: 25 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4841470403141965		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 4.4841470403141965 | validation: 4.4748437874438345]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4843438608870105		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 4.4843438608870105 | validation: 4.502474570909304]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.508316439392586		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 4.508316439392586 | validation: 4.49422611269271]
	TIME [epoch: 25 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501943891435955		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 4.501943891435955 | validation: 4.486551717605912]
	TIME [epoch: 24.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488775472625198		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 4.488775472625198 | validation: 4.482874395026397]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493623830557052		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 4.493623830557052 | validation: 4.517967651174628]
	TIME [epoch: 25 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506223798178032		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 4.506223798178032 | validation: 4.47490422265152]
	TIME [epoch: 24.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475519447682494		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 4.475519447682494 | validation: 4.495816334848261]
	TIME [epoch: 24.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484144412129309		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 4.484144412129309 | validation: 4.472998557031728]
	TIME [epoch: 25 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4824678689037745		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 4.4824678689037745 | validation: 4.482053852635366]
	TIME [epoch: 24.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4847194622061926		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 4.4847194622061926 | validation: 4.483427108215369]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479851668892754		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 4.479851668892754 | validation: 4.50284781326589]
	TIME [epoch: 25 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.507740330015806		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 4.507740330015806 | validation: 4.496224588810965]
	TIME [epoch: 24.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479053557607841		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 4.479053557607841 | validation: 4.469822851985137]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481793440602295		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 4.481793440602295 | validation: 4.490124022776055]
	TIME [epoch: 25 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.502285963953005		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 4.502285963953005 | validation: 4.487455065860224]
	TIME [epoch: 24.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477069581908717		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 4.477069581908717 | validation: 4.465611974473439]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_716.pth
	Model improved!!!
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480286963005327		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 4.480286963005327 | validation: 4.471675354024345]
	TIME [epoch: 25 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473052545592514		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 4.473052545592514 | validation: 4.489007811949649]
	TIME [epoch: 25 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4845305007784475		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 4.4845305007784475 | validation: 4.492763120674204]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486118965152175		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 4.486118965152175 | validation: 4.492669029388452]
	TIME [epoch: 25 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525720548724605		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 4.525720548724605 | validation: 4.522617353816564]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4834922756969675		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 4.4834922756969675 | validation: 4.467322327744696]
	TIME [epoch: 25 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47595834426592		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 4.47595834426592 | validation: 4.474604456873599]
	TIME [epoch: 25 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468263398887896		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 4.468263398887896 | validation: 4.473860254012227]
	TIME [epoch: 25 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476264036172504		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 4.476264036172504 | validation: 4.482342102962792]
	TIME [epoch: 25 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4832964962266395		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 4.4832964962266395 | validation: 4.466858297719175]
	TIME [epoch: 25 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486438513546546		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 4.486438513546546 | validation: 4.555274366567735]
	TIME [epoch: 25 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5077915700689015		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 4.5077915700689015 | validation: 4.475377690914429]
	TIME [epoch: 25 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473732569635484		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 4.473732569635484 | validation: 4.486278200615987]
	TIME [epoch: 25 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477028690382224		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 4.477028690382224 | validation: 4.469582518072911]
	TIME [epoch: 24.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476545779279759		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 4.476545779279759 | validation: 4.5055456710999895]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4814013571141045		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 4.4814013571141045 | validation: 4.471349776833674]
	TIME [epoch: 25 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477466561683519		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 4.477466561683519 | validation: 4.471347766268938]
	TIME [epoch: 25 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473608402314138		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 4.473608402314138 | validation: 4.475591278508906]
	TIME [epoch: 25 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4742902733784735		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 4.4742902733784735 | validation: 4.4654741073010085]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_735.pth
	Model improved!!!
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468421054094715		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 4.468421054094715 | validation: 4.4686964902932225]
	TIME [epoch: 25 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47474965215714		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 4.47474965215714 | validation: 4.468824228084629]
	TIME [epoch: 25 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467906986019186		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 4.467906986019186 | validation: 4.46889411838474]
	TIME [epoch: 25 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482400495412403		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 4.482400495412403 | validation: 4.533888626407815]
	TIME [epoch: 25 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.548212033553639		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 4.548212033553639 | validation: 4.501234364806832]
	TIME [epoch: 25 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485683701453034		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 4.485683701453034 | validation: 4.473068133186397]
	TIME [epoch: 25 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470435170258166		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 4.470435170258166 | validation: 4.471371435553299]
	TIME [epoch: 25 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477482235103439		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 4.477482235103439 | validation: 4.479247376786192]
	TIME [epoch: 25 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476821246616871		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 4.476821246616871 | validation: 4.468031798123542]
	TIME [epoch: 25 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48919545582594		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 4.48919545582594 | validation: 4.494877781883542]
	TIME [epoch: 25 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4795535288478305		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 4.4795535288478305 | validation: 4.494615196578554]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483018098246346		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 4.483018098246346 | validation: 4.476359875223294]
	TIME [epoch: 25 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480941561714083		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 4.480941561714083 | validation: 4.477147221653649]
	TIME [epoch: 25 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479224763389107		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 4.479224763389107 | validation: 4.468040989494345]
	TIME [epoch: 25 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475472269561421		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 4.475472269561421 | validation: 4.4862293406143205]
	TIME [epoch: 25 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487156264870595		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 4.487156264870595 | validation: 4.47256414823514]
	TIME [epoch: 25 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47850117580988		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 4.47850117580988 | validation: 4.4764170711907205]
	TIME [epoch: 25 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48916117420065		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 4.48916117420065 | validation: 4.501408252043912]
	TIME [epoch: 25 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498436851577103		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 4.498436851577103 | validation: 4.499699837368196]
	TIME [epoch: 25 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4805160794215055		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 4.4805160794215055 | validation: 4.484001925803542]
	TIME [epoch: 24.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491062157048493		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 4.491062157048493 | validation: 4.542430559588308]
	TIME [epoch: 25 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.516391262158068		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 4.516391262158068 | validation: 4.468426429908191]
	TIME [epoch: 25 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475867431643574		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 4.475867431643574 | validation: 4.4670994577498]
	TIME [epoch: 25 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479170597433248		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 4.479170597433248 | validation: 4.4719456885449]
	TIME [epoch: 25 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473650395033435		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 4.473650395033435 | validation: 4.488792016043521]
	TIME [epoch: 25 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488133515298301		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 4.488133515298301 | validation: 4.4726689100770365]
	TIME [epoch: 25 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471999451431238		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 4.471999451431238 | validation: 4.497074154175577]
	TIME [epoch: 25 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479401358764625		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 4.479401358764625 | validation: 4.477444403322877]
	TIME [epoch: 25 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479020702641458		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 4.479020702641458 | validation: 4.464629915622918]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_764.pth
	Model improved!!!
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4726411754177615		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 4.4726411754177615 | validation: 4.482102374218704]
	TIME [epoch: 25 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476008924571612		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 4.476008924571612 | validation: 4.50782447912916]
	TIME [epoch: 25 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489374496531684		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 4.489374496531684 | validation: 4.467739446224731]
	TIME [epoch: 24.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48945975378753		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 4.48945975378753 | validation: 4.48573304194709]
	TIME [epoch: 25 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470537674864541		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 4.470537674864541 | validation: 4.497551025943571]
	TIME [epoch: 25 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504468182493819		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 4.504468182493819 | validation: 4.4773579390818705]
	TIME [epoch: 24.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475357543988636		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 4.475357543988636 | validation: 4.46997029593217]
	TIME [epoch: 25 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47668698230654		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 4.47668698230654 | validation: 4.468241721432712]
	TIME [epoch: 25 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468929486734072		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 4.468929486734072 | validation: 4.500762048533528]
	TIME [epoch: 25 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490072191763791		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 4.490072191763791 | validation: 4.494257748378252]
	TIME [epoch: 25 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483909814789268		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 4.483909814789268 | validation: 4.483016918247505]
	TIME [epoch: 25 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476090732890926		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 4.476090732890926 | validation: 4.47506814182302]
	TIME [epoch: 25 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476445387658333		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 4.476445387658333 | validation: 4.483234143145769]
	TIME [epoch: 25 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478602898214982		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 4.478602898214982 | validation: 4.485368654333972]
	TIME [epoch: 25 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492720862140878		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 4.492720862140878 | validation: 4.501772614643001]
	TIME [epoch: 25 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4871770436087335		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 4.4871770436087335 | validation: 4.476271481011334]
	TIME [epoch: 25 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470416957682366		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 4.470416957682366 | validation: 4.4716783197496905]
	TIME [epoch: 25 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470678297523774		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 4.470678297523774 | validation: 4.477948642419029]
	TIME [epoch: 25 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489571110771866		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 4.489571110771866 | validation: 4.478606006836091]
	TIME [epoch: 25 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478801005483339		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 4.478801005483339 | validation: 4.4695471000654425]
	TIME [epoch: 25 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480173422004527		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 4.480173422004527 | validation: 4.528381505054965]
	TIME [epoch: 25 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488115959102981		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 4.488115959102981 | validation: 4.472995936938226]
	TIME [epoch: 25 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473073415189782		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 4.473073415189782 | validation: 4.4929829034522335]
	TIME [epoch: 25 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487166535121523		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 4.487166535121523 | validation: 4.493565556046841]
	TIME [epoch: 25 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486440976357941		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 4.486440976357941 | validation: 4.484809073075663]
	TIME [epoch: 25 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4852095236440075		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 4.4852095236440075 | validation: 4.481128414439222]
	TIME [epoch: 25 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4743047686759265		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 4.4743047686759265 | validation: 4.483169395401283]
	TIME [epoch: 25 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470650100627445		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 4.470650100627445 | validation: 4.469432041918455]
	TIME [epoch: 25 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4713479674094785		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 4.4713479674094785 | validation: 4.461828430782969]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_793.pth
	Model improved!!!
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47121049393542		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 4.47121049393542 | validation: 4.496395916230512]
	TIME [epoch: 24.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511872818327239		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 4.511872818327239 | validation: 4.481669508008395]
	TIME [epoch: 25 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478492794464381		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 4.478492794464381 | validation: 4.474471127316927]
	TIME [epoch: 25 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467428622852253		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 4.467428622852253 | validation: 4.48644841750251]
	TIME [epoch: 25 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486883254812549		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 4.486883254812549 | validation: 4.489221610904829]
	TIME [epoch: 25 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482688857500495		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 4.482688857500495 | validation: 4.494326096963662]
	TIME [epoch: 25 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476178188962967		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 4.476178188962967 | validation: 4.470389638430348]
	TIME [epoch: 25 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469055316651938		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 4.469055316651938 | validation: 4.470820398094561]
	TIME [epoch: 25 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469065081662357		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 4.469065081662357 | validation: 4.474053183057832]
	TIME [epoch: 25 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474455333557854		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 4.474455333557854 | validation: 4.480846918400531]
	TIME [epoch: 25 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468651876632638		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 4.468651876632638 | validation: 4.47665085134016]
	TIME [epoch: 25 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.505913601738948		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 4.505913601738948 | validation: 4.507598588505998]
	TIME [epoch: 25 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47916117351042		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 4.47916117351042 | validation: 4.489886810871979]
	TIME [epoch: 25 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486165025546472		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 4.486165025546472 | validation: 4.521739044889224]
	TIME [epoch: 25 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482581592504129		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 4.482581592504129 | validation: 4.479044963723688]
	TIME [epoch: 25 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473199293811454		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 4.473199293811454 | validation: 4.472927648214214]
	TIME [epoch: 25 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469127280688729		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 4.469127280688729 | validation: 4.461239541371551]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47306874541428		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 4.47306874541428 | validation: 4.46661269205068]
	TIME [epoch: 25 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469818408590948		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 4.469818408590948 | validation: 4.479179994998983]
	TIME [epoch: 25 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470933068308215		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 4.470933068308215 | validation: 4.507107555197213]
	TIME [epoch: 25 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4912503483149475		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 4.4912503483149475 | validation: 4.52592443929804]
	TIME [epoch: 25 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497759014063821		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 4.497759014063821 | validation: 4.468822049732211]
	TIME [epoch: 25 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46932933318681		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 4.46932933318681 | validation: 4.4681963531025835]
	TIME [epoch: 25 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469080172430155		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 4.469080172430155 | validation: 4.4809352757258]
	TIME [epoch: 25 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475107530624982		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 4.475107530624982 | validation: 4.469783549512238]
	TIME [epoch: 24.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4681418107347755		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 4.4681418107347755 | validation: 4.46684503957522]
	TIME [epoch: 25 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474409371283244		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 4.474409371283244 | validation: 4.466207198074256]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471378831859854		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 4.471378831859854 | validation: 4.493794885266407]
	TIME [epoch: 25 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473245359099833		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 4.473245359099833 | validation: 4.469024219115832]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470632625549465		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 4.470632625549465 | validation: 4.466660259956402]
	TIME [epoch: 25 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470693328573596		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 4.470693328573596 | validation: 4.48826729463348]
	TIME [epoch: 25 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471671724061419		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 4.471671724061419 | validation: 4.474986321161244]
	TIME [epoch: 25 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474938086183337		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 4.474938086183337 | validation: 4.494998868542516]
	TIME [epoch: 25 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515294777284048		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 4.515294777284048 | validation: 4.492764371121139]
	TIME [epoch: 25 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476039290148382		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 4.476039290148382 | validation: 4.484527551464492]
	TIME [epoch: 24.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484014319584648		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 4.484014319584648 | validation: 4.468754725123294]
	TIME [epoch: 25 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479542972490134		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 4.479542972490134 | validation: 4.521173530554397]
	TIME [epoch: 25 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493498450955103		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 4.493498450955103 | validation: 4.464814224415743]
	TIME [epoch: 24.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4699355710958155		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 4.4699355710958155 | validation: 4.482979110049634]
	TIME [epoch: 25 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490803464451992		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 4.490803464451992 | validation: 4.476542841869785]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476333653129984		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 4.476333653129984 | validation: 4.46966803677772]
	TIME [epoch: 25 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4703779950388505		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 4.4703779950388505 | validation: 4.461684680354327]
	TIME [epoch: 25 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472883924779931		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 4.472883924779931 | validation: 4.468700459428278]
	TIME [epoch: 25 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473956650752903		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 4.473956650752903 | validation: 4.461172660387889]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470730067648127		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 4.470730067648127 | validation: 4.498421085610287]
	TIME [epoch: 25 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4823784328854		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 4.4823784328854 | validation: 4.471050207433311]
	TIME [epoch: 25 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471699431340362		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 4.471699431340362 | validation: 4.507591726753691]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485700124628248		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 4.485700124628248 | validation: 4.465186428796698]
	TIME [epoch: 25 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480914710759253		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 4.480914710759253 | validation: 4.501981179897176]
	TIME [epoch: 25 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481127109954589		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 4.481127109954589 | validation: 4.46962174360399]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467955778738197		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 4.467955778738197 | validation: 4.465917489835942]
	TIME [epoch: 25 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474292137327865		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 4.474292137327865 | validation: 4.466873755384869]
	TIME [epoch: 25 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468166620465718		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 4.468166620465718 | validation: 4.465021860084712]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47677609096373		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 4.47677609096373 | validation: 4.459066537825236]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_847.pth
	Model improved!!!
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472397131099642		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 4.472397131099642 | validation: 4.483903495074451]
	TIME [epoch: 25 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477218929955199		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 4.477218929955199 | validation: 4.47828697579173]
	TIME [epoch: 24.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476008828088678		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 4.476008828088678 | validation: 4.473994241996642]
	TIME [epoch: 24.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470191578972131		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 4.470191578972131 | validation: 4.477885289429913]
	TIME [epoch: 25 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474388647249848		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 4.474388647249848 | validation: 4.46934514844839]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474178616092057		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 4.474178616092057 | validation: 4.481827388623851]
	TIME [epoch: 25 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471642111380463		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 4.471642111380463 | validation: 4.462589314722379]
	TIME [epoch: 25 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47904379961547		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 4.47904379961547 | validation: 4.469854209069873]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467320644772201		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 4.467320644772201 | validation: 4.475502969204826]
	TIME [epoch: 25 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4723804564149665		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 4.4723804564149665 | validation: 4.475760267092071]
	TIME [epoch: 24.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482753505997563		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 4.482753505997563 | validation: 4.509465747056671]
	TIME [epoch: 25 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506491233181862		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 4.506491233181862 | validation: 4.506037540202647]
	TIME [epoch: 25 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4807974927423615		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 4.4807974927423615 | validation: 4.464267229926804]
	TIME [epoch: 25 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468652689537741		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 4.468652689537741 | validation: 4.466695667898005]
	TIME [epoch: 24.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4644641841035835		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 4.4644641841035835 | validation: 4.480828948686081]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500755930965374		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 4.500755930965374 | validation: 4.462038481797805]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469122494793783		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 4.469122494793783 | validation: 4.475895507691463]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480669519078778		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 4.480669519078778 | validation: 4.465397718329187]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484449010287813		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 4.484449010287813 | validation: 4.481606227053302]
	TIME [epoch: 25 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4985954306166756		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 4.4985954306166756 | validation: 4.514116280271942]
	TIME [epoch: 25 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496221538066397		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 4.496221538066397 | validation: 4.465446160169782]
	TIME [epoch: 25 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469637777337555		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 4.469637777337555 | validation: 4.484139443276287]
	TIME [epoch: 25 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474679405838643		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 4.474679405838643 | validation: 4.459518980758169]
	TIME [epoch: 25 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469261185082946		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 4.469261185082946 | validation: 4.476813005163139]
	TIME [epoch: 25 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4759008735664585		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 4.4759008735664585 | validation: 4.473523744772787]
	TIME [epoch: 25 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467476095675946		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 4.467476095675946 | validation: 4.467744004256425]
	TIME [epoch: 24.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463353622891264		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 4.463353622891264 | validation: 4.4616848113601995]
	TIME [epoch: 25 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469209306929783		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 4.469209306929783 | validation: 4.474749310523181]
	TIME [epoch: 24.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467033884920859		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 4.467033884920859 | validation: 4.464010457532701]
	TIME [epoch: 24.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4720564869524475		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 4.4720564869524475 | validation: 4.46908561976834]
	TIME [epoch: 24.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465091342889155		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 4.465091342889155 | validation: 4.466638851536256]
	TIME [epoch: 25 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484030138816105		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 4.484030138816105 | validation: 4.463367274301967]
	TIME [epoch: 24.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47102643161471		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 4.47102643161471 | validation: 4.467689778380223]
	TIME [epoch: 25 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467993381142015		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 4.467993381142015 | validation: 4.497891546870058]
	TIME [epoch: 25 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486550665338971		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 4.486550665338971 | validation: 4.493921758593281]
	TIME [epoch: 24.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484004100764027		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 4.484004100764027 | validation: 4.480284349313355]
	TIME [epoch: 25 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471311094565879		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 4.471311094565879 | validation: 4.466054970614938]
	TIME [epoch: 24.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476898761408338		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 4.476898761408338 | validation: 4.468205797707899]
	TIME [epoch: 24.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46851168516535		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 4.46851168516535 | validation: 4.4629572393595005]
	TIME [epoch: 25 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46770495757791		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 4.46770495757791 | validation: 4.4644767978173485]
	TIME [epoch: 24.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467511142778074		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 4.467511142778074 | validation: 4.475192989996477]
	TIME [epoch: 24.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476547734562953		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 4.476547734562953 | validation: 4.485861194247776]
	TIME [epoch: 24.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487995772508965		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 4.487995772508965 | validation: 4.502743438752048]
	TIME [epoch: 25 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483839368007031		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 4.483839368007031 | validation: 4.470144107840538]
	TIME [epoch: 24.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472985955479858		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 4.472985955479858 | validation: 4.484526120869385]
	TIME [epoch: 25 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466462765088147		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 4.466462765088147 | validation: 4.467124068821372]
	TIME [epoch: 25 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472131181482058		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 4.472131181482058 | validation: 4.467132126623427]
	TIME [epoch: 24.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467686979874766		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 4.467686979874766 | validation: 4.483710902863976]
	TIME [epoch: 25 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471415954379259		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 4.471415954379259 | validation: 4.46769757099467]
	TIME [epoch: 25 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4624819950867245		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 4.4624819950867245 | validation: 4.472534751517568]
	TIME [epoch: 25 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489110583414442		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 4.489110583414442 | validation: 4.493730686672685]
	TIME [epoch: 24.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491330460551231		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 4.491330460551231 | validation: 4.500440644053858]
	TIME [epoch: 25 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480536097232541		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 4.480536097232541 | validation: 4.471792837958672]
	TIME [epoch: 24.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470202187956843		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 4.470202187956843 | validation: 4.481020514159322]
	TIME [epoch: 25 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476548826192857		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 4.476548826192857 | validation: 4.465995654618594]
	TIME [epoch: 25 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467001500289518		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 4.467001500289518 | validation: 4.467263780983621]
	TIME [epoch: 24.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482519480604704		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 4.482519480604704 | validation: 4.485805722326534]
	TIME [epoch: 25 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468681433524672		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 4.468681433524672 | validation: 4.474865247249889]
	TIME [epoch: 25 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473688751387215		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 4.473688751387215 | validation: 4.473283474026901]
	TIME [epoch: 24.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4788884061271785		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 4.4788884061271785 | validation: 4.483429931376967]
	TIME [epoch: 25 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469800393568493		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 4.469800393568493 | validation: 4.463007487162269]
	TIME [epoch: 25 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463624648346937		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 4.463624648346937 | validation: 4.466810700459894]
	TIME [epoch: 25 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465826479070396		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 4.465826479070396 | validation: 4.463664913546089]
	TIME [epoch: 25 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463316915458435		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 4.463316915458435 | validation: 4.4698390846478695]
	TIME [epoch: 24.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485117935078094		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 4.485117935078094 | validation: 4.50080403887832]
	TIME [epoch: 25 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.499651014014806		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 4.499651014014806 | validation: 4.507588701147835]
	TIME [epoch: 25 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49441104913509		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 4.49441104913509 | validation: 4.4693598327471395]
	TIME [epoch: 25 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467817287298698		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 4.467817287298698 | validation: 4.464261013019678]
	TIME [epoch: 24.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465372766075116		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 4.465372766075116 | validation: 4.468904297131563]
	TIME [epoch: 25 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467782484679031		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 4.467782484679031 | validation: 4.45762687453656]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_917.pth
	Model improved!!!
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473196872260942		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 4.473196872260942 | validation: 4.469517378942572]
	TIME [epoch: 24.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468963763661974		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 4.468963763661974 | validation: 4.472941635682144]
	TIME [epoch: 25 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4722481525751805		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 4.4722481525751805 | validation: 4.4745515497919826]
	TIME [epoch: 24.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490333995013015		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 4.490333995013015 | validation: 4.477360926281452]
	TIME [epoch: 24.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467911146295485		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 4.467911146295485 | validation: 4.467810001925852]
	TIME [epoch: 25 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469318490134027		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 4.469318490134027 | validation: 4.4722080705351]
	TIME [epoch: 25 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470872452644912		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 4.470872452644912 | validation: 4.469503671273781]
	TIME [epoch: 24.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465532791454594		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 4.465532791454594 | validation: 4.468230982124808]
	TIME [epoch: 25 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47121184986994		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 4.47121184986994 | validation: 4.465024708847489]
	TIME [epoch: 25 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465808182713431		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 4.465808182713431 | validation: 4.461919218059207]
	TIME [epoch: 25 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463695439142665		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 4.463695439142665 | validation: 4.465184938064501]
	TIME [epoch: 25 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473315499431786		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 4.473315499431786 | validation: 4.462715696927271]
	TIME [epoch: 25 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4722207814009245		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 4.4722207814009245 | validation: 4.4694134298052655]
	TIME [epoch: 25 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465506937016996		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 4.465506937016996 | validation: 4.468250222286956]
	TIME [epoch: 25 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47380547054918		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 4.47380547054918 | validation: 4.45954713002493]
	TIME [epoch: 25 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463971400542325		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 4.463971400542325 | validation: 4.462431431753465]
	TIME [epoch: 25 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462447314071997		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 4.462447314071997 | validation: 4.469586914826573]
	TIME [epoch: 25 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461885575533122		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 4.461885575533122 | validation: 4.464490632996346]
	TIME [epoch: 25 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46925051348593		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 4.46925051348593 | validation: 4.458677962101057]
	TIME [epoch: 24.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46711044628519		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 4.46711044628519 | validation: 4.465862045235977]
	TIME [epoch: 25 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464188142383857		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 4.464188142383857 | validation: 4.467246721288175]
	TIME [epoch: 25 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466552812879577		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 4.466552812879577 | validation: 4.484074819619457]
	TIME [epoch: 25 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477031169396718		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 4.477031169396718 | validation: 4.467914394230813]
	TIME [epoch: 24.9 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4670484732854945		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 4.4670484732854945 | validation: 4.469330479632988]
	TIME [epoch: 25 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471021056335207		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 4.471021056335207 | validation: 4.479732265743316]
	TIME [epoch: 24.9 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467354328458606		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 4.467354328458606 | validation: 4.476214161737609]
	TIME [epoch: 25 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475159512129453		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 4.475159512129453 | validation: 4.4607590219123985]
	TIME [epoch: 25 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46786209377518		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 4.46786209377518 | validation: 4.474826199083128]
	TIME [epoch: 25 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464849288948511		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 4.464849288948511 | validation: 4.4651405442647265]
	TIME [epoch: 25 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464603300175378		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 4.464603300175378 | validation: 4.452474628932997]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_947.pth
	Model improved!!!
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464449505210631		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 4.464449505210631 | validation: 4.465013057991034]
	TIME [epoch: 24.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461677528879752		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 4.461677528879752 | validation: 4.462206092511713]
	TIME [epoch: 25 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4686678975759175		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 4.4686678975759175 | validation: 4.469829895802749]
	TIME [epoch: 25 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468819164366868		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 4.468819164366868 | validation: 4.472510165850914]
	TIME [epoch: 25 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466502828044316		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 4.466502828044316 | validation: 4.47212197315483]
	TIME [epoch: 25 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471537051112626		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 4.471537051112626 | validation: 4.5159806209645]
	TIME [epoch: 25 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497969854046449		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 4.497969854046449 | validation: 4.5012572313271075]
	TIME [epoch: 25 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478961461729629		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 4.478961461729629 | validation: 4.470149179593214]
	TIME [epoch: 25 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465082507682124		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 4.465082507682124 | validation: 4.461305569385555]
	TIME [epoch: 25 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466325804756505		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 4.466325804756505 | validation: 4.475326362567722]
	TIME [epoch: 25 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463080515238343		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 4.463080515238343 | validation: 4.461826409606536]
	TIME [epoch: 25 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465397582194002		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 4.465397582194002 | validation: 4.4656852652864805]
	TIME [epoch: 25 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464767518147713		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 4.464767518147713 | validation: 4.465714783102278]
	TIME [epoch: 25 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460938754944735		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 4.460938754944735 | validation: 4.460928632272218]
	TIME [epoch: 25 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462957940599246		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 4.462957940599246 | validation: 4.471199344501764]
	TIME [epoch: 25 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467313305777617		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 4.467313305777617 | validation: 4.46932875477508]
	TIME [epoch: 25 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468639582032444		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 4.468639582032444 | validation: 4.460289178078021]
	TIME [epoch: 25 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456349228098339		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 4.456349228098339 | validation: 4.475235616863626]
	TIME [epoch: 25 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463220631165139		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 4.463220631165139 | validation: 4.464336345374846]
	TIME [epoch: 25 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468520361759849		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 4.468520361759849 | validation: 4.463396912428268]
	TIME [epoch: 25 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462192456516604		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 4.462192456516604 | validation: 4.479861915157308]
	TIME [epoch: 25 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470370767665847		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 4.470370767665847 | validation: 4.465405099604107]
	TIME [epoch: 25 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462488929254577		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 4.462488929254577 | validation: 4.477011624973291]
	TIME [epoch: 25 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471722268390181		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 4.471722268390181 | validation: 4.466882661003531]
	TIME [epoch: 25 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465344961255365		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 4.465344961255365 | validation: 4.462020411282851]
	TIME [epoch: 25 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461863504096225		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 4.461863504096225 | validation: 4.468544430013207]
	TIME [epoch: 25 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46501714901688		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 4.46501714901688 | validation: 4.464917410720281]
	TIME [epoch: 25 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461574047268529		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 4.461574047268529 | validation: 4.4677175247482195]
	TIME [epoch: 25 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46212611534607		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 4.46212611534607 | validation: 4.458813434760815]
	TIME [epoch: 25 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461160523993413		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 4.461160523993413 | validation: 4.472905818034221]
	TIME [epoch: 25 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470010820829504		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 4.470010820829504 | validation: 4.469081558663254]
	TIME [epoch: 25 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46398241509951		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 4.46398241509951 | validation: 4.4790249527652275]
	TIME [epoch: 25 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469405459753118		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 4.469405459753118 | validation: 4.471871206434907]
	TIME [epoch: 25 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462945464792911		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 4.462945464792911 | validation: 4.47258426261668]
	TIME [epoch: 25 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458718162234851		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 4.458718162234851 | validation: 4.462863723338259]
	TIME [epoch: 25 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475392316343463		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 4.475392316343463 | validation: 4.4804284027853445]
	TIME [epoch: 25 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470077993695636		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 4.470077993695636 | validation: 4.472817537521072]
	TIME [epoch: 25.1 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478465198282466		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 4.478465198282466 | validation: 4.467390540444234]
	TIME [epoch: 25 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465767911323248		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 4.465767911323248 | validation: 4.486523407408548]
	TIME [epoch: 25 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476707241634316		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 4.476707241634316 | validation: 4.459894414496715]
	TIME [epoch: 25 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461953098007925		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 4.461953098007925 | validation: 4.471812808338512]
	TIME [epoch: 25 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463416592584737		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 4.463416592584737 | validation: 4.460983394367751]
	TIME [epoch: 25 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474378123349991		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 4.474378123349991 | validation: 4.474629523321547]
	TIME [epoch: 25 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466794113118512		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 4.466794113118512 | validation: 4.470401514907604]
	TIME [epoch: 25 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4647545812635405		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 4.4647545812635405 | validation: 4.466503384729283]
	TIME [epoch: 25 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4636882683284815		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 4.4636882683284815 | validation: 4.460926093930883]
	TIME [epoch: 25 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462874465347839		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 4.462874465347839 | validation: 4.463681571345497]
	TIME [epoch: 25 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45879126270102		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 4.45879126270102 | validation: 4.4599889391764025]
	TIME [epoch: 25 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46214467465609		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 4.46214467465609 | validation: 4.479591151896738]
	TIME [epoch: 25 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464396202174155		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 4.464396202174155 | validation: 4.470083312372995]
	TIME [epoch: 25 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459985791438907		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 4.459985791438907 | validation: 4.465182477269466]
	TIME [epoch: 25 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464773847178763		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 4.464773847178763 | validation: 4.47017992314558]
	TIME [epoch: 25 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4621212675906285		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 4.4621212675906285 | validation: 4.466264593545159]
	TIME [epoch: 25 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458236008035144		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 4.458236008035144 | validation: 4.4604940065383945]
	TIME [epoch: 25 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463073312654161		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 4.463073312654161 | validation: 4.456070511393242]
	TIME [epoch: 25 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458065786537695		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 4.458065786537695 | validation: 4.457969188873618]
	TIME [epoch: 25 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457297875324265		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 4.457297875324265 | validation: 4.4609402800078355]
	TIME [epoch: 25 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470365220299991		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 4.470365220299991 | validation: 4.476197701812666]
	TIME [epoch: 25 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460910266258326		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 4.460910266258326 | validation: 4.466964237121938]
	TIME [epoch: 25 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482342075744412		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 4.482342075744412 | validation: 4.4907349098601355]
	TIME [epoch: 25 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471914073299166		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 4.471914073299166 | validation: 4.46421782213791]
	TIME [epoch: 25 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463507129379802		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 4.463507129379802 | validation: 4.4692103893057435]
	TIME [epoch: 25 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460155013731331		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 4.460155013731331 | validation: 4.456545686189206]
	TIME [epoch: 25 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4567103328446525		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 4.4567103328446525 | validation: 4.46287436091303]
	TIME [epoch: 25 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462949789525942		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 4.462949789525942 | validation: 4.467262749158812]
	TIME [epoch: 25 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470233584015463		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 4.470233584015463 | validation: 4.465445386649163]
	TIME [epoch: 25 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46347802105846		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 4.46347802105846 | validation: 4.462417888956882]
	TIME [epoch: 25 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471558607442572		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 4.471558607442572 | validation: 4.453915992753375]
	TIME [epoch: 25 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460329089513231		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 4.460329089513231 | validation: 4.459832975736438]
	TIME [epoch: 25 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463889608658425		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 4.463889608658425 | validation: 4.4610827258128785]
	TIME [epoch: 25 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458377490008974		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 4.458377490008974 | validation: 4.481567985458675]
	TIME [epoch: 25 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4828158378490235		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 4.4828158378490235 | validation: 4.490538776364658]
	TIME [epoch: 25 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469703574179852		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 4.469703574179852 | validation: 4.464731609034394]
	TIME [epoch: 25 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460625224586099		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 4.460625224586099 | validation: 4.46571091841207]
	TIME [epoch: 25 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46680161549686		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 4.46680161549686 | validation: 4.463823595733604]
	TIME [epoch: 25 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4592106851753215		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 4.4592106851753215 | validation: 4.46044714202252]
	TIME [epoch: 25 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464100424467244		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 4.464100424467244 | validation: 4.464470448194851]
	TIME [epoch: 25 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460167310657109		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 4.460167310657109 | validation: 4.466826062371005]
	TIME [epoch: 25 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472464224230222		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 4.472464224230222 | validation: 4.470855512733218]
	TIME [epoch: 25 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463567752821625		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 4.463567752821625 | validation: 4.467808492972249]
	TIME [epoch: 25 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468236209333789		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 4.468236209333789 | validation: 4.47133154283034]
	TIME [epoch: 25 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461460542353784		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 4.461460542353784 | validation: 4.464634871548612]
	TIME [epoch: 25 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461006982829373		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 4.461006982829373 | validation: 4.469721968067484]
	TIME [epoch: 25 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465253552993258		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 4.465253552993258 | validation: 4.473655732690148]
	TIME [epoch: 25 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479182010249662		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 4.479182010249662 | validation: 4.465768034244885]
	TIME [epoch: 25 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46296093312251		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 4.46296093312251 | validation: 4.469398182419329]
	TIME [epoch: 25 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461335171440257		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 4.461335171440257 | validation: 4.456268461818957]
	TIME [epoch: 25 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460093314344832		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 4.460093314344832 | validation: 4.467006317431362]
	TIME [epoch: 25 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461708923652477		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 4.461708923652477 | validation: 4.471150498365964]
	TIME [epoch: 25 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463182537013502		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 4.463182537013502 | validation: 4.453223078134724]
	TIME [epoch: 25 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457894301342268		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 4.457894301342268 | validation: 4.4586790391961]
	TIME [epoch: 25 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46543021522627		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 4.46543021522627 | validation: 4.475054887491026]
	TIME [epoch: 25 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466615342366744		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 4.466615342366744 | validation: 4.457155515277427]
	TIME [epoch: 25 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460783010461918		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 4.460783010461918 | validation: 4.467202651236814]
	TIME [epoch: 25 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459675086587396		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 4.459675086587396 | validation: 4.466183627575447]
	TIME [epoch: 25 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463291628661851		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 4.463291628661851 | validation: 4.4616086723661095]
	TIME [epoch: 25 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4621170368579115		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 4.4621170368579115 | validation: 4.468605926705811]
	TIME [epoch: 25 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465271281925882		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 4.465271281925882 | validation: 4.472423287762346]
	TIME [epoch: 25 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461356579031499		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 4.461356579031499 | validation: 4.455837053024844]
	TIME [epoch: 25 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458163291950941		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 4.458163291950941 | validation: 4.46865056163835]
	TIME [epoch: 25 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459561028574097		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 4.459561028574097 | validation: 4.4598291959737235]
	TIME [epoch: 25 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462601325658825		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 4.462601325658825 | validation: 4.4594001241376295]
	TIME [epoch: 25 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46048088381831		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 4.46048088381831 | validation: 4.469744716782255]
	TIME [epoch: 25 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463396348480311		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 4.463396348480311 | validation: 4.464627443461664]
	TIME [epoch: 25 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467384174911155		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 4.467384174911155 | validation: 4.474472464399989]
	TIME [epoch: 25 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45945847108049		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 4.45945847108049 | validation: 4.458617552499852]
	TIME [epoch: 25 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46052526960683		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 4.46052526960683 | validation: 4.460378350891504]
	TIME [epoch: 25 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468244593920035		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 4.468244593920035 | validation: 4.487105496503252]
	TIME [epoch: 25 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468991313617435		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 4.468991313617435 | validation: 4.456581001838575]
	TIME [epoch: 25 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4590816336977275		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 4.4590816336977275 | validation: 4.461747766113134]
	TIME [epoch: 25 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457061805234209		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 4.457061805234209 | validation: 4.459573561080207]
	TIME [epoch: 25 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467603784507583		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 4.467603784507583 | validation: 4.466096993081553]
	TIME [epoch: 25 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468139922868801		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 4.468139922868801 | validation: 4.478824372650684]
	TIME [epoch: 25 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463548317791176		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 4.463548317791176 | validation: 4.4627142954320345]
	TIME [epoch: 25 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457400473032029		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 4.457400473032029 | validation: 4.46452634863128]
	TIME [epoch: 25 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461840348528417		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 4.461840348528417 | validation: 4.4526887790966825]
	TIME [epoch: 25 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466992475241717		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 4.466992475241717 | validation: 4.460903193395962]
	TIME [epoch: 25 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455725411509372		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 4.455725411509372 | validation: 4.460979384468237]
	TIME [epoch: 25 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4599771375336825		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 4.4599771375336825 | validation: 4.461484053074531]
	TIME [epoch: 25 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463333239014091		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 4.463333239014091 | validation: 4.466666017193398]
	TIME [epoch: 25 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472896783776758		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 4.472896783776758 | validation: 4.472403299945482]
	TIME [epoch: 25 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4593670874733515		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 4.4593670874733515 | validation: 4.458663965789129]
	TIME [epoch: 25 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4599801266074435		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 4.4599801266074435 | validation: 4.466689313478961]
	TIME [epoch: 25 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463324254491421		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 4.463324254491421 | validation: 4.480898548119959]
	TIME [epoch: 25 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4653982408841335		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 4.4653982408841335 | validation: 4.466986247472915]
	TIME [epoch: 25 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460854644758022		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 4.460854644758022 | validation: 4.456736778195514]
	TIME [epoch: 25 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459607867964444		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 4.459607867964444 | validation: 4.450297720157283]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_1074.pth
	Model improved!!!
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4605740821427355		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 4.4605740821427355 | validation: 4.463400694311491]
	TIME [epoch: 25 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4612054749072545		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 4.4612054749072545 | validation: 4.454772381517282]
	TIME [epoch: 25 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459146247742832		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 4.459146247742832 | validation: 4.462171766150027]
	TIME [epoch: 25 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46702921123935		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 4.46702921123935 | validation: 4.473686988184867]
	TIME [epoch: 24.9 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468353480891838		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 4.468353480891838 | validation: 4.460151341972959]
	TIME [epoch: 24.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459003520332878		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 4.459003520332878 | validation: 4.467193121509857]
	TIME [epoch: 25 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458199854860615		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 4.458199854860615 | validation: 4.463479207423766]
	TIME [epoch: 24.9 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467059374783381		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 4.467059374783381 | validation: 4.471825759540261]
	TIME [epoch: 25 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471061741565602		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 4.471061741565602 | validation: 4.47920207928919]
	TIME [epoch: 24.9 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477812842193508		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 4.477812842193508 | validation: 4.471092358236636]
	TIME [epoch: 24.9 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466706443771488		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 4.466706443771488 | validation: 4.4570613314826515]
	TIME [epoch: 24.9 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46032657741442		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 4.46032657741442 | validation: 4.461402859321811]
	TIME [epoch: 24.9 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4615140881783395		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 4.4615140881783395 | validation: 4.454301388751561]
	TIME [epoch: 25 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455972899142537		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 4.455972899142537 | validation: 4.461087042154409]
	TIME [epoch: 24.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460107470582848		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 4.460107470582848 | validation: 4.461071164895678]
	TIME [epoch: 25 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459704944700911		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 4.459704944700911 | validation: 4.4599590970779195]
	TIME [epoch: 24.9 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463850486124126		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 4.463850486124126 | validation: 4.448428171090572]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_1091.pth
	Model improved!!!
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462361153943293		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 4.462361153943293 | validation: 4.456543948297849]
	TIME [epoch: 25 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45773118883255		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 4.45773118883255 | validation: 4.465156777783608]
	TIME [epoch: 24.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458594861428089		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 4.458594861428089 | validation: 4.467981862817601]
	TIME [epoch: 24.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463569543848547		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 4.463569543848547 | validation: 4.467418817170424]
	TIME [epoch: 24.9 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462701202733053		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 4.462701202733053 | validation: 4.450617524350541]
	TIME [epoch: 24.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456254635217977		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 4.456254635217977 | validation: 4.473566115086483]
	TIME [epoch: 24.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469313226817583		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 4.469313226817583 | validation: 4.476039197104779]
	TIME [epoch: 24.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462669168017134		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 4.462669168017134 | validation: 4.458301917271465]
	TIME [epoch: 24.9 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456657634252422		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 4.456657634252422 | validation: 4.457139169219513]
	TIME [epoch: 24.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461416037610837		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 4.461416037610837 | validation: 4.466938102618937]
	TIME [epoch: 24.9 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462410691035871		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 4.462410691035871 | validation: 4.455158159452221]
	TIME [epoch: 24.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457451132539837		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 4.457451132539837 | validation: 4.458531693832109]
	TIME [epoch: 24.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46399218262195		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 4.46399218262195 | validation: 4.468610726508447]
	TIME [epoch: 24.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466637483822342		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 4.466637483822342 | validation: 4.45418013605424]
	TIME [epoch: 24.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460869567314601		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 4.460869567314601 | validation: 4.458997534003658]
	TIME [epoch: 24.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46446908262458		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 4.46446908262458 | validation: 4.465318763375328]
	TIME [epoch: 24.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463491840150126		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 4.463491840150126 | validation: 4.462966491267771]
	TIME [epoch: 24.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461054562023843		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 4.461054562023843 | validation: 4.477419741608792]
	TIME [epoch: 24.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467307068533909		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 4.467307068533909 | validation: 4.464407846481977]
	TIME [epoch: 25 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4587517313599445		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 4.4587517313599445 | validation: 4.465275241415212]
	TIME [epoch: 24.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460019428585324		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 4.460019428585324 | validation: 4.458326172007365]
	TIME [epoch: 25 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458024098122975		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 4.458024098122975 | validation: 4.457264202902013]
	TIME [epoch: 24.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458834278065515		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 4.458834278065515 | validation: 4.465078577148717]
	TIME [epoch: 24.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476151097069699		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 4.476151097069699 | validation: 4.471773669381691]
	TIME [epoch: 24.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463863584042971		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 4.463863584042971 | validation: 4.449166458130858]
	TIME [epoch: 24.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4577763966893285		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 4.4577763966893285 | validation: 4.451091875982298]
	TIME [epoch: 24.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461138104807406		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 4.461138104807406 | validation: 4.458389116267675]
	TIME [epoch: 24.9 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4569441358888096		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 4.4569441358888096 | validation: 4.4616510202129245]
	TIME [epoch: 24.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463032095786279		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 4.463032095786279 | validation: 4.454550950209186]
	TIME [epoch: 24.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458187907240983		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 4.458187907240983 | validation: 4.454700362934116]
	TIME [epoch: 24.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457741797468085		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 4.457741797468085 | validation: 4.453415938721162]
	TIME [epoch: 24.9 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456795412819773		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 4.456795412819773 | validation: 4.45639360904316]
	TIME [epoch: 25 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46213537975724		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 4.46213537975724 | validation: 4.462250090638003]
	TIME [epoch: 24.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4615786332325085		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 4.4615786332325085 | validation: 4.459955268122421]
	TIME [epoch: 24.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459417784779911		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 4.459417784779911 | validation: 4.457488506917299]
	TIME [epoch: 24.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461038128870965		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 4.461038128870965 | validation: 4.458451352909683]
	TIME [epoch: 24.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463433399151899		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 4.463433399151899 | validation: 4.469116051867029]
	TIME [epoch: 24.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465516751490837		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 4.465516751490837 | validation: 4.45929334507303]
	TIME [epoch: 24.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4573254594104394		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 4.4573254594104394 | validation: 4.4558355004543575]
	TIME [epoch: 24.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461835757021248		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 4.461835757021248 | validation: 4.459767774010447]
	TIME [epoch: 24.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46712501481509		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 4.46712501481509 | validation: 4.461580613023841]
	TIME [epoch: 24.9 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459337888995807		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 4.459337888995807 | validation: 4.462197239426685]
	TIME [epoch: 24.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459408296489304		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 4.459408296489304 | validation: 4.467418268690777]
	TIME [epoch: 25 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466066599470361		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 4.466066599470361 | validation: 4.474298943478321]
	TIME [epoch: 25 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472314905224274		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 4.472314905224274 | validation: 4.462398122383093]
	TIME [epoch: 25 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459662392179518		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 4.459662392179518 | validation: 4.459017492181257]
	TIME [epoch: 25 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4629996685378375		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 4.4629996685378375 | validation: 4.469597148489599]
	TIME [epoch: 25 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468462667714659		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 4.468462667714659 | validation: 4.47738269275181]
	TIME [epoch: 25 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464600199261546		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 4.464600199261546 | validation: 4.461016274430671]
	TIME [epoch: 25 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456887390705252		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 4.456887390705252 | validation: 4.45906065375058]
	TIME [epoch: 25 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457016041992807		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 4.457016041992807 | validation: 4.456217341051406]
	TIME [epoch: 25 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4560338880661154		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 4.4560338880661154 | validation: 4.459799817134175]
	TIME [epoch: 25 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462941897146587		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 4.462941897146587 | validation: 4.479875825008064]
	TIME [epoch: 24.9 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475139931308915		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 4.475139931308915 | validation: 4.471729281658268]
	TIME [epoch: 24.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461350022849915		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 4.461350022849915 | validation: 4.462726693293463]
	TIME [epoch: 24.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4556157018696805		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 4.4556157018696805 | validation: 4.459798268843563]
	TIME [epoch: 24.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458619455823602		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 4.458619455823602 | validation: 4.463250935799352]
	TIME [epoch: 24.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461182051912337		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 4.461182051912337 | validation: 4.464527733317984]
	TIME [epoch: 25 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463264061996421		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 4.463264061996421 | validation: 4.460343032648305]
	TIME [epoch: 25 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456690430154193		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 4.456690430154193 | validation: 4.45868880295461]
	TIME [epoch: 24.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456295448084871		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 4.456295448084871 | validation: 4.465455377346214]
	TIME [epoch: 24.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465014924462515		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 4.465014924462515 | validation: 4.45709546724983]
	TIME [epoch: 24.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460080624790958		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 4.460080624790958 | validation: 4.462068898650631]
	TIME [epoch: 24.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4549720096810805		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 4.4549720096810805 | validation: 4.457741820319621]
	TIME [epoch: 24.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460136593906531		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 4.460136593906531 | validation: 4.461005969745809]
	TIME [epoch: 24.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456836865372502		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 4.456836865372502 | validation: 4.471542412102089]
	TIME [epoch: 24.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459019672006071		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 4.459019672006071 | validation: 4.460368266347333]
	TIME [epoch: 24.9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453730328277786		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 4.453730328277786 | validation: 4.460224715024345]
	TIME [epoch: 24.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462550668556719		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 4.462550668556719 | validation: 4.457628224714468]
	TIME [epoch: 25 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453256276218784		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 4.453256276218784 | validation: 4.453336220237296]
	TIME [epoch: 25 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456123207919945		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 4.456123207919945 | validation: 4.471740889351509]
	TIME [epoch: 25 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459118704075271		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 4.459118704075271 | validation: 4.469822742034378]
	TIME [epoch: 25 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456278476078635		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 4.456278476078635 | validation: 4.456890123479411]
	TIME [epoch: 24.9 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456200258665424		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 4.456200258665424 | validation: 4.455602310239262]
	TIME [epoch: 25 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454137206011934		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 4.454137206011934 | validation: 4.453584349718675]
	TIME [epoch: 25 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459779111451662		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 4.459779111451662 | validation: 4.458637705353867]
	TIME [epoch: 25 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459068204142051		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 4.459068204142051 | validation: 4.459470673276713]
	TIME [epoch: 25 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458581483611302		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 4.458581483611302 | validation: 4.461531364453613]
	TIME [epoch: 24.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463782950102139		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 4.463782950102139 | validation: 4.4518992616513495]
	TIME [epoch: 24.9 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457208107475822		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 4.457208107475822 | validation: 4.457557274204298]
	TIME [epoch: 25 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459342600063282		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 4.459342600063282 | validation: 4.46380225848634]
	TIME [epoch: 24.9 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45581681424261		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 4.45581681424261 | validation: 4.462398833690354]
	TIME [epoch: 24.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457920708525675		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 4.457920708525675 | validation: 4.464083874450604]
	TIME [epoch: 24.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462452944056713		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 4.462452944056713 | validation: 4.462076352800262]
	TIME [epoch: 24.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467359899869557		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 4.467359899869557 | validation: 4.477642209850707]
	TIME [epoch: 24.9 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459855902316457		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 4.459855902316457 | validation: 4.461197135546228]
	TIME [epoch: 24.9 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456515640179406		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 4.456515640179406 | validation: 4.463002898974377]
	TIME [epoch: 24.9 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455641918713553		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 4.455641918713553 | validation: 4.4675565124137355]
	TIME [epoch: 24.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46281509930941		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 4.46281509930941 | validation: 4.458910178559372]
	TIME [epoch: 24.9 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4559584815326705		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 4.4559584815326705 | validation: 4.463345933279283]
	TIME [epoch: 24.9 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464946866939829		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 4.464946866939829 | validation: 4.467097946816556]
	TIME [epoch: 24.9 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46185924489717		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 4.46185924489717 | validation: 4.458075584967042]
	TIME [epoch: 24.9 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457965374242765		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 4.457965374242765 | validation: 4.454995268633481]
	TIME [epoch: 24.9 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457180597502166		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 4.457180597502166 | validation: 4.460927662269801]
	TIME [epoch: 24.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459308377140603		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 4.459308377140603 | validation: 4.46550320607164]
	TIME [epoch: 24.9 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458400384537911		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 4.458400384537911 | validation: 4.456319070763903]
	TIME [epoch: 24.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45554366024334		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 4.45554366024334 | validation: 4.461877634345493]
	TIME [epoch: 24.9 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459903287923765		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 4.459903287923765 | validation: 4.454585906885332]
	TIME [epoch: 24.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458437920131164		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 4.458437920131164 | validation: 4.457279121923663]
	TIME [epoch: 24.9 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4547464461661646		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 4.4547464461661646 | validation: 4.457241940732714]
	TIME [epoch: 24.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458736803490239		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 4.458736803490239 | validation: 4.45529433262565]
	TIME [epoch: 24.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45674696080925		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 4.45674696080925 | validation: 4.460979235753923]
	TIME [epoch: 25 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457931093314016		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 4.457931093314016 | validation: 4.4594841586728515]
	TIME [epoch: 24.9 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456286791252131		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 4.456286791252131 | validation: 4.467905990797399]
	TIME [epoch: 24.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460491185544115		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 4.460491185544115 | validation: 4.4608606574559655]
	TIME [epoch: 24.9 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457390426264754		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 4.457390426264754 | validation: 4.459682997774474]
	TIME [epoch: 24.9 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45988737605005		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 4.45988737605005 | validation: 4.463129997687651]
	TIME [epoch: 24.9 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46202423411704		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 4.46202423411704 | validation: 4.465306892345577]
	TIME [epoch: 25 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455014258259156		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 4.455014258259156 | validation: 4.463342183829148]
	TIME [epoch: 24.9 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45840666889163		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 4.45840666889163 | validation: 4.456809706967356]
	TIME [epoch: 24.9 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457812533464923		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 4.457812533464923 | validation: 4.472250604025079]
	TIME [epoch: 24.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462162994524493		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 4.462162994524493 | validation: 4.4608550958805875]
	TIME [epoch: 24.9 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462963485863785		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 4.462963485863785 | validation: 4.469039957307925]
	TIME [epoch: 24.9 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462129781225348		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 4.462129781225348 | validation: 4.458805762224384]
	TIME [epoch: 24.9 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454196354242181		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 4.454196354242181 | validation: 4.462260388712718]
	TIME [epoch: 24.9 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460442564554355		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 4.460442564554355 | validation: 4.4617468254041]
	TIME [epoch: 24.9 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459139371857515		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 4.459139371857515 | validation: 4.461627056488068]
	TIME [epoch: 25 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456006736740708		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 4.456006736740708 | validation: 4.472817515075106]
	TIME [epoch: 25 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464234328443574		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 4.464234328443574 | validation: 4.458502841140101]
	TIME [epoch: 25 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456901824734406		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 4.456901824734406 | validation: 4.459424454381826]
	TIME [epoch: 25 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460501643421155		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 4.460501643421155 | validation: 4.456806599690335]
	TIME [epoch: 25 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455172153852614		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 4.455172153852614 | validation: 4.46176703911238]
	TIME [epoch: 25 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468099275437954		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 4.468099275437954 | validation: 4.472917181567314]
	TIME [epoch: 24.9 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463675265709432		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 4.463675265709432 | validation: 4.462786051651333]
	TIME [epoch: 25 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455711984203763		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 4.455711984203763 | validation: 4.462818656352954]
	TIME [epoch: 25 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459321652449182		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 4.459321652449182 | validation: 4.461381900747047]
	TIME [epoch: 24.9 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454564187443394		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 4.454564187443394 | validation: 4.456194916384548]
	TIME [epoch: 24.9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45907100650932		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 4.45907100650932 | validation: 4.456554342064709]
	TIME [epoch: 24.9 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451686252147683		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 4.451686252147683 | validation: 4.456672414136798]
	TIME [epoch: 25 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45718779589108		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 4.45718779589108 | validation: 4.459382730716839]
	TIME [epoch: 24.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461658112890293		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 4.461658112890293 | validation: 4.460795018920785]
	TIME [epoch: 24.9 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459977260970481		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 4.459977260970481 | validation: 4.4576608154442]
	TIME [epoch: 25 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459346364299863		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 4.459346364299863 | validation: 4.460331295427512]
	TIME [epoch: 24.9 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4588038586820735		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 4.4588038586820735 | validation: 4.454078032329849]
	TIME [epoch: 25 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4567032892447624		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 4.4567032892447624 | validation: 4.4547618164838285]
	TIME [epoch: 24.9 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455674963364472		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 4.455674963364472 | validation: 4.459697756165867]
	TIME [epoch: 24.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456435595991846		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 4.456435595991846 | validation: 4.450875003017707]
	TIME [epoch: 25 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455368435167906		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 4.455368435167906 | validation: 4.459234209505645]
	TIME [epoch: 24.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45519858508375		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 4.45519858508375 | validation: 4.454207702177197]
	TIME [epoch: 24.9 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460739157771681		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 4.460739157771681 | validation: 4.4604802939408055]
	TIME [epoch: 25 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46366268871174		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 4.46366268871174 | validation: 4.456451210200055]
	TIME [epoch: 24.9 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455102883864839		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 4.455102883864839 | validation: 4.458725570672093]
	TIME [epoch: 25 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457273824380333		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 4.457273824380333 | validation: 4.461205414527211]
	TIME [epoch: 25 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454962250216269		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 4.454962250216269 | validation: 4.4629660468730235]
	TIME [epoch: 24.9 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457202396193405		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 4.457202396193405 | validation: 4.47109226265561]
	TIME [epoch: 25 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468233515338303		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 4.468233515338303 | validation: 4.454124718057406]
	TIME [epoch: 25 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464364453409303		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 4.464364453409303 | validation: 4.456605917521625]
	TIME [epoch: 25 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4637643596353325		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 4.4637643596353325 | validation: 4.458851144433001]
	TIME [epoch: 24.9 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4584756750891055		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 4.4584756750891055 | validation: 4.447430997593478]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r4_20240310_060952/states/model_tr_study206_1240.pth
	Model improved!!!
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459221282993418		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 4.459221282993418 | validation: 4.464659210890676]
	TIME [epoch: 24.9 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461985175640486		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 4.461985175640486 | validation: 4.4627310110191045]
	TIME [epoch: 25 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4603797820401265		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 4.4603797820401265 | validation: 4.455479921430485]
	TIME [epoch: 25 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466350163640129		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 4.466350163640129 | validation: 4.468884155870106]
	TIME [epoch: 24.9 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465735584483346		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 4.465735584483346 | validation: 4.4577103773783575]
	TIME [epoch: 24.9 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457010382452181		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 4.457010382452181 | validation: 4.450412677360251]
	TIME [epoch: 24.9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455456148615273		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 4.455456148615273 | validation: 4.457479306842027]
	TIME [epoch: 24.9 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457309092215093		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 4.457309092215093 | validation: 4.4554071547707155]
	TIME [epoch: 25 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45748279562845		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 4.45748279562845 | validation: 4.451058838884246]
	TIME [epoch: 24.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457465589111098		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 4.457465589111098 | validation: 4.46245481614632]
	TIME [epoch: 25 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458402234495538		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 4.458402234495538 | validation: 4.457131978238514]
	TIME [epoch: 24.9 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4566397312110135		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 4.4566397312110135 | validation: 4.456449289168926]
	TIME [epoch: 25 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455202322669862		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 4.455202322669862 | validation: 4.461878863744538]
	TIME [epoch: 24.9 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456267624863882		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 4.456267624863882 | validation: 4.466614066538515]
	TIME [epoch: 24.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461889584728041		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 4.461889584728041 | validation: 4.46094510729933]
	TIME [epoch: 25 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464363237891073		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 4.464363237891073 | validation: 4.474697749920661]
	TIME [epoch: 25 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461821706011465		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 4.461821706011465 | validation: 4.466826070529902]
	TIME [epoch: 24.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463352190666125		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 4.463352190666125 | validation: 4.467724990882501]
	TIME [epoch: 24.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461665824570311		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 4.461665824570311 | validation: 4.466403054310209]
	TIME [epoch: 25 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456661370037521		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 4.456661370037521 | validation: 4.457337057516399]
	TIME [epoch: 24.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455140823756889		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 4.455140823756889 | validation: 4.454127878485514]
	TIME [epoch: 25 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456302378720169		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 4.456302378720169 | validation: 4.460949521523317]
	TIME [epoch: 24.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460385499958922		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 4.460385499958922 | validation: 4.459933616168768]
	TIME [epoch: 24.9 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46071827599407		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 4.46071827599407 | validation: 4.451694211216709]
	TIME [epoch: 24.9 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4593708468560775		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 4.4593708468560775 | validation: 4.455806605990199]
	TIME [epoch: 25 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456684930776493		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 4.456684930776493 | validation: 4.45646077449225]
	TIME [epoch: 25 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4574920567922875		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 4.4574920567922875 | validation: 4.45827806827246]
	TIME [epoch: 25.1 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4584433081929165		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 4.4584433081929165 | validation: 4.457081044653353]
	TIME [epoch: 25 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457110238859893		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 4.457110238859893 | validation: 4.453226886877791]
	TIME [epoch: 25.1 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458193993071841		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 4.458193993071841 | validation: 4.454570878642442]
	TIME [epoch: 25.1 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45785949035607		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 4.45785949035607 | validation: 4.464679101547354]
	TIME [epoch: 25 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461443066756028		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 4.461443066756028 | validation: 4.456434479767142]
	TIME [epoch: 25 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4582143848689455		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 4.4582143848689455 | validation: 4.459220010002092]
	TIME [epoch: 25 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45194610431486		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 4.45194610431486 | validation: 4.457106448414079]
	TIME [epoch: 25.1 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454581887420888		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 4.454581887420888 | validation: 4.455907305444116]
	TIME [epoch: 24.9 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4540894114903224		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 4.4540894114903224 | validation: 4.451931483175397]
	TIME [epoch: 25 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45653633896296		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 4.45653633896296 | validation: 4.457106181889928]
	TIME [epoch: 25 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459832793396808		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 4.459832793396808 | validation: 4.464246684165155]
	TIME [epoch: 25 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454581083415846		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 4.454581083415846 | validation: 4.4587102132887155]
	TIME [epoch: 25 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4599823756581		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 4.4599823756581 | validation: 4.458554140697491]
	TIME [epoch: 25 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455015694245563		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 4.455015694245563 | validation: 4.452901332175601]
	TIME [epoch: 25 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455012160065369		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 4.455012160065369 | validation: 4.463886971423466]
	TIME [epoch: 25 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457281500556248		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 4.457281500556248 | validation: 4.463492221264672]
	TIME [epoch: 25 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458461595149323		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 4.458461595149323 | validation: 4.454387598685964]
	TIME [epoch: 25 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457915952475004		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 4.457915952475004 | validation: 4.455799365417023]
	TIME [epoch: 25 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457453753206746		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 4.457453753206746 | validation: 4.456782522706403]
	TIME [epoch: 25 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455375372217161		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 4.455375372217161 | validation: 4.457562909778779]
	TIME [epoch: 25 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454949736257896		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 4.454949736257896 | validation: 4.451770933613294]
	TIME [epoch: 25 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455579574325698		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 4.455579574325698 | validation: 4.451557865786641]
	TIME [epoch: 25 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452144678405613		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 4.452144678405613 | validation: 4.456196829092394]
	TIME [epoch: 25 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460848830077374		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 4.460848830077374 | validation: 4.456621843688378]
	TIME [epoch: 25 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454666118044444		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 4.454666118044444 | validation: 4.453124798713169]
	TIME [epoch: 25.2 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459090663787858		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 4.459090663787858 | validation: 4.455071486767377]
	TIME [epoch: 25 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454567446024811		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 4.454567446024811 | validation: 4.450184084237929]
	TIME [epoch: 25 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4535191881578005		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 4.4535191881578005 | validation: 4.456547935381819]
	TIME [epoch: 25 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457412643050559		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 4.457412643050559 | validation: 4.454822895629004]
	TIME [epoch: 25 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454910080977657		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 4.454910080977657 | validation: 4.459394082247094]
	TIME [epoch: 25.1 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459174268851026		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 4.459174268851026 | validation: 4.459776050345472]
	TIME [epoch: 25 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4587587085404055		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 4.4587587085404055 | validation: 4.456428489998619]
	TIME [epoch: 25 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454467830383624		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 4.454467830383624 | validation: 4.459746758788575]
	TIME [epoch: 25 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457159631911382		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 4.457159631911382 | validation: 4.461912022159788]
	TIME [epoch: 25.2 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460765403554819		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 4.460765403554819 | validation: 4.460819150657078]
	TIME [epoch: 25 sec]
EPOCH 1303/2000:
	Training over batches...
