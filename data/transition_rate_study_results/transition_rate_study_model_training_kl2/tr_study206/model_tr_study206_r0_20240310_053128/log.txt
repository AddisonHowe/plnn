Args:
Namespace(name='model_tr_study206', outdir='out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0', training_data='data/transition_rate_studies/tr_study206/tr_study206_training/r0', validation_data='data/transition_rate_studies/tr_study206/tr_study206_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2670855229

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.292900614403967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.292900614403967 | validation: 13.016745489708908]
	TIME [epoch: 125 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.168755094297829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.168755094297829 | validation: 10.930691185158116]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.941982407298344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.941982407298344 | validation: 10.745305443477013]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.543032455822509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.543032455822509 | validation: 10.95549790345795]
	TIME [epoch: 28 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.338481250135484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.338481250135484 | validation: 11.574830386350163]
	TIME [epoch: 27.9 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.140802686095462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.140802686095462 | validation: 10.575832106820608]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.3985298399769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.3985298399769 | validation: 7.247077657655958]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.554922450906851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.554922450906851 | validation: 7.9001543294784895]
	TIME [epoch: 28 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1052412231115305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1052412231115305 | validation: 4.768106302650333]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.904693151123311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.904693151123311 | validation: 4.843996127252784]
	TIME [epoch: 28 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.264273709603895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.264273709603895 | validation: 5.44311813034168]
	TIME [epoch: 27.9 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.63477889714067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.63477889714067 | validation: 4.7517936144380695]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.436831592652369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.436831592652369 | validation: 4.586825642942469]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.460224209495786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.460224209495786 | validation: 4.843733439637654]
	TIME [epoch: 28 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.550818704692358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.550818704692358 | validation: 4.808292196895085]
	TIME [epoch: 28 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.492866088389316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.492866088389316 | validation: 4.692758884481995]
	TIME [epoch: 28 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2096682785422725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2096682785422725 | validation: 5.396597509722187]
	TIME [epoch: 27.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.307873335227272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.307873335227272 | validation: 4.431645650488604]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.900663278998385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.900663278998385 | validation: 4.575313483602771]
	TIME [epoch: 27.9 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.563715241158334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.563715241158334 | validation: 4.672935886796031]
	TIME [epoch: 27.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.06695300432664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.06695300432664 | validation: 6.722828964270633]
	TIME [epoch: 28 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.802001071841744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.802001071841744 | validation: 5.192793596081946]
	TIME [epoch: 28 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.216603211195254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.216603211195254 | validation: 4.838681710282166]
	TIME [epoch: 27.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.253490791499854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.253490791499854 | validation: 4.640518315281454]
	TIME [epoch: 28 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.172156784788785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.172156784788785 | validation: 4.665016460057117]
	TIME [epoch: 27.9 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1745002244274145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1745002244274145 | validation: 4.3924747995616835]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.273158057521271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.273158057521271 | validation: 4.346293971485402]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.036359535768229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.036359535768229 | validation: 5.2494080248547]
	TIME [epoch: 27.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.226080795486927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.226080795486927 | validation: 4.499423833311965]
	TIME [epoch: 27.9 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.207396865573476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.207396865573476 | validation: 4.9625292252371125]
	TIME [epoch: 27.9 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.111868687027178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.111868687027178 | validation: 4.475250648415265]
	TIME [epoch: 27.9 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.297898652105833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.297898652105833 | validation: 4.608557450780304]
	TIME [epoch: 28 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.932034411213293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.932034411213293 | validation: 4.28366627102286]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.063432136336779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.063432136336779 | validation: 5.403841153873758]
	TIME [epoch: 27.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.12873811229767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.12873811229767 | validation: 4.6490074029400095]
	TIME [epoch: 27.9 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.03180993176753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.03180993176753 | validation: 4.144027487564715]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.413315833509071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.413315833509071 | validation: 5.307733308342249]
	TIME [epoch: 27.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.175695787618774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.175695787618774 | validation: 4.123818241884295]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.187276985875407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.187276985875407 | validation: 4.359485640847663]
	TIME [epoch: 28 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.07898016647633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.07898016647633 | validation: 4.611592747671581]
	TIME [epoch: 27.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.015226066597781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.015226066597781 | validation: 4.7779233379291774]
	TIME [epoch: 28 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.004727133923139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.004727133923139 | validation: 4.385257405453695]
	TIME [epoch: 28 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.97375965056688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.97375965056688 | validation: 4.159286354788983]
	TIME [epoch: 27.9 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.047883597680969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.047883597680969 | validation: 4.7446176007150385]
	TIME [epoch: 27.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.026211810939298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.026211810939298 | validation: 4.705793236272956]
	TIME [epoch: 27.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9135787362439185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9135787362439185 | validation: 5.857518147415986]
	TIME [epoch: 28 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.307207940436964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.307207940436964 | validation: 4.569398744363675]
	TIME [epoch: 27.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.935283033841617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.935283033841617 | validation: 4.4112474208275225]
	TIME [epoch: 27.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.809402322184768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.809402322184768 | validation: 4.081812381959225]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.876269971409025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.876269971409025 | validation: 5.358407062151457]
	TIME [epoch: 28 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.058674146841137		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.058674146841137 | validation: 4.210758820999634]
	TIME [epoch: 28 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.840232749493285		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.840232749493285 | validation: 4.537091559779289]
	TIME [epoch: 27.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7446038639084565		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.7446038639084565 | validation: 3.9318996355680396]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.885779168445421		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.885779168445421 | validation: 4.2568023506729435]
	TIME [epoch: 27.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.611497480011058		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.611497480011058 | validation: 3.9252680468564067]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.925635838336234		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.925635838336234 | validation: 4.146377495102464]
	TIME [epoch: 27.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.578857164238756		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.578857164238756 | validation: 3.8480876826837913]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.809803474271733		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.809803474271733 | validation: 4.456917912288727]
	TIME [epoch: 28 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8292956581906825		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.8292956581906825 | validation: 4.7667713509798295]
	TIME [epoch: 28 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.982627636890884		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.982627636890884 | validation: 3.9107805932955944]
	TIME [epoch: 28 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.751254246092621		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.751254246092621 | validation: 4.055402644806391]
	TIME [epoch: 28 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.557909583256106		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.557909583256106 | validation: 4.197884049024135]
	TIME [epoch: 28 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.815178407485773		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.815178407485773 | validation: 3.8828595981203797]
	TIME [epoch: 27.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525101445845234		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.525101445845234 | validation: 4.44801663206508]
	TIME [epoch: 28 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.763974876118646		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.763974876118646 | validation: 4.070596910254454]
	TIME [epoch: 28 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.857798698981507		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.857798698981507 | validation: 3.956812540723412]
	TIME [epoch: 28 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.588404200876669		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.588404200876669 | validation: 4.40660078345622]
	TIME [epoch: 28 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.882465794361618		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.882465794361618 | validation: 4.2714544862684685]
	TIME [epoch: 28 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.559431539461192		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.559431539461192 | validation: 5.010279345208012]
	TIME [epoch: 27.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.815013078305672		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.815013078305672 | validation: 4.004637028928661]
	TIME [epoch: 28 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.692665749150168		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.692665749150168 | validation: 4.054147417288922]
	TIME [epoch: 28 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.691653406512506		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.691653406512506 | validation: 4.0173045955473]
	TIME [epoch: 28 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.630043626691499		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.630043626691499 | validation: 3.8415668386331685]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510187665419828		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.510187665419828 | validation: 4.286088385614129]
	TIME [epoch: 28 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.670854202268986		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.670854202268986 | validation: 3.798475143624163]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.425301742691826		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.425301742691826 | validation: 4.2621486460506794]
	TIME [epoch: 28 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.735012487954076		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.735012487954076 | validation: 3.7297690436492816]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518349134580272		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.518349134580272 | validation: 3.9399958885773767]
	TIME [epoch: 28 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472610870317174		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.472610870317174 | validation: 3.658330965290417]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7824050669959135		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.7824050669959135 | validation: 3.841160962940589]
	TIME [epoch: 28 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.402394975787574		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.402394975787574 | validation: 4.409944594661944]
	TIME [epoch: 28 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487346436170112		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.487346436170112 | validation: 4.240744783449083]
	TIME [epoch: 28 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.686213317663642		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.686213317663642 | validation: 4.344651318285938]
	TIME [epoch: 28 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.618019155817079		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.618019155817079 | validation: 4.124449040028982]
	TIME [epoch: 28 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.840497372995722		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.840497372995722 | validation: 4.710856394492655]
	TIME [epoch: 28 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.670329045196272		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.670329045196272 | validation: 3.735572565435563]
	TIME [epoch: 28 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.383326613286541		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.383326613286541 | validation: 3.8215614764535366]
	TIME [epoch: 28 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.60943360143193		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.60943360143193 | validation: 3.886899810956178]
	TIME [epoch: 28 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6281276472604125		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.6281276472604125 | validation: 4.229283618490242]
	TIME [epoch: 28 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48006336639355		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.48006336639355 | validation: 4.287526223503826]
	TIME [epoch: 28 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.526023451755651		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.526023451755651 | validation: 3.6417822238110804]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.331583436043692		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.331583436043692 | validation: 3.794817810206702]
	TIME [epoch: 28 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.820954478304853		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.820954478304853 | validation: 3.6765922003277156]
	TIME [epoch: 28 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.524991921565214		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.524991921565214 | validation: 3.6757916266908968]
	TIME [epoch: 28 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.446624762222686		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.446624762222686 | validation: 4.177353421099946]
	TIME [epoch: 28 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.569285995344261		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.569285995344261 | validation: 4.193416751954818]
	TIME [epoch: 28 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4136679840845225		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.4136679840845225 | validation: 4.063352712203384]
	TIME [epoch: 28 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.422068607084598		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 4.422068607084598 | validation: 3.616878201831692]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.595350935721148		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 4.595350935721148 | validation: 3.8299643625702777]
	TIME [epoch: 28 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.343837799558796		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.343837799558796 | validation: 3.723408266482346]
	TIME [epoch: 28 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.407143825736293		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 4.407143825736293 | validation: 4.517228398733174]
	TIME [epoch: 27.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.565425139095982		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.565425139095982 | validation: 3.7987130350232405]
	TIME [epoch: 28 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.382067275220395		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.382067275220395 | validation: 4.120355656928527]
	TIME [epoch: 28 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464602508550962		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.464602508550962 | validation: 4.0541266154078]
	TIME [epoch: 27.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.574870218817767		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 4.574870218817767 | validation: 3.823437410598911]
	TIME [epoch: 28 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3145018837526665		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.3145018837526665 | validation: 3.8100220020503888]
	TIME [epoch: 28 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518630292840611		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 4.518630292840611 | validation: 3.7630594759944427]
	TIME [epoch: 27.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3846947313253395		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.3846947313253395 | validation: 3.5898409225722516]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.553799732762701		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.553799732762701 | validation: 3.5825968067730516]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.324193784564129		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 4.324193784564129 | validation: 4.036987747116382]
	TIME [epoch: 27.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4334733815374054		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 4.4334733815374054 | validation: 3.977131384876131]
	TIME [epoch: 28 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.353716281262198		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 4.353716281262198 | validation: 3.8626639195010344]
	TIME [epoch: 28 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.430033046194105		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 4.430033046194105 | validation: 3.616734044349665]
	TIME [epoch: 27.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3174721053236		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.3174721053236 | validation: 3.9149868629076865]
	TIME [epoch: 28 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.449537434097438		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.449537434097438 | validation: 3.903126364832514]
	TIME [epoch: 27.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.384407771539012		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.384407771539012 | validation: 3.659717724585763]
	TIME [epoch: 27.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4449803298929424		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.4449803298929424 | validation: 3.623731969203685]
	TIME [epoch: 28 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.230154108784458		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 4.230154108784458 | validation: 3.8661495605435108]
	TIME [epoch: 28 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.372248947103211		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.372248947103211 | validation: 3.6556016951945822]
	TIME [epoch: 27.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.409206180685182		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 4.409206180685182 | validation: 3.7893060221815418]
	TIME [epoch: 28 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.444260667325972		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 4.444260667325972 | validation: 3.8584810581873046]
	TIME [epoch: 27.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4856772031764685		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.4856772031764685 | validation: 3.625285241891475]
	TIME [epoch: 28 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.272030715606863		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 4.272030715606863 | validation: 3.6116549990213627]
	TIME [epoch: 28 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.394870790175812		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 4.394870790175812 | validation: 3.550736705540051]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.243642615884197		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.243642615884197 | validation: 3.608033725591572]
	TIME [epoch: 28 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3909278783893075		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.3909278783893075 | validation: 3.8720930983768547]
	TIME [epoch: 28 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4394163697006155		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 4.4394163697006155 | validation: 3.944187881389795]
	TIME [epoch: 27.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.379003105664314		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.379003105664314 | validation: 3.832199113352804]
	TIME [epoch: 28 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466154272431194		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.466154272431194 | validation: 3.606300354213689]
	TIME [epoch: 28 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.287379321746126		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.287379321746126 | validation: 3.706027871222186]
	TIME [epoch: 27.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.321359944146285		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 4.321359944146285 | validation: 3.915732867671011]
	TIME [epoch: 28 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.374072303789564		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 4.374072303789564 | validation: 3.625787484557989]
	TIME [epoch: 28 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.236514815930288		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.236514815930288 | validation: 3.559672826616372]
	TIME [epoch: 27.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.336810381896276		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.336810381896276 | validation: 3.5620976702844964]
	TIME [epoch: 28 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.33549916219803		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 4.33549916219803 | validation: 3.565317679004153]
	TIME [epoch: 28 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.322432243974379		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 4.322432243974379 | validation: 3.6724475186273713]
	TIME [epoch: 27.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.320459158989605		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 4.320459158989605 | validation: 3.5582102792924117]
	TIME [epoch: 28 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.342076593149538		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 4.342076593149538 | validation: 3.549452068173334]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3421967654090965		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 4.3421967654090965 | validation: 3.7253881979901076]
	TIME [epoch: 28 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.258577090469029		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 4.258577090469029 | validation: 3.547040969929453]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.322839357932521		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 4.322839357932521 | validation: 3.511736001175612]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.281405277597987		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 4.281405277597987 | validation: 3.6079269830388707]
	TIME [epoch: 28 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.362804579871529		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 4.362804579871529 | validation: 3.576699844156561]
	TIME [epoch: 28 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.20573532300442		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 4.20573532300442 | validation: 3.516055502077955]
	TIME [epoch: 28 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.335336573967602		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 4.335336573967602 | validation: 3.529038509513092]
	TIME [epoch: 28 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.353359799215516		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 4.353359799215516 | validation: 3.5076688159877927]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2378104338550635		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 4.2378104338550635 | validation: 3.7372912089576396]
	TIME [epoch: 28 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.315890725282861		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 4.315890725282861 | validation: 3.610541130597159]
	TIME [epoch: 28 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.308829881655207		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 4.308829881655207 | validation: 3.5584514605741266]
	TIME [epoch: 28 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2735652318147075		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 4.2735652318147075 | validation: 3.766602118229554]
	TIME [epoch: 28 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.406604385765047		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 4.406604385765047 | validation: 3.6465876695366486]
	TIME [epoch: 28 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.289338283068062		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 4.289338283068062 | validation: 3.56065690498668]
	TIME [epoch: 28 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3879199603851236		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 4.3879199603851236 | validation: 3.7171907722525486]
	TIME [epoch: 28 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.293393811517883		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 4.293393811517883 | validation: 3.73477112092785]
	TIME [epoch: 28 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.329264286335816		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 4.329264286335816 | validation: 3.602572295290428]
	TIME [epoch: 28 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.304714272307545		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 4.304714272307545 | validation: 3.525662774931806]
	TIME [epoch: 28 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.318159347271059		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 4.318159347271059 | validation: 4.018534771943747]
	TIME [epoch: 28 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.310709556433958		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 4.310709556433958 | validation: 3.7323716893233496]
	TIME [epoch: 28 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.30839015145759		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 4.30839015145759 | validation: 3.5597527016242396]
	TIME [epoch: 28 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.28104814325825		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 4.28104814325825 | validation: 3.8082327099042317]
	TIME [epoch: 28 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.26944667912376		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 4.26944667912376 | validation: 3.7567415826540844]
	TIME [epoch: 28 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471781786457635		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 4.471781786457635 | validation: 3.5865180899804114]
	TIME [epoch: 28 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.224992301986059		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 4.224992301986059 | validation: 3.756826478105405]
	TIME [epoch: 28 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.239596995360511		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 4.239596995360511 | validation: 4.1996200349349575]
	TIME [epoch: 28 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.450230807387705		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 4.450230807387705 | validation: 3.5795126117387905]
	TIME [epoch: 27.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.19553010653436		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 4.19553010653436 | validation: 3.508519931994896]
	TIME [epoch: 28 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.222729070721472		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 4.222729070721472 | validation: 3.81010922344204]
	TIME [epoch: 27.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.279649211606984		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 4.279649211606984 | validation: 3.5083888593809798]
	TIME [epoch: 28 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.228624994592143		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 4.228624994592143 | validation: 4.564870023626777]
	TIME [epoch: 28 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.534193246347966		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 4.534193246347966 | validation: 3.780275317752914]
	TIME [epoch: 28 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.403727700766596		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 4.403727700766596 | validation: 3.513367109346822]
	TIME [epoch: 27.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.252512287588503		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 4.252512287588503 | validation: 3.4772674382297692]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.174948805134351		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 4.174948805134351 | validation: 3.4845511324856693]
	TIME [epoch: 28.1 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.562140096695195		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 4.562140096695195 | validation: 3.7247817642117527]
	TIME [epoch: 28 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49788074171718		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 4.49788074171718 | validation: 3.6646400034844726]
	TIME [epoch: 28 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.23931898896947		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 4.23931898896947 | validation: 3.5276837471847124]
	TIME [epoch: 28 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.221891908358916		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 4.221891908358916 | validation: 3.497625786679537]
	TIME [epoch: 28 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.214017962502435		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 4.214017962502435 | validation: 3.4891587641457877]
	TIME [epoch: 28 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.237413438480067		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 4.237413438480067 | validation: 3.6034491756497995]
	TIME [epoch: 28 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.200922310608997		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 4.200922310608997 | validation: 4.120387402020426]
	TIME [epoch: 28 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.396237571042741		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 4.396237571042741 | validation: 3.5547409748046035]
	TIME [epoch: 28 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.209183746451114		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 4.209183746451114 | validation: 3.6177460673275723]
	TIME [epoch: 28 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.193833751552189		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 4.193833751552189 | validation: 3.5599559071188787]
	TIME [epoch: 28 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.224745151971208		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 4.224745151971208 | validation: 3.774232645314951]
	TIME [epoch: 28 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.257203794755217		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 4.257203794755217 | validation: 3.6605601281524343]
	TIME [epoch: 28 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2349328636203225		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 4.2349328636203225 | validation: 3.4996898971576424]
	TIME [epoch: 28 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.161800431502257		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 4.161800431502257 | validation: 3.527233715109464]
	TIME [epoch: 28 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.250706935155885		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 4.250706935155885 | validation: 3.7895773951066594]
	TIME [epoch: 28 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3613847717803464		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 4.3613847717803464 | validation: 3.518277395104474]
	TIME [epoch: 28 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.18944240028904		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 4.18944240028904 | validation: 3.7317038421695954]
	TIME [epoch: 28 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.210268639151378		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 4.210268639151378 | validation: 3.4699186989826685]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.271956523956344		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 4.271956523956344 | validation: 3.45728941205516]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.251977065742833		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 4.251977065742833 | validation: 3.5216601563654]
	TIME [epoch: 28 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.186137186993679		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 4.186137186993679 | validation: 3.62061411636041]
	TIME [epoch: 28 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.20817098783837		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 4.20817098783837 | validation: 3.8100543326228227]
	TIME [epoch: 28 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.273931170942603		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 4.273931170942603 | validation: 3.4549249637136374]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.152099539745465		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 4.152099539745465 | validation: 3.4694875808105863]
	TIME [epoch: 28 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.284490522504751		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 4.284490522504751 | validation: 3.4695893082536413]
	TIME [epoch: 28 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.204340181441719		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 4.204340181441719 | validation: 3.478439449883914]
	TIME [epoch: 28 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.23134185392832		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 4.23134185392832 | validation: 3.5060678507224385]
	TIME [epoch: 28 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.196149054886167		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 4.196149054886167 | validation: 3.531123376949314]
	TIME [epoch: 28 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.617862335247123		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 4.617862335247123 | validation: 3.564002151054723]
	TIME [epoch: 28 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.206957811580476		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 4.206957811580476 | validation: 3.660193182638782]
	TIME [epoch: 28 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.260968768754149		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 4.260968768754149 | validation: 3.497901912767736]
	TIME [epoch: 28 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.245770874208639		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 4.245770874208639 | validation: 3.518049189754621]
	TIME [epoch: 28 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2107011188751216		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 4.2107011188751216 | validation: 3.5345012667886744]
	TIME [epoch: 28 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.226239199873803		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 4.226239199873803 | validation: 3.499541511905097]
	TIME [epoch: 28 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.180154990934864		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 4.180154990934864 | validation: 3.605580584453822]
	TIME [epoch: 28 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.152165171140499		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 4.152165171140499 | validation: 3.448766509256316]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.228114785040527		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 4.228114785040527 | validation: 3.6039618997143963]
	TIME [epoch: 28 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.195411035908017		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 4.195411035908017 | validation: 3.663560450689171]
	TIME [epoch: 28 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.210750445268333		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 4.210750445268333 | validation: 3.71441481615249]
	TIME [epoch: 28 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.201718442689019		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 4.201718442689019 | validation: 3.529660188813881]
	TIME [epoch: 28 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.326532597083061		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 4.326532597083061 | validation: 3.4458531591263513]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.207010910411197		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 4.207010910411197 | validation: 3.5368764004334845]
	TIME [epoch: 28 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.211409569147057		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 4.211409569147057 | validation: 3.6894388692444204]
	TIME [epoch: 28 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.287906478207026		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 4.287906478207026 | validation: 3.719839584613392]
	TIME [epoch: 28 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.198965233380893		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 4.198965233380893 | validation: 3.5183084035266314]
	TIME [epoch: 28 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.241921266679674		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 4.241921266679674 | validation: 3.438431023695752]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2023729792233695		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 4.2023729792233695 | validation: 3.4715710747922044]
	TIME [epoch: 28 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.156905824810037		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 4.156905824810037 | validation: 3.46971212954081]
	TIME [epoch: 28 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.174964730717884		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 4.174964730717884 | validation: 3.51895947547355]
	TIME [epoch: 28 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.201860544063291		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 4.201860544063291 | validation: 3.5404799039141928]
	TIME [epoch: 28 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.226912967963221		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 4.226912967963221 | validation: 3.458161222323927]
	TIME [epoch: 28 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.122600769997866		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 4.122600769997866 | validation: 3.5924008471480215]
	TIME [epoch: 28.1 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.208307349279457		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 4.208307349279457 | validation: 3.6492846569100528]
	TIME [epoch: 28 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.198603958885164		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 4.198603958885164 | validation: 3.496436009589459]
	TIME [epoch: 28 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.120594258469352		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 4.120594258469352 | validation: 3.5602519734059475]
	TIME [epoch: 28 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.169014959791017		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 4.169014959791017 | validation: 3.8328784079598144]
	TIME [epoch: 28 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.328156489491402		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 4.328156489491402 | validation: 3.6333256111151617]
	TIME [epoch: 28 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.331995596116793		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 4.331995596116793 | validation: 3.597023865557754]
	TIME [epoch: 28 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.177275879298346		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 4.177275879298346 | validation: 3.5435050406869744]
	TIME [epoch: 28 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.186521914143439		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 4.186521914143439 | validation: 3.4981040507981858]
	TIME [epoch: 28 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.324665197779698		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 4.324665197779698 | validation: 3.587176548731262]
	TIME [epoch: 28 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.16369333560905		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 4.16369333560905 | validation: 3.4452757436401633]
	TIME [epoch: 28 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.110065428307811		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 4.110065428307811 | validation: 3.5914703746828454]
	TIME [epoch: 28 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1386949492570535		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 4.1386949492570535 | validation: 3.715834715704762]
	TIME [epoch: 28 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.239054045342362		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 4.239054045342362 | validation: 3.5258319054204175]
	TIME [epoch: 28 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.136485065470849		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 4.136485065470849 | validation: 3.5326290302976204]
	TIME [epoch: 28 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1472352340178045		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 4.1472352340178045 | validation: 3.4928018276685346]
	TIME [epoch: 28 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.119715791530524		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 4.119715791530524 | validation: 3.427238851029989]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.095583903455774		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 4.095583903455774 | validation: 3.4706770875534745]
	TIME [epoch: 28 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.177216043126053		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 4.177216043126053 | validation: 3.542918048870181]
	TIME [epoch: 28 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.234103477540291		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 4.234103477540291 | validation: 3.585372722852505]
	TIME [epoch: 28 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.19704350023099		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 4.19704350023099 | validation: 3.418013514943589]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.284084796182281		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 4.284084796182281 | validation: 3.4131981937683644]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1343125754902355		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 4.1343125754902355 | validation: 3.431560839835272]
	TIME [epoch: 28 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.210346602796811		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 4.210346602796811 | validation: 3.4132591519043394]
	TIME [epoch: 28 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2087539635901345		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 4.2087539635901345 | validation: 3.9163304212019705]
	TIME [epoch: 28 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.206225399210243		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 4.206225399210243 | validation: 3.4968646719557923]
	TIME [epoch: 28 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.161989109577443		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 4.161989109577443 | validation: 3.5100042771830964]
	TIME [epoch: 28 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.170656897532375		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 4.170656897532375 | validation: 3.4378491350554903]
	TIME [epoch: 28 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.106191020046673		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 4.106191020046673 | validation: 3.43833152431665]
	TIME [epoch: 28 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.138622406728608		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 4.138622406728608 | validation: 3.4279376023191506]
	TIME [epoch: 28 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2053356947872125		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 4.2053356947872125 | validation: 3.424706561288582]
	TIME [epoch: 28 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.157377445190032		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 4.157377445190032 | validation: 3.4862233683658785]
	TIME [epoch: 28 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.230946052101648		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 4.230946052101648 | validation: 3.4298838458888032]
	TIME [epoch: 28 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.247617598875558		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 4.247617598875558 | validation: 3.485281963159192]
	TIME [epoch: 28 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.10983602510996		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 4.10983602510996 | validation: 3.4101191804703985]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.13538235930673		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 4.13538235930673 | validation: 3.43531697453877]
	TIME [epoch: 28 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.132036787674293		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 4.132036787674293 | validation: 3.614777714158494]
	TIME [epoch: 28 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.155657017729029		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 4.155657017729029 | validation: 3.4156769418484227]
	TIME [epoch: 28 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.118673754952037		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 4.118673754952037 | validation: 3.5022214029661045]
	TIME [epoch: 28 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1108694142472135		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 4.1108694142472135 | validation: 3.6768907051180397]
	TIME [epoch: 28 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.334554602921742		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 4.334554602921742 | validation: 3.5489036741817603]
	TIME [epoch: 28 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.210967785214091		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 4.210967785214091 | validation: 3.412434432257488]
	TIME [epoch: 28 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.111121875163782		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 4.111121875163782 | validation: 3.4704898550413703]
	TIME [epoch: 28 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.143661048393643		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 4.143661048393643 | validation: 3.502857054823725]
	TIME [epoch: 28 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.194541510557716		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 4.194541510557716 | validation: 3.4962012055056575]
	TIME [epoch: 28 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.181865673198007		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 4.181865673198007 | validation: 3.4401781604490167]
	TIME [epoch: 28 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.11229585737047		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 4.11229585737047 | validation: 3.4946445466253664]
	TIME [epoch: 28 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.153297890431674		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 4.153297890431674 | validation: 3.439806964660188]
	TIME [epoch: 28 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.129607309614276		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 4.129607309614276 | validation: 3.464200354842656]
	TIME [epoch: 28 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.182146328821863		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 4.182146328821863 | validation: 3.402703627277901]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1406042312142874		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 4.1406042312142874 | validation: 3.457015657530689]
	TIME [epoch: 28 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.115267939231376		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 4.115267939231376 | validation: 3.4121735594007028]
	TIME [epoch: 28 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.17986715995023		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 4.17986715995023 | validation: 3.479961539665061]
	TIME [epoch: 28 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.190180731833119		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 4.190180731833119 | validation: 3.451956113461813]
	TIME [epoch: 28 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.084028718768764		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 4.084028718768764 | validation: 3.48439475230126]
	TIME [epoch: 28 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.097781566184803		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 4.097781566184803 | validation: 3.500543215901035]
	TIME [epoch: 28 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.098872533452076		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 4.098872533452076 | validation: 3.435080708251037]
	TIME [epoch: 28 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.109112914319639		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 4.109112914319639 | validation: 3.5886382504718357]
	TIME [epoch: 28 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.161650476439352		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 4.161650476439352 | validation: 3.4157048074527325]
	TIME [epoch: 28 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.125182764134132		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 4.125182764134132 | validation: 3.5037400241736334]
	TIME [epoch: 28 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.110522770260321		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 4.110522770260321 | validation: 3.790025522981007]
	TIME [epoch: 28 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2323154888723655		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 4.2323154888723655 | validation: 3.642896396018365]
	TIME [epoch: 28 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1957597613885085		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 4.1957597613885085 | validation: 3.4288287554915247]
	TIME [epoch: 28 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1387268879837205		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 4.1387268879837205 | validation: 3.408533238593225]
	TIME [epoch: 28 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.148346613607408		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 4.148346613607408 | validation: 3.5370887623775946]
	TIME [epoch: 28 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.229293172252655		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 4.229293172252655 | validation: 3.4736717754407067]
	TIME [epoch: 28 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.113419330098658		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 4.113419330098658 | validation: 3.4687323603638642]
	TIME [epoch: 28 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.146008209821938		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 4.146008209821938 | validation: 3.5061656502760963]
	TIME [epoch: 28 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.111443278746681		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 4.111443278746681 | validation: 3.397294756834834]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.103746275491112		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 4.103746275491112 | validation: 3.9547459103776976]
	TIME [epoch: 28 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525135236543143		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 4.525135236543143 | validation: 3.4465537908066954]
	TIME [epoch: 28 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.140018823715446		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 4.140018823715446 | validation: 3.402502855148863]
	TIME [epoch: 28 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.092722217743599		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 4.092722217743599 | validation: 3.409663678336299]
	TIME [epoch: 28 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.14177288600958		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 4.14177288600958 | validation: 3.457808005887511]
	TIME [epoch: 28 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.210535698729467		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 4.210535698729467 | validation: 3.408171707448321]
	TIME [epoch: 28 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.186034454391461		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 4.186034454391461 | validation: 3.571074289122896]
	TIME [epoch: 28 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.11640760743656		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 4.11640760743656 | validation: 3.381771067209528]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.157836603227241		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 4.157836603227241 | validation: 3.585531729807002]
	TIME [epoch: 28 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.199221590992307		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 4.199221590992307 | validation: 3.434103289563058]
	TIME [epoch: 28 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0975379072814215		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 4.0975379072814215 | validation: 3.4235971743940774]
	TIME [epoch: 28 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.10280930323271		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 4.10280930323271 | validation: 3.563049250428641]
	TIME [epoch: 28 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.215621796207863		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 4.215621796207863 | validation: 3.5072403178270446]
	TIME [epoch: 28 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.08738623332302		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 4.08738623332302 | validation: 3.458529883625615]
	TIME [epoch: 28 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.140107613532036		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 4.140107613532036 | validation: 3.376308709564347]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.128945848430585		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 4.128945848430585 | validation: 3.4107308585325904]
	TIME [epoch: 28 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.099623108619255		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 4.099623108619255 | validation: 3.410084362425504]
	TIME [epoch: 28 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0951415985351405		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 4.0951415985351405 | validation: 3.53945681501717]
	TIME [epoch: 28 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.193193770901374		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 4.193193770901374 | validation: 3.449589796355607]
	TIME [epoch: 28 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.071167178552877		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 4.071167178552877 | validation: 3.369165315420041]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.073141462773483		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 4.073141462773483 | validation: 3.46510526850091]
	TIME [epoch: 28 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.076684780689951		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 4.076684780689951 | validation: 3.7774398830750733]
	TIME [epoch: 28 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.162591497098221		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 4.162591497098221 | validation: 3.364029759064834]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.082856239187322		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 4.082856239187322 | validation: 3.4011379569430535]
	TIME [epoch: 28 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.18205109128647		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 4.18205109128647 | validation: 3.417551929697946]
	TIME [epoch: 28 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.188730862433789		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 4.188730862433789 | validation: 3.5276790149353734]
	TIME [epoch: 28 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.250125627062293		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 4.250125627062293 | validation: 3.4152455550669476]
	TIME [epoch: 28 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.078371961718		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 4.078371961718 | validation: 3.4563435381290595]
	TIME [epoch: 28 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.118506240490619		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 4.118506240490619 | validation: 3.512864622166783]
	TIME [epoch: 28 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.11688010956748		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 4.11688010956748 | validation: 3.3985213322026837]
	TIME [epoch: 28 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.116786894827354		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 4.116786894827354 | validation: 3.393130791567192]
	TIME [epoch: 28 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.09985995058628		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 4.09985995058628 | validation: 3.6703814293779193]
	TIME [epoch: 28 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.138193378148992		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 4.138193378148992 | validation: 3.384571423387578]
	TIME [epoch: 28 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.113528205547627		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 4.113528205547627 | validation: 3.4097283731600228]
	TIME [epoch: 28 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.129297873044368		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 4.129297873044368 | validation: 3.50201565584043]
	TIME [epoch: 28 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.133883515153916		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 4.133883515153916 | validation: 3.37921090736953]
	TIME [epoch: 28 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.087191149860244		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 4.087191149860244 | validation: 3.4022834900839896]
	TIME [epoch: 28 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.128524907582404		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 4.128524907582404 | validation: 3.3847212073187785]
	TIME [epoch: 28 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.130976225375248		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 4.130976225375248 | validation: 3.4489362427831343]
	TIME [epoch: 28 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.127940172309887		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 4.127940172309887 | validation: 3.4346320050899295]
	TIME [epoch: 28 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.133339060880995		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 4.133339060880995 | validation: 3.5048861768810395]
	TIME [epoch: 28 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.077247683386017		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 4.077247683386017 | validation: 3.376224043072812]
	TIME [epoch: 28 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.059057241240309		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 4.059057241240309 | validation: 3.429495001596821]
	TIME [epoch: 28 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.084795167835402		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 4.084795167835402 | validation: 3.3816745165287863]
	TIME [epoch: 28 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.183234349957343		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 4.183234349957343 | validation: 3.4002841384094977]
	TIME [epoch: 28 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.129818768974927		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 4.129818768974927 | validation: 3.423392981772735]
	TIME [epoch: 28 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0594639156168295		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 4.0594639156168295 | validation: 3.3791768023654782]
	TIME [epoch: 28 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.110643460164356		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 4.110643460164356 | validation: 3.4577624625127465]
	TIME [epoch: 28 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.127671185798759		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 4.127671185798759 | validation: 3.3823791509650833]
	TIME [epoch: 28 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.128067156325404		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 4.128067156325404 | validation: 3.779393293390674]
	TIME [epoch: 28 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.201075178402401		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 4.201075178402401 | validation: 3.611554507613198]
	TIME [epoch: 28 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.13513936062416		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 4.13513936062416 | validation: 3.4740900340874306]
	TIME [epoch: 28 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.108836417967503		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 4.108836417967503 | validation: 3.412319351508766]
	TIME [epoch: 28 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.088643748267476		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 4.088643748267476 | validation: 3.3849081396461465]
	TIME [epoch: 28 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0966212987055695		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 4.0966212987055695 | validation: 3.3728980336506016]
	TIME [epoch: 28 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.166814615041887		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 4.166814615041887 | validation: 3.428797595192287]
	TIME [epoch: 28 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.080590174270485		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 4.080590174270485 | validation: 3.47509693653511]
	TIME [epoch: 28 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.128873969771861		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 4.128873969771861 | validation: 3.4032105194433324]
	TIME [epoch: 28 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.091220117283582		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 4.091220117283582 | validation: 3.410723366198944]
	TIME [epoch: 28 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.063517550644417		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 4.063517550644417 | validation: 3.4692417897149546]
	TIME [epoch: 28 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1048611664080275		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 4.1048611664080275 | validation: 3.3744043445124796]
	TIME [epoch: 28 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.063839830716511		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 4.063839830716511 | validation: 3.404596744309071]
	TIME [epoch: 28 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0812395939025325		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 4.0812395939025325 | validation: 3.5085547714951257]
	TIME [epoch: 28 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.103935770365298		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 4.103935770365298 | validation: 3.396395128950713]
	TIME [epoch: 28 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.087958831777254		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 4.087958831777254 | validation: 3.4324853015425925]
	TIME [epoch: 28 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.11589824429724		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 4.11589824429724 | validation: 3.347674969080842]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_359.pth
	Model improved!!!
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.08330577729778		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 4.08330577729778 | validation: 3.4149429670301283]
	TIME [epoch: 28 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.096898761260339		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 4.096898761260339 | validation: 3.4594844376525082]
	TIME [epoch: 28 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.105650844440661		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 4.105650844440661 | validation: 3.3521186946214208]
	TIME [epoch: 28 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0387052521296285		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 4.0387052521296285 | validation: 3.5524685421551623]
	TIME [epoch: 28 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.169710246406471		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 4.169710246406471 | validation: 3.3631933739628925]
	TIME [epoch: 28 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.062621233416557		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 4.062621233416557 | validation: 3.571487660867016]
	TIME [epoch: 28 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.166117358099312		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 4.166117358099312 | validation: 3.595754789825465]
	TIME [epoch: 28 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1408850542238405		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 4.1408850542238405 | validation: 3.432538178728133]
	TIME [epoch: 28 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.082151241352228		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 4.082151241352228 | validation: 3.5514316942594406]
	TIME [epoch: 28 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.075352702374113		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 4.075352702374113 | validation: 3.3977815258002906]
	TIME [epoch: 28 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.092127397623917		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 4.092127397623917 | validation: 3.380583346377704]
	TIME [epoch: 28.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.122955106525392		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 4.122955106525392 | validation: 3.475248042816854]
	TIME [epoch: 28 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.053169063400575		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 4.053169063400575 | validation: 3.5274419493522324]
	TIME [epoch: 28 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.112248946215903		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 4.112248946215903 | validation: 3.3787216675250993]
	TIME [epoch: 28 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.118725512476583		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 4.118725512476583 | validation: 3.6981576816911956]
	TIME [epoch: 28 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.127590538016116		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 4.127590538016116 | validation: 3.35909040229188]
	TIME [epoch: 28 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.131376079117522		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 4.131376079117522 | validation: 3.690870625681882]
	TIME [epoch: 28 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.127835693873095		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 4.127835693873095 | validation: 3.4321234458256775]
	TIME [epoch: 28 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.132597529091085		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 4.132597529091085 | validation: 3.3759640276169707]
	TIME [epoch: 28 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.038438976761582		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 4.038438976761582 | validation: 3.381968746528735]
	TIME [epoch: 28 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.102615051321406		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 4.102615051321406 | validation: 3.3694912065670217]
	TIME [epoch: 28 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.08769414466939		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 4.08769414466939 | validation: 3.3527985891723824]
	TIME [epoch: 28 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.071651549777226		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 4.071651549777226 | validation: 3.4199112306884416]
	TIME [epoch: 28 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.078570129440205		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 4.078570129440205 | validation: 3.6606261607022885]
	TIME [epoch: 28 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.141023041619383		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 4.141023041619383 | validation: 3.369816663525357]
	TIME [epoch: 28 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.054048271691276		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 4.054048271691276 | validation: 3.4857352030880215]
	TIME [epoch: 28 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.089441701125087		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 4.089441701125087 | validation: 3.477436660726859]
	TIME [epoch: 28 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.107584281392853		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 4.107584281392853 | validation: 3.405163540170048]
	TIME [epoch: 28 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.091025647946379		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 4.091025647946379 | validation: 3.405828646024416]
	TIME [epoch: 28 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0845596262106625		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 4.0845596262106625 | validation: 3.4341862583473883]
	TIME [epoch: 28 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.072700057519232		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 4.072700057519232 | validation: 3.3483656976343124]
	TIME [epoch: 28 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.066088440003185		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 4.066088440003185 | validation: 3.3735351334534656]
	TIME [epoch: 28 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.095623870695952		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 4.095623870695952 | validation: 3.36625402195627]
	TIME [epoch: 28 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.100341918798301		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 4.100341918798301 | validation: 3.388977810213333]
	TIME [epoch: 28 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.087244568312859		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 4.087244568312859 | validation: 3.5042773051405405]
	TIME [epoch: 28 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.087431878889824		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 4.087431878889824 | validation: 3.3563949886276885]
	TIME [epoch: 28 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.067824116772055		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 4.067824116772055 | validation: 3.45820862649044]
	TIME [epoch: 28 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.103773749808471		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 4.103773749808471 | validation: 3.392413771927204]
	TIME [epoch: 28 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.061963450348624		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 4.061963450348624 | validation: 3.422132642852217]
	TIME [epoch: 28 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.106139497228383		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 4.106139497228383 | validation: 3.4390540083825125]
	TIME [epoch: 28 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.061244989334844		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 4.061244989334844 | validation: 3.415126520603458]
	TIME [epoch: 28 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.066569329079392		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 4.066569329079392 | validation: 3.490444451174328]
	TIME [epoch: 28 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.137762367243662		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 4.137762367243662 | validation: 3.417030511007553]
	TIME [epoch: 28 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.081415769118368		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 4.081415769118368 | validation: 3.4588306020247543]
	TIME [epoch: 28 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.068316250062441		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 4.068316250062441 | validation: 3.4035376204682453]
	TIME [epoch: 28 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.053120707327212		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 4.053120707327212 | validation: 3.38517525794491]
	TIME [epoch: 28 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.060551912916008		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 4.060551912916008 | validation: 3.3614201959345933]
	TIME [epoch: 28 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.041413676092086		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 4.041413676092086 | validation: 3.469153772889897]
	TIME [epoch: 28 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.086748477628458		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 4.086748477628458 | validation: 3.3623149588172176]
	TIME [epoch: 28 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.041930268196543		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 4.041930268196543 | validation: 3.3873192802023966]
	TIME [epoch: 28 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.087627022567241		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 4.087627022567241 | validation: 3.3752524874481624]
	TIME [epoch: 28 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.036046589544192		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 4.036046589544192 | validation: 3.4029559356583645]
	TIME [epoch: 28 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.116771885579046		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 4.116771885579046 | validation: 3.512099954706456]
	TIME [epoch: 28 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.138882836581593		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 4.138882836581593 | validation: 3.5191960823612507]
	TIME [epoch: 28 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.13141794323924		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 4.13141794323924 | validation: 3.3855272319930574]
	TIME [epoch: 28 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.037235274928436		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 4.037235274928436 | validation: 3.4626018303186914]
	TIME [epoch: 28 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.083926068394292		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 4.083926068394292 | validation: 3.5615411743899017]
	TIME [epoch: 28 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.140797613140034		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 4.140797613140034 | validation: 3.4396718778447566]
	TIME [epoch: 28 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0850367321409315		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 4.0850367321409315 | validation: 3.417648929845949]
	TIME [epoch: 28 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0788194551700325		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 4.0788194551700325 | validation: 3.4158693330340966]
	TIME [epoch: 28.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.087011848474671		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 4.087011848474671 | validation: 3.365674417208589]
	TIME [epoch: 28 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.14744169192103		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 4.14744169192103 | validation: 3.4578759830577885]
	TIME [epoch: 28 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.145768670260356		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 4.145768670260356 | validation: 3.424405553109525]
	TIME [epoch: 28 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.107429941005917		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 4.107429941005917 | validation: 3.582641522271315]
	TIME [epoch: 28 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0916899572483985		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 4.0916899572483985 | validation: 3.770711983621942]
	TIME [epoch: 28 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2084713357814145		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 4.2084713357814145 | validation: 3.3613031082123044]
	TIME [epoch: 28 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0424619588812		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 4.0424619588812 | validation: 3.358976518582722]
	TIME [epoch: 28 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.044122692634113		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 4.044122692634113 | validation: 3.455878965729701]
	TIME [epoch: 28 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.073729494542517		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 4.073729494542517 | validation: 3.3991920840880105]
	TIME [epoch: 28 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.043973608862816		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 4.043973608862816 | validation: 3.4078905114509257]
	TIME [epoch: 28 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.131346116927089		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 4.131346116927089 | validation: 3.445705460006458]
	TIME [epoch: 28 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.056803152055723		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 4.056803152055723 | validation: 3.3556682761459378]
	TIME [epoch: 28 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.061312702595061		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 4.061312702595061 | validation: 3.390691343424089]
	TIME [epoch: 28 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.066041813381219		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 4.066041813381219 | validation: 3.4175972593555297]
	TIME [epoch: 28 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.141575195824574		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 4.141575195824574 | validation: 3.342370845346542]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.074025678164692		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 4.074025678164692 | validation: 3.3626119230647307]
	TIME [epoch: 28 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.068135258254445		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 4.068135258254445 | validation: 3.4096848367983954]
	TIME [epoch: 28 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.044047364849513		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 4.044047364849513 | validation: 3.4183222415934438]
	TIME [epoch: 28 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.047254598081711		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 4.047254598081711 | validation: 3.337393379941744]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0829647475321496		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 4.0829647475321496 | validation: 3.508659187268622]
	TIME [epoch: 28 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.070013820564714		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 4.070013820564714 | validation: 3.368590812258226]
	TIME [epoch: 28 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.053786209431364		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 4.053786209431364 | validation: 3.3566578522028467]
	TIME [epoch: 28 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.042335868170877		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 4.042335868170877 | validation: 3.3838654286605983]
	TIME [epoch: 28 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.107567654628686		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 4.107567654628686 | validation: 3.433914780053959]
	TIME [epoch: 28 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.081083861969159		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 4.081083861969159 | validation: 3.3638002084873273]
	TIME [epoch: 28 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.087063487970254		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 4.087063487970254 | validation: 3.536630543142138]
	TIME [epoch: 28 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.102425383920822		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 4.102425383920822 | validation: 3.405628151884006]
	TIME [epoch: 28 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.044702249899938		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 4.044702249899938 | validation: 3.357914759218313]
	TIME [epoch: 28 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.028515507283809		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 4.028515507283809 | validation: 3.384123488503604]
	TIME [epoch: 28 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.05058632418564		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 4.05058632418564 | validation: 3.3959972021677847]
	TIME [epoch: 28 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0773495215120725		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 4.0773495215120725 | validation: 3.3783634238261446]
	TIME [epoch: 28 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.36817342328974		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 4.36817342328974 | validation: 3.3926624233865414]
	TIME [epoch: 28 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0322897778165805		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 4.0322897778165805 | validation: 3.3636053174760487]
	TIME [epoch: 28 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.04578770964312		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 4.04578770964312 | validation: 3.4335098938888233]
	TIME [epoch: 28 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.072298964180511		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 4.072298964180511 | validation: 3.3535400342121773]
	TIME [epoch: 28 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.066163638334228		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 4.066163638334228 | validation: 3.5476467008429053]
	TIME [epoch: 28 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1200916745413725		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 4.1200916745413725 | validation: 3.375154219772891]
	TIME [epoch: 28 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.055547160694042		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 4.055547160694042 | validation: 3.383256592112591]
	TIME [epoch: 28 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.04580132932021		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 4.04580132932021 | validation: 3.361985120163406]
	TIME [epoch: 28 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.109721811542791		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 4.109721811542791 | validation: 3.537566704786899]
	TIME [epoch: 28 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.091328662377313		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 4.091328662377313 | validation: 3.344566440936002]
	TIME [epoch: 28 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0315469589516395		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 4.0315469589516395 | validation: 3.5582911129764354]
	TIME [epoch: 28 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0720296899968265		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 4.0720296899968265 | validation: 3.4529172425357855]
	TIME [epoch: 28 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.061741773957967		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 4.061741773957967 | validation: 3.352513141535994]
	TIME [epoch: 28 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.048829667394755		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 4.048829667394755 | validation: 3.363819568307148]
	TIME [epoch: 28 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.066694428603251		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 4.066694428603251 | validation: 3.389707128291824]
	TIME [epoch: 28 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.063545509677473		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 4.063545509677473 | validation: 3.4037603964270544]
	TIME [epoch: 28 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.047620683898603		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 4.047620683898603 | validation: 3.385434190102756]
	TIME [epoch: 28 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.03213261258548		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 4.03213261258548 | validation: 3.378235046317326]
	TIME [epoch: 28 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.076687859775699		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 4.076687859775699 | validation: 3.348223283924723]
	TIME [epoch: 28 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.061513172843164		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 4.061513172843164 | validation: 3.350214523645044]
	TIME [epoch: 28 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.072460880763626		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 4.072460880763626 | validation: 3.4118774700817602]
	TIME [epoch: 28 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.06376065829728		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 4.06376065829728 | validation: 3.3774163771746863]
	TIME [epoch: 28 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.059369313659586		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 4.059369313659586 | validation: 3.3527741885059483]
	TIME [epoch: 28 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.040542465909689		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 4.040542465909689 | validation: 3.342500012962583]
	TIME [epoch: 28 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.081455889561541		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 4.081455889561541 | validation: 3.351013215044314]
	TIME [epoch: 28 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.036716315240977		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 4.036716315240977 | validation: 3.3811754151597273]
	TIME [epoch: 28 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.048280310814677		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 4.048280310814677 | validation: 3.49996429497671]
	TIME [epoch: 28 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.069946273394875		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 4.069946273394875 | validation: 3.341703898327992]
	TIME [epoch: 28 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.071880006525824		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 4.071880006525824 | validation: 3.3671078357470403]
	TIME [epoch: 28 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.069099843320065		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 4.069099843320065 | validation: 3.417105459507201]
	TIME [epoch: 28 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.053062247908571		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 4.053062247908571 | validation: 3.342084684688688]
	TIME [epoch: 28 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.047812621677342		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 4.047812621677342 | validation: 3.336790673345772]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.027074210035993		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 4.027074210035993 | validation: 3.339115584241897]
	TIME [epoch: 28 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.03339953414118		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 4.03339953414118 | validation: 3.37080706087664]
	TIME [epoch: 28 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.032760320096171		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 4.032760320096171 | validation: 3.356396068563855]
	TIME [epoch: 28 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.064600744630061		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 4.064600744630061 | validation: 3.360030072738977]
	TIME [epoch: 28 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.038601778485089		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 4.038601778485089 | validation: 3.3776024351865988]
	TIME [epoch: 28 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0618888943820135		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 4.0618888943820135 | validation: 3.349591947213501]
	TIME [epoch: 28 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.031475875759382		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 4.031475875759382 | validation: 3.4472593029704646]
	TIME [epoch: 28 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0696106216876995		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 4.0696106216876995 | validation: 3.435150761056218]
	TIME [epoch: 28 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.036594370087886		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 4.036594370087886 | validation: 3.3633999065670417]
	TIME [epoch: 28 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.062032904345415		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 4.062032904345415 | validation: 3.386378318920095]
	TIME [epoch: 28 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.044060369386994		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 4.044060369386994 | validation: 3.354868473157179]
	TIME [epoch: 28 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0749790628651406		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 4.0749790628651406 | validation: 3.35958022499687]
	TIME [epoch: 28 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.029299943273241		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 4.029299943273241 | validation: 3.4037486006438464]
	TIME [epoch: 28 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.057452022413935		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 4.057452022413935 | validation: 3.3595441215209085]
	TIME [epoch: 28 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.027664722175334		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 4.027664722175334 | validation: 3.334940461930533]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_497.pth
	Model improved!!!
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.013279376676573		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 4.013279376676573 | validation: 3.338861397563063]
	TIME [epoch: 28 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.046515026531758		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 4.046515026531758 | validation: 3.504705267472645]
	TIME [epoch: 28 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.052372342629907		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 4.052372342629907 | validation: 3.348157885158687]
	TIME [epoch: 28 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.094352459029299		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 4.094352459029299 | validation: 3.33763976247477]
	TIME [epoch: 28 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.028675005434409		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 4.028675005434409 | validation: 3.385870701966198]
	TIME [epoch: 28 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.055897286357771		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 4.055897286357771 | validation: 3.340847126524002]
	TIME [epoch: 28 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.060677748515811		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 4.060677748515811 | validation: 3.343549127434808]
	TIME [epoch: 28 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.02189326721895		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 4.02189326721895 | validation: 3.3699699363889772]
	TIME [epoch: 28 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.039017060908826		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 4.039017060908826 | validation: 3.5272627690093294]
	TIME [epoch: 28 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.062945599568715		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 4.062945599568715 | validation: 3.3452244776330655]
	TIME [epoch: 28 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0307189245472985		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 4.0307189245472985 | validation: 3.3931935638224093]
	TIME [epoch: 28 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.058484127329857		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 4.058484127329857 | validation: 3.4429196303636123]
	TIME [epoch: 28 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.065071233661273		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 4.065071233661273 | validation: 3.3555594963056063]
	TIME [epoch: 28 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.022039058788592		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 4.022039058788592 | validation: 3.344108415047391]
	TIME [epoch: 28 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.083679703805266		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 4.083679703805266 | validation: 3.3648536162570246]
	TIME [epoch: 28 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.028943656677264		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 4.028943656677264 | validation: 3.4455021618417936]
	TIME [epoch: 28 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0831110822867185		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 4.0831110822867185 | validation: 3.351844876956643]
	TIME [epoch: 28 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.034969799162647		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 4.034969799162647 | validation: 3.3306790847142396]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_515.pth
	Model improved!!!
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.005267252345025		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 4.005267252345025 | validation: 3.3400891071258916]
	TIME [epoch: 28 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.027402768191234		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 4.027402768191234 | validation: 3.3292072582984567]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_517.pth
	Model improved!!!
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.078875661452709		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 4.078875661452709 | validation: 3.3326021755886814]
	TIME [epoch: 28 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.035476120490809		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 4.035476120490809 | validation: 3.3524966799467952]
	TIME [epoch: 28 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.032265011624102		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 4.032265011624102 | validation: 3.361634939971787]
	TIME [epoch: 28 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.089729252119382		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 4.089729252119382 | validation: 3.4786695079530974]
	TIME [epoch: 28 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.053139633099798		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 4.053139633099798 | validation: 3.4115435063637056]
	TIME [epoch: 28 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.039670336821317		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 4.039670336821317 | validation: 3.396012715385748]
	TIME [epoch: 28 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0408548339480435		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 4.0408548339480435 | validation: 3.378094964726327]
	TIME [epoch: 28 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.048775583366781		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 4.048775583366781 | validation: 3.3800904399193934]
	TIME [epoch: 28 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0340161203185		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 4.0340161203185 | validation: 3.3647312877124285]
	TIME [epoch: 28 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.041667295867615		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 4.041667295867615 | validation: 3.3819536089055906]
	TIME [epoch: 28 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0688902488730765		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 4.0688902488730765 | validation: 3.352410475218196]
	TIME [epoch: 28 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.040629165050489		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 4.040629165050489 | validation: 3.3671064790412473]
	TIME [epoch: 28 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0324610872643		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 4.0324610872643 | validation: 3.3309868501604196]
	TIME [epoch: 28 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.248689483495329		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 4.248689483495329 | validation: 3.462902286913504]
	TIME [epoch: 28 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.094695059187419		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 4.094695059187419 | validation: 3.372826637242194]
	TIME [epoch: 28 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.050809734406023		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 4.050809734406023 | validation: 3.414232773078875]
	TIME [epoch: 28 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.039897161519288		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 4.039897161519288 | validation: 3.3375223187844343]
	TIME [epoch: 28 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.023240099113224		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 4.023240099113224 | validation: 3.521472735782036]
	TIME [epoch: 28 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0631950859869415		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 4.0631950859869415 | validation: 3.3752864630949215]
	TIME [epoch: 28 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.039399542443154		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 4.039399542443154 | validation: 3.3296762036207173]
	TIME [epoch: 28 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.035924524214449		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 4.035924524214449 | validation: 3.3300798578502113]
	TIME [epoch: 28 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.024387127772417		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 4.024387127772417 | validation: 3.3460767785291727]
	TIME [epoch: 28 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.020975469859103		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 4.020975469859103 | validation: 3.368990379842155]
	TIME [epoch: 28 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.037542411672794		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 4.037542411672794 | validation: 3.3356183592921265]
	TIME [epoch: 28 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.039629049926227		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 4.039629049926227 | validation: 3.3725885701190794]
	TIME [epoch: 28 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.014424365096989		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 4.014424365096989 | validation: 3.3399767130516347]
	TIME [epoch: 28 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.014439157738309		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 4.014439157738309 | validation: 3.3455582207467174]
	TIME [epoch: 28 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.030313714587057		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 4.030313714587057 | validation: 3.4168088757610384]
	TIME [epoch: 28 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.031830732257351		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 4.031830732257351 | validation: 3.369408855652024]
	TIME [epoch: 28 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.019606668658006		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 4.019606668658006 | validation: 3.3535870377557315]
	TIME [epoch: 28 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0125427101168345		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 4.0125427101168345 | validation: 3.335074700414677]
	TIME [epoch: 28 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.009281444647879		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 4.009281444647879 | validation: 3.3414008506798094]
	TIME [epoch: 28 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.043618354931354		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 4.043618354931354 | validation: 3.464176567915357]
	TIME [epoch: 28 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.094252019266413		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 4.094252019266413 | validation: 3.358924260862794]
	TIME [epoch: 28 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.077331915784189		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 4.077331915784189 | validation: 3.3376555598647952]
	TIME [epoch: 28 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.018935590774557		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 4.018935590774557 | validation: 3.370384122843225]
	TIME [epoch: 28 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0415645679831025		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 4.0415645679831025 | validation: 3.377848459006396]
	TIME [epoch: 28 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.032437987533799		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 4.032437987533799 | validation: 3.32442416065727]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_555.pth
	Model improved!!!
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.024821404138751		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 4.024821404138751 | validation: 3.36709712812903]
	TIME [epoch: 28 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.041002634796891		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 4.041002634796891 | validation: 3.3959529521620007]
	TIME [epoch: 28 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.031307632704269		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 4.031307632704269 | validation: 3.312691069550817]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_558.pth
	Model improved!!!
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9970866861659826		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 3.9970866861659826 | validation: 3.3396095968688053]
	TIME [epoch: 28 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.023674658708849		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 4.023674658708849 | validation: 3.399949231958793]
	TIME [epoch: 28 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.050987940396446		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 4.050987940396446 | validation: 3.3217021419260857]
	TIME [epoch: 28 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.006476297580934		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 4.006476297580934 | validation: 3.3522435814134997]
	TIME [epoch: 28 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.015377010287882		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 4.015377010287882 | validation: 3.351858566122796]
	TIME [epoch: 28 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.027528225857058		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 4.027528225857058 | validation: 3.3148237516567747]
	TIME [epoch: 28 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.042161255164408		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 4.042161255164408 | validation: 3.383541218359416]
	TIME [epoch: 28 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.019911283897471		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 4.019911283897471 | validation: 3.344986572330613]
	TIME [epoch: 28 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0060243364729855		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 4.0060243364729855 | validation: 3.34577857150568]
	TIME [epoch: 28 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.038504316861417		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 4.038504316861417 | validation: 3.3403353594820406]
	TIME [epoch: 28 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.018268958611533		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 4.018268958611533 | validation: 3.360161321928927]
	TIME [epoch: 28 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0119932079331955		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 4.0119932079331955 | validation: 3.357349870569247]
	TIME [epoch: 28 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.016074985289001		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 4.016074985289001 | validation: 3.3816437316874834]
	TIME [epoch: 28 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.01040330486081		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 4.01040330486081 | validation: 3.3185601659241675]
	TIME [epoch: 28 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011386716134946		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 4.011386716134946 | validation: 3.4476208771182155]
	TIME [epoch: 28 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.027299490876447		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 4.027299490876447 | validation: 3.348632132315801]
	TIME [epoch: 28 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.019365717309215		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 4.019365717309215 | validation: 3.3282517030917775]
	TIME [epoch: 28 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.00365313791421		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 4.00365313791421 | validation: 3.3233793529798197]
	TIME [epoch: 28 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0216863708787844		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 4.0216863708787844 | validation: 3.345605700193618]
	TIME [epoch: 28 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011904441867581		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 4.011904441867581 | validation: 3.3358533609889767]
	TIME [epoch: 27.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.005210162085822		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 4.005210162085822 | validation: 3.3850165562574226]
	TIME [epoch: 28 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.014246335366854		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 4.014246335366854 | validation: 3.358393305228974]
	TIME [epoch: 28 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.036254233681303		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 4.036254233681303 | validation: 3.373836222488707]
	TIME [epoch: 28 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.013922325220777		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 4.013922325220777 | validation: 3.365474509960378]
	TIME [epoch: 28 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.004758179493103		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 4.004758179493103 | validation: 3.395804369793514]
	TIME [epoch: 28 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.023667605221164		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 4.023667605221164 | validation: 3.3117474966106375]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.996090301467027		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 3.996090301467027 | validation: 3.3353698985550846]
	TIME [epoch: 28 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.014714958344625		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 4.014714958344625 | validation: 3.3607712320248266]
	TIME [epoch: 28 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.012358868233574		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 4.012358868233574 | validation: 3.3617009843648296]
	TIME [epoch: 28 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.008427685287996		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 4.008427685287996 | validation: 3.3639962408237216]
	TIME [epoch: 28 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.01824534236188		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 4.01824534236188 | validation: 3.3148567173858248]
	TIME [epoch: 28 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.038956790171442		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 4.038956790171442 | validation: 3.3316625813273704]
	TIME [epoch: 28 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.005679279447969		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 4.005679279447969 | validation: 3.3214990776763127]
	TIME [epoch: 28 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.003097157002339		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 4.003097157002339 | validation: 3.3202174264823463]
	TIME [epoch: 28 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.001305974505712		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 4.001305974505712 | validation: 3.35435737800564]
	TIME [epoch: 28 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.022851972799798		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 4.022851972799798 | validation: 3.336315508106367]
	TIME [epoch: 28 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.993280406979666		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 3.993280406979666 | validation: 3.329738302278528]
	TIME [epoch: 28 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0313345410041315		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 4.0313345410041315 | validation: 3.315952083809407]
	TIME [epoch: 28 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.046396285565328		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 4.046396285565328 | validation: 3.392912568429486]
	TIME [epoch: 28 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.029583877928146		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 4.029583877928146 | validation: 3.3351747442534982]
	TIME [epoch: 28 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.025270793793082		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 4.025270793793082 | validation: 3.3230463425707852]
	TIME [epoch: 28 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.041680087274737		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 4.041680087274737 | validation: 3.327256771584591]
	TIME [epoch: 28 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.004068172478451		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 4.004068172478451 | validation: 3.3522231269139775]
	TIME [epoch: 28 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.006286216522605		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 4.006286216522605 | validation: 3.365146530485699]
	TIME [epoch: 28 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.032485498737628		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 4.032485498737628 | validation: 3.30575580220814]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_603.pth
	Model improved!!!
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.032022215372494		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 4.032022215372494 | validation: 3.333709492295337]
	TIME [epoch: 28 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0278845805766235		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 4.0278845805766235 | validation: 3.3256546311117683]
	TIME [epoch: 28 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9954096667620327		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 3.9954096667620327 | validation: 3.3130309558071374]
	TIME [epoch: 28 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.000667433583408		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 4.000667433583408 | validation: 3.346563969614539]
	TIME [epoch: 28 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.02785020520026		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 4.02785020520026 | validation: 3.347099926484373]
	TIME [epoch: 28 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0350155189863095		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 4.0350155189863095 | validation: 3.312810269912628]
	TIME [epoch: 28 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011329399503176		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 4.011329399503176 | validation: 3.3272129979305043]
	TIME [epoch: 28 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9905342975044977		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 3.9905342975044977 | validation: 3.315189616835123]
	TIME [epoch: 28 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.042462088699967		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 4.042462088699967 | validation: 3.3075195215889797]
	TIME [epoch: 28 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.008305811454101		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 4.008305811454101 | validation: 3.3498319940827055]
	TIME [epoch: 28 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9959784002023144		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 3.9959784002023144 | validation: 3.3549851578988337]
	TIME [epoch: 28 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.006855597349977		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 4.006855597349977 | validation: 3.3317291203808646]
	TIME [epoch: 28 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.003613715985818		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 4.003613715985818 | validation: 3.3431639488827183]
	TIME [epoch: 28 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.06217529841712		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 4.06217529841712 | validation: 3.3598989294597037]
	TIME [epoch: 28 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.034298478503302		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 4.034298478503302 | validation: 3.3220444202335044]
	TIME [epoch: 28 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9939199423122305		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 3.9939199423122305 | validation: 3.362302394865533]
	TIME [epoch: 28 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.004707355065205		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 4.004707355065205 | validation: 3.3150709524698305]
	TIME [epoch: 28 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.008717706228468		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 4.008717706228468 | validation: 3.3106746909046207]
	TIME [epoch: 28 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9877613638171545		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 3.9877613638171545 | validation: 3.3324541546772166]
	TIME [epoch: 28 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.993409632001333		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 3.993409632001333 | validation: 3.3964616880604157]
	TIME [epoch: 28 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.02785311363915		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 4.02785311363915 | validation: 3.3185716005370502]
	TIME [epoch: 28 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9985850978647415		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 3.9985850978647415 | validation: 3.3154813757669634]
	TIME [epoch: 28 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.01440775230411		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 4.01440775230411 | validation: 3.3747807080896055]
	TIME [epoch: 28 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011694810151346		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 4.011694810151346 | validation: 3.37059591515399]
	TIME [epoch: 28 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.064089559293799		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 4.064089559293799 | validation: 3.3776729401771717]
	TIME [epoch: 28 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.008436710320849		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 4.008436710320849 | validation: 3.385571475380903]
	TIME [epoch: 28 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.038895081709156		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 4.038895081709156 | validation: 3.330820518868052]
	TIME [epoch: 28 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.008067601021733		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 4.008067601021733 | validation: 3.3507755178216154]
	TIME [epoch: 28 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.040074782726532		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 4.040074782726532 | validation: 3.3990875687099527]
	TIME [epoch: 28 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.014547981617566		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 4.014547981617566 | validation: 3.34308230075324]
	TIME [epoch: 28.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.043747739996955		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 4.043747739996955 | validation: 3.401472126345336]
	TIME [epoch: 28 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.059265555609651		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 4.059265555609651 | validation: 3.3613103258420467]
	TIME [epoch: 28.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.996504085698793		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 3.996504085698793 | validation: 3.3133944710791514]
	TIME [epoch: 28 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.036014929084542		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 4.036014929084542 | validation: 3.4287547904138416]
	TIME [epoch: 28 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.03130826362188		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 4.03130826362188 | validation: 3.3711461377361287]
	TIME [epoch: 28 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.028874790723655		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 4.028874790723655 | validation: 3.347056108715675]
	TIME [epoch: 28 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.036413537302804		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 4.036413537302804 | validation: 3.31359772490422]
	TIME [epoch: 28 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9889409382951917		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 3.9889409382951917 | validation: 3.3430223915053325]
	TIME [epoch: 28 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.035098931504868		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 4.035098931504868 | validation: 3.31086384541518]
	TIME [epoch: 28 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9858759908103947		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 3.9858759908103947 | validation: 3.3548937286084426]
	TIME [epoch: 28 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1115925993030045		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 4.1115925993030045 | validation: 3.334252673609943]
	TIME [epoch: 28 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9974645303791205		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 3.9974645303791205 | validation: 3.329992540671114]
	TIME [epoch: 28 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9972162674974507		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 3.9972162674974507 | validation: 3.3963288817337687]
	TIME [epoch: 28 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.074620399095407		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 4.074620399095407 | validation: 3.3432017153700753]
	TIME [epoch: 28 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.001951904047419		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 4.001951904047419 | validation: 3.334149584971302]
	TIME [epoch: 28 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.013328143607066		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 4.013328143607066 | validation: 3.3197109203724278]
	TIME [epoch: 28 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011894828006076		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 4.011894828006076 | validation: 3.381843011865077]
	TIME [epoch: 28 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.001433181974461		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 4.001433181974461 | validation: 3.314753278729378]
	TIME [epoch: 28 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.994994441578064		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 3.994994441578064 | validation: 3.3826869547839467]
	TIME [epoch: 28 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.010554267848342		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 4.010554267848342 | validation: 3.321690509735495]
	TIME [epoch: 28 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011405090461892		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 4.011405090461892 | validation: 3.32989167863333]
	TIME [epoch: 28 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.005635003911196		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 4.005635003911196 | validation: 3.3354543482242422]
	TIME [epoch: 28 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.00792454999398		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 4.00792454999398 | validation: 3.3490790192854227]
	TIME [epoch: 28 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9990656579349677		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 3.9990656579349677 | validation: 3.3512715528823898]
	TIME [epoch: 28 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.020785315839209		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 4.020785315839209 | validation: 3.3574435381186487]
	TIME [epoch: 28 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9350454458587825		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 3.9350454458587825 | validation: 3.1647735727898065]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_659.pth
	Model improved!!!
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5929198224798196		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 3.5929198224798196 | validation: 2.9141680449058818]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_660.pth
	Model improved!!!
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4726575038007508		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 3.4726575038007508 | validation: 2.8607652411311744]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_661.pth
	Model improved!!!
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.449994989656554		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 3.449994989656554 | validation: 2.892926801984298]
	TIME [epoch: 28 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4453910747012535		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 3.4453910747012535 | validation: 2.8309670096644437]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_663.pth
	Model improved!!!
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4160171415964475		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 3.4160171415964475 | validation: 2.820329514923121]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_664.pth
	Model improved!!!
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4003215664120328		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 3.4003215664120328 | validation: 2.830878385881696]
	TIME [epoch: 28 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.38429376308281		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 3.38429376308281 | validation: 2.8128999381749633]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3708894840293846		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 3.3708894840293846 | validation: 2.7695186232227735]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3377935738292455		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 3.3377935738292455 | validation: 2.7822870580146692]
	TIME [epoch: 28 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3420142452150206		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 3.3420142452150206 | validation: 2.7195460281385615]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_669.pth
	Model improved!!!
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3072386404256613		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 3.3072386404256613 | validation: 2.716427079811772]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2841762679046864		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 3.2841762679046864 | validation: 2.6684500853210147]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_671.pth
	Model improved!!!
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2660743145016857		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 3.2660743145016857 | validation: 2.7148168774061334]
	TIME [epoch: 28 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.231432131952382		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 3.231432131952382 | validation: 2.6104593842824575]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_673.pth
	Model improved!!!
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1744593848955787		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 3.1744593848955787 | validation: 2.596894981561975]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_674.pth
	Model improved!!!
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.14104909497627		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 3.14104909497627 | validation: 2.5296897056642753]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0697097329085814		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 3.0697097329085814 | validation: 2.4568575692968313]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_676.pth
	Model improved!!!
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.998595896509572		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 2.998595896509572 | validation: 2.421522989777205]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9474117686985872		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 2.9474117686985872 | validation: 2.312708789634559]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_678.pth
	Model improved!!!
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7750875431633153		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 2.7750875431633153 | validation: 2.1913931230774533]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_679.pth
	Model improved!!!
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5860145413063713		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 2.5860145413063713 | validation: 1.9728162452164646]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2884341577120724		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 2.2884341577120724 | validation: 1.7141637616872683]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_681.pth
	Model improved!!!
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0356598312779988		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 2.0356598312779988 | validation: 1.6814544560610951]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9788020109457958		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 1.9788020109457958 | validation: 1.6576278232807347]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9231152435025503		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.9231152435025503 | validation: 1.5789994793911184]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_684.pth
	Model improved!!!
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8909685600883257		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 1.8909685600883257 | validation: 1.6529881856610933]
	TIME [epoch: 28 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.868688653701923		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.868688653701923 | validation: 1.6129314557193335]
	TIME [epoch: 28 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8642745356715642		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 1.8642745356715642 | validation: 1.652995549450102]
	TIME [epoch: 28 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.861208163031164		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 1.861208163031164 | validation: 1.5819521204953482]
	TIME [epoch: 28 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8067277800434731		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 1.8067277800434731 | validation: 1.4922731133609546]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_689.pth
	Model improved!!!
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7668536131139816		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 1.7668536131139816 | validation: 1.490121546100394]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_690.pth
	Model improved!!!
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7165300903229654		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 1.7165300903229654 | validation: 1.5038699853532609]
	TIME [epoch: 28 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7032168924837092		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 1.7032168924837092 | validation: 1.4340090480370409]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_692.pth
	Model improved!!!
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6583781493734713		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 1.6583781493734713 | validation: 1.36888770350727]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_693.pth
	Model improved!!!
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.624996069804839		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 1.624996069804839 | validation: 1.3431386216386603]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_694.pth
	Model improved!!!
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5421704713672029		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 1.5421704713672029 | validation: 1.2129228202247782]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_695.pth
	Model improved!!!
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.448816823500659		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 1.448816823500659 | validation: 1.041413785904805]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3253228744468473		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 1.3253228744468473 | validation: 0.8975309422430965]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_697.pth
	Model improved!!!
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1531687350051425		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 1.1531687350051425 | validation: 0.7448516974609365]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0287355160437648		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 1.0287355160437648 | validation: 0.6771932689194943]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_699.pth
	Model improved!!!
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9562015856209776		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.9562015856209776 | validation: 0.6657345529526838]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_700.pth
	Model improved!!!
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9135149748116731		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.9135149748116731 | validation: 0.6033843902822954]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_701.pth
	Model improved!!!
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8457954982054743		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.8457954982054743 | validation: 0.5817484558406245]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_702.pth
	Model improved!!!
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8474341104618218		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.8474341104618218 | validation: 0.5660556693601168]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_703.pth
	Model improved!!!
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7972319418705544		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.7972319418705544 | validation: 0.5601611650331302]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_704.pth
	Model improved!!!
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7859961814142702		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.7859961814142702 | validation: 0.6476234072400585]
	TIME [epoch: 28 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.773259582189826		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.773259582189826 | validation: 0.5080505821598875]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_706.pth
	Model improved!!!
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7412579622137404		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.7412579622137404 | validation: 0.5747308275278122]
	TIME [epoch: 28 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7601745833913361		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.7601745833913361 | validation: 0.5345699392535406]
	TIME [epoch: 28 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191861071222897		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.7191861071222897 | validation: 0.58369947444075]
	TIME [epoch: 28 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073570412730625		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.7073570412730625 | validation: 0.49818776177008517]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_710.pth
	Model improved!!!
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6950917522736378		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.6950917522736378 | validation: 0.5928988943183984]
	TIME [epoch: 28 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6335980196311057		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.6335980196311057 | validation: 0.5376131366483047]
	TIME [epoch: 28.1 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6378868397954705		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.6378868397954705 | validation: 0.4991742308253072]
	TIME [epoch: 28 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6057368925818672		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.6057368925818672 | validation: 0.5148563648150456]
	TIME [epoch: 28 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6050142250169702		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.6050142250169702 | validation: 0.4523735498665563]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5899913698559933		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.5899913698559933 | validation: 0.4664077676623747]
	TIME [epoch: 28 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5925650713679769		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.5925650713679769 | validation: 0.4474056460021716]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_717.pth
	Model improved!!!
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5632377276127709		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.5632377276127709 | validation: 0.46018722301005993]
	TIME [epoch: 28 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.557289108814419		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.557289108814419 | validation: 0.44075727500450185]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5633593909551634		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5633593909551634 | validation: 0.4312586444435742]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_720.pth
	Model improved!!!
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6068467599823867		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.6068467599823867 | validation: 0.4851058585351394]
	TIME [epoch: 28.1 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5528128717486456		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.5528128717486456 | validation: 0.43836758067720966]
	TIME [epoch: 28 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558558501677862		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.558558501677862 | validation: 0.4198770718897589]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_723.pth
	Model improved!!!
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381793849247819		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.5381793849247819 | validation: 0.4735218772142109]
	TIME [epoch: 28 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5273398252970566		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.5273398252970566 | validation: 0.3989324242396162]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115881636149419		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.5115881636149419 | validation: 0.38900774884147804]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5281232113508131		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.5281232113508131 | validation: 0.39645834511003153]
	TIME [epoch: 28 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.508417585203132		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.508417585203132 | validation: 0.43936827273679385]
	TIME [epoch: 28 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5234650617019673		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.5234650617019673 | validation: 0.5171111919339926]
	TIME [epoch: 28 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5032903975225063		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.5032903975225063 | validation: 0.44345638447821983]
	TIME [epoch: 28 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49455160724124997		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.49455160724124997 | validation: 0.43356356671296153]
	TIME [epoch: 28 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49593320547698905		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.49593320547698905 | validation: 0.45504536592998224]
	TIME [epoch: 28 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5188489916842601		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.5188489916842601 | validation: 0.4233141104534081]
	TIME [epoch: 28 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5228942992686607		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5228942992686607 | validation: 0.4812782106642903]
	TIME [epoch: 28 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5456544189170587		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.5456544189170587 | validation: 0.44675879386456147]
	TIME [epoch: 28 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5527747210364243		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.5527747210364243 | validation: 0.5205724452313792]
	TIME [epoch: 28 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5222900976199376		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.5222900976199376 | validation: 0.4114666924654691]
	TIME [epoch: 28 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47327121044343917		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.47327121044343917 | validation: 0.4393640831574158]
	TIME [epoch: 28 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49296322741535736		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.49296322741535736 | validation: 0.3770154103486648]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_739.pth
	Model improved!!!
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679938528416536		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.4679938528416536 | validation: 0.40381963432726564]
	TIME [epoch: 28 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4731795892949059		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.4731795892949059 | validation: 0.4010139158827182]
	TIME [epoch: 28 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5043890605301501		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.5043890605301501 | validation: 0.3898977658517664]
	TIME [epoch: 28 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48952696614643665		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.48952696614643665 | validation: 0.4675446413456984]
	TIME [epoch: 28 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5076390904560073		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.5076390904560073 | validation: 0.4139838130666892]
	TIME [epoch: 28 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4545086141321413		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.4545086141321413 | validation: 0.4177080052707059]
	TIME [epoch: 28 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4900011178021364		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.4900011178021364 | validation: 0.4297524043937538]
	TIME [epoch: 28 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5055836629287		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.5055836629287 | validation: 0.40976810368743116]
	TIME [epoch: 28 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46055773058478333		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.46055773058478333 | validation: 0.4169589559579077]
	TIME [epoch: 28 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4647479066176247		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.4647479066176247 | validation: 0.4304223940264153]
	TIME [epoch: 28 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47103253824526614		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.47103253824526614 | validation: 0.4110429459680273]
	TIME [epoch: 28 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4721406636201746		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.4721406636201746 | validation: 0.4086404384180641]
	TIME [epoch: 28 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4699060155038765		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.4699060155038765 | validation: 0.3819636978449238]
	TIME [epoch: 28 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5087383561005268		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.5087383561005268 | validation: 0.3961796569531491]
	TIME [epoch: 28 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48134863036587144		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.48134863036587144 | validation: 0.4269513544715461]
	TIME [epoch: 28 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4674244181966466		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.4674244181966466 | validation: 0.4451571307033766]
	TIME [epoch: 28 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47143807454290804		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.47143807454290804 | validation: 0.463981062594496]
	TIME [epoch: 28 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5403214795701499		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.5403214795701499 | validation: 0.3802243083875918]
	TIME [epoch: 28 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46126126679822643		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.46126126679822643 | validation: 0.37814246305502364]
	TIME [epoch: 28 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4394608860969394		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4394608860969394 | validation: 0.3855765382944057]
	TIME [epoch: 28 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4524333266761687		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.4524333266761687 | validation: 0.4153751737910366]
	TIME [epoch: 28 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4510412743979323		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.4510412743979323 | validation: 0.39060853760260833]
	TIME [epoch: 28 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4437952775607109		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.4437952775607109 | validation: 0.3513082606363349]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_762.pth
	Model improved!!!
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5019414443260989		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.5019414443260989 | validation: 0.3882604568450085]
	TIME [epoch: 28 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45295644288643366		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.45295644288643366 | validation: 0.37501408720740076]
	TIME [epoch: 28 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47151993909008505		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.47151993909008505 | validation: 0.3702653065323137]
	TIME [epoch: 28 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4481863237052491		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.4481863237052491 | validation: 0.35053825896499874]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44808243079708854		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.44808243079708854 | validation: 0.4027891338484299]
	TIME [epoch: 28 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47316399767727874		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.47316399767727874 | validation: 0.3798374886833744]
	TIME [epoch: 28 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45801422588762364		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.45801422588762364 | validation: 0.3362685175977155]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46020307800740334		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.46020307800740334 | validation: 0.37408234362272647]
	TIME [epoch: 28 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45143523818519304		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.45143523818519304 | validation: 0.35615717598660396]
	TIME [epoch: 28.1 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4677652608183053		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.4677652608183053 | validation: 0.37439027905530486]
	TIME [epoch: 28 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42444992706139306		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.42444992706139306 | validation: 0.36194274735206267]
	TIME [epoch: 28.1 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44786876209991544		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.44786876209991544 | validation: 0.3706230928981322]
	TIME [epoch: 28 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48120163625433104		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.48120163625433104 | validation: 0.3580826006691058]
	TIME [epoch: 28 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43817168646111476		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.43817168646111476 | validation: 0.3704068900415207]
	TIME [epoch: 28 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44378373844518015		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.44378373844518015 | validation: 0.3708129176448555]
	TIME [epoch: 28 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42947870727427084		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.42947870727427084 | validation: 0.3554646291602684]
	TIME [epoch: 28 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4369052553234366		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.4369052553234366 | validation: 0.4285391147238407]
	TIME [epoch: 28 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5198932291118563		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.5198932291118563 | validation: 0.3952848679567238]
	TIME [epoch: 28 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271481974956207		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.5271481974956207 | validation: 0.44312905791048446]
	TIME [epoch: 28 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4517273468136419		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.4517273468136419 | validation: 0.4003741843107858]
	TIME [epoch: 28 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45591636857393536		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.45591636857393536 | validation: 0.3695925189617519]
	TIME [epoch: 28 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43642116257665237		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.43642116257665237 | validation: 0.42297422551444075]
	TIME [epoch: 28 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44461309687483785		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.44461309687483785 | validation: 0.4161260426684013]
	TIME [epoch: 28 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4281535710364244		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.4281535710364244 | validation: 0.3483302939898289]
	TIME [epoch: 28 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46965355973140743		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.46965355973140743 | validation: 0.39531652046668153]
	TIME [epoch: 28 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44025431169038154		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.44025431169038154 | validation: 0.3831959098175153]
	TIME [epoch: 28 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43670841436689345		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.43670841436689345 | validation: 0.3777523001874073]
	TIME [epoch: 28 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44997574985004457		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.44997574985004457 | validation: 0.3676893218323806]
	TIME [epoch: 28 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4436444049765669		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.4436444049765669 | validation: 0.3824256256839553]
	TIME [epoch: 28 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43465361182880907		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.43465361182880907 | validation: 0.3885476659458418]
	TIME [epoch: 28 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48605424346496867		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.48605424346496867 | validation: 0.4360738513146008]
	TIME [epoch: 28 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5028010394602647		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.5028010394602647 | validation: 0.4242222192011704]
	TIME [epoch: 28 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4536727918843507		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.4536727918843507 | validation: 0.36516819709201953]
	TIME [epoch: 28 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.437517569787377		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.437517569787377 | validation: 0.36342398400415143]
	TIME [epoch: 28 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4451166970981626		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.4451166970981626 | validation: 0.4253782083622791]
	TIME [epoch: 28 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4984743713649954		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.4984743713649954 | validation: 0.34837445489069185]
	TIME [epoch: 28 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42716045237644673		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.42716045237644673 | validation: 0.35351494501007447]
	TIME [epoch: 28 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4091350086484248		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.4091350086484248 | validation: 0.3757259846939878]
	TIME [epoch: 28 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4538644448470332		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.4538644448470332 | validation: 0.4191555414796676]
	TIME [epoch: 28 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183988013938088		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.4183988013938088 | validation: 0.40719596001282266]
	TIME [epoch: 28 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40871046732649363		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.40871046732649363 | validation: 0.35271012670912966]
	TIME [epoch: 28 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44917409441495193		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.44917409441495193 | validation: 0.3429929201725869]
	TIME [epoch: 28 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47208816259267966		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.47208816259267966 | validation: 0.35602784678791444]
	TIME [epoch: 28 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4351114156521136		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.4351114156521136 | validation: 0.4341970829449523]
	TIME [epoch: 28 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5376148178099037		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.5376148178099037 | validation: 0.362141187813598]
	TIME [epoch: 28 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4123691427361071		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.4123691427361071 | validation: 0.3462029403404858]
	TIME [epoch: 28 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41711642670908167		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.41711642670908167 | validation: 0.3738793049300472]
	TIME [epoch: 28 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41019738900068814		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.41019738900068814 | validation: 0.33820452305240084]
	TIME [epoch: 28 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4218104801554274		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.4218104801554274 | validation: 0.3418669295239831]
	TIME [epoch: 28 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4454233896590254		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.4454233896590254 | validation: 0.3815962878748628]
	TIME [epoch: 28 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4279109767519316		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.4279109767519316 | validation: 0.36121415197728596]
	TIME [epoch: 28 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.508718704009672		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.508718704009672 | validation: 0.5018876990464691]
	TIME [epoch: 28 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5373741678155542		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.5373741678155542 | validation: 0.6282119466390539]
	TIME [epoch: 28 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499288712435196		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.5499288712435196 | validation: 0.33370158125276095]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_816.pth
	Model improved!!!
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4049093239605136		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.4049093239605136 | validation: 0.35242088878428207]
	TIME [epoch: 28 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4091741305681545		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4091741305681545 | validation: 0.3970118088839938]
	TIME [epoch: 28 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4359119072688989		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.4359119072688989 | validation: 0.3603610259102469]
	TIME [epoch: 28 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41445344492012876		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.41445344492012876 | validation: 0.35394579075199245]
	TIME [epoch: 28 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44475005702037634		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.44475005702037634 | validation: 0.36816329593837666]
	TIME [epoch: 28 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43320682225027674		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.43320682225027674 | validation: 0.3320535091357127]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_822.pth
	Model improved!!!
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4296598997673855		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.4296598997673855 | validation: 0.3590786986889225]
	TIME [epoch: 28 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40571971493106934		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.40571971493106934 | validation: 0.34121473973797434]
	TIME [epoch: 28 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4079404115392026		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.4079404115392026 | validation: 0.32643974273579973]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4079914569549656		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.4079914569549656 | validation: 0.3649311797539113]
	TIME [epoch: 28 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056403422707392		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.4056403422707392 | validation: 0.42213105745862534]
	TIME [epoch: 28 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5005636940054103		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.5005636940054103 | validation: 0.3996352335779675]
	TIME [epoch: 28 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4147616952939124		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.4147616952939124 | validation: 0.3390173937730839]
	TIME [epoch: 28 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42136673640044076		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.42136673640044076 | validation: 0.4126953115700711]
	TIME [epoch: 28 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43002522800599186		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.43002522800599186 | validation: 0.3156444333932862]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722603703928946		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.4722603703928946 | validation: 0.34238808538266824]
	TIME [epoch: 28 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4246672988692164		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.4246672988692164 | validation: 0.436899586202889]
	TIME [epoch: 28 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4226759572157342		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.4226759572157342 | validation: 0.34140035411403935]
	TIME [epoch: 28 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4000808302086511		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.4000808302086511 | validation: 0.32108893331776583]
	TIME [epoch: 28 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4436166602939675		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4436166602939675 | validation: 0.3267564601313407]
	TIME [epoch: 28 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4382002206469684		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.4382002206469684 | validation: 0.41984937308375]
	TIME [epoch: 28 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4479046991165793		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.4479046991165793 | validation: 0.31031121598714345]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_838.pth
	Model improved!!!
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4179734683074289		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.4179734683074289 | validation: 0.30764527979494277]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_839.pth
	Model improved!!!
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911280078720265		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.3911280078720265 | validation: 0.3209726788753253]
	TIME [epoch: 28 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43744913433272165		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.43744913433272165 | validation: 0.3540729511247522]
	TIME [epoch: 28 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4343993654490025		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.4343993654490025 | validation: 0.3909006075799195]
	TIME [epoch: 28 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4240180218999354		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.4240180218999354 | validation: 0.3341113412901303]
	TIME [epoch: 28 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3951027114126035		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.3951027114126035 | validation: 0.323185075707288]
	TIME [epoch: 28 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3979509137114733		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.3979509137114733 | validation: 0.3314937861398144]
	TIME [epoch: 28 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39528580867414026		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.39528580867414026 | validation: 0.3789541965119023]
	TIME [epoch: 28 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973087927132188		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.3973087927132188 | validation: 0.34224976986263883]
	TIME [epoch: 28 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40439925476130556		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.40439925476130556 | validation: 0.42280274282191366]
	TIME [epoch: 28 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43537611072295024		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.43537611072295024 | validation: 0.3646340924245422]
	TIME [epoch: 28 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3991339866586559		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.3991339866586559 | validation: 0.356029291488129]
	TIME [epoch: 28 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39509732024239685		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.39509732024239685 | validation: 0.31966070042820494]
	TIME [epoch: 28 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40818130360554206		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.40818130360554206 | validation: 0.4361768645852404]
	TIME [epoch: 28 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4349593366211893		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.4349593366211893 | validation: 0.3321766253058837]
	TIME [epoch: 28 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.447043955904289		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.447043955904289 | validation: 0.38316256401490334]
	TIME [epoch: 28 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41292610396611995		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.41292610396611995 | validation: 0.37641485129948815]
	TIME [epoch: 28 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.412174006269628		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.412174006269628 | validation: 0.38610809332550317]
	TIME [epoch: 28 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42713164015937455		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.42713164015937455 | validation: 0.380059266171063]
	TIME [epoch: 28 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40157714220238055		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.40157714220238055 | validation: 0.33680378656212845]
	TIME [epoch: 28 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4037340198734666		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.4037340198734666 | validation: 0.35550813664842323]
	TIME [epoch: 28 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39456791923302525		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.39456791923302525 | validation: 0.33500513444709984]
	TIME [epoch: 28 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43234572068356814		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.43234572068356814 | validation: 0.3241004881677711]
	TIME [epoch: 28 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.412444511353159		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.412444511353159 | validation: 0.3510729452835284]
	TIME [epoch: 28 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39448660853099093		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.39448660853099093 | validation: 0.32093009250138765]
	TIME [epoch: 28 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43131937446546414		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.43131937446546414 | validation: 0.4702958968402344]
	TIME [epoch: 28 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4239386071630751		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.4239386071630751 | validation: 0.3749440727284397]
	TIME [epoch: 28 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6097467420611572		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.6097467420611572 | validation: 0.32734823626173265]
	TIME [epoch: 28 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42748636557658		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.42748636557658 | validation: 0.3138618782961566]
	TIME [epoch: 28 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925190508945198		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.3925190508945198 | validation: 0.32601699261745354]
	TIME [epoch: 28 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3901784654198326		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.3901784654198326 | validation: 0.3092859196225248]
	TIME [epoch: 28 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40416775835999436		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.40416775835999436 | validation: 0.3577765980148098]
	TIME [epoch: 28 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4125470403391219		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.4125470403391219 | validation: 0.3442091158298971]
	TIME [epoch: 28 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043217038043304		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.4043217038043304 | validation: 0.3765055002435381]
	TIME [epoch: 28 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.403255660775785		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.403255660775785 | validation: 0.31426574295788123]
	TIME [epoch: 28 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.395238662285807		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.395238662285807 | validation: 0.39938911105757585]
	TIME [epoch: 28 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4010945113923031		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.4010945113923031 | validation: 0.3346965378450542]
	TIME [epoch: 28 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4034514605769803		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.4034514605769803 | validation: 0.40059224020101897]
	TIME [epoch: 28 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44085112591748393		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.44085112591748393 | validation: 0.3437410383467824]
	TIME [epoch: 28 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3900032840168898		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.3900032840168898 | validation: 0.29410742532154266]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_878.pth
	Model improved!!!
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872948235234983		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.3872948235234983 | validation: 0.3613795877860808]
	TIME [epoch: 28 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38745727180401435		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.38745727180401435 | validation: 0.3350871470942441]
	TIME [epoch: 28 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931527813884145		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.3931527813884145 | validation: 0.33987450923339735]
	TIME [epoch: 28 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39762328145638703		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.39762328145638703 | validation: 0.3168521695551182]
	TIME [epoch: 28 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4299020012378918		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.4299020012378918 | validation: 0.3567121343706643]
	TIME [epoch: 28 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3940351667446596		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.3940351667446596 | validation: 0.3002323959253961]
	TIME [epoch: 28 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39221905345111374		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.39221905345111374 | validation: 0.3251649350861064]
	TIME [epoch: 28 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3773971330929354		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.3773971330929354 | validation: 0.3419560176022606]
	TIME [epoch: 28 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779387502988339		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.3779387502988339 | validation: 0.3063842281839325]
	TIME [epoch: 28 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39572309017808915		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.39572309017808915 | validation: 0.32248613646151697]
	TIME [epoch: 28 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3982579465254012		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.3982579465254012 | validation: 0.35180836847205116]
	TIME [epoch: 28 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43213292187810787		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.43213292187810787 | validation: 0.4465788461041346]
	TIME [epoch: 28 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4298379028996003		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.4298379028996003 | validation: 0.35737568445379025]
	TIME [epoch: 28 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39600067178290155		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.39600067178290155 | validation: 0.32890319586501776]
	TIME [epoch: 28 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3880783244499545		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.3880783244499545 | validation: 0.36094324385892335]
	TIME [epoch: 28 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39617065691283243		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.39617065691283243 | validation: 0.33145169489210907]
	TIME [epoch: 28 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3858535034637299		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.3858535034637299 | validation: 0.3475551884411418]
	TIME [epoch: 28 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39068850742435857		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.39068850742435857 | validation: 0.3769731569066485]
	TIME [epoch: 28 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40616925504902024		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.40616925504902024 | validation: 0.35232380421106163]
	TIME [epoch: 28 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41760457430317144		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.41760457430317144 | validation: 0.37513205026480395]
	TIME [epoch: 28 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3817798527133962		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.3817798527133962 | validation: 0.3199365892204385]
	TIME [epoch: 28 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39128072892856774		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.39128072892856774 | validation: 0.3714994622879025]
	TIME [epoch: 28 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39915516167791143		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.39915516167791143 | validation: 0.33907433423448896]
	TIME [epoch: 28 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3815908818877544		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.3815908818877544 | validation: 0.35294882689151863]
	TIME [epoch: 28 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4238786991399504		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.4238786991399504 | validation: 0.3713318957549486]
	TIME [epoch: 28 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39420523876957797		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.39420523876957797 | validation: 0.33778028015533507]
	TIME [epoch: 28 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44120421886233496		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.44120421886233496 | validation: 0.32416250666140933]
	TIME [epoch: 28 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.449852112142311		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.449852112142311 | validation: 0.4398618670246103]
	TIME [epoch: 28 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4520580350969591		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.4520580350969591 | validation: 0.3366997851396438]
	TIME [epoch: 28 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4088000525384446		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.4088000525384446 | validation: 0.3476006400177562]
	TIME [epoch: 28 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39230227364369685		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.39230227364369685 | validation: 0.3243265960920106]
	TIME [epoch: 28 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38024406287161683		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.38024406287161683 | validation: 0.3058605309388432]
	TIME [epoch: 28 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38133927295666625		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.38133927295666625 | validation: 0.36144097997951713]
	TIME [epoch: 28 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41084630726575033		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.41084630726575033 | validation: 0.3597073466407154]
	TIME [epoch: 28 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4162127638517729		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.4162127638517729 | validation: 0.375855054700921]
	TIME [epoch: 28 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40161110707079595		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.40161110707079595 | validation: 0.3162956421837216]
	TIME [epoch: 28 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3825945967717749		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.3825945967717749 | validation: 0.30947622287155246]
	TIME [epoch: 28 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4128258873355933		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.4128258873355933 | validation: 0.34443603344839996]
	TIME [epoch: 28 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39737474993357685		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.39737474993357685 | validation: 0.38359985320317963]
	TIME [epoch: 28 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4114798354652037		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.4114798354652037 | validation: 0.3394068946758003]
	TIME [epoch: 28 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805179530109755		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.3805179530109755 | validation: 0.3408460140352563]
	TIME [epoch: 28 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938794659872463		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.3938794659872463 | validation: 0.35542959349015557]
	TIME [epoch: 28 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3858305630745299		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.3858305630745299 | validation: 0.36091256873440175]
	TIME [epoch: 28 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4231030107872874		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.4231030107872874 | validation: 0.32874986407799284]
	TIME [epoch: 28 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39295958131668285		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.39295958131668285 | validation: 0.3465833267310414]
	TIME [epoch: 28 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39780465513205365		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.39780465513205365 | validation: 0.31818512712125085]
	TIME [epoch: 28 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39775757320598526		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.39775757320598526 | validation: 0.3514232185061949]
	TIME [epoch: 28 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38356175532607895		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.38356175532607895 | validation: 0.3140234847868022]
	TIME [epoch: 28 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3832977183744463		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.3832977183744463 | validation: 0.32845348847664185]
	TIME [epoch: 28 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.388921812073476		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.388921812073476 | validation: 0.3549486225863103]
	TIME [epoch: 28 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39022520339041755		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.39022520339041755 | validation: 0.3413927308321847]
	TIME [epoch: 28 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889807146303917		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.3889807146303917 | validation: 0.3137679446122945]
	TIME [epoch: 28 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3832474757467955		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.3832474757467955 | validation: 0.3195624320435734]
	TIME [epoch: 28 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3838655175534008		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.3838655175534008 | validation: 0.3366224568390009]
	TIME [epoch: 28 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934171427030837		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.3934171427030837 | validation: 0.3190222825775133]
	TIME [epoch: 28 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736036837914487		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.3736036837914487 | validation: 0.3231475053475097]
	TIME [epoch: 28 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.382296573370804		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.382296573370804 | validation: 0.4430252004638644]
	TIME [epoch: 28 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4413037735211154		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.4413037735211154 | validation: 0.3189689648799985]
	TIME [epoch: 28 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38269349153070664		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.38269349153070664 | validation: 0.35631165610784565]
	TIME [epoch: 28 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3874012502151303		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.3874012502151303 | validation: 0.3534253883971678]
	TIME [epoch: 28 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3819579988946925		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.3819579988946925 | validation: 0.33729581370938144]
	TIME [epoch: 28 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37773799546976466		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.37773799546976466 | validation: 0.34773276876399173]
	TIME [epoch: 28 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3792605956001265		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.3792605956001265 | validation: 0.34446308649923324]
	TIME [epoch: 28 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3799507425498541		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.3799507425498541 | validation: 0.33502176633036923]
	TIME [epoch: 28 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38395078992253934		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.38395078992253934 | validation: 0.33556466523339135]
	TIME [epoch: 28 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37998869692844384		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.37998869692844384 | validation: 0.3363953680851273]
	TIME [epoch: 28 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011140086161817		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.4011140086161817 | validation: 0.3326046015646458]
	TIME [epoch: 28 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844317617746247		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.3844317617746247 | validation: 0.32884848395939514]
	TIME [epoch: 28 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41297666465575245		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.41297666465575245 | validation: 0.31013248809829824]
	TIME [epoch: 28 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3941926314798141		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.3941926314798141 | validation: 0.30097188358744414]
	TIME [epoch: 28 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38372512432616845		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.38372512432616845 | validation: 0.3725856113172084]
	TIME [epoch: 28 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42765756962317863		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.42765756962317863 | validation: 0.33292140712717233]
	TIME [epoch: 28 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3915841455986794		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.3915841455986794 | validation: 0.35952116631857167]
	TIME [epoch: 28 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3798538259702313		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.3798538259702313 | validation: 0.32210043162993246]
	TIME [epoch: 28 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45122860500334694		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.45122860500334694 | validation: 0.2896104267579571]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_953.pth
	Model improved!!!
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373540988072542		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.373540988072542 | validation: 0.32917201355933773]
	TIME [epoch: 28 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38819726673543187		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.38819726673543187 | validation: 0.27462709156844684]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_955.pth
	Model improved!!!
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38580634434666083		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.38580634434666083 | validation: 0.28338382727480016]
	TIME [epoch: 28 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37219032786844236		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.37219032786844236 | validation: 0.3135027370317855]
	TIME [epoch: 28 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38351152929981247		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.38351152929981247 | validation: 0.31506225820473255]
	TIME [epoch: 28 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3749202491244933		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.3749202491244933 | validation: 0.2996586652525861]
	TIME [epoch: 28 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37421376290819214		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.37421376290819214 | validation: 0.29949429957487705]
	TIME [epoch: 28 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37122881133150565		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.37122881133150565 | validation: 0.3102810430933198]
	TIME [epoch: 28 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36944652275485934		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.36944652275485934 | validation: 0.3095050077299542]
	TIME [epoch: 28 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38247868598238016		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.38247868598238016 | validation: 0.31460087477929927]
	TIME [epoch: 28.1 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843609850790473		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.3843609850790473 | validation: 0.34680861375350475]
	TIME [epoch: 28 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.378724425975691		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.378724425975691 | validation: 0.2856692408274429]
	TIME [epoch: 28 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3605014335679966		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.3605014335679966 | validation: 0.2884183198868637]
	TIME [epoch: 28 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37201343883278426		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.37201343883278426 | validation: 0.3234808716827189]
	TIME [epoch: 28 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4004425156669581		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.4004425156669581 | validation: 0.3241774748499391]
	TIME [epoch: 28 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37833356532120976		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.37833356532120976 | validation: 0.32228824639515674]
	TIME [epoch: 28 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.379974016544574		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.379974016544574 | validation: 0.27032331059037445]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_970.pth
	Model improved!!!
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37520469032112624		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.37520469032112624 | validation: 0.2760949619026687]
	TIME [epoch: 28 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36886487937557955		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.36886487937557955 | validation: 0.27722424856836886]
	TIME [epoch: 28 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851611924063884		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.3851611924063884 | validation: 0.34206695495001577]
	TIME [epoch: 28 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3998358639133556		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.3998358639133556 | validation: 0.3381168563478058]
	TIME [epoch: 28 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3819372442586082		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.3819372442586082 | validation: 0.2728058552510739]
	TIME [epoch: 28 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36870014403812995		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.36870014403812995 | validation: 0.3046047923177801]
	TIME [epoch: 28 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38546457755442587		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.38546457755442587 | validation: 0.3463324444487554]
	TIME [epoch: 28 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36027374479100194		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.36027374479100194 | validation: 0.2997714909712192]
	TIME [epoch: 28 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36842786540862693		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.36842786540862693 | validation: 0.2901435422832948]
	TIME [epoch: 28 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3862613730334862		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.3862613730334862 | validation: 0.34291341226206984]
	TIME [epoch: 28 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38904572803187365		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.38904572803187365 | validation: 0.3364175665852103]
	TIME [epoch: 28 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3855727099563751		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.3855727099563751 | validation: 0.30489254930183846]
	TIME [epoch: 28 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640560398069241		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.3640560398069241 | validation: 0.34400751295860316]
	TIME [epoch: 28 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3602860780341756		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.3602860780341756 | validation: 0.29778351603306896]
	TIME [epoch: 28 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4028207279441669		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.4028207279441669 | validation: 0.310124779721086]
	TIME [epoch: 28 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3785582277866827		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.3785582277866827 | validation: 0.3715742719691986]
	TIME [epoch: 28 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37704265724419944		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.37704265724419944 | validation: 0.31813467019072117]
	TIME [epoch: 28 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.354649000261843		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.354649000261843 | validation: 0.30124638805832377]
	TIME [epoch: 28 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36136307169210113		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.36136307169210113 | validation: 0.2844085356058849]
	TIME [epoch: 28 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3624884085243892		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.3624884085243892 | validation: 0.315697978781552]
	TIME [epoch: 28 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3665232949714493		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.3665232949714493 | validation: 0.29950848093351207]
	TIME [epoch: 28 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37734365488541266		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.37734365488541266 | validation: 0.32821660022322746]
	TIME [epoch: 28 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805372103859487		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.3805372103859487 | validation: 0.3035563950688181]
	TIME [epoch: 28 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3644399398367046		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.3644399398367046 | validation: 0.3206322133263079]
	TIME [epoch: 28 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37840253886779335		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.37840253886779335 | validation: 0.3398440190810949]
	TIME [epoch: 28 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3763891685336994		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.3763891685336994 | validation: 0.3242452729111298]
	TIME [epoch: 28 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3881549254487662		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.3881549254487662 | validation: 0.3382801713584682]
	TIME [epoch: 28 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37336020836028416		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.37336020836028416 | validation: 0.3198107672571474]
	TIME [epoch: 28.1 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37262831179455974		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.37262831179455974 | validation: 0.3191704414913004]
	TIME [epoch: 28.1 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4069489802344933		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.4069489802344933 | validation: 0.3917894341883249]
	TIME [epoch: 28 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.385876896506243		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.385876896506243 | validation: 0.2875050493645641]
	TIME [epoch: 28 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368926495385661		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.368926495385661 | validation: 0.2898565403805413]
	TIME [epoch: 28 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35596280846717065		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.35596280846717065 | validation: 0.2995402481929386]
	TIME [epoch: 28 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542612946576458		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.3542612946576458 | validation: 0.361332581913497]
	TIME [epoch: 28 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3863244974959352		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.3863244974959352 | validation: 0.31884139314129295]
	TIME [epoch: 28 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3582119975154483		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.3582119975154483 | validation: 0.3028528363599082]
	TIME [epoch: 28 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3813252371044004		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.3813252371044004 | validation: 0.2991653015747115]
	TIME [epoch: 28 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653592777041521		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.3653592777041521 | validation: 0.2892452008891672]
	TIME [epoch: 28 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36537223343400743		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.36537223343400743 | validation: 0.3437255582040865]
	TIME [epoch: 28 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36974303607100645		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.36974303607100645 | validation: 0.3143729979665472]
	TIME [epoch: 28 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36574156073679737		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.36574156073679737 | validation: 0.32270485525145]
	TIME [epoch: 28 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696154692499368		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.3696154692499368 | validation: 0.30603052408905257]
	TIME [epoch: 28 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37285046076639233		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.37285046076639233 | validation: 0.314511502363594]
	TIME [epoch: 28 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36000644477617894		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.36000644477617894 | validation: 0.3301623164212569]
	TIME [epoch: 28 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37869628530775234		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.37869628530775234 | validation: 0.33139576085717715]
	TIME [epoch: 28 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37107884391037904		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.37107884391037904 | validation: 0.33810207474745485]
	TIME [epoch: 28 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35694241302367175		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.35694241302367175 | validation: 0.30401116356098906]
	TIME [epoch: 28 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36863000022193554		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.36863000022193554 | validation: 0.28193810373941547]
	TIME [epoch: 28 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512788691979474		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.3512788691979474 | validation: 0.289204162267248]
	TIME [epoch: 28 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347790685198462		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.347790685198462 | validation: 0.2932640663019683]
	TIME [epoch: 28 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572270993048658		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.3572270993048658 | validation: 0.29855742536091684]
	TIME [epoch: 28 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3686956369973117		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.3686956369973117 | validation: 0.3296680361531695]
	TIME [epoch: 28 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36407859067501513		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.36407859067501513 | validation: 0.31636116663380504]
	TIME [epoch: 28 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3633069376699439		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.3633069376699439 | validation: 0.29323878810391835]
	TIME [epoch: 28 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704684746946004		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.3704684746946004 | validation: 0.30264567540553555]
	TIME [epoch: 28 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3643608885062203		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.3643608885062203 | validation: 0.3111967604691378]
	TIME [epoch: 28 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36669111413239247		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.36669111413239247 | validation: 0.31954489964691896]
	TIME [epoch: 28 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35024943665520664		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.35024943665520664 | validation: 0.28320866922350424]
	TIME [epoch: 28 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3529181539481335		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.3529181539481335 | validation: 0.31542663019535416]
	TIME [epoch: 28 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3636586998785359		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.3636586998785359 | validation: 0.3424113455438289]
	TIME [epoch: 28 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38779319809088797		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.38779319809088797 | validation: 0.33850236539206463]
	TIME [epoch: 28 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37345251280746006		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.37345251280746006 | validation: 0.30121457288941317]
	TIME [epoch: 28 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3662924456433325		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.3662924456433325 | validation: 0.33151058086421514]
	TIME [epoch: 28 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771093358161735		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.3771093358161735 | validation: 0.3546311479421891]
	TIME [epoch: 28 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38722989173513095		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.38722989173513095 | validation: 0.313175452656565]
	TIME [epoch: 28 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36687715916645036		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.36687715916645036 | validation: 0.3121918140242439]
	TIME [epoch: 28 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3582237327544018		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.3582237327544018 | validation: 0.359815949994644]
	TIME [epoch: 28 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843547276793635		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.3843547276793635 | validation: 0.3682967024409325]
	TIME [epoch: 28 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38169193067863477		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.38169193067863477 | validation: 0.36375451063150577]
	TIME [epoch: 28 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3751234694932013		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.3751234694932013 | validation: 0.3120473951038714]
	TIME [epoch: 28 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632777967317734		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.3632777967317734 | validation: 0.3069291905496589]
	TIME [epoch: 28 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3772125849499566		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.3772125849499566 | validation: 0.3034611280981275]
	TIME [epoch: 28 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3719283281003888		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.3719283281003888 | validation: 0.3106283824772816]
	TIME [epoch: 28 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3869506159130659		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.3869506159130659 | validation: 0.4322889742365918]
	TIME [epoch: 28.1 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44403344629272257		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.44403344629272257 | validation: 0.3120464270305914]
	TIME [epoch: 28 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3604207973881508		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.3604207973881508 | validation: 0.2913535585241808]
	TIME [epoch: 28 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543015460516219		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.3543015460516219 | validation: 0.27743901465442494]
	TIME [epoch: 28 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3751796313218554		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.3751796313218554 | validation: 0.3327600686574785]
	TIME [epoch: 28 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36587463220261196		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.36587463220261196 | validation: 0.30890299469431476]
	TIME [epoch: 28 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3529375343029004		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.3529375343029004 | validation: 0.27364198097418185]
	TIME [epoch: 28 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36175866839631854		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.36175866839631854 | validation: 0.30263166293435595]
	TIME [epoch: 28 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36287452565914086		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.36287452565914086 | validation: 0.3391685086245304]
	TIME [epoch: 28 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3630232174702866		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.3630232174702866 | validation: 0.27694882698492473]
	TIME [epoch: 28 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3604050859321237		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.3604050859321237 | validation: 0.2754016100551797]
	TIME [epoch: 28 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525508000789389		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.3525508000789389 | validation: 0.28171914285574157]
	TIME [epoch: 28 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501547714878852		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.3501547714878852 | validation: 0.3674378216092959]
	TIME [epoch: 28 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810996265160481		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.3810996265160481 | validation: 0.2839517119265134]
	TIME [epoch: 28 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34627564160162205		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.34627564160162205 | validation: 0.27202254307126855]
	TIME [epoch: 28 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3554300327186406		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.3554300327186406 | validation: 0.2962334220615016]
	TIME [epoch: 28 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597663722828638		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.3597663722828638 | validation: 0.3018276071662891]
	TIME [epoch: 28 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3531233946619931		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.3531233946619931 | validation: 0.3412891687136982]
	TIME [epoch: 28 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.371010661449517		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.371010661449517 | validation: 0.3002319528831095]
	TIME [epoch: 28 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3579556956792808		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.3579556956792808 | validation: 0.30358854248775663]
	TIME [epoch: 28 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35384870813170344		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.35384870813170344 | validation: 0.29733488743339814]
	TIME [epoch: 28 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35184047385854256		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.35184047385854256 | validation: 0.27702131250567075]
	TIME [epoch: 28 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433654836515075		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.3433654836515075 | validation: 0.300442292965015]
	TIME [epoch: 28 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34652655361589524		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.34652655361589524 | validation: 0.3009945810117069]
	TIME [epoch: 28 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3603989518247941		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.3603989518247941 | validation: 0.3196289775109645]
	TIME [epoch: 28 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36974280262524867		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.36974280262524867 | validation: 0.2931674961693624]
	TIME [epoch: 28 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3914508584080802		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.3914508584080802 | validation: 0.4451414307666069]
	TIME [epoch: 28 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4094538464945021		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.4094538464945021 | validation: 0.2947867056764421]
	TIME [epoch: 28 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466237317763431		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.3466237317763431 | validation: 0.27900516416690496]
	TIME [epoch: 28 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35571228440673297		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.35571228440673297 | validation: 0.2854965689201675]
	TIME [epoch: 28 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3599627951002052		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.3599627951002052 | validation: 0.31833448717170854]
	TIME [epoch: 28 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37340839775129253		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.37340839775129253 | validation: 0.30121885226111195]
	TIME [epoch: 28 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36945791569382025		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.36945791569382025 | validation: 0.34996546296998615]
	TIME [epoch: 28 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36439953897590316		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.36439953897590316 | validation: 0.2840603825147354]
	TIME [epoch: 28 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3514415385255021		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.3514415385255021 | validation: 0.28164476218169654]
	TIME [epoch: 28 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35206201629216005		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.35206201629216005 | validation: 0.27050888739149437]
	TIME [epoch: 28 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563303757035094		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.3563303757035094 | validation: 0.2855612925794074]
	TIME [epoch: 28 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551062029333632		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.3551062029333632 | validation: 0.2794116122164045]
	TIME [epoch: 28 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34776285775581145		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.34776285775581145 | validation: 0.32635084139926973]
	TIME [epoch: 28 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36125132111627456		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.36125132111627456 | validation: 0.2794508006482455]
	TIME [epoch: 28 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35107405416975757		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.35107405416975757 | validation: 0.3187663195589698]
	TIME [epoch: 28 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35821615155242814		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.35821615155242814 | validation: 0.3004845150860653]
	TIME [epoch: 28 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34437386724628827		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.34437386724628827 | validation: 0.279247312103608]
	TIME [epoch: 28 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34497846157228285		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.34497846157228285 | validation: 0.28489789723435704]
	TIME [epoch: 28 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3482161175273391		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.3482161175273391 | validation: 0.2815513984901704]
	TIME [epoch: 28 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3505714625703117		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.3505714625703117 | validation: 0.3129875569676488]
	TIME [epoch: 28 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3592858727705139		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.3592858727705139 | validation: 0.3198410039876402]
	TIME [epoch: 28 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40160817531689824		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.40160817531689824 | validation: 0.27688358176971306]
	TIME [epoch: 28 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3452115225843792		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.3452115225843792 | validation: 0.3209682837527041]
	TIME [epoch: 28 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36344161924570445		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.36344161924570445 | validation: 0.30140970459889455]
	TIME [epoch: 28 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475378565193141		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.3475378565193141 | validation: 0.3083669879685823]
	TIME [epoch: 28 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.399742426662955		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.399742426662955 | validation: 0.33420428929315377]
	TIME [epoch: 28 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38123950280310615		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.38123950280310615 | validation: 0.33187549538385375]
	TIME [epoch: 28 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36592743479837947		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.36592743479837947 | validation: 0.2953310402934272]
	TIME [epoch: 28 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345150821333319		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.345150821333319 | validation: 0.2683517693449164]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_1098.pth
	Model improved!!!
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3462869662338607		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.3462869662338607 | validation: 0.29326828136198246]
	TIME [epoch: 28 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.342509037574402		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.342509037574402 | validation: 0.2959384226123454]
	TIME [epoch: 28 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3469692502234937		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.3469692502234937 | validation: 0.2816169565114192]
	TIME [epoch: 28 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34782908535266277		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.34782908535266277 | validation: 0.29400556021869195]
	TIME [epoch: 28 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574543855791015		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.3574543855791015 | validation: 0.3056155416864727]
	TIME [epoch: 28 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3544603536201732		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.3544603536201732 | validation: 0.3164936604959748]
	TIME [epoch: 28 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472967462661669		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.3472967462661669 | validation: 0.3213948752247541]
	TIME [epoch: 28 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35553776416717553		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.35553776416717553 | validation: 0.3042531057470425]
	TIME [epoch: 28 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495606989787943		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.3495606989787943 | validation: 0.30611615437259715]
	TIME [epoch: 28 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3654995553493782		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.3654995553493782 | validation: 0.30252780782648175]
	TIME [epoch: 28 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347325977135569		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.347325977135569 | validation: 0.300703593418472]
	TIME [epoch: 28 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37801769102536814		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.37801769102536814 | validation: 0.3160971124158855]
	TIME [epoch: 28 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.420299408420895		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.420299408420895 | validation: 0.27556722077756196]
	TIME [epoch: 28 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36253561050573013		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.36253561050573013 | validation: 0.27992551351612294]
	TIME [epoch: 28 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35387793634713455		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.35387793634713455 | validation: 0.3030566953650309]
	TIME [epoch: 28 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533826950358817		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.3533826950358817 | validation: 0.3013749589690451]
	TIME [epoch: 28 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36591371410223367		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.36591371410223367 | validation: 0.29188480341006307]
	TIME [epoch: 28 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523854178445812		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.3523854178445812 | validation: 0.3051881437757093]
	TIME [epoch: 28 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34880386314593637		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.34880386314593637 | validation: 0.3410942117645092]
	TIME [epoch: 28 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3777018867173028		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.3777018867173028 | validation: 0.34392958324383843]
	TIME [epoch: 28 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3709882266357165		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.3709882266357165 | validation: 0.3227293627877011]
	TIME [epoch: 28 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35627364169219433		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.35627364169219433 | validation: 0.3277025088697393]
	TIME [epoch: 28 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34981847958101514		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.34981847958101514 | validation: 0.2832825855637969]
	TIME [epoch: 28 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34507615112713147		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.34507615112713147 | validation: 0.28781691485123834]
	TIME [epoch: 28 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3427371114892594		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.3427371114892594 | validation: 0.27263503272087186]
	TIME [epoch: 28 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34079768820290357		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.34079768820290357 | validation: 0.2847781930074803]
	TIME [epoch: 28 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3376379022220086		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.3376379022220086 | validation: 0.27054048354048243]
	TIME [epoch: 28 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.350717174076563		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.350717174076563 | validation: 0.26183716443431754]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_1126.pth
	Model improved!!!
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447237657074125		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.3447237657074125 | validation: 0.30609084424875965]
	TIME [epoch: 28 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35743518386511075		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.35743518386511075 | validation: 0.28546092168158976]
	TIME [epoch: 28 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34635941991139374		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.34635941991139374 | validation: 0.2939322376852788]
	TIME [epoch: 28 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550902177815851		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.3550902177815851 | validation: 0.3021646949940632]
	TIME [epoch: 28 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35434689355492127		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.35434689355492127 | validation: 0.32727685042450766]
	TIME [epoch: 28 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490850616075975		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.3490850616075975 | validation: 0.28050162688619595]
	TIME [epoch: 28 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34944744199634575		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.34944744199634575 | validation: 0.3088609340152589]
	TIME [epoch: 28 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3544898256393364		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.3544898256393364 | validation: 0.32243145145765484]
	TIME [epoch: 28 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36342944892649764		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.36342944892649764 | validation: 0.31817954029389256]
	TIME [epoch: 28 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3537263373083943		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.3537263373083943 | validation: 0.29441739542442946]
	TIME [epoch: 28 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33960090940511944		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.33960090940511944 | validation: 0.2734433067135206]
	TIME [epoch: 28 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3520961275431874		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.3520961275431874 | validation: 0.31737109193956947]
	TIME [epoch: 28 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347515940937866		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.347515940937866 | validation: 0.3276615106682388]
	TIME [epoch: 28 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500377563493634		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.4500377563493634 | validation: 0.2691251044051763]
	TIME [epoch: 28 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35842102553334304		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.35842102553334304 | validation: 0.2882502266772505]
	TIME [epoch: 28 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3531971413099245		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.3531971413099245 | validation: 0.2909179779257892]
	TIME [epoch: 28 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36683496101851615		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.36683496101851615 | validation: 0.29450531161277427]
	TIME [epoch: 28 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552114418300665		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.3552114418300665 | validation: 0.2828784945270185]
	TIME [epoch: 30.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36915165838393726		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.36915165838393726 | validation: 0.3135526404600767]
	TIME [epoch: 28 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576809711486921		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.3576809711486921 | validation: 0.29504989327779335]
	TIME [epoch: 28 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35194019047388625		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.35194019047388625 | validation: 0.29964610644113676]
	TIME [epoch: 28 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585014717605839		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.3585014717605839 | validation: 0.2929520436773663]
	TIME [epoch: 28 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3722236603812095		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.3722236603812095 | validation: 0.2904748252272928]
	TIME [epoch: 28 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35457037260139074		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.35457037260139074 | validation: 0.2971433446179048]
	TIME [epoch: 28 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35186362728402953		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.35186362728402953 | validation: 0.28366099023903996]
	TIME [epoch: 28 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35768004033241385		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.35768004033241385 | validation: 0.3123788913877509]
	TIME [epoch: 28 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019557773049577		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.4019557773049577 | validation: 0.331203239718878]
	TIME [epoch: 28 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3614828986414084		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.3614828986414084 | validation: 0.2913637596448104]
	TIME [epoch: 28 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33993326460507134		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.33993326460507134 | validation: 0.27383583615302176]
	TIME [epoch: 28 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34270868111216735		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.34270868111216735 | validation: 0.2677300915962145]
	TIME [epoch: 28 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3485153827748805		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.3485153827748805 | validation: 0.2593107898356395]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r0_20240310_053128/states/model_tr_study206_1157.pth
	Model improved!!!
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3448569906632951		[learning rate: 0.00019759]
