Args:
Namespace(name='model_tr_study206', outdir='out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5', training_data='data/transition_rate_studies/tr_study206/tr_study206_training/r5', validation_data='data/transition_rate_studies/tr_study206/tr_study206_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3293214525

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.189503111712822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.189503111712822 | validation: 11.080447467382909]
	TIME [epoch: 114 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.87209646893745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.87209646893745 | validation: 9.519703305639732]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.270147905334214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.270147905334214 | validation: 9.51435161312627]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.652916792861483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.652916792861483 | validation: 9.013487935181459]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.887790461474427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.887790461474427 | validation: 7.619008111875265]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.321310309527254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.321310309527254 | validation: 6.693402522820072]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.021668690065506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.021668690065506 | validation: 8.334890668457115]
	TIME [epoch: 25 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.112814270180806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.112814270180806 | validation: 6.68924863214286]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.234236139093365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.234236139093365 | validation: 5.34953155313815]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.89361780314665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.89361780314665 | validation: 5.012786169300884]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.785178034434358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.785178034434358 | validation: 4.844137549583924]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.580113567023107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.580113567023107 | validation: 4.838968171342086]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.568612954264748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.568612954264748 | validation: 4.510206315692543]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.481964641319614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.481964641319614 | validation: 5.146242441290172]
	TIME [epoch: 25 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.621907540277446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.621907540277446 | validation: 4.381835454002694]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.264614407772743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.264614407772743 | validation: 6.067663416687524]
	TIME [epoch: 25 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.676935594676174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.676935594676174 | validation: 4.4231031524626285]
	TIME [epoch: 25 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.346223109275405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.346223109275405 | validation: 4.438922860571262]
	TIME [epoch: 25 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.30154193476282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.30154193476282 | validation: 4.494110546315838]
	TIME [epoch: 25 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.230016019469774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.230016019469774 | validation: 4.4292542479604515]
	TIME [epoch: 25 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.413577015598605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.413577015598605 | validation: 4.17044844337953]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.175491179526743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.175491179526743 | validation: 4.7366302924172565]
	TIME [epoch: 25 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.353191681294836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.353191681294836 | validation: 4.214135207032934]
	TIME [epoch: 25 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.248018233383873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.248018233383873 | validation: 4.217934677018543]
	TIME [epoch: 25 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.203723512459081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.203723512459081 | validation: 4.046244311881914]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.031696787253755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.031696787253755 | validation: 4.944928695355683]
	TIME [epoch: 25 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.277675345765862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.277675345765862 | validation: 4.464044791966555]
	TIME [epoch: 25 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.534120998299546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.534120998299546 | validation: 4.057747877717445]
	TIME [epoch: 25 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.077039190363678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.077039190363678 | validation: 4.0580700151681945]
	TIME [epoch: 25 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.043309983794977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.043309983794977 | validation: 4.077716553520288]
	TIME [epoch: 25 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0235049944515655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0235049944515655 | validation: 4.312275082303635]
	TIME [epoch: 25 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.057543629983092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.057543629983092 | validation: 4.258986726354477]
	TIME [epoch: 25 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.203370506225011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.203370506225011 | validation: 3.9652223307204713]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.907211426662229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.907211426662229 | validation: 4.555189536753438]
	TIME [epoch: 25 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.991745637804133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.991745637804133 | validation: 5.257657424266673]
	TIME [epoch: 25 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.301319831671394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.301319831671394 | validation: 4.114672270440172]
	TIME [epoch: 25 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.249556290730205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.249556290730205 | validation: 3.954051574534675]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.818821253376904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.818821253376904 | validation: 4.305007100968815]
	TIME [epoch: 25 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1359047031913825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1359047031913825 | validation: 4.004827883025338]
	TIME [epoch: 25 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.891264575685225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.891264575685225 | validation: 3.9693018256004224]
	TIME [epoch: 25 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.083757260293418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.083757260293418 | validation: 4.030127536660225]
	TIME [epoch: 25 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.918866029640667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.918866029640667 | validation: 4.532513244300076]
	TIME [epoch: 25 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.934175598457543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.934175598457543 | validation: 3.8415628684352443]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.123390951295925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.123390951295925 | validation: 4.052045820931455]
	TIME [epoch: 25 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.956387091478038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.956387091478038 | validation: 3.8624587733388234]
	TIME [epoch: 25 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.769266147554077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.769266147554077 | validation: 5.046119405847027]
	TIME [epoch: 25 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.143128619752723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.143128619752723 | validation: 3.9182075896173933]
	TIME [epoch: 25 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.85554105255439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.85554105255439 | validation: 4.631373785235872]
	TIME [epoch: 25 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.11201038328945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.11201038328945 | validation: 3.969756255817255]
	TIME [epoch: 25 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9288648934268995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9288648934268995 | validation: 4.1182698380018845]
	TIME [epoch: 25 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.007847227099127		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.007847227099127 | validation: 3.9852077389027376]
	TIME [epoch: 25 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.95165641138282		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.95165641138282 | validation: 4.312153388344624]
	TIME [epoch: 25 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.98898358636261		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.98898358636261 | validation: 4.154506505128003]
	TIME [epoch: 25 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.866254580990818		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.866254580990818 | validation: 5.071316821371348]
	TIME [epoch: 24.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.22099758934606		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.22099758934606 | validation: 4.8527967430159356]
	TIME [epoch: 25 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.080611478901692		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.080611478901692 | validation: 4.9527519880504585]
	TIME [epoch: 25 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.251115732908124		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.251115732908124 | validation: 4.125457407644839]
	TIME [epoch: 25 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.809165287785142		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.809165287785142 | validation: 3.8747104128339744]
	TIME [epoch: 25 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.962331651885597		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.962331651885597 | validation: 4.533642720472659]
	TIME [epoch: 25 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.939794085028861		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.939794085028861 | validation: 3.7928187306770167]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9505258589623695		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.9505258589623695 | validation: 4.0917718886167895]
	TIME [epoch: 25 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.810112208441847		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.810112208441847 | validation: 4.267439839500906]
	TIME [epoch: 25 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.898197913334252		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.898197913334252 | validation: 4.0897630716910225]
	TIME [epoch: 25 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.791734437133254		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.791734437133254 | validation: 3.757103756782336]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.944180078460306		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.944180078460306 | validation: 4.117886803527679]
	TIME [epoch: 25 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9514764521472205		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.9514764521472205 | validation: 3.8222551736733634]
	TIME [epoch: 24.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.901447815734232		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.901447815734232 | validation: 4.122433459126829]
	TIME [epoch: 25 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.779960389907434		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.779960389907434 | validation: 4.507962650433982]
	TIME [epoch: 25 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.011341119888558		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 5.011341119888558 | validation: 4.109783627931099]
	TIME [epoch: 24.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.912207406496366		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.912207406496366 | validation: 3.883375966852743]
	TIME [epoch: 25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.839925343097737		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.839925343097737 | validation: 3.931275913891796]
	TIME [epoch: 25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.840157950604196		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.840157950604196 | validation: 4.019941554788327]
	TIME [epoch: 24.9 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8602517424667955		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.8602517424667955 | validation: 4.01313969015477]
	TIME [epoch: 25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.843269255222511		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.843269255222511 | validation: 3.8278421706138226]
	TIME [epoch: 25 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9036010534452945		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.9036010534452945 | validation: 3.8221747371207426]
	TIME [epoch: 24.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.790498582851357		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.790498582851357 | validation: 3.7975835438804166]
	TIME [epoch: 25 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.443192694859738		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 5.443192694859738 | validation: 3.9716140501664343]
	TIME [epoch: 25 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.881914349093436		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.881914349093436 | validation: 3.767763796345562]
	TIME [epoch: 24.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.846353894300544		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.846353894300544 | validation: 4.052976585685689]
	TIME [epoch: 25 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.860472790208764		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.860472790208764 | validation: 3.9941414952891683]
	TIME [epoch: 25 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.763214398951117		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.763214398951117 | validation: 3.943009254849568]
	TIME [epoch: 24.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.840962294819615		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.840962294819615 | validation: 3.901671429991586]
	TIME [epoch: 25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.70715718254294		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.70715718254294 | validation: 3.7501495942182372]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8450260314686195		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.8450260314686195 | validation: 3.820699253372863]
	TIME [epoch: 25 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7393312925191475		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.7393312925191475 | validation: 3.6815628230824964]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.939672874139395		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.939672874139395 | validation: 3.745530651402287]
	TIME [epoch: 25 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.801867729058388		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.801867729058388 | validation: 3.7750485881395255]
	TIME [epoch: 25 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.719172333125183		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.719172333125183 | validation: 4.020343947996454]
	TIME [epoch: 25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.811448092586945		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.811448092586945 | validation: 4.154443666432116]
	TIME [epoch: 25 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7963332705062465		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.7963332705062465 | validation: 3.8796228825913017]
	TIME [epoch: 25 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.687611391858861		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.687611391858861 | validation: 3.76922078588114]
	TIME [epoch: 25 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.809662033245858		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.809662033245858 | validation: 3.6847411690151466]
	TIME [epoch: 25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.884746188384954		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.884746188384954 | validation: 3.920655136810696]
	TIME [epoch: 25 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.738517986947015		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.738517986947015 | validation: 3.883142720478588]
	TIME [epoch: 25 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.772479743883796		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.772479743883796 | validation: 3.859794018652427]
	TIME [epoch: 25 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.727179959730187		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.727179959730187 | validation: 3.7784569815912654]
	TIME [epoch: 25 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.730973525788447		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.730973525788447 | validation: 3.7007710327698433]
	TIME [epoch: 25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.783143668771194		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 4.783143668771194 | validation: 4.025415359529403]
	TIME [epoch: 25 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.805486157816672		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 4.805486157816672 | validation: 3.7064281133937595]
	TIME [epoch: 25 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.704657656613936		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.704657656613936 | validation: 3.9208059176826]
	TIME [epoch: 25 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.784349024632028		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 4.784349024632028 | validation: 3.906246293423908]
	TIME [epoch: 25 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.779134386005406		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.779134386005406 | validation: 3.8851080509252176]
	TIME [epoch: 25 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7802943839309915		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.7802943839309915 | validation: 4.069656155189454]
	TIME [epoch: 25 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.821650540760494		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.821650540760494 | validation: 5.658734797085287]
	TIME [epoch: 25 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.55450438265941		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 5.55450438265941 | validation: 4.037214834645874]
	TIME [epoch: 25 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.732510094075635		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.732510094075635 | validation: 3.8382035234893594]
	TIME [epoch: 25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.703241016590174		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 4.703241016590174 | validation: 3.839292579620482]
	TIME [epoch: 25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.779174766188431		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.779174766188431 | validation: 3.7835214312149867]
	TIME [epoch: 25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.732668708356998		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.732668708356998 | validation: 3.934599980638832]
	TIME [epoch: 25 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7166429933676035		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 4.7166429933676035 | validation: 3.704910219883794]
	TIME [epoch: 25 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.757998220328648		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 4.757998220328648 | validation: 3.78350795000184]
	TIME [epoch: 25 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.825606876715586		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 4.825606876715586 | validation: 3.782628925959728]
	TIME [epoch: 25 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.83879135087004		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 4.83879135087004 | validation: 3.8983900390487856]
	TIME [epoch: 25 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.749658764186814		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.749658764186814 | validation: 3.691033815925387]
	TIME [epoch: 25 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.756731952488156		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.756731952488156 | validation: 3.820713997704002]
	TIME [epoch: 25 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.695067214683357		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.695067214683357 | validation: 3.688105901140209]
	TIME [epoch: 25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.779869184908861		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.779869184908861 | validation: 3.7516006256824768]
	TIME [epoch: 25 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.902662909710427		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 4.902662909710427 | validation: 3.9019436011737607]
	TIME [epoch: 25 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.730971631330313		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.730971631330313 | validation: 3.8359416771494246]
	TIME [epoch: 25 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.800103231191845		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 4.800103231191845 | validation: 3.7205697948336245]
	TIME [epoch: 25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.782570046236909		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 4.782570046236909 | validation: 3.693941379175137]
	TIME [epoch: 25 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.704560479419674		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.704560479419674 | validation: 4.032912094229505]
	TIME [epoch: 25 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.909690866520874		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 4.909690866520874 | validation: 3.927572533646129]
	TIME [epoch: 25 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.774035573643798		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 4.774035573643798 | validation: 3.6982558758952515]
	TIME [epoch: 25 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6653265176228595		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.6653265176228595 | validation: 3.814192364201772]
	TIME [epoch: 25 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.817024159779924		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.817024159779924 | validation: 3.7222342692831547]
	TIME [epoch: 25 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.62643753284779		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 4.62643753284779 | validation: 4.4719540827252375]
	TIME [epoch: 25 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.884800850074218		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.884800850074218 | validation: 3.7326520559974554]
	TIME [epoch: 25 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.750164227925603		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.750164227925603 | validation: 3.795015272675083]
	TIME [epoch: 25 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.709197213343432		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.709197213343432 | validation: 3.9305816621227256]
	TIME [epoch: 25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.728577169374634		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 4.728577169374634 | validation: 3.7965132916279107]
	TIME [epoch: 25 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.724478419995649		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 4.724478419995649 | validation: 4.202525940614981]
	TIME [epoch: 25 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.733817611337468		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.733817611337468 | validation: 3.86076202144997]
	TIME [epoch: 25 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8590611104253485		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.8590611104253485 | validation: 4.095240611741678]
	TIME [epoch: 25 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.796683692099927		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 4.796683692099927 | validation: 3.921992926093575]
	TIME [epoch: 25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.697043620515037		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 4.697043620515037 | validation: 3.9991592271571315]
	TIME [epoch: 25 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.811292904359654		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 4.811292904359654 | validation: 3.753045567673013]
	TIME [epoch: 25 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.679928962799692		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 4.679928962799692 | validation: 3.7469248797509422]
	TIME [epoch: 25 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.751139009523175		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 4.751139009523175 | validation: 3.826996012611429]
	TIME [epoch: 25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.012831807608995		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 5.012831807608995 | validation: 4.156964996998355]
	TIME [epoch: 25 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.830604261814231		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 4.830604261814231 | validation: 4.021835750397395]
	TIME [epoch: 25 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.811373126280909		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 4.811373126280909 | validation: 3.732905069501186]
	TIME [epoch: 25 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.676135766777648		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 4.676135766777648 | validation: 3.671417164345628]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.666835914480374		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 4.666835914480374 | validation: 3.9110493836504974]
	TIME [epoch: 25 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7049466198734935		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 4.7049466198734935 | validation: 3.7333279780486874]
	TIME [epoch: 25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7470271896249905		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 4.7470271896249905 | validation: 3.674915576207315]
	TIME [epoch: 25 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.602076097918481		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 4.602076097918481 | validation: 3.8945411193266306]
	TIME [epoch: 25 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7064853961842665		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 4.7064853961842665 | validation: 3.653960895552133]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.716098737040155		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 4.716098737040155 | validation: 3.926942483232183]
	TIME [epoch: 25 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.735210966548713		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 4.735210966548713 | validation: 3.6773995688139496]
	TIME [epoch: 25 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.580848043990622		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 4.580848043990622 | validation: 3.6814076826916606]
	TIME [epoch: 25 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.672763830394396		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 4.672763830394396 | validation: 3.781895447883199]
	TIME [epoch: 25 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.843999546593265		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 4.843999546593265 | validation: 3.8978420577425905]
	TIME [epoch: 25 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.810327831138795		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 4.810327831138795 | validation: 3.668819941648221]
	TIME [epoch: 24.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.606234605041593		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 4.606234605041593 | validation: 3.6409952814022986]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.598280847140207		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 4.598280847140207 | validation: 3.986611531739055]
	TIME [epoch: 25 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.822197619287152		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 4.822197619287152 | validation: 3.647273217598819]
	TIME [epoch: 25 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.609819055093682		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 4.609819055093682 | validation: 3.6948397339532746]
	TIME [epoch: 25 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.701901709700529		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 4.701901709700529 | validation: 3.6676080672614852]
	TIME [epoch: 25 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.596095844703791		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 4.596095844703791 | validation: 4.049807675669156]
	TIME [epoch: 24.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.750329798324097		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 4.750329798324097 | validation: 3.6726886868135513]
	TIME [epoch: 25 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.576929267206695		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 4.576929267206695 | validation: 3.746302822564957]
	TIME [epoch: 25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7180516533301		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 4.7180516533301 | validation: 3.8150718738794054]
	TIME [epoch: 24.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.684422827921381		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 4.684422827921381 | validation: 3.7197001686943]
	TIME [epoch: 25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.639497731839141		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 4.639497731839141 | validation: 3.6721307576515887]
	TIME [epoch: 25 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.648683919579208		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 4.648683919579208 | validation: 3.6212924930362727]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.620826880682468		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 4.620826880682468 | validation: 3.676924417421619]
	TIME [epoch: 25 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.636270885802025		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 4.636270885802025 | validation: 3.946693825457984]
	TIME [epoch: 25 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.661119499437163		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 4.661119499437163 | validation: 3.873218809197283]
	TIME [epoch: 24.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.667826442941813		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 4.667826442941813 | validation: 3.7621227534473385]
	TIME [epoch: 25 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6969041087167005		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 4.6969041087167005 | validation: 3.865816032420413]
	TIME [epoch: 25 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.717963962178499		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 4.717963962178499 | validation: 3.6470629100651637]
	TIME [epoch: 24.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.761057630653433		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 4.761057630653433 | validation: 3.7061585932969434]
	TIME [epoch: 25 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.659455193446892		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 4.659455193446892 | validation: 3.6120971529614234]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.65210122223999		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 4.65210122223999 | validation: 4.031416795265286]
	TIME [epoch: 24.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.780374699284708		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 4.780374699284708 | validation: 3.6285259241151175]
	TIME [epoch: 25 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.659219418288859		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 4.659219418288859 | validation: 3.631722840059433]
	TIME [epoch: 25 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.629793376252818		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 4.629793376252818 | validation: 3.7047817388805755]
	TIME [epoch: 24.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.741096513846261		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 4.741096513846261 | validation: 3.6364461548530604]
	TIME [epoch: 25 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.615887684276665		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 4.615887684276665 | validation: 3.6367904179021053]
	TIME [epoch: 25 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.68419842127422		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 4.68419842127422 | validation: 3.9460903232931646]
	TIME [epoch: 24.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6511291603006235		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 4.6511291603006235 | validation: 3.8364013928497083]
	TIME [epoch: 25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.638182794685993		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 4.638182794685993 | validation: 3.6041532274219255]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.656316284675793		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 4.656316284675793 | validation: 3.7030143879351125]
	TIME [epoch: 24.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.57345431651869		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 4.57345431651869 | validation: 3.7927931940961974]
	TIME [epoch: 25 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.590884951985923		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 4.590884951985923 | validation: 3.6400401421204744]
	TIME [epoch: 25 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.80984401280832		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 4.80984401280832 | validation: 3.7389779046045146]
	TIME [epoch: 24.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.754996004598195		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 4.754996004598195 | validation: 3.6740771995592887]
	TIME [epoch: 25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.703822227709382		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 4.703822227709382 | validation: 3.8077770517715597]
	TIME [epoch: 25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.672809563851898		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 4.672809563851898 | validation: 3.6935399993841953]
	TIME [epoch: 24.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.600250835760332		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 4.600250835760332 | validation: 3.6446097109536315]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5774988666031735		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 4.5774988666031735 | validation: 3.7792353680337225]
	TIME [epoch: 25 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.657985122688196		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 4.657985122688196 | validation: 3.6523125456468164]
	TIME [epoch: 24.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5553057684429845		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 4.5553057684429845 | validation: 3.6275123117916026]
	TIME [epoch: 25 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.635665231130941		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 4.635665231130941 | validation: 3.5896855336049027]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.637173043752442		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 4.637173043752442 | validation: 3.746484052918825]
	TIME [epoch: 24.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6012995953306035		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 4.6012995953306035 | validation: 3.6222250611320463]
	TIME [epoch: 25 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.612186066935825		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 4.612186066935825 | validation: 3.7132901934961993]
	TIME [epoch: 25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.565100024275827		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 4.565100024275827 | validation: 3.6020659676499878]
	TIME [epoch: 24.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7267066790376004		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 4.7267066790376004 | validation: 3.922750459176764]
	TIME [epoch: 25 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.648330282268403		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 4.648330282268403 | validation: 3.662853425322984]
	TIME [epoch: 25 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.684614415249858		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 4.684614415249858 | validation: 3.7197992884907927]
	TIME [epoch: 24.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.592453420677176		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 4.592453420677176 | validation: 3.6328556354608055]
	TIME [epoch: 25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.748364057023409		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 4.748364057023409 | validation: 3.660150468770761]
	TIME [epoch: 25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.729597252394584		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 4.729597252394584 | validation: 3.598873153368379]
	TIME [epoch: 24.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.566238344232326		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 4.566238344232326 | validation: 3.6514575630230937]
	TIME [epoch: 25 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.625013587630252		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 4.625013587630252 | validation: 3.7110867030803445]
	TIME [epoch: 25 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.614087829888021		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 4.614087829888021 | validation: 3.7621996593355935]
	TIME [epoch: 24.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.580699861368606		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 4.580699861368606 | validation: 3.654946676972144]
	TIME [epoch: 25 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.666454391164782		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 4.666454391164782 | validation: 3.647507636555729]
	TIME [epoch: 25 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.553462319189178		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 4.553462319189178 | validation: 3.8785614040463976]
	TIME [epoch: 24.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.695313461127485		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 4.695313461127485 | validation: 3.643287586636434]
	TIME [epoch: 25 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.635121773459388		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 4.635121773459388 | validation: 3.7123514912060522]
	TIME [epoch: 25 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.600885831683373		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 4.600885831683373 | validation: 3.793248307440568]
	TIME [epoch: 24.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.615895161573849		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 4.615895161573849 | validation: 3.6516534224405235]
	TIME [epoch: 25 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.572075141611574		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 4.572075141611574 | validation: 3.5971212155882872]
	TIME [epoch: 25 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.69067230437243		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 4.69067230437243 | validation: 3.8533689704332104]
	TIME [epoch: 24.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.720673400869655		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 4.720673400869655 | validation: 3.8320059096092485]
	TIME [epoch: 25 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.596280810872138		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 4.596280810872138 | validation: 3.731394857691406]
	TIME [epoch: 25 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.631385396487757		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 4.631385396487757 | validation: 3.6405905491747066]
	TIME [epoch: 24.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.60428759694155		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 4.60428759694155 | validation: 3.935726533245605]
	TIME [epoch: 25 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6186625005565		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 4.6186625005565 | validation: 3.7869871049981043]
	TIME [epoch: 25 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.588950138902764		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 4.588950138902764 | validation: 3.651598824485026]
	TIME [epoch: 24.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.66484034842383		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 4.66484034842383 | validation: 3.6310895241935186]
	TIME [epoch: 25 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.626230017024035		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 4.626230017024035 | validation: 3.7223583891480723]
	TIME [epoch: 25 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.588067001153262		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 4.588067001153262 | validation: 3.7012099267741907]
	TIME [epoch: 25 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.565767833136764		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 4.565767833136764 | validation: 3.6294109807835992]
	TIME [epoch: 25 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.542711392248459		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 4.542711392248459 | validation: 3.717913482027201]
	TIME [epoch: 25 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.560281094799539		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 4.560281094799539 | validation: 3.756810256470333]
	TIME [epoch: 24.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.579749933179325		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 4.579749933179325 | validation: 3.6721942988060428]
	TIME [epoch: 25 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.655119341197171		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 4.655119341197171 | validation: 4.05719898453329]
	TIME [epoch: 25 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.826467212375654		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 4.826467212375654 | validation: 3.902978910344684]
	TIME [epoch: 24.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.63853969748997		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 4.63853969748997 | validation: 3.6485235629206576]
	TIME [epoch: 25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.58579929056593		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 4.58579929056593 | validation: 3.6132193416251503]
	TIME [epoch: 25 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.555815522129832		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 4.555815522129832 | validation: 3.5861807857304826]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.554422465966709		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 4.554422465966709 | validation: 3.626674123182758]
	TIME [epoch: 25 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.537410341232176		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 4.537410341232176 | validation: 3.7754896966205993]
	TIME [epoch: 25 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5997323893924165		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 4.5997323893924165 | validation: 3.8200977769560853]
	TIME [epoch: 24.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.601307887586675		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 4.601307887586675 | validation: 3.6361690129046047]
	TIME [epoch: 25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.59200557219919		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 4.59200557219919 | validation: 3.605791018505231]
	TIME [epoch: 25 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.56555804109968		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 4.56555804109968 | validation: 3.6103449295422663]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5715338395892635		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 4.5715338395892635 | validation: 3.676984166968899]
	TIME [epoch: 25 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.578474441149205		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 4.578474441149205 | validation: 3.646727115025659]
	TIME [epoch: 25 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.670705130263814		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 4.670705130263814 | validation: 3.6713932626403527]
	TIME [epoch: 24.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.591773357133623		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 4.591773357133623 | validation: 3.635212012872795]
	TIME [epoch: 25 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.543181812128526		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 4.543181812128526 | validation: 3.5995152667588752]
	TIME [epoch: 25 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.620732657235391		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 4.620732657235391 | validation: 3.7441516301866615]
	TIME [epoch: 24.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.570288235798712		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 4.570288235798712 | validation: 3.719788676727115]
	TIME [epoch: 25 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5752839468342135		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 4.5752839468342135 | validation: 3.777614306562357]
	TIME [epoch: 25 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.611171325764004		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 4.611171325764004 | validation: 3.6183262684850512]
	TIME [epoch: 24.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.571488505814235		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 4.571488505814235 | validation: 3.6390011043746164]
	TIME [epoch: 25 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.545362382494631		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 4.545362382494631 | validation: 3.7409360093611843]
	TIME [epoch: 25 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.58369624691565		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 4.58369624691565 | validation: 3.6993439279907796]
	TIME [epoch: 25 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.833975810671079		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 4.833975810671079 | validation: 3.7117700796536908]
	TIME [epoch: 25 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6252498309463475		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 4.6252498309463475 | validation: 3.6409944301545862]
	TIME [epoch: 25 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.538813723858587		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 4.538813723858587 | validation: 3.6430591310450753]
	TIME [epoch: 25 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.586600570988754		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 4.586600570988754 | validation: 3.591103005578125]
	TIME [epoch: 25 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.559494459753362		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 4.559494459753362 | validation: 3.845303911900113]
	TIME [epoch: 25 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.598585282387816		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 4.598585282387816 | validation: 3.6234069254831667]
	TIME [epoch: 25 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.549558971078627		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 4.549558971078627 | validation: 3.7860531940297726]
	TIME [epoch: 25 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.584583658037151		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 4.584583658037151 | validation: 3.81541231318033]
	TIME [epoch: 25 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.607214827278846		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 4.607214827278846 | validation: 3.566832038973193]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.577289664634376		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 4.577289664634376 | validation: 3.579765304886802]
	TIME [epoch: 25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525002631781273		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 4.525002631781273 | validation: 3.701822165402256]
	TIME [epoch: 25 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.584311890703128		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 4.584311890703128 | validation: 3.6181066924161103]
	TIME [epoch: 25 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.581152222528717		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 4.581152222528717 | validation: 3.6506901571984396]
	TIME [epoch: 25 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5710134504901125		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 4.5710134504901125 | validation: 3.6752814654180863]
	TIME [epoch: 25 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.651524241809443		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 4.651524241809443 | validation: 3.620350558875789]
	TIME [epoch: 25 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.583290965429734		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 4.583290965429734 | validation: 3.5915193119614504]
	TIME [epoch: 25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.52944526092839		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 4.52944526092839 | validation: 3.5782507925633698]
	TIME [epoch: 25 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5565058583061235		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 4.5565058583061235 | validation: 3.7608538688714805]
	TIME [epoch: 25 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.575783592097995		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 4.575783592097995 | validation: 3.6288853399043606]
	TIME [epoch: 25 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.546400304475457		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 4.546400304475457 | validation: 3.595367074467588]
	TIME [epoch: 25 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.597239779664221		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 4.597239779664221 | validation: 3.5953471802503003]
	TIME [epoch: 25 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5291978271687645		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 4.5291978271687645 | validation: 3.5897269693730016]
	TIME [epoch: 25 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513043856573965		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 4.513043856573965 | validation: 3.6471927203634205]
	TIME [epoch: 25 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.566420972022323		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 4.566420972022323 | validation: 3.5658849592690998]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.52591680565593		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 4.52591680565593 | validation: 4.002422461049565]
	TIME [epoch: 25 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.657261865082456		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 4.657261865082456 | validation: 3.585257679619659]
	TIME [epoch: 25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.551601836334134		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 4.551601836334134 | validation: 3.739784008248862]
	TIME [epoch: 25 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.59329514744123		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 4.59329514744123 | validation: 3.609639111552334]
	TIME [epoch: 25 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.559764005124849		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 4.559764005124849 | validation: 3.7513004943629555]
	TIME [epoch: 25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.560107188032143		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 4.560107188032143 | validation: 3.67934842856247]
	TIME [epoch: 25 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.663069817929282		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 4.663069817929282 | validation: 3.7543019815241623]
	TIME [epoch: 24.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.587310960614022		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 4.587310960614022 | validation: 3.615818960582875]
	TIME [epoch: 25 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.52409793804024		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 4.52409793804024 | validation: 3.582149809136003]
	TIME [epoch: 25 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.576040393253435		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 4.576040393253435 | validation: 3.6510037989669137]
	TIME [epoch: 25 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.580126605009285		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 4.580126605009285 | validation: 3.6121647871906095]
	TIME [epoch: 25 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.535445571576443		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 4.535445571576443 | validation: 3.579508048906561]
	TIME [epoch: 25 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506116904198692		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 4.506116904198692 | validation: 3.6088227726798676]
	TIME [epoch: 25 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.51493810267789		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 4.51493810267789 | validation: 3.8378082079979516]
	TIME [epoch: 25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6086705456126005		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 4.6086705456126005 | validation: 4.016150738942779]
	TIME [epoch: 25 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.65987071097581		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 4.65987071097581 | validation: 3.659912362495545]
	TIME [epoch: 25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.544120937995343		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 4.544120937995343 | validation: 3.7592865941783296]
	TIME [epoch: 25 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.657438032484663		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 4.657438032484663 | validation: 3.6845051416789123]
	TIME [epoch: 25 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547235205924634		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 4.547235205924634 | validation: 3.6186128700045264]
	TIME [epoch: 25 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.555675928983881		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 4.555675928983881 | validation: 3.6151618294375494]
	TIME [epoch: 25 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5587269212637835		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 4.5587269212637835 | validation: 3.6181246919473575]
	TIME [epoch: 25 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514020327624399		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 4.514020327624399 | validation: 3.594056776389941]
	TIME [epoch: 25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50520223063744		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 4.50520223063744 | validation: 3.8459353729680243]
	TIME [epoch: 25 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.572744472207764		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 4.572744472207764 | validation: 3.647603826467587]
	TIME [epoch: 25 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5406421359056885		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 4.5406421359056885 | validation: 3.551034397031483]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.521251269268809		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 4.521251269268809 | validation: 3.7120189948713573]
	TIME [epoch: 25 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5630304000335915		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 4.5630304000335915 | validation: 3.6422204333340065]
	TIME [epoch: 25 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.588023060943669		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 4.588023060943669 | validation: 3.6410156621741336]
	TIME [epoch: 24.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510583633387867		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 4.510583633387867 | validation: 3.565635635044472]
	TIME [epoch: 25 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.554974843007949		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 4.554974843007949 | validation: 3.5733933765431063]
	TIME [epoch: 25 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.559811354337655		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 4.559811354337655 | validation: 3.6430374041746894]
	TIME [epoch: 24.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.595318756242602		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 4.595318756242602 | validation: 3.7816836813247017]
	TIME [epoch: 25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.61329627895383		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 4.61329627895383 | validation: 3.607768208551817]
	TIME [epoch: 25 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.622205164736582		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 4.622205164736582 | validation: 3.742601988272662]
	TIME [epoch: 24.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.581857106516051		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 4.581857106516051 | validation: 3.589690242843807]
	TIME [epoch: 25 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522263153706056		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 4.522263153706056 | validation: 3.65451635883862]
	TIME [epoch: 25 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5151722376455785		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 4.5151722376455785 | validation: 3.87601331470232]
	TIME [epoch: 24.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6054848022187445		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 4.6054848022187445 | validation: 3.646774100125538]
	TIME [epoch: 25 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.591806625708449		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 4.591806625708449 | validation: 3.5747486865018785]
	TIME [epoch: 25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.620264575901988		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 4.620264575901988 | validation: 3.6199365175355163]
	TIME [epoch: 24.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5541820666802		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 4.5541820666802 | validation: 3.6584135467104004]
	TIME [epoch: 25 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.60051038355096		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 4.60051038355096 | validation: 3.7785840395601027]
	TIME [epoch: 25 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.646555459490471		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 4.646555459490471 | validation: 3.794277692865086]
	TIME [epoch: 24.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.560372545954691		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 4.560372545954691 | validation: 3.652550745031091]
	TIME [epoch: 25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.530649381319981		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 4.530649381319981 | validation: 3.584195581742317]
	TIME [epoch: 25 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.529129542825772		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 4.529129542825772 | validation: 3.5581583060933166]
	TIME [epoch: 24.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518725284788838		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 4.518725284788838 | validation: 3.587774604867981]
	TIME [epoch: 25 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531289298706147		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 4.531289298706147 | validation: 3.652593531252736]
	TIME [epoch: 25 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.582622838569187		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 4.582622838569187 | validation: 3.6426491862331565]
	TIME [epoch: 24.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.554054830565783		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 4.554054830565783 | validation: 3.898157268245903]
	TIME [epoch: 25 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.589902471447067		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 4.589902471447067 | validation: 3.6361786198119352]
	TIME [epoch: 25 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.571901014025518		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 4.571901014025518 | validation: 3.703952140116888]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522663553330702		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 4.522663553330702 | validation: 3.686903113257603]
	TIME [epoch: 25 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.556522803309942		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 4.556522803309942 | validation: 3.620510712521304]
	TIME [epoch: 25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.537602106405348		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 4.537602106405348 | validation: 3.5645071637081305]
	TIME [epoch: 24.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547406431437738		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 4.547406431437738 | validation: 3.6794753114733467]
	TIME [epoch: 25 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515661175291688		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 4.515661175291688 | validation: 3.6815300468414835]
	TIME [epoch: 25 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.588076423413389		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 4.588076423413389 | validation: 3.6381313549337033]
	TIME [epoch: 24.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.52398922517655		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 4.52398922517655 | validation: 3.6235249741753957]
	TIME [epoch: 25 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.574617773553136		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 4.574617773553136 | validation: 3.6379933329279015]
	TIME [epoch: 25 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.558932422891919		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 4.558932422891919 | validation: 3.558367080046311]
	TIME [epoch: 24.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506359315812315		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 4.506359315812315 | validation: 3.5719578521679516]
	TIME [epoch: 25 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.604129690395706		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 4.604129690395706 | validation: 3.6398860259510535]
	TIME [epoch: 25 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.560310637748427		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 4.560310637748427 | validation: 3.585414127831264]
	TIME [epoch: 24.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.545982757145837		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 4.545982757145837 | validation: 3.61048220192283]
	TIME [epoch: 25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.632171541799826		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 4.632171541799826 | validation: 3.604780633555894]
	TIME [epoch: 25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5837715877861775		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 4.5837715877861775 | validation: 3.5784392837209493]
	TIME [epoch: 24.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497125643196819		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 4.497125643196819 | validation: 3.667882134251858]
	TIME [epoch: 25 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.533747868459402		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 4.533747868459402 | validation: 3.592911843950081]
	TIME [epoch: 25 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.533953607273819		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 4.533953607273819 | validation: 3.619075894618311]
	TIME [epoch: 24.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.587145796245027		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 4.587145796245027 | validation: 3.6124186441977986]
	TIME [epoch: 25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.523764357842019		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 4.523764357842019 | validation: 3.7704488622554595]
	TIME [epoch: 25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.59552349826957		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 4.59552349826957 | validation: 3.5835835710946036]
	TIME [epoch: 24.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.556138489965812		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 4.556138489965812 | validation: 3.6548247135892793]
	TIME [epoch: 25 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.616099053999266		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 4.616099053999266 | validation: 3.574067040207222]
	TIME [epoch: 25 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50482171472877		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 4.50482171472877 | validation: 3.5768116239660173]
	TIME [epoch: 24.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514632895058049		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 4.514632895058049 | validation: 3.5660832859454183]
	TIME [epoch: 25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496455375150694		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 4.496455375150694 | validation: 3.608132396332633]
	TIME [epoch: 25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5275518718231735		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 4.5275518718231735 | validation: 3.6542621734594376]
	TIME [epoch: 24.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514413232652523		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 4.514413232652523 | validation: 3.5597166709238435]
	TIME [epoch: 25 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.532199439469199		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 4.532199439469199 | validation: 3.842324838771087]
	TIME [epoch: 25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.561015888053866		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 4.561015888053866 | validation: 3.5835665414420994]
	TIME [epoch: 24.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491456097891687		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 4.491456097891687 | validation: 3.5657760610138842]
	TIME [epoch: 25 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.521559282643852		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 4.521559282643852 | validation: 3.614031864660183]
	TIME [epoch: 25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504789935953523		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 4.504789935953523 | validation: 3.6774836687529926]
	TIME [epoch: 25 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.530783289614591		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 4.530783289614591 | validation: 3.689132011492163]
	TIME [epoch: 25 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.57822052453167		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 4.57822052453167 | validation: 3.563039570688965]
	TIME [epoch: 25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.521238409179448		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 4.521238409179448 | validation: 3.718280298331285]
	TIME [epoch: 25 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.535501290891655		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 4.535501290891655 | validation: 3.599573873429303]
	TIME [epoch: 25 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5086323282790755		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 4.5086323282790755 | validation: 3.743490173776737]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.566033504511857		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 4.566033504511857 | validation: 3.6020686565388558]
	TIME [epoch: 25 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.533290170144783		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 4.533290170144783 | validation: 3.585925771762427]
	TIME [epoch: 25 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489435922646956		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 4.489435922646956 | validation: 3.6088611383833005]
	TIME [epoch: 25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.542889681295903		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 4.542889681295903 | validation: 3.589951313174564]
	TIME [epoch: 25 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547171897132345		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 4.547171897132345 | validation: 3.5957053377547665]
	TIME [epoch: 25 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.605083140623015		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 4.605083140623015 | validation: 3.670015318318485]
	TIME [epoch: 25 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.598508889638794		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 4.598508889638794 | validation: 3.587185486456756]
	TIME [epoch: 25 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.537055783566517		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 4.537055783566517 | validation: 3.6035193468534126]
	TIME [epoch: 25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511415494778246		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 4.511415494778246 | validation: 3.6141747754407323]
	TIME [epoch: 25 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513072527385887		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 4.513072527385887 | validation: 3.566121760420714]
	TIME [epoch: 25 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514623102356001		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 4.514623102356001 | validation: 3.565161392669099]
	TIME [epoch: 25 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.56677753386705		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 4.56677753386705 | validation: 3.5927354517249035]
	TIME [epoch: 25 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496493517029771		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 4.496493517029771 | validation: 3.6798602984289754]
	TIME [epoch: 25 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5327639511280005		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 4.5327639511280005 | validation: 3.588663272182533]
	TIME [epoch: 25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515607096767562		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 4.515607096767562 | validation: 3.6997289091620553]
	TIME [epoch: 25 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.516053886406647		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 4.516053886406647 | validation: 3.5933157038994454]
	TIME [epoch: 25 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510023920316705		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 4.510023920316705 | validation: 3.6330449997273515]
	TIME [epoch: 25 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.568055695451055		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 4.568055695451055 | validation: 3.670404112157878]
	TIME [epoch: 25 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522517408365494		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 4.522517408365494 | validation: 3.671227165946135]
	TIME [epoch: 25 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.535560829148988		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 4.535560829148988 | validation: 3.60226445721995]
	TIME [epoch: 25 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547701773336609		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 4.547701773336609 | validation: 3.6237771499613967]
	TIME [epoch: 25 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.523409146002244		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 4.523409146002244 | validation: 3.635191821596123]
	TIME [epoch: 25 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525723276433768		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 4.525723276433768 | validation: 3.615585929936243]
	TIME [epoch: 25 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506125286923679		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 4.506125286923679 | validation: 3.621442271051307]
	TIME [epoch: 25 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522901626375577		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 4.522901626375577 | validation: 3.5731559138854116]
	TIME [epoch: 25 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.516948740858067		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 4.516948740858067 | validation: 3.589827216980694]
	TIME [epoch: 25 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510908940534346		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 4.510908940534346 | validation: 3.6838473731836006]
	TIME [epoch: 25 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.538869243219914		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 4.538869243219914 | validation: 3.6489214903345566]
	TIME [epoch: 25 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522150364879444		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 4.522150364879444 | validation: 3.5553835037342534]
	TIME [epoch: 25 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540277515723881		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 4.540277515723881 | validation: 3.5735983057649845]
	TIME [epoch: 25 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.529202690025812		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 4.529202690025812 | validation: 3.6377926054367378]
	TIME [epoch: 25 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.550592230106771		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 4.550592230106771 | validation: 3.5856097409775884]
	TIME [epoch: 25 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504052091224124		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 4.504052091224124 | validation: 3.5637616538971577]
	TIME [epoch: 25 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6046770233389465		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 4.6046770233389465 | validation: 3.5675324441340095]
	TIME [epoch: 25 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495405330833196		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 4.495405330833196 | validation: 3.6552414538898734]
	TIME [epoch: 25 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.538328196736156		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 4.538328196736156 | validation: 3.577289138352906]
	TIME [epoch: 25 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.502629292889775		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 4.502629292889775 | validation: 3.551981614824074]
	TIME [epoch: 25 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.519905154032269		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 4.519905154032269 | validation: 3.5794982244091114]
	TIME [epoch: 25 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5191117690746205		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 4.5191117690746205 | validation: 3.5769359386378254]
	TIME [epoch: 25 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483060459467556		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 4.483060459467556 | validation: 3.5433026479252296]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512510065874868		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 4.512510065874868 | validation: 3.548147749649311]
	TIME [epoch: 25 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4923589414803455		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 4.4923589414803455 | validation: 3.588140395131848]
	TIME [epoch: 25 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.519895228188044		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 4.519895228188044 | validation: 3.555023241708766]
	TIME [epoch: 25 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.523706949605555		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 4.523706949605555 | validation: 3.6723667260263655]
	TIME [epoch: 25 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5266737645404795		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 4.5266737645404795 | validation: 3.5654757797629792]
	TIME [epoch: 25 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48848623380746		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 4.48848623380746 | validation: 3.5617029232548885]
	TIME [epoch: 25 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501204615487231		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 4.501204615487231 | validation: 3.5420536238025666]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488541022326757		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 4.488541022326757 | validation: 3.5890324469158728]
	TIME [epoch: 25 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515069843974315		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 4.515069843974315 | validation: 3.7920066924909577]
	TIME [epoch: 25 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.593994388773256		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 4.593994388773256 | validation: 3.6507601048230516]
	TIME [epoch: 25 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540265403562009		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 4.540265403562009 | validation: 3.5865589356733607]
	TIME [epoch: 25 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.536188559896905		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 4.536188559896905 | validation: 3.550497860977123]
	TIME [epoch: 25 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49498002430739		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 4.49498002430739 | validation: 3.563832186321038]
	TIME [epoch: 25 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.509857028986067		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 4.509857028986067 | validation: 3.567449645377176]
	TIME [epoch: 25 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504011057577236		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 4.504011057577236 | validation: 3.636662719880353]
	TIME [epoch: 25 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513736183262655		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 4.513736183262655 | validation: 3.769853936931669]
	TIME [epoch: 25 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.669319890938538		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 4.669319890938538 | validation: 3.6068198878775717]
	TIME [epoch: 25 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.533519681840457		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 4.533519681840457 | validation: 3.616423142286943]
	TIME [epoch: 25 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.559190941435627		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 4.559190941435627 | validation: 3.5936250087193486]
	TIME [epoch: 25 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511599949542008		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 4.511599949542008 | validation: 3.568398353605959]
	TIME [epoch: 25 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.499384217465578		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 4.499384217465578 | validation: 3.699175661066421]
	TIME [epoch: 25 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.576118959675063		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 4.576118959675063 | validation: 3.6132406173196263]
	TIME [epoch: 25 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.507787128287937		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 4.507787128287937 | validation: 3.5738384353496215]
	TIME [epoch: 25 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487493602468541		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 4.487493602468541 | validation: 3.651498152723097]
	TIME [epoch: 25 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.541845740438698		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 4.541845740438698 | validation: 3.569562365252989]
	TIME [epoch: 25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4954128499615695		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 4.4954128499615695 | validation: 3.6003863237731264]
	TIME [epoch: 25 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531987049199107		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 4.531987049199107 | validation: 3.5812290092331036]
	TIME [epoch: 25 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512111340388221		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 4.512111340388221 | validation: 3.597005503572737]
	TIME [epoch: 25 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495902638994954		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 4.495902638994954 | validation: 3.5854879033580556]
	TIME [epoch: 25 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.570395722641285		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 4.570395722641285 | validation: 3.625775501445994]
	TIME [epoch: 25 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.551670197379569		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 4.551670197379569 | validation: 3.6710515253395624]
	TIME [epoch: 25 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517586840849052		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 4.517586840849052 | validation: 3.612459784416213]
	TIME [epoch: 25 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514729904738321		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 4.514729904738321 | validation: 3.636933895774713]
	TIME [epoch: 25 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.539327303384785		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 4.539327303384785 | validation: 3.571965357516406]
	TIME [epoch: 24.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515838666590864		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 4.515838666590864 | validation: 3.5924113547185272]
	TIME [epoch: 25 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486131422567675		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 4.486131422567675 | validation: 3.573727616978695]
	TIME [epoch: 25 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482764656596206		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 4.482764656596206 | validation: 3.632277691782062]
	TIME [epoch: 24.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.553315813390514		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 4.553315813390514 | validation: 3.6404611518048835]
	TIME [epoch: 25 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517712052361471		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 4.517712052361471 | validation: 3.55219987725308]
	TIME [epoch: 25 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.529071768864586		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 4.529071768864586 | validation: 3.545509341256981]
	TIME [epoch: 24.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5176253609874015		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 4.5176253609874015 | validation: 3.5631915659116293]
	TIME [epoch: 25 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485890456213069		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 4.485890456213069 | validation: 3.5677989239698276]
	TIME [epoch: 25 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517413115289093		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 4.517413115289093 | validation: 3.585705751789289]
	TIME [epoch: 24.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487602891099131		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 4.487602891099131 | validation: 3.5616611162371674]
	TIME [epoch: 25 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49166139359524		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 4.49166139359524 | validation: 3.555299529310259]
	TIME [epoch: 25 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495986028814944		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 4.495986028814944 | validation: 3.5717301351518986]
	TIME [epoch: 24.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5361056158581		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 4.5361056158581 | validation: 3.6528549463542617]
	TIME [epoch: 25 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.563980707389194		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 4.563980707389194 | validation: 3.542930051371146]
	TIME [epoch: 25 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486464765801221		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 4.486464765801221 | validation: 3.5606617159764427]
	TIME [epoch: 25 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50338972348887		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 4.50338972348887 | validation: 3.6176256589303524]
	TIME [epoch: 25 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.561485535918585		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 4.561485535918585 | validation: 3.5766501831323727]
	TIME [epoch: 25 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489519742530654		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 4.489519742530654 | validation: 3.6231782793357]
	TIME [epoch: 24.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.510382973677384		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 4.510382973677384 | validation: 3.535429468684557]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504364341612187		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 4.504364341612187 | validation: 3.5454944643808792]
	TIME [epoch: 25 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.522027122708428		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 4.522027122708428 | validation: 3.585566444461804]
	TIME [epoch: 24.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488441289360129		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 4.488441289360129 | validation: 3.534359164047545]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_463.pth
	Model improved!!!
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492964624594369		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 4.492964624594369 | validation: 3.5854674693699065]
	TIME [epoch: 25 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.505074395999807		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 4.505074395999807 | validation: 3.571794577573379]
	TIME [epoch: 24.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488286451633598		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 4.488286451633598 | validation: 3.557349690423994]
	TIME [epoch: 25 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482254981178926		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 4.482254981178926 | validation: 3.5544401205486666]
	TIME [epoch: 25 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4855762108752275		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 4.4855762108752275 | validation: 3.5703325891335407]
	TIME [epoch: 24.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5142210427812035		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 4.5142210427812035 | validation: 3.590838868959389]
	TIME [epoch: 25 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4885576167753385		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 4.4885576167753385 | validation: 3.6022112671574567]
	TIME [epoch: 25 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488725793502389		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 4.488725793502389 | validation: 3.6052466069913374]
	TIME [epoch: 24.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486467779220191		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 4.486467779220191 | validation: 3.566339771093438]
	TIME [epoch: 25 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492402840200895		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 4.492402840200895 | validation: 3.5452545701488716]
	TIME [epoch: 25 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5088444676018415		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 4.5088444676018415 | validation: 3.5933208286666307]
	TIME [epoch: 24.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.53594758075348		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 4.53594758075348 | validation: 3.67051331318978]
	TIME [epoch: 25 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514309002446343		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 4.514309002446343 | validation: 3.6843736298477827]
	TIME [epoch: 25 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517909913636675		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 4.517909913636675 | validation: 3.576745192057945]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487231526647456		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 4.487231526647456 | validation: 3.5543006392857595]
	TIME [epoch: 25 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5050069721851935		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 4.5050069721851935 | validation: 3.559135456693541]
	TIME [epoch: 25 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479798767794336		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 4.479798767794336 | validation: 3.55884380367851]
	TIME [epoch: 24.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517198362730909		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 4.517198362730909 | validation: 3.620732051495474]
	TIME [epoch: 25 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49832918803223		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 4.49832918803223 | validation: 3.5633112811031453]
	TIME [epoch: 25 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484845327398668		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 4.484845327398668 | validation: 3.546071038306428]
	TIME [epoch: 24.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50624655427742		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 4.50624655427742 | validation: 3.6693363650125383]
	TIME [epoch: 25 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.557356318702738		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 4.557356318702738 | validation: 3.566710934863017]
	TIME [epoch: 25 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494471531553038		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 4.494471531553038 | validation: 3.567360847823386]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480866898908505		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 4.480866898908505 | validation: 3.556895473945208]
	TIME [epoch: 25 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481620957926618		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 4.481620957926618 | validation: 3.6026643584571127]
	TIME [epoch: 25 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.52254176211275		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 4.52254176211275 | validation: 3.5854762218901435]
	TIME [epoch: 24.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.508343728288332		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 4.508343728288332 | validation: 3.5589375904594602]
	TIME [epoch: 25 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500340333212073		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 4.500340333212073 | validation: 3.643190779262436]
	TIME [epoch: 25 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514811247963761		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 4.514811247963761 | validation: 3.5473784816213207]
	TIME [epoch: 24.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48650808898603		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 4.48650808898603 | validation: 3.623508436369141]
	TIME [epoch: 25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506326340230802		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 4.506326340230802 | validation: 3.571453124828989]
	TIME [epoch: 25 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506347730336115		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 4.506347730336115 | validation: 3.5582989644406973]
	TIME [epoch: 25 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.543345197387598		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 4.543345197387598 | validation: 3.556489863088549]
	TIME [epoch: 25 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.529123556759947		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 4.529123556759947 | validation: 3.598129725084194]
	TIME [epoch: 25 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50390737223295		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 4.50390737223295 | validation: 3.571452214132826]
	TIME [epoch: 24.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.533539274251363		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 4.533539274251363 | validation: 3.5776112505022777]
	TIME [epoch: 25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480057623342724		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 4.480057623342724 | validation: 3.5547576969558548]
	TIME [epoch: 25 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5039258252257035		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 4.5039258252257035 | validation: 3.542033349851199]
	TIME [epoch: 24.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467850179168306		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 4.467850179168306 | validation: 3.594941368429926]
	TIME [epoch: 25 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4952782377129346		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 4.4952782377129346 | validation: 3.5553068502967955]
	TIME [epoch: 25 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.508991411032563		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 4.508991411032563 | validation: 3.603011037755774]
	TIME [epoch: 24.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485401329506605		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 4.485401329506605 | validation: 3.5731823027374494]
	TIME [epoch: 25 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.497832866684469		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 4.497832866684469 | validation: 3.538213523617354]
	TIME [epoch: 25 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.505440906702967		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 4.505440906702967 | validation: 3.5559186588375145]
	TIME [epoch: 24.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500314058553886		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 4.500314058553886 | validation: 3.5363237558832736]
	TIME [epoch: 25 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472627529033426		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 4.472627529033426 | validation: 3.5552595693884452]
	TIME [epoch: 25 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50026468811832		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 4.50026468811832 | validation: 3.557239048632268]
	TIME [epoch: 25 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4844752465205335		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 4.4844752465205335 | validation: 3.570576411612458]
	TIME [epoch: 25 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506707112440632		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 4.506707112440632 | validation: 3.5548852431709284]
	TIME [epoch: 25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489877482441664		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 4.489877482441664 | validation: 3.5500088565877457]
	TIME [epoch: 24.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493635598196552		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 4.493635598196552 | validation: 3.5420316098545332]
	TIME [epoch: 25 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4702642110401465		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 4.4702642110401465 | validation: 3.585439515255343]
	TIME [epoch: 25 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.520993770858828		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 4.520993770858828 | validation: 3.6825913097146263]
	TIME [epoch: 24.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5160262436232115		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 4.5160262436232115 | validation: 3.657662069171911]
	TIME [epoch: 25 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504022827724812		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 4.504022827724812 | validation: 3.550870153908962]
	TIME [epoch: 25 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473466185749561		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 4.473466185749561 | validation: 3.6338512974065997]
	TIME [epoch: 24.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.67824217298647		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 4.67824217298647 | validation: 3.754639493272033]
	TIME [epoch: 25 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.55606011086566		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 4.55606011086566 | validation: 3.704259203045642]
	TIME [epoch: 25 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.509248497711		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 4.509248497711 | validation: 3.561067488962799]
	TIME [epoch: 25 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483996426055294		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 4.483996426055294 | validation: 3.542031194474968]
	TIME [epoch: 25 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472987545074643		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 4.472987545074643 | validation: 3.5372173793719788]
	TIME [epoch: 25 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492619140697535		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 4.492619140697535 | validation: 3.552476885841799]
	TIME [epoch: 24.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512415659815635		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 4.512415659815635 | validation: 3.5559754451352483]
	TIME [epoch: 25 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466937689089936		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 4.466937689089936 | validation: 3.5849195507372067]
	TIME [epoch: 25 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495050396198396		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 4.495050396198396 | validation: 3.5841908105427898]
	TIME [epoch: 24.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478479661173666		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 4.478479661173666 | validation: 3.5509955972786993]
	TIME [epoch: 25 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.529814006155492		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 4.529814006155492 | validation: 3.5709868933751405]
	TIME [epoch: 25 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5255487199623206		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 4.5255487199623206 | validation: 3.589172932186989]
	TIME [epoch: 25 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477125043136978		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 4.477125043136978 | validation: 3.5873937144705508]
	TIME [epoch: 25 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480679226222693		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 4.480679226222693 | validation: 3.555002292217687]
	TIME [epoch: 25 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476932186684407		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 4.476932186684407 | validation: 3.6163114121609956]
	TIME [epoch: 25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.537894730710617		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 4.537894730710617 | validation: 3.595502961148874]
	TIME [epoch: 25 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.528304892441934		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 4.528304892441934 | validation: 3.587533003879979]
	TIME [epoch: 25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475222746029424		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 4.475222746029424 | validation: 3.563176360420202]
	TIME [epoch: 25 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498888940873037		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 4.498888940873037 | validation: 3.5729278865903336]
	TIME [epoch: 25 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483306630545301		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 4.483306630545301 | validation: 3.5904192759174403]
	TIME [epoch: 25 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506981501283615		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 4.506981501283615 | validation: 3.5531179713899395]
	TIME [epoch: 25 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469390621211073		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 4.469390621211073 | validation: 3.5969302310939977]
	TIME [epoch: 25 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.546286864761575		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 4.546286864761575 | validation: 3.7758608573710957]
	TIME [epoch: 25 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5555452912625025		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 4.5555452912625025 | validation: 3.662752215775277]
	TIME [epoch: 25 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.519664638650133		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 4.519664638650133 | validation: 3.5646092204202944]
	TIME [epoch: 25 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493716192772098		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 4.493716192772098 | validation: 3.6806357006045936]
	TIME [epoch: 25 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515904956414279		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 4.515904956414279 | validation: 3.56188733987128]
	TIME [epoch: 25 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492499106614902		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 4.492499106614902 | validation: 3.6498836420044736]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513052886677587		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 4.513052886677587 | validation: 3.602677028994989]
	TIME [epoch: 25 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495619724706698		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 4.495619724706698 | validation: 3.571933496936693]
	TIME [epoch: 25 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476937416640509		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 4.476937416640509 | validation: 3.5655538003871836]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485853305110437		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 4.485853305110437 | validation: 3.5535249283245047]
	TIME [epoch: 25 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490728884204849		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 4.490728884204849 | validation: 3.552972411580139]
	TIME [epoch: 25 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484676697548186		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 4.484676697548186 | validation: 3.6185285987426523]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490667061723556		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 4.490667061723556 | validation: 3.5399350371297205]
	TIME [epoch: 25 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47415301147959		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 4.47415301147959 | validation: 3.6050118796752653]
	TIME [epoch: 24.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500021590535463		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 4.500021590535463 | validation: 3.5315266413426456]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484319074071464		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 4.484319074071464 | validation: 3.5460042585421263]
	TIME [epoch: 25 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469171228516323		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 4.469171228516323 | validation: 3.553354982758159]
	TIME [epoch: 25 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489422538586587		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 4.489422538586587 | validation: 3.606948425825499]
	TIME [epoch: 25 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518849420755325		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 4.518849420755325 | validation: 3.559467750126133]
	TIME [epoch: 25 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500262515788568		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 4.500262515788568 | validation: 3.634133747002336]
	TIME [epoch: 24.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495190096437067		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 4.495190096437067 | validation: 3.57174015159542]
	TIME [epoch: 24.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473657003666424		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 4.473657003666424 | validation: 3.551513994826394]
	TIME [epoch: 25 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476913010535462		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 4.476913010535462 | validation: 3.5602958067698207]
	TIME [epoch: 25 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.502255474834925		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 4.502255474834925 | validation: 3.7336796460105894]
	TIME [epoch: 25 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.534859816594275		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 4.534859816594275 | validation: 3.6118598532851762]
	TIME [epoch: 25 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483911962175634		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 4.483911962175634 | validation: 3.5665649867199467]
	TIME [epoch: 25 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481680363579553		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 4.481680363579553 | validation: 3.5950366474941404]
	TIME [epoch: 25 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493180733187027		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 4.493180733187027 | validation: 3.558615533810213]
	TIME [epoch: 25 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479691208359728		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 4.479691208359728 | validation: 3.549090573502549]
	TIME [epoch: 25 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490306107702145		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 4.490306107702145 | validation: 3.5361263449596603]
	TIME [epoch: 24.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481374741875474		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 4.481374741875474 | validation: 3.540446800444428]
	TIME [epoch: 25 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491019649144993		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 4.491019649144993 | validation: 3.5286203022713676]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_573.pth
	Model improved!!!
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494064657780225		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 4.494064657780225 | validation: 3.523120259421196]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_574.pth
	Model improved!!!
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484686349205721		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 4.484686349205721 | validation: 3.5497359973505254]
	TIME [epoch: 25 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488005868972282		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 4.488005868972282 | validation: 3.552529239656831]
	TIME [epoch: 25 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487052592409004		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 4.487052592409004 | validation: 3.570135571101813]
	TIME [epoch: 24.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486568244486741		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 4.486568244486741 | validation: 3.6027072057449727]
	TIME [epoch: 25 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492342186669687		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 4.492342186669687 | validation: 3.559213517885011]
	TIME [epoch: 25 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493098436104715		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 4.493098436104715 | validation: 3.543308959568434]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472403209604674		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 4.472403209604674 | validation: 3.5463707704535343]
	TIME [epoch: 25 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473675030334894		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 4.473675030334894 | validation: 3.5446200063613333]
	TIME [epoch: 25 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.505962379887625		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 4.505962379887625 | validation: 3.547040995835345]
	TIME [epoch: 24.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472175369423275		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 4.472175369423275 | validation: 3.5580014504613438]
	TIME [epoch: 25 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485964887970468		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 4.485964887970468 | validation: 3.540691823740849]
	TIME [epoch: 25 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495315297228657		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 4.495315297228657 | validation: 3.533969281565299]
	TIME [epoch: 25 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487583583808173		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 4.487583583808173 | validation: 3.6066195762701305]
	TIME [epoch: 25 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515720563315365		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 4.515720563315365 | validation: 3.5326441645342026]
	TIME [epoch: 25 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5143491361211625		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 4.5143491361211625 | validation: 3.553176046368325]
	TIME [epoch: 24.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464748120599436		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 4.464748120599436 | validation: 3.556008030382336]
	TIME [epoch: 25 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4813554869371135		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 4.4813554869371135 | validation: 3.583180293245273]
	TIME [epoch: 25 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494232824616862		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 4.494232824616862 | validation: 3.6332940366543722]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511826332668282		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 4.511826332668282 | validation: 3.592292322599839]
	TIME [epoch: 25 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498511204320617		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 4.498511204320617 | validation: 3.6026320045120883]
	TIME [epoch: 25 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.503986380243254		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 4.503986380243254 | validation: 3.60018512247412]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496509440696185		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 4.496509440696185 | validation: 3.5831709211832514]
	TIME [epoch: 25 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.509327068887535		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 4.509327068887535 | validation: 3.541069621216678]
	TIME [epoch: 25 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480829396576977		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 4.480829396576977 | validation: 3.5338263171132906]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4754752638617745		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 4.4754752638617745 | validation: 3.5397450197340836]
	TIME [epoch: 25 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473851606280994		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 4.473851606280994 | validation: 3.541157027606839]
	TIME [epoch: 25 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467513223422965		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 4.467513223422965 | validation: 3.572663157944088]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484347696861731		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 4.484347696861731 | validation: 3.542383732201875]
	TIME [epoch: 25 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475173563193262		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 4.475173563193262 | validation: 3.528726681925249]
	TIME [epoch: 25 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476312787655803		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 4.476312787655803 | validation: 3.5302205874250805]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473390889923584		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 4.473390889923584 | validation: 3.5541437612446902]
	TIME [epoch: 25 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50000830880369		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 4.50000830880369 | validation: 3.570697995343122]
	TIME [epoch: 25 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494353641899242		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 4.494353641899242 | validation: 3.539003875375881]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484582916635235		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 4.484582916635235 | validation: 3.5718471729477277]
	TIME [epoch: 25 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.504797863671667		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 4.504797863671667 | validation: 3.5882618124776777]
	TIME [epoch: 25 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492900010664123		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 4.492900010664123 | validation: 3.561287741635839]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470819803383039		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 4.470819803383039 | validation: 3.542328116503045]
	TIME [epoch: 25 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.50327870152791		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 4.50327870152791 | validation: 3.5596310097547654]
	TIME [epoch: 25 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482261726152838		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 4.482261726152838 | validation: 3.5441789667169656]
	TIME [epoch: 24.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472286006181449		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 4.472286006181449 | validation: 3.5393838321075743]
	TIME [epoch: 25 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481248857488057		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 4.481248857488057 | validation: 3.541435303915428]
	TIME [epoch: 25 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466020722670576		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 4.466020722670576 | validation: 3.5830381959173794]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4731609534382635		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 4.4731609534382635 | validation: 3.5360065911084804]
	TIME [epoch: 25 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46902464858567		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 4.46902464858567 | validation: 3.5397745129378997]
	TIME [epoch: 25 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46862738027559		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 4.46862738027559 | validation: 3.5788841856544793]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490652802062235		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 4.490652802062235 | validation: 3.5541426322252305]
	TIME [epoch: 25 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47303723924418		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 4.47303723924418 | validation: 3.549522921678829]
	TIME [epoch: 25 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476569248377636		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 4.476569248377636 | validation: 3.547015645773339]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493965383021907		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 4.493965383021907 | validation: 3.552535292667468]
	TIME [epoch: 25 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469751492289232		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 4.469751492289232 | validation: 3.5464795082537752]
	TIME [epoch: 25 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464505400981671		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 4.464505400981671 | validation: 3.582847433409353]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498340909336255		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 4.498340909336255 | validation: 3.5339430832608163]
	TIME [epoch: 25 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476298630764722		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 4.476298630764722 | validation: 3.5599601651581736]
	TIME [epoch: 25 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49653947730628		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 4.49653947730628 | validation: 3.5725669824056916]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478402898981894		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 4.478402898981894 | validation: 3.5612254236166017]
	TIME [epoch: 25 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5207053911625605		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 4.5207053911625605 | validation: 3.567183803437348]
	TIME [epoch: 25 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486746271703701		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 4.486746271703701 | validation: 3.5765021432248205]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486000347032286		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 4.486000347032286 | validation: 3.561437298377112]
	TIME [epoch: 25 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477761750945745		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 4.477761750945745 | validation: 3.564411516983064]
	TIME [epoch: 25 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473663928118025		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 4.473663928118025 | validation: 3.5487104604648274]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477549043262606		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 4.477549043262606 | validation: 3.531105756921936]
	TIME [epoch: 25 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481549734135243		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 4.481549734135243 | validation: 3.590518690479741]
	TIME [epoch: 25 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498602092260918		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 4.498602092260918 | validation: 3.5757432388320836]
	TIME [epoch: 24.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485568088097432		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 4.485568088097432 | validation: 3.571770117264856]
	TIME [epoch: 25 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.509580873254285		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 4.509580873254285 | validation: 3.558946785516945]
	TIME [epoch: 25 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48051987768172		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 4.48051987768172 | validation: 3.5491083949273583]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471188532948689		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 4.471188532948689 | validation: 3.5434259531180614]
	TIME [epoch: 25 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4727533566897275		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 4.4727533566897275 | validation: 3.565390951999702]
	TIME [epoch: 25 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471265763213545		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 4.471265763213545 | validation: 3.5512629776792815]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482922151290513		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 4.482922151290513 | validation: 3.5603884291930927]
	TIME [epoch: 25 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4794013356245515		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 4.4794013356245515 | validation: 3.549901433794357]
	TIME [epoch: 25 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484524890180088		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 4.484524890180088 | validation: 3.544964515909817]
	TIME [epoch: 25 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488645519657305		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 4.488645519657305 | validation: 3.5389692678557663]
	TIME [epoch: 25 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4811608726427705		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 4.4811608726427705 | validation: 3.5474690656401595]
	TIME [epoch: 25 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479094243337931		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 4.479094243337931 | validation: 3.5464233181418034]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47425074834217		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 4.47425074834217 | validation: 3.5432940154750687]
	TIME [epoch: 25 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466518412463869		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 4.466518412463869 | validation: 3.581042513210083]
	TIME [epoch: 25 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473393819872723		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 4.473393819872723 | validation: 3.5451509061378954]
	TIME [epoch: 25 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464273353135197		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 4.464273353135197 | validation: 3.548555132568194]
	TIME [epoch: 25 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4674484398795276		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 4.4674484398795276 | validation: 3.5390568054687765]
	TIME [epoch: 25 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462146654339452		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 4.462146654339452 | validation: 3.5522060597522795]
	TIME [epoch: 25 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465953305749835		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 4.465953305749835 | validation: 3.534172122141901]
	TIME [epoch: 25 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490837700723753		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 4.490837700723753 | validation: 3.625603729539191]
	TIME [epoch: 25 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485815323493234		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 4.485815323493234 | validation: 3.5415796658771]
	TIME [epoch: 25 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468424321678091		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 4.468424321678091 | validation: 3.5590167566592004]
	TIME [epoch: 25 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490642836102072		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 4.490642836102072 | validation: 3.5356010412271264]
	TIME [epoch: 25 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483434557674499		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 4.483434557674499 | validation: 3.531170205741657]
	TIME [epoch: 25 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468185716242214		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 4.468185716242214 | validation: 3.5544377644096437]
	TIME [epoch: 25 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462036369024009		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 4.462036369024009 | validation: 3.588346692314803]
	TIME [epoch: 25 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475406334746442		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 4.475406334746442 | validation: 3.543493066543556]
	TIME [epoch: 25 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4646156751058985		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 4.4646156751058985 | validation: 3.5378903449965913]
	TIME [epoch: 25 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466447529231305		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 4.466447529231305 | validation: 3.542222979021269]
	TIME [epoch: 25 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.507076083596695		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 4.507076083596695 | validation: 3.5619562396020417]
	TIME [epoch: 25 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493725762232291		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 4.493725762232291 | validation: 3.566036752160768]
	TIME [epoch: 25 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486091338260024		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 4.486091338260024 | validation: 3.558283618818093]
	TIME [epoch: 25 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471968094451469		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 4.471968094451469 | validation: 3.542574105865851]
	TIME [epoch: 25 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48406348349539		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 4.48406348349539 | validation: 3.587608010298962]
	TIME [epoch: 25 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.508555287018753		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 4.508555287018753 | validation: 3.5300994163050663]
	TIME [epoch: 25 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467399221182793		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 4.467399221182793 | validation: 3.5387656873848012]
	TIME [epoch: 25 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466675591234025		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 4.466675591234025 | validation: 3.545405286211418]
	TIME [epoch: 25 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4895207434198765		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 4.4895207434198765 | validation: 3.5626407643456632]
	TIME [epoch: 25 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483798455560078		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 4.483798455560078 | validation: 3.5572195510241795]
	TIME [epoch: 25 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469391707828333		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 4.469391707828333 | validation: 3.5295723333791362]
	TIME [epoch: 25 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471197985998419		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 4.471197985998419 | validation: 3.544054777815239]
	TIME [epoch: 25 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481071596705895		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 4.481071596705895 | validation: 3.5251200238256533]
	TIME [epoch: 25 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482123508992789		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 4.482123508992789 | validation: 3.5548520969110866]
	TIME [epoch: 25 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473271340531053		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 4.473271340531053 | validation: 3.5346509006297144]
	TIME [epoch: 25 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4611849963662795		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 4.4611849963662795 | validation: 3.5257784700517973]
	TIME [epoch: 25 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465434598896327		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 4.465434598896327 | validation: 3.553988190256178]
	TIME [epoch: 25 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483708576032101		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 4.483708576032101 | validation: 3.5785209071966895]
	TIME [epoch: 25 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491126601596735		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 4.491126601596735 | validation: 3.5530693578263843]
	TIME [epoch: 25 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465309945598748		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 4.465309945598748 | validation: 3.5421151391310084]
	TIME [epoch: 25 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473460083111832		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 4.473460083111832 | validation: 3.550886493837321]
	TIME [epoch: 25 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463336113122278		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 4.463336113122278 | validation: 3.5637629972191394]
	TIME [epoch: 25 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475319310874323		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 4.475319310874323 | validation: 3.5546731393420203]
	TIME [epoch: 25 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.495789688324014		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 4.495789688324014 | validation: 3.5664032561978156]
	TIME [epoch: 25 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.48413327723945		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 4.48413327723945 | validation: 3.537831800149983]
	TIME [epoch: 25 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463869823293134		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 4.463869823293134 | validation: 3.55484471509727]
	TIME [epoch: 25 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475011961374161		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 4.475011961374161 | validation: 3.5556894941994246]
	TIME [epoch: 25 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474782061016493		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 4.474782061016493 | validation: 3.5501461035117665]
	TIME [epoch: 25 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469343003079709		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 4.469343003079709 | validation: 3.54465152778079]
	TIME [epoch: 25 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468651692930372		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 4.468651692930372 | validation: 3.5594028411455314]
	TIME [epoch: 25 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471261576438717		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 4.471261576438717 | validation: 3.5435491831577437]
	TIME [epoch: 25 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479125839666296		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 4.479125839666296 | validation: 3.600381347001654]
	TIME [epoch: 25 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.494080421445094		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 4.494080421445094 | validation: 3.558187560538969]
	TIME [epoch: 25 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.507257156334641		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 4.507257156334641 | validation: 3.5383226474385947]
	TIME [epoch: 25 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471649569981021		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 4.471649569981021 | validation: 3.5630926570118824]
	TIME [epoch: 25 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490994976044039		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 4.490994976044039 | validation: 3.5539908819160235]
	TIME [epoch: 25 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467635755804176		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 4.467635755804176 | validation: 3.543823729114486]
	TIME [epoch: 25 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466315088987994		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 4.466315088987994 | validation: 3.5299717891403977]
	TIME [epoch: 25 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466883506628793		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 4.466883506628793 | validation: 3.5321118303733043]
	TIME [epoch: 25 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469543010560907		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 4.469543010560907 | validation: 3.569703998528901]
	TIME [epoch: 25 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474986472950963		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 4.474986472950963 | validation: 3.5373841410176063]
	TIME [epoch: 25 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471079303699771		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 4.471079303699771 | validation: 3.54980644219973]
	TIME [epoch: 25 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465020581909234		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 4.465020581909234 | validation: 3.5571287370606446]
	TIME [epoch: 25 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475651993602506		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 4.475651993602506 | validation: 3.5453976162293124]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471911808148454		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 4.471911808148454 | validation: 3.5419637838577067]
	TIME [epoch: 25 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466658312805827		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 4.466658312805827 | validation: 3.5466613559030464]
	TIME [epoch: 25 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462142195720534		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 4.462142195720534 | validation: 3.524848915283862]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4863001425622855		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 4.4863001425622855 | validation: 3.541239567912246]
	TIME [epoch: 25 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464174961431651		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 4.464174961431651 | validation: 3.538407900114899]
	TIME [epoch: 25 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481619011881679		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 4.481619011881679 | validation: 3.5681702821358408]
	TIME [epoch: 25 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481996745550105		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 4.481996745550105 | validation: 3.5637633456885225]
	TIME [epoch: 25 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4914935916556855		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 4.4914935916556855 | validation: 3.548814939151181]
	TIME [epoch: 25 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470235742953353		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 4.470235742953353 | validation: 3.5501874184288806]
	TIME [epoch: 25 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477879199927276		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 4.477879199927276 | validation: 3.578424571506698]
	TIME [epoch: 25 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480854149082427		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 4.480854149082427 | validation: 3.5789400121863015]
	TIME [epoch: 25 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475334879753768		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 4.475334879753768 | validation: 3.5273587199797194]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4692814278197925		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 4.4692814278197925 | validation: 3.5293489970210477]
	TIME [epoch: 25 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470360060473152		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 4.470360060473152 | validation: 3.566211397398948]
	TIME [epoch: 25 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.484014163441358		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 4.484014163441358 | validation: 3.5439781224972977]
	TIME [epoch: 24.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.512491408269403		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 4.512491408269403 | validation: 3.529022758825978]
	TIME [epoch: 25 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481386246090542		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 4.481386246090542 | validation: 3.563498795911389]
	TIME [epoch: 25 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4655905456703975		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 4.4655905456703975 | validation: 3.537720008232838]
	TIME [epoch: 24.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460404200981695		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 4.460404200981695 | validation: 3.5381493986575134]
	TIME [epoch: 25 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478276262780291		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 4.478276262780291 | validation: 3.55605128507262]
	TIME [epoch: 25 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47062697405135		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 4.47062697405135 | validation: 3.575093187428418]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.489056631000472		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 4.489056631000472 | validation: 3.567365045813824]
	TIME [epoch: 25 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479989572065882		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 4.479989572065882 | validation: 3.5192231635499276]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_733.pth
	Model improved!!!
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4591209300639925		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 4.4591209300639925 | validation: 3.532326345404657]
	TIME [epoch: 25 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468294845666643		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 4.468294845666643 | validation: 3.5504145481112936]
	TIME [epoch: 25 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468031762805449		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 4.468031762805449 | validation: 3.555293642231346]
	TIME [epoch: 25 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511206556367229		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 4.511206556367229 | validation: 3.527092888047341]
	TIME [epoch: 25 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463223976032939		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 4.463223976032939 | validation: 3.5436580768368366]
	TIME [epoch: 25 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480255611722954		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 4.480255611722954 | validation: 3.550868327976615]
	TIME [epoch: 25 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477151417329356		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 4.477151417329356 | validation: 3.5192840390148614]
	TIME [epoch: 25 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465167482218653		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 4.465167482218653 | validation: 3.5776652486357854]
	TIME [epoch: 25 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476979384656895		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 4.476979384656895 | validation: 3.533968440687472]
	TIME [epoch: 25 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496955761324065		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 4.496955761324065 | validation: 3.5446083576437695]
	TIME [epoch: 25 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463477509712342		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 4.463477509712342 | validation: 3.5365565246780064]
	TIME [epoch: 25 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480897529452953		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 4.480897529452953 | validation: 3.5413158306711097]
	TIME [epoch: 25 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469654905581305		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 4.469654905581305 | validation: 3.533948356419254]
	TIME [epoch: 25 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46634928506126		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 4.46634928506126 | validation: 3.5349462510202514]
	TIME [epoch: 25 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474404710522366		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 4.474404710522366 | validation: 3.552349560251006]
	TIME [epoch: 25 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4782804249563934		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 4.4782804249563934 | validation: 3.5303236943885787]
	TIME [epoch: 24.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4562949504667095		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 4.4562949504667095 | validation: 3.544249601382569]
	TIME [epoch: 25 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467691109575276		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 4.467691109575276 | validation: 3.5284894491768]
	TIME [epoch: 25 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4613102101074995		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 4.4613102101074995 | validation: 3.5403539793511833]
	TIME [epoch: 24.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496394151232909		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 4.496394151232909 | validation: 3.5291484631743066]
	TIME [epoch: 25 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45872202788948		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 4.45872202788948 | validation: 3.527807232621234]
	TIME [epoch: 25 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460354816897981		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 4.460354816897981 | validation: 3.5317208451541275]
	TIME [epoch: 24.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460293110884197		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 4.460293110884197 | validation: 3.534106736709473]
	TIME [epoch: 25 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478595424130142		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 4.478595424130142 | validation: 3.565199241712767]
	TIME [epoch: 25 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472143735751847		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 4.472143735751847 | validation: 3.5438962913839602]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462962870031229		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 4.462962870031229 | validation: 3.5235842171492364]
	TIME [epoch: 25 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4896379547163665		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 4.4896379547163665 | validation: 3.538910889657698]
	TIME [epoch: 25 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474067352833253		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 4.474067352833253 | validation: 3.5335605965709536]
	TIME [epoch: 24.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461648383694049		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 4.461648383694049 | validation: 3.5486316963332887]
	TIME [epoch: 25 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475567269851532		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 4.475567269851532 | validation: 3.540937783324349]
	TIME [epoch: 25 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46244386404188		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 4.46244386404188 | validation: 3.5348480768852175]
	TIME [epoch: 25 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462472752955298		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 4.462472752955298 | validation: 3.5528911160791252]
	TIME [epoch: 25 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465125522184394		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 4.465125522184394 | validation: 3.52812970809401]
	TIME [epoch: 25 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473635317824396		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 4.473635317824396 | validation: 3.5340653255360475]
	TIME [epoch: 25 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4764436716778855		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 4.4764436716778855 | validation: 3.5238211619600257]
	TIME [epoch: 25 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47840890540566		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 4.47840890540566 | validation: 3.536890061474437]
	TIME [epoch: 25 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4781953603240305		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 4.4781953603240305 | validation: 3.5290831878533444]
	TIME [epoch: 25 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45925289288175		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 4.45925289288175 | validation: 3.5562595874770193]
	TIME [epoch: 25 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481280491674655		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 4.481280491674655 | validation: 3.5300273692855706]
	TIME [epoch: 25 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460439793990956		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 4.460439793990956 | validation: 3.5313361697714143]
	TIME [epoch: 25 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465240759096876		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 4.465240759096876 | validation: 3.525697275138821]
	TIME [epoch: 25 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464172439383918		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 4.464172439383918 | validation: 3.557023726629378]
	TIME [epoch: 25 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461879258939742		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 4.461879258939742 | validation: 3.5361266465433814]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463985837167783		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 4.463985837167783 | validation: 3.5263829962707653]
	TIME [epoch: 25 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469321192577128		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 4.469321192577128 | validation: 3.5290483879449313]
	TIME [epoch: 25 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463688391456735		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 4.463688391456735 | validation: 3.538179525856052]
	TIME [epoch: 25 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457257760093209		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 4.457257760093209 | validation: 3.5548211363914]
	TIME [epoch: 25 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461356477347658		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 4.461356477347658 | validation: 3.5468268531639326]
	TIME [epoch: 25 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492336264950747		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 4.492336264950747 | validation: 3.535835580839553]
	TIME [epoch: 25 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467651954020303		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 4.467651954020303 | validation: 3.531283259153463]
	TIME [epoch: 25 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464815623796971		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 4.464815623796971 | validation: 3.530058072547926]
	TIME [epoch: 25 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464055060513496		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 4.464055060513496 | validation: 3.5415919344467506]
	TIME [epoch: 25 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462104308884916		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 4.462104308884916 | validation: 3.5306352177878866]
	TIME [epoch: 25 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475698794281126		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 4.475698794281126 | validation: 3.5298345568799188]
	TIME [epoch: 25 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471851234083884		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 4.471851234083884 | validation: 3.543559716558931]
	TIME [epoch: 25 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47664370270218		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 4.47664370270218 | validation: 3.53110888489478]
	TIME [epoch: 25 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478215434491597		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 4.478215434491597 | validation: 3.587746359471505]
	TIME [epoch: 25 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475877599505484		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 4.475877599505484 | validation: 3.5534406009413466]
	TIME [epoch: 25 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473703305222004		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 4.473703305222004 | validation: 3.5395581580876727]
	TIME [epoch: 25 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457344315727546		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 4.457344315727546 | validation: 3.5323691028691613]
	TIME [epoch: 25 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462530137865345		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 4.462530137865345 | validation: 3.534658698122111]
	TIME [epoch: 25 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4616475591756934		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 4.4616475591756934 | validation: 3.5382958392158566]
	TIME [epoch: 25 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468477918961135		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 4.468477918961135 | validation: 3.540594090872147]
	TIME [epoch: 25 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462378885992025		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 4.462378885992025 | validation: 3.538552313395021]
	TIME [epoch: 25 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458383504705354		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 4.458383504705354 | validation: 3.529850975509958]
	TIME [epoch: 25 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469795994716751		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 4.469795994716751 | validation: 3.5631919455257357]
	TIME [epoch: 25 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4814536170666175		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 4.4814536170666175 | validation: 3.54651650344592]
	TIME [epoch: 25 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480298502452319		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 4.480298502452319 | validation: 3.5324512495114835]
	TIME [epoch: 25 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467020261403332		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 4.467020261403332 | validation: 3.5285092527070754]
	TIME [epoch: 25 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469543457783241		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 4.469543457783241 | validation: 3.523766630546528]
	TIME [epoch: 25 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457032607155316		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 4.457032607155316 | validation: 3.5308220245706723]
	TIME [epoch: 25 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4648373139631		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 4.4648373139631 | validation: 3.5521605961453138]
	TIME [epoch: 25 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46832761073038		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 4.46832761073038 | validation: 3.5393788031354276]
	TIME [epoch: 25 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470205582104873		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 4.470205582104873 | validation: 3.535799487778476]
	TIME [epoch: 25 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45833816281511		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 4.45833816281511 | validation: 3.5274970959088643]
	TIME [epoch: 25 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460922234441313		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 4.460922234441313 | validation: 3.531800829552458]
	TIME [epoch: 25 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4578405429714785		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 4.4578405429714785 | validation: 3.537237419178733]
	TIME [epoch: 25 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479464117718519		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 4.479464117718519 | validation: 3.5436420818077705]
	TIME [epoch: 25 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462661108501084		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 4.462661108501084 | validation: 3.5302515705957056]
	TIME [epoch: 25 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455746049403218		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 4.455746049403218 | validation: 3.5393373199451204]
	TIME [epoch: 25 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464041703255669		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 4.464041703255669 | validation: 3.5544735446252207]
	TIME [epoch: 25 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461175406372941		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 4.461175406372941 | validation: 3.5622353455347198]
	TIME [epoch: 25 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47007054211654		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 4.47007054211654 | validation: 3.520551293569703]
	TIME [epoch: 25 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467057100168489		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 4.467057100168489 | validation: 3.521961805658571]
	TIME [epoch: 25 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4570674903660175		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 4.4570674903660175 | validation: 3.5386314733531163]
	TIME [epoch: 25 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466915226730646		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 4.466915226730646 | validation: 3.5409493328779833]
	TIME [epoch: 25 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466266322458882		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 4.466266322458882 | validation: 3.521623331116614]
	TIME [epoch: 25 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461465223731739		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 4.461465223731739 | validation: 3.5595696375624266]
	TIME [epoch: 25 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483472079636142		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 4.483472079636142 | validation: 3.5304299594686723]
	TIME [epoch: 25 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459841688119673		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 4.459841688119673 | validation: 3.5391657711788524]
	TIME [epoch: 25 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469409176991254		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 4.469409176991254 | validation: 3.528699324531541]
	TIME [epoch: 25 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461502171470735		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 4.461502171470735 | validation: 3.5361036117615177]
	TIME [epoch: 25 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464800221879696		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 4.464800221879696 | validation: 3.5277237046262586]
	TIME [epoch: 25 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470369068863116		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 4.470369068863116 | validation: 3.5388324694230717]
	TIME [epoch: 25 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460723821552557		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 4.460723821552557 | validation: 3.532709139696259]
	TIME [epoch: 25 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45632633010063		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 4.45632633010063 | validation: 3.533855563441081]
	TIME [epoch: 25 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46470101083178		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 4.46470101083178 | validation: 3.5610993831037083]
	TIME [epoch: 25 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467451018119877		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 4.467451018119877 | validation: 3.5448531252353224]
	TIME [epoch: 25 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46880958868874		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 4.46880958868874 | validation: 3.543382447592029]
	TIME [epoch: 25 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4767466743104976		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 4.4767466743104976 | validation: 3.522463572577901]
	TIME [epoch: 25 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462214347468534		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 4.462214347468534 | validation: 3.530456551863888]
	TIME [epoch: 25 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460954097472054		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 4.460954097472054 | validation: 3.533188411024828]
	TIME [epoch: 25 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4635454402566435		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 4.4635454402566435 | validation: 3.5314207206807806]
	TIME [epoch: 25 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463604731508918		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 4.463604731508918 | validation: 3.553591230675462]
	TIME [epoch: 25 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468963530316499		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 4.468963530316499 | validation: 3.5606457243900174]
	TIME [epoch: 25 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492452876172971		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 4.492452876172971 | validation: 3.5625923600100595]
	TIME [epoch: 25 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469812275592789		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 4.469812275592789 | validation: 3.536304184606203]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459794684851692		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 4.459794684851692 | validation: 3.5394753707340896]
	TIME [epoch: 25 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464812516992995		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 4.464812516992995 | validation: 3.5208956254886057]
	TIME [epoch: 25 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4691043555198835		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 4.4691043555198835 | validation: 3.5547282481692357]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47430567342022		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 4.47430567342022 | validation: 3.5397068139625816]
	TIME [epoch: 25 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466390881244246		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 4.466390881244246 | validation: 3.551150519674816]
	TIME [epoch: 25 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477386610339089		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 4.477386610339089 | validation: 3.6104845530528262]
	TIME [epoch: 25 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4941150113720205		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 4.4941150113720205 | validation: 3.537845538263838]
	TIME [epoch: 25 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465723892240737		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 4.465723892240737 | validation: 3.5303368969256157]
	TIME [epoch: 25 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4555867164899094		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 4.4555867164899094 | validation: 3.538906816202575]
	TIME [epoch: 25 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4614526077203305		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 4.4614526077203305 | validation: 3.53045310649658]
	TIME [epoch: 25 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459879779973708		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 4.459879779973708 | validation: 3.543573297551262]
	TIME [epoch: 25 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466010837012895		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 4.466010837012895 | validation: 3.533503639303524]
	TIME [epoch: 25 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464561358052697		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 4.464561358052697 | validation: 3.552190878580215]
	TIME [epoch: 25 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471090323791441		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 4.471090323791441 | validation: 3.5312062425713853]
	TIME [epoch: 25 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4700885662165035		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 4.4700885662165035 | validation: 3.5290969222491606]
	TIME [epoch: 25 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460994628258859		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 4.460994628258859 | validation: 3.5404816414137272]
	TIME [epoch: 25 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472663550361724		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 4.472663550361724 | validation: 3.5329676494758675]
	TIME [epoch: 25 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462756335451255		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 4.462756335451255 | validation: 3.5385716656925004]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463995142958408		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 4.463995142958408 | validation: 3.532490664494874]
	TIME [epoch: 25 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479750050885199		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 4.479750050885199 | validation: 3.5268504203311855]
	TIME [epoch: 25 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465309017947356		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 4.465309017947356 | validation: 3.585504489415555]
	TIME [epoch: 25 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4793251859649015		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 4.4793251859649015 | validation: 3.533272231139463]
	TIME [epoch: 25 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465729040379886		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 4.465729040379886 | validation: 3.53521497040393]
	TIME [epoch: 25 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459311830605854		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 4.459311830605854 | validation: 3.537138358745296]
	TIME [epoch: 25 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457995766199795		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 4.457995766199795 | validation: 3.542098331915371]
	TIME [epoch: 25 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472359244117622		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 4.472359244117622 | validation: 3.5308241343168585]
	TIME [epoch: 25 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4599837119315335		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 4.4599837119315335 | validation: 3.543070899475134]
	TIME [epoch: 24.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4743139557254015		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 4.4743139557254015 | validation: 3.5242150005747606]
	TIME [epoch: 25 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461867247979667		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 4.461867247979667 | validation: 3.521825516248683]
	TIME [epoch: 25 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459943787746478		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 4.459943787746478 | validation: 3.524157314248389]
	TIME [epoch: 24.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456717695019449		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 4.456717695019449 | validation: 3.538148223254343]
	TIME [epoch: 25 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457391132499681		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 4.457391132499681 | validation: 3.526529385213748]
	TIME [epoch: 25 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457118807291371		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 4.457118807291371 | validation: 3.5390795932634735]
	TIME [epoch: 24.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49070584139972		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 4.49070584139972 | validation: 3.5657018601148343]
	TIME [epoch: 25 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474642787029162		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 4.474642787029162 | validation: 3.5396373214123327]
	TIME [epoch: 25 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4614581049605135		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 4.4614581049605135 | validation: 3.530536076032898]
	TIME [epoch: 25 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472162880217057		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 4.472162880217057 | validation: 3.5643661037494314]
	TIME [epoch: 25 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483575086383857		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 4.483575086383857 | validation: 3.54149909367259]
	TIME [epoch: 25 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468751094061092		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 4.468751094061092 | validation: 3.5230673844173577]
	TIME [epoch: 24.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4551199434469275		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 4.4551199434469275 | validation: 3.529507227177078]
	TIME [epoch: 25 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458740896535504		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 4.458740896535504 | validation: 3.5245455653586704]
	TIME [epoch: 25 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459084492186445		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 4.459084492186445 | validation: 3.521448360218858]
	TIME [epoch: 24.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461206429071041		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 4.461206429071041 | validation: 3.527297572346579]
	TIME [epoch: 25 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46612461518466		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 4.46612461518466 | validation: 3.5524917890585823]
	TIME [epoch: 25 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462172544600779		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 4.462172544600779 | validation: 3.5416259474318417]
	TIME [epoch: 25 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468642895774575		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 4.468642895774575 | validation: 3.5482601128432236]
	TIME [epoch: 25 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471841764353993		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 4.471841764353993 | validation: 3.5249842890783065]
	TIME [epoch: 27.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458983859870042		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 4.458983859870042 | validation: 3.546892538126695]
	TIME [epoch: 24.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471117614886203		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 4.471117614886203 | validation: 3.5264522336783655]
	TIME [epoch: 25 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469899876913818		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 4.469899876913818 | validation: 3.5790434577697114]
	TIME [epoch: 25 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4736258609687924		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 4.4736258609687924 | validation: 3.5350011058767006]
	TIME [epoch: 25 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474812699532932		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 4.474812699532932 | validation: 3.535292154358387]
	TIME [epoch: 25 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461428404841566		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 4.461428404841566 | validation: 3.5338624237334186]
	TIME [epoch: 25 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4607333251595485		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 4.4607333251595485 | validation: 3.529357922442746]
	TIME [epoch: 25 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45859675135374		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 4.45859675135374 | validation: 3.527603753511464]
	TIME [epoch: 25 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459947193831817		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 4.459947193831817 | validation: 3.563409053457712]
	TIME [epoch: 25 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479616704811305		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 4.479616704811305 | validation: 3.522491521124249]
	TIME [epoch: 24.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461614549485522		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 4.461614549485522 | validation: 3.5412711573907774]
	TIME [epoch: 25 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458726212887996		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 4.458726212887996 | validation: 3.531657193212677]
	TIME [epoch: 25 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455964941616472		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 4.455964941616472 | validation: 3.5280528891586744]
	TIME [epoch: 24.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4608049471993265		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 4.4608049471993265 | validation: 3.5545348098869334]
	TIME [epoch: 25 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472934723056207		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 4.472934723056207 | validation: 3.533136948499932]
	TIME [epoch: 25 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459675676570518		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 4.459675676570518 | validation: 3.521082077830549]
	TIME [epoch: 24.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46581982701209		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 4.46581982701209 | validation: 3.5310076982756176]
	TIME [epoch: 25 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461835476729901		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 4.461835476729901 | validation: 3.523093800155166]
	TIME [epoch: 25 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458315529701072		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 4.458315529701072 | validation: 3.537608126401177]
	TIME [epoch: 24.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475439315167971		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 4.475439315167971 | validation: 3.525811624310517]
	TIME [epoch: 25 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460666263571		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 4.460666263571 | validation: 3.5559760226176578]
	TIME [epoch: 25 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4782230898468		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 4.4782230898468 | validation: 3.551090156573577]
	TIME [epoch: 25 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474884926218934		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 4.474884926218934 | validation: 3.536681290215424]
	TIME [epoch: 25 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459644248677491		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 4.459644248677491 | validation: 3.52924502814527]
	TIME [epoch: 25 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4598396993179765		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 4.4598396993179765 | validation: 3.5297549660663616]
	TIME [epoch: 24.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461368922590458		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 4.461368922590458 | validation: 3.5225422884962514]
	TIME [epoch: 25 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4560379466483155		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 4.4560379466483155 | validation: 3.526998941500865]
	TIME [epoch: 25 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461867582991271		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 4.461867582991271 | validation: 3.531928742096781]
	TIME [epoch: 25 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45778425400146		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 4.45778425400146 | validation: 3.521786938378964]
	TIME [epoch: 25 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458012593580465		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 4.458012593580465 | validation: 3.527188587192164]
	TIME [epoch: 25 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465192937113687		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 4.465192937113687 | validation: 3.5514348986813618]
	TIME [epoch: 25 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501074616571399		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 4.501074616571399 | validation: 3.571906106944821]
	TIME [epoch: 25 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468531283108849		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 4.468531283108849 | validation: 3.525138797062756]
	TIME [epoch: 25 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454390819291642		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 4.454390819291642 | validation: 3.5261813198320806]
	TIME [epoch: 25 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453545512226748		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 4.453545512226748 | validation: 3.5295859534702063]
	TIME [epoch: 25 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46345158117545		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 4.46345158117545 | validation: 3.5747244508176856]
	TIME [epoch: 25 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478749815323832		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 4.478749815323832 | validation: 3.529151039448084]
	TIME [epoch: 25 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465272592110887		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 4.465272592110887 | validation: 3.547313313122329]
	TIME [epoch: 25 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461095437168604		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 4.461095437168604 | validation: 3.53015451776266]
	TIME [epoch: 25 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465522045225209		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 4.465522045225209 | validation: 3.5302677869282038]
	TIME [epoch: 25 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45561338312673		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 4.45561338312673 | validation: 3.5318080292448237]
	TIME [epoch: 25 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456740779132528		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 4.456740779132528 | validation: 3.5358110027089458]
	TIME [epoch: 25 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470507950087342		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 4.470507950087342 | validation: 3.532296910170303]
	TIME [epoch: 24.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455210635817647		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 4.455210635817647 | validation: 3.5368279922562045]
	TIME [epoch: 25 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457430668402478		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 4.457430668402478 | validation: 3.521007391046478]
	TIME [epoch: 25 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458801418070432		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 4.458801418070432 | validation: 3.533580985187764]
	TIME [epoch: 25 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475494153810404		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 4.475494153810404 | validation: 3.5675782908625604]
	TIME [epoch: 25 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473408724250635		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 4.473408724250635 | validation: 3.547433574453081]
	TIME [epoch: 25 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461509673784384		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 4.461509673784384 | validation: 3.5335666412686324]
	TIME [epoch: 25 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459928014443567		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 4.459928014443567 | validation: 3.5342291133850656]
	TIME [epoch: 25 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460324511635912		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 4.460324511635912 | validation: 3.5331653877383453]
	TIME [epoch: 25 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460366362856294		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 4.460366362856294 | validation: 3.527108492146859]
	TIME [epoch: 25 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456772545460257		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 4.456772545460257 | validation: 3.5246285054319633]
	TIME [epoch: 25 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4621845823814485		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 4.4621845823814485 | validation: 3.5265617634630453]
	TIME [epoch: 25 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4649482706737444		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 4.4649482706737444 | validation: 3.5344730662037875]
	TIME [epoch: 25 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4589249807188445		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 4.4589249807188445 | validation: 3.530533936769596]
	TIME [epoch: 25 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4640690994606365		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 4.4640690994606365 | validation: 3.5248681029161752]
	TIME [epoch: 25 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453982266218761		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 4.453982266218761 | validation: 3.5281086662602417]
	TIME [epoch: 25 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457520723493261		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 4.457520723493261 | validation: 3.524505966186302]
	TIME [epoch: 25 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458720346479239		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 4.458720346479239 | validation: 3.536866755274529]
	TIME [epoch: 25 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458836069960219		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 4.458836069960219 | validation: 3.529218496733027]
	TIME [epoch: 25 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4565907929863045		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 4.4565907929863045 | validation: 3.5274279457784803]
	TIME [epoch: 25 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4573259126001		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 4.4573259126001 | validation: 3.5250462626182664]
	TIME [epoch: 25 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459511403224044		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 4.459511403224044 | validation: 3.5253337863264784]
	TIME [epoch: 25 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467849692021437		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 4.467849692021437 | validation: 3.544705121687564]
	TIME [epoch: 25 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465977008885542		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 4.465977008885542 | validation: 3.5328087132920314]
	TIME [epoch: 25 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4608151449629805		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 4.4608151449629805 | validation: 3.529937291057266]
	TIME [epoch: 25 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456814377146572		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 4.456814377146572 | validation: 3.541374268797412]
	TIME [epoch: 25 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456857910923631		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 4.456857910923631 | validation: 3.538592313675372]
	TIME [epoch: 25 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462678061114687		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 4.462678061114687 | validation: 3.5369940031753675]
	TIME [epoch: 25 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460867097231307		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 4.460867097231307 | validation: 3.522578556401079]
	TIME [epoch: 25 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453838680605244		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 4.453838680605244 | validation: 3.5238376797647244]
	TIME [epoch: 25 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459515821230351		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 4.459515821230351 | validation: 3.551729456311419]
	TIME [epoch: 25 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460966584588572		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 4.460966584588572 | validation: 3.535227963692608]
	TIME [epoch: 25 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455155262652704		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 4.455155262652704 | validation: 3.515840480618034]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_962.pth
	Model improved!!!
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461397371462327		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 4.461397371462327 | validation: 3.5631436521724376]
	TIME [epoch: 25 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477269298713562		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 4.477269298713562 | validation: 3.5262961010522687]
	TIME [epoch: 25 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455049837255654		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 4.455049837255654 | validation: 3.5360075258149677]
	TIME [epoch: 25 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467582329618084		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 4.467582329618084 | validation: 3.5208572078078717]
	TIME [epoch: 25 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460153893552427		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 4.460153893552427 | validation: 3.5251354428878656]
	TIME [epoch: 25 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4695884397526084		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 4.4695884397526084 | validation: 3.5458751232243175]
	TIME [epoch: 25 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461041209949958		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 4.461041209949958 | validation: 3.5420306496525997]
	TIME [epoch: 25 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4671947631884095		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 4.4671947631884095 | validation: 3.534481411461543]
	TIME [epoch: 25 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45417385614517		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 4.45417385614517 | validation: 3.526587384059586]
	TIME [epoch: 25 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459313760718847		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 4.459313760718847 | validation: 3.527058178973765]
	TIME [epoch: 25 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.450630981504835		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 4.450630981504835 | validation: 3.52501433866963]
	TIME [epoch: 25 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465513057876496		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 4.465513057876496 | validation: 3.5271409791408694]
	TIME [epoch: 25 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456054434138791		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 4.456054434138791 | validation: 3.5233155850407174]
	TIME [epoch: 25 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453543335414597		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 4.453543335414597 | validation: 3.5249828945171133]
	TIME [epoch: 25 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4589709621113		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 4.4589709621113 | validation: 3.5254922801565933]
	TIME [epoch: 25 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4606101823168975		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 4.4606101823168975 | validation: 3.5353599570985614]
	TIME [epoch: 25 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460930999269932		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 4.460930999269932 | validation: 3.5320728055812594]
	TIME [epoch: 25 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464511779146975		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 4.464511779146975 | validation: 3.5543501429356743]
	TIME [epoch: 25 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492883431236373		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 4.492883431236373 | validation: 3.601314855391987]
	TIME [epoch: 25 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.485828677553209		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 4.485828677553209 | validation: 3.5340198091414705]
	TIME [epoch: 25 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4608243577798055		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 4.4608243577798055 | validation: 3.5378137342120826]
	TIME [epoch: 25 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457462299822955		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 4.457462299822955 | validation: 3.518529267864289]
	TIME [epoch: 25 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457715783267998		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 4.457715783267998 | validation: 3.5349123221564303]
	TIME [epoch: 25 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461112902179892		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 4.461112902179892 | validation: 3.535936152117302]
	TIME [epoch: 25 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469697631063479		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 4.469697631063479 | validation: 3.539895803540386]
	TIME [epoch: 25 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465378834008823		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 4.465378834008823 | validation: 3.5517378728853948]
	TIME [epoch: 25 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4709568288880295		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 4.4709568288880295 | validation: 3.552123491987689]
	TIME [epoch: 25 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463571060151007		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 4.463571060151007 | validation: 3.534934637303646]
	TIME [epoch: 25 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459958899275524		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 4.459958899275524 | validation: 3.533270921010328]
	TIME [epoch: 25 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465649754861612		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 4.465649754861612 | validation: 3.54681097240597]
	TIME [epoch: 25 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4635715703766685		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 4.4635715703766685 | validation: 3.523105199106118]
	TIME [epoch: 25 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455785288078363		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 4.455785288078363 | validation: 3.532591234668778]
	TIME [epoch: 25 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463359098435843		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 4.463359098435843 | validation: 3.554379299779323]
	TIME [epoch: 25 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463691023651952		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 4.463691023651952 | validation: 3.541610637795382]
	TIME [epoch: 25 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460639312476228		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 4.460639312476228 | validation: 3.5447808425427976]
	TIME [epoch: 25 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457335704877767		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 4.457335704877767 | validation: 3.532271104228995]
	TIME [epoch: 25 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455644101920596		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 4.455644101920596 | validation: 3.535085589299176]
	TIME [epoch: 25 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458669686947509		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 4.458669686947509 | validation: 3.516673581844569]
	TIME [epoch: 25 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4590812695763065		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 4.4590812695763065 | validation: 3.515317598093761]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_1001.pth
	Model improved!!!
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454387279210421		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 4.454387279210421 | validation: 3.5202536813109044]
	TIME [epoch: 25 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478786039549723		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 4.478786039549723 | validation: 3.5435947554272413]
	TIME [epoch: 25 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472396264045435		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 4.472396264045435 | validation: 3.533678473308547]
	TIME [epoch: 25 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458018339115124		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 4.458018339115124 | validation: 3.5253179124266687]
	TIME [epoch: 25 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457311810722889		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 4.457311810722889 | validation: 3.5301440811792917]
	TIME [epoch: 24.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454043242856783		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 4.454043242856783 | validation: 3.527924977245535]
	TIME [epoch: 25 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454418985532499		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 4.454418985532499 | validation: 3.5370853918309506]
	TIME [epoch: 25 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470370260826478		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 4.470370260826478 | validation: 3.528959013227234]
	TIME [epoch: 24.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4578985989860165		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 4.4578985989860165 | validation: 3.524441759539003]
	TIME [epoch: 25 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455018443872636		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 4.455018443872636 | validation: 3.5240966551036523]
	TIME [epoch: 25 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458601262419937		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 4.458601262419937 | validation: 3.532338591837106]
	TIME [epoch: 24.9 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462314119867846		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 4.462314119867846 | validation: 3.581812594127402]
	TIME [epoch: 25 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490399375853336		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 4.490399375853336 | validation: 3.5641491341493263]
	TIME [epoch: 25 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471835821572736		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 4.471835821572736 | validation: 3.5432299416320077]
	TIME [epoch: 24.9 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457971885213325		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 4.457971885213325 | validation: 3.527245242203191]
	TIME [epoch: 25 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459736323405593		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 4.459736323405593 | validation: 3.5293667419651356]
	TIME [epoch: 25 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461811332840371		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 4.461811332840371 | validation: 3.543559892579864]
	TIME [epoch: 24.9 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461924188761122		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 4.461924188761122 | validation: 3.5352982368228654]
	TIME [epoch: 25 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464261951021012		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 4.464261951021012 | validation: 3.5674242475847264]
	TIME [epoch: 25 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482756688191165		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 4.482756688191165 | validation: 3.5568807769335513]
	TIME [epoch: 24.9 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464415429609739		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 4.464415429609739 | validation: 3.538419543935887]
	TIME [epoch: 25 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451222266809969		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 4.451222266809969 | validation: 3.532422919331674]
	TIME [epoch: 25 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4600056988814725		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 4.4600056988814725 | validation: 3.5427551591063353]
	TIME [epoch: 25 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462158493915414		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 4.462158493915414 | validation: 3.539050135616786]
	TIME [epoch: 25 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458753698379333		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 4.458753698379333 | validation: 3.5265657730135267]
	TIME [epoch: 25 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4659966365869375		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 4.4659966365869375 | validation: 3.534684452734242]
	TIME [epoch: 25 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461286628071107		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 4.461286628071107 | validation: 3.5375665771828917]
	TIME [epoch: 25 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.46080974967102		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 4.46080974967102 | validation: 3.520389831889546]
	TIME [epoch: 25 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4594337616729804		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 4.4594337616729804 | validation: 3.5268182925554243]
	TIME [epoch: 25 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463203374849462		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 4.463203374849462 | validation: 3.5240247115015313]
	TIME [epoch: 25 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462878051154105		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 4.462878051154105 | validation: 3.530754576083673]
	TIME [epoch: 25 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456034143334208		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 4.456034143334208 | validation: 3.5220789275608797]
	TIME [epoch: 25 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456378838193071		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 4.456378838193071 | validation: 3.5325764172832885]
	TIME [epoch: 25 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4624780510968645		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 4.4624780510968645 | validation: 3.5228939454950297]
	TIME [epoch: 25 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454189950517744		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 4.454189950517744 | validation: 3.522308178649947]
	TIME [epoch: 25 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460020493626949		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 4.460020493626949 | validation: 3.535726873587448]
	TIME [epoch: 25 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4548285029090255		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 4.4548285029090255 | validation: 3.524853305909724]
	TIME [epoch: 25 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456493427548553		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 4.456493427548553 | validation: 3.530786975063245]
	TIME [epoch: 25 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456059969217195		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 4.456059969217195 | validation: 3.5260268794492546]
	TIME [epoch: 25 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454090282916419		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 4.454090282916419 | validation: 3.5416428779323113]
	TIME [epoch: 25 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462286213798826		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 4.462286213798826 | validation: 3.52948672268544]
	TIME [epoch: 25 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464187420759235		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 4.464187420759235 | validation: 3.5342772709211916]
	TIME [epoch: 25 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465790344222782		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 4.465790344222782 | validation: 3.5445447223464277]
	TIME [epoch: 25 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459635927115139		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 4.459635927115139 | validation: 3.526050707916226]
	TIME [epoch: 25 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461107752490689		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 4.461107752490689 | validation: 3.533848633787154]
	TIME [epoch: 25 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463377662096061		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 4.463377662096061 | validation: 3.528745124650583]
	TIME [epoch: 25 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453477065959544		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 4.453477065959544 | validation: 3.513946825881718]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_1048.pth
	Model improved!!!
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455839817415942		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 4.455839817415942 | validation: 3.525939235927699]
	TIME [epoch: 25 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4588966417799		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 4.4588966417799 | validation: 3.527638265434398]
	TIME [epoch: 25 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4562291954767765		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 4.4562291954767765 | validation: 3.535736897790425]
	TIME [epoch: 24.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45864617337416		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 4.45864617337416 | validation: 3.519483484642001]
	TIME [epoch: 25 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452455586354472		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 4.452455586354472 | validation: 3.52632258470482]
	TIME [epoch: 25 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459920555173579		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 4.459920555173579 | validation: 3.538803878647954]
	TIME [epoch: 25 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454831884053243		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 4.454831884053243 | validation: 3.522238433551505]
	TIME [epoch: 24.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4608072017085005		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 4.4608072017085005 | validation: 3.528765514840245]
	TIME [epoch: 25 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456764391396987		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 4.456764391396987 | validation: 3.5318972189260154]
	TIME [epoch: 25 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.472014163767642		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 4.472014163767642 | validation: 3.553289139732306]
	TIME [epoch: 24.9 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464945555341365		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 4.464945555341365 | validation: 3.53390538180505]
	TIME [epoch: 25 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458767380663837		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 4.458767380663837 | validation: 3.54854979054618]
	TIME [epoch: 25 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4626902225125935		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 4.4626902225125935 | validation: 3.527974395157973]
	TIME [epoch: 25 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461210611242523		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 4.461210611242523 | validation: 3.535081204575462]
	TIME [epoch: 25 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470236247573869		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 4.470236247573869 | validation: 3.536834126021481]
	TIME [epoch: 25 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460314571517406		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 4.460314571517406 | validation: 3.531400771969895]
	TIME [epoch: 24.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4717836137353615		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 4.4717836137353615 | validation: 3.531788009150567]
	TIME [epoch: 25 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458094381828223		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 4.458094381828223 | validation: 3.536305596284912]
	TIME [epoch: 24.9 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463862874146269		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 4.463862874146269 | validation: 3.5318349256948434]
	TIME [epoch: 25 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45261965933116		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 4.45261965933116 | validation: 3.527199358225892]
	TIME [epoch: 25 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456372747162418		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 4.456372747162418 | validation: 3.531174539377701]
	TIME [epoch: 25 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467418246250418		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 4.467418246250418 | validation: 3.522907950447176]
	TIME [epoch: 24.9 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451467467816298		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 4.451467467816298 | validation: 3.5249051936276494]
	TIME [epoch: 25 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458863539377979		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 4.458863539377979 | validation: 3.5291195676804996]
	TIME [epoch: 25 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45393582968648		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 4.45393582968648 | validation: 3.5349122097088537]
	TIME [epoch: 25 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459076990668108		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 4.459076990668108 | validation: 3.522251313636574]
	TIME [epoch: 25 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454147713966648		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 4.454147713966648 | validation: 3.5179604665253703]
	TIME [epoch: 25 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457573440067327		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 4.457573440067327 | validation: 3.533343194062123]
	TIME [epoch: 24.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457545472191927		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 4.457545472191927 | validation: 3.528994346016707]
	TIME [epoch: 25 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4542142779250735		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 4.4542142779250735 | validation: 3.5312015804130943]
	TIME [epoch: 25 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455724898085279		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 4.455724898085279 | validation: 3.5339991419999195]
	TIME [epoch: 25 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461571516945008		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 4.461571516945008 | validation: 3.5349854323672405]
	TIME [epoch: 25 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458375627810092		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 4.458375627810092 | validation: 3.5200076804963785]
	TIME [epoch: 24.9 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461068318746078		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 4.461068318746078 | validation: 3.517768652675447]
	TIME [epoch: 24.9 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457643394184604		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 4.457643394184604 | validation: 3.5154947678016923]
	TIME [epoch: 25 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458673748730581		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 4.458673748730581 | validation: 3.5304648356655295]
	TIME [epoch: 25 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452808651582593		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 4.452808651582593 | validation: 3.5208849201474037]
	TIME [epoch: 25 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455083387230184		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 4.455083387230184 | validation: 3.524707059744676]
	TIME [epoch: 25 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45592597070346		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 4.45592597070346 | validation: 3.525361273523822]
	TIME [epoch: 25 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457374306564759		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 4.457374306564759 | validation: 3.525761331879106]
	TIME [epoch: 24.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454392325010055		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 4.454392325010055 | validation: 3.516763103770611]
	TIME [epoch: 25 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455075359654967		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 4.455075359654967 | validation: 3.5337388226371873]
	TIME [epoch: 25 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4605496086711085		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 4.4605496086711085 | validation: 3.529366321256393]
	TIME [epoch: 24.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464685395274196		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 4.464685395274196 | validation: 3.5298838237523693]
	TIME [epoch: 25 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456258674867633		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 4.456258674867633 | validation: 3.5157209089215273]
	TIME [epoch: 25 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4553529588060305		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 4.4553529588060305 | validation: 3.523815098989054]
	TIME [epoch: 24.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455862277212946		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 4.455862277212946 | validation: 3.5224241442210076]
	TIME [epoch: 25 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458665590742898		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 4.458665590742898 | validation: 3.530546640629229]
	TIME [epoch: 25 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464505912374028		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 4.464505912374028 | validation: 3.53844110442446]
	TIME [epoch: 24.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464324169306317		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 4.464324169306317 | validation: 3.5373367598750893]
	TIME [epoch: 25 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465013507542668		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 4.465013507542668 | validation: 3.528038314433905]
	TIME [epoch: 25 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45208480452877		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 4.45208480452877 | validation: 3.5236148271401646]
	TIME [epoch: 24.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466850245720114		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 4.466850245720114 | validation: 3.55019440933007]
	TIME [epoch: 25 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470574303896522		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 4.470574303896522 | validation: 3.554879301342403]
	TIME [epoch: 25 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470888304995881		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 4.470888304995881 | validation: 3.5402235188414357]
	TIME [epoch: 24.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465611900590672		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 4.465611900590672 | validation: 3.5291321063840506]
	TIME [epoch: 25 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456217809907358		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 4.456217809907358 | validation: 3.5257862037679297]
	TIME [epoch: 25 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452216871931898		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 4.452216871931898 | validation: 3.538101369797694]
	TIME [epoch: 24.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460634660854984		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 4.460634660854984 | validation: 3.5435470489300998]
	TIME [epoch: 25 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467833315253439		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 4.467833315253439 | validation: 3.5435397038721668]
	TIME [epoch: 25 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468915631641789		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 4.468915631641789 | validation: 3.5332758777965854]
	TIME [epoch: 24.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4565711074469885		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 4.4565711074469885 | validation: 3.526164808322211]
	TIME [epoch: 25 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45516814175445		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 4.45516814175445 | validation: 3.5219994086875532]
	TIME [epoch: 25 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4569308376761585		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 4.4569308376761585 | validation: 3.5203076646193394]
	TIME [epoch: 24.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456409584061342		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 4.456409584061342 | validation: 3.5303877808003823]
	TIME [epoch: 25 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459226056519773		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 4.459226056519773 | validation: 3.532735231070555]
	TIME [epoch: 25 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457872253997753		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 4.457872253997753 | validation: 3.5240334657779084]
	TIME [epoch: 24.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453837584879975		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 4.453837584879975 | validation: 3.538317084383763]
	TIME [epoch: 25 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464063087601824		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 4.464063087601824 | validation: 3.5511852454077246]
	TIME [epoch: 25 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471713625071277		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 4.471713625071277 | validation: 3.5521586496031077]
	TIME [epoch: 24.9 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464809593607865		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 4.464809593607865 | validation: 3.521669637102718]
	TIME [epoch: 25 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452639755317307		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 4.452639755317307 | validation: 3.5277538292283728]
	TIME [epoch: 25 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452758646445163		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 4.452758646445163 | validation: 3.523709578064453]
	TIME [epoch: 24.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458845145446306		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 4.458845145446306 | validation: 3.521338152798245]
	TIME [epoch: 25 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457772470839757		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 4.457772470839757 | validation: 3.526601566141594]
	TIME [epoch: 25 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455685637925125		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 4.455685637925125 | validation: 3.5288226347455227]
	TIME [epoch: 24.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457735519656737		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 4.457735519656737 | validation: 3.519059151150909]
	TIME [epoch: 25 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458047560791047		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 4.458047560791047 | validation: 3.531703882692119]
	TIME [epoch: 25 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454884452720112		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 4.454884452720112 | validation: 3.525194416353979]
	TIME [epoch: 24.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4554736900739975		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 4.4554736900739975 | validation: 3.535753064645527]
	TIME [epoch: 25 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459571485522914		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 4.459571485522914 | validation: 3.528593672060513]
	TIME [epoch: 25 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454937046008292		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 4.454937046008292 | validation: 3.5194179461595474]
	TIME [epoch: 24.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452762997977417		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 4.452762997977417 | validation: 3.5226754757099386]
	TIME [epoch: 25 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453700847094269		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 4.453700847094269 | validation: 3.52230706054911]
	TIME [epoch: 25 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453950590160945		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 4.453950590160945 | validation: 3.5262273731805527]
	TIME [epoch: 24.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455381968363587		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 4.455381968363587 | validation: 3.531596629984091]
	TIME [epoch: 25 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457788799667967		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 4.457788799667967 | validation: 3.5247326610810354]
	TIME [epoch: 25 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452027116047856		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 4.452027116047856 | validation: 3.523857224135801]
	TIME [epoch: 24.9 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462822063265116		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 4.462822063265116 | validation: 3.5302157358227895]
	TIME [epoch: 25 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462144088786706		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 4.462144088786706 | validation: 3.5190414397479652]
	TIME [epoch: 25 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459938663321328		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 4.459938663321328 | validation: 3.5328396922372143]
	TIME [epoch: 24.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464841251320701		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 4.464841251320701 | validation: 3.537319981911283]
	TIME [epoch: 25 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462933978453751		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 4.462933978453751 | validation: 3.528854239421175]
	TIME [epoch: 25 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458534572574511		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 4.458534572574511 | validation: 3.5222826217914998]
	TIME [epoch: 24.9 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459632817913954		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 4.459632817913954 | validation: 3.5266965324630095]
	TIME [epoch: 25 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457854606317185		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 4.457854606317185 | validation: 3.5257770319849318]
	TIME [epoch: 25 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458200072332383		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 4.458200072332383 | validation: 3.5214496165119193]
	TIME [epoch: 24.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454130180173194		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 4.454130180173194 | validation: 3.5249246561894565]
	TIME [epoch: 25 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4559295197464825		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 4.4559295197464825 | validation: 3.527492738698921]
	TIME [epoch: 25 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453012726745689		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 4.453012726745689 | validation: 3.532719112732878]
	TIME [epoch: 24.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456260456552404		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 4.456260456552404 | validation: 3.5190562325289343]
	TIME [epoch: 25 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4543313698928735		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 4.4543313698928735 | validation: 3.521599163139232]
	TIME [epoch: 25 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456972405221968		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 4.456972405221968 | validation: 3.525136136221076]
	TIME [epoch: 24.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45838447997197		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 4.45838447997197 | validation: 3.5201478843602083]
	TIME [epoch: 25 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455410392429279		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 4.455410392429279 | validation: 3.5279602326348347]
	TIME [epoch: 25 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455497453672949		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 4.455497453672949 | validation: 3.533497210420898]
	TIME [epoch: 24.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461061392472239		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 4.461061392472239 | validation: 3.523466048268152]
	TIME [epoch: 25 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455214755083065		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 4.455214755083065 | validation: 3.54324473335045]
	TIME [epoch: 25 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458609322391014		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 4.458609322391014 | validation: 3.5278143183616057]
	TIME [epoch: 24.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457923391551181		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 4.457923391551181 | validation: 3.53061382306996]
	TIME [epoch: 25 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455225574655913		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 4.455225574655913 | validation: 3.51857189728562]
	TIME [epoch: 25 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454959499607419		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 4.454959499607419 | validation: 3.5341008162876495]
	TIME [epoch: 24.9 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459062662044255		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 4.459062662044255 | validation: 3.522369829518315]
	TIME [epoch: 25 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455595341461571		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 4.455595341461571 | validation: 3.530227947365055]
	TIME [epoch: 25 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455651727137914		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 4.455651727137914 | validation: 3.5227461066441332]
	TIME [epoch: 24.9 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452757796094342		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 4.452757796094342 | validation: 3.5313814116842166]
	TIME [epoch: 25 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4548311022085585		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 4.4548311022085585 | validation: 3.5240121379848404]
	TIME [epoch: 25 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454136171346373		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 4.454136171346373 | validation: 3.5280929715971223]
	TIME [epoch: 24.9 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457519305833385		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 4.457519305833385 | validation: 3.5320050979904103]
	TIME [epoch: 25 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457959235693004		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 4.457959235693004 | validation: 3.5287719230434096]
	TIME [epoch: 25 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453962470614024		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 4.453962470614024 | validation: 3.523492633525388]
	TIME [epoch: 24.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452691935887209		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 4.452691935887209 | validation: 3.5177288994138802]
	TIME [epoch: 25 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45321080259798		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 4.45321080259798 | validation: 3.5255539080683342]
	TIME [epoch: 25 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458096006420676		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 4.458096006420676 | validation: 3.513120231383636]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r5_20240310_060952/states/model_tr_study206_1172.pth
	Model improved!!!
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456994548521974		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 4.456994548521974 | validation: 3.521766207691701]
	TIME [epoch: 25 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456070585848611		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 4.456070585848611 | validation: 3.5223594848527684]
	TIME [epoch: 25 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461080475694114		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 4.461080475694114 | validation: 3.5202157459049763]
	TIME [epoch: 24.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458775421160014		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 4.458775421160014 | validation: 3.518899228831342]
	TIME [epoch: 25 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454129676398663		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 4.454129676398663 | validation: 3.5147693642766518]
	TIME [epoch: 25 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455636816159705		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 4.455636816159705 | validation: 3.5213179185778642]
	TIME [epoch: 24.9 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457915328415546		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 4.457915328415546 | validation: 3.5302954429983378]
	TIME [epoch: 25 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457416342259678		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 4.457416342259678 | validation: 3.523065309030884]
	TIME [epoch: 25 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4565592374421765		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 4.4565592374421765 | validation: 3.5190473740669566]
	TIME [epoch: 24.9 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4565703014038425		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 4.4565703014038425 | validation: 3.535215617022643]
	TIME [epoch: 25 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461547656627198		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 4.461547656627198 | validation: 3.529372913768219]
	TIME [epoch: 25 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455190998618002		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 4.455190998618002 | validation: 3.519246276856211]
	TIME [epoch: 24.9 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455837512923814		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 4.455837512923814 | validation: 3.5186663842614734]
	TIME [epoch: 24.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452558692987328		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 4.452558692987328 | validation: 3.5241575404064167]
	TIME [epoch: 25 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453838514302198		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 4.453838514302198 | validation: 3.5206566253666085]
	TIME [epoch: 24.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452190021173067		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 4.452190021173067 | validation: 3.5261459146255074]
	TIME [epoch: 25 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459877726001828		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 4.459877726001828 | validation: 3.5217019495495987]
	TIME [epoch: 25 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455872756026298		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 4.455872756026298 | validation: 3.5254114785989907]
	TIME [epoch: 24.9 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454957633821817		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 4.454957633821817 | validation: 3.523597277573556]
	TIME [epoch: 25 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4534719793651805		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 4.4534719793651805 | validation: 3.5225742467791554]
	TIME [epoch: 25 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460164710921589		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 4.460164710921589 | validation: 3.521367962757822]
	TIME [epoch: 24.9 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4598989961756885		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 4.4598989961756885 | validation: 3.524027606120402]
	TIME [epoch: 25 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459495256690669		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 4.459495256690669 | validation: 3.5228119286257353]
	TIME [epoch: 25 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456391951838572		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 4.456391951838572 | validation: 3.5218158636180568]
	TIME [epoch: 25 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460327678257127		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 4.460327678257127 | validation: 3.520520178447191]
	TIME [epoch: 24.9 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451670271304635		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 4.451670271304635 | validation: 3.5191255307727864]
	TIME [epoch: 25 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452760489880427		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 4.452760489880427 | validation: 3.523394236533751]
	TIME [epoch: 25 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452698927429415		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 4.452698927429415 | validation: 3.5233336203331067]
	TIME [epoch: 24.9 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455103671356079		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 4.455103671356079 | validation: 3.5207349590126147]
	TIME [epoch: 25 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4582369449817785		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 4.4582369449817785 | validation: 3.5226563658823906]
	TIME [epoch: 25 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458681021475274		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 4.458681021475274 | validation: 3.51737380553947]
	TIME [epoch: 24.9 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4536222384861475		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 4.4536222384861475 | validation: 3.518843976323386]
	TIME [epoch: 25 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454963869685399		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 4.454963869685399 | validation: 3.5214093468597354]
	TIME [epoch: 24.9 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455786492250555		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 4.455786492250555 | validation: 3.5214573243053064]
	TIME [epoch: 24.9 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.450432933781071		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 4.450432933781071 | validation: 3.5227065771942114]
	TIME [epoch: 25 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455134946179726		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 4.455134946179726 | validation: 3.530749969193195]
	TIME [epoch: 24.9 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45872982175287		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 4.45872982175287 | validation: 3.5226610081574825]
	TIME [epoch: 25 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453084184897816		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 4.453084184897816 | validation: 3.521761210893818]
	TIME [epoch: 25 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453713519280703		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 4.453713519280703 | validation: 3.5299684628362877]
	TIME [epoch: 24.9 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455910040302386		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 4.455910040302386 | validation: 3.523658344274275]
	TIME [epoch: 24.9 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456673484657242		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 4.456673484657242 | validation: 3.526980941622866]
	TIME [epoch: 25 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4555065440727395		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 4.4555065440727395 | validation: 3.5289837987210717]
	TIME [epoch: 24.9 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458893871641731		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 4.458893871641731 | validation: 3.53436891363472]
	TIME [epoch: 25 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452211121424914		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 4.452211121424914 | validation: 3.530685158057456]
	TIME [epoch: 25 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454049891476867		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 4.454049891476867 | validation: 3.522469022744915]
	TIME [epoch: 24.9 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455732218421018		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 4.455732218421018 | validation: 3.531439419550955]
	TIME [epoch: 25 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4565262773868515		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 4.4565262773868515 | validation: 3.518972390345265]
	TIME [epoch: 25 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455543560342331		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 4.455543560342331 | validation: 3.5276523217022233]
	TIME [epoch: 24.9 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458180793537942		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 4.458180793537942 | validation: 3.5165043114180548]
	TIME [epoch: 25 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452468986332351		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 4.452468986332351 | validation: 3.520520006874199]
	TIME [epoch: 25 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4569847014317645		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 4.4569847014317645 | validation: 3.5243202128411744]
	TIME [epoch: 24.9 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45564384431128		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 4.45564384431128 | validation: 3.522178539636032]
	TIME [epoch: 25 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455706061470482		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 4.455706061470482 | validation: 3.514845657911912]
	TIME [epoch: 25 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457190825721467		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 4.457190825721467 | validation: 3.5286202318618622]
	TIME [epoch: 24.9 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456569741528832		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 4.456569741528832 | validation: 3.519466969737062]
	TIME [epoch: 25 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45256028205033		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 4.45256028205033 | validation: 3.527543030571062]
	TIME [epoch: 25 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453478936520799		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 4.453478936520799 | validation: 3.523500634792482]
	TIME [epoch: 24.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461535805540496		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 4.461535805540496 | validation: 3.521919136617048]
	TIME [epoch: 24.9 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456145227910592		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 4.456145227910592 | validation: 3.519042863516006]
	TIME [epoch: 25 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452886853692728		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 4.452886853692728 | validation: 3.514197079949405]
	TIME [epoch: 25 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455727928666949		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 4.455727928666949 | validation: 3.519550039993309]
	TIME [epoch: 24.9 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4559774906735194		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 4.4559774906735194 | validation: 3.5267602102025215]
	TIME [epoch: 25 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459641462721185		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 4.459641462721185 | validation: 3.5251079617229126]
	TIME [epoch: 25 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457362576747054		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 4.457362576747054 | validation: 3.5263839708043427]
	TIME [epoch: 24.9 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.450997404765657		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 4.450997404765657 | validation: 3.5233598353448703]
	TIME [epoch: 25 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454029755038853		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 4.454029755038853 | validation: 3.5218051632170275]
	TIME [epoch: 25 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454959174044916		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 4.454959174044916 | validation: 3.5260561979888156]
	TIME [epoch: 24.9 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453579455269473		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 4.453579455269473 | validation: 3.525405102304383]
	TIME [epoch: 25 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451288966347604		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 4.451288966347604 | validation: 3.5218050932161584]
	TIME [epoch: 25 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4544526981651735		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 4.4544526981651735 | validation: 3.525748687052026]
	TIME [epoch: 24.9 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453420602514137		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 4.453420602514137 | validation: 3.528506295915311]
	TIME [epoch: 25 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451941833847474		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 4.451941833847474 | validation: 3.51934562997852]
	TIME [epoch: 25 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458075374123862		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 4.458075374123862 | validation: 3.5201229573387334]
	TIME [epoch: 24.9 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456944325844924		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 4.456944325844924 | validation: 3.517382101654649]
	TIME [epoch: 25 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451374299775477		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 4.451374299775477 | validation: 3.523313960200935]
	TIME [epoch: 25 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4546378060383285		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 4.4546378060383285 | validation: 3.515882500000797]
	TIME [epoch: 24.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455883294070754		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 4.455883294070754 | validation: 3.522851182846518]
	TIME [epoch: 25 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45511183946736		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 4.45511183946736 | validation: 3.517718156436704]
	TIME [epoch: 25 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456245839649407		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 4.456245839649407 | validation: 3.5247964305167727]
	TIME [epoch: 24.9 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467769338990751		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 4.467769338990751 | validation: 3.526598750310149]
	TIME [epoch: 25 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456726955150746		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 4.456726955150746 | validation: 3.521216591259871]
	TIME [epoch: 25 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451119881982939		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 4.451119881982939 | validation: 3.524467565802464]
	TIME [epoch: 24.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4549718496773		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 4.4549718496773 | validation: 3.5175289282671494]
	TIME [epoch: 25 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454599095186333		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 4.454599095186333 | validation: 3.5218736250386793]
	TIME [epoch: 25 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452042850940613		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 4.452042850940613 | validation: 3.5207207340655144]
	TIME [epoch: 24.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455060580637728		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 4.455060580637728 | validation: 3.5160679130277006]
	TIME [epoch: 25 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453791767122096		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 4.453791767122096 | validation: 3.522917960290382]
	TIME [epoch: 25 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454039911462425		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 4.454039911462425 | validation: 3.5262344709647984]
	TIME [epoch: 24.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4556480349325955		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 4.4556480349325955 | validation: 3.525396814927608]
	TIME [epoch: 25 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451617526671661		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 4.451617526671661 | validation: 3.523658094686153]
	TIME [epoch: 25 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4552050020608975		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 4.4552050020608975 | validation: 3.523371584250693]
	TIME [epoch: 24.9 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456658624484562		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 4.456658624484562 | validation: 3.517153962605737]
	TIME [epoch: 25 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459247121460779		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 4.459247121460779 | validation: 3.528473305788136]
	TIME [epoch: 25 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456838099931599		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 4.456838099931599 | validation: 3.537641307484439]
	TIME [epoch: 25 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455253966363564		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 4.455253966363564 | validation: 3.531472142183481]
	TIME [epoch: 25.1 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.451862968402402		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 4.451862968402402 | validation: 3.535367522811898]
	TIME [epoch: 25.1 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455336544603442		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 4.455336544603442 | validation: 3.5215199869223155]
	TIME [epoch: 25 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453391280936701		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 4.453391280936701 | validation: 3.527661686253934]
	TIME [epoch: 25.1 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4546586172039095		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 4.4546586172039095 | validation: 3.5286777838654593]
	TIME [epoch: 25.1 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45510153945892		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 4.45510153945892 | validation: 3.5263052789313782]
	TIME [epoch: 25 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458172652648788		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 4.458172652648788 | validation: 3.533902564312382]
	TIME [epoch: 25 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453596685559457		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 4.453596685559457 | validation: 3.529769315942065]
	TIME [epoch: 25 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458537324145728		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 4.458537324145728 | validation: 3.527594641818662]
	TIME [epoch: 25 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45650713851404		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 4.45650713851404 | validation: 3.520793671552279]
	TIME [epoch: 25 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452563332219065		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 4.452563332219065 | validation: 3.5298097091264355]
	TIME [epoch: 25.1 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462104106013177		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 4.462104106013177 | validation: 3.5266773196343975]
	TIME [epoch: 25.1 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.455030680846267		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 4.455030680846267 | validation: 3.5240401889460053]
	TIME [epoch: 25.1 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452836797743411		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 4.452836797743411 | validation: 3.5186748469167255]
	TIME [epoch: 25.1 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456964258576943		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 4.456964258576943 | validation: 3.5292087702053494]
	TIME [epoch: 25 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458929730612699		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 4.458929730612699 | validation: 3.5218820316197292]
	TIME [epoch: 25 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452718323445922		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 4.452718323445922 | validation: 3.5249698242619285]
	TIME [epoch: 25 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457533336943476		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 4.457533336943476 | validation: 3.5265884968030123]
	TIME [epoch: 25 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4544477671562905		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 4.4544477671562905 | validation: 3.517258091819624]
	TIME [epoch: 25.1 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453995239308733		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 4.453995239308733 | validation: 3.5219264395313665]
	TIME [epoch: 25.1 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4505631264678485		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 4.4505631264678485 | validation: 3.5234731947688807]
	TIME [epoch: 25 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460060357959023		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 4.460060357959023 | validation: 3.530505972721611]
	TIME [epoch: 25 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4596523901197616		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 4.4596523901197616 | validation: 3.533883820199061]
	TIME [epoch: 25 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458069214517917		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 4.458069214517917 | validation: 3.5232557410166874]
	TIME [epoch: 25 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456268084784146		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 4.456268084784146 | validation: 3.5248180205559163]
	TIME [epoch: 25 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.460554741933686		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 4.460554741933686 | validation: 3.525007837428616]
	TIME [epoch: 25.1 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453904471040309		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 4.453904471040309 | validation: 3.5233383031668115]
	TIME [epoch: 25.2 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459612720421239		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 4.459612720421239 | validation: 3.5257044278171987]
	TIME [epoch: 25 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.456980453863869		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 4.456980453863869 | validation: 3.520315339771461]
	TIME [epoch: 25.1 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454198643988676		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 4.454198643988676 | validation: 3.531712871587134]
	TIME [epoch: 25 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.458821361279514		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 4.458821361279514 | validation: 3.520279125475212]
	TIME [epoch: 25 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461679286560727		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 4.461679286560727 | validation: 3.532808136859505]
	TIME [epoch: 25.1 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45270159567088		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 4.45270159567088 | validation: 3.521236088686623]
	TIME [epoch: 25 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453498623244254		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 4.453498623244254 | validation: 3.520077664762455]
	TIME [epoch: 25 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452477668179663		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 4.452477668179663 | validation: 3.5153557940550457]
	TIME [epoch: 25.1 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.449769210920079		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 4.449769210920079 | validation: 3.5200718756346205]
	TIME [epoch: 25.1 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453461686816047		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 4.453461686816047 | validation: 3.5260413234502783]
	TIME [epoch: 25 sec]
EPOCH 1304/2000:
	Training over batches...
