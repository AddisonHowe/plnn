Args:
Namespace(name='model_tr_study206', outdir='out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1', training_data='data/transition_rate_studies/tr_study206/tr_study206_training/r1', validation_data='data/transition_rate_studies/tr_study206/tr_study206_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1344987276

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.162771748115214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.162771748115214 | validation: 11.154522288695548]
	TIME [epoch: 110 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.01580346659949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.01580346659949 | validation: 11.925565486129171]
	TIME [epoch: 24.9 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.820578141705354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.820578141705354 | validation: 9.48654848669869]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.33222217637355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.33222217637355 | validation: 8.656059661648507]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.35770554944961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.35770554944961 | validation: 8.147014918468356]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.034142448689709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.034142448689709 | validation: 7.568450494898834]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.54471392914925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.54471392914925 | validation: 7.1554056060664335]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.24784337892159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.24784337892159 | validation: 6.710493131898488]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.318642498686513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.318642498686513 | validation: 7.229273522557754]
	TIME [epoch: 24.7 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.621108035558281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.621108035558281 | validation: 6.450883896591184]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.544095318212484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.544095318212484 | validation: 6.089935953946435]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1946472794826715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1946472794826715 | validation: 6.393797074991437]
	TIME [epoch: 24.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.20275518322651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.20275518322651 | validation: 5.825024039688194]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.843498108218837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.843498108218837 | validation: 5.668119752551362]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.570279922382426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.570279922382426 | validation: 5.572272230254387]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.751045962015578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.751045962015578 | validation: 6.832187898301929]
	TIME [epoch: 24.8 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.735171325639215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.735171325639215 | validation: 5.58542296524588]
	TIME [epoch: 24.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.374052231142041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.374052231142041 | validation: 5.607563892919484]
	TIME [epoch: 24.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2635642318662015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2635642318662015 | validation: 5.371259086845619]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.288321621779897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.288321621779897 | validation: 5.210152876717197]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0650857651078205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0650857651078205 | validation: 5.603661459280097]
	TIME [epoch: 24.8 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.192942875686802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.192942875686802 | validation: 5.697260190393372]
	TIME [epoch: 24.8 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.389408516981578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.389408516981578 | validation: 5.278114006329136]
	TIME [epoch: 24.8 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.946095724331126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.946095724331126 | validation: 5.201706099100867]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.013277310967356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.013277310967356 | validation: 5.794643013855464]
	TIME [epoch: 24.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2593805868691925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2593805868691925 | validation: 5.084517553110665]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.02464946421984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.02464946421984 | validation: 5.418258922756211]
	TIME [epoch: 24.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.077001043562717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.077001043562717 | validation: 5.639609291387772]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.112785985792671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.112785985792671 | validation: 5.155566155773768]
	TIME [epoch: 24.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.955383286963861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.955383286963861 | validation: 5.324575073156624]
	TIME [epoch: 24.9 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.85629613754977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.85629613754977 | validation: 5.056270409621403]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7760345056130955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7760345056130955 | validation: 5.056306816452669]
	TIME [epoch: 24.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.051619678436678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.051619678436678 | validation: 5.09641123338171]
	TIME [epoch: 24.8 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.703770809244049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.703770809244049 | validation: 4.695085041521393]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514582681047849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.514582681047849 | validation: 4.591769350966461]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.43025379035198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.43025379035198 | validation: 6.524808153048767]
	TIME [epoch: 24.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.086484155300438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.086484155300438 | validation: 4.910870700835185]
	TIME [epoch: 24.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.427316468650796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.427316468650796 | validation: 4.835275070285534]
	TIME [epoch: 24.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.653615830145984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.653615830145984 | validation: 4.485935415464081]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6667459649240115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6667459649240115 | validation: 5.667511435318921]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.863360187840701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.863360187840701 | validation: 7.925646298849349]
	TIME [epoch: 24.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.065965580604753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.065965580604753 | validation: 6.044800724602705]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.96006506032269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.96006506032269 | validation: 4.477923578358526]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.202992473474865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.202992473474865 | validation: 5.379557361457329]
	TIME [epoch: 24.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.723104468810052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.723104468810052 | validation: 4.6278040378859036]
	TIME [epoch: 24.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.519627803450884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.519627803450884 | validation: 5.041157661779148]
	TIME [epoch: 24.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.77894786596263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.77894786596263 | validation: 4.459128472393846]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.409161141184191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.409161141184191 | validation: 5.803829440487432]
	TIME [epoch: 24.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7979607231411165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7979607231411165 | validation: 5.2587856455849735]
	TIME [epoch: 24.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454667927443048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.454667927443048 | validation: 7.31430210566992]
	TIME [epoch: 24.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.53393455284847		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 6.53393455284847 | validation: 5.923835760666727]
	TIME [epoch: 24.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.882904811338348		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.882904811338348 | validation: 4.337182272677867]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.085948221958935		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.085948221958935 | validation: 4.179246177021126]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.530177670251056		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.530177670251056 | validation: 4.36192389595137]
	TIME [epoch: 24.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.443472791757814		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.443472791757814 | validation: 4.548678813861035]
	TIME [epoch: 24.9 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.043454452837388		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.043454452837388 | validation: 4.1883518621285685]
	TIME [epoch: 24.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.896031165521862		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.896031165521862 | validation: 4.170610920927673]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.407953000753341		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 6.407953000753341 | validation: 5.660165031897343]
	TIME [epoch: 24.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.941590894172678		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.941590894172678 | validation: 4.740693989484867]
	TIME [epoch: 24.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.307534650890077		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.307534650890077 | validation: 4.184469524091509]
	TIME [epoch: 24.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.122203904978184		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.122203904978184 | validation: 5.2120918869732105]
	TIME [epoch: 24.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.964365426398319		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.964365426398319 | validation: 4.6286391204496615]
	TIME [epoch: 24.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.125754268769057		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.125754268769057 | validation: 4.345800721334404]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.021945537819278		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.021945537819278 | validation: 4.475941376228217]
	TIME [epoch: 24.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9323621780021094		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.9323621780021094 | validation: 4.370213985894764]
	TIME [epoch: 24.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0364574113616225		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.0364574113616225 | validation: 4.172626930882592]
	TIME [epoch: 24.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.071658883670284		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.071658883670284 | validation: 4.552412824512126]
	TIME [epoch: 24.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.963799448568225		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.963799448568225 | validation: 4.051503175431754]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.087709177731901		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.087709177731901 | validation: 4.14954314303633]
	TIME [epoch: 24.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.948636509120924		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.948636509120924 | validation: 3.9259325925604514]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6507715560217906		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.6507715560217906 | validation: 4.029448645071495]
	TIME [epoch: 24.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9215505363704395		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.9215505363704395 | validation: 4.023967112139708]
	TIME [epoch: 24.9 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.764950923490217		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.764950923490217 | validation: 4.199649738747146]
	TIME [epoch: 24.9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.853539374750614		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 5.853539374750614 | validation: 4.279874446225793]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.466406665059477		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.466406665059477 | validation: 4.014263746852603]
	TIME [epoch: 24.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6766061311128375		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.6766061311128375 | validation: 4.052667471694581]
	TIME [epoch: 24.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7790504664715248		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.7790504664715248 | validation: 4.119075975856054]
	TIME [epoch: 24.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6553435216486463		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.6553435216486463 | validation: 4.253659852410319]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7086629581827357		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.7086629581827357 | validation: 3.8625502407210526]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7054989735394166		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.7054989735394166 | validation: 4.7786702403221515]
	TIME [epoch: 24.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9975543452865487		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.9975543452865487 | validation: 4.138394726713544]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.592310290309183		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.592310290309183 | validation: 3.975383356516717]
	TIME [epoch: 24.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6039787556109384		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.6039787556109384 | validation: 6.263291120797785]
	TIME [epoch: 24.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.646880475646495		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.646880475646495 | validation: 3.8170385544587404]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.095040678009814		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.095040678009814 | validation: 3.8405555106556206]
	TIME [epoch: 24.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8991155317009945		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.8991155317009945 | validation: 4.021799823445941]
	TIME [epoch: 24.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.041724790742753		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.041724790742753 | validation: 4.6035327852728924]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.963581256598164		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.963581256598164 | validation: 3.9561558435099586]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.679021817597936		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.679021817597936 | validation: 3.8948307639191837]
	TIME [epoch: 24.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.871229927814962		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.871229927814962 | validation: 3.8959067937149205]
	TIME [epoch: 24.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.239982029863514		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.239982029863514 | validation: 3.8815862220608963]
	TIME [epoch: 24.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.589298566799895		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.589298566799895 | validation: 3.7844430189406]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8592323245948434		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.8592323245948434 | validation: 4.037570051399539]
	TIME [epoch: 24.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5321852326261283		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.5321852326261283 | validation: 4.256522772754098]
	TIME [epoch: 24.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7615369945809003		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.7615369945809003 | validation: 4.349940210643197]
	TIME [epoch: 24.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6241914081137496		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.6241914081137496 | validation: 3.6788392978269355]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6091834510776186		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.6091834510776186 | validation: 3.8098107074616094]
	TIME [epoch: 24.8 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.522680431385653		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.522680431385653 | validation: 4.1015500890506615]
	TIME [epoch: 24.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.504009325512325		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.504009325512325 | validation: 3.741056547166802]
	TIME [epoch: 24.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.547863036970249		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.547863036970249 | validation: 4.057738834763154]
	TIME [epoch: 24.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5172273674780232		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.5172273674780232 | validation: 4.421332577499221]
	TIME [epoch: 24.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.895550088877577		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.895550088877577 | validation: 3.7384253009889177]
	TIME [epoch: 24.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4237998711243915		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.4237998711243915 | validation: 4.289249910657092]
	TIME [epoch: 24.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.681584792362708		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.681584792362708 | validation: 4.853022898839042]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9199488590821674		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.9199488590821674 | validation: 3.8618242327198655]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.688399059856768		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.688399059856768 | validation: 3.7437509159022295]
	TIME [epoch: 24.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6102760564120677		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.6102760564120677 | validation: 3.7348154362532284]
	TIME [epoch: 24.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.613666061618605		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.613666061618605 | validation: 3.7401835273158883]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.580245918516111		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.580245918516111 | validation: 3.8349385134213936]
	TIME [epoch: 24.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3791020098428417		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.3791020098428417 | validation: 3.67968783406768]
	TIME [epoch: 24.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7412606888602626		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.7412606888602626 | validation: 4.642203059695917]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.562802237333269		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.562802237333269 | validation: 4.461346797877851]
	TIME [epoch: 24.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9622083154997996		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.9622083154997996 | validation: 3.7547012740564254]
	TIME [epoch: 24.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8073570214068466		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.8073570214068466 | validation: 3.830141811696616]
	TIME [epoch: 24.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.357225592693256		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.357225592693256 | validation: 3.6232229494793082]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2805507155355667		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.2805507155355667 | validation: 4.163608104472181]
	TIME [epoch: 24.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.697870742056719		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.697870742056719 | validation: 3.9205022478490106]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.857199211187224		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 5.857199211187224 | validation: 4.10446301540093]
	TIME [epoch: 24.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6732614587524273		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.6732614587524273 | validation: 3.851471105204041]
	TIME [epoch: 24.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.51942233378662		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.51942233378662 | validation: 3.6540889210772183]
	TIME [epoch: 24.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4329231114454126		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.4329231114454126 | validation: 3.62523591382881]
	TIME [epoch: 24.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4906942294269716		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.4906942294269716 | validation: 3.70190963029757]
	TIME [epoch: 24.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.637265214335038		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.637265214335038 | validation: 3.8374151788692563]
	TIME [epoch: 24.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8777107764427		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.8777107764427 | validation: 3.8506484799166163]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9949359248339116		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.9949359248339116 | validation: 4.332091189793059]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7128619021932376		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.7128619021932376 | validation: 7.42456231307509]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.829415550955433		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 5.829415550955433 | validation: 5.055992880020612]
	TIME [epoch: 24.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.05150288473661		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.05150288473661 | validation: 3.7217947734927077]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3607099308149877		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.3607099308149877 | validation: 3.9877803844711766]
	TIME [epoch: 24.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4032866165617355		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.4032866165617355 | validation: 4.405264270275147]
	TIME [epoch: 24.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.729078378642942		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.729078378642942 | validation: 4.024418270322328]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.049953929855709		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 5.049953929855709 | validation: 4.3809487522688855]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.346581180505788		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.346581180505788 | validation: 3.942504052390166]
	TIME [epoch: 24.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6009092981427884		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.6009092981427884 | validation: 3.834602644772299]
	TIME [epoch: 24.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.43678399296728		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.43678399296728 | validation: 4.889301296029696]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.057715632453202		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 4.057715632453202 | validation: 3.890109854885395]
	TIME [epoch: 24.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.92075678492682		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.92075678492682 | validation: 3.7870470037078]
	TIME [epoch: 24.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.953883019164466		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.953883019164466 | validation: 3.825339618506996]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.572928560181178		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.572928560181178 | validation: 3.873378475185706]
	TIME [epoch: 24.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7139028640128107		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.7139028640128107 | validation: 4.164142298659844]
	TIME [epoch: 24.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7118742622727594		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.7118742622727594 | validation: 3.961591092540519]
	TIME [epoch: 24.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.56450095005681		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.56450095005681 | validation: 3.6987143452647433]
	TIME [epoch: 24.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3450031420817803		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.3450031420817803 | validation: 3.8907175760455055]
	TIME [epoch: 24.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3792824696355215		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.3792824696355215 | validation: 3.651047264722548]
	TIME [epoch: 24.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.579452143606011		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.579452143606011 | validation: 3.8594530861181817]
	TIME [epoch: 24.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4629847397268567		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.4629847397268567 | validation: 3.6351226785356183]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.335951093413777		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.335951093413777 | validation: 3.5509797974168853]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2939265510293456		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.2939265510293456 | validation: 3.5933301717236343]
	TIME [epoch: 24.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3405502754825394		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.3405502754825394 | validation: 3.681520413487356]
	TIME [epoch: 24.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2363935750656667		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.2363935750656667 | validation: 3.458584964193866]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5454094103925704		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.5454094103925704 | validation: 4.286724014824044]
	TIME [epoch: 24.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.400744607972447		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.400744607972447 | validation: 4.046477058487658]
	TIME [epoch: 24.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5830775845538065		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.5830775845538065 | validation: 3.6559521983541177]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.275572223680789		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.275572223680789 | validation: 3.631119161471851]
	TIME [epoch: 24.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6821497147088964		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.6821497147088964 | validation: 3.6264190867146873]
	TIME [epoch: 24.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.329086784765996		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.329086784765996 | validation: 3.5121208871106466]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2988638155860883		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.2988638155860883 | validation: 3.6915943353019025]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.237411200334306		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.237411200334306 | validation: 3.449749556831952]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2999401320294535		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.2999401320294535 | validation: 3.7397619038762526]
	TIME [epoch: 24.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.457726846404059		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.457726846404059 | validation: 3.5943233857704344]
	TIME [epoch: 24.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.192665913444503		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.192665913444503 | validation: 3.5566123102929295]
	TIME [epoch: 24.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2023603874446676		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.2023603874446676 | validation: 3.4662848965460986]
	TIME [epoch: 24.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2084655280122822		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.2084655280122822 | validation: 3.445361756569243]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1685829832189847		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.1685829832189847 | validation: 3.3210201977520217]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.715531362406237		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.715531362406237 | validation: 3.6051246193724147]
	TIME [epoch: 24.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4839363489129607		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.4839363489129607 | validation: 3.479521385457046]
	TIME [epoch: 24.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1560314777464784		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.1560314777464784 | validation: 5.1448954554098325]
	TIME [epoch: 24.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8025990393620672		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.8025990393620672 | validation: 3.7287170478643743]
	TIME [epoch: 24.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.28750115391689		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.28750115391689 | validation: 3.463414715736714]
	TIME [epoch: 24.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1234503898137933		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.1234503898137933 | validation: 3.3903868916655746]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0274730290395486		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.0274730290395486 | validation: 3.3695159548867055]
	TIME [epoch: 24.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3772036694099032		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.3772036694099032 | validation: 3.6304916280078476]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.35005621848392		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.35005621848392 | validation: 3.493041509981597]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0715902060429996		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.0715902060429996 | validation: 3.3945291055787306]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1500147157599		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.1500147157599 | validation: 3.3868331477841247]
	TIME [epoch: 24.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2378556250858397		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.2378556250858397 | validation: 3.4160898423834976]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.001598815331216		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.001598815331216 | validation: 3.3133704620739195]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1281053127868836		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.1281053127868836 | validation: 3.290786047304784]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.261961008125469		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.261961008125469 | validation: 3.9219510848744377]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3294755984830653		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.3294755984830653 | validation: 3.8632881778845114]
	TIME [epoch: 24.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.260652746264423		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 4.260652746264423 | validation: 3.6156523323581475]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.190712767386345		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.190712767386345 | validation: 3.436714340229587]
	TIME [epoch: 24.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.107743383414412		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.107743383414412 | validation: 3.4244844551766267]
	TIME [epoch: 24.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.117723990847609		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.117723990847609 | validation: 3.5596647492223785]
	TIME [epoch: 24.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2150154997426		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.2150154997426 | validation: 3.4580625431321765]
	TIME [epoch: 24.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2984431834083643		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.2984431834083643 | validation: 3.4671467227037915]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0969721636765777		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.0969721636765777 | validation: 3.3643617520999225]
	TIME [epoch: 24.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.135628368157008		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.135628368157008 | validation: 3.3412171699851685]
	TIME [epoch: 24.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9223935524273297		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.9223935524273297 | validation: 3.3677234350307548]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.020247499920664		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 4.020247499920664 | validation: 4.097939072212432]
	TIME [epoch: 24.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.822382699781924		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.822382699781924 | validation: 2.2229630874489756]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0582456165093275		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.0582456165093275 | validation: 1.6575334775683592]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3155739916338876		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.3155739916338876 | validation: 1.7570352204340787]
	TIME [epoch: 24.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2346147789998128		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.2346147789998128 | validation: 6.883700877389417]
	TIME [epoch: 24.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.102825586821086		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 7.102825586821086 | validation: 2.2037574871643097]
	TIME [epoch: 24.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8299834414352825		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.8299834414352825 | validation: 3.4217592637837333]
	TIME [epoch: 24.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4984196724309626		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.4984196724309626 | validation: 1.739632255596448]
	TIME [epoch: 24.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9822106219385516		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.9822106219385516 | validation: 2.9335942446759873]
	TIME [epoch: 24.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2909570976306717		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.2909570976306717 | validation: 2.1216401555320736]
	TIME [epoch: 24.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9118369481553894		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.9118369481553894 | validation: 1.8638335215682305]
	TIME [epoch: 24.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9935844317334257		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.9935844317334257 | validation: 2.0487310761501583]
	TIME [epoch: 24.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.20136709677902		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.20136709677902 | validation: 1.7462774224915825]
	TIME [epoch: 24.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9588072292837144		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.9588072292837144 | validation: 2.3027290430512632]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.959637108130997		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.959637108130997 | validation: 2.572149693704272]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3897220343188383		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.3897220343188383 | validation: 2.854123532439055]
	TIME [epoch: 24.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7026895188038766		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.7026895188038766 | validation: 2.7953661305271384]
	TIME [epoch: 24.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048671241460451		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.048671241460451 | validation: 1.7520335300370402]
	TIME [epoch: 24.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.022758229587162		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.022758229587162 | validation: 2.1419792681146888]
	TIME [epoch: 24.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1015919693683855		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.1015919693683855 | validation: 2.5942845542691977]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9818289515038896		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.9818289515038896 | validation: 2.612586113149571]
	TIME [epoch: 24.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.118439244910574		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.118439244910574 | validation: 2.565389426809075]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.483646230967232		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.483646230967232 | validation: 2.6977690460309565]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.167627669974963		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.167627669974963 | validation: 2.705557618276614]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.413009311618879		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.413009311618879 | validation: 2.2345211787209505]
	TIME [epoch: 24.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.917252420860868		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.917252420860868 | validation: 2.556272150619882]
	TIME [epoch: 24.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.449545689350286		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.449545689350286 | validation: 1.801397158586068]
	TIME [epoch: 24.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8111767278057043		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.8111767278057043 | validation: 1.7910934839353991]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8323065904857991		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.8323065904857991 | validation: 1.8247579885438947]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1142932037202775		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.1142932037202775 | validation: 1.7580505822604702]
	TIME [epoch: 24.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6789445988323664		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.6789445988323664 | validation: 1.4438017071431728]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6098754639252004		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.6098754639252004 | validation: 1.4779839981791012]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.515368751145507		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.515368751145507 | validation: 1.4590761654913071]
	TIME [epoch: 24.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8405654127131337		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.8405654127131337 | validation: 1.4607253161434561]
	TIME [epoch: 24.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6693215937650137		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.6693215937650137 | validation: 1.446348659352538]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5828678321680638		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.5828678321680638 | validation: 1.4079846549497754]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5928850800585612		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.5928850800585612 | validation: 1.419439635749163]
	TIME [epoch: 24.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.512519194890643		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.512519194890643 | validation: 1.3521092903218506]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6147638455368387		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.6147638455368387 | validation: 1.6691251534510902]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0919949561403075		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.0919949561403075 | validation: 2.4155560201309196]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5346199042385154		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.5346199042385154 | validation: 1.842545236020819]
	TIME [epoch: 24.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.677385714144664		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.677385714144664 | validation: 1.4656073705306187]
	TIME [epoch: 24.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7585799577796917		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.7585799577796917 | validation: 1.4078554521810256]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4496806945219747		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.4496806945219747 | validation: 1.5194997563525439]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.488748633025017		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.488748633025017 | validation: 1.2852092022736306]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4190263950197015		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.4190263950197015 | validation: 1.375112441661162]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5057812790826262		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.5057812790826262 | validation: 1.6999269945973834]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5508376141718208		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.5508376141718208 | validation: 1.6132177841187973]
	TIME [epoch: 24.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5103342146396816		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.5103342146396816 | validation: 1.241855987159924]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4084911139309957		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.4084911139309957 | validation: 1.4422528766626135]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4835728102353007		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.4835728102353007 | validation: 1.4627524721747225]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4573605651718498		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.4573605651718498 | validation: 1.2568412991679017]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3213885243576144		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.3213885243576144 | validation: 1.1735122585403068]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.269051645965786		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.269051645965786 | validation: 1.4664729036088802]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5208915451640026		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.5208915451640026 | validation: 1.4578563137050258]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.283810717018958		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.283810717018958 | validation: 1.2834490184390877]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2736810347815273		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.2736810347815273 | validation: 1.353271220769625]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2263971836358334		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.2263971836358334 | validation: 1.174092820514389]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2926570412347942		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.2926570412347942 | validation: 1.3309780209676425]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3155860037377156		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.3155860037377156 | validation: 1.2223188713853452]
	TIME [epoch: 24.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2854252222031615		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.2854252222031615 | validation: 1.0948967320294454]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.187105025167823		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.187105025167823 | validation: 1.2562951112663472]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1814816904460395		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.1814816904460395 | validation: 1.2963946627699101]
	TIME [epoch: 24.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.81560871755135		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.81560871755135 | validation: 2.489892318795227]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1571804097021583		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.1571804097021583 | validation: 1.4905655155393456]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2751787314763436		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.2751787314763436 | validation: 1.0655781994937288]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576370942763786		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.0576370942763786 | validation: 1.7945504222250555]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4166587650859135		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.4166587650859135 | validation: 1.1457875255220142]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1534358920673797		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.1534358920673797 | validation: 1.3447315989479625]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6359638808805248		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.6359638808805248 | validation: 1.9446667329707878]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6186646430219813		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.6186646430219813 | validation: 1.3179363299060254]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2545044653716855		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.2545044653716855 | validation: 1.1261288243388825]
	TIME [epoch: 24.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3832739050897191		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.3832739050897191 | validation: 1.111619516538271]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1444367550065784		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.1444367550065784 | validation: 3.98995124666474]
	TIME [epoch: 24.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7194302746656813		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.7194302746656813 | validation: 1.6064318801426134]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2034850407498197		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.2034850407498197 | validation: 1.0937110970233308]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1330449557494726		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.1330449557494726 | validation: 1.101710914856024]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405698251165506		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.1405698251165506 | validation: 1.233928088045856]
	TIME [epoch: 24.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1100086530772573		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.1100086530772573 | validation: 1.0996790799454457]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0760539365665587		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.0760539365665587 | validation: 1.1865206806638973]
	TIME [epoch: 24.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1133622790624642		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.1133622790624642 | validation: 1.0497100773597168]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0837881364638684		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.0837881364638684 | validation: 1.4006183454980772]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1835497102323378		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.1835497102323378 | validation: 1.1133721749895296]
	TIME [epoch: 24.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1024815514951956		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.1024815514951956 | validation: 1.1532411322312017]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.121520450305112		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.121520450305112 | validation: 1.1538173888019172]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0769967082091458		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.0769967082091458 | validation: 1.0202098463933076]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.190702126029446		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.190702126029446 | validation: 1.2838215834154256]
	TIME [epoch: 24.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2734884455003965		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.2734884455003965 | validation: 1.1579665763406741]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.341835512650237		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.341835512650237 | validation: 1.55231514228689]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3431700730517615		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.3431700730517615 | validation: 1.0388335442507752]
	TIME [epoch: 24.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0381551204630268		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.0381551204630268 | validation: 1.1357360026618002]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1071431944291938		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.1071431944291938 | validation: 1.1081051154778911]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0488783552609804		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.0488783552609804 | validation: 1.2908831974671082]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1776740377719621		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.1776740377719621 | validation: 1.655812326680221]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.284350230353872		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.284350230353872 | validation: 1.2238607639121415]
	TIME [epoch: 24.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0872567985870991		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.0872567985870991 | validation: 0.958752964839695]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9997956900399654		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.9997956900399654 | validation: 1.2291854269140625]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1568556637115184		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.1568556637115184 | validation: 1.179471861959179]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3520782445915707		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.3520782445915707 | validation: 1.3237896631912924]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1140078498153954		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.1140078498153954 | validation: 0.9862853832725585]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.042353281163523		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.042353281163523 | validation: 1.3208108577737787]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1060433544438943		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.1060433544438943 | validation: 1.0392691081523113]
	TIME [epoch: 24.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0497813933042175		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.0497813933042175 | validation: 1.1260839257894326]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060296528039699		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.060296528039699 | validation: 0.9517799942711759]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576181647154141		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.0576181647154141 | validation: 1.0873989073405717]
	TIME [epoch: 24.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9986375158009704		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.9986375158009704 | validation: 1.4060276728246124]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.27645971227216		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.27645971227216 | validation: 1.1353220551124483]
	TIME [epoch: 24.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0569485923160198		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.0569485923160198 | validation: 1.0985270497409783]
	TIME [epoch: 24.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624681340154587		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.0624681340154587 | validation: 0.9327792130676196]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_298.pth
	Model improved!!!
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0305229710692998		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.0305229710692998 | validation: 0.917047007709344]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0373446418527934		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.0373446418527934 | validation: 1.0218693890102242]
	TIME [epoch: 24.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2002869167698829		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.2002869167698829 | validation: 0.9733378461239918]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1526332635428296		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.1526332635428296 | validation: 1.230008218297386]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1073354057021956		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.1073354057021956 | validation: 0.9744552969410186]
	TIME [epoch: 24.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9545836193495479		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.9545836193495479 | validation: 0.9953211171374136]
	TIME [epoch: 24.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9354855480064409		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.9354855480064409 | validation: 0.9753642777877883]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9652095581015822		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.9652095581015822 | validation: 1.1615794196500122]
	TIME [epoch: 24.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9808234832512871		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.9808234832512871 | validation: 0.8710195562854971]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.005246438552003		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.005246438552003 | validation: 0.9300894518520468]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9826703270966721		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.9826703270966721 | validation: 0.8979355382753516]
	TIME [epoch: 24.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9531030803790461		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.9531030803790461 | validation: 0.9719977916045918]
	TIME [epoch: 24.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0336392110979766		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.0336392110979766 | validation: 0.8884922477144737]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9390777182549914		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.9390777182549914 | validation: 1.0552675652260504]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.941426577031921		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.941426577031921 | validation: 1.002802925627587]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9970532271266966		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.9970532271266966 | validation: 1.1107515903390988]
	TIME [epoch: 24.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9535236040893932		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.9535236040893932 | validation: 0.9476934579229654]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9271018744689744		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.9271018744689744 | validation: 0.8978062522603805]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8870467233145801		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.8870467233145801 | validation: 1.1582529742854097]
	TIME [epoch: 24.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0008720692338686		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.0008720692338686 | validation: 0.9458396283713753]
	TIME [epoch: 24.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9256390840041822		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.9256390840041822 | validation: 0.9078666840807641]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9079733668299304		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.9079733668299304 | validation: 1.0359925659806826]
	TIME [epoch: 24.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9226499662880069		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.9226499662880069 | validation: 0.8195525961497647]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9037929902353788		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.9037929902353788 | validation: 1.0742101987213257]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9224354168235416		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.9224354168235416 | validation: 0.9852230768193272]
	TIME [epoch: 24.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8968232494605195		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.8968232494605195 | validation: 0.8075745995356156]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8202661936200246		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8202661936200246 | validation: 0.8994147465283102]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.832067285029734		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.832067285029734 | validation: 1.337231042347469]
	TIME [epoch: 24.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9450718619518026		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.9450718619518026 | validation: 1.096421100465353]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9404244449908019		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9404244449908019 | validation: 0.9012170564078745]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9004173561922063		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.9004173561922063 | validation: 0.8812722350990113]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8394902163086413		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.8394902163086413 | validation: 0.9481676718436844]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8832199140734994		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.8832199140734994 | validation: 0.8449384205089412]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8635380165212665		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8635380165212665 | validation: 0.9619045804755392]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.870820628218302		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.870820628218302 | validation: 1.2660337502602756]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8879924423824017		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.8879924423824017 | validation: 0.949173933299823]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8826397445954788		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.8826397445954788 | validation: 0.7666702845685077]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8232696645784222		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.8232696645784222 | validation: 0.8301017164608433]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7794666919000709		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7794666919000709 | validation: 0.9695120236597053]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8161514952976028		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.8161514952976028 | validation: 0.8913876804949382]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7906749479820637		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.7906749479820637 | validation: 1.049010951375915]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8825185262815285		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.8825185262815285 | validation: 0.8248519070488176]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.834747582048667		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.834747582048667 | validation: 0.7619901115467262]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4258052543805602		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.4258052543805602 | validation: 0.9309258041296694]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8024234758501846		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.8024234758501846 | validation: 0.852693492933454]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8081282337079871		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.8081282337079871 | validation: 0.6825730099489248]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8319115727383617		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.8319115727383617 | validation: 0.7891208171126093]
	TIME [epoch: 24.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7518497660368029		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7518497660368029 | validation: 0.8913360220938081]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.801040294571665		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.801040294571665 | validation: 0.7744100405425549]
	TIME [epoch: 24.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7478728660785496		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.7478728660785496 | validation: 0.74144087273977]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7156139322796414		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.7156139322796414 | validation: 0.7225185944106532]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.737396750917168		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.737396750917168 | validation: 0.7025073904391737]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7613749554685803		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.7613749554685803 | validation: 1.0772994753379421]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8186099769855179		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.8186099769855179 | validation: 0.8343102795845274]
	TIME [epoch: 24.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7619346383889243		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.7619346383889243 | validation: 0.893272864010865]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8596514229263212		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.8596514229263212 | validation: 0.9068136680695971]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305218099720936		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.7305218099720936 | validation: 0.8930350745949391]
	TIME [epoch: 24.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8394852260369203		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.8394852260369203 | validation: 0.9891100640621665]
	TIME [epoch: 24.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8483218791805601		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.8483218791805601 | validation: 0.7650229264115557]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8642402746381525		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.8642402746381525 | validation: 0.9301793173879368]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7949020662711249		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.7949020662711249 | validation: 0.7679397352798316]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188776314183076		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.7188776314183076 | validation: 0.7198838272997926]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7785441729367932		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.7785441729367932 | validation: 0.9068526539107141]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.704194616928271		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.704194616928271 | validation: 0.7913411928981711]
	TIME [epoch: 24.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7472638971703998		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.7472638971703998 | validation: 0.6932112498875374]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720754129287429		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.720754129287429 | validation: 0.7128539353075607]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7378936271285159		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.7378936271285159 | validation: 0.8790887967745556]
	TIME [epoch: 24.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8749943875102664		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.8749943875102664 | validation: 0.8413036235550103]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7768976941174344		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.7768976941174344 | validation: 0.687586592137268]
	TIME [epoch: 24.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273316570250798		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.7273316570250798 | validation: 0.8719054863445967]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7392452752157228		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.7392452752157228 | validation: 1.0889199143001436]
	TIME [epoch: 24.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.797709918729908		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.797709918729908 | validation: 0.7430358103267433]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218771177394325		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.7218771177394325 | validation: 1.0825270075871438]
	TIME [epoch: 24.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8018948828140453		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.8018948828140453 | validation: 0.7213529970560754]
	TIME [epoch: 24.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036781413818357		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7036781413818357 | validation: 1.416249157762706]
	TIME [epoch: 24.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9442045746611067		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.9442045746611067 | validation: 0.7212290182144868]
	TIME [epoch: 24.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850118697313359		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.6850118697313359 | validation: 0.838505766952932]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7346246186916955		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.7346246186916955 | validation: 1.097058844231175]
	TIME [epoch: 24.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.810480681647527		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.810480681647527 | validation: 0.8617891426933671]
	TIME [epoch: 24.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.773350057518216		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.773350057518216 | validation: 0.8283496063931588]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007149093643406		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.7007149093643406 | validation: 0.7582836566318222]
	TIME [epoch: 24.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7630335848075165		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.7630335848075165 | validation: 0.9626871234760682]
	TIME [epoch: 24.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7363190653069513		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.7363190653069513 | validation: 0.7241363780142698]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6788241573654575		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.6788241573654575 | validation: 0.7335026752558792]
	TIME [epoch: 24.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6763078512813713		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.6763078512813713 | validation: 0.8317548518600062]
	TIME [epoch: 24.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7133782370324699		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.7133782370324699 | validation: 0.7661571543781807]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7334090667100426		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.7334090667100426 | validation: 0.6944972796787575]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809368317132214		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.6809368317132214 | validation: 0.7504251639434176]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731908837984781		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.731908837984781 | validation: 0.6796687031071427]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_387.pth
	Model improved!!!
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291343229820998		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.7291343229820998 | validation: 1.2298580906905614]
	TIME [epoch: 24.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8402511451523627		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.8402511451523627 | validation: 0.6545452114212872]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_389.pth
	Model improved!!!
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6545089613060571		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.6545089613060571 | validation: 0.6778554755500116]
	TIME [epoch: 24.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247272725280536		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.7247272725280536 | validation: 0.6648185121372662]
	TIME [epoch: 24.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6754878194037556		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.6754878194037556 | validation: 0.960195019706101]
	TIME [epoch: 24.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7494620200775288		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.7494620200775288 | validation: 0.7008711666063765]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7502977258314463		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7502977258314463 | validation: 0.6551936794836877]
	TIME [epoch: 24.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3678145819861884		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.3678145819861884 | validation: 0.6210164470775191]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_395.pth
	Model improved!!!
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918995884408358		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.6918995884408358 | validation: 0.6651682892448342]
	TIME [epoch: 24.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7424946846320146		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.7424946846320146 | validation: 0.7380273883688383]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657428522842699		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6657428522842699 | validation: 0.8522388899360234]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6584200343213404		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.6584200343213404 | validation: 0.6768012742628863]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7454947959145597		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.7454947959145597 | validation: 0.6283427596318852]
	TIME [epoch: 24.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582152095896131		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.582152095896131 | validation: 0.6160838479637272]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7694290594637642		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.7694290594637642 | validation: 0.9011860257200587]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7782009477515441		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.7782009477515441 | validation: 0.920258042502631]
	TIME [epoch: 24.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6703667817257609		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.6703667817257609 | validation: 1.253569758323635]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4036461794141606		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.4036461794141606 | validation: 0.8135623560619634]
	TIME [epoch: 24.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7579457662961521		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.7579457662961521 | validation: 0.9653840389672118]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7568086475360256		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.7568086475360256 | validation: 0.6290073363394535]
	TIME [epoch: 24.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6892633871564624		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.6892633871564624 | validation: 0.747775369020199]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250067133900627		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.7250067133900627 | validation: 0.6907096552237424]
	TIME [epoch: 24.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733655857931916		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.6733655857931916 | validation: 1.0376355469614353]
	TIME [epoch: 24.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7974148746742673		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.7974148746742673 | validation: 0.7758367900159141]
	TIME [epoch: 24.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6776473942545591		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.6776473942545591 | validation: 0.6630879218217866]
	TIME [epoch: 24.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589664899449446		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.6589664899449446 | validation: 0.7264469782884676]
	TIME [epoch: 24.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253176357762966		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6253176357762966 | validation: 0.8099218905766402]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8240660197476926		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.8240660197476926 | validation: 0.7687218483931862]
	TIME [epoch: 24.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6524777074899453		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.6524777074899453 | validation: 0.640415151513155]
	TIME [epoch: 24.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6196791105802693		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.6196791105802693 | validation: 0.5865661085141116]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744115551787576		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.5744115551787576 | validation: 0.6670192718189416]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6183804211137833		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.6183804211137833 | validation: 0.6523118125054841]
	TIME [epoch: 24.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6371726088089389		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.6371726088089389 | validation: 0.9093546780902786]
	TIME [epoch: 24.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8409639852743072		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.8409639852743072 | validation: 3.915313631553197]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7070129244192978		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.7070129244192978 | validation: 0.7109384099938086]
	TIME [epoch: 24.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879576644053398		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.6879576644053398 | validation: 0.641317685075476]
	TIME [epoch: 24.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6279283924954173		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.6279283924954173 | validation: 0.6043622747501677]
	TIME [epoch: 24.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955163792737311		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.5955163792737311 | validation: 0.652828045059002]
	TIME [epoch: 24.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.669083882271897		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.669083882271897 | validation: 0.6239335258146449]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6683653366251487		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.6683653366251487 | validation: 0.8789432320911823]
	TIME [epoch: 24.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7352365963769694		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.7352365963769694 | validation: 0.6396910544854894]
	TIME [epoch: 24.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6200636136512202		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.6200636136512202 | validation: 0.6879050105301586]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757333960848613		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.6757333960848613 | validation: 0.6135775004118555]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7352197345036192		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.7352197345036192 | validation: 0.7325176702436954]
	TIME [epoch: 24.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5979308095160193		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.5979308095160193 | validation: 0.6687343730268143]
	TIME [epoch: 24.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.592135260709558		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.592135260709558 | validation: 0.7763776798323586]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760049129979715		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.6760049129979715 | validation: 0.7082568793270015]
	TIME [epoch: 24.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6236978116331469		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.6236978116331469 | validation: 0.6776897419803163]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6295479575271745		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.6295479575271745 | validation: 0.6691734993176313]
	TIME [epoch: 24.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7713559972113021		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.7713559972113021 | validation: 0.6562696020762292]
	TIME [epoch: 24.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6219015143368578		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.6219015143368578 | validation: 0.7287230004857933]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.641926232667782		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.641926232667782 | validation: 0.6271829504096397]
	TIME [epoch: 24.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6088632606817772		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.6088632606817772 | validation: 0.624368810206645]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7768509658098219		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7768509658098219 | validation: 0.6396375880344823]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6322811697182812		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.6322811697182812 | validation: 0.65867953434349]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2648739566996554		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.2648739566996554 | validation: 0.9687360832535824]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6458031096526982		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.6458031096526982 | validation: 0.5737896073381361]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_444.pth
	Model improved!!!
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616753567577458		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.616753567577458 | validation: 0.5842986850809201]
	TIME [epoch: 24.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7576371841233638		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.7576371841233638 | validation: 0.9623151136424423]
	TIME [epoch: 24.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963861636585356		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.6963861636585356 | validation: 0.9737507536260387]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290241648684113		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.7290241648684113 | validation: 0.7544057813315038]
	TIME [epoch: 24.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6137075546171775		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.6137075546171775 | validation: 0.5900428452216994]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5938665949358264		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.5938665949358264 | validation: 0.5618205890533391]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6023250222280909		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.6023250222280909 | validation: 0.6381615013797731]
	TIME [epoch: 24.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7076540282475094		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.7076540282475094 | validation: 0.6815350900719713]
	TIME [epoch: 24.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927892226164271		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.6927892226164271 | validation: 0.6123204143228507]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.586841122746117		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.586841122746117 | validation: 0.60797778692041]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6325750292005421		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.6325750292005421 | validation: 0.7034536273044326]
	TIME [epoch: 24.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5643733250314249		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.5643733250314249 | validation: 0.6096106944720548]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877819790986287		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.5877819790986287 | validation: 0.7344564192925325]
	TIME [epoch: 24.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7832951167932072		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.7832951167932072 | validation: 0.880276856063563]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7540029058582853		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.7540029058582853 | validation: 0.802831646638127]
	TIME [epoch: 24.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6644221467288178		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.6644221467288178 | validation: 0.9056419165953895]
	TIME [epoch: 24.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6313524429031996		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.6313524429031996 | validation: 0.8110982320534555]
	TIME [epoch: 24.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8616572704475316		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.8616572704475316 | validation: 0.5874905049801834]
	TIME [epoch: 24.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8099985963975092		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.8099985963975092 | validation: 0.9977497215235854]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279614112129323		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.7279614112129323 | validation: 1.1442962557175536]
	TIME [epoch: 24.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8796465226525598		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.8796465226525598 | validation: 0.6396840245023789]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6021271589606589		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.6021271589606589 | validation: 0.6971296335504201]
	TIME [epoch: 24.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699766117617183		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.6699766117617183 | validation: 0.6729032716036776]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5674538959807935		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5674538959807935 | validation: 0.6682742863768898]
	TIME [epoch: 24.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7269169180874375		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.7269169180874375 | validation: 0.634188185354938]
	TIME [epoch: 24.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6038691435916643		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6038691435916643 | validation: 0.6586750923072388]
	TIME [epoch: 24.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6462217541637352		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6462217541637352 | validation: 0.6293624993889905]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5916354346986175		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.5916354346986175 | validation: 0.5969888285729191]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5562936388184603		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5562936388184603 | validation: 0.5923864137981054]
	TIME [epoch: 24.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056506685404783		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.6056506685404783 | validation: 0.6798745862105997]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878311542909531		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.6878311542909531 | validation: 0.5809417716084138]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6507947378034388		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.6507947378034388 | validation: 0.5715679478374461]
	TIME [epoch: 24.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5947458861756805		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5947458861756805 | validation: 0.5735299124074347]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063268384143731		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.063268384143731 | validation: 0.7450857520708678]
	TIME [epoch: 24.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.62312048211224		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.62312048211224 | validation: 0.6152618674299187]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5715174166543618		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.5715174166543618 | validation: 0.6146204960333282]
	TIME [epoch: 24.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5661668759318783		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5661668759318783 | validation: 0.6576378788063719]
	TIME [epoch: 24.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757324687606106		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.5757324687606106 | validation: 0.5993947151814777]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7038676466002818		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.7038676466002818 | validation: 0.6107598897025363]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5883519137096591		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5883519137096591 | validation: 0.5859803963892144]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5190161306904519		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5190161306904519 | validation: 0.6311294333439846]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5602603066609011		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.5602603066609011 | validation: 0.5453000130981328]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_486.pth
	Model improved!!!
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615324364434634		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.5615324364434634 | validation: 0.60950024375775]
	TIME [epoch: 24.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5422646329689136		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5422646329689136 | validation: 0.5801813033281282]
	TIME [epoch: 24.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5450009078928908		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.5450009078928908 | validation: 1.0935992914655426]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2058065914115854		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 2.2058065914115854 | validation: 1.7478994118000555]
	TIME [epoch: 24.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056252911575798		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.056252911575798 | validation: 0.5588210725615168]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6027195173869413		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.6027195173869413 | validation: 0.7778073047687346]
	TIME [epoch: 24.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.834307989910704		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.834307989910704 | validation: 0.5923399448787654]
	TIME [epoch: 24.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5546845966015668		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.5546845966015668 | validation: 0.5978423466580967]
	TIME [epoch: 24.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507773866313497		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.5507773866313497 | validation: 0.6031576519619791]
	TIME [epoch: 24.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5685273663379832		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.5685273663379832 | validation: 0.544426488498579]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5241656160495782		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.5241656160495782 | validation: 0.556647746501914]
	TIME [epoch: 24.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5762392166826859		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.5762392166826859 | validation: 0.5940777508954903]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374389998399255		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.6374389998399255 | validation: 1.2340053427341264]
	TIME [epoch: 24.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8230974937920205		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.8230974937920205 | validation: 0.5422887037337486]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_500.pth
	Model improved!!!
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5730180560078961		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.5730180560078961 | validation: 0.502211914710798]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49167698697012185		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.49167698697012185 | validation: 0.5323707547177177]
	TIME [epoch: 24.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446527039762576		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.5446527039762576 | validation: 0.6920116994235609]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5509551519015884		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.5509551519015884 | validation: 0.5858186220990287]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230010645129402		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.5230010645129402 | validation: 0.5404524540709763]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.525006487135547		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.525006487135547 | validation: 0.6142641209558202]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6245549893083748		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.6245549893083748 | validation: 0.6909006583595693]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086993468914157		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.6086993468914157 | validation: 0.5631759346974573]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399189701493043		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.5399189701493043 | validation: 0.639801966877433]
	TIME [epoch: 24.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5214234123866939		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.5214234123866939 | validation: 0.5273998494351948]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49085671577196804		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.49085671577196804 | validation: 0.6176239772674686]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534395051384882		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.5534395051384882 | validation: 0.500015066321387]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48672133770315795		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.48672133770315795 | validation: 0.6213814825957477]
	TIME [epoch: 24.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082938956089642		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.5082938956089642 | validation: 0.6395674299397756]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6505528963377095		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.6505528963377095 | validation: 0.5158257134031635]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5277262518938565		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.5277262518938565 | validation: 0.5520865918672911]
	TIME [epoch: 24.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48218438041716505		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.48218438041716505 | validation: 0.5757039517994403]
	TIME [epoch: 24.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5489525925651156		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.5489525925651156 | validation: 0.5660474957579458]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4993364166968016		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.4993364166968016 | validation: 0.5882784671178205]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47268475825588346		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.47268475825588346 | validation: 0.5937942246737752]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6311304450585228		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.6311304450585228 | validation: 0.6339660248642289]
	TIME [epoch: 24.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7323684264412128		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.7323684264412128 | validation: 0.5607807064792414]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4271944633778515		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.4271944633778515 | validation: 0.4998636596710391]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_523.pth
	Model improved!!!
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6154368997467147		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.6154368997467147 | validation: 0.6280129940481739]
	TIME [epoch: 24.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5487153309299333		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.5487153309299333 | validation: 0.9699833808710789]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7927097628368334		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.7927097628368334 | validation: 0.8192963737719104]
	TIME [epoch: 24.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6451322178707778		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.6451322178707778 | validation: 0.4699883525264302]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6475344382912778		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.6475344382912778 | validation: 0.6931424710174193]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5979230309072401		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.5979230309072401 | validation: 0.7537119500386557]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6295413129284781		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.6295413129284781 | validation: 0.4507969015097361]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4470913054334068		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.4470913054334068 | validation: 0.5626458642471664]
	TIME [epoch: 24.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193305126315419		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.7193305126315419 | validation: 0.5550677783274282]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7381521065683556		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.7381521065683556 | validation: 0.5946209057292429]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9113890035944703		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.9113890035944703 | validation: 0.5701744711673874]
	TIME [epoch: 24.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5129944125447341		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.5129944125447341 | validation: 0.5619410964823629]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336896291901507		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5336896291901507 | validation: 0.5450411844046253]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136745168203144		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.5136745168203144 | validation: 0.8111526762585033]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220854661668773		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.6220854661668773 | validation: 0.746222856311934]
	TIME [epoch: 24.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6308623951787582		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.6308623951787582 | validation: 0.5377542523706881]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205735519304738		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.5205735519304738 | validation: 0.6468988302357711]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5263874336781196		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.5263874336781196 | validation: 0.7341611960161731]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7025335221611702		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.7025335221611702 | validation: 0.6131920161478681]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.557418274374962		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.557418274374962 | validation: 0.7084270344441109]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585708659293023		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.5585708659293023 | validation: 0.5825770902799936]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571875480831454		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.571875480831454 | validation: 0.5134099149589936]
	TIME [epoch: 24.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5479906481181671		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.5479906481181671 | validation: 0.527877657633629]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5257059297444611		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.5257059297444611 | validation: 0.5050947358668195]
	TIME [epoch: 24.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003953022212912		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.5003953022212912 | validation: 0.635636332199581]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236028976896127		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5236028976896127 | validation: 0.5113004906228852]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688994623058742		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.7688994623058742 | validation: 0.5535745651047163]
	TIME [epoch: 24.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155541122229987		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.5155541122229987 | validation: 0.6999634873352322]
	TIME [epoch: 24.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6784762309829577		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.6784762309829577 | validation: 0.9030884758971144]
	TIME [epoch: 24.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809747950282268		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.6809747950282268 | validation: 0.5232027025140499]
	TIME [epoch: 24.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4857964185686076		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.4857964185686076 | validation: 0.550763218451246]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49648718399320746		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.49648718399320746 | validation: 0.6332382265501931]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5410402089824058		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.5410402089824058 | validation: 0.5463375166851117]
	TIME [epoch: 24.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144678120019962		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.5144678120019962 | validation: 0.5272370947616268]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5496987131443075		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.5496987131443075 | validation: 0.7929174657324112]
	TIME [epoch: 24.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231873705096345		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.6231873705096345 | validation: 0.6265849996105981]
	TIME [epoch: 24.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5816242340972537		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.5816242340972537 | validation: 0.5453075935589057]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5297013736770848		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.5297013736770848 | validation: 0.5801506017426766]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5390368263804026		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.5390368263804026 | validation: 0.560813720151158]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5835558088460915		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.5835558088460915 | validation: 0.636469436126262]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5595879540390055		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5595879540390055 | validation: 0.6887025658085141]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5723056618707807		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.5723056618707807 | validation: 0.6150275897021833]
	TIME [epoch: 24.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316998264902851		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.5316998264902851 | validation: 0.5396767410016908]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301129457638006		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5301129457638006 | validation: 0.5273574129225194]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5663250608467606		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.5663250608467606 | validation: 0.6124075094273197]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.538278643192659		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.538278643192659 | validation: 0.5332832819027432]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.570325376757499		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.570325376757499 | validation: 0.5291308784576054]
	TIME [epoch: 24.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4924010578421822		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.4924010578421822 | validation: 0.563344899923344]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5025931693331961		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.5025931693331961 | validation: 0.5691525488666708]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48901292554561493		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.48901292554561493 | validation: 0.5913243834037749]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4885961530063569		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.4885961530063569 | validation: 0.7816955055074587]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5892500234291762		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5892500234291762 | validation: 0.758560596196252]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.648398884104517		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.648398884104517 | validation: 0.5220102027031905]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518115024332593		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.518115024332593 | validation: 0.6260917355985745]
	TIME [epoch: 24.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5245490597406424		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5245490597406424 | validation: 0.6681677643317531]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5993456346060945		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.5993456346060945 | validation: 0.6732343140921538]
	TIME [epoch: 24.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571165800673884		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.571165800673884 | validation: 0.5204112447401801]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.670478483693115		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.670478483693115 | validation: 1.3165058134658556]
	TIME [epoch: 24.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0218842335291187		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.0218842335291187 | validation: 0.6181884657177852]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6906893694551118		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6906893694551118 | validation: 0.49887441487699913]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615333356312672		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.5615333356312672 | validation: 0.5086151439872587]
	TIME [epoch: 24.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4841641441109318		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.4841641441109318 | validation: 0.42998332478033957]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626186767566612		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.5626186767566612 | validation: 0.6034539100348394]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4787348242056716		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.4787348242056716 | validation: 0.4623066306493192]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346546255602376		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.5346546255602376 | validation: 0.46296865345543736]
	TIME [epoch: 24.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095834019513805		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.5095834019513805 | validation: 0.47467383556244186]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4590587990316824		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.4590587990316824 | validation: 0.6057453763246613]
	TIME [epoch: 24.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5932699113559023		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.5932699113559023 | validation: 0.5001017818681724]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5250605743336895		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.5250605743336895 | validation: 0.4462684469501988]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5991450442896437		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.5991450442896437 | validation: 0.5183738892149706]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6922076590692838		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.6922076590692838 | validation: 0.7382421788628193]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5927444091225567		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.5927444091225567 | validation: 0.5941999328592644]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49397474397394303		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.49397474397394303 | validation: 0.5228715526646189]
	TIME [epoch: 24.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6341635289009622		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.6341635289009622 | validation: 0.5029697342990019]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.480802052538092		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.480802052538092 | validation: 0.6093317431412871]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5326276941998307		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.5326276941998307 | validation: 0.5176906691384854]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46424808848135934		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.46424808848135934 | validation: 0.550435144931029]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.484182889049933		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.484182889049933 | validation: 0.5647720756930145]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.471563381277718		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.471563381277718 | validation: 0.4945777448078319]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088095974190913		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.5088095974190913 | validation: 0.5044833079522355]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4548493312966032		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.4548493312966032 | validation: 0.5979634838703728]
	TIME [epoch: 24.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8234222528922148		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.8234222528922148 | validation: 0.626423948121501]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5362294017585335		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.5362294017585335 | validation: 0.49346542930649356]
	TIME [epoch: 24.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704439470518599		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.4704439470518599 | validation: 0.544727467630555]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4776833940793265		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.4776833940793265 | validation: 0.5002465012024796]
	TIME [epoch: 24.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.543151017864938		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.543151017864938 | validation: 0.5171695143087288]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4785362588313277		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.4785362588313277 | validation: 0.5535601786118027]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4378993892428381		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.4378993892428381 | validation: 0.6081987777673917]
	TIME [epoch: 24.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5666900442150166		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.5666900442150166 | validation: 0.5525866852446074]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.441803206900879		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.441803206900879 | validation: 0.6858015557614041]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49772452723103716		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.49772452723103716 | validation: 0.5140908492830161]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46468263600178183		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.46468263600178183 | validation: 0.5437057351417717]
	TIME [epoch: 24.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6131498873750303		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.6131498873750303 | validation: 0.5675242280019326]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42531788380339713		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.42531788380339713 | validation: 0.44021985806785596]
	TIME [epoch: 24.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6012684663697916		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.6012684663697916 | validation: 0.5365579963798532]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.452564158856709		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.452564158856709 | validation: 0.6083979051092527]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4906089391307868		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.4906089391307868 | validation: 0.3899001066630433]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4872466864626219		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.4872466864626219 | validation: 0.5110417878188063]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4264793958322989		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.4264793958322989 | validation: 0.4993263865889614]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47866768623867195		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.47866768623867195 | validation: 0.6037325585372745]
	TIME [epoch: 24.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647021353112491		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.6647021353112491 | validation: 0.7208271324047324]
	TIME [epoch: 24.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46817167152973815		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.46817167152973815 | validation: 0.5513151880933838]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077920749293592		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.5077920749293592 | validation: 0.6263829730297504]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5636969231057463		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5636969231057463 | validation: 0.5135755545592668]
	TIME [epoch: 24.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518397439064749		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.518397439064749 | validation: 0.42338092116356263]
	TIME [epoch: 24.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42779456541482935		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.42779456541482935 | validation: 0.4108410053473604]
	TIME [epoch: 24.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5254360918316894		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5254360918316894 | validation: 0.7351663828681287]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4747006420254793		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.4747006420254793 | validation: 0.5579099213619904]
	TIME [epoch: 24.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4179025050964132		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.4179025050964132 | validation: 0.41405646661455486]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5341372546027761		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.5341372546027761 | validation: 0.5660370689498312]
	TIME [epoch: 24.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45633620412942894		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.45633620412942894 | validation: 0.5019792927575415]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5934792124838133		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.5934792124838133 | validation: 0.6313495050375061]
	TIME [epoch: 24.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49312697899565205		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.49312697899565205 | validation: 0.5353795125153986]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492470972567172		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.4492470972567172 | validation: 0.42752071118541224]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48200884561961366		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.48200884561961366 | validation: 0.45047031368285984]
	TIME [epoch: 24.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4186100746168374		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.4186100746168374 | validation: 0.4874150006051609]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4228724814440277		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.4228724814440277 | validation: 0.4183646496446807]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241517841506054		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.4241517841506054 | validation: 0.4298969607157012]
	TIME [epoch: 24.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40825628857840546		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.40825628857840546 | validation: 0.49897171643989213]
	TIME [epoch: 24.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511726973253308		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.511726973253308 | validation: 0.513970336326612]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679157899643593		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.4679157899643593 | validation: 0.5115871109623619]
	TIME [epoch: 24.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468105735060983		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.4468105735060983 | validation: 0.4231760011063599]
	TIME [epoch: 24.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4155126783380671		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.4155126783380671 | validation: 0.4688401227658378]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421009259927676		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.6421009259927676 | validation: 0.6575663682810325]
	TIME [epoch: 24.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.447067078541233		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.447067078541233 | validation: 0.4652833784174962]
	TIME [epoch: 24.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059327727672646		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.059327727672646 | validation: 0.3868430632694439]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_649.pth
	Model improved!!!
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42300719142437804		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.42300719142437804 | validation: 0.6145887164276601]
	TIME [epoch: 24.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4180890789177693		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.4180890789177693 | validation: 0.4757993895405215]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9307962037059263		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.9307962037059263 | validation: 0.6950607924204343]
	TIME [epoch: 24.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5480716273026893		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.5480716273026893 | validation: 0.46542953727042774]
	TIME [epoch: 24.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4002165020950783		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.4002165020950783 | validation: 0.48103234598660116]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3988149232107394		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.3988149232107394 | validation: 0.4779058082510946]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4673908825786265		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.4673908825786265 | validation: 0.4771885024620535]
	TIME [epoch: 24.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4604610177626861		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.4604610177626861 | validation: 0.4652369291957563]
	TIME [epoch: 24.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4347458301558678		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.4347458301558678 | validation: 0.647240959911531]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5259419692683563		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.5259419692683563 | validation: 0.4818056226473512]
	TIME [epoch: 24.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889599271168384		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.3889599271168384 | validation: 0.43759355556854107]
	TIME [epoch: 24.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39767090833663127		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.39767090833663127 | validation: 0.627488314935147]
	TIME [epoch: 24.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5052354319789075		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5052354319789075 | validation: 0.5197661922905147]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4685785457562531		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.4685785457562531 | validation: 0.41070747351281434]
	TIME [epoch: 24.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49985932554541423		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.49985932554541423 | validation: 0.6519139553099166]
	TIME [epoch: 24.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5342374417860458		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.5342374417860458 | validation: 0.6876466920780793]
	TIME [epoch: 24.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47921640071889743		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.47921640071889743 | validation: 0.4376734612216894]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4641475988926289		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.4641475988926289 | validation: 0.6773542294621572]
	TIME [epoch: 24.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5174540649866632		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.5174540649866632 | validation: 0.5435471859348394]
	TIME [epoch: 24.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42210023370694416		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.42210023370694416 | validation: 0.4276232678139563]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396019437240616		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.5396019437240616 | validation: 0.5413453571151469]
	TIME [epoch: 24.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5947169941266403		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5947169941266403 | validation: 0.42600782004587545]
	TIME [epoch: 24.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3970643574956214		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.3970643574956214 | validation: 0.4910412786533764]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43436651568092277		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.43436651568092277 | validation: 0.43977723323127993]
	TIME [epoch: 24.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4327543641271151		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.4327543641271151 | validation: 0.6339484597065168]
	TIME [epoch: 24.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5716748999799887		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.5716748999799887 | validation: 0.7287577057790829]
	TIME [epoch: 24.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5297657425300272		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.5297657425300272 | validation: 0.49564564973149133]
	TIME [epoch: 24.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4452883664295104		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.4452883664295104 | validation: 0.40434510302153015]
	TIME [epoch: 24.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585915897774432		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.3585915897774432 | validation: 0.38362203659328614]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_678.pth
	Model improved!!!
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.400096467856151		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.400096467856151 | validation: 0.537413491942017]
	TIME [epoch: 24.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42653644138162206		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.42653644138162206 | validation: 0.40314398977804017]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3724678119663161		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.3724678119663161 | validation: 0.40859068438005863]
	TIME [epoch: 24.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4641165623229099		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.4641165623229099 | validation: 0.7394015486160825]
	TIME [epoch: 24.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5640759675145461		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.5640759675145461 | validation: 0.44705197987007284]
	TIME [epoch: 24.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1231189370140202		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.1231189370140202 | validation: 1.0634621940414055]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8127876750025018		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.8127876750025018 | validation: 0.5131132849673423]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43236787958703266		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.43236787958703266 | validation: 0.6548846093626]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6102555985901309		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.6102555985901309 | validation: 0.36661683879243084]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_687.pth
	Model improved!!!
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4132100895837192		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.4132100895837192 | validation: 0.464137753560198]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4465458133408783		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.4465458133408783 | validation: 0.42197752708835906]
	TIME [epoch: 24.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3723911726440652		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.3723911726440652 | validation: 0.41422828504674786]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37560394706999506		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.37560394706999506 | validation: 0.5251184292331083]
	TIME [epoch: 24.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753580237848136		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.4753580237848136 | validation: 0.46046222653566743]
	TIME [epoch: 24.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.397576211817863		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.397576211817863 | validation: 0.41568214975290985]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4340329460242328		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.4340329460242328 | validation: 1.346630914527188]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7537676502946372		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.7537676502946372 | validation: 0.6808370719248501]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.545403770000447		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.545403770000447 | validation: 0.43424444313944427]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43493672998393484		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.43493672998393484 | validation: 0.8986497730430628]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461443835710758		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.6461443835710758 | validation: 0.4388704483048332]
	TIME [epoch: 24.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42312003714158286		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.42312003714158286 | validation: 0.3372164761640266]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_699.pth
	Model improved!!!
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736023197438467		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.3736023197438467 | validation: 0.9949430020187116]
	TIME [epoch: 24.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8187865285028338		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.8187865285028338 | validation: 0.3247361594922542]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_701.pth
	Model improved!!!
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4283022058338199		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.4283022058338199 | validation: 0.487882577415877]
	TIME [epoch: 24.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5422581493496701		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.5422581493496701 | validation: 0.39740287339282715]
	TIME [epoch: 24.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.399579877051839		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.399579877051839 | validation: 0.543797967101992]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4069489523110602		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.4069489523110602 | validation: 0.3570849416459572]
	TIME [epoch: 24.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4237780895387555		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.4237780895387555 | validation: 0.7214034731575216]
	TIME [epoch: 24.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344049700374488		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.6344049700374488 | validation: 0.6162771110357615]
	TIME [epoch: 24.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7544177947212474		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.7544177947212474 | validation: 0.4498162053901903]
	TIME [epoch: 24.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40433723825655976		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.40433723825655976 | validation: 0.4320894969567185]
	TIME [epoch: 24.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41580027888125454		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.41580027888125454 | validation: 0.44172439550819]
	TIME [epoch: 24.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40233375130634563		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.40233375130634563 | validation: 0.45878361379559196]
	TIME [epoch: 24.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4290487894583702		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.4290487894583702 | validation: 0.42651420538275936]
	TIME [epoch: 24.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42406940606027477		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.42406940606027477 | validation: 0.4888311116696745]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1571218459919366		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 1.1571218459919366 | validation: 0.6985980451443351]
	TIME [epoch: 24.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49409424910730254		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.49409424910730254 | validation: 0.496174838937493]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4401774930190016		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.4401774930190016 | validation: 0.3521624116730574]
	TIME [epoch: 24.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805691709392595		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.3805691709392595 | validation: 0.532994675610308]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4173593357166361		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.4173593357166361 | validation: 0.48180478541895044]
	TIME [epoch: 24.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4174713890012994		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.4174713890012994 | validation: 0.42886661652630026]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40761442429389905		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.40761442429389905 | validation: 0.3915774915846981]
	TIME [epoch: 24.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41148124422328414		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.41148124422328414 | validation: 0.47430927624904384]
	TIME [epoch: 24.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4388493985652555		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.4388493985652555 | validation: 0.5747203355754661]
	TIME [epoch: 24.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45988474820273473		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.45988474820273473 | validation: 0.4954404666356827]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6169316096724524		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.6169316096724524 | validation: 0.32519733752463753]
	TIME [epoch: 24.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3424986186935595		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.3424986186935595 | validation: 0.3610588693523711]
	TIME [epoch: 24.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43833977015477354		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.43833977015477354 | validation: 0.38008501640894965]
	TIME [epoch: 24.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6391853201686133		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.6391853201686133 | validation: 0.4033494133290608]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7372025993942558		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.7372025993942558 | validation: 0.942743184828943]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5807870147573432		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.5807870147573432 | validation: 0.518616601481583]
	TIME [epoch: 24.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44153720429431287		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.44153720429431287 | validation: 0.43434191467088423]
	TIME [epoch: 24.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569041364529116		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.4569041364529116 | validation: 0.4066911052279564]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38858909688683824		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.38858909688683824 | validation: 0.4270531234675542]
	TIME [epoch: 24.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3781916337956929		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.3781916337956929 | validation: 0.36711671557265796]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36966722324012624		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.36966722324012624 | validation: 0.3564024995810624]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.399717567457873		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.399717567457873 | validation: 1.0222070241602657]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532936674139348		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.7532936674139348 | validation: 0.5258736928101102]
	TIME [epoch: 24.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38132231153488483		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.38132231153488483 | validation: 0.2884292701395221]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_737.pth
	Model improved!!!
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37089288334905635		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.37089288334905635 | validation: 0.4450264552158215]
	TIME [epoch: 24.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31833244381466297		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.31833244381466297 | validation: 0.3401900552167186]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3640025027223572		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.3640025027223572 | validation: 0.6142327654074187]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4604995601225683		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.4604995601225683 | validation: 0.3904865769661065]
	TIME [epoch: 24.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3361130721487598		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.3361130721487598 | validation: 0.3370123181243154]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5884386412542654		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.5884386412542654 | validation: 0.4700810371074819]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47655928516826784		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.47655928516826784 | validation: 0.5762545960796785]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4716394426302626		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.4716394426302626 | validation: 0.3643259902732732]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36657890875571386		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.36657890875571386 | validation: 0.31783830745049096]
	TIME [epoch: 24.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4181369761118853		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.4181369761118853 | validation: 0.3397385415137194]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555890123488411		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.3555890123488411 | validation: 0.45199694658622824]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35796040264405415		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.35796040264405415 | validation: 0.3161539009560974]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4212711652259181		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.4212711652259181 | validation: 0.31997041417812677]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3393046104394487		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.3393046104394487 | validation: 0.4145658227534992]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737822681485746		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.3737822681485746 | validation: 0.3640183720643328]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36424724664472674		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.36424724664472674 | validation: 0.3949419841751802]
	TIME [epoch: 24.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.461821788270772		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.461821788270772 | validation: 1.0595229379592475]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.728966514946324		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.728966514946324 | validation: 0.4821352286743888]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40820179213619334		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.40820179213619334 | validation: 0.4486559971310483]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40233893810494814		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.40233893810494814 | validation: 0.4588759041313253]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3853422522250986		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.3853422522250986 | validation: 0.5911617894415275]
	TIME [epoch: 24.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4568613840145166		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4568613840145166 | validation: 0.4601478790895874]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41242287541064626		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.41242287541064626 | validation: 0.43974604320706945]
	TIME [epoch: 24.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4596642352019076		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.4596642352019076 | validation: 0.4071722406793529]
	TIME [epoch: 24.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5699380390676815		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.5699380390676815 | validation: 0.6345701294840618]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4710287166308299		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.4710287166308299 | validation: 0.4697932517927518]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4063732728751708		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.4063732728751708 | validation: 0.377316526087855]
	TIME [epoch: 24.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3871924369849504		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.3871924369849504 | validation: 0.38199066146648675]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44604102804298207		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.44604102804298207 | validation: 0.5068536361003771]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46648862735526103		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.46648862735526103 | validation: 0.6243201071273181]
	TIME [epoch: 24.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48632255971622984		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.48632255971622984 | validation: 0.5247895951693677]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4482865746757555		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.4482865746757555 | validation: 0.48474923116051843]
	TIME [epoch: 24.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4021825774370373		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.4021825774370373 | validation: 0.42872171753825683]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4481925028117335		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.4481925028117335 | validation: 0.5607313747501328]
	TIME [epoch: 24.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4473279807626962		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.4473279807626962 | validation: 0.32739833102566396]
	TIME [epoch: 24.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3693260580116725		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.3693260580116725 | validation: 0.45430443083710714]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3750598908506555		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.3750598908506555 | validation: 0.41290474767832336]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3755232895160475		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.3755232895160475 | validation: 0.37453100009726537]
	TIME [epoch: 24.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42469657692671764		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.42469657692671764 | validation: 0.5220352284943265]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37976994541106157		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.37976994541106157 | validation: 0.4404262596710197]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925288909180724		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.3925288909180724 | validation: 0.4787565239300568]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938337473139141		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.3938337473139141 | validation: 0.5206886838194281]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4259852981718584		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.4259852981718584 | validation: 0.3924726109069712]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3728180070903096		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.3728180070903096 | validation: 0.38690702885143785]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3645841137019224		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.3645841137019224 | validation: 0.400443093822167]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3292173404759137		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.3292173404759137 | validation: 0.43581784515569255]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117452609251423		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.5117452609251423 | validation: 0.7192046177452812]
	TIME [epoch: 24.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46958298488493244		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.46958298488493244 | validation: 0.37306962811284317]
	TIME [epoch: 24.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4083796509685441		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.4083796509685441 | validation: 0.4084373973590259]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3954751551579002		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.3954751551579002 | validation: 0.48642728922537304]
	TIME [epoch: 24.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990043071799201		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.3990043071799201 | validation: 0.3943712870351429]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39626787078327086		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.39626787078327086 | validation: 0.39893069623028204]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3761122606766065		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.3761122606766065 | validation: 0.4245578496105118]
	TIME [epoch: 24.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46120960334920125		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.46120960334920125 | validation: 0.6445023721547135]
	TIME [epoch: 24.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4252725124945793		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.4252725124945793 | validation: 0.32716440456273577]
	TIME [epoch: 24.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129484026981758		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.4129484026981758 | validation: 0.3640441537208776]
	TIME [epoch: 24.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4499682003561477		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.4499682003561477 | validation: 0.4545601295286757]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5397919098124657		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.5397919098124657 | validation: 0.41228527815184707]
	TIME [epoch: 24.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683884812119447		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.3683884812119447 | validation: 0.3950749610535276]
	TIME [epoch: 24.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500168499456905		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.4500168499456905 | validation: 0.4138343628716366]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389431809423058		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.389431809423058 | validation: 0.3557777152002232]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36159998008251526		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.36159998008251526 | validation: 0.4368402224604991]
	TIME [epoch: 24.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36472153613559377		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.36472153613559377 | validation: 0.3271593834271376]
	TIME [epoch: 24.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3365335134013936		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.3365335134013936 | validation: 0.3484779698043112]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34567703892000357		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.34567703892000357 | validation: 0.37353745489605217]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3399393758056882		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.3399393758056882 | validation: 0.3143229243684671]
	TIME [epoch: 24.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435714390371127		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.3435714390371127 | validation: 0.3249604464901803]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.669086216333344		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.669086216333344 | validation: 0.3009344652780237]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145017748177465		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.5145017748177465 | validation: 0.3394459110096112]
	TIME [epoch: 24.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3257140602622392		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.3257140602622392 | validation: 0.2658812088087731]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_807.pth
	Model improved!!!
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3060904266212316		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.3060904266212316 | validation: 0.28596463751837387]
	TIME [epoch: 24.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3657127937714663		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.3657127937714663 | validation: 0.3221585153660375]
	TIME [epoch: 24.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36538136689218004		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.36538136689218004 | validation: 0.37184219005571506]
	TIME [epoch: 24.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3201166507591787		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.3201166507591787 | validation: 0.2997031038144018]
	TIME [epoch: 24.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3241649523352075		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.3241649523352075 | validation: 0.25991360538631986]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_812.pth
	Model improved!!!
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5045121282631306		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.5045121282631306 | validation: 0.5260698294979477]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39216448208642546		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.39216448208642546 | validation: 0.2948033235748305]
	TIME [epoch: 24.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40880632337184886		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.40880632337184886 | validation: 0.3536285651348611]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.599993967575199		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.599993967575199 | validation: 0.5290918230303759]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5359464319811779		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.5359464319811779 | validation: 0.3549894560046935]
	TIME [epoch: 24.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3616090284283706		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.3616090284283706 | validation: 0.33346977581253795]
	TIME [epoch: 24.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468419471514237		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.3468419471514237 | validation: 0.314565957540154]
	TIME [epoch: 24.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.309717224745103		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.309717224745103 | validation: 0.5316020576788015]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41914611343882435		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.41914611343882435 | validation: 0.32754133551441955]
	TIME [epoch: 24.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4012393331137014		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.4012393331137014 | validation: 0.3877903540321118]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316761952061988		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.3316761952061988 | validation: 0.42641187064954805]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44663100122486177		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.44663100122486177 | validation: 0.557101984361984]
	TIME [epoch: 24.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43996805838944364		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.43996805838944364 | validation: 0.41083413802808033]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3627786719802647		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.3627786719802647 | validation: 0.4169768587891106]
	TIME [epoch: 24.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918169420663853		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.3918169420663853 | validation: 0.3860525867486449]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49828793685213235		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.49828793685213235 | validation: 0.3333320855202803]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33419263604975574		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.33419263604975574 | validation: 0.3686669588050793]
	TIME [epoch: 24.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42005555646263054		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.42005555646263054 | validation: 0.3547992293419484]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49003828144464695		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.49003828144464695 | validation: 0.33814496300528235]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3191808380284223		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.3191808380284223 | validation: 0.35047450575930067]
	TIME [epoch: 24.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31368101288462		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.31368101288462 | validation: 0.44436894169595365]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4775495883517308		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.4775495883517308 | validation: 0.4320833434810858]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37016688771110523		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.37016688771110523 | validation: 0.39800370118465267]
	TIME [epoch: 24.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3975775239418402		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.3975775239418402 | validation: 0.530035137021143]
	TIME [epoch: 24.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47513949059805727		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.47513949059805727 | validation: 0.5107433938396402]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38089050763630206		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.38089050763630206 | validation: 0.41226471500229717]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3666591170840495		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.3666591170840495 | validation: 0.401431816712343]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33677692920306834		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.33677692920306834 | validation: 0.3328536032256437]
	TIME [epoch: 24.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3105337762891451		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.3105337762891451 | validation: 0.3258845874543948]
	TIME [epoch: 24.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363843986105863		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.363843986105863 | validation: 0.3639584401716602]
	TIME [epoch: 24.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31052762729752886		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.31052762729752886 | validation: 0.33880323057086914]
	TIME [epoch: 24.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32511140842592867		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.32511140842592867 | validation: 0.44728151692515705]
	TIME [epoch: 24.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4241848052332243		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.4241848052332243 | validation: 0.6467108723098489]
	TIME [epoch: 24.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5274482588103422		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.5274482588103422 | validation: 0.4398761811790783]
	TIME [epoch: 24.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33309741703597234		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.33309741703597234 | validation: 0.2932484935049367]
	TIME [epoch: 24.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3855287795066688		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.3855287795066688 | validation: 0.36045877873547283]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702132967084029		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.3702132967084029 | validation: 0.3238694526502451]
	TIME [epoch: 24.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30987494510831554		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.30987494510831554 | validation: 0.33354649881644505]
	TIME [epoch: 24.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35659988734791315		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.35659988734791315 | validation: 0.31343190367270707]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312305117736127		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.3312305117736127 | validation: 0.26184605689484863]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32464944514284805		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.32464944514284805 | validation: 0.24896441539161696]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_853.pth
	Model improved!!!
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330488375924088		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.330488375924088 | validation: 0.2585552990748256]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30025126527096646		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.30025126527096646 | validation: 0.34573306362679973]
	TIME [epoch: 24.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39631691129363256		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.39631691129363256 | validation: 0.35640594686069]
	TIME [epoch: 24.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3400779680612817		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.3400779680612817 | validation: 0.4096293592565528]
	TIME [epoch: 24.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295648713806535		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.3295648713806535 | validation: 0.42261819278340435]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5588061302027829		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.5588061302027829 | validation: 0.42696242134534224]
	TIME [epoch: 24.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.339276863380225		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.339276863380225 | validation: 0.2896459156176264]
	TIME [epoch: 24.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33357880423519587		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.33357880423519587 | validation: 0.3692419402133521]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38134290206964166		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.38134290206964166 | validation: 0.32258757252310494]
	TIME [epoch: 24.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48234964237938194		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.48234964237938194 | validation: 0.7922508772928493]
	TIME [epoch: 24.7 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46745828596596406		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.46745828596596406 | validation: 0.3117643075779917]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3075860036101342		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.3075860036101342 | validation: 0.29439069738061613]
	TIME [epoch: 24.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3803299122597068		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.3803299122597068 | validation: 0.39812350712436173]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32053660145016316		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.32053660145016316 | validation: 0.43989457966900786]
	TIME [epoch: 24.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34421183579490433		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.34421183579490433 | validation: 0.32209519266255926]
	TIME [epoch: 24.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3939926171399456		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.3939926171399456 | validation: 0.3598454818930414]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45437888241580904		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.45437888241580904 | validation: 0.3187521818159499]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31078001558027535		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.31078001558027535 | validation: 0.3135247820393281]
	TIME [epoch: 24.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141981821987069		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.3141981821987069 | validation: 0.42367258833451177]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805949441555462		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.3805949441555462 | validation: 0.3687744461767876]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32048895555707213		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.32048895555707213 | validation: 0.33783966575445135]
	TIME [epoch: 24.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844413469427842		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.3844413469427842 | validation: 0.30975788480389677]
	TIME [epoch: 24.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37552313663253545		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.37552313663253545 | validation: 0.3495814174908221]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.348707100915259		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.348707100915259 | validation: 0.3810073975744939]
	TIME [epoch: 24.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352540884307015		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.352540884307015 | validation: 0.5339959503249838]
	TIME [epoch: 24.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41677112203815503		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.41677112203815503 | validation: 0.41693453989063783]
	TIME [epoch: 24.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36231654052230416		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.36231654052230416 | validation: 0.38662132641648994]
	TIME [epoch: 24.8 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31942204006838576		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.31942204006838576 | validation: 0.34761391171822636]
	TIME [epoch: 24.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282630223395914		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.282630223395914 | validation: 0.28466055186990635]
	TIME [epoch: 24.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33691508549915494		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.33691508549915494 | validation: 0.3277404253890694]
	TIME [epoch: 24.8 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36507774837355983		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.36507774837355983 | validation: 0.3889509842208897]
	TIME [epoch: 24.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3094638987838079		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.3094638987838079 | validation: 0.34116682818633015]
	TIME [epoch: 24.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36364007420285405		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.36364007420285405 | validation: 0.6184568845523635]
	TIME [epoch: 24.8 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4362491116001335		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.4362491116001335 | validation: 0.39662469408498624]
	TIME [epoch: 24.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36696760387700095		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.36696760387700095 | validation: 0.3586155760834649]
	TIME [epoch: 24.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2961996425690649		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.2961996425690649 | validation: 0.2810371660261364]
	TIME [epoch: 24.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489838677061925		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.3489838677061925 | validation: 0.29782212097756416]
	TIME [epoch: 24.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30925163060888533		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.30925163060888533 | validation: 0.383035583663497]
	TIME [epoch: 24.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33056214823261354		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.33056214823261354 | validation: 0.29334796860878054]
	TIME [epoch: 24.8 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28198691674733223		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.28198691674733223 | validation: 0.3948080461953426]
	TIME [epoch: 24.8 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32763586319503263		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.32763586319503263 | validation: 0.29907855823427715]
	TIME [epoch: 24.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977296626768262		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.2977296626768262 | validation: 0.3633022185380484]
	TIME [epoch: 24.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569529578551165		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.4569529578551165 | validation: 0.26946350490162335]
	TIME [epoch: 24.8 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3710106298395532		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.3710106298395532 | validation: 0.33633908863701223]
	TIME [epoch: 24.8 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33553836161489403		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.33553836161489403 | validation: 0.26723454659022616]
	TIME [epoch: 24.8 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35207142726699325		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.35207142726699325 | validation: 0.21175615377661275]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_899.pth
	Model improved!!!
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2698417033434058		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.2698417033434058 | validation: 0.2324699214606666]
	TIME [epoch: 24.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27774908419937056		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.27774908419937056 | validation: 0.4428595277782719]
	TIME [epoch: 24.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3158195021345987		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.3158195021345987 | validation: 0.43625670235852226]
	TIME [epoch: 24.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6503593215117076		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.6503593215117076 | validation: 0.34034498748265435]
	TIME [epoch: 24.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34360749889723075		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.34360749889723075 | validation: 0.25075445253321027]
	TIME [epoch: 24.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2469024735058351		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.2469024735058351 | validation: 0.2845306828120205]
	TIME [epoch: 24.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2836317612746652		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.2836317612746652 | validation: 0.23172546164676264]
	TIME [epoch: 24.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.320367155738336		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.320367155738336 | validation: 0.3229544609677462]
	TIME [epoch: 24.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518325294395819		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.3518325294395819 | validation: 0.30136030064702235]
	TIME [epoch: 24.9 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32877812830974795		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.32877812830974795 | validation: 0.2478480394462331]
	TIME [epoch: 24.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268829669715711		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.268829669715711 | validation: 0.23591184142075097]
	TIME [epoch: 24.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2398653681836292		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.2398653681836292 | validation: 0.23686423950414187]
	TIME [epoch: 24.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785372601530598		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.2785372601530598 | validation: 0.27522497465920004]
	TIME [epoch: 24.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251520593545418		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.251520593545418 | validation: 0.2417056968016727]
	TIME [epoch: 24.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686028189431561		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.2686028189431561 | validation: 0.35250991261724374]
	TIME [epoch: 24.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377478584842605		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.5377478584842605 | validation: 0.32479867451704125]
	TIME [epoch: 24.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4388240304333674		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.4388240304333674 | validation: 0.22370552603360336]
	TIME [epoch: 24.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22799464057207441		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.22799464057207441 | validation: 0.2135877497105536]
	TIME [epoch: 24.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651560053822543		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.2651560053822543 | validation: 0.2409948363081003]
	TIME [epoch: 24.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33536185730398455		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.33536185730398455 | validation: 0.611082730666935]
	TIME [epoch: 24.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38472409832542254		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.38472409832542254 | validation: 0.21422518423145448]
	TIME [epoch: 24.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23400968899939434		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.23400968899939434 | validation: 0.2836649682724054]
	TIME [epoch: 24.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33873360375675177		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.33873360375675177 | validation: 0.2366637544209069]
	TIME [epoch: 24.8 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28495792246375207		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.28495792246375207 | validation: 0.3292391772572432]
	TIME [epoch: 24.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36829787930431446		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.36829787930431446 | validation: 0.48188789081078287]
	TIME [epoch: 24.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983922746193819		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.3983922746193819 | validation: 0.45928823410984637]
	TIME [epoch: 24.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3285061533906922		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.3285061533906922 | validation: 0.3510142065984489]
	TIME [epoch: 24.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3218313903634354		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.3218313903634354 | validation: 0.2855740875995756]
	TIME [epoch: 24.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3096148853938195		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.3096148853938195 | validation: 0.31761471239267375]
	TIME [epoch: 24.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28646521064658537		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.28646521064658537 | validation: 0.2821477208212897]
	TIME [epoch: 24.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666009255239104		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.2666009255239104 | validation: 0.3175329175840574]
	TIME [epoch: 24.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29257118330470433		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.29257118330470433 | validation: 0.29056212546415666]
	TIME [epoch: 24.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2973074948259014		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.2973074948259014 | validation: 0.2926711870647746]
	TIME [epoch: 24.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3419178208072074		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.3419178208072074 | validation: 0.3584342722392481]
	TIME [epoch: 24.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943307446552741		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.2943307446552741 | validation: 0.27772053498138255]
	TIME [epoch: 24.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2819597696277815		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.2819597696277815 | validation: 0.3673527798641058]
	TIME [epoch: 24.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37059991906425804		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.37059991906425804 | validation: 0.23659964095272298]
	TIME [epoch: 24.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591184015249409		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.2591184015249409 | validation: 0.2839008799000621]
	TIME [epoch: 24.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26268051103877665		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.26268051103877665 | validation: 0.2864239979698222]
	TIME [epoch: 24.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2615132012460941		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.2615132012460941 | validation: 0.24232899507431818]
	TIME [epoch: 24.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658514635907364		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.2658514635907364 | validation: 0.3511240873361877]
	TIME [epoch: 24.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189379009278899		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.7189379009278899 | validation: 0.20666268174167932]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_941.pth
	Model improved!!!
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26706373321249255		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.26706373321249255 | validation: 0.22985098186553907]
	TIME [epoch: 24.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5755263879735136		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.5755263879735136 | validation: 0.27430510768837196]
	TIME [epoch: 24.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32927502356626615		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.32927502356626615 | validation: 0.2304701684117663]
	TIME [epoch: 24.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24550565540617564		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.24550565540617564 | validation: 0.22753346928366003]
	TIME [epoch: 24.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29473291168428684		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.29473291168428684 | validation: 0.27579074851052204]
	TIME [epoch: 24.7 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2777976924373887		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.2777976924373887 | validation: 0.19632902701775293]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_947.pth
	Model improved!!!
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2317220334223482		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.2317220334223482 | validation: 0.18406547437380055]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_948.pth
	Model improved!!!
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21424895995403245		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.21424895995403245 | validation: 0.39209485434411107]
	TIME [epoch: 24.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687901016366801		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.687901016366801 | validation: 0.41862589312563453]
	TIME [epoch: 24.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4091836398942402		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.4091836398942402 | validation: 0.4164412321257363]
	TIME [epoch: 24.8 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694236571862358		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.3694236571862358 | validation: 0.7007785627703289]
	TIME [epoch: 24.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4458283547351184		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.4458283547351184 | validation: 0.3364031861979187]
	TIME [epoch: 24.8 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695245534303673		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.3695245534303673 | validation: 0.32951588595065223]
	TIME [epoch: 24.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31767806338174176		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.31767806338174176 | validation: 0.2550411428049842]
	TIME [epoch: 24.7 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40611908967239285		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.40611908967239285 | validation: 0.2333934456506057]
	TIME [epoch: 24.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336403053953467		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.3336403053953467 | validation: 0.517929206130346]
	TIME [epoch: 24.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43035439622058724		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.43035439622058724 | validation: 0.2173815215994415]
	TIME [epoch: 24.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897789536813929		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.2897789536813929 | validation: 0.24318950404063763]
	TIME [epoch: 24.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757711082060032		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.3757711082060032 | validation: 0.2374747170664566]
	TIME [epoch: 24.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35394566945915396		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.35394566945915396 | validation: 0.2342429403781948]
	TIME [epoch: 24.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931301550244917		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.2931301550244917 | validation: 0.3353378655078963]
	TIME [epoch: 24.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26516625464251375		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.26516625464251375 | validation: 0.2398086902209051]
	TIME [epoch: 24.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23639092716023283		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.23639092716023283 | validation: 0.24059781689505666]
	TIME [epoch: 24.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23142163575430283		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.23142163575430283 | validation: 0.19549814974127244]
	TIME [epoch: 24.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24854474756639477		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.24854474756639477 | validation: 0.42953622463425334]
	TIME [epoch: 24.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30838814971649764		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.30838814971649764 | validation: 0.21731875769421563]
	TIME [epoch: 24.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24952202256129352		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.24952202256129352 | validation: 0.19817630970154113]
	TIME [epoch: 24.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33480182658725244		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.33480182658725244 | validation: 0.19654066272538573]
	TIME [epoch: 24.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26336428247278576		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.26336428247278576 | validation: 0.19557035401001188]
	TIME [epoch: 24.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23513873880258093		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.23513873880258093 | validation: 0.39160813641536124]
	TIME [epoch: 24.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28745875290180634		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.28745875290180634 | validation: 0.273261320740795]
	TIME [epoch: 24.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4575609724559963		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.4575609724559963 | validation: 0.23028836903313932]
	TIME [epoch: 24.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595354227733033		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.2595354227733033 | validation: 0.2436240215778828]
	TIME [epoch: 24.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26474020586507285		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.26474020586507285 | validation: 0.2663733371571497]
	TIME [epoch: 24.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.265889702927333		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.265889702927333 | validation: 0.23595669936118197]
	TIME [epoch: 24.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512647685474363		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.2512647685474363 | validation: 0.2984326163701296]
	TIME [epoch: 24.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24246834272289788		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.24246834272289788 | validation: 0.2170121989679899]
	TIME [epoch: 24.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439483883884895		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.3439483883884895 | validation: 0.2176873871377559]
	TIME [epoch: 24.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24596287668486722		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.24596287668486722 | validation: 0.20914433188115447]
	TIME [epoch: 24.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2265860281062706		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.2265860281062706 | validation: 0.23633106762186523]
	TIME [epoch: 24.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846319580078448		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.2846319580078448 | validation: 0.27697267877786497]
	TIME [epoch: 24.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254489133484796		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.254489133484796 | validation: 0.20582516681142257]
	TIME [epoch: 24.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23685031717801824		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.23685031717801824 | validation: 0.3524184870361347]
	TIME [epoch: 24.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3473983481914703		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.3473983481914703 | validation: 0.3245432557202616]
	TIME [epoch: 24.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533231857577517		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.2533231857577517 | validation: 0.2404428042502718]
	TIME [epoch: 24.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868075954627502		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.2868075954627502 | validation: 0.2311104508397214]
	TIME [epoch: 24.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2309895373018408		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.2309895373018408 | validation: 0.2551654315805969]
	TIME [epoch: 24.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681667432773653		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.2681667432773653 | validation: 0.49250924626183085]
	TIME [epoch: 24.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39849459234060897		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.39849459234060897 | validation: 0.21345478506130036]
	TIME [epoch: 24.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23154814991871506		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.23154814991871506 | validation: 0.23789810752004378]
	TIME [epoch: 24.8 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28804467425337466		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.28804467425337466 | validation: 0.22812871068663015]
	TIME [epoch: 24.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2418760205358614		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.2418760205358614 | validation: 0.19551321775614852]
	TIME [epoch: 24.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28176156452419676		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.28176156452419676 | validation: 0.25062211707331555]
	TIME [epoch: 24.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33654415764233114		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.33654415764233114 | validation: 0.4683941742190801]
	TIME [epoch: 24.8 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7420514196272843		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.7420514196272843 | validation: 0.20810471211242706]
	TIME [epoch: 24.8 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2984326200940878		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.2984326200940878 | validation: 0.3570336001495093]
	TIME [epoch: 24.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35830572125641147		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.35830572125641147 | validation: 0.3489029525382303]
	TIME [epoch: 24.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26993851210298947		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.26993851210298947 | validation: 0.22289768818607755]
	TIME [epoch: 24.8 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23018099479431994		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.23018099479431994 | validation: 0.24831033565145652]
	TIME [epoch: 24.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28637621201172286		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.28637621201172286 | validation: 0.38763468774371157]
	TIME [epoch: 24.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33201133210721334		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.33201133210721334 | validation: 0.28698577721932333]
	TIME [epoch: 24.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26438713032268224		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.26438713032268224 | validation: 0.29975035107482717]
	TIME [epoch: 24.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771629211928885		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.2771629211928885 | validation: 0.27800371303977767]
	TIME [epoch: 24.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748729428354954		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.2748729428354954 | validation: 0.3179205811899933]
	TIME [epoch: 24.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077365687562434		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.5077365687562434 | validation: 0.1980559639221906]
	TIME [epoch: 24.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2954424408705536		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.2954424408705536 | validation: 0.43174325709117845]
	TIME [epoch: 24.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36706281350752995		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.36706281350752995 | validation: 0.23573986365450175]
	TIME [epoch: 24.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533482060121885		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.2533482060121885 | validation: 0.26313633215133914]
	TIME [epoch: 24.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25138482842228904		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.25138482842228904 | validation: 0.22622958522719547]
	TIME [epoch: 24.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23575617524885262		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.23575617524885262 | validation: 0.19537553321800463]
	TIME [epoch: 24.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22192151670796667		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.22192151670796667 | validation: 0.19551304936167524]
	TIME [epoch: 24.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22766206950369572		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.22766206950369572 | validation: 0.37809405375651567]
	TIME [epoch: 24.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2884962432467685		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.2884962432467685 | validation: 0.23885003661518234]
	TIME [epoch: 24.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578593391606987		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.2578593391606987 | validation: 0.19634775386822312]
	TIME [epoch: 24.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22122905815716126		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.22122905815716126 | validation: 0.25791105290311317]
	TIME [epoch: 24.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28658575993172664		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.28658575993172664 | validation: 0.5103525311401176]
	TIME [epoch: 24.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33294754775396923		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.33294754775396923 | validation: 0.22768417414541145]
	TIME [epoch: 24.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23436233262310757		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.23436233262310757 | validation: 0.22283566460899804]
	TIME [epoch: 24.8 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29798887165600507		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.29798887165600507 | validation: 0.3481748763297914]
	TIME [epoch: 24.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28897328356785495		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.28897328356785495 | validation: 0.2836781318046757]
	TIME [epoch: 24.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2577934471016917		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.2577934471016917 | validation: 0.2266088784447531]
	TIME [epoch: 24.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592242346228137		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.2592242346228137 | validation: 0.24158666242193824]
	TIME [epoch: 24.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30683461579765703		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.30683461579765703 | validation: 0.593241546516974]
	TIME [epoch: 24.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4680837702518912		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.4680837702518912 | validation: 0.39540167779239854]
	TIME [epoch: 24.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3660183169024031		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.3660183169024031 | validation: 0.469070850001158]
	TIME [epoch: 24.8 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470084090312433		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.3470084090312433 | validation: 0.3429027552603668]
	TIME [epoch: 24.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3047776607567399		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.3047776607567399 | validation: 0.402001438968449]
	TIME [epoch: 24.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3494011570365225		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.3494011570365225 | validation: 0.30048043393485324]
	TIME [epoch: 24.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30670980041262164		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.30670980041262164 | validation: 0.3638668364887822]
	TIME [epoch: 24.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3166021805640427		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.3166021805640427 | validation: 0.3289614920529765]
	TIME [epoch: 24.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29805299286042997		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.29805299286042997 | validation: 0.3166319481043234]
	TIME [epoch: 24.8 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088290051752951		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.3088290051752951 | validation: 0.28612989343363937]
	TIME [epoch: 24.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27614900799362796		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.27614900799362796 | validation: 0.2817048764100053]
	TIME [epoch: 24.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24961481175968642		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.24961481175968642 | validation: 0.34650763777871135]
	TIME [epoch: 24.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37061979391258737		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.37061979391258737 | validation: 0.4547313007115615]
	TIME [epoch: 24.8 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34484884764004564		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.34484884764004564 | validation: 0.2326474787159026]
	TIME [epoch: 24.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2685602595215333		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.2685602595215333 | validation: 0.27844433619215603]
	TIME [epoch: 24.8 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703659811614403		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.2703659811614403 | validation: 0.23777133464210154]
	TIME [epoch: 24.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2684585674509708		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.2684585674509708 | validation: 0.2677228181914425]
	TIME [epoch: 24.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23961341932516445		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.23961341932516445 | validation: 0.22843934390078272]
	TIME [epoch: 24.8 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22019933950633633		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.22019933950633633 | validation: 0.23192426040133898]
	TIME [epoch: 24.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23256325732240593		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.23256325732240593 | validation: 0.20459434023142972]
	TIME [epoch: 24.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24044535948433285		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.24044535948433285 | validation: 0.2264785717549463]
	TIME [epoch: 24.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24481067190008615		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.24481067190008615 | validation: 0.2542630613533053]
	TIME [epoch: 24.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26410710948782823		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.26410710948782823 | validation: 0.33859455915053616]
	TIME [epoch: 24.8 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2817203541375345		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.2817203541375345 | validation: 0.2151250458175871]
	TIME [epoch: 24.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2235414214358719		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.2235414214358719 | validation: 0.25317096598321553]
	TIME [epoch: 24.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3048393014634403		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.3048393014634403 | validation: 0.28869974584175845]
	TIME [epoch: 24.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25323965465600995		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.25323965465600995 | validation: 0.2367250375118731]
	TIME [epoch: 24.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24553349045437722		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.24553349045437722 | validation: 0.24948027604077538]
	TIME [epoch: 24.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23411314206928546		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.23411314206928546 | validation: 0.27339932384724974]
	TIME [epoch: 24.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3526520871532536		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.3526520871532536 | validation: 0.2374227077984675]
	TIME [epoch: 24.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2323487605779142		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.2323487605779142 | validation: 0.2517113811815642]
	TIME [epoch: 24.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.225517430143848		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.225517430143848 | validation: 0.2360888954764144]
	TIME [epoch: 24.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25469855577428024		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.25469855577428024 | validation: 0.21733183268918893]
	TIME [epoch: 24.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21613833564079413		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.21613833564079413 | validation: 0.2416493557601821]
	TIME [epoch: 24.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22715144147323527		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.22715144147323527 | validation: 0.2484956259595235]
	TIME [epoch: 24.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26248348623710377		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.26248348623710377 | validation: 0.38458188700242263]
	TIME [epoch: 24.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778190228956946		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.2778190228956946 | validation: 0.1861341936479396]
	TIME [epoch: 24.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2188528861675631		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.2188528861675631 | validation: 0.21146571863218933]
	TIME [epoch: 24.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2536392841466556		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.2536392841466556 | validation: 0.28223265914488466]
	TIME [epoch: 24.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22370071398416588		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.22370071398416588 | validation: 0.19565427542320848]
	TIME [epoch: 24.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2161694879205021		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.2161694879205021 | validation: 0.2051190377964214]
	TIME [epoch: 24.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219634071036649		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.219634071036649 | validation: 0.24311509021783792]
	TIME [epoch: 24.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25097689070347107		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.25097689070347107 | validation: 0.3171401952615144]
	TIME [epoch: 24.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2541776699230498		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.2541776699230498 | validation: 0.2575504301797785]
	TIME [epoch: 24.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23064467920464823		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.23064467920464823 | validation: 0.22227792320536538]
	TIME [epoch: 24.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21017931083287855		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.21017931083287855 | validation: 0.22763098227956874]
	TIME [epoch: 24.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2398346230270591		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.2398346230270591 | validation: 0.23794592866857336]
	TIME [epoch: 24.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2161326348478145		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.2161326348478145 | validation: 0.2062886770922764]
	TIME [epoch: 24.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21799970331024823		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.21799970331024823 | validation: 0.24325304779803117]
	TIME [epoch: 24.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23348438750410946		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.23348438750410946 | validation: 0.23901121812523762]
	TIME [epoch: 24.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22679418607813345		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.22679418607813345 | validation: 0.2234827269046459]
	TIME [epoch: 24.8 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22525173010732397		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.22525173010732397 | validation: 0.32388199406542056]
	TIME [epoch: 24.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2649784539783337		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.2649784539783337 | validation: 0.22874912149510082]
	TIME [epoch: 24.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2362660965712028		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.2362660965712028 | validation: 0.2448231933870819]
	TIME [epoch: 24.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509623615253156		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.2509623615253156 | validation: 0.2954727954603888]
	TIME [epoch: 24.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24211535548170696		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.24211535548170696 | validation: 0.22506141022911366]
	TIME [epoch: 24.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24991691340965627		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.24991691340965627 | validation: 0.2881986221528356]
	TIME [epoch: 24.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.239733169305481		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.239733169305481 | validation: 0.22659531596978785]
	TIME [epoch: 24.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2404520636093825		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.2404520636093825 | validation: 0.2110517571113475]
	TIME [epoch: 24.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2151872794863386		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.2151872794863386 | validation: 0.30280742827607854]
	TIME [epoch: 24.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2424765597888882		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.2424765597888882 | validation: 0.21897532480262194]
	TIME [epoch: 24.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2030685110910161		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.2030685110910161 | validation: 0.2819112799746937]
	TIME [epoch: 24.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32080412208175646		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.32080412208175646 | validation: 0.29804538140139886]
	TIME [epoch: 24.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2448276876534069		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.2448276876534069 | validation: 0.2279812484922153]
	TIME [epoch: 24.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23039658167798624		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.23039658167798624 | validation: 0.20568574183720276]
	TIME [epoch: 24.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2096825298281161		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.2096825298281161 | validation: 0.20087020832217256]
	TIME [epoch: 24.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20607627553478033		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.20607627553478033 | validation: 0.19117700845808705]
	TIME [epoch: 24.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31699938905718134		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.31699938905718134 | validation: 0.4440525310740351]
	TIME [epoch: 24.8 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33195828860056054		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.33195828860056054 | validation: 0.1987544089031561]
	TIME [epoch: 24.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21881746159842133		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.21881746159842133 | validation: 0.2699667458584659]
	TIME [epoch: 24.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524083351332148		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.2524083351332148 | validation: 0.26800300156313195]
	TIME [epoch: 24.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2638175075845875		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.2638175075845875 | validation: 0.2700975834478872]
	TIME [epoch: 24.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23583337575151742		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.23583337575151742 | validation: 0.20789634456760056]
	TIME [epoch: 24.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21456270068593364		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.21456270068593364 | validation: 0.22589175112585336]
	TIME [epoch: 24.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2625990519649979		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.2625990519649979 | validation: 0.26799943933216447]
	TIME [epoch: 24.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29939449373907395		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.29939449373907395 | validation: 0.42515264959469096]
	TIME [epoch: 24.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34942165214141546		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.34942165214141546 | validation: 0.31295054332324607]
	TIME [epoch: 24.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23351064878064073		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.23351064878064073 | validation: 0.21525853470374276]
	TIME [epoch: 24.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23910039976678663		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.23910039976678663 | validation: 0.22804301836412452]
	TIME [epoch: 24.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22461114775357144		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.22461114775357144 | validation: 0.2218788014498568]
	TIME [epoch: 24.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22620233697407952		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.22620233697407952 | validation: 0.2190848318824556]
	TIME [epoch: 24.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20821985016069275		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.20821985016069275 | validation: 0.21470909578194497]
	TIME [epoch: 24.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23234037859868734		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.23234037859868734 | validation: 0.2636097623296496]
	TIME [epoch: 24.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2431587129773693		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.2431587129773693 | validation: 0.2833881197430902]
	TIME [epoch: 24.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3001901521577065		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.3001901521577065 | validation: 0.22482351967587466]
	TIME [epoch: 24.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139887089153839		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.2139887089153839 | validation: 0.22730512592486815]
	TIME [epoch: 24.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20410941856026743		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.20410941856026743 | validation: 0.2054823197201625]
	TIME [epoch: 24.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20048500554328702		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.20048500554328702 | validation: 0.196279677309347]
	TIME [epoch: 24.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2282384935555321		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.2282384935555321 | validation: 0.3423196017949988]
	TIME [epoch: 24.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39193491958350435		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.39193491958350435 | validation: 0.3316365974925216]
	TIME [epoch: 24.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26407428725047327		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.26407428725047327 | validation: 0.32139470628784367]
	TIME [epoch: 24.8 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24247968477210435		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.24247968477210435 | validation: 0.2546303678972126]
	TIME [epoch: 24.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558633504809442		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.2558633504809442 | validation: 0.2897087176679888]
	TIME [epoch: 24.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402672008208158		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.3402672008208158 | validation: 0.28363608901810156]
	TIME [epoch: 24.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25772531495811174		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.25772531495811174 | validation: 0.20540200180936247]
	TIME [epoch: 24.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24834788748823783		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.24834788748823783 | validation: 0.30177411112672653]
	TIME [epoch: 24.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22908799985530848		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.22908799985530848 | validation: 0.19866469581147952]
	TIME [epoch: 24.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21268699716530579		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.21268699716530579 | validation: 0.25509574967769927]
	TIME [epoch: 24.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24158730347781987		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.24158730347781987 | validation: 0.2469897748076631]
	TIME [epoch: 24.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219733245148958		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.219733245148958 | validation: 0.21700461849042058]
	TIME [epoch: 24.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22308218087402065		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.22308218087402065 | validation: 0.2068606472318051]
	TIME [epoch: 24.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209435870192404		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.2209435870192404 | validation: 0.19422490342835252]
	TIME [epoch: 24.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26984815764124576		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.26984815764124576 | validation: 0.40124519012777515]
	TIME [epoch: 24.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3396016208680245		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.3396016208680245 | validation: 0.3028861515659987]
	TIME [epoch: 24.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515646319622281		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.2515646319622281 | validation: 0.26718140032161813]
	TIME [epoch: 24.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.262406350959053		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.262406350959053 | validation: 0.22116049832152976]
	TIME [epoch: 24.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34382886808630686		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.34382886808630686 | validation: 0.7172672768671182]
	TIME [epoch: 24.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6633702642318002		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.6633702642318002 | validation: 0.19653397770654288]
	TIME [epoch: 24.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2451452366569411		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.2451452366569411 | validation: 0.24229693549547962]
	TIME [epoch: 24.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21241380941536248		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.21241380941536248 | validation: 0.33169868110038137]
	TIME [epoch: 24.8 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31337708494337635		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.31337708494337635 | validation: 0.25065756731438105]
	TIME [epoch: 24.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2295599131013852		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.2295599131013852 | validation: 0.22530377246789932]
	TIME [epoch: 24.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22037682724241633		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.22037682724241633 | validation: 0.2949806294402361]
	TIME [epoch: 24.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25868111237556307		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.25868111237556307 | validation: 0.22116400499769068]
	TIME [epoch: 24.8 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31691991652990315		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.31691991652990315 | validation: 0.3368101652939061]
	TIME [epoch: 24.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30394386707704835		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.30394386707704835 | validation: 0.25108301730524557]
	TIME [epoch: 24.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24016277341678163		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.24016277341678163 | validation: 0.24046076976089964]
	TIME [epoch: 24.8 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22525524163205868		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.22525524163205868 | validation: 0.2365741014329248]
	TIME [epoch: 24.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.224783132793984		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.224783132793984 | validation: 0.23798700141255025]
	TIME [epoch: 24.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.218660168808049		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.218660168808049 | validation: 0.2119772093428589]
	TIME [epoch: 24.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21769055596870682		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.21769055596870682 | validation: 0.22765952781972612]
	TIME [epoch: 24.8 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20877506792528427		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.20877506792528427 | validation: 0.1987175172252664]
	TIME [epoch: 24.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24475108211270813		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.24475108211270813 | validation: 0.24437820970699178]
	TIME [epoch: 24.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22430123995740228		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.22430123995740228 | validation: 0.21043323678495043]
	TIME [epoch: 24.8 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.213659559872148		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.213659559872148 | validation: 0.20502754216730004]
	TIME [epoch: 24.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20121187303520885		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.20121187303520885 | validation: 0.1871556293773684]
	TIME [epoch: 24.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18218286668308525		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.18218286668308525 | validation: 0.17934489212446902]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_1150.pth
	Model improved!!!
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1951434975929654		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.1951434975929654 | validation: 0.1887714316996042]
	TIME [epoch: 24.8 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25858732587615796		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.25858732587615796 | validation: 0.3452598951843217]
	TIME [epoch: 24.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2716920618144905		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.2716920618144905 | validation: 0.24151607630676655]
	TIME [epoch: 24.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24389688660735184		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.24389688660735184 | validation: 0.2066317250755425]
	TIME [epoch: 24.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21915315650103556		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.21915315650103556 | validation: 0.20380319299028316]
	TIME [epoch: 24.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2359419444483176		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.2359419444483176 | validation: 0.29046584190021035]
	TIME [epoch: 24.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25558917420921823		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.25558917420921823 | validation: 0.2128405116162547]
	TIME [epoch: 24.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199650138886435		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.2199650138886435 | validation: 0.19877391344144207]
	TIME [epoch: 24.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21915243634827927		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.21915243634827927 | validation: 0.23528368032282032]
	TIME [epoch: 24.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22777730736319965		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.22777730736319965 | validation: 0.26398260658786066]
	TIME [epoch: 24.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27098338125022975		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.27098338125022975 | validation: 0.3132386209280335]
	TIME [epoch: 24.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29502678240108504		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.29502678240108504 | validation: 0.26772099276738887]
	TIME [epoch: 24.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25616110745310705		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.25616110745310705 | validation: 0.28121882467103504]
	TIME [epoch: 24.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2404149724944339		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.2404149724944339 | validation: 0.25880043653814544]
	TIME [epoch: 24.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24203576176475994		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.24203576176475994 | validation: 0.22928661114045817]
	TIME [epoch: 24.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2594699683087499		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.2594699683087499 | validation: 0.3069782569036999]
	TIME [epoch: 24.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2450531412033376		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.2450531412033376 | validation: 0.2327248734444917]
	TIME [epoch: 24.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2539931398220326		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.2539931398220326 | validation: 0.36889606595699986]
	TIME [epoch: 24.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31685140393016437		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.31685140393016437 | validation: 0.38220516689758527]
	TIME [epoch: 24.8 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3152156243986144		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.3152156243986144 | validation: 0.2821817504408363]
	TIME [epoch: 24.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771606427368448		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.2771606427368448 | validation: 0.2724838598232307]
	TIME [epoch: 24.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251036006145465		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.251036006145465 | validation: 0.2628748721841264]
	TIME [epoch: 24.8 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761075706287559		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.2761075706287559 | validation: 0.2784115532938833]
	TIME [epoch: 24.8 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25965624822720385		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.25965624822720385 | validation: 0.23434671693462128]
	TIME [epoch: 24.8 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24629318176906556		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.24629318176906556 | validation: 0.2501242914796653]
	TIME [epoch: 24.8 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23924194409340088		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.23924194409340088 | validation: 0.23329614180031727]
	TIME [epoch: 24.8 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21398260425017135		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.21398260425017135 | validation: 0.21194618193044235]
	TIME [epoch: 24.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20552171279038214		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.20552171279038214 | validation: 0.2240373252793333]
	TIME [epoch: 24.8 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21507036049285563		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.21507036049285563 | validation: 0.21630415935127306]
	TIME [epoch: 24.8 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2927030015958967		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.2927030015958967 | validation: 0.29241493781638705]
	TIME [epoch: 24.8 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22459886874028898		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.22459886874028898 | validation: 0.20552563307950933]
	TIME [epoch: 24.8 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2632133158051562		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.2632133158051562 | validation: 0.46232672394042806]
	TIME [epoch: 24.8 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39378473320840435		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.39378473320840435 | validation: 0.23841946631929592]
	TIME [epoch: 24.8 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21246030653319617		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.21246030653319617 | validation: 0.2026012595812689]
	TIME [epoch: 24.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18980686292031093		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.18980686292031093 | validation: 0.19768251903496353]
	TIME [epoch: 24.8 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19410432480966205		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.19410432480966205 | validation: 0.18715492628467614]
	TIME [epoch: 24.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912266931563469		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.1912266931563469 | validation: 0.1733063390979929]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_1187.pth
	Model improved!!!
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20847499632020927		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.20847499632020927 | validation: 0.24174308286314958]
	TIME [epoch: 24.7 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35236019870534796		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.35236019870534796 | validation: 0.21936537974053605]
	TIME [epoch: 24.7 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21357832947326946		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.21357832947326946 | validation: 0.18148318769017743]
	TIME [epoch: 24.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19055600035307402		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.19055600035307402 | validation: 0.2535764106208753]
	TIME [epoch: 24.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694313628841232		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.2694313628841232 | validation: 0.19417872099889727]
	TIME [epoch: 24.7 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19556395114340364		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.19556395114340364 | validation: 0.18009402365615138]
	TIME [epoch: 24.8 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2328961101344128		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.2328961101344128 | validation: 0.3831562171960453]
	TIME [epoch: 24.8 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38105813409954564		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.38105813409954564 | validation: 0.29631751362512987]
	TIME [epoch: 24.8 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24765568996134601		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.24765568996134601 | validation: 0.22983285718483917]
	TIME [epoch: 24.8 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2020959938324621		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.2020959938324621 | validation: 0.1877413327916098]
	TIME [epoch: 24.8 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18474604170136633		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.18474604170136633 | validation: 0.23698692262679646]
	TIME [epoch: 24.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2556517739108012		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.2556517739108012 | validation: 0.21295412145823217]
	TIME [epoch: 24.8 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2133404251399798		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.2133404251399798 | validation: 0.24717777236345775]
	TIME [epoch: 24.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931300566718361		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.2931300566718361 | validation: 0.3052181538920194]
	TIME [epoch: 24.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23166763917082397		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.23166763917082397 | validation: 0.22548171639736672]
	TIME [epoch: 24.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27636113425463465		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.27636113425463465 | validation: 0.20004206586182882]
	TIME [epoch: 24.7 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19087615816999332		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.19087615816999332 | validation: 0.1978993207421486]
	TIME [epoch: 24.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19980710252860498		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.19980710252860498 | validation: 0.19157764185650508]
	TIME [epoch: 24.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20928121853289672		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.20928121853289672 | validation: 0.20811678532275274]
	TIME [epoch: 24.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21054680642990448		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.21054680642990448 | validation: 0.2014158463454127]
	TIME [epoch: 24.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2472987320345929		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.2472987320345929 | validation: 0.300839589229849]
	TIME [epoch: 24.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834095984969265		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.2834095984969265 | validation: 0.18333790954284063]
	TIME [epoch: 24.7 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18165262942565247		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.18165262942565247 | validation: 0.16322084273337048]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_1210.pth
	Model improved!!!
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17500329575932547		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.17500329575932547 | validation: 0.23330150244163797]
	TIME [epoch: 24.8 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30251276636721547		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.30251276636721547 | validation: 0.21735898619608704]
	TIME [epoch: 24.8 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1863979976731863		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.1863979976731863 | validation: 0.1840429354362248]
	TIME [epoch: 24.7 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19528588538027156		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.19528588538027156 | validation: 0.16382246413203475]
	TIME [epoch: 24.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766608781305461		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.1766608781305461 | validation: 0.1671673845246114]
	TIME [epoch: 24.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1876921599792843		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.1876921599792843 | validation: 0.2557053531351695]
	TIME [epoch: 24.7 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26063177304974916		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.26063177304974916 | validation: 0.21654584264913546]
	TIME [epoch: 24.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20801335711935656		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.20801335711935656 | validation: 0.16919363005652038]
	TIME [epoch: 24.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22106551460725216		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.22106551460725216 | validation: 0.27217448229508245]
	TIME [epoch: 24.7 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23096023339268745		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.23096023339268745 | validation: 0.24779616707553273]
	TIME [epoch: 24.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23324397637893918		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.23324397637893918 | validation: 0.2594594556605443]
	TIME [epoch: 24.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35017698880249654		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.35017698880249654 | validation: 0.1654068333943257]
	TIME [epoch: 24.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20827472926109855		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.20827472926109855 | validation: 0.1680633273551113]
	TIME [epoch: 24.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17588236589657044		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.17588236589657044 | validation: 0.1600575022512581]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_1224.pth
	Model improved!!!
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19862395457374454		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.19862395457374454 | validation: 0.20073431351831147]
	TIME [epoch: 24.8 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733972941347969		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.2733972941347969 | validation: 0.2077851772047218]
	TIME [epoch: 24.8 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19064626102130633		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.19064626102130633 | validation: 0.22973094584365236]
	TIME [epoch: 24.8 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19347516164798023		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.19347516164798023 | validation: 0.16135191150518402]
	TIME [epoch: 25.9 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1928816201644102		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.1928816201644102 | validation: 0.16715159322504028]
	TIME [epoch: 24.8 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1700704711519745		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.1700704711519745 | validation: 0.16140065178659285]
	TIME [epoch: 24.8 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3082560005848617		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.3082560005848617 | validation: 0.2235204571218509]
	TIME [epoch: 24.8 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22088081863372455		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.22088081863372455 | validation: 0.16495863281225695]
	TIME [epoch: 24.8 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20672294943749384		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.20672294943749384 | validation: 0.17234721953064772]
	TIME [epoch: 24.8 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17972298486290036		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.17972298486290036 | validation: 0.1888331811919103]
	TIME [epoch: 24.8 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1863860157340474		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.1863860157340474 | validation: 0.16148242919158987]
	TIME [epoch: 24.8 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18452713406288607		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.18452713406288607 | validation: 0.15508948684848842]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_1236.pth
	Model improved!!!
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1908868821117387		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.1908868821117387 | validation: 0.15754755837911133]
	TIME [epoch: 24.8 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16987185665847637		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.16987185665847637 | validation: 0.13724806888753302]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_1238.pth
	Model improved!!!
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17081282717457164		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.17081282717457164 | validation: 0.16495921471867422]
	TIME [epoch: 24.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17576176434560054		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.17576176434560054 | validation: 0.15882493904616493]
	TIME [epoch: 24.8 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20121706035985226		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.20121706035985226 | validation: 0.15234451819860317]
	TIME [epoch: 24.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17803515644238455		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.17803515644238455 | validation: 0.2460224839449274]
	TIME [epoch: 24.8 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26203368843364083		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.26203368843364083 | validation: 0.3193318994472634]
	TIME [epoch: 24.8 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25265144643484105		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.25265144643484105 | validation: 0.17652032452548924]
	TIME [epoch: 24.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1813639759918589		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.1813639759918589 | validation: 0.1708160445049453]
	TIME [epoch: 24.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1777781315635653		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.1777781315635653 | validation: 0.15277626746332815]
	TIME [epoch: 24.8 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18058809871915452		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.18058809871915452 | validation: 0.17422373958284773]
	TIME [epoch: 24.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16593703819709474		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.16593703819709474 | validation: 0.15107351017380893]
	TIME [epoch: 24.8 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19815324621489783		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.19815324621489783 | validation: 0.2270201743760358]
	TIME [epoch: 24.8 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200168303305385		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.200168303305385 | validation: 0.187359291215303]
	TIME [epoch: 24.8 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1764222467767128		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.1764222467767128 | validation: 0.1563877731135783]
	TIME [epoch: 24.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17101469107009948		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.17101469107009948 | validation: 0.18306507202004071]
	TIME [epoch: 24.8 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909290707317755		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.1909290707317755 | validation: 0.17220927179509773]
	TIME [epoch: 24.8 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17412537312494578		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.17412537312494578 | validation: 0.1583237444643581]
	TIME [epoch: 24.8 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15961127845255157		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.15961127845255157 | validation: 0.14558451674862627]
	TIME [epoch: 24.8 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646111261440028		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.1646111261440028 | validation: 0.17625447017643808]
	TIME [epoch: 24.8 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18797531358803637		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.18797531358803637 | validation: 0.17313948138019952]
	TIME [epoch: 24.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17817960765230523		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.17817960765230523 | validation: 0.15574143638733276]
	TIME [epoch: 24.8 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18517258811161647		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.18517258811161647 | validation: 0.17004155386167655]
	TIME [epoch: 24.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709621798984895		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.2709621798984895 | validation: 0.1985031183349299]
	TIME [epoch: 24.8 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20931233914133002		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.20931233914133002 | validation: 0.13635606559572783]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_1261.pth
	Model improved!!!
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18322403522141475		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.18322403522141475 | validation: 0.25389541328834947]
	TIME [epoch: 24.8 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24139823672202737		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.24139823672202737 | validation: 0.15591618574975039]
	TIME [epoch: 24.8 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1869697238131915		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.1869697238131915 | validation: 0.198321270519808]
	TIME [epoch: 24.8 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18061266803398124		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.18061266803398124 | validation: 0.16866847378856462]
	TIME [epoch: 24.8 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16629205697856148		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.16629205697856148 | validation: 0.16278999171831765]
	TIME [epoch: 24.8 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1989700831507413		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.1989700831507413 | validation: 0.20044317185353236]
	TIME [epoch: 24.8 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871001858437401		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.1871001858437401 | validation: 0.16460913673905128]
	TIME [epoch: 24.8 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17764184458843624		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.17764184458843624 | validation: 0.17977240916466383]
	TIME [epoch: 24.8 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21230935857421956		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.21230935857421956 | validation: 0.2508815027510531]
	TIME [epoch: 24.8 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28399347347119985		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.28399347347119985 | validation: 0.3346585036849725]
	TIME [epoch: 24.8 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773792628641748		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.2773792628641748 | validation: 0.21524468568982558]
	TIME [epoch: 24.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19791084594366473		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.19791084594366473 | validation: 0.19468566341436067]
	TIME [epoch: 24.8 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1848650502905566		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.1848650502905566 | validation: 0.1689037916934144]
	TIME [epoch: 24.8 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18064190291897117		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.18064190291897117 | validation: 0.19909424498008108]
	TIME [epoch: 24.8 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840886216340787		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.1840886216340787 | validation: 0.15939628105852321]
	TIME [epoch: 24.8 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1749931913701419		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.1749931913701419 | validation: 0.16866878509171415]
	TIME [epoch: 24.8 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1710635955766898		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.1710635955766898 | validation: 0.16027134888233913]
	TIME [epoch: 24.8 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16497903587478477		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.16497903587478477 | validation: 0.18445522814580226]
	TIME [epoch: 24.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.176783551473695		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.176783551473695 | validation: 0.15205720385293103]
	TIME [epoch: 24.8 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19723727870245164		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.19723727870245164 | validation: 0.16303666746868536]
	TIME [epoch: 24.8 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17968868935008014		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.17968868935008014 | validation: 0.16752288397542398]
	TIME [epoch: 24.8 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621663203815491		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.1621663203815491 | validation: 0.15634572784048728]
	TIME [epoch: 24.8 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16555520776914023		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.16555520776914023 | validation: 0.20103952045039086]
	TIME [epoch: 24.8 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22027871767790047		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.22027871767790047 | validation: 0.17796819127925978]
	TIME [epoch: 24.8 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17190884350799535		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.17190884350799535 | validation: 0.14978917471656444]
	TIME [epoch: 24.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16778833342812338		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.16778833342812338 | validation: 0.14696193895053736]
	TIME [epoch: 24.8 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18031230542607232		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.18031230542607232 | validation: 0.17359332871173971]
	TIME [epoch: 24.8 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18001182885872652		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.18001182885872652 | validation: 0.14266790216795605]
	TIME [epoch: 24.8 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16507608998486256		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.16507608998486256 | validation: 0.15348672517053677]
	TIME [epoch: 24.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17533556427580255		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.17533556427580255 | validation: 0.189177765141817]
	TIME [epoch: 24.8 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18772038980314276		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.18772038980314276 | validation: 0.19379597855173264]
	TIME [epoch: 24.8 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17193123767810536		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.17193123767810536 | validation: 0.17569501513384572]
	TIME [epoch: 24.8 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18964262164225443		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.18964262164225443 | validation: 0.1617424804198793]
	TIME [epoch: 24.8 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1672186082839522		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.1672186082839522 | validation: 0.16860925744955718]
	TIME [epoch: 24.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17370260054829648		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.17370260054829648 | validation: 0.1580333684248288]
	TIME [epoch: 24.8 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16057663828625243		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.16057663828625243 | validation: 0.1476045413093651]
	TIME [epoch: 24.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1641447315744499		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.1641447315744499 | validation: 0.1419672659510571]
	TIME [epoch: 24.8 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1693213441252172		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.1693213441252172 | validation: 0.17186225846959302]
	TIME [epoch: 24.8 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747879389945623		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.1747879389945623 | validation: 0.17473651196721687]
	TIME [epoch: 24.8 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19532022995950685		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.19532022995950685 | validation: 0.14477457247491804]
	TIME [epoch: 24.8 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15969837798770592		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.15969837798770592 | validation: 0.15752595243481823]
	TIME [epoch: 24.8 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18920993671036823		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.18920993671036823 | validation: 0.13206639237909543]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study206/model_tr_study206_r1_20240310_055840/states/model_tr_study206_1303.pth
	Model improved!!!
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16193746616948215		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.16193746616948215 | validation: 0.1483018232995469]
	TIME [epoch: 24.8 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17821903394205627		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.17821903394205627 | validation: 0.16303490634037854]
	TIME [epoch: 24.8 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16377690378223242		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.16377690378223242 | validation: 0.16221317760907744]
	TIME [epoch: 24.8 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125448895699857		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.2125448895699857 | validation: 0.2567882819197247]
	TIME [epoch: 24.8 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20049750895393764		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.20049750895393764 | validation: 0.18644309835780631]
	TIME [epoch: 24.8 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21499151730783334		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.21499151730783334 | validation: 0.1539533518828715]
	TIME [epoch: 24.8 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18610207283096988		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.18610207283096988 | validation: 0.16190355735674167]
	TIME [epoch: 24.8 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16845927691463433		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.16845927691463433 | validation: 0.14447258793203469]
	TIME [epoch: 24.8 sec]
EPOCH 1312/2000:
	Training over batches...
