Args:
Namespace(name='model_tr_study203', outdir='out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5', training_data='data/transition_rate_studies/tr_study203/tr_study203_training/r5', validation_data='data/transition_rate_studies/tr_study203/tr_study203_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1332766258

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.134674514774098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.134674514774098 | validation: 13.097712694309084]
	TIME [epoch: 97.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.880361613106647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.880361613106647 | validation: 12.894470637145144]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.724731482332333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.724731482332333 | validation: 13.470982392944416]
	TIME [epoch: 11.5 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.09094471295686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.09094471295686 | validation: 10.647059180915084]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.36017807845075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.36017807845075 | validation: 8.966823315597642]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.070500482057119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.070500482057119 | validation: 7.219944377364075]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.109510785792041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.109510785792041 | validation: 8.771154909928233]
	TIME [epoch: 11.6 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.766730019962932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.766730019962932 | validation: 5.721814005971405]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.358536741334252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.358536741334252 | validation: 5.704635599008655]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.9062677362456455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.9062677362456455 | validation: 5.404230614177306]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.0143697105059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0143697105059 | validation: 5.081089284169767]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.798089705513746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.798089705513746 | validation: 6.046086705139328]
	TIME [epoch: 11.6 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.579230261245124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.579230261245124 | validation: 4.698458684191875]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.137384832553503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.137384832553503 | validation: 4.62099003784819]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2151855330420185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2151855330420185 | validation: 4.617294096959641]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.068296422730354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.068296422730354 | validation: 4.593855673696836]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.199766770552872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.199766770552872 | validation: 5.1827717304275]
	TIME [epoch: 11.6 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.102731688376034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.102731688376034 | validation: 4.320137694556406]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.971950154669047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.971950154669047 | validation: 5.063298748468119]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7697428352873015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7697428352873015 | validation: 4.261497227287931]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.54354954552086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.54354954552086 | validation: 4.219515676855067]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.569729002221559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.569729002221559 | validation: 5.862163292959387]
	TIME [epoch: 11.6 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.80084642057809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.80084642057809 | validation: 3.9968022352277157]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.396623007535986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.396623007535986 | validation: 4.597373904930418]
	TIME [epoch: 11.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.629344569222793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.629344569222793 | validation: 3.7535337201975603]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.369925730000087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.369925730000087 | validation: 3.773249172260031]
	TIME [epoch: 11.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.337243390232512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.337243390232512 | validation: 3.822607349688923]
	TIME [epoch: 11.6 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.019284587234843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.019284587234843 | validation: 3.4704704265457984]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.635231621512929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.635231621512929 | validation: 3.4114668135953075]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.998548529837795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.998548529837795 | validation: 3.780393972343304]
	TIME [epoch: 11.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.13197941428256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.13197941428256 | validation: 3.5594734986220806]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.101133691306442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.101133691306442 | validation: 4.447177172909886]
	TIME [epoch: 11.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.056222213980884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.056222213980884 | validation: 4.38888261827569]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0972634120803315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0972634120803315 | validation: 3.182102545461156]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.971196310458524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.971196310458524 | validation: 3.450101185787941]
	TIME [epoch: 11.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.067157087838414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.067157087838414 | validation: 3.3686584695178134]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7113784468821445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7113784468821445 | validation: 3.585451048285413]
	TIME [epoch: 11.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.206053084658328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.206053084658328 | validation: 3.498956004098843]
	TIME [epoch: 11.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9087205365760695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9087205365760695 | validation: 4.131142558798016]
	TIME [epoch: 11.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.001126189490734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.001126189490734 | validation: 3.1896718335106455]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.789121979479745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.789121979479745 | validation: 3.3582845546534714]
	TIME [epoch: 11.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.24945864795273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.24945864795273 | validation: 4.253378119779298]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.066772063793996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.066772063793996 | validation: 3.2680054858856558]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.844861532177828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.844861532177828 | validation: 3.714714499363743]
	TIME [epoch: 11.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.802206549087228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.802206549087228 | validation: 3.2963769100528864]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.00872670578584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.00872670578584 | validation: 2.9965453451044826]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.688145909494502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.688145909494502 | validation: 4.0550578952443574]
	TIME [epoch: 11.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9199702868321635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9199702868321635 | validation: 3.3129270669788657]
	TIME [epoch: 11.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.716814475891895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.716814475891895 | validation: 3.465313523987824]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.778031581911644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.778031581911644 | validation: 2.896625091455843]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.924934455905886		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.924934455905886 | validation: 3.1483723050070864]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.896045952427562		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.896045952427562 | validation: 3.1904503479908715]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.582760606742002		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.582760606742002 | validation: 3.2013295018818533]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.51603848253413		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.51603848253413 | validation: 4.322776564786632]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.366716246924218		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.366716246924218 | validation: 3.572280824182522]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.647090698421232		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.647090698421232 | validation: 3.247869494942563]
	TIME [epoch: 11.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.692704514342487		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.692704514342487 | validation: 2.7518838250001396]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6836888069108		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.6836888069108 | validation: 3.028780871762769]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6290650339519335		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.6290650339519335 | validation: 3.839226339751051]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.958139490391153		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.958139490391153 | validation: 2.8483962300242824]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.529047451988316		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.529047451988316 | validation: 3.4162705740033688]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.680691346780608		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.680691346780608 | validation: 3.034366863338655]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.506350214013864		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.506350214013864 | validation: 3.051232426050267]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.579863010907725		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.579863010907725 | validation: 2.8972195220427603]
	TIME [epoch: 11.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.697086033932667		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.697086033932667 | validation: 2.9083277938466017]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4200715807682665		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.4200715807682665 | validation: 2.641072035331383]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.304201116543691		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.304201116543691 | validation: 3.003549301413912]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.948147949473821		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.948147949473821 | validation: 3.2330808447648516]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518754093992		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.518754093992 | validation: 2.838980550629167]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.602895889438032		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.602895889438032 | validation: 2.72412442215376]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.599667301613691		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.599667301613691 | validation: 2.8277708526648575]
	TIME [epoch: 11.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.668444120758722		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.668444120758722 | validation: 3.346864507422307]
	TIME [epoch: 11.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6028378314204		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.6028378314204 | validation: 3.625451578929755]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.694073483351879		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.694073483351879 | validation: 2.876840717416367]
	TIME [epoch: 11.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.609889645741788		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.609889645741788 | validation: 2.836621206181777]
	TIME [epoch: 11.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.547583875984607		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.547583875984607 | validation: 2.79615113820003]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.603794732602742		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.603794732602742 | validation: 2.793053937578811]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5082143668436		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.5082143668436 | validation: 3.5650165548632016]
	TIME [epoch: 11.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.594860353329543		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.594860353329543 | validation: 2.728019193254571]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.390646295092266		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.390646295092266 | validation: 3.195254045261086]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476799951663085		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.476799951663085 | validation: 2.537549385571814]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501936923331444		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.501936923331444 | validation: 3.0110437301480033]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.518454997988555		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.518454997988555 | validation: 2.9819606603084354]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.538018755081075		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.538018755081075 | validation: 2.6749422785022285]
	TIME [epoch: 11.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.383264908940698		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.383264908940698 | validation: 2.720498339840367]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.44771923047049		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.44771923047049 | validation: 2.799795679376437]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.308247146554283		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.308247146554283 | validation: 2.425798278511685]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5948218653666695		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.5948218653666695 | validation: 6.698746703236533]
	TIME [epoch: 11.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.829388007921535		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 5.829388007921535 | validation: 3.37153143895941]
	TIME [epoch: 11.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.343315675280318		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.343315675280318 | validation: 2.430144235147024]
	TIME [epoch: 11.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.263188622517097		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.263188622517097 | validation: 3.5663312670784753]
	TIME [epoch: 11.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.365948488403939		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.365948488403939 | validation: 2.5024363477551548]
	TIME [epoch: 11.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.375390150735785		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.375390150735785 | validation: 2.5936779537763055]
	TIME [epoch: 11.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3013970474907		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.3013970474907 | validation: 2.552099239015389]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4797923265681945		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.4797923265681945 | validation: 2.438345600729041]
	TIME [epoch: 11.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.321831172303048		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.321831172303048 | validation: 2.5574899656020595]
	TIME [epoch: 11.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.680177476061793		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.680177476061793 | validation: 2.647675972107042]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.401325410369427		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 4.401325410369427 | validation: 3.6858478967198316]
	TIME [epoch: 11.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.41285318587908		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 4.41285318587908 | validation: 2.4168762335735705]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.239520205004795		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.239520205004795 | validation: 3.842469072591831]
	TIME [epoch: 11.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.750917241507673		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 4.750917241507673 | validation: 2.593989801139462]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.358406151800459		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.358406151800459 | validation: 2.4805132683374786]
	TIME [epoch: 11.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.302380110520302		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.302380110520302 | validation: 2.7188506663547676]
	TIME [epoch: 11.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3620024912303705		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.3620024912303705 | validation: 2.5587252295270297]
	TIME [epoch: 11.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.218664629257667		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 4.218664629257667 | validation: 2.9609331015166847]
	TIME [epoch: 11.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.273119257119831		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.273119257119831 | validation: 2.6019574032004575]
	TIME [epoch: 11.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.363875581612845		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 4.363875581612845 | validation: 2.631328917390979]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.11306029747262		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.11306029747262 | validation: 3.04709334692087]
	TIME [epoch: 11.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492580659808132		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.492580659808132 | validation: 2.514581154085637]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.087926399670184		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 4.087926399670184 | validation: 2.56702314160906]
	TIME [epoch: 11.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.258761096054285		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 4.258761096054285 | validation: 2.379002272931077]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.435345982465364		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 4.435345982465364 | validation: 3.0281159979365975]
	TIME [epoch: 11.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.206943245052538		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 4.206943245052538 | validation: 2.782307926531518]
	TIME [epoch: 11.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.201142854436272		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.201142854436272 | validation: 2.3963765457133297]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.113981118037897		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.113981118037897 | validation: 2.3520373325511463]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.259875711872396		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.259875711872396 | validation: 2.199141503506795]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.11347580263919		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.11347580263919 | validation: 2.369718553927994]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.172293660524709		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 4.172293660524709 | validation: 2.589086476420661]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.430771085196027		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.430771085196027 | validation: 2.2150584609874735]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.13741910642989		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 4.13741910642989 | validation: 2.916635138763281]
	TIME [epoch: 11.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.203812364540769		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 4.203812364540769 | validation: 2.8401738773505354]
	TIME [epoch: 11.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.283350490431799		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.283350490431799 | validation: 3.196873910823988]
	TIME [epoch: 11.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525377300490064		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 4.525377300490064 | validation: 2.749923310877895]
	TIME [epoch: 11.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0984083023384805		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 6.0984083023384805 | validation: 3.1083261142819163]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.440113248599123		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.440113248599123 | validation: 2.5561168538812438]
	TIME [epoch: 11.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1428059705862985		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.1428059705862985 | validation: 3.4777771570135134]
	TIME [epoch: 11.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.293400594831116		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 4.293400594831116 | validation: 2.826915114898647]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.176437822948721		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.176437822948721 | validation: 2.4346375647866494]
	TIME [epoch: 11.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.059320072800973		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.059320072800973 | validation: 2.694517864323598]
	TIME [epoch: 11.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.307183637842775		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.307183637842775 | validation: 2.3063841310557316]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9164238556492896		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.9164238556492896 | validation: 3.723847786280237]
	TIME [epoch: 11.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.337790666157468		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 4.337790666157468 | validation: 3.333777534101148]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3071855041794755		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.3071855041794755 | validation: 2.238161404415158]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8997484868986456		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.8997484868986456 | validation: 2.3955522573562553]
	TIME [epoch: 11.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.182699415425672		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 4.182699415425672 | validation: 2.2883325860944006]
	TIME [epoch: 11.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.205402852413366		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 4.205402852413366 | validation: 2.3136986069830496]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.974862268103143		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.974862268103143 | validation: 2.3364300701153455]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8182054247729456		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.8182054247729456 | validation: 2.2295304130367395]
	TIME [epoch: 11.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9365943695973735		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.9365943695973735 | validation: 3.0280657629845225]
	TIME [epoch: 11.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.110760857081161		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 4.110760857081161 | validation: 2.21817531723523]
	TIME [epoch: 11.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7814792496890703		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.7814792496890703 | validation: 2.6372235825268393]
	TIME [epoch: 11.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.696628964059066		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.696628964059066 | validation: 2.2114018732071266]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.788153228017676		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.788153228017676 | validation: 1.9389735528936092]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4602324051880275		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.4602324051880275 | validation: 2.085760869028893]
	TIME [epoch: 11.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.273880807604947		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.273880807604947 | validation: 3.0190131642510902]
	TIME [epoch: 11.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.304847583100478		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 4.304847583100478 | validation: 2.582335179777315]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6488491370106058		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.6488491370106058 | validation: 2.087588436199986]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6377201127040926		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.6377201127040926 | validation: 2.101241771958485]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.300218124343985		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.300218124343985 | validation: 1.86515727149037]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.479600679753066		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.479600679753066 | validation: 2.0573189278949293]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6837503386408326		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.6837503386408326 | validation: 1.8553742384294236]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.251254784778432		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.251254784778432 | validation: 1.9529856040865374]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1689899502607233		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.1689899502607233 | validation: 1.9765763506580607]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.322180412892002		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.322180412892002 | validation: 1.740617776196969]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1142632736189046		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.1142632736189046 | validation: 1.8089104751129839]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.329578771151018		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.329578771151018 | validation: 2.0312111142640497]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.299358711141579		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.299358711141579 | validation: 1.7482927922345892]
	TIME [epoch: 11.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2591419718790413		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.2591419718790413 | validation: 1.7915484393547063]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1611928203769413		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.1611928203769413 | validation: 1.8283787215891636]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3452661927312874		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.3452661927312874 | validation: 1.7442369608427908]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.28612880193333		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.28612880193333 | validation: 1.624034602354678]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.274087155656849		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.274087155656849 | validation: 1.7386342867705986]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.19232692058012		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.19232692058012 | validation: 1.6369455108081474]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3556194255095577		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.3556194255095577 | validation: 1.7757187104644612]
	TIME [epoch: 11.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.332876253998621		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.332876253998621 | validation: 1.6675363725053962]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0468905994204585		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.0468905994204585 | validation: 1.6827978959658116]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1796234950542117		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.1796234950542117 | validation: 1.7559374770145446]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3481343275665907		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.3481343275665907 | validation: 1.607535804649023]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1965184539463456		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.1965184539463456 | validation: 1.7936610607675822]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.19062005542136		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.19062005542136 | validation: 2.6927459403656138]
	TIME [epoch: 11.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2793826185643526		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.2793826185643526 | validation: 1.8130308761579477]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.059471997331303		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.059471997331303 | validation: 2.5909151417326544]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5751461943850362		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.5751461943850362 | validation: 2.379323318514749]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.426754797068343		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.426754797068343 | validation: 1.9845329670254455]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2264555672775077		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.2264555672775077 | validation: 1.8360944380695208]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1164822255375846		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.1164822255375846 | validation: 2.048094165710675]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1128335020438898		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.1128335020438898 | validation: 1.8703610344499897]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2182389683967925		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.2182389683967925 | validation: 1.6204648323537996]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0726015403255915		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.0726015403255915 | validation: 1.7308335769352703]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.438792475352943		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.438792475352943 | validation: 1.7956483858192196]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1004880107899284		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.1004880107899284 | validation: 1.638576950213467]
	TIME [epoch: 11.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0840604306647386		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.0840604306647386 | validation: 3.46260148927692]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.624913578748942		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.624913578748942 | validation: 2.246520681034809]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1983047011876073		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.1983047011876073 | validation: 1.6038379075310945]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.259716678146653		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.259716678146653 | validation: 2.3190271743967186]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.094139907366367		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.094139907366367 | validation: 1.9872595312439874]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.098220882167641		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.098220882167641 | validation: 1.647089976731]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8819918077806563		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.8819918077806563 | validation: 3.052610829176843]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4175116992937866		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.4175116992937866 | validation: 1.7921359239835633]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.056800657668399		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.056800657668399 | validation: 1.7393374770471228]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.971528721243029		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.971528721243029 | validation: 1.6356655290312043]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.078118395145972		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.078118395145972 | validation: 1.752406092796851]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.919732612653268		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.919732612653268 | validation: 1.8119043115220064]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0412675592173417		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.0412675592173417 | validation: 1.837417799913717]
	TIME [epoch: 11.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9793422371481437		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.9793422371481437 | validation: 1.6286315396452273]
	TIME [epoch: 11.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8771613410354604		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.8771613410354604 | validation: 2.0779943025013843]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.233052778841704		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.233052778841704 | validation: 1.7601647341477265]
	TIME [epoch: 11.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221674673073094		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.221674673073094 | validation: 1.588904479008117]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1226994566180855		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 3.1226994566180855 | validation: 1.8837241294155933]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0176884013087415		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.0176884013087415 | validation: 1.8058528122016584]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.871631592574338		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.871631592574338 | validation: 1.6109678465823083]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9022515363356076		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.9022515363356076 | validation: 1.8965712186145858]
	TIME [epoch: 11.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0011467519610036		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 3.0011467519610036 | validation: 1.90672795504316]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2593676067901054		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.2593676067901054 | validation: 1.6232074872600157]
	TIME [epoch: 11.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.019377876428793		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.019377876428793 | validation: 1.7379478928843475]
	TIME [epoch: 11.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9869361944663053		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.9869361944663053 | validation: 1.6254493530069545]
	TIME [epoch: 11.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.873017467033137		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.873017467033137 | validation: 1.4644037371276397]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.883106188347935		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.883106188347935 | validation: 1.5763872551669986]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.077719436221228		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 3.077719436221228 | validation: 1.6206985032284376]
	TIME [epoch: 11.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0847450527153075		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 3.0847450527153075 | validation: 2.2335434640224476]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.012489263861694		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 3.012489263861694 | validation: 2.0679545824738197]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9666049343618477		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.9666049343618477 | validation: 1.8045977663727217]
	TIME [epoch: 11.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.948430908359704		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.948430908359704 | validation: 1.5275406857834906]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.835872853025235		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.835872853025235 | validation: 2.1700059673642382]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1406483874198283		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 3.1406483874198283 | validation: 1.8333994843799417]
	TIME [epoch: 11.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0690572657262356		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 3.0690572657262356 | validation: 1.6674340064339492]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.871215766385295		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.871215766385295 | validation: 1.6032586629333043]
	TIME [epoch: 11.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8688908240475697		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.8688908240475697 | validation: 2.1032954768112266]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.886732446750559		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.886732446750559 | validation: 1.596345553287183]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9611415260382374		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.9611415260382374 | validation: 1.5541403897454218]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8478773956735095		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.8478773956735095 | validation: 2.826867648570903]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.109640497442917		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 3.109640497442917 | validation: 1.6548752702346128]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8214166613540788		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.8214166613540788 | validation: 1.660892530104577]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.889587881001447		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.889587881001447 | validation: 1.593116994086283]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8443349154705166		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.8443349154705166 | validation: 2.067665971680067]
	TIME [epoch: 11.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9313674003261476		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.9313674003261476 | validation: 1.4646914358680447]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.035833464466488		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 3.035833464466488 | validation: 2.4651486482019287]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9584776926406713		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.9584776926406713 | validation: 1.5961000042339106]
	TIME [epoch: 11.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9826087531025847		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.9826087531025847 | validation: 1.76922147621234]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.827334500744485		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.827334500744485 | validation: 1.4446240503133232]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7286390374761407		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.7286390374761407 | validation: 1.8861312290523666]
	TIME [epoch: 11.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.767302898352798		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.767302898352798 | validation: 1.517910749037675]
	TIME [epoch: 11.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9706518951809047		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.9706518951809047 | validation: 1.4648862186469658]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3857591380995267		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 3.3857591380995267 | validation: 1.8179369509626497]
	TIME [epoch: 11.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.855562536094694		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.855562536094694 | validation: 1.6788233162951218]
	TIME [epoch: 11.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.059083427364701		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 4.059083427364701 | validation: 1.6748818501705787]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9788110935066476		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.9788110935066476 | validation: 1.5502961706933962]
	TIME [epoch: 11.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7229084295121915		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.7229084295121915 | validation: 1.4754330785527743]
	TIME [epoch: 11.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.729175287430104		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.729175287430104 | validation: 1.5469629152761206]
	TIME [epoch: 11.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7432022438741748		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.7432022438741748 | validation: 1.4916093315951375]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.711454134755707		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.711454134755707 | validation: 1.5311899097771722]
	TIME [epoch: 11.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6127627334876706		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.6127627334876706 | validation: 2.2807123787538117]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0895315033777204		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 3.0895315033777204 | validation: 2.082888370713371]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8365595010175344		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.8365595010175344 | validation: 2.3133857651329235]
	TIME [epoch: 11.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7723991145388673		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.7723991145388673 | validation: 1.4522457877921522]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.696387665691958		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.696387665691958 | validation: 1.5843079802057662]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7270593401943737		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.7270593401943737 | validation: 1.4576419107361323]
	TIME [epoch: 11.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7519951008315986		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.7519951008315986 | validation: 1.438810708208173]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.744583460973767		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 2.744583460973767 | validation: 1.5196522416070546]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6404603195723095		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.6404603195723095 | validation: 1.7580654251217187]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6865692650057724		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.6865692650057724 | validation: 2.0612804129224496]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7603562120297176		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.7603562120297176 | validation: 1.891095936101467]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8210718499031437		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.8210718499031437 | validation: 1.4362813889219581]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1182818304116786		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 3.1182818304116786 | validation: 1.7364228681999465]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.614856972897626		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.614856972897626 | validation: 1.6193471412076854]
	TIME [epoch: 11.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.774140799013015		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.774140799013015 | validation: 1.7704154287287832]
	TIME [epoch: 11.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.632040807413708		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 2.632040807413708 | validation: 1.4498650915973064]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.536565103342985		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.536565103342985 | validation: 1.4368077618802426]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5104674530297895		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.5104674530297895 | validation: 1.8307071221865403]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.633746157349821		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.633746157349821 | validation: 1.7080560647316627]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.558871307757289		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.558871307757289 | validation: 1.9625569787485]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.655003186610767		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.655003186610767 | validation: 1.687732924999409]
	TIME [epoch: 11.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5932320475694057		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.5932320475694057 | validation: 1.4793546758992948]
	TIME [epoch: 11.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.494295957129605		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.494295957129605 | validation: 1.6245261140212983]
	TIME [epoch: 11.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6061271611438914		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.6061271611438914 | validation: 1.5386878235781936]
	TIME [epoch: 11.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.507018438362465		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 2.507018438362465 | validation: 1.5384591433820907]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.512017438097534		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 2.512017438097534 | validation: 1.8054801659904296]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6000765124608076		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.6000765124608076 | validation: 1.5445172490354622]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.499651538613291		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.499651538613291 | validation: 1.723525540537994]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5278168744939227		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.5278168744939227 | validation: 1.4987062156369604]
	TIME [epoch: 11.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.573692299417731		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.573692299417731 | validation: 1.564807186905468]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4729496042292554		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.4729496042292554 | validation: 1.7104561468056028]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.461115877541537		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.461115877541537 | validation: 1.8386886793187156]
	TIME [epoch: 11.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.570502844912891		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.570502844912891 | validation: 1.5995980585835496]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3823689365489265		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.3823689365489265 | validation: 2.0827851044039885]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.478150286847631		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.478150286847631 | validation: 1.4260387783470152]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358933947092016		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.358933947092016 | validation: 1.659443182944351]
	TIME [epoch: 11.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5578409943459914		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.5578409943459914 | validation: 2.313120594479663]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5933263540428997		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.5933263540428997 | validation: 1.9648691603474344]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3833356373858368		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 2.3833356373858368 | validation: 1.4579539313092826]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.194402585037701		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.194402585037701 | validation: 1.4952894026584824]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2860884388682585		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.2860884388682585 | validation: 1.515737360986525]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297690253441111		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.297690253441111 | validation: 1.4074134543010757]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3903309839496134		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.3903309839496134 | validation: 2.0173310760016894]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340711891917616		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.340711891917616 | validation: 1.6660742774864374]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.20879634614301		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.20879634614301 | validation: 1.852625869131777]
	TIME [epoch: 11.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2963223383274385		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.2963223383274385 | validation: 1.5333339598506472]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2347370410320324		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.2347370410320324 | validation: 1.4109416152020777]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325401074132963		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.325401074132963 | validation: 1.4296502709924976]
	TIME [epoch: 11.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2507942011316047		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.2507942011316047 | validation: 1.6659572614663665]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1659382627704025		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.1659382627704025 | validation: 1.3817718198389757]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29200549747446		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.29200549747446 | validation: 1.5681179738513316]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3158864936478816		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.3158864936478816 | validation: 2.1859076429600424]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254178452528329		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.254178452528329 | validation: 1.5031039254771823]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1650131637398258		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.1650131637398258 | validation: 1.5433409232538413]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2248069532305426		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.2248069532305426 | validation: 1.3555293515684315]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078420741544425		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.078420741544425 | validation: 1.9347101089767458]
	TIME [epoch: 11.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0750379973578914		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.0750379973578914 | validation: 1.5984189212515652]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3479543696437295		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.3479543696437295 | validation: 1.9020154732284191]
	TIME [epoch: 11.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.055267503425484		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.055267503425484 | validation: 1.4427495593212758]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1068109359133036		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.1068109359133036 | validation: 1.4404218072508497]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.076177163855304		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.076177163855304 | validation: 1.3909696147506965]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.224519877366882		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.224519877366882 | validation: 1.3813191952537198]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0015820330907954		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.0015820330907954 | validation: 1.5229249925610915]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.190391863128112		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 2.190391863128112 | validation: 1.3342321831154826]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1682318569324632		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.1682318569324632 | validation: 1.36725434260172]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0017376931825805		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.0017376931825805 | validation: 1.4005539123342958]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1266873221023084		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.1266873221023084 | validation: 1.8560536617734453]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.10773260910334		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.10773260910334 | validation: 1.8283216547558991]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1070957160323567		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.1070957160323567 | validation: 1.4465932550055283]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0421451780012703		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.0421451780012703 | validation: 1.498894573880167]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9814082909290067		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.9814082909290067 | validation: 1.6056362165204012]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.959143866108513		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.959143866108513 | validation: 1.4839771752804376]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.926804134174195		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.926804134174195 | validation: 1.4983381276655865]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1136583593004232		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.1136583593004232 | validation: 2.232602034230672]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0883880594960287		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.0883880594960287 | validation: 1.627660997355363]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044818376660232		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.044818376660232 | validation: 1.7277612384563543]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2336945418608085		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.2336945418608085 | validation: 1.4318417539509074]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2203085729119834		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 2.2203085729119834 | validation: 1.336368362024856]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044324643199017		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.044324643199017 | validation: 1.4423631887405615]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.099362819367978		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.099362819367978 | validation: 1.753561901973955]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1560648071652606		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.1560648071652606 | validation: 2.8610068956701866]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.441067002127234		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.441067002127234 | validation: 1.7780096789135196]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0966255426536344		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.0966255426536344 | validation: 1.4242518097232175]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.887218747008144		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.887218747008144 | validation: 2.9267694144913388]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4807307630948694		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.4807307630948694 | validation: 1.9056148507443638]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.097589336261416		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.097589336261416 | validation: 1.3516883221177454]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8955659938181626		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.8955659938181626 | validation: 1.3520640829268336]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9637261975106455		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.9637261975106455 | validation: 1.6344288043658162]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.978185197873739		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.978185197873739 | validation: 1.4702827002984682]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9315550292836208		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.9315550292836208 | validation: 1.4865624590382158]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9263062517270368		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.9263062517270368 | validation: 1.292948341002123]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.920556716103262		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.920556716103262 | validation: 2.362337450387015]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281592190322042		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.281592190322042 | validation: 1.8626161685306404]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9593623795195094		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.9593623795195094 | validation: 1.580311363231795]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9266663302213631		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.9266663302213631 | validation: 1.343163377321382]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8628052873111358		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.8628052873111358 | validation: 1.409710509673029]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8646996251621182		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.8646996251621182 | validation: 1.290203290076912]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9410234167941105		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.9410234167941105 | validation: 1.2709999163024168]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8463183264993264		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.8463183264993264 | validation: 1.6397857836974152]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9394194464023773		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.9394194464023773 | validation: 1.262287047184835]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8868980624382041		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.8868980624382041 | validation: 1.2881097686853673]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8266165614209489		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.8266165614209489 | validation: 1.6545948294043962]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8744618757804687		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.8744618757804687 | validation: 1.4301406980128968]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.987745494303553		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.987745494303553 | validation: 1.303889476605583]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7694446801003432		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.7694446801003432 | validation: 1.5802358778063172]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8908443085167095		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.8908443085167095 | validation: 1.7343883980348214]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8564855104336146		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.8564855104336146 | validation: 2.0074403214550767]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.889632843728509		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.889632843728509 | validation: 1.2520823567346793]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9882769702441576		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.9882769702441576 | validation: 1.881915807561706]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9758187071440338		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.9758187071440338 | validation: 1.3861908341734652]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7872858277030972		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.7872858277030972 | validation: 1.378493792797307]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8275752921748676		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.8275752921748676 | validation: 1.3089689141350929]
	TIME [epoch: 11.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8769753668237197		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.8769753668237197 | validation: 1.3839507894436052]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.576269146092887		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 2.576269146092887 | validation: 3.122387350937005]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3305773730460104		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.3305773730460104 | validation: 1.5770081187413352]
	TIME [epoch: 11.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1707612317255123		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 2.1707612317255123 | validation: 1.3610839470980711]
	TIME [epoch: 11.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.786655941608588		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.786655941608588 | validation: 1.7177343247494345]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.902591356393814		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.902591356393814 | validation: 1.2211433121940733]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_359.pth
	Model improved!!!
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7165373616043846		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.7165373616043846 | validation: 1.2916669621114583]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7540202617940923		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.7540202617940923 | validation: 1.2139383013717113]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1279628210076957		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 2.1279628210076957 | validation: 3.2711361218828077]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.425132591237938		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.425132591237938 | validation: 1.5964799570716235]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.084652290471743		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.084652290471743 | validation: 1.3360924798531337]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.773039855840918		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.773039855840918 | validation: 1.2643010378995283]
	TIME [epoch: 11.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8592582725331852		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.8592582725331852 | validation: 1.2140574303488625]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7415409778820132		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.7415409778820132 | validation: 1.5533847825052323]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7799825733756325		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.7799825733756325 | validation: 1.4269384032090193]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281969695926687		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.7281969695926687 | validation: 1.5582991529129766]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9215190524139616		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.9215190524139616 | validation: 1.3844120573715353]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7553655144718883		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.7553655144718883 | validation: 1.331780049955729]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739368178467271		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.739368178467271 | validation: 1.3282981423824982]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7827342685048246		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.7827342685048246 | validation: 1.7270583834692759]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8546906682763105		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.8546906682763105 | validation: 2.0434620712099836]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8731644361733644		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.8731644361733644 | validation: 1.276136230427319]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.808163432131476		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.808163432131476 | validation: 1.285464977604704]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7054576895266544		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.7054576895266544 | validation: 1.3418547039976363]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6744546302361667		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.6744546302361667 | validation: 1.2720242193190694]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.934326138428256		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.934326138428256 | validation: 1.2341779905616628]
	TIME [epoch: 11.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.706258312362253		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.706258312362253 | validation: 1.269755829032571]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6716643805653424		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.6716643805653424 | validation: 1.4629367096334103]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7067403225729174		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.7067403225729174 | validation: 1.38082954124218]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8877397603876924		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.8877397603876924 | validation: 1.6652530719801788]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7871572855785707		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.7871572855785707 | validation: 1.1919637279742]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8088082477917853		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.8088082477917853 | validation: 1.5856451876282847]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8682372641523646		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.8682372641523646 | validation: 1.2887050627221812]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9076696408481757		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.9076696408481757 | validation: 1.3427588739679013]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7616707469062236		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.7616707469062236 | validation: 1.7753353653092803]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.80967617187463		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.80967617187463 | validation: 1.545178159467916]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7130755011636731		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.7130755011636731 | validation: 1.4588285484973245]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.756658013338599		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.756658013338599 | validation: 1.4479374127690705]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7708265844206854		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.7708265844206854 | validation: 1.4161107962377901]
	TIME [epoch: 11.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7238547134685853		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.7238547134685853 | validation: 1.2880774510758977]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6785427133089312		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.6785427133089312 | validation: 1.2344729676789563]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7145116068761879		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.7145116068761879 | validation: 1.2807123168092291]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8423127479460226		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.8423127479460226 | validation: 1.373014448651349]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7076583304682076		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.7076583304682076 | validation: 1.4423492541170873]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8007479610656598		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.8007479610656598 | validation: 1.231721915395251]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7142329683200561		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.7142329683200561 | validation: 1.1323616739304734]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_399.pth
	Model improved!!!
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7435092831362524		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.7435092831362524 | validation: 1.1751794244927039]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8570119193944545		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.8570119193944545 | validation: 1.1477579520199068]
	TIME [epoch: 11.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7493829590386945		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.7493829590386945 | validation: 1.2405882089670444]
	TIME [epoch: 11.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8018529010301954		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.8018529010301954 | validation: 1.2323554767303442]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7296778828301556		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.7296778828301556 | validation: 1.2047861287816861]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6893258248773284		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.6893258248773284 | validation: 1.1797665604765506]
	TIME [epoch: 11.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7015538208445355		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.7015538208445355 | validation: 1.3687494500083068]
	TIME [epoch: 11.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7309639970258253		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.7309639970258253 | validation: 1.219791868878776]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044817255294122		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 2.044817255294122 | validation: 1.3146010429567088]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8136892641267783		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.8136892641267783 | validation: 1.1320683481537064]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6930491282055165		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.6930491282055165 | validation: 1.6594548355543608]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.805050328102539		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.805050328102539 | validation: 1.1567791504845406]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.652055810449458		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.652055810449458 | validation: 1.4614338825975295]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8081492443184841		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.8081492443184841 | validation: 1.3146893840062865]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7422982276383814		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.7422982276383814 | validation: 1.3996774305294866]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6987955101813343		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.6987955101813343 | validation: 1.7128140881268976]
	TIME [epoch: 11.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9525005494343122		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.9525005494343122 | validation: 1.1403365159799657]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8418858769105417		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.8418858769105417 | validation: 1.1909631931363398]
	TIME [epoch: 11.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.66316867280465		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.66316867280465 | validation: 1.3934241695547118]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294807199660043		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.7294807199660043 | validation: 1.7171504504557908]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7503884674186252		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.7503884674186252 | validation: 1.2588008460673419]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7738688777142637		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.7738688777142637 | validation: 1.298039980504371]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6876548007306118		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.6876548007306118 | validation: 1.2757083389001829]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7758781055809578		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.7758781055809578 | validation: 1.446121592180471]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7300591155688276		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.7300591155688276 | validation: 1.9672028112909423]
	TIME [epoch: 11.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.86971652353792		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.86971652353792 | validation: 1.1676594519219796]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6604003694678775		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.6604003694678775 | validation: 1.296336555804832]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6878640948056856		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.6878640948056856 | validation: 1.3402435101917942]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7692752994518892		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.7692752994518892 | validation: 1.204070198143715]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7167826012254652		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.7167826012254652 | validation: 1.1531012701397445]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.663160883433639		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.663160883433639 | validation: 1.364534737682568]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6919557170041775		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.6919557170041775 | validation: 1.246609972695637]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8038784315752414		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.8038784315752414 | validation: 1.3499220691956724]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.781456619925235		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.781456619925235 | validation: 1.6007022922927063]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8200283740094794		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.8200283740094794 | validation: 1.173968164721448]
	TIME [epoch: 11.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7637603324629403		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.7637603324629403 | validation: 1.1783540118308446]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8660415837418702		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.8660415837418702 | validation: 1.280407829060759]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7767508918302863		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.7767508918302863 | validation: 1.186961649729143]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6890637198665264		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.6890637198665264 | validation: 1.274977861241769]
	TIME [epoch: 11.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6761999142354786		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.6761999142354786 | validation: 1.1957448882864592]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4754358429052545		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 2.4754358429052545 | validation: 1.2889962015110916]
	TIME [epoch: 11.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9041701886850406		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.9041701886850406 | validation: 1.3795022995265447]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7326627892958566		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.7326627892958566 | validation: 1.214758020379299]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.686601432135884		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.686601432135884 | validation: 1.3793981833284448]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6630509177271993		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.6630509177271993 | validation: 1.5298661733494243]
	TIME [epoch: 11.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6898426769578374		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.6898426769578374 | validation: 1.1264455300144527]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.705092627567397		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.705092627567397 | validation: 1.396099432381956]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1516180078241707		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 2.1516180078241707 | validation: 1.3356772782404767]
	TIME [epoch: 11.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6402998794165624		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.6402998794165624 | validation: 1.148605471303362]
	TIME [epoch: 11.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6648598960914174		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.6648598960914174 | validation: 1.3070383431166313]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.763918915502414		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.763918915502414 | validation: 1.4096396698977003]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.707432080780442		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.707432080780442 | validation: 1.1832023709544424]
	TIME [epoch: 11.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5946254860987528		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.5946254860987528 | validation: 1.1791968136303494]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6645111479168102		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.6645111479168102 | validation: 1.1835256294218868]
	TIME [epoch: 11.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6416522710070787		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.6416522710070787 | validation: 1.1750959666255258]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6418225821561117		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.6418225821561117 | validation: 1.136402618062221]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6130086162769266		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.6130086162769266 | validation: 1.1710123722380705]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5940099297543042		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.5940099297543042 | validation: 1.4025765933374743]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.786911251674838		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.786911251674838 | validation: 1.2591345915560226]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6234151851587078		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.6234151851587078 | validation: 1.1355029914552803]
	TIME [epoch: 11.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6188634996234714		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.6188634996234714 | validation: 1.1343870065510095]
	TIME [epoch: 11.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6843577746907579		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.6843577746907579 | validation: 1.1464177864627845]
	TIME [epoch: 11.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5956534503573905		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.5956534503573905 | validation: 1.2738316512711452]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.617906453598565		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.617906453598565 | validation: 1.1236955369859865]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_463.pth
	Model improved!!!
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6994439318646861		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.6994439318646861 | validation: 1.132226671914316]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6559610328381673		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.6559610328381673 | validation: 1.1658385347196505]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0438204759670096		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 2.0438204759670096 | validation: 1.7584511572529333]
	TIME [epoch: 11.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8917428362486026		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.8917428362486026 | validation: 1.175202004454597]
	TIME [epoch: 11.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.76018226361907		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.76018226361907 | validation: 1.6587875336476827]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7486626504472826		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.7486626504472826 | validation: 1.1720853237371287]
	TIME [epoch: 11.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7450690826527242		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.7450690826527242 | validation: 1.278899299784716]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7357716740855902		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.7357716740855902 | validation: 1.203558414004663]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5840914782414894		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.5840914782414894 | validation: 1.091546587478352]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6331850061865465		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.6331850061865465 | validation: 1.2348065942432263]
	TIME [epoch: 11.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.856353726719863		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.856353726719863 | validation: 1.3365226187841543]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8575797915572962		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.8575797915572962 | validation: 1.1211736672076598]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.682877073239948		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.682877073239948 | validation: 1.1598829938781006]
	TIME [epoch: 11.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6170308917171927		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.6170308917171927 | validation: 1.2209509597660935]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.76559555611783		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.76559555611783 | validation: 1.123731335164772]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7946552086132421		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.7946552086132421 | validation: 1.1473945867759272]
	TIME [epoch: 11.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6065263401129948		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.6065263401129948 | validation: 1.217377735189564]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6564449280369509		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.6564449280369509 | validation: 1.1352815295936807]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5595086901919561		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.5595086901919561 | validation: 1.1476707682993261]
	TIME [epoch: 11.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8513663635553055		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.8513663635553055 | validation: 1.0919678516932398]
	TIME [epoch: 11.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.707147660479315		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.707147660479315 | validation: 1.2420683115452034]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6007395852585584		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.6007395852585584 | validation: 1.5555241477794919]
	TIME [epoch: 11.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0530086923767716		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 2.0530086923767716 | validation: 1.3085743240863172]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6953743883988208		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.6953743883988208 | validation: 1.1166175119235655]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6612380608491029		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.6612380608491029 | validation: 1.2739438646076953]
	TIME [epoch: 11.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6096670013944994		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.6096670013944994 | validation: 1.2991922526129853]
	TIME [epoch: 11.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6578697311211186		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.6578697311211186 | validation: 1.092200762793176]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6151716763534392		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.6151716763534392 | validation: 1.341043992434331]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6587848527721636		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.6587848527721636 | validation: 1.20058710841561]
	TIME [epoch: 11.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6194223425946899		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.6194223425946899 | validation: 1.7085637397098024]
	TIME [epoch: 11.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.807477000490116		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.807477000490116 | validation: 1.3702293152674216]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.584274358637413		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.584274358637413 | validation: 1.7004396253501788]
	TIME [epoch: 11.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6805204486546743		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.6805204486546743 | validation: 1.1347934699999322]
	TIME [epoch: 11.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5970131255953741		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.5970131255953741 | validation: 1.2831691364924984]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6117056403124275		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.6117056403124275 | validation: 2.1646327414147755]
	TIME [epoch: 11.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8576881255910727		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.8576881255910727 | validation: 1.5353489745827944]
	TIME [epoch: 11.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7172732381482623		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.7172732381482623 | validation: 1.1340835565586505]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5997252925970011		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.5997252925970011 | validation: 1.11540736879314]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5276980444353965		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.5276980444353965 | validation: 1.1237506513162767]
	TIME [epoch: 11.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6037402526885636		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.6037402526885636 | validation: 1.0607709844968742]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_503.pth
	Model improved!!!
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5829725272131443		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.5829725272131443 | validation: 1.1209096088397699]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5464480414911481		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.5464480414911481 | validation: 1.1583764799091048]
	TIME [epoch: 11.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.623034929429944		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.623034929429944 | validation: 1.1651555572611898]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6197781549951313		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.6197781549951313 | validation: 1.2154670514464503]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6160736072327058		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.6160736072327058 | validation: 1.100038444894649]
	TIME [epoch: 11.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.612391068608931		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.612391068608931 | validation: 1.2304917938138555]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5756486164113368		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.5756486164113368 | validation: 1.3307414732358642]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.664253843224683		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.664253843224683 | validation: 1.8387372273067848]
	TIME [epoch: 11.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8298333254652628		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.8298333254652628 | validation: 1.645912001126205]
	TIME [epoch: 11.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6920593939598072		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.6920593939598072 | validation: 1.0736441863457895]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6872403503343236		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.6872403503343236 | validation: 1.140466925364384]
	TIME [epoch: 11.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5902873180178807		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.5902873180178807 | validation: 1.4769540986926761]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6132990240364968		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.6132990240364968 | validation: 1.4139580606983202]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5866191313204454		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.5866191313204454 | validation: 1.1804139703194838]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5753382794237987		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.5753382794237987 | validation: 1.1457736181761147]
	TIME [epoch: 11.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6653656163997645		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.6653656163997645 | validation: 1.0833185598119395]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6068247996464764		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.6068247996464764 | validation: 1.0782096601969533]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5083770696990828		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.5083770696990828 | validation: 1.383621013886789]
	TIME [epoch: 11.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6870322759335232		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.6870322759335232 | validation: 1.0574044980428898]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_522.pth
	Model improved!!!
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6279030770350875		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.6279030770350875 | validation: 2.145575959816986]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9923450943819567		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.9923450943819567 | validation: 1.4701689956986286]
	TIME [epoch: 11.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6716932821429147		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.6716932821429147 | validation: 1.1507532354020535]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6172601315932276		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.6172601315932276 | validation: 1.1940747698164902]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5615273244240266		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.5615273244240266 | validation: 1.1466505754725336]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5250730216794943		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.5250730216794943 | validation: 1.6979883628093335]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7617977688539164		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.7617977688539164 | validation: 1.1043433988060596]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6602620496501679		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.6602620496501679 | validation: 1.5329725271780998]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7288800352806362		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.7288800352806362 | validation: 1.0457949193093883]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_531.pth
	Model improved!!!
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7970894418015357		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.7970894418015357 | validation: 1.2383823910276825]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.658348999996933		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.658348999996933 | validation: 1.170697660455417]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5449087017540108		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.5449087017540108 | validation: 1.043188326874432]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_534.pth
	Model improved!!!
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4988968405649117		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.4988968405649117 | validation: 1.977604664873091]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8986039943222623		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 1.8986039943222623 | validation: 1.3718077074282935]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6601020224286427		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 1.6601020224286427 | validation: 1.1044330389630934]
	TIME [epoch: 11.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6729788891990176		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 1.6729788891990176 | validation: 1.266776519797038]
	TIME [epoch: 11.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5666270090481411		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 1.5666270090481411 | validation: 1.2189029130870963]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.580012462774461		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.580012462774461 | validation: 1.1697199691194862]
	TIME [epoch: 11.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6916404477068812		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.6916404477068812 | validation: 1.0758610897504122]
	TIME [epoch: 11.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5296155499945592		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 1.5296155499945592 | validation: 1.1031754678707373]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.570158965079336		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.570158965079336 | validation: 1.1196888415958817]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5682067958439352		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 1.5682067958439352 | validation: 1.4394165140550916]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.672661496390589		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.672661496390589 | validation: 1.4494093239746213]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5861953814910983		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.5861953814910983 | validation: 1.277306783983722]
	TIME [epoch: 11.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5465756862717779		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.5465756862717779 | validation: 1.1602665071224814]
	TIME [epoch: 11.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5124359077171563		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.5124359077171563 | validation: 1.1216568117193038]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6029721809418636		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.6029721809418636 | validation: 1.0434743673002675]
	TIME [epoch: 11.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5300173417031946		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.5300173417031946 | validation: 1.3692720233959086]
	TIME [epoch: 11.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6186544037547355		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.6186544037547355 | validation: 1.0438495438765676]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.608985800040008		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 1.608985800040008 | validation: 1.1778843228676414]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5654776706068196		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.5654776706068196 | validation: 1.3769751952089744]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5815576843561752		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 1.5815576843561752 | validation: 1.1081168251319642]
	TIME [epoch: 11.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5101546720483148		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.5101546720483148 | validation: 1.0328877446790823]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_555.pth
	Model improved!!!
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5334311433859686		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.5334311433859686 | validation: 1.127041781474598]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6534286965152687		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 1.6534286965152687 | validation: 1.1349213188760323]
	TIME [epoch: 11.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.501020982978154		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.501020982978154 | validation: 1.0772283640704183]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5308546079350542		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.5308546079350542 | validation: 1.1013272186040142]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.513559727044168		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.513559727044168 | validation: 1.2785005045613698]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5430237296308424		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 1.5430237296308424 | validation: 1.0395026092869526]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5133410184683573		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.5133410184683573 | validation: 1.0738897997996335]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6228754439755066		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 1.6228754439755066 | validation: 1.0835348425489333]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.48995111281857		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 1.48995111281857 | validation: 1.1014156748971078]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.485117703117711		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.485117703117711 | validation: 1.2713528400279075]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.642204106979546		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.642204106979546 | validation: 1.0264654185454822]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_566.pth
	Model improved!!!
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.619655834279263		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.619655834279263 | validation: 1.4309627139287056]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6197293717536136		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.6197293717536136 | validation: 1.0351785162233424]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.546247677126195		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.546247677126195 | validation: 1.2603238283118439]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5754212814722044		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.5754212814722044 | validation: 1.0476807037625702]
	TIME [epoch: 11.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4892843998024599		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.4892843998024599 | validation: 1.0393794425748903]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5665691932249663		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.5665691932249663 | validation: 1.2030180526667715]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5337717818311445		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.5337717818311445 | validation: 1.117189100642674]
	TIME [epoch: 11.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.516113066973594		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 1.516113066973594 | validation: 1.0389833192261448]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5681665116884123		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 1.5681665116884123 | validation: 1.16739526607145]
	TIME [epoch: 11.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.602487120293259		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 1.602487120293259 | validation: 1.12517767254289]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7627842695537783		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 1.7627842695537783 | validation: 1.2166467401104928]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5118439627163016		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 1.5118439627163016 | validation: 1.0487091719923682]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.52810261317882		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 1.52810261317882 | validation: 1.0999195577511978]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5836672560629057		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.5836672560629057 | validation: 1.2339793573158826]
	TIME [epoch: 11.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.559159922400302		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 1.559159922400302 | validation: 1.2098660245910728]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5431686237928797		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.5431686237928797 | validation: 1.080637580160421]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.581835667177578		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 1.581835667177578 | validation: 1.115228744139929]
	TIME [epoch: 11.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5065408179655422		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 1.5065408179655422 | validation: 1.064420513828642]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.50132166040455		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.50132166040455 | validation: 1.0894897976138083]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.537520801181834		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 1.537520801181834 | validation: 1.0471324798518413]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6131568863578731		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 1.6131568863578731 | validation: 1.0705598190747379]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6036635754216024		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.6036635754216024 | validation: 1.0603708907523055]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.579008583497719		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.579008583497719 | validation: 1.0537904319764348]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4943439400401815		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 1.4943439400401815 | validation: 1.1317526452670943]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.530426595537203		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.530426595537203 | validation: 1.0067910589398212]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_591.pth
	Model improved!!!
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6130962186347264		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 1.6130962186347264 | validation: 1.2492198396497634]
	TIME [epoch: 11.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5487716176713238		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 1.5487716176713238 | validation: 1.0383543673236326]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6524547929014435		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.6524547929014435 | validation: 1.1864009878782975]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5466283524230031		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 1.5466283524230031 | validation: 1.0240144750784346]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4439478836989865		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 1.4439478836989865 | validation: 1.0653121534169174]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6646455349206586		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 1.6646455349206586 | validation: 1.1290123723706649]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4736810270252054		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.4736810270252054 | validation: 1.2528659317448085]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5885589341147006		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.5885589341147006 | validation: 1.0345389222741037]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.770979732669205		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 1.770979732669205 | validation: 1.0613541124699546]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5117493707915928		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.5117493707915928 | validation: 1.0460644199568274]
	TIME [epoch: 11.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4561968777479142		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 1.4561968777479142 | validation: 1.1953115470511273]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.47880552201872		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 1.47880552201872 | validation: 1.077100787779722]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5155753098053875		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 1.5155753098053875 | validation: 1.0111660568595624]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5326355037711685		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 1.5326355037711685 | validation: 1.0792529890431417]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6998069752774085		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.6998069752774085 | validation: 1.068121093511186]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4724197230148395		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 1.4724197230148395 | validation: 1.0651817436838424]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4849981672309123		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 1.4849981672309123 | validation: 1.1018076889922992]
	TIME [epoch: 11.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5903546921616456		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 1.5903546921616456 | validation: 1.1870664713770713]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5806562213021964		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 1.5806562213021964 | validation: 1.0481988432329161]
	TIME [epoch: 11.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.529996597213744		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 1.529996597213744 | validation: 1.0122974025978062]
	TIME [epoch: 11.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5264360164746653		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 1.5264360164746653 | validation: 1.0377971608221135]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5302142634038451		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 1.5302142634038451 | validation: 1.0732926697088232]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4729506775842605		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 1.4729506775842605 | validation: 1.1477338754527695]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4874883984884386		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 1.4874883984884386 | validation: 1.0330918259005126]
	TIME [epoch: 11.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5511839615390544		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 1.5511839615390544 | validation: 1.088905227726934]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5917365605832323		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 1.5917365605832323 | validation: 1.189483144651094]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4879283879733696		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 1.4879283879733696 | validation: 1.2084271112858875]
	TIME [epoch: 11.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.52227278689388		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 1.52227278689388 | validation: 1.048619168002824]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4692835014289052		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 1.4692835014289052 | validation: 1.4006465772258025]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6218758202202415		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 1.6218758202202415 | validation: 1.6387212926109664]
	TIME [epoch: 11.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6238472509282396		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 1.6238472509282396 | validation: 1.2665666164371774]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.54830997144746		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.54830997144746 | validation: 1.3146727698988088]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5272139024049602		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 1.5272139024049602 | validation: 1.0416893781207583]
	TIME [epoch: 11.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4582358845923096		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 1.4582358845923096 | validation: 1.0313497107640128]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6074953912907595		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 1.6074953912907595 | validation: 1.131720042717367]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4523952986751676		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 1.4523952986751676 | validation: 1.0782883343168694]
	TIME [epoch: 11.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5192718844244366		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.5192718844244366 | validation: 1.019310170174316]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4898252426016931		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 1.4898252426016931 | validation: 1.0956726629435547]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5401465729985162		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.5401465729985162 | validation: 1.2317201945260612]
	TIME [epoch: 11.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.479313495514119		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 1.479313495514119 | validation: 1.2888301694844706]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.545529796621091		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 1.545529796621091 | validation: 1.0998344992785751]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5326955860106177		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 1.5326955860106177 | validation: 1.1480076498450618]
	TIME [epoch: 11.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4806501325708321		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 1.4806501325708321 | validation: 1.0485155784652318]
	TIME [epoch: 11.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.482192576703297		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 1.482192576703297 | validation: 1.2741341881518247]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5245264675648835		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 1.5245264675648835 | validation: 1.2119602254421127]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5286033286333895		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 1.5286033286333895 | validation: 1.0570829700445739]
	TIME [epoch: 11.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.501610466018989		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 1.501610466018989 | validation: 1.3854885167580506]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5244727701223275		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.5244727701223275 | validation: 1.063246746983018]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4731012375626433		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.4731012375626433 | validation: 1.1166268222670062]
	TIME [epoch: 11.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4629939168479418		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.4629939168479418 | validation: 1.15728111662765]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6052852225836092		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 1.6052852225836092 | validation: 1.009011233002327]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.550469572855166		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 1.550469572855166 | validation: 1.137697122392147]
	TIME [epoch: 11.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4856325395124552		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.4856325395124552 | validation: 1.0130596950311903]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5800070010333083		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.5800070010333083 | validation: 1.1502784410244633]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5221006350705744		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 1.5221006350705744 | validation: 1.012239440550528]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4567936934020185		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 1.4567936934020185 | validation: 1.2687693892431595]
	TIME [epoch: 11.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5264554404941109		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.5264554404941109 | validation: 0.9768130267543765]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6060437224867452		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.6060437224867452 | validation: 1.0306814291421498]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5611726899975338		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 1.5611726899975338 | validation: 1.013281959356433]
	TIME [epoch: 11.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.459850634263988		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 1.459850634263988 | validation: 1.2689518627985634]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.529898029333464		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 1.529898029333464 | validation: 1.112336125730949]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4561433989280048		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 1.4561433989280048 | validation: 1.0065979057584094]
	TIME [epoch: 11.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4374664547695006		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 1.4374664547695006 | validation: 1.0477073325591635]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.516923213238376		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 1.516923213238376 | validation: 0.9982082618766478]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4594024279336053		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 1.4594024279336053 | validation: 1.093647821100404]
	TIME [epoch: 11.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.494291454043612		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 1.494291454043612 | validation: 0.9876571283033825]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.432659307651189		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 1.432659307651189 | validation: 0.9618654235208698]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.501420964857339		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 1.501420964857339 | validation: 0.9916554182150202]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4644584941405359		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 1.4644584941405359 | validation: 0.9820203469768468]
	TIME [epoch: 11.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4893261367267951		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 1.4893261367267951 | validation: 1.1015081172769294]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4994134529992076		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 1.4994134529992076 | validation: 1.043222131391154]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5929012980121429		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 1.5929012980121429 | validation: 1.0849397189358265]
	TIME [epoch: 11.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4587667637339792		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.4587667637339792 | validation: 0.9914397327429287]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4447956698052926		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 1.4447956698052926 | validation: 1.0388859033944016]
	TIME [epoch: 11.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4228175613145004		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 1.4228175613145004 | validation: 1.2535070391443988]
	TIME [epoch: 11.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4645563968501296		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 1.4645563968501296 | validation: 1.0357799844228697]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.533293816579941		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 1.533293816579941 | validation: 1.0006094850460086]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5500468318114198		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 1.5500468318114198 | validation: 1.2075025085353885]
	TIME [epoch: 11.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4549530809309599		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 1.4549530809309599 | validation: 0.9832055551862459]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4480938362462368		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 1.4480938362462368 | validation: 1.6171199124507842]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6649822630099944		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 1.6649822630099944 | validation: 1.0657512881697957]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.415761336743703		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 1.415761336743703 | validation: 1.0887962663753914]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4454403422532638		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 1.4454403422532638 | validation: 0.9935019926919931]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.427578073466074		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 1.427578073466074 | validation: 1.0007450247939615]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4506407709913		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 1.4506407709913 | validation: 1.266089080654884]
	TIME [epoch: 11.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4995473553077008		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 1.4995473553077008 | validation: 1.3093305674302633]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5375532770732168		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 1.5375532770732168 | validation: 1.063180956847289]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.439722956206828		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 1.439722956206828 | validation: 1.076673766272508]
	TIME [epoch: 11.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.422742654227246		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 1.422742654227246 | validation: 0.9760154022258466]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4208078455812976		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 1.4208078455812976 | validation: 1.0149656560869076]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4367800197483593		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 1.4367800197483593 | validation: 1.1471047345006917]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4594415700550951		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 1.4594415700550951 | validation: 0.9972287066801451]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.462807776551598		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.462807776551598 | validation: 1.0080895613779455]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4959884005222375		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 1.4959884005222375 | validation: 1.0527830414501969]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4130218801396408		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.4130218801396408 | validation: 1.0309643468159735]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4207971751539203		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 1.4207971751539203 | validation: 1.0488190933320067]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4260995320515777		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 1.4260995320515777 | validation: 1.0676006920854588]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4128334620176943		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 1.4128334620176943 | validation: 0.984611596769158]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.447870528360594		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 1.447870528360594 | validation: 1.0089513324278911]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5984443686072827		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 1.5984443686072827 | validation: 1.369281991176166]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.525903152037127		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 1.525903152037127 | validation: 1.0169392622651074]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.509151869544328		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 1.509151869544328 | validation: 1.1384840821593392]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4861379159057577		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 1.4861379159057577 | validation: 0.9960138277939007]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4251904872840695		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 1.4251904872840695 | validation: 1.100579556867287]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4665973905971719		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 1.4665973905971719 | validation: 1.0441467760480003]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.418772799712365		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 1.418772799712365 | validation: 1.0062526663813278]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4297256202176134		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 1.4297256202176134 | validation: 1.1405506505180014]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4545184473246444		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 1.4545184473246444 | validation: 0.9527189350358728]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_699.pth
	Model improved!!!
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3807194434121965		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 1.3807194434121965 | validation: 0.9839504606089944]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4519520443869878		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 1.4519520443869878 | validation: 1.0254026052463052]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4240896063657742		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 1.4240896063657742 | validation: 1.1828748628346017]
	TIME [epoch: 11.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5125811245334497		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 1.5125811245334497 | validation: 0.993976746650814]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.409557969618077		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 1.409557969618077 | validation: 1.0713807352197313]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4395104279157702		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 1.4395104279157702 | validation: 0.9910128060549354]
	TIME [epoch: 11.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4335798764211451		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 1.4335798764211451 | validation: 1.0676215463086554]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4290490217394476		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 1.4290490217394476 | validation: 1.0783872670189636]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4333379542353935		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 1.4333379542353935 | validation: 0.9598088182695047]
	TIME [epoch: 11.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.424039358252665		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 1.424039358252665 | validation: 1.0764103444838584]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.451280762676162		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 1.451280762676162 | validation: 1.0035714985639173]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6366577300623284		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 1.6366577300623284 | validation: 0.9798765778473708]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4538997417910258		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 1.4538997417910258 | validation: 0.9659350037134291]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3919447548507364		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 1.3919447548507364 | validation: 1.095116920798821]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4488332890069073		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 1.4488332890069073 | validation: 1.402869268599252]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.500523231904813		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 1.500523231904813 | validation: 1.0801653414759826]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4304556210189543		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 1.4304556210189543 | validation: 0.9745309798481878]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4073663630764264		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 1.4073663630764264 | validation: 1.1785976521405301]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4301267936408957		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 1.4301267936408957 | validation: 1.1188043510940122]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4610613532444547		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 1.4610613532444547 | validation: 1.2996294980333656]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5016566358762924		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 1.5016566358762924 | validation: 1.0894701104371274]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4076339593800251		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 1.4076339593800251 | validation: 1.1628938519172936]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4938351574927826		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 1.4938351574927826 | validation: 1.063421957379219]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.415675841826604		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 1.415675841826604 | validation: 1.1212348289197647]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4847250988024694		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 1.4847250988024694 | validation: 1.2973122672097677]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4732733134205955		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 1.4732733134205955 | validation: 1.177658831731448]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4602775101407477		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 1.4602775101407477 | validation: 0.9514605563834329]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4134800522785276		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 1.4134800522785276 | validation: 0.9860811830075767]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4095492928965965		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 1.4095492928965965 | validation: 0.9820673524482655]
	TIME [epoch: 11.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3996784210770155		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 1.3996784210770155 | validation: 1.127194351070881]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4719391019728172		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 1.4719391019728172 | validation: 1.077294237597867]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4347547633729745		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 1.4347547633729745 | validation: 1.2331449219256863]
	TIME [epoch: 11.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4489566972786077		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 1.4489566972786077 | validation: 1.0533314759193595]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3896629916663625		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 1.3896629916663625 | validation: 0.9741323567635383]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4018840066410707		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 1.4018840066410707 | validation: 1.057666998483454]
	TIME [epoch: 11.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4936243546482588		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 1.4936243546482588 | validation: 1.0176339261895708]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.478480301066571		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 1.478480301066571 | validation: 0.9648194542030076]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.411258220935422		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 1.411258220935422 | validation: 0.9314560616852191]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_737.pth
	Model improved!!!
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.40561089269459		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 1.40561089269459 | validation: 0.9774917648237282]
	TIME [epoch: 11.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4290058060460016		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 1.4290058060460016 | validation: 1.0385955124163961]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4082432715710411		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 1.4082432715710411 | validation: 1.0955954544564401]
	TIME [epoch: 11.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4307166976616825		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 1.4307166976616825 | validation: 0.9622570277652429]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3474648539668634		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 1.3474648539668634 | validation: 1.0631750266790443]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5012556389703535		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 1.5012556389703535 | validation: 1.0230490332603583]
	TIME [epoch: 11.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3924040255854595		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 1.3924040255854595 | validation: 1.1604562754632033]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4823531195728887		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 1.4823531195728887 | validation: 0.9906342820189258]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.398225612562939		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 1.398225612562939 | validation: 0.9445062723611107]
	TIME [epoch: 11.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.391432573825909		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 1.391432573825909 | validation: 0.9436208628820688]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3988094930886092		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 1.3988094930886092 | validation: 0.9317422636101157]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4105265827911506		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 1.4105265827911506 | validation: 0.9715901403561772]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4166542843108636		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 1.4166542843108636 | validation: 0.9395612157178765]
	TIME [epoch: 11.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.39575530674212		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 1.39575530674212 | validation: 1.0264633968594339]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4524724103094924		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 1.4524724103094924 | validation: 1.1244995296151528]
	TIME [epoch: 11.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4160292471080027		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 1.4160292471080027 | validation: 1.0016021889538036]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3992207902215799		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 1.3992207902215799 | validation: 1.036622016308505]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.438703291694305		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 1.438703291694305 | validation: 1.0686465103728144]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4781292708797853		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 1.4781292708797853 | validation: 0.9779906386001577]
	TIME [epoch: 11.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4705871715579426		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 1.4705871715579426 | validation: 1.0844220812212475]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4217175043237325		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 1.4217175043237325 | validation: 1.104617123737253]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.434622873510362		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 1.434622873510362 | validation: 1.0044418580356669]
	TIME [epoch: 11.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4115031246978216		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 1.4115031246978216 | validation: 1.2200779107755506]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4915797536419881		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 1.4915797536419881 | validation: 1.0256200942186715]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4443382287363213		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 1.4443382287363213 | validation: 1.027916302504032]
	TIME [epoch: 11.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4164240726518098		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 1.4164240726518098 | validation: 1.025130212017524]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3823412459482782		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 1.3823412459482782 | validation: 1.0866291691336525]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3955254852843975		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 1.3955254852843975 | validation: 0.9523326226310113]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3817053381543514		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 1.3817053381543514 | validation: 0.9475437144960543]
	TIME [epoch: 11.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4602446146227401		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 1.4602446146227401 | validation: 0.935560127248383]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3587908100153427		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 1.3587908100153427 | validation: 1.043291290886831]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4145417041798074		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 1.4145417041798074 | validation: 1.0568624723393645]
	TIME [epoch: 11.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4166259043431768		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 1.4166259043431768 | validation: 1.0269772866142073]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4800211112671193		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 1.4800211112671193 | validation: 0.9635722608028304]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3841183692675694		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 1.3841183692675694 | validation: 1.0232708703438538]
	TIME [epoch: 11.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.411625784835475		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 1.411625784835475 | validation: 1.037650015385203]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3742766041438745		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 1.3742766041438745 | validation: 0.9442631688168885]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4193122722960883		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 1.4193122722960883 | validation: 0.9122753021937109]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_775.pth
	Model improved!!!
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.461428234312824		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 1.461428234312824 | validation: 1.1349708985860234]
	TIME [epoch: 11.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.418535279257282		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 1.418535279257282 | validation: 1.1841798033249484]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4233496654855762		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 1.4233496654855762 | validation: 0.9513336707876328]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3957873299303847		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 1.3957873299303847 | validation: 1.0074592678704632]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.368452077557484		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 1.368452077557484 | validation: 1.0194579671463289]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3644918336162009		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 1.3644918336162009 | validation: 0.9307120777152683]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4988878109624482		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 1.4988878109624482 | validation: 1.2267597270874355]
	TIME [epoch: 11.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.418283700215362		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 1.418283700215362 | validation: 1.0418033521818892]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4018133883238677		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 1.4018133883238677 | validation: 0.9573956821986883]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3543985115430428		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 1.3543985115430428 | validation: 0.9370291836610056]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3893732148200055		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 1.3893732148200055 | validation: 1.3543412643917965]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4776269379830027		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 1.4776269379830027 | validation: 0.9359475647992619]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4128862719004454		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 1.4128862719004454 | validation: 0.9927937954145619]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4113252179525468		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 1.4113252179525468 | validation: 0.9347993995096949]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.367682437494066		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 1.367682437494066 | validation: 0.9831631364559946]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3998892215102177		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 1.3998892215102177 | validation: 1.0110802364452272]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3901848762038411		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 1.3901848762038411 | validation: 0.9345287246493575]
	TIME [epoch: 11.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.379306908264134		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 1.379306908264134 | validation: 0.976509742708583]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3743024034248443		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 1.3743024034248443 | validation: 1.007126722978516]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.589285648954979		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 1.589285648954979 | validation: 0.9737312828415433]
	TIME [epoch: 11.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3860438772300248		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 1.3860438772300248 | validation: 0.9640168792182644]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4010174814681338		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 1.4010174814681338 | validation: 1.0417898544340138]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4210763109998248		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 1.4210763109998248 | validation: 0.9799794120023851]
	TIME [epoch: 11.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4515267617296177		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 1.4515267617296177 | validation: 1.0044325992365521]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3940506117667117		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 1.3940506117667117 | validation: 0.9116407883903263]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_800.pth
	Model improved!!!
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.385556129744839		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 1.385556129744839 | validation: 0.9591709075545037]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4230634736603167		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 1.4230634736603167 | validation: 0.9653207726241152]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3905224151743678		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 1.3905224151743678 | validation: 0.9673548591710267]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4161176454595759		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 1.4161176454595759 | validation: 0.9847788421817106]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.364017613627977		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 1.364017613627977 | validation: 1.0476039873422593]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4648748539115302		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 1.4648748539115302 | validation: 0.9684455730495947]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3860001974030136		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 1.3860001974030136 | validation: 0.9592361513415746]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4285522418046719		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 1.4285522418046719 | validation: 0.9247607314885707]
	TIME [epoch: 11.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3788287094475278		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 1.3788287094475278 | validation: 0.9580839529984774]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3700192629064722		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 1.3700192629064722 | validation: 1.0533364300567316]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3974220206827692		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 1.3974220206827692 | validation: 0.992826828059126]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4304398583856015		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 1.4304398583856015 | validation: 0.9373511537665927]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.40403319048921		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 1.40403319048921 | validation: 1.0379928778506906]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3865657455381095		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 1.3865657455381095 | validation: 1.034016522377256]
	TIME [epoch: 11.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4113819438912831		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 1.4113819438912831 | validation: 1.0409244574248226]
	TIME [epoch: 11.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3756116396175744		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 1.3756116396175744 | validation: 0.9255639129076354]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4238429351757804		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 1.4238429351757804 | validation: 0.9320394424288708]
	TIME [epoch: 11.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3953533758335597		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 1.3953533758335597 | validation: 0.9801692055412354]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4218157560016758		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 1.4218157560016758 | validation: 0.9622247402339169]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3764505428799847		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 1.3764505428799847 | validation: 1.031893725494131]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4020191698041407		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 1.4020191698041407 | validation: 0.9352164735518474]
	TIME [epoch: 11.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3939727386677867		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 1.3939727386677867 | validation: 1.0122002266292203]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4165645421360697		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 1.4165645421360697 | validation: 0.9278306013244385]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4067452596762295		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 1.4067452596762295 | validation: 0.9650232426855344]
	TIME [epoch: 11.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3698364915133776		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 1.3698364915133776 | validation: 0.9364363496104413]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3961573760928196		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 1.3961573760928196 | validation: 1.0176383794483035]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4109576017324443		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 1.4109576017324443 | validation: 0.9921784027710342]
	TIME [epoch: 11.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4654667699055355		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 1.4654667699055355 | validation: 0.9863843035744796]
	TIME [epoch: 11.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3992213501313575		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 1.3992213501313575 | validation: 1.0636828888114753]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.441875255871852		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 1.441875255871852 | validation: 0.9857395434707985]
	TIME [epoch: 11.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3728547394901425		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 1.3728547394901425 | validation: 0.9978284204719698]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3774091058967481		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 1.3774091058967481 | validation: 0.9790312395790959]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3966479829099334		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 1.3966479829099334 | validation: 0.9334943023240889]
	TIME [epoch: 11.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5747397461450259		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 1.5747397461450259 | validation: 0.9333880794514358]
	TIME [epoch: 11.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.395629558926892		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 1.395629558926892 | validation: 0.9456149492041837]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4072052838478184		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 1.4072052838478184 | validation: 0.9384165014917011]
	TIME [epoch: 11.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3764187166661128		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 1.3764187166661128 | validation: 0.9114156172449471]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3995901840760165		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 1.3995901840760165 | validation: 0.9265802797677174]
	TIME [epoch: 11.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3615209726876183		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 1.3615209726876183 | validation: 1.0410097924883892]
	TIME [epoch: 11.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3796060471531169		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 1.3796060471531169 | validation: 0.9548943776450445]
	TIME [epoch: 11.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4670090924684527		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 1.4670090924684527 | validation: 0.9393488844520798]
	TIME [epoch: 11.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3991779809757363		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 1.3991779809757363 | validation: 1.2665029675610076]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5200135965022625		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 1.5200135965022625 | validation: 0.9272882275828414]
	TIME [epoch: 11.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.356039516223591		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 1.356039516223591 | validation: 0.9612836510981615]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.378325626371523		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 1.378325626371523 | validation: 0.9655705162205794]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.384306450728508		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 1.384306450728508 | validation: 0.9368739612679642]
	TIME [epoch: 11.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.338828254538127		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 1.338828254538127 | validation: 0.9177627704090972]
	TIME [epoch: 11.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3412401811155832		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 1.3412401811155832 | validation: 0.9176036687900859]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.401482083839423		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 1.401482083839423 | validation: 0.953811083436741]
	TIME [epoch: 11.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3335953408177172		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 1.3335953408177172 | validation: 0.9292512494046921]
	TIME [epoch: 11.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3408154582958038		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 1.3408154582958038 | validation: 0.964760571161543]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.354266082557045		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 1.354266082557045 | validation: 0.9195218933927035]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3252977047067074		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 1.3252977047067074 | validation: 1.0240054422125355]
	TIME [epoch: 11.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3375885741639904		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 1.3375885741639904 | validation: 0.9669524044631658]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3781767619260532		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 1.3781767619260532 | validation: 0.9784296473008081]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3611117420657137		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 1.3611117420657137 | validation: 0.9706383218589417]
	TIME [epoch: 11.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.332481495757393		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 1.332481495757393 | validation: 0.9015630885801362]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_857.pth
	Model improved!!!
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3259008744682825		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 1.3259008744682825 | validation: 1.0269490137074364]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3557196705067722		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 1.3557196705067722 | validation: 0.9254238348750424]
	TIME [epoch: 11.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.321997513205753		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 1.321997513205753 | validation: 0.9139029215094913]
	TIME [epoch: 11.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3167537372203473		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 1.3167537372203473 | validation: 0.9432581570771782]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3247287698629422		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 1.3247287698629422 | validation: 0.9498703336622399]
	TIME [epoch: 11.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3695428140675416		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 1.3695428140675416 | validation: 0.934459980451754]
	TIME [epoch: 11.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.344607104984225		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 1.344607104984225 | validation: 0.9889348654695956]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3418725521729424		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 1.3418725521729424 | validation: 0.9443196173505376]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3451240622858402		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 1.3451240622858402 | validation: 0.9065763713154334]
	TIME [epoch: 11.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3258807363275962		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 1.3258807363275962 | validation: 0.8920429028542691]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3175761301306423		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 1.3175761301306423 | validation: 1.0124925852189686]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.345034606145074		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 1.345034606145074 | validation: 0.9294772803325506]
	TIME [epoch: 11.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3113554552265059		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 1.3113554552265059 | validation: 0.9272156268018549]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3148137985769996		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 1.3148137985769996 | validation: 1.0029258113837503]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3592168778825195		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 1.3592168778825195 | validation: 0.9369800430879889]
	TIME [epoch: 11.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3267472146886403		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 1.3267472146886403 | validation: 1.1463034878340546]
	TIME [epoch: 11.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3979009016745103		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 1.3979009016745103 | validation: 0.9480914208050915]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3715837305521725		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 1.3715837305521725 | validation: 0.9367129756442346]
	TIME [epoch: 11.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.304878318014571		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 1.304878318014571 | validation: 0.9248952597755263]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3651745013310923		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 1.3651745013310923 | validation: 0.907763906693651]
	TIME [epoch: 11.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3220048391191832		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 1.3220048391191832 | validation: 0.9263673906718802]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.311946467134161		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 1.311946467134161 | validation: 0.982366656969947]
	TIME [epoch: 11.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3074149021788974		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 1.3074149021788974 | validation: 0.9259009207676351]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3135347280095528		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 1.3135347280095528 | validation: 0.951578095326158]
	TIME [epoch: 11.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2875405998420968		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 1.2875405998420968 | validation: 0.9450989583739019]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3082742456994014		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 1.3082742456994014 | validation: 0.9309987124559203]
	TIME [epoch: 11.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3479400744497616		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 1.3479400744497616 | validation: 0.9727082544703598]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2937899472647016		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 1.2937899472647016 | validation: 0.9172191767415693]
	TIME [epoch: 11.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.302947124732102		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 1.302947124732102 | validation: 0.9677340173797006]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.299490382804807		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 1.299490382804807 | validation: 0.9149253055844249]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3082084436511248		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 1.3082084436511248 | validation: 0.9303659281449942]
	TIME [epoch: 11.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.284220698226528		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 1.284220698226528 | validation: 0.9347050840618224]
	TIME [epoch: 11.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2842582279626982		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 1.2842582279626982 | validation: 0.9285004881109804]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2467562215078614		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 1.2467562215078614 | validation: 0.9340045692181073]
	TIME [epoch: 11.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2490339349622595		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 1.2490339349622595 | validation: 1.0642467102795545]
	TIME [epoch: 11.6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257534004947166		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 1.257534004947166 | validation: 1.0388394550356548]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2704960968997783		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 1.2704960968997783 | validation: 0.9069358861992833]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2239912885218158		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 1.2239912885218158 | validation: 0.9697423398559296]
	TIME [epoch: 11.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2409570339604419		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 1.2409570339604419 | validation: 0.9004064501209897]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2867974362987575		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 1.2867974362987575 | validation: 1.0245669084601083]
	TIME [epoch: 11.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2814246349017977		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 1.2814246349017977 | validation: 0.8923522790105821]
	TIME [epoch: 11.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1908480473279897		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 1.1908480473279897 | validation: 0.9640498545967782]
	TIME [epoch: 11.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2131552582349074		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 1.2131552582349074 | validation: 0.8978044452386327]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2098177131764958		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 1.2098177131764958 | validation: 0.8981416960251434]
	TIME [epoch: 11.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1984330666665683		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 1.1984330666665683 | validation: 0.8878486942735472]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_902.pth
	Model improved!!!
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1516043912406908		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 1.1516043912406908 | validation: 0.8780509429342956]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_903.pth
	Model improved!!!
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1090590034764702		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 1.1090590034764702 | validation: 0.8788129364948583]
	TIME [epoch: 11.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0856779153034932		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 1.0856779153034932 | validation: 0.8891526766465774]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0577150775451423		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 1.0577150775451423 | validation: 0.8497184787707639]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_906.pth
	Model improved!!!
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020533057074616		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 1.020533057074616 | validation: 0.8188315961057886]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_907.pth
	Model improved!!!
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0075155533990408		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 1.0075155533990408 | validation: 0.8075329289597193]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_908.pth
	Model improved!!!
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9419371398811208		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.9419371398811208 | validation: 0.8163040281085452]
	TIME [epoch: 11.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9866700547714561		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.9866700547714561 | validation: 0.8664826289968519]
	TIME [epoch: 11.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9612883126520366		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.9612883126520366 | validation: 0.8732896908054465]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9491207958356148		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.9491207958356148 | validation: 0.9096759608279955]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9744761986224513		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.9744761986224513 | validation: 0.8023646382579316]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_913.pth
	Model improved!!!
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9600271142575223		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.9600271142575223 | validation: 0.7657586262635746]
	TIME [epoch: 11.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_914.pth
	Model improved!!!
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8953423230687069		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.8953423230687069 | validation: 0.8039299790268797]
	TIME [epoch: 11.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9124234200372406		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.9124234200372406 | validation: 0.7582564311492668]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_916.pth
	Model improved!!!
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9275142308980627		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.9275142308980627 | validation: 0.7625456237408414]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9216331035952404		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.9216331035952404 | validation: 1.040392967313047]
	TIME [epoch: 11.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9786535593029286		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.9786535593029286 | validation: 0.9285180566838612]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.974756634525971		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.974756634525971 | validation: 0.7704844047609549]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9274820133600686		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.9274820133600686 | validation: 0.8163253327746958]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.899101232284865		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.899101232284865 | validation: 0.771372548955477]
	TIME [epoch: 11.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.917810275267622		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.917810275267622 | validation: 0.7959864105532605]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9573606589024972		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.9573606589024972 | validation: 0.9254160716689995]
	TIME [epoch: 11.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9208175830001887		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.9208175830001887 | validation: 0.7469735544831665]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_925.pth
	Model improved!!!
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9521228526145152		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.9521228526145152 | validation: 0.7434894710511745]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_926.pth
	Model improved!!!
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9195761952078434		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.9195761952078434 | validation: 0.7916883583688704]
	TIME [epoch: 11.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9509309699909364		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.9509309699909364 | validation: 0.8309706079364088]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9131051393750413		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.9131051393750413 | validation: 0.761108928922182]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.936170899807049		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.936170899807049 | validation: 0.7542232776442986]
	TIME [epoch: 11.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.903558253803068		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.903558253803068 | validation: 0.7539953171435148]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9189463774556055		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.9189463774556055 | validation: 0.8465178509374357]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9131228822628119		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.9131228822628119 | validation: 0.7852623853619705]
	TIME [epoch: 11.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9562540607256516		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.9562540607256516 | validation: 0.8234084659944321]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9533646535099705		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.9533646535099705 | validation: 0.7961623544607542]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9142265840026549		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.9142265840026549 | validation: 1.1474538733845798]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0093577364946875		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 1.0093577364946875 | validation: 0.7388416509211747]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_937.pth
	Model improved!!!
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9087105977875832		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.9087105977875832 | validation: 0.7434897886903297]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.894773663704005		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.894773663704005 | validation: 0.9030343769187557]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9328620469935157		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.9328620469935157 | validation: 0.8713733681026183]
	TIME [epoch: 11.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9392073546314426		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.9392073546314426 | validation: 0.7796607752584092]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8927480060541799		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.8927480060541799 | validation: 0.812774700180275]
	TIME [epoch: 11.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9254182281468204		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.9254182281468204 | validation: 0.995114271626178]
	TIME [epoch: 11.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9916908764424425		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.9916908764424425 | validation: 0.7398563869057327]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8917705238533226		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.8917705238533226 | validation: 0.7372183942940768]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_945.pth
	Model improved!!!
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8999992365774174		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.8999992365774174 | validation: 0.7919025112808741]
	TIME [epoch: 11.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9439487028334661		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.9439487028334661 | validation: 0.7348162857676478]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_947.pth
	Model improved!!!
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9454735632542851		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.9454735632542851 | validation: 0.970773829726456]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9467777016067783		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.9467777016067783 | validation: 0.7429647956119174]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8881136719883282		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.8881136719883282 | validation: 0.725075830363806]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_950.pth
	Model improved!!!
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.887950426093544		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.887950426093544 | validation: 0.8248676055593503]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9196538897169126		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.9196538897169126 | validation: 0.7315180700119305]
	TIME [epoch: 11.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.911785456670986		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.911785456670986 | validation: 0.7651906463629016]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8718831971547945		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.8718831971547945 | validation: 0.7236948096862372]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_954.pth
	Model improved!!!
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8759136903014648		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.8759136903014648 | validation: 0.713737980827952]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_955.pth
	Model improved!!!
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8698543566555994		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.8698543566555994 | validation: 0.7631449200725137]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9306327309445847		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.9306327309445847 | validation: 0.7475329228535443]
	TIME [epoch: 11.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.869349655878517		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.869349655878517 | validation: 0.7190773880454423]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90038568028204		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.90038568028204 | validation: 0.7473753232091626]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8737362964598893		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.8737362964598893 | validation: 0.7239099161776088]
	TIME [epoch: 11.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8866696833450627		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.8866696833450627 | validation: 0.7749905265461001]
	TIME [epoch: 11.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9200369488782361		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.9200369488782361 | validation: 0.7295645232983907]
	TIME [epoch: 11.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.865516744295405		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.865516744295405 | validation: 0.7980051698284407]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8802995361379309		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.8802995361379309 | validation: 0.7499414466932113]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8832496424943539		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.8832496424943539 | validation: 0.7313283116650651]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8922004559416155		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.8922004559416155 | validation: 0.8063115224045896]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.882982431925303		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.882982431925303 | validation: 0.8306598005938736]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.904092952714898		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.904092952714898 | validation: 0.7877893367707793]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9294032944956405		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.9294032944956405 | validation: 0.7396352253066698]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8686753620056586		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.8686753620056586 | validation: 0.7358663508926944]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.865638201458921		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.865638201458921 | validation: 0.697583352396303]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_971.pth
	Model improved!!!
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8578244242277091		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.8578244242277091 | validation: 0.7704594617067188]
	TIME [epoch: 11.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8783647181328018		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.8783647181328018 | validation: 0.7826583816152599]
	TIME [epoch: 11.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8794385957439779		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.8794385957439779 | validation: 0.732282530375184]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8726401778718474		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.8726401778718474 | validation: 0.8140344149626154]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8861894259393363		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.8861894259393363 | validation: 0.7096766905213948]
	TIME [epoch: 11.6 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8647931780311602		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.8647931780311602 | validation: 0.7404044524066071]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8679192901595395		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.8679192901595395 | validation: 0.7037986355540673]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8612246181606755		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.8612246181606755 | validation: 0.7060936142907924]
	TIME [epoch: 11.6 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8514562128721814		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.8514562128721814 | validation: 0.723456950965007]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8900788796559214		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.8900788796559214 | validation: 0.7260834360367361]
	TIME [epoch: 11.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866945017471678		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.866945017471678 | validation: 0.7162446322594227]
	TIME [epoch: 11.6 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8563293335114726		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.8563293335114726 | validation: 0.7022097124839369]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8761531729159069		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.8761531729159069 | validation: 0.6907968760318386]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_984.pth
	Model improved!!!
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8550630406596234		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.8550630406596234 | validation: 0.7134432183586042]
	TIME [epoch: 11.6 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8577325997825597		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.8577325997825597 | validation: 0.7349613768645492]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8696816326643398		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.8696816326643398 | validation: 0.7410908560124926]
	TIME [epoch: 11.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8800875334944194		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.8800875334944194 | validation: 0.7122745888720611]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8920547454791008		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.8920547454791008 | validation: 0.8749859829434966]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.88179359515276		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.88179359515276 | validation: 0.7145024979967457]
	TIME [epoch: 11.6 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8711087942686427		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.8711087942686427 | validation: 0.6911472639933647]
	TIME [epoch: 11.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8471007637024441		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.8471007637024441 | validation: 0.7169875955876225]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8468647996951083		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.8468647996951083 | validation: 0.6925404870648063]
	TIME [epoch: 11.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8608825760895218		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.8608825760895218 | validation: 0.7218218122874782]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8537762853634644		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.8537762853634644 | validation: 0.7444820087396917]
	TIME [epoch: 11.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8695519223103548		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.8695519223103548 | validation: 0.6976210905258592]
	TIME [epoch: 11.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8500238218107812		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.8500238218107812 | validation: 0.733562205404886]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8707875592617831		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.8707875592617831 | validation: 0.7173878181703873]
	TIME [epoch: 11.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8749804055253679		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.8749804055253679 | validation: 0.7194997021813088]
	TIME [epoch: 11.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.868137457118317		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.868137457118317 | validation: 0.7134167231853019]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8483858141881696		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.8483858141881696 | validation: 0.7240117273605787]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8430787171764941		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.8430787171764941 | validation: 0.7176930739163961]
	TIME [epoch: 11.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8396114515145182		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.8396114515145182 | validation: 0.6915115045911158]
	TIME [epoch: 11.6 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8467195770145891		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.8467195770145891 | validation: 0.6881269767834646]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1004.pth
	Model improved!!!
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8461631626099917		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.8461631626099917 | validation: 0.7332861941567026]
	TIME [epoch: 11.6 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8549252715828003		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.8549252715828003 | validation: 0.6944888544287082]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8346295101129512		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.8346295101129512 | validation: 0.7276743731642804]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8781188869187013		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.8781188869187013 | validation: 0.7652888001749446]
	TIME [epoch: 11.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8573621286066666		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.8573621286066666 | validation: 0.776121595950336]
	TIME [epoch: 11.6 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.87215130782386		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.87215130782386 | validation: 0.6884259259886187]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.835217082800814		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.835217082800814 | validation: 0.6844595917664552]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1011.pth
	Model improved!!!
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8418422456999766		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.8418422456999766 | validation: 0.715822335542278]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8874675554287019		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.8874675554287019 | validation: 0.8155851475284651]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8579669940191397		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.8579669940191397 | validation: 0.7463853148173588]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8714901586093848		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.8714901586093848 | validation: 0.8409407427269914]
	TIME [epoch: 11.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8866514964161678		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.8866514964161678 | validation: 0.6847280919288642]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8789648952094086		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.8789648952094086 | validation: 0.7168102732432442]
	TIME [epoch: 11.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862552428169195		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.862552428169195 | validation: 0.864054477268401]
	TIME [epoch: 11.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8836049995826241		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.8836049995826241 | validation: 0.6773433550775443]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1019.pth
	Model improved!!!
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8676951096835475		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.8676951096835475 | validation: 0.7026761725461725]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8362446146516134		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.8362446146516134 | validation: 0.7015284149223107]
	TIME [epoch: 11.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8417749140763147		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.8417749140763147 | validation: 0.704945920131104]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8619419584393841		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.8619419584393841 | validation: 0.7049720337937154]
	TIME [epoch: 11.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8998034639702623		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.8998034639702623 | validation: 0.700237564406798]
	TIME [epoch: 11.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8433811698571223		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.8433811698571223 | validation: 0.7203295649465958]
	TIME [epoch: 11.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9413719390293889		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.9413719390293889 | validation: 0.7158538119872435]
	TIME [epoch: 11.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8511217430934169		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.8511217430934169 | validation: 0.6859957784028634]
	TIME [epoch: 11.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8275158564110716		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.8275158564110716 | validation: 0.7128640253485705]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8348913377318159		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.8348913377318159 | validation: 0.7393878981199792]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8462481581248641		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.8462481581248641 | validation: 0.6877240835523627]
	TIME [epoch: 11.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9014175842161396		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.9014175842161396 | validation: 0.7897601114750384]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8572862040576066		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.8572862040576066 | validation: 0.7025386090177816]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8306149752882815		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.8306149752882815 | validation: 0.707489234015776]
	TIME [epoch: 11.6 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8727895260819469		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.8727895260819469 | validation: 0.7331938920133795]
	TIME [epoch: 11.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8475284976281273		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.8475284976281273 | validation: 0.7134378752504642]
	TIME [epoch: 11.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8490051200224266		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.8490051200224266 | validation: 0.7141640747653751]
	TIME [epoch: 11.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.840260147767977		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.840260147767977 | validation: 0.6856126416021406]
	TIME [epoch: 11.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8439612843498687		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.8439612843498687 | validation: 0.6854376549891342]
	TIME [epoch: 11.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8351513867020753		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.8351513867020753 | validation: 0.7165055287488447]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8409261289287447		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.8409261289287447 | validation: 0.6804401081642718]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8663894842643032		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.8663894842643032 | validation: 0.7568427777259251]
	TIME [epoch: 11.6 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9086153685428557		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.9086153685428557 | validation: 0.7148996310779685]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8482020878120862		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.8482020878120862 | validation: 0.6783879673155506]
	TIME [epoch: 11.6 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8692399044614872		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.8692399044614872 | validation: 0.8049985894213327]
	TIME [epoch: 11.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862987716838658		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.862987716838658 | validation: 0.6733697222831694]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1045.pth
	Model improved!!!
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8524038913676681		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.8524038913676681 | validation: 0.6648139823726541]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1046.pth
	Model improved!!!
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8399179187616337		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.8399179187616337 | validation: 0.6862750251552171]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8355333092770187		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.8355333092770187 | validation: 0.6932528105392296]
	TIME [epoch: 11.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8326380901498467		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.8326380901498467 | validation: 0.6813413520002155]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.856509742718427		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.856509742718427 | validation: 0.687041036079176]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8307404190495882		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.8307404190495882 | validation: 0.8197788090663659]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8893862761404274		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.8893862761404274 | validation: 0.7105705011867156]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8398292208907242		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.8398292208907242 | validation: 0.7104380498437199]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8376237401916686		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.8376237401916686 | validation: 0.7025574028759352]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9273532319665532		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.9273532319665532 | validation: 0.7430220639072616]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8617957457530255		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.8617957457530255 | validation: 0.7478867613658684]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8351213233096411		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.8351213233096411 | validation: 0.6737804047212629]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8205062216682055		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.8205062216682055 | validation: 0.6842284082200518]
	TIME [epoch: 11.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8303109873430505		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.8303109873430505 | validation: 0.725494384617988]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8358397589234514		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.8358397589234514 | validation: 0.7154980693613383]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8439684627098304		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.8439684627098304 | validation: 0.7018955884792696]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8402172012903408		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.8402172012903408 | validation: 0.6799527880763483]
	TIME [epoch: 11.6 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8139064558836431		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.8139064558836431 | validation: 0.6752232483497229]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.816009029110167		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.816009029110167 | validation: 0.6898939886572478]
	TIME [epoch: 11.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8096196485430378		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.8096196485430378 | validation: 0.7388833795269929]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8525316178199102		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.8525316178199102 | validation: 0.8240902902326249]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8627272644504074		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.8627272644504074 | validation: 0.6793441790409283]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8153086617712555		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.8153086617712555 | validation: 0.7081900793151433]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8291221207609648		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.8291221207609648 | validation: 0.7285659859793009]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8414324928107484		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.8414324928107484 | validation: 0.6750971370154545]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8175623581455389		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.8175623581455389 | validation: 0.6709093697389189]
	TIME [epoch: 11.6 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8612777400546505		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.8612777400546505 | validation: 0.6544894815739923]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1072.pth
	Model improved!!!
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8098304774687276		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.8098304774687276 | validation: 0.7247713405932567]
	TIME [epoch: 11.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8064028013082031		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.8064028013082031 | validation: 0.6981532988357801]
	TIME [epoch: 11.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8201930563663108		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.8201930563663108 | validation: 0.6673237066358256]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8098060930333273		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.8098060930333273 | validation: 0.7420614077944189]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8304324964516585		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.8304324964516585 | validation: 0.6653603378644172]
	TIME [epoch: 11.6 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8117335593009043		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.8117335593009043 | validation: 0.6665319353679547]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8158894114038941		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.8158894114038941 | validation: 0.6742195857239236]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7993948708416643		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.7993948708416643 | validation: 0.6711591854833808]
	TIME [epoch: 11.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7956216210879037		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.7956216210879037 | validation: 0.6693471575239823]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8301154730085882		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.8301154730085882 | validation: 0.772375954055822]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8441461377578751		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.8441461377578751 | validation: 0.6797277074395665]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8195375698148133		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.8195375698148133 | validation: 0.684941487936633]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8119569122688892		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.8119569122688892 | validation: 0.7617750092385753]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8516359462130745		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.8516359462130745 | validation: 0.717911399383533]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8182983037253762		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.8182983037253762 | validation: 0.6815442146573658]
	TIME [epoch: 11.6 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8182825697305864		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.8182825697305864 | validation: 0.7242915398638582]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8335593618958351		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.8335593618958351 | validation: 0.7034675544867705]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8108754382831056		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.8108754382831056 | validation: 0.6992867281499778]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8244599890122306		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.8244599890122306 | validation: 0.7212340225563069]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8315201011779128		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.8315201011779128 | validation: 0.6931816561437814]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8259049670921832		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.8259049670921832 | validation: 0.7895018291744862]
	TIME [epoch: 11.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8321233171759187		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.8321233171759187 | validation: 0.6515010747337385]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1094.pth
	Model improved!!!
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8547421392025588		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.8547421392025588 | validation: 0.6854713639876299]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8055506412388875		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.8055506412388875 | validation: 0.6566315842177525]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8122323552102404		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.8122323552102404 | validation: 0.8773875888783007]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8935690094520814		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.8935690094520814 | validation: 0.6703351489898557]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8057224543042838		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.8057224543042838 | validation: 0.6600714924691198]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7931525895759128		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.7931525895759128 | validation: 0.6645377309489843]
	TIME [epoch: 11.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.796769784825874		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.796769784825874 | validation: 0.6823030403369574]
	TIME [epoch: 11.6 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8031367242309208		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.8031367242309208 | validation: 0.6854752045858229]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8039318655724756		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.8039318655724756 | validation: 0.6655175664534747]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8028424852765789		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.8028424852765789 | validation: 0.6802170639912498]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8617991146473094		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.8617991146473094 | validation: 0.693692971339718]
	TIME [epoch: 11.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.824287958451946		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.824287958451946 | validation: 0.688593914546262]
	TIME [epoch: 11.6 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8246897696419611		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.8246897696419611 | validation: 0.6476745862620835]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1107.pth
	Model improved!!!
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7949054297468042		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.7949054297468042 | validation: 0.6517826659926976]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8054246536843211		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.8054246536843211 | validation: 0.6479392693596984]
	TIME [epoch: 11.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7919218328670149		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.7919218328670149 | validation: 0.6911081039936464]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8424166263926619		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.8424166263926619 | validation: 0.7695150256248223]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8338806717491706		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.8338806717491706 | validation: 0.7051712961928485]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8094864705123437		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.8094864705123437 | validation: 0.70157716969442]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8077921493752847		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.8077921493752847 | validation: 0.6471026600309893]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1114.pth
	Model improved!!!
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8083511353015956		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.8083511353015956 | validation: 0.6564885970386084]
	TIME [epoch: 11.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7989788925535413		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.7989788925535413 | validation: 0.6486209613282496]
	TIME [epoch: 11.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8118051945731425		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.8118051945731425 | validation: 0.7119625619235234]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8181103632337483		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.8181103632337483 | validation: 0.6473159647381195]
	TIME [epoch: 11.6 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8135455697859276		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.8135455697859276 | validation: 0.6610327041123759]
	TIME [epoch: 11.6 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7883051404050145		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.7883051404050145 | validation: 0.6488973339127319]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8048436931850141		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.8048436931850141 | validation: 0.6638990695192846]
	TIME [epoch: 11.6 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8530430950874426		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.8530430950874426 | validation: 0.6503615825502688]
	TIME [epoch: 11.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8017511000837493		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.8017511000837493 | validation: 0.6458753432906025]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1123.pth
	Model improved!!!
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8002393637763265		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.8002393637763265 | validation: 0.6372275546626617]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1124.pth
	Model improved!!!
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8027260707697964		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.8027260707697964 | validation: 0.7056684126325612]
	TIME [epoch: 11.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7989640641962941		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.7989640641962941 | validation: 0.7170211558358068]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8167585776163631		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.8167585776163631 | validation: 0.6443533258854377]
	TIME [epoch: 11.6 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7871888619156693		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.7871888619156693 | validation: 0.6779722051326585]
	TIME [epoch: 11.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8464490275831025		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.8464490275831025 | validation: 0.6474002582277193]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7842498458976086		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.7842498458976086 | validation: 0.6573897601193199]
	TIME [epoch: 11.6 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7854876418850951		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.7854876418850951 | validation: 0.6511855187684253]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7843257603109782		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.7843257603109782 | validation: 0.6527523665672931]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7988231206353248		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.7988231206353248 | validation: 0.6884813026967715]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799140604504539		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.799140604504539 | validation: 0.6677131975179252]
	TIME [epoch: 11.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7899857891077219		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.7899857891077219 | validation: 0.6590828691668861]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7907340257887213		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.7907340257887213 | validation: 0.6462461522513305]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7887593950427		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.7887593950427 | validation: 0.6571200903356201]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7831071994757083		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.7831071994757083 | validation: 0.666830977845535]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845699915515595		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.7845699915515595 | validation: 0.6580911140549313]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7877080566010035		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.7877080566010035 | validation: 0.7184316012069664]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8033106013171545		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.8033106013171545 | validation: 0.6559049472903193]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7864213190769469		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.7864213190769469 | validation: 0.6482121883525376]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7903560413783293		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.7903560413783293 | validation: 0.6486370735960547]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845528371849587		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.7845528371849587 | validation: 0.6568402994743227]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7908236629623779		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.7908236629623779 | validation: 0.7340462008236983]
	TIME [epoch: 11.6 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8106322644307673		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.8106322644307673 | validation: 0.6523452183139754]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845634921595543		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.7845634921595543 | validation: 0.655117637535262]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.78437081587811		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.78437081587811 | validation: 0.6891469806324909]
	TIME [epoch: 11.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8007238134256438		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.8007238134256438 | validation: 0.7276553371279374]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7980504168568681		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.7980504168568681 | validation: 0.6650056175003186]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.790109207547729		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.790109207547729 | validation: 0.6633648500114174]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7737709003383635		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.7737709003383635 | validation: 0.6512131906155827]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7789940731979821		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.7789940731979821 | validation: 0.6650567305638615]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7838492431006022		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.7838492431006022 | validation: 0.6610144136124534]
	TIME [epoch: 11.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7973420825867272		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.7973420825867272 | validation: 0.6507683218494162]
	TIME [epoch: 11.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7717101137670384		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.7717101137670384 | validation: 0.6455956924048128]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7746174782030087		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.7746174782030087 | validation: 0.653825701805919]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7873156624694615		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.7873156624694615 | validation: 0.7308033089786595]
	TIME [epoch: 11.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.806974704929414		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.806974704929414 | validation: 0.6373103711278487]
	TIME [epoch: 11.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7907164639860762		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.7907164639860762 | validation: 0.6482346423738572]
	TIME [epoch: 11.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7880538051680513		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.7880538051680513 | validation: 0.6630466649976043]
	TIME [epoch: 11.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7892556857659458		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.7892556857659458 | validation: 0.6375149773758307]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7891694846145357		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.7891694846145357 | validation: 0.6424530068495267]
	TIME [epoch: 11.6 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7787055726029769		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.7787055726029769 | validation: 0.6501494231243916]
	TIME [epoch: 11.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8038712826731385		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.8038712826731385 | validation: 0.6477562712908693]
	TIME [epoch: 11.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7906639394205277		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.7906639394205277 | validation: 0.6231627567204917]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1166.pth
	Model improved!!!
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.780160689609643		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.780160689609643 | validation: 0.7425415728580735]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8094522877658306		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.8094522877658306 | validation: 0.6867884306043435]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7966145390645218		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.7966145390645218 | validation: 0.6420256767729763]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7752707512695121		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.7752707512695121 | validation: 0.6371531505947944]
	TIME [epoch: 11.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7806457087995626		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.7806457087995626 | validation: 0.6608845040897383]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7865206563382853		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.7865206563382853 | validation: 0.7122193425098248]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7932917057143187		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.7932917057143187 | validation: 0.6609211395870327]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7733633199707144		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.7733633199707144 | validation: 0.6417349477947671]
	TIME [epoch: 11.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7883486952157323		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.7883486952157323 | validation: 0.728967057564589]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8028667079299268		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.8028667079299268 | validation: 0.7079244272874459]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7993262903444337		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.7993262903444337 | validation: 0.6334015990101117]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7739172877081315		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.7739172877081315 | validation: 0.6430980964594964]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7789281384572746		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.7789281384572746 | validation: 0.6496153807868776]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7880847064368391		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.7880847064368391 | validation: 0.6329138818544715]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7842284591159338		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.7842284591159338 | validation: 0.6417986108518747]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7656991836243635		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.7656991836243635 | validation: 0.6190876244060475]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1182.pth
	Model improved!!!
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.773512546873244		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.773512546873244 | validation: 0.6725580924114992]
	TIME [epoch: 11.6 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.782349459971452		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.782349459971452 | validation: 0.6849162140364262]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7821354431069081		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.7821354431069081 | validation: 0.6527625185945235]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7707023828006427		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.7707023828006427 | validation: 0.6161431818135431]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1186.pth
	Model improved!!!
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7783107355509481		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.7783107355509481 | validation: 0.6654467359252706]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7856595816030534		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.7856595816030534 | validation: 0.646126548993382]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7813161864357642		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.7813161864357642 | validation: 0.6214670872158632]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7806310054017584		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.7806310054017584 | validation: 0.6208794726262701]
	TIME [epoch: 11.6 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7700713155705161		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.7700713155705161 | validation: 0.6242923505375467]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7677397108457042		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.7677397108457042 | validation: 0.6668838754064597]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7795840490481888		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.7795840490481888 | validation: 0.6330731018793877]
	TIME [epoch: 11.6 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7719131799005768		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.7719131799005768 | validation: 0.6415282829280778]
	TIME [epoch: 11.6 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7683480529836041		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.7683480529836041 | validation: 0.6461654240261003]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7781761107475248		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.7781761107475248 | validation: 0.6699087097325022]
	TIME [epoch: 11.6 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7850657774581625		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.7850657774581625 | validation: 0.6326976728411546]
	TIME [epoch: 11.6 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7821773500569346		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.7821773500569346 | validation: 0.6431116414651339]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885987679899533		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.7885987679899533 | validation: 0.6459382717729836]
	TIME [epoch: 11.6 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.773560231143841		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.773560231143841 | validation: 0.6115410926309092]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1200.pth
	Model improved!!!
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7866482858725744		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.7866482858725744 | validation: 0.7194740723680145]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7916950801948978		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.7916950801948978 | validation: 0.6178593174342786]
	TIME [epoch: 11.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7676407761307789		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.7676407761307789 | validation: 0.6234223679576352]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7578361522656024		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.7578361522656024 | validation: 0.6266866939789104]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7664117655191688		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.7664117655191688 | validation: 0.6100883334378696]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1205.pth
	Model improved!!!
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7665603993790567		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.7665603993790567 | validation: 0.6311914401229477]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7884707419681557		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.7884707419681557 | validation: 0.6623046647440771]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7701925255610822		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.7701925255610822 | validation: 0.6691235108690404]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7773784092314959		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.7773784092314959 | validation: 0.6535591401949208]
	TIME [epoch: 11.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7711512927623287		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.7711512927623287 | validation: 0.6095989991362355]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1210.pth
	Model improved!!!
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7710940972709663		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.7710940972709663 | validation: 0.6406040646317827]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7626281441781599		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.7626281441781599 | validation: 0.6457657322256737]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7858860729981909		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.7858860729981909 | validation: 0.6623101993847221]
	TIME [epoch: 11.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.788237080527465		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.788237080527465 | validation: 0.7368985779859182]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8258730676432844		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.8258730676432844 | validation: 0.6201980540401317]
	TIME [epoch: 11.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7694759112290992		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.7694759112290992 | validation: 0.6458764699004352]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.784052313820752		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.784052313820752 | validation: 0.6114607650471229]
	TIME [epoch: 11.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7636907267208972		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.7636907267208972 | validation: 0.6483700589507194]
	TIME [epoch: 11.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7685367790281848		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.7685367790281848 | validation: 0.6572995729046854]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7852505286548382		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.7852505286548382 | validation: 0.6332646580441325]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7934364556212679		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.7934364556212679 | validation: 0.6271003543700913]
	TIME [epoch: 11.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7696217044800986		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.7696217044800986 | validation: 0.6197336327236282]
	TIME [epoch: 11.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7613333861260984		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.7613333861260984 | validation: 0.6448846594834734]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7916302471497565		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.7916302471497565 | validation: 0.6279622998203022]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547012794604184		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.7547012794604184 | validation: 0.6131958313044157]
	TIME [epoch: 11.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7556021699415958		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.7556021699415958 | validation: 0.6155297486084349]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885970310081316		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.7885970310081316 | validation: 0.6310902929446983]
	TIME [epoch: 11.6 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7569014918244572		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.7569014918244572 | validation: 0.6244742866107109]
	TIME [epoch: 11.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.763214980959273		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.763214980959273 | validation: 0.6296200628913229]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.76926388728987		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.76926388728987 | validation: 0.6306145525371791]
	TIME [epoch: 11.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7744889312611175		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.7744889312611175 | validation: 0.6457479121893998]
	TIME [epoch: 11.6 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7645034748477092		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.7645034748477092 | validation: 0.6087280608726731]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1232.pth
	Model improved!!!
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7617281452410881		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.7617281452410881 | validation: 0.6254541918338148]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.757467567361565		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.757467567361565 | validation: 0.6229984332931079]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7917203520097604		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.7917203520097604 | validation: 0.6432295391593545]
	TIME [epoch: 11.6 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712558987334968		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.7712558987334968 | validation: 0.6603247446710742]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7851139904337733		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.7851139904337733 | validation: 0.6457214851580557]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712772992082497		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.7712772992082497 | validation: 0.6221979042432019]
	TIME [epoch: 11.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7660185953127094		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.7660185953127094 | validation: 0.6294191002905358]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7731527566347711		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.7731527566347711 | validation: 0.6179401551112358]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7707547822503162		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.7707547822503162 | validation: 0.6269617756567003]
	TIME [epoch: 11.6 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7680868038823196		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.7680868038823196 | validation: 0.6546465123467283]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7823109207982015		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.7823109207982015 | validation: 0.6287284325688175]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7680601140056909		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.7680601140056909 | validation: 0.6256729767193345]
	TIME [epoch: 11.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7624809653226345		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.7624809653226345 | validation: 0.6283372923531753]
	TIME [epoch: 11.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7666521676149036		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.7666521676149036 | validation: 0.5998720442173174]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1246.pth
	Model improved!!!
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.762168649534726		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.762168649534726 | validation: 0.6126547738966718]
	TIME [epoch: 11.6 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.756633485471346		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.756633485471346 | validation: 0.6279987895895514]
	TIME [epoch: 11.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7571470419274962		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.7571470419274962 | validation: 0.6235737713339322]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.764952314474465		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.764952314474465 | validation: 0.6393805451597023]
	TIME [epoch: 11.6 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7580053217941987		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.7580053217941987 | validation: 0.6182911711644011]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7615551127051872		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.7615551127051872 | validation: 0.6444850066793785]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7671888300760943		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.7671888300760943 | validation: 0.6137203593981795]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7482949426519038		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.7482949426519038 | validation: 0.6250865594792369]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.767757400606243		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.767757400606243 | validation: 0.6280335800794005]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7647329987250062		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.7647329987250062 | validation: 0.5926407619468295]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1256.pth
	Model improved!!!
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7525955933935566		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.7525955933935566 | validation: 0.6218044584663465]
	TIME [epoch: 11.6 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7533494049563635		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.7533494049563635 | validation: 0.6177153538852544]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7632031945318459		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.7632031945318459 | validation: 0.6144025691911766]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7585630877055649		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.7585630877055649 | validation: 0.6205546367017991]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.766254760685505		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.766254760685505 | validation: 0.6394236008481774]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7629979008242794		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.7629979008242794 | validation: 0.5990200813070878]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532902950632497		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.7532902950632497 | validation: 0.6604824386077601]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7624080149196097		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.7624080149196097 | validation: 0.6390234700755245]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7639795594547609		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.7639795594547609 | validation: 0.6269066722528344]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7515298584839712		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.7515298584839712 | validation: 0.6234845790480371]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7622718508261017		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.7622718508261017 | validation: 0.6187122839868888]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.746032019757199		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.746032019757199 | validation: 0.6184763895140641]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7474217630931698		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.7474217630931698 | validation: 0.6118173999070736]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7529233355658711		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.7529233355658711 | validation: 0.6219108505285406]
	TIME [epoch: 11.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.751321434011444		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.751321434011444 | validation: 0.5827853272530156]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1271.pth
	Model improved!!!
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563886302901651		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.7563886302901651 | validation: 0.627484549010687]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7602873593436755		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.7602873593436755 | validation: 0.6047492662130628]
	TIME [epoch: 11.6 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7496365302242564		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.7496365302242564 | validation: 0.6226469156391548]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7480564485047086		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.7480564485047086 | validation: 0.6137591823152372]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7693264298831684		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.7693264298831684 | validation: 0.6048596970653537]
	TIME [epoch: 11.6 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7438837355639278		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.7438837355639278 | validation: 0.6059516259220098]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7492138274342739		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.7492138274342739 | validation: 0.635075542523026]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.74714593314317		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.74714593314317 | validation: 0.6648897955809491]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7801851242415614		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.7801851242415614 | validation: 0.5906325263796656]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7538403419048626		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.7538403419048626 | validation: 0.6031714258382526]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7584000973025717		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.7584000973025717 | validation: 0.6011255355288678]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7398410741456172		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.7398410741456172 | validation: 0.6147862054897233]
	TIME [epoch: 11.6 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8063691259007482		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.8063691259007482 | validation: 0.6268768784101776]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7467135235003004		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.7467135235003004 | validation: 0.6196063776193886]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7522578122926442		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.7522578122926442 | validation: 0.6106475467845519]
	TIME [epoch: 11.6 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7496305579904845		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.7496305579904845 | validation: 0.6006801841983328]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475709159857247		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.7475709159857247 | validation: 0.630040039136944]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7592068324882633		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.7592068324882633 | validation: 0.623558729703123]
	TIME [epoch: 11.6 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7439863089631658		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.7439863089631658 | validation: 0.6553683480035528]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7630436625973941		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.7630436625973941 | validation: 0.6032638494466972]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7470357600172242		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.7470357600172242 | validation: 0.6097819637742449]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7513881099685721		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.7513881099685721 | validation: 0.6001090607026913]
	TIME [epoch: 11.6 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7421255533796174		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.7421255533796174 | validation: 0.6225407647264568]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484097071141623		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.7484097071141623 | validation: 0.6082991540998554]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7572505523850594		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.7572505523850594 | validation: 0.6025295195057935]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7371927534053446		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.7371927534053446 | validation: 0.6276799127284484]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7508201057407689		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.7508201057407689 | validation: 0.6076721525352189]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7377207804742005		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.7377207804742005 | validation: 0.6038691922632561]
	TIME [epoch: 11.6 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7454374873018289		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.7454374873018289 | validation: 0.5967615954193185]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7422644120445304		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.7422644120445304 | validation: 0.6038825742038024]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7586050010046339		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.7586050010046339 | validation: 0.5941530728657524]
	TIME [epoch: 11.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7346899069698343		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.7346899069698343 | validation: 0.5997948371792782]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7405040241339974		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.7405040241339974 | validation: 0.5822924313447767]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1304.pth
	Model improved!!!
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7554026936568593		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.7554026936568593 | validation: 0.5935522242808856]
	TIME [epoch: 11.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.73626410741729		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.73626410741729 | validation: 0.6003220270585324]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7389024631677945		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.7389024631677945 | validation: 0.578256769217525]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1307.pth
	Model improved!!!
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324728567894584		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.7324728567894584 | validation: 0.6032213642596905]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7354781528268223		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.7354781528268223 | validation: 0.5993902586841263]
	TIME [epoch: 11.6 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7415365358227816		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.7415365358227816 | validation: 0.5861905391453024]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.748877315102022		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.748877315102022 | validation: 0.609173566849427]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7486279860629776		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.7486279860629776 | validation: 0.5996168562041685]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7447829874395082		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.7447829874395082 | validation: 0.5945693551520302]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7397200904336979		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.7397200904336979 | validation: 0.6213648989547008]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7544777091453401		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.7544777091453401 | validation: 0.5945631131821527]
	TIME [epoch: 11.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7342351042677767		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.7342351042677767 | validation: 0.6077226317156854]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7588242095496723		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.7588242095496723 | validation: 0.5837005386282779]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7392622516227172		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.7392622516227172 | validation: 0.5998619227772959]
	TIME [epoch: 11.6 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.743933814156015		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.743933814156015 | validation: 0.6637743428315818]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7701449053822533		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.7701449053822533 | validation: 0.6095501231087643]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7309646981990465		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.7309646981990465 | validation: 0.6040685000822238]
	TIME [epoch: 11.6 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7485785839901078		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.7485785839901078 | validation: 0.6250383713325457]
	TIME [epoch: 11.6 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7562002642567434		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.7562002642567434 | validation: 0.5881831722924544]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7564048649284651		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.7564048649284651 | validation: 0.5885663342932226]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7267581846623963		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.7267581846623963 | validation: 0.5816216773139002]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7343030624649104		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.7343030624649104 | validation: 0.5876733785739987]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7361075814684407		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.7361075814684407 | validation: 0.6128277719336112]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7592630608903193		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.7592630608903193 | validation: 0.6183561351582711]
	TIME [epoch: 11.6 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7501482792179475		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.7501482792179475 | validation: 0.6042406291021307]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7382984708716391		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.7382984708716391 | validation: 0.6216433696315471]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7504022292992691		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.7504022292992691 | validation: 0.5960486488345803]
	TIME [epoch: 11.6 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7402160990151432		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.7402160990151432 | validation: 0.5885398435945381]
	TIME [epoch: 11.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333690130555284		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.7333690130555284 | validation: 0.5974195105012118]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7340344338541402		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.7340344338541402 | validation: 0.5945571204279197]
	TIME [epoch: 11.6 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7388815441964546		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.7388815441964546 | validation: 0.6008494573453199]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7404024279791412		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.7404024279791412 | validation: 0.6315717887249355]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7463229414019966		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.7463229414019966 | validation: 0.6024295869103665]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7388042591508239		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.7388042591508239 | validation: 0.5967409371776963]
	TIME [epoch: 11.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731593094184206		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.731593094184206 | validation: 0.6150187118396873]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414422483251606		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.7414422483251606 | validation: 0.6261306200561523]
	TIME [epoch: 11.6 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7470229669402313		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.7470229669402313 | validation: 0.6013926665970754]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7346769908130923		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.7346769908130923 | validation: 0.6166980828103812]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744839255864457		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.744839255864457 | validation: 0.6681349191776438]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7562932110285836		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.7562932110285836 | validation: 0.639802023357616]
	TIME [epoch: 11.6 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7472122695542351		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.7472122695542351 | validation: 0.5862755991130766]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7356115134984668		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.7356115134984668 | validation: 0.594323923201388]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7398585504586666		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.7398585504586666 | validation: 0.6000111395299923]
	TIME [epoch: 11.6 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7444805538161728		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.7444805538161728 | validation: 0.6017117176293106]
	TIME [epoch: 11.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7403660856666647		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.7403660856666647 | validation: 0.6101701142256988]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336362581282869		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.7336362581282869 | validation: 0.5828235731220366]
	TIME [epoch: 11.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324473669630149		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.7324473669630149 | validation: 0.6039082727104532]
	TIME [epoch: 11.6 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265772813476061		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.7265772813476061 | validation: 0.600082971328526]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376215698907516		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.7376215698907516 | validation: 0.5834024260385595]
	TIME [epoch: 11.6 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7286537414639712		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.7286537414639712 | validation: 0.5992965284687567]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7468370941231712		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.7468370941231712 | validation: 0.6026365733498967]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333594080131749		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.7333594080131749 | validation: 0.5924062852539829]
	TIME [epoch: 11.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7465408205066004		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.7465408205066004 | validation: 0.5883578154157804]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7314193600350457		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.7314193600350457 | validation: 0.6045099386482875]
	TIME [epoch: 11.6 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7425730408559166		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.7425730408559166 | validation: 0.597587142796712]
	TIME [epoch: 11.6 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246992428651617		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.7246992428651617 | validation: 0.585717427453544]
	TIME [epoch: 11.6 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254709189677417		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.7254709189677417 | validation: 0.5974899766988848]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.73054239007054		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.73054239007054 | validation: 0.5929655472928256]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265797001838746		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.7265797001838746 | validation: 0.590811309302061]
	TIME [epoch: 11.6 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.726752321967941		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.726752321967941 | validation: 0.5902659549291405]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216079799881837		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.7216079799881837 | validation: 0.5880722569494807]
	TIME [epoch: 11.6 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258009833886172		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.7258009833886172 | validation: 0.6066576531826343]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7288878474428009		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.7288878474428009 | validation: 0.6111406206675503]
	TIME [epoch: 11.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7401493149202809		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.7401493149202809 | validation: 0.5878648002933295]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255656739243435		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.7255656739243435 | validation: 0.5952739599453382]
	TIME [epoch: 11.6 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7339620112432717		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.7339620112432717 | validation: 0.5917790102623439]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239832079219248		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.7239832079219248 | validation: 0.5907815823617305]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7286199643165072		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.7286199643165072 | validation: 0.6052608991526943]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7261090225016751		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.7261090225016751 | validation: 0.5961755450180081]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7288190310224733		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.7288190310224733 | validation: 0.598105264663833]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212223754405398		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.7212223754405398 | validation: 0.5753503085957759]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1375.pth
	Model improved!!!
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217428538917663		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.7217428538917663 | validation: 0.5943640972501316]
	TIME [epoch: 11.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7319012106827782		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.7319012106827782 | validation: 0.5929859925786114]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7297489552299734		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.7297489552299734 | validation: 0.5866952169840318]
	TIME [epoch: 11.6 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228465276283238		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.7228465276283238 | validation: 0.5910064028154456]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220839824185659		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.7220839824185659 | validation: 0.6042250760857597]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7307136046257131		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.7307136046257131 | validation: 0.5976048709300901]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.746151138743415		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.746151138743415 | validation: 0.6213220975371972]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7395902606070495		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.7395902606070495 | validation: 0.5850558629996421]
	TIME [epoch: 11.6 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204619749325553		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.7204619749325553 | validation: 0.595287959108682]
	TIME [epoch: 11.6 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235137703037546		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.7235137703037546 | validation: 0.5759203116563777]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206391886752945		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.7206391886752945 | validation: 0.5878054573424919]
	TIME [epoch: 11.6 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190952371603123		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.7190952371603123 | validation: 0.5922188818950208]
	TIME [epoch: 11.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213308866241896		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.7213308866241896 | validation: 0.5861241513279383]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252014793382593		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.7252014793382593 | validation: 0.5912458242251144]
	TIME [epoch: 11.6 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281630280708468		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.7281630280708468 | validation: 0.5819601154619006]
	TIME [epoch: 11.6 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7152843544468959		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.7152843544468959 | validation: 0.5788501080274752]
	TIME [epoch: 11.6 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224674669743687		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.7224674669743687 | validation: 0.5826928101238391]
	TIME [epoch: 11.6 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228463539915362		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.7228463539915362 | validation: 0.5855842760867652]
	TIME [epoch: 11.6 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194554058482973		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.7194554058482973 | validation: 0.5807499207410769]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181412702003597		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.7181412702003597 | validation: 0.6009285208767857]
	TIME [epoch: 11.6 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7348490910723092		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.7348490910723092 | validation: 0.5696744906710792]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1396.pth
	Model improved!!!
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211530954027099		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.7211530954027099 | validation: 0.5892822654269361]
	TIME [epoch: 11.6 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206047861179036		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.7206047861179036 | validation: 0.5988908791118427]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7299038930955359		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.7299038930955359 | validation: 0.5901602355470607]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161795655275823		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.7161795655275823 | validation: 0.5751827319132828]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7164670904890671		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.7164670904890671 | validation: 0.6007812570740833]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7549256673038164		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.7549256673038164 | validation: 0.6108897281156698]
	TIME [epoch: 11.6 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7296020592660353		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.7296020592660353 | validation: 0.5853564953783675]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289545121674782		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.7289545121674782 | validation: 0.5841292367697121]
	TIME [epoch: 11.6 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250811649689906		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.7250811649689906 | validation: 0.5916472442350378]
	TIME [epoch: 11.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7146186665476028		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.7146186665476028 | validation: 0.5876644452877077]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7139967309540459		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.7139967309540459 | validation: 0.587860791693026]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7126801136116693		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.7126801136116693 | validation: 0.5891695177346322]
	TIME [epoch: 11.6 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268083622432168		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.7268083622432168 | validation: 0.5891618662991905]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204378375100705		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.7204378375100705 | validation: 0.5878193794755373]
	TIME [epoch: 11.6 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255749624247614		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.7255749624247614 | validation: 0.5849066100893273]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172158470784005		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.7172158470784005 | validation: 0.5753275840964325]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7152254005799372		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.7152254005799372 | validation: 0.574741981784688]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204182122323426		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.7204182122323426 | validation: 0.5919169185252342]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232178464370066		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.7232178464370066 | validation: 0.5786257910289493]
	TIME [epoch: 11.6 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7113140306551862		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.7113140306551862 | validation: 0.5860219540837859]
	TIME [epoch: 11.6 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192224110374308		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.7192224110374308 | validation: 0.6000735595604167]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7274157615361421		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.7274157615361421 | validation: 0.601109227240251]
	TIME [epoch: 11.6 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264555185645627		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.7264555185645627 | validation: 0.5997593430779768]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240438928236357		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.7240438928236357 | validation: 0.5984553294018913]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7129795670335133		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.7129795670335133 | validation: 0.5775093619849452]
	TIME [epoch: 11.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157645971724975		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.7157645971724975 | validation: 0.5735406924273373]
	TIME [epoch: 11.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252465805664585		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.7252465805664585 | validation: 0.5846356684260491]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7178794794363762		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.7178794794363762 | validation: 0.5788939881699474]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722945005278051		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.722945005278051 | validation: 0.5891679230439644]
	TIME [epoch: 11.6 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131650518859329		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.7131650518859329 | validation: 0.5886692287278293]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7129691046175528		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.7129691046175528 | validation: 0.5744323672067317]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189685543358996		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.7189685543358996 | validation: 0.5674989503162]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1428.pth
	Model improved!!!
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237580623594959		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.7237580623594959 | validation: 0.5763834519143043]
	TIME [epoch: 11.6 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7067661226317044		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.7067661226317044 | validation: 0.5661373623163813]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1430.pth
	Model improved!!!
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7089158317154601		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.7089158317154601 | validation: 0.5740033234698279]
	TIME [epoch: 11.6 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071311306463217		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.7071311306463217 | validation: 0.5799028816876496]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7077356292975567		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.7077356292975567 | validation: 0.5693991918786153]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7087886964369422		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.7087886964369422 | validation: 0.571745524400602]
	TIME [epoch: 11.6 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7078703304055659		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.7078703304055659 | validation: 0.5837563309196688]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7108287125358809		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.7108287125358809 | validation: 0.6062308206875544]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243838318913385		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.7243838318913385 | validation: 0.5858031166764864]
	TIME [epoch: 11.6 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7098783064574452		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.7098783064574452 | validation: 0.594821334773778]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7233996105400019		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.7233996105400019 | validation: 0.5761533563642002]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7110178223038776		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.7110178223038776 | validation: 0.5678568195661301]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000489342313077		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.7000489342313077 | validation: 0.5638731075024684]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1441.pth
	Model improved!!!
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7067912568304713		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.7067912568304713 | validation: 0.5661170911010686]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071669742438553		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.7071669742438553 | validation: 0.557694109196843]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1443.pth
	Model improved!!!
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7117120955910378		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.7117120955910378 | validation: 0.5751213163245561]
	TIME [epoch: 11.6 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192994437104038		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.7192994437104038 | validation: 0.5765086442315641]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.710792705508518		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.710792705508518 | validation: 0.5935663406359776]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7128010446147905		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.7128010446147905 | validation: 0.5790657023371176]
	TIME [epoch: 11.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7087072228739999		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.7087072228739999 | validation: 0.5776401509219941]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7089402461948173		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.7089402461948173 | validation: 0.5665852368175397]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707736946027743		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.707736946027743 | validation: 0.5737604934075248]
	TIME [epoch: 11.6 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7062135408933031		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.7062135408933031 | validation: 0.5782029045597645]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257401365059433		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.7257401365059433 | validation: 0.5839427920075818]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7022632937583515		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.7022632937583515 | validation: 0.5614909668549476]
	TIME [epoch: 11.6 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060609957621368		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.7060609957621368 | validation: 0.584386647734344]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079464439037543		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.7079464439037543 | validation: 0.5525060846728853]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1455.pth
	Model improved!!!
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7010186635447182		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.7010186635447182 | validation: 0.5568733927256772]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058840868818681		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.7058840868818681 | validation: 0.5868454845689266]
	TIME [epoch: 11.6 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177425209120202		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.7177425209120202 | validation: 0.5528132235145854]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956376424954861		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.6956376424954861 | validation: 0.5752963634441751]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333201968744981		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.7333201968744981 | validation: 0.6365727687262587]
	TIME [epoch: 11.6 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7573771083828458		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.7573771083828458 | validation: 0.5849974956182754]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7062645980745664		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.7062645980745664 | validation: 0.5640351148624985]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084816995319896		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.7084816995319896 | validation: 0.5620456717287385]
	TIME [epoch: 11.6 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7143618659884167		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.7143618659884167 | validation: 0.5841912072761012]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034333888946436		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.7034333888946436 | validation: 0.5577095193022072]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6976138052904082		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.6976138052904082 | validation: 0.5545432527999742]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698040182882378		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.698040182882378 | validation: 0.5543970309653813]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972171948979677		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.6972171948979677 | validation: 0.5548848294783316]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7101664670492366		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.7101664670492366 | validation: 0.570531962290712]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7103044769063598		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.7103044769063598 | validation: 0.5514850017762669]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1470.pth
	Model improved!!!
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014335533197524		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.7014335533197524 | validation: 0.5488065191513948]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1471.pth
	Model improved!!!
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6936166928817451		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.6936166928817451 | validation: 0.5633607782169062]
	TIME [epoch: 11.6 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055509305975309		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.7055509305975309 | validation: 0.5549237422696836]
	TIME [epoch: 11.6 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968011075583614		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.6968011075583614 | validation: 0.5497722399523773]
	TIME [epoch: 11.6 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888609094283747		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.6888609094283747 | validation: 0.5641497091632267]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7048470668795609		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.7048470668795609 | validation: 0.5568261544652764]
	TIME [epoch: 11.6 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6943517407832203		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.6943517407832203 | validation: 0.559653796398673]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979568609839834		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.6979568609839834 | validation: 0.55266818310221]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6912459609907967		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.6912459609907967 | validation: 0.548976585639222]
	TIME [epoch: 11.6 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6895823938783887		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.6895823938783887 | validation: 0.5470690825695487]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1480.pth
	Model improved!!!
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6939140902446506		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.6939140902446506 | validation: 0.5414170471508263]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1481.pth
	Model improved!!!
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864028479651083		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.6864028479651083 | validation: 0.5750770470254507]
	TIME [epoch: 11.6 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7059863340361192		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.7059863340361192 | validation: 0.5629933501823474]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6925305879098349		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.6925305879098349 | validation: 0.5660140309815733]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854087463488117		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.6854087463488117 | validation: 0.5621570544017207]
	TIME [epoch: 11.6 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6892691574876781		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.6892691574876781 | validation: 0.5610632540713492]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6998158456332075		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.6998158456332075 | validation: 0.563287662580205]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962867863576172		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.6962867863576172 | validation: 0.5806571448656975]
	TIME [epoch: 11.6 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7052401857221362		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.7052401857221362 | validation: 0.569599408594299]
	TIME [epoch: 11.6 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.692484178208097		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.692484178208097 | validation: 0.563668625972762]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999643709400825		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.6999643709400825 | validation: 0.5876810358085578]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701108619964968		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.701108619964968 | validation: 0.568802237693835]
	TIME [epoch: 11.6 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931137404064975		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.6931137404064975 | validation: 0.5533248641225493]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815559434827185		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.6815559434827185 | validation: 0.5496202656435278]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955354912549799		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.6955354912549799 | validation: 0.5456948734192553]
	TIME [epoch: 11.6 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6892834680987184		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.6892834680987184 | validation: 0.5504137764612489]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6907267798387356		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.6907267798387356 | validation: 0.5633609009998712]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846833624652395		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.6846833624652395 | validation: 0.559306748751553]
	TIME [epoch: 11.6 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857776129819302		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.6857776129819302 | validation: 0.5397311728024157]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1499.pth
	Model improved!!!
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6939656903733293		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.6939656903733293 | validation: 0.5564470244934985]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685706484975554		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.685706484975554 | validation: 0.5492306997155804]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822304008343761		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.6822304008343761 | validation: 0.5433061903955982]
	TIME [epoch: 11.6 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899526534498471		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.6899526534498471 | validation: 0.5757718687047229]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876902322130202		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.6876902322130202 | validation: 0.5490261853182465]
	TIME [epoch: 11.6 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851840429902893		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.6851840429902893 | validation: 0.5599445880104316]
	TIME [epoch: 11.6 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6942667938758724		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.6942667938758724 | validation: 0.569206259615843]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694499140832195		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.694499140832195 | validation: 0.5365883778388185]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1507.pth
	Model improved!!!
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830388794199298		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.6830388794199298 | validation: 0.547146864941337]
	TIME [epoch: 11.6 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869126103831044		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.6869126103831044 | validation: 0.5494240795363673]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955734961866252		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.6955734961866252 | validation: 0.546825686755]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873747798018913		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.6873747798018913 | validation: 0.5437092285976197]
	TIME [epoch: 11.6 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6907665673719544		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.6907665673719544 | validation: 0.5432044293963045]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872919213872195		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.6872919213872195 | validation: 0.5537245280645285]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690379793945548		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.690379793945548 | validation: 0.5477404424680985]
	TIME [epoch: 11.6 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685157521048291		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.685157521048291 | validation: 0.5586499682063155]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793487506977949		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.6793487506977949 | validation: 0.5467304997748639]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820316724548697		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.6820316724548697 | validation: 0.5401530421865461]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6788318378808249		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.6788318378808249 | validation: 0.5551040416443187]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818117513349673		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.6818117513349673 | validation: 0.555635588354354]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801584389948921		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.6801584389948921 | validation: 0.5518344722396907]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6790224697135838		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.6790224697135838 | validation: 0.5342269207613258]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1521.pth
	Model improved!!!
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837309663766176		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.6837309663766176 | validation: 0.5517168315622151]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848653020915749		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.6848653020915749 | validation: 0.5538235159859894]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818393088201695		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.6818393088201695 | validation: 0.5466157116156078]
	TIME [epoch: 11.6 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980776768108552		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.6980776768108552 | validation: 0.5618705517037488]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927643542068458		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.6927643542068458 | validation: 0.545889658724536]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6752060879567059		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.6752060879567059 | validation: 0.564987765264019]
	TIME [epoch: 11.6 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876215065543111		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.6876215065543111 | validation: 0.5549943977609296]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862009588043134		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.6862009588043134 | validation: 0.5703496673380167]
	TIME [epoch: 11.6 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6988131619557234		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.6988131619557234 | validation: 0.5631116620039341]
	TIME [epoch: 11.6 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684428942472585		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.684428942472585 | validation: 0.5524713948697868]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806988146227437		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.6806988146227437 | validation: 0.5429481570283605]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682074305151061		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.682074305151061 | validation: 0.5529757844088903]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6724678747027905		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.6724678747027905 | validation: 0.5403794549826217]
	TIME [epoch: 11.6 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6779428035339771		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.6779428035339771 | validation: 0.5418807140989078]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6778165982151438		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.6778165982151438 | validation: 0.5522880445398949]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859899780203412		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.6859899780203412 | validation: 0.5514650786320409]
	TIME [epoch: 11.6 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.678554609721355		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.678554609721355 | validation: 0.5471920726788926]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6745620481318679		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.6745620481318679 | validation: 0.5482865368712369]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6731406548518937		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.6731406548518937 | validation: 0.540134120411904]
	TIME [epoch: 11.6 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6676941580300639		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.6676941580300639 | validation: 0.5356529637994173]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706082423996285		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.6706082423996285 | validation: 0.5375731352678738]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6748024518947844		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.6748024518947844 | validation: 0.542390726341892]
	TIME [epoch: 11.6 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6722533592239683		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.6722533592239683 | validation: 0.530337677934658]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1544.pth
	Model improved!!!
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6763462866099668		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.6763462866099668 | validation: 0.5421705465482595]
	TIME [epoch: 11.6 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6802960504777912		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.6802960504777912 | validation: 0.540825720894823]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6775942449190535		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.6775942449190535 | validation: 0.5424656287558827]
	TIME [epoch: 11.6 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6745831932297233		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.6745831932297233 | validation: 0.543949353954828]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647564483508329		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.6647564483508329 | validation: 0.5285723311864312]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1549.pth
	Model improved!!!
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6742607638406126		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.6742607638406126 | validation: 0.5419964357662526]
	TIME [epoch: 11.6 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760360895088893		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.6760360895088893 | validation: 0.5292787548549043]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693317652254419		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.6693317652254419 | validation: 0.54161164437836]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6663488783563694		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.6663488783563694 | validation: 0.5388850920335405]
	TIME [epoch: 11.6 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6576968878568192		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.6576968878568192 | validation: 0.5439445293588969]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616130621029366		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.6616130621029366 | validation: 0.5387713764664696]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6645950304813247		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.6645950304813247 | validation: 0.5464979365963086]
	TIME [epoch: 11.6 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697723979516239		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.6697723979516239 | validation: 0.5444665556821695]
	TIME [epoch: 11.6 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6718856105812241		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.6718856105812241 | validation: 0.5411344376350413]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.67570729828983		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.67570729828983 | validation: 0.5541342201498035]
	TIME [epoch: 11.6 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704676193542346		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.6704676193542346 | validation: 0.5525013204203275]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6721993961752348		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.6721993961752348 | validation: 0.5502295734283192]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6748523234320762		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.6748523234320762 | validation: 0.5397929884945638]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6739041005445187		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.6739041005445187 | validation: 0.5511601963895661]
	TIME [epoch: 11.6 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6749013439095445		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.6749013439095445 | validation: 0.5503130952383869]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.667320635005556		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.667320635005556 | validation: 0.5549976409959246]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6677156732107743		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.6677156732107743 | validation: 0.5582436432647364]
	TIME [epoch: 11.6 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6631582968082612		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.6631582968082612 | validation: 0.5437689223396676]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6653050057947174		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.6653050057947174 | validation: 0.5427741560923633]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6692952639093555		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.6692952639093555 | validation: 0.5304508454440293]
	TIME [epoch: 11.6 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6682739969721558		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.6682739969721558 | validation: 0.5512838368773718]
	TIME [epoch: 11.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6708847618814047		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.6708847618814047 | validation: 0.5317105517216109]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704294423956783		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.6704294423956783 | validation: 0.5410273421057504]
	TIME [epoch: 11.6 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6660073672617619		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.6660073672617619 | validation: 0.5501167551210286]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6761146617109862		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.6761146617109862 | validation: 0.5529362294785302]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793350618219052		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.6793350618219052 | validation: 0.5466364434854375]
	TIME [epoch: 11.6 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6728055517502453		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.6728055517502453 | validation: 0.5438334837135446]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6626406801757945		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.6626406801757945 | validation: 0.5524643343437619]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6648812343722872		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.6648812343722872 | validation: 0.5419791942763879]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6741439934113208		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.6741439934113208 | validation: 0.5412194925869364]
	TIME [epoch: 11.6 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6756898716504878		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.6756898716504878 | validation: 0.538866538773213]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706077145746734		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.6706077145746734 | validation: 0.5413746836069605]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6660029230887641		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.6660029230887641 | validation: 0.5532368204605288]
	TIME [epoch: 11.6 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6596499490727461		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.6596499490727461 | validation: 0.537903873469788]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6679377593038504		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.6679377593038504 | validation: 0.5392600079707888]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6591320441197641		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.6591320441197641 | validation: 0.5423089650732041]
	TIME [epoch: 11.6 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6674931539875545		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.6674931539875545 | validation: 0.5536544441069049]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733853937297782		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.6733853937297782 | validation: 0.5344911820802581]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6640557149696196		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.6640557149696196 | validation: 0.5254969436507866]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1588.pth
	Model improved!!!
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6635049390520134		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.6635049390520134 | validation: 0.5442555424139771]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6567291883055582		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.6567291883055582 | validation: 0.5329556242690429]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664157021567365		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.6664157021567365 | validation: 0.5399069092357653]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560527266428782		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.6560527266428782 | validation: 0.5392697384781726]
	TIME [epoch: 11.6 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.671898985864435		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.671898985864435 | validation: 0.5326481525709301]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693025602420679		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.6693025602420679 | validation: 0.5445853405861056]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6663655906998414		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.6663655906998414 | validation: 0.54516451600568]
	TIME [epoch: 11.6 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6618126069365257		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.6618126069365257 | validation: 0.5384628805266343]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563343763284679		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.6563343763284679 | validation: 0.5379617821589381]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.663199084525626		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.663199084525626 | validation: 0.5595550650960418]
	TIME [epoch: 11.6 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842762496348976		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.6842762496348976 | validation: 0.5359533588911475]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6628985471988197		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.6628985471988197 | validation: 0.5357671047332009]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6629119956794534		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.6629119956794534 | validation: 0.5452231860693981]
	TIME [epoch: 11.6 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6566677586370573		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.6566677586370573 | validation: 0.5395442214322703]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6542029075286363		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.6542029075286363 | validation: 0.5354314185860748]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6620761526817612		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.6620761526817612 | validation: 0.5452248781094972]
	TIME [epoch: 11.6 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.656955527702706		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.656955527702706 | validation: 0.5290147048376954]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6609932890595602		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.6609932890595602 | validation: 0.5367256841947275]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616880693526854		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.6616880693526854 | validation: 0.536396273462814]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6501593009774012		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.6501593009774012 | validation: 0.5353801433084507]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6584281343392587		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.6584281343392587 | validation: 0.5432424909592661]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6713810707679059		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.6713810707679059 | validation: 0.5530582136799788]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6606141212962974		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.6606141212962974 | validation: 0.535249177771912]
	TIME [epoch: 11.6 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680638328049036		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.6680638328049036 | validation: 0.5444976570576955]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6612390841163576		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.6612390841163576 | validation: 0.5466381964590353]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6575054175003543		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.6575054175003543 | validation: 0.5492939656242714]
	TIME [epoch: 11.6 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6535175200340727		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.6535175200340727 | validation: 0.5170056489521475]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1615.pth
	Model improved!!!
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6619189946114721		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.6619189946114721 | validation: 0.5342477374916987]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6554855735522622		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.6554855735522622 | validation: 0.5385361098261237]
	TIME [epoch: 11.6 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589368526573615		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.6589368526573615 | validation: 0.5736343841312092]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844956208752572		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.6844956208752572 | validation: 0.557456395065099]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6666126800905288		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.6666126800905288 | validation: 0.5405266654395876]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6526568757080009		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.6526568757080009 | validation: 0.5296516484173714]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560149735108081		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.6560149735108081 | validation: 0.531243725553515]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6565798639206588		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.6565798639206588 | validation: 0.5392504831338987]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6524585355615466		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.6524585355615466 | validation: 0.537356084035747]
	TIME [epoch: 11.6 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6567382098841452		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.6567382098841452 | validation: 0.5374991989416222]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6492610638917757		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.6492610638917757 | validation: 0.5360525942881543]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6538489730608659		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.6538489730608659 | validation: 0.5424533916082477]
	TIME [epoch: 11.6 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6487406137508509		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.6487406137508509 | validation: 0.5327597795904164]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6509979251330418		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.6509979251330418 | validation: 0.537777987499442]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6597305997994894		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.6597305997994894 | validation: 0.5512321331256389]
	TIME [epoch: 11.6 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6544779136049943		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.6544779136049943 | validation: 0.5221763874531291]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540574478268645		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.6540574478268645 | validation: 0.5370123411546005]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6506607047028863		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.6506607047028863 | validation: 0.5341380212994229]
	TIME [epoch: 11.6 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6486896319301735		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.6486896319301735 | validation: 0.5448483709051761]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6548984510420514		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.6548984510420514 | validation: 0.5502597056779202]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6607592663234891		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.6607592663234891 | validation: 0.5530775441824223]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6621168968044036		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.6621168968044036 | validation: 0.5670732076367587]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6677407112022462		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.6677407112022462 | validation: 0.5418407734567876]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6634356094256552		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.6634356094256552 | validation: 0.5513352434865704]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6653286387407327		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.6653286387407327 | validation: 0.5751997977771375]
	TIME [epoch: 11.6 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615734484727886		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.6615734484727886 | validation: 0.5564923505966041]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6656431181504325		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.6656431181504325 | validation: 0.539967482675863]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6591549831612178		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.6591549831612178 | validation: 0.5576619021044519]
	TIME [epoch: 11.6 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6542899420572887		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.6542899420572887 | validation: 0.5515463940105699]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6606205430321771		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.6606205430321771 | validation: 0.5479830726081817]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6534065341005677		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.6534065341005677 | validation: 0.54421993576505]
	TIME [epoch: 11.6 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6492043139293818		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.6492043139293818 | validation: 0.5397785784337341]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6527774591629706		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.6527774591629706 | validation: 0.5298998422905159]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463531596168052		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.6463531596168052 | validation: 0.5466821490609233]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6486282869137876		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.6486282869137876 | validation: 0.5388505024775612]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6582248923412766		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.6582248923412766 | validation: 0.5392102015334146]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6455495728757968		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.6455495728757968 | validation: 0.5453463270262386]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6481288942940102		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.6481288942940102 | validation: 0.5337373913298685]
	TIME [epoch: 11.6 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6509226419672246		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.6509226419672246 | validation: 0.5449229659218817]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560292658832477		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.6560292658832477 | validation: 0.5399558111059919]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.648480958366607		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.648480958366607 | validation: 0.5415135720413747]
	TIME [epoch: 11.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6526854382256998		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.6526854382256998 | validation: 0.5470745328111865]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6501413436001167		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.6501413436001167 | validation: 0.5356776765946301]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6475214068613503		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.6475214068613503 | validation: 0.5293466102995226]
	TIME [epoch: 11.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6495684623064004		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.6495684623064004 | validation: 0.5392014837000065]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6587196812970223		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.6587196812970223 | validation: 0.5379734063771145]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6499184250106435		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.6499184250106435 | validation: 0.5379780943394272]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6496982412810678		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.6496982412810678 | validation: 0.5278731231444962]
	TIME [epoch: 11.6 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6442241241314846		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.6442241241314846 | validation: 0.5354897135271199]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6496214700860015		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.6496214700860015 | validation: 0.5403490387248531]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6489170771738547		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.6489170771738547 | validation: 0.5357261702950192]
	TIME [epoch: 11.6 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6482840289146337		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.6482840289146337 | validation: 0.5313714892285861]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6478419573082537		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.6478419573082537 | validation: 0.5195195348531916]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.647402094978869		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.647402094978869 | validation: 0.5434632308146109]
	TIME [epoch: 11.6 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493267395620027		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.6493267395620027 | validation: 0.5215948680852195]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6498795937389917		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.6498795937389917 | validation: 0.5287209726569325]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463155288174113		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.6463155288174113 | validation: 0.5481447630567106]
	TIME [epoch: 11.6 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6474721902058211		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.6474721902058211 | validation: 0.5354111833594302]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6474414811124449		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.6474414811124449 | validation: 0.5313144302546887]
	TIME [epoch: 11.6 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493393474125067		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.6493393474125067 | validation: 0.5476145484574143]
	TIME [epoch: 11.6 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6547602817844582		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.6547602817844582 | validation: 0.5551582851265454]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6474908016783043		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.6474908016783043 | validation: 0.5461895665635302]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6498916294601184		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.6498916294601184 | validation: 0.5236846289288816]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493304546473309		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.6493304546473309 | validation: 0.5406312502752264]
	TIME [epoch: 11.6 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.646010317227038		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.646010317227038 | validation: 0.5489187502998102]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6512564702054733		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.6512564702054733 | validation: 0.5420415591810318]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6416730428832604		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.6416730428832604 | validation: 0.5329939864768468]
	TIME [epoch: 11.6 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6483238891026579		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.6483238891026579 | validation: 0.5337102357438785]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6489683517404564		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.6489683517404564 | validation: 0.5306990040637005]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536175039618146		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.6536175039618146 | validation: 0.548195484815653]
	TIME [epoch: 11.6 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6472729931998851		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.6472729931998851 | validation: 0.5310628351230762]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6459048737468673		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.6459048737468673 | validation: 0.520418140670803]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6440974574335173		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.6440974574335173 | validation: 0.5371875184636676]
	TIME [epoch: 11.6 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6492283821448651		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.6492283821448651 | validation: 0.529991273098618]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6428771756989573		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.6428771756989573 | validation: 0.5273269523179358]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6444134012469731		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.6444134012469731 | validation: 0.5278456760716163]
	TIME [epoch: 11.6 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6438510494942875		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.6438510494942875 | validation: 0.5255909969376396]
	TIME [epoch: 11.6 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6457659128096606		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.6457659128096606 | validation: 0.5306926259985907]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.642203250100668		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.642203250100668 | validation: 0.5372393271146223]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6427209303612701		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.6427209303612701 | validation: 0.5355592781310572]
	TIME [epoch: 11.6 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6519376110061725		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.6519376110061725 | validation: 0.5468128245140789]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6502238636499653		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.6502238636499653 | validation: 0.5362468666936372]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6478722493173985		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.6478722493173985 | validation: 0.5339345733119804]
	TIME [epoch: 11.6 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6472410595846511		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.6472410595846511 | validation: 0.5265249787331348]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374539084237062		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.6374539084237062 | validation: 0.5261503208775262]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6481496748597125		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.6481496748597125 | validation: 0.5443532623235354]
	TIME [epoch: 11.6 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.644047747807811		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.644047747807811 | validation: 0.522052442078658]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6476721248217505		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.6476721248217505 | validation: 0.5370692678488442]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6423529478108028		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.6423529478108028 | validation: 0.5432892526784117]
	TIME [epoch: 11.6 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6467573008764458		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.6467573008764458 | validation: 0.5245762755424187]
	TIME [epoch: 11.6 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6496218037620207		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.6496218037620207 | validation: 0.5378662799799774]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390541664832695		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.6390541664832695 | validation: 0.5208163739879786]
	TIME [epoch: 11.6 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6414125266171308		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.6414125266171308 | validation: 0.529441450252315]
	TIME [epoch: 11.6 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6428364061780155		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.6428364061780155 | validation: 0.5182770928007595]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6405483965586252		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.6405483965586252 | validation: 0.5252697905504664]
	TIME [epoch: 11.6 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6581881871165016		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.6581881871165016 | validation: 0.5359727952811456]
	TIME [epoch: 11.6 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6485011820740683		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.6485011820740683 | validation: 0.528527493546435]
	TIME [epoch: 11.6 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6468186655783564		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.6468186655783564 | validation: 0.5488373201764102]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6459399553447261		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.6459399553447261 | validation: 0.5250782739811496]
	TIME [epoch: 11.6 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6487462795195877		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.6487462795195877 | validation: 0.5314270159671309]
	TIME [epoch: 11.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6443122919168197		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.6443122919168197 | validation: 0.5336315581014589]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6468352199781443		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.6468352199781443 | validation: 0.5399167777954047]
	TIME [epoch: 11.6 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6443498593614264		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.6443498593614264 | validation: 0.527207481468391]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6410446979679223		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.6410446979679223 | validation: 0.5302737984593519]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6525703032361385		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.6525703032361385 | validation: 0.5404635912246251]
	TIME [epoch: 11.6 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6523984828556213		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.6523984828556213 | validation: 0.5193735205361025]
	TIME [epoch: 11.6 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6500943858104005		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.6500943858104005 | validation: 0.525505731638448]
	TIME [epoch: 11.6 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.642291287619232		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.642291287619232 | validation: 0.5354095023623449]
	TIME [epoch: 11.6 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470125906394392		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.6470125906394392 | validation: 0.518590690181156]
	TIME [epoch: 11.6 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493867462811675		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.6493867462811675 | validation: 0.573213759047588]
	TIME [epoch: 11.6 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6586289283692787		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.6586289283692787 | validation: 0.5377762449419173]
	TIME [epoch: 11.6 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6417331969194526		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.6417331969194526 | validation: 0.5473226886480391]
	TIME [epoch: 11.6 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374204581883074		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.6374204581883074 | validation: 0.5246710171269469]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6419097606935804		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.6419097606935804 | validation: 0.5258273062823697]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374823608133336		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.6374823608133336 | validation: 0.530504300252717]
	TIME [epoch: 11.6 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6443579238254903		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.6443579238254903 | validation: 0.5416076762428501]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6430209390140768		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.6430209390140768 | validation: 0.5386237310809581]
	TIME [epoch: 11.6 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6395112302662934		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.6395112302662934 | validation: 0.5424533309098792]
	TIME [epoch: 11.6 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6439557055355524		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.6439557055355524 | validation: 0.5296736058423187]
	TIME [epoch: 11.6 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6464713002597435		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.6464713002597435 | validation: 0.5365318529781655]
	TIME [epoch: 11.6 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6396783007988941		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.6396783007988941 | validation: 0.5213426507626364]
	TIME [epoch: 11.6 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.643667878245836		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.643667878245836 | validation: 0.5194521321178042]
	TIME [epoch: 11.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.640369446114674		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.640369446114674 | validation: 0.5329806189491288]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6450074602507876		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.6450074602507876 | validation: 0.5407149962894312]
	TIME [epoch: 11.6 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.636714327375972		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.636714327375972 | validation: 0.5362883392194345]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6349387980497403		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.6349387980497403 | validation: 0.5325226185941252]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6445929210154007		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.6445929210154007 | validation: 0.5363510823546365]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6448537597468643		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.6448537597468643 | validation: 0.5333683256920687]
	TIME [epoch: 11.6 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6398910199912917		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.6398910199912917 | validation: 0.5407779394485028]
	TIME [epoch: 11.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6481250989961889		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.6481250989961889 | validation: 0.5457583294327115]
	TIME [epoch: 11.6 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6406820838676248		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.6406820838676248 | validation: 0.5384320488683594]
	TIME [epoch: 11.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6407478102723682		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.6407478102723682 | validation: 0.533475931826007]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6376922799648285		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.6376922799648285 | validation: 0.5316492283777636]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.637342949337463		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.637342949337463 | validation: 0.5396248580949808]
	TIME [epoch: 11.6 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6330996095083241		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.6330996095083241 | validation: 0.5414484970550661]
	TIME [epoch: 11.6 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6386448988537333		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.6386448988537333 | validation: 0.5264245363067157]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6432979899068079		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.6432979899068079 | validation: 0.5325250315923824]
	TIME [epoch: 11.6 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.639507880062259		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.639507880062259 | validation: 0.5436643212684272]
	TIME [epoch: 11.6 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6449884376767889		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.6449884376767889 | validation: 0.5430426952462033]
	TIME [epoch: 11.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6393329000886919		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.6393329000886919 | validation: 0.5252006667715402]
	TIME [epoch: 11.6 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6357164039554524		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.6357164039554524 | validation: 0.5205005965177404]
	TIME [epoch: 11.6 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6429990786568617		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.6429990786568617 | validation: 0.5375813923954595]
	TIME [epoch: 11.6 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6405276944725495		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.6405276944725495 | validation: 0.5239693315275477]
	TIME [epoch: 11.6 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6469280941421507		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.6469280941421507 | validation: 0.528881001510979]
	TIME [epoch: 11.6 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6358619778055941		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.6358619778055941 | validation: 0.5352887697271903]
	TIME [epoch: 11.6 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6442945385668061		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.6442945385668061 | validation: 0.5397266125858305]
	TIME [epoch: 11.6 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.634267542935456		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.634267542935456 | validation: 0.5226956078275525]
	TIME [epoch: 11.6 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6406987089658052		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.6406987089658052 | validation: 0.5404796335680225]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6519016795662216		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.6519016795662216 | validation: 0.5272256323697234]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6476928651065148		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.6476928651065148 | validation: 0.5393775769197154]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6448357496370268		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.6448357496370268 | validation: 0.5295932202540464]
	TIME [epoch: 11.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6445712974860937		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.6445712974860937 | validation: 0.5390895774469896]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6528512662151311		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.6528512662151311 | validation: 0.5416784693261928]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6422053403357872		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.6422053403357872 | validation: 0.5298880916643405]
	TIME [epoch: 11.6 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6361227447575781		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.6361227447575781 | validation: 0.5393214114960919]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6378692182068929		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.6378692182068929 | validation: 0.527774397775216]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6406818363804541		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.6406818363804541 | validation: 0.5389466445733708]
	TIME [epoch: 11.6 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6492145197123824		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.6492145197123824 | validation: 0.544455725147147]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6342825456242412		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.6342825456242412 | validation: 0.5335713853736332]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6333372792013697		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.6333372792013697 | validation: 0.5318274569836301]
	TIME [epoch: 11.6 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6373692175640414		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.6373692175640414 | validation: 0.5237411094135744]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6388306411422334		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.6388306411422334 | validation: 0.5399158818108108]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6359564534850535		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.6359564534850535 | validation: 0.5320927302409271]
	TIME [epoch: 11.6 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6401288614137773		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.6401288614137773 | validation: 0.5431747750025567]
	TIME [epoch: 11.6 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6414109341247873		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.6414109341247873 | validation: 0.5258904219111127]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6328459614168481		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.6328459614168481 | validation: 0.5349640419251759]
	TIME [epoch: 11.6 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6370165535974477		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.6370165535974477 | validation: 0.5333229941047474]
	TIME [epoch: 11.6 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6385123911977454		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.6385123911977454 | validation: 0.5228469744962062]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6347978624053239		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.6347978624053239 | validation: 0.5234631714835316]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6398457223783572		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.6398457223783572 | validation: 0.5278915062133839]
	TIME [epoch: 11.6 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6375500375560974		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.6375500375560974 | validation: 0.5225290793968103]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6391309084542387		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.6391309084542387 | validation: 0.5356905153656599]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6353701483789593		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.6353701483789593 | validation: 0.5373533079762961]
	TIME [epoch: 11.6 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6396589001546337		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.6396589001546337 | validation: 0.5381294803968973]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6336181473327401		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.6336181473327401 | validation: 0.5251888290540472]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6363162461947585		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.6363162461947585 | validation: 0.5350517351633143]
	TIME [epoch: 11.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6336784741290505		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.6336784741290505 | validation: 0.528871818179932]
	TIME [epoch: 11.6 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.633538867083463		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.633538867083463 | validation: 0.5367289069411041]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6360848254183056		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.6360848254183056 | validation: 0.5345775763662542]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6353978617479012		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.6353978617479012 | validation: 0.5353907971369529]
	TIME [epoch: 11.6 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6385223808476129		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.6385223808476129 | validation: 0.5407340434907482]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6373365707585177		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.6373365707585177 | validation: 0.5266616970559107]
	TIME [epoch: 11.6 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6368946549794534		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.6368946549794534 | validation: 0.5287596784061557]
	TIME [epoch: 11.6 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6327729737154016		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.6327729737154016 | validation: 0.5357264620391857]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6339668756657512		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.6339668756657512 | validation: 0.5310463001060789]
	TIME [epoch: 11.6 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6336537143237757		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.6336537143237757 | validation: 0.5234508973210379]
	TIME [epoch: 11.6 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6282306938807277		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.6282306938807277 | validation: 0.5241241168616836]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6353145581672072		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.6353145581672072 | validation: 0.5294905131668757]
	TIME [epoch: 11.6 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6345455068111983		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.6345455068111983 | validation: 0.5200812250701107]
	TIME [epoch: 11.6 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6335718113209866		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.6335718113209866 | validation: 0.5200367368447982]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6394856828468509		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.6394856828468509 | validation: 0.5121038627560627]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1806.pth
	Model improved!!!
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6352380943857042		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.6352380943857042 | validation: 0.528044956398967]
	TIME [epoch: 11.6 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6423763891002738		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.6423763891002738 | validation: 0.5308808942221609]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6388810737177771		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.6388810737177771 | validation: 0.5218629398159271]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390991997599273		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.6390991997599273 | validation: 0.5137807792978453]
	TIME [epoch: 11.6 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281463587773493		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.6281463587773493 | validation: 0.5336697846765677]
	TIME [epoch: 11.6 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267792075351197		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.6267792075351197 | validation: 0.5326946500806173]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.633157698582874		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.633157698582874 | validation: 0.5234404591482533]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.636338256480217		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.636338256480217 | validation: 0.5326352484242104]
	TIME [epoch: 11.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6377715225980416		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.6377715225980416 | validation: 0.5274975059753662]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6307698714293541		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.6307698714293541 | validation: 0.5155806202620238]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344901983938852		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.6344901983938852 | validation: 0.5210001226310138]
	TIME [epoch: 11.6 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329428446030063		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.6329428446030063 | validation: 0.5393645020003447]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6306278839462869		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.6306278839462869 | validation: 0.5242924340449647]
	TIME [epoch: 11.6 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6333286380533827		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.6333286380533827 | validation: 0.5291234804514169]
	TIME [epoch: 11.6 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6338015689026264		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.6338015689026264 | validation: 0.5337649120252634]
	TIME [epoch: 11.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287777900527168		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.6287777900527168 | validation: 0.521843680015042]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6388009053804087		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.6388009053804087 | validation: 0.5293553874775959]
	TIME [epoch: 11.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6351698106701849		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.6351698106701849 | validation: 0.5376682927017055]
	TIME [epoch: 11.6 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6414265961037504		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.6414265961037504 | validation: 0.5305876737547369]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.640079135787037		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.640079135787037 | validation: 0.5294560841525214]
	TIME [epoch: 11.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6351555924103138		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.6351555924103138 | validation: 0.5386250666509748]
	TIME [epoch: 11.6 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6341450101552927		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.6341450101552927 | validation: 0.521604594751054]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6362500623387856		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.6362500623387856 | validation: 0.5235571271894397]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.638037446618865		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.638037446618865 | validation: 0.5212655229775505]
	TIME [epoch: 11.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.633519056441532		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.633519056441532 | validation: 0.5220988306618174]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329007776411864		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.6329007776411864 | validation: 0.516735792517809]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.630066728402318		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.630066728402318 | validation: 0.5293340531735663]
	TIME [epoch: 11.6 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293996254595376		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.6293996254595376 | validation: 0.5227924427858045]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6328605488124033		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.6328605488124033 | validation: 0.5415775695920347]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6297884537804617		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.6297884537804617 | validation: 0.5283251051678294]
	TIME [epoch: 11.6 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6348806901976716		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.6348806901976716 | validation: 0.5328110197500019]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6365389273162485		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.6365389273162485 | validation: 0.5091261899811632]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1838.pth
	Model improved!!!
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.632196012846082		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.632196012846082 | validation: 0.5307002841799774]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6349712542980642		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.6349712542980642 | validation: 0.5296395121807091]
	TIME [epoch: 11.6 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6219708198559859		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.6219708198559859 | validation: 0.5339159672118887]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6251103517594062		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.6251103517594062 | validation: 0.5305207900709469]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6268734392935568		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.6268734392935568 | validation: 0.5365454874048369]
	TIME [epoch: 11.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6357343859714129		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.6357343859714129 | validation: 0.5134980691147143]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299541701262775		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.6299541701262775 | validation: 0.5263434263740139]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6323296129366804		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.6323296129366804 | validation: 0.5133304062208881]
	TIME [epoch: 11.6 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6252386184519146		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.6252386184519146 | validation: 0.526713134323206]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6357766005710388		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.6357766005710388 | validation: 0.5169335002743203]
	TIME [epoch: 11.6 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6272184186004767		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.6272184186004767 | validation: 0.5234211191938207]
	TIME [epoch: 11.6 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6300029538910712		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.6300029538910712 | validation: 0.5228597686700622]
	TIME [epoch: 11.6 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6260766092378798		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.6260766092378798 | validation: 0.5342742464095437]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6377983670399863		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.6377983670399863 | validation: 0.5294957119943795]
	TIME [epoch: 11.6 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6246597132677785		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.6246597132677785 | validation: 0.5200069614750783]
	TIME [epoch: 11.6 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6334474063775362		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.6334474063775362 | validation: 0.5288688597210451]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6381398694525748		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.6381398694525748 | validation: 0.531544922410543]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293805358540554		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.6293805358540554 | validation: 0.5124263445835886]
	TIME [epoch: 11.6 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275808041125116		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.6275808041125116 | validation: 0.5192435707353361]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6263092059416702		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.6263092059416702 | validation: 0.5337043751323314]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.626418781945383		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.626418781945383 | validation: 0.5198545520221319]
	TIME [epoch: 11.6 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.628520831896021		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.628520831896021 | validation: 0.5183320730687395]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220382466678915		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.6220382466678915 | validation: 0.5236770210440469]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6309756326361216		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.6309756326361216 | validation: 0.5333392906165736]
	TIME [epoch: 11.6 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6285771753382731		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.6285771753382731 | validation: 0.5225235077972985]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6257889682390697		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.6257889682390697 | validation: 0.5160856902563405]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6274298654827601		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.6274298654827601 | validation: 0.5249883420979146]
	TIME [epoch: 11.6 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6315440075099408		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.6315440075099408 | validation: 0.5242430216081199]
	TIME [epoch: 11.6 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6289019501600501		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.6289019501600501 | validation: 0.5246202663299093]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6302320310776539		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.6302320310776539 | validation: 0.5303838494218535]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281358647833645		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.6281358647833645 | validation: 0.5286035479775752]
	TIME [epoch: 11.6 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.629258720439752		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.629258720439752 | validation: 0.5265012175317859]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.635080242443324		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.635080242443324 | validation: 0.5185520200486394]
	TIME [epoch: 11.6 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6303214066374785		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.6303214066374785 | validation: 0.5272151769849299]
	TIME [epoch: 11.6 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.641443743086905		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.641443743086905 | validation: 0.5157071012754797]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.633043456087066		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.633043456087066 | validation: 0.5265989901054051]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6326300719095868		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.6326300719095868 | validation: 0.5111185656765236]
	TIME [epoch: 11.6 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6369871187352936		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.6369871187352936 | validation: 0.5205745882331663]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6272120127066614		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.6272120127066614 | validation: 0.5214261605063721]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6323718157427378		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.6323718157427378 | validation: 0.5225990176375641]
	TIME [epoch: 11.6 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6376142452529101		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.6376142452529101 | validation: 0.5252114555900638]
	TIME [epoch: 11.6 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6240062833085913		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.6240062833085913 | validation: 0.5266638170279418]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6298978476044326		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.6298978476044326 | validation: 0.5305914860675713]
	TIME [epoch: 11.6 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6288016036354307		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.6288016036354307 | validation: 0.5235816641705259]
	TIME [epoch: 11.6 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621195012300797		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.621195012300797 | validation: 0.5216249727437111]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6311207784263213		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.6311207784263213 | validation: 0.5315493718526425]
	TIME [epoch: 11.6 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224235242501353		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.6224235242501353 | validation: 0.5150741082447349]
	TIME [epoch: 11.6 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6222174200885962		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.6222174200885962 | validation: 0.5252253395896859]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6273809727975304		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.6273809727975304 | validation: 0.5170467506801006]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253865977663421		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.6253865977663421 | validation: 0.5135604872225451]
	TIME [epoch: 11.6 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301590596735367		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.6301590596735367 | validation: 0.5234361394079597]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6257708174145105		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.6257708174145105 | validation: 0.5287305821246763]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6314735088157726		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.6314735088157726 | validation: 0.5220159765131857]
	TIME [epoch: 11.6 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231856730384563		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.6231856730384563 | validation: 0.5258585798507306]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6303410106778338		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.6303410106778338 | validation: 0.5188539855100395]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6244581034178853		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.6244581034178853 | validation: 0.5211791030932964]
	TIME [epoch: 11.6 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6316705591920229		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.6316705591920229 | validation: 0.5237205129761402]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278859158835426		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.6278859158835426 | validation: 0.5308108716023666]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312956683120106		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.6312956683120106 | validation: 0.5073312358201439]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1897.pth
	Model improved!!!
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6310394691166131		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.6310394691166131 | validation: 0.5261760052197758]
	TIME [epoch: 11.6 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621436992039446		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.621436992039446 | validation: 0.5176201639803748]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6216771992532972		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.6216771992532972 | validation: 0.5215842073363467]
	TIME [epoch: 11.6 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6263678476330827		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.6263678476330827 | validation: 0.5269436647519191]
	TIME [epoch: 11.6 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329100897020469		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.6329100897020469 | validation: 0.5174215151243825]
	TIME [epoch: 11.6 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281419154364565		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.6281419154364565 | validation: 0.5158429289887262]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6244458917935934		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.6244458917935934 | validation: 0.5236741462340686]
	TIME [epoch: 11.6 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267978150396947		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.6267978150396947 | validation: 0.5154332091951886]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6333492381382702		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.6333492381382702 | validation: 0.5359418191647478]
	TIME [epoch: 11.6 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6221477637582419		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.6221477637582419 | validation: 0.5148715544450304]
	TIME [epoch: 11.6 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243065888487459		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.6243065888487459 | validation: 0.5265441960977291]
	TIME [epoch: 11.6 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6248113769033252		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.6248113769033252 | validation: 0.517369921210101]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.625013128111902		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.625013128111902 | validation: 0.5129141117093737]
	TIME [epoch: 11.6 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283667144756677		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.6283667144756677 | validation: 0.5229105271881395]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6289276902164905		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.6289276902164905 | validation: 0.5290991067198325]
	TIME [epoch: 11.6 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301234599892892		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.6301234599892892 | validation: 0.5218124830548185]
	TIME [epoch: 11.6 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6234661098232164		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.6234661098232164 | validation: 0.517458946954403]
	TIME [epoch: 11.6 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278183007572603		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.6278183007572603 | validation: 0.5257444254538537]
	TIME [epoch: 11.6 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6282910745044172		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.6282910745044172 | validation: 0.5212050207805333]
	TIME [epoch: 11.6 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235928533918249		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.6235928533918249 | validation: 0.5221062385224196]
	TIME [epoch: 11.6 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6305472531912693		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.6305472531912693 | validation: 0.5126396442766635]
	TIME [epoch: 11.6 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6306176578832485		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.6306176578832485 | validation: 0.5253153476773275]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6303979896580377		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.6303979896580377 | validation: 0.526138890205797]
	TIME [epoch: 11.6 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275684375733429		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.6275684375733429 | validation: 0.5287800819299384]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6247914117593087		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.6247914117593087 | validation: 0.5350342457294951]
	TIME [epoch: 11.6 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6286296744415396		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.6286296744415396 | validation: 0.5305415092612803]
	TIME [epoch: 11.6 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231416823797067		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.6231416823797067 | validation: 0.5271333836764918]
	TIME [epoch: 11.6 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6350645281485602		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.6350645281485602 | validation: 0.540554491675491]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6313521910546148		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.6313521910546148 | validation: 0.5308369724730385]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6276346146905684		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.6276346146905684 | validation: 0.527167803503884]
	TIME [epoch: 11.6 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235823311251535		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.6235823311251535 | validation: 0.5327785581526505]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6260459413101406		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.6260459413101406 | validation: 0.5290742898344253]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275919328522024		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.6275919328522024 | validation: 0.5090492767689099]
	TIME [epoch: 11.6 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6245456506354015		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.6245456506354015 | validation: 0.5374497255326054]
	TIME [epoch: 11.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6256018711322986		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.6256018711322986 | validation: 0.5291054922504226]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253205228799859		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.6253205228799859 | validation: 0.5315160055838015]
	TIME [epoch: 11.6 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6279828217240033		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.6279828217240033 | validation: 0.5198781222274477]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6232147132230115		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.6232147132230115 | validation: 0.5380451043590305]
	TIME [epoch: 11.6 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6222332725252298		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.6222332725252298 | validation: 0.5240777322604883]
	TIME [epoch: 11.6 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6241500417349075		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.6241500417349075 | validation: 0.5198654623627876]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6250766149776461		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.6250766149776461 | validation: 0.5199266965355369]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6274005782662017		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.6274005782662017 | validation: 0.5351029508513551]
	TIME [epoch: 11.6 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299144616594107		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.6299144616594107 | validation: 0.5265608568949303]
	TIME [epoch: 11.6 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.620305278974844		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.620305278974844 | validation: 0.5198926620736222]
	TIME [epoch: 11.6 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6244311595013469		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.6244311595013469 | validation: 0.5272098083455273]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.61126371348513		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.61126371348513 | validation: 0.5287520713663091]
	TIME [epoch: 11.6 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6244651387651822		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.6244651387651822 | validation: 0.5161904289569168]
	TIME [epoch: 11.6 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6221378098052602		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.6221378098052602 | validation: 0.5295819466695625]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621577551047392		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.621577551047392 | validation: 0.525339736930787]
	TIME [epoch: 11.6 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.628696891134628		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.628696891134628 | validation: 0.5162930340561313]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283489242369781		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.6283489242369781 | validation: 0.5211287682955795]
	TIME [epoch: 11.6 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267194373940506		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.6267194373940506 | validation: 0.5310094469501031]
	TIME [epoch: 11.6 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6225309686024149		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.6225309686024149 | validation: 0.5244277409632571]
	TIME [epoch: 11.6 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6308717716646227		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.6308717716646227 | validation: 0.5252095823830205]
	TIME [epoch: 11.6 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6284156033873745		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.6284156033873745 | validation: 0.5194899898377086]
	TIME [epoch: 11.6 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616984902500761		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.616984902500761 | validation: 0.5279674269662565]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6296912197489883		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.6296912197489883 | validation: 0.49732348806522125]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r5_20240310_045134/states/model_tr_study203_1954.pth
	Model improved!!!
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6211905769185102		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.6211905769185102 | validation: 0.5143391445133825]
	TIME [epoch: 11.6 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6247225167119177		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.6247225167119177 | validation: 0.5235890883670167]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.619095234094716		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.619095234094716 | validation: 0.5110477532220996]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6234318906389984		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.6234318906389984 | validation: 0.5293833537428407]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6230154862292656		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.6230154862292656 | validation: 0.5166668402004475]
	TIME [epoch: 11.6 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6208705772277152		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.6208705772277152 | validation: 0.5305979814639036]
	TIME [epoch: 11.6 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6250433625228689		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.6250433625228689 | validation: 0.5240619880753367]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6255358734482991		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.6255358734482991 | validation: 0.5244342901925869]
	TIME [epoch: 11.6 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301008979298226		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.6301008979298226 | validation: 0.5186293761165635]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254733395895071		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.6254733395895071 | validation: 0.5040284285652499]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6240218384535225		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.6240218384535225 | validation: 0.5136914774381082]
	TIME [epoch: 11.6 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6270652215801734		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.6270652215801734 | validation: 0.5350634188379949]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329181235117438		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.6329181235117438 | validation: 0.523531289283075]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6230580150136502		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.6230580150136502 | validation: 0.5218840224856857]
	TIME [epoch: 11.6 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.629259906043363		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.629259906043363 | validation: 0.5192338606313499]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299821094050853		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.6299821094050853 | validation: 0.5161671329267905]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6268467111184133		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.6268467111184133 | validation: 0.518462088159972]
	TIME [epoch: 11.6 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239493105954775		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.6239493105954775 | validation: 0.5127133319104866]
	TIME [epoch: 11.6 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287170799185318		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.6287170799185318 | validation: 0.5192864217091101]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228065269184679		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.6228065269184679 | validation: 0.5344740684978108]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6268874130587588		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.6268874130587588 | validation: 0.5243019054595439]
	TIME [epoch: 11.6 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6149741530222118		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.6149741530222118 | validation: 0.5168578433162856]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224577502364954		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.6224577502364954 | validation: 0.5297575746732777]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6261024686996266		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.6261024686996266 | validation: 0.514963102043981]
	TIME [epoch: 11.6 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6244481050069979		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.6244481050069979 | validation: 0.5281706725398457]
	TIME [epoch: 11.6 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.626746191464512		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.626746191464512 | validation: 0.5143373524460315]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269771617935243		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.6269771617935243 | validation: 0.5156642361091219]
	TIME [epoch: 11.6 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6227500596763103		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.6227500596763103 | validation: 0.5123889803491435]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6262856301752644		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.6262856301752644 | validation: 0.5110942651720286]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6221055443128041		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.6221055443128041 | validation: 0.5247409778110981]
	TIME [epoch: 11.6 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6264566366241726		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.6264566366241726 | validation: 0.5264736704952592]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205014428055198		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.6205014428055198 | validation: 0.5278376546053449]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6245114456502778		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.6245114456502778 | validation: 0.5029448397110946]
	TIME [epoch: 11.6 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6282052522313915		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.6282052522313915 | validation: 0.5187566980792453]
	TIME [epoch: 11.6 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6272581027066972		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.6272581027066972 | validation: 0.5235081606640796]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243429467289019		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.6243429467289019 | validation: 0.5280817021098031]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6233913000044791		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.6233913000044791 | validation: 0.5265354614596331]
	TIME [epoch: 11.6 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.626129749592882		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.626129749592882 | validation: 0.515520891356029]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235020394601177		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.6235020394601177 | validation: 0.5257032309763238]
	TIME [epoch: 11.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6230706270970522		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.6230706270970522 | validation: 0.5119213142684491]
	TIME [epoch: 11.6 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6212822766506837		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.6212822766506837 | validation: 0.5213896599253579]
	TIME [epoch: 11.6 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6271825585651521		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.6271825585651521 | validation: 0.5135635983857972]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6218197417933277		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.6218197417933277 | validation: 0.5335190887672093]
	TIME [epoch: 11.6 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6238145522185279		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.6238145522185279 | validation: 0.5236512481674263]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6211743534696341		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.6211743534696341 | validation: 0.5231523078742015]
	TIME [epoch: 11.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6208598651295966		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.6208598651295966 | validation: 0.5219031452091197]
	TIME [epoch: 11.5 sec]
Finished training in 23358.521 seconds.
