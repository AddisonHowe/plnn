Args:
Namespace(name='model_tr_study203', outdir='out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2', training_data='data/transition_rate_studies/tr_study203/tr_study203_training/r2', validation_data='data/transition_rate_studies/tr_study203/tr_study203_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 9906231

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.443669916775438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.443669916775438 | validation: 11.420720926871894]
	TIME [epoch: 47.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.85528914446253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.85528914446253 | validation: 10.96720156483858]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.278495071489479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.278495071489479 | validation: 10.412923380834524]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.2007749413235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.2007749413235 | validation: 9.166051152357689]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.686621868955878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.686621868955878 | validation: 7.365803516165709]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.407232082961855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.407232082961855 | validation: 6.266539687924897]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.814801421452626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.814801421452626 | validation: 6.038351226384276]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.328874910338789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.328874910338789 | validation: 5.846215048434727]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.988426418308433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.988426418308433 | validation: 5.254733719810084]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.694527392759443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.694527392759443 | validation: 5.113919674461756]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.626226521489424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.626226521489424 | validation: 5.2330119060371985]
	TIME [epoch: 9.11 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.35732968845777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.35732968845777 | validation: 4.779841344430453]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.997399456600205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.997399456600205 | validation: 4.380278839469607]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9800387389608494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9800387389608494 | validation: 8.383584267391681]
	TIME [epoch: 9.08 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.461851032537934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.461851032537934 | validation: 4.6285489549147965]
	TIME [epoch: 9.11 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7408054317088784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7408054317088784 | validation: 4.1346786852974216]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6045759278301994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6045759278301994 | validation: 4.0662404847484925]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.570653255195748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.570653255195748 | validation: 3.929585429765771]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5807777272946737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5807777272946737 | validation: 4.462119077495374]
	TIME [epoch: 9.18 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4886132874197813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4886132874197813 | validation: 3.8839616885084096]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.731267353264969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.731267353264969 | validation: 3.8200909215877124]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6558592765651325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6558592765651325 | validation: 3.7431960429094016]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.390772481082783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.390772481082783 | validation: 4.387322643862359]
	TIME [epoch: 9.12 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.38219353124028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.38219353124028 | validation: 4.277530897737789]
	TIME [epoch: 9.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4021895823605925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4021895823605925 | validation: 3.8481532561889322]
	TIME [epoch: 9.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.218752095855904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.218752095855904 | validation: 4.632010660728934]
	TIME [epoch: 9.1 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8518367531622304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8518367531622304 | validation: 4.118824654664332]
	TIME [epoch: 9.09 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.182121576985675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.182121576985675 | validation: 4.057331247399858]
	TIME [epoch: 9.12 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.588277703978098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.588277703978098 | validation: 3.8193778003826946]
	TIME [epoch: 9.11 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.428060379363855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.428060379363855 | validation: 3.8910173267294157]
	TIME [epoch: 9.1 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3189425988802577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3189425988802577 | validation: 3.7403755894343735]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2757590039020825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2757590039020825 | validation: 3.8653137391192]
	TIME [epoch: 9.1 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.167328504716878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.167328504716878 | validation: 4.195128592356904]
	TIME [epoch: 9.09 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.226412270483516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.226412270483516 | validation: 3.573272817486073]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4973862944686034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4973862944686034 | validation: 3.4544627739764193]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.333059775921529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.333059775921529 | validation: 4.199360828578574]
	TIME [epoch: 9.1 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8767272792892404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8767272792892404 | validation: 3.8240279833919555]
	TIME [epoch: 9.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7933474295219014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7933474295219014 | validation: 3.831064968298528]
	TIME [epoch: 9.09 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.247829840148009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.247829840148009 | validation: 3.9453432555344725]
	TIME [epoch: 9.09 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2534439821026964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2534439821026964 | validation: 3.950064090194165]
	TIME [epoch: 9.09 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.208827733023899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.208827733023899 | validation: 3.6499787766228704]
	TIME [epoch: 9.11 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1052103440038064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1052103440038064 | validation: 3.9798733903163814]
	TIME [epoch: 9.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2014505106782787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2014505106782787 | validation: 3.985960667575643]
	TIME [epoch: 9.09 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1365829637013016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1365829637013016 | validation: 3.7211188756246614]
	TIME [epoch: 9.09 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.153101947594337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.153101947594337 | validation: 4.827181790653143]
	TIME [epoch: 9.11 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0702440843714367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0702440843714367 | validation: 5.007082646099324]
	TIME [epoch: 9.09 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1467457228986118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1467457228986118 | validation: 3.730357655778737]
	TIME [epoch: 9.09 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.120672041791913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.120672041791913 | validation: 3.4848475505820957]
	TIME [epoch: 9.08 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1588653238371562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1588653238371562 | validation: 3.6979310517192605]
	TIME [epoch: 9.09 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1616867520951972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1616867520951972 | validation: 3.6379011205974825]
	TIME [epoch: 9.1 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0522893139805727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0522893139805727 | validation: 3.4362530741338917]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.0893983131036595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0893983131036595 | validation: 3.987860318031661]
	TIME [epoch: 9.09 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4137134831815907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4137134831815907 | validation: 4.0289510202034835]
	TIME [epoch: 9.1 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0959093329818543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0959093329818543 | validation: 4.985054843685167]
	TIME [epoch: 9.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.862815859689436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.862815859689436 | validation: 3.5014389102641017]
	TIME [epoch: 9.08 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1539020365881743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1539020365881743 | validation: 3.7465462452767566]
	TIME [epoch: 9.09 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0233920670328556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0233920670328556 | validation: 4.325276298768869]
	TIME [epoch: 9.08 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0493746542411655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0493746542411655 | validation: 3.592553954947713]
	TIME [epoch: 9.11 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0864955282103765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0864955282103765 | validation: 3.523539681169745]
	TIME [epoch: 9.1 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.015724448343465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.015724448343465 | validation: 3.44772461885992]
	TIME [epoch: 9.09 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.01758676330569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.01758676330569 | validation: 4.149390347759754]
	TIME [epoch: 9.09 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.997941625221389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.997941625221389 | validation: 4.009149143902047]
	TIME [epoch: 9.11 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.997664444190533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.997664444190533 | validation: 5.1377013270848675]
	TIME [epoch: 9.09 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2618008744939275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2618008744939275 | validation: 3.5950135276212905]
	TIME [epoch: 9.09 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.546155406790144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.546155406790144 | validation: 3.353924821906288]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0844793945936386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0844793945936386 | validation: 3.7444673110184095]
	TIME [epoch: 9.11 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.965142515255635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.965142515255635 | validation: 4.134557530961908]
	TIME [epoch: 9.09 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.968344328998128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.968344328998128 | validation: 3.790836123135055]
	TIME [epoch: 9.09 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.026155530495153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.026155530495153 | validation: 3.669923211827483]
	TIME [epoch: 9.09 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0273902957771077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0273902957771077 | validation: 3.748509261078813]
	TIME [epoch: 9.09 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.021891440879958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.021891440879958 | validation: 3.5801244989858945]
	TIME [epoch: 9.12 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2922585587570787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2922585587570787 | validation: 5.672464896488227]
	TIME [epoch: 9.08 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6255895052094935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6255895052094935 | validation: 5.177991846323082]
	TIME [epoch: 9.08 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6698119420227187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6698119420227187 | validation: 4.52726995805467]
	TIME [epoch: 9.09 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.671594341883516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.671594341883516 | validation: 3.5324357464998104]
	TIME [epoch: 9.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.388893386727201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.388893386727201 | validation: 3.6199241059289786]
	TIME [epoch: 9.08 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0394892178814135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0394892178814135 | validation: 3.5487091974547607]
	TIME [epoch: 9.09 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.933581791792151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.933581791792151 | validation: 3.738456953315005]
	TIME [epoch: 9.08 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.037379526044613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.037379526044613 | validation: 3.5851270700574913]
	TIME [epoch: 9.11 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.809256079465394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.809256079465394 | validation: 3.4356464083078277]
	TIME [epoch: 9.09 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.155833310754904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.155833310754904 | validation: 3.3796649784992274]
	TIME [epoch: 9.09 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.747500801419909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.747500801419909 | validation: 3.758268959815287]
	TIME [epoch: 9.09 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5127382793719932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5127382793719932 | validation: 3.615957091967095]
	TIME [epoch: 9.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3570044951139018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3570044951139018 | validation: 4.01154536350816]
	TIME [epoch: 9.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.447168262881811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.447168262881811 | validation: 3.6865547808467936]
	TIME [epoch: 9.08 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.025056829986995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.025056829986995 | validation: 4.868843388799459]
	TIME [epoch: 9.08 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4275553624615407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4275553624615407 | validation: 4.759489413861709]
	TIME [epoch: 9.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.260547906522477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.260547906522477 | validation: 3.7563971694072418]
	TIME [epoch: 9.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1400178473172273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1400178473172273 | validation: 3.6122170791705477]
	TIME [epoch: 9.09 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.254008710376381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.254008710376381 | validation: 3.7731526919727356]
	TIME [epoch: 9.09 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0629986636541626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0629986636541626 | validation: 3.7395904331570904]
	TIME [epoch: 9.08 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4011819055011685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4011819055011685 | validation: 5.315433396002772]
	TIME [epoch: 9.1 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.475270101245468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.475270101245468 | validation: 3.4032157173491866]
	TIME [epoch: 9.08 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.194372637322384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.194372637322384 | validation: 3.470206938746631]
	TIME [epoch: 9.08 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9319909018835197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9319909018835197 | validation: 4.059035555269234]
	TIME [epoch: 9.09 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8884611576851458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8884611576851458 | validation: 3.1678618176055693]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.933898652232662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.933898652232662 | validation: 5.467759652127856]
	TIME [epoch: 9.09 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4641501971751723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4641501971751723 | validation: 4.519644866524736]
	TIME [epoch: 9.07 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7016640127341085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7016640127341085 | validation: 4.003278916972581]
	TIME [epoch: 9.07 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.504223170977331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.504223170977331 | validation: 4.430471572185851]
	TIME [epoch: 9.1 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9263693840366174		[learning rate: 0.0099673]
	Learning Rate: 0.00996733
	LOSS [training: 2.9263693840366174 | validation: 3.8221780190543266]
	TIME [epoch: 9.08 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.84600459057912		[learning rate: 0.0099312]
	Learning Rate: 0.00993116
	LOSS [training: 2.84600459057912 | validation: 5.140041249456606]
	TIME [epoch: 9.08 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2442966042092594		[learning rate: 0.0098951]
	Learning Rate: 0.00989512
	LOSS [training: 3.2442966042092594 | validation: 4.87483559873905]
	TIME [epoch: 9.08 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.254339904841211		[learning rate: 0.0098592]
	Learning Rate: 0.00985921
	LOSS [training: 3.254339904841211 | validation: 4.1417032453149325]
	TIME [epoch: 9.08 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.07718706310238		[learning rate: 0.0098234]
	Learning Rate: 0.00982343
	LOSS [training: 3.07718706310238 | validation: 4.251016872023179]
	TIME [epoch: 9.09 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.923158301981406		[learning rate: 0.0097878]
	Learning Rate: 0.00978778
	LOSS [training: 2.923158301981406 | validation: 4.0831085040088295]
	TIME [epoch: 9.07 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2583300710733356		[learning rate: 0.0097523]
	Learning Rate: 0.00975226
	LOSS [training: 3.2583300710733356 | validation: 3.3386932064764037]
	TIME [epoch: 9.08 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.397364761230669		[learning rate: 0.0097169]
	Learning Rate: 0.00971687
	LOSS [training: 3.397364761230669 | validation: 3.4795773465179316]
	TIME [epoch: 9.08 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9771940990884365		[learning rate: 0.0096816]
	Learning Rate: 0.0096816
	LOSS [training: 2.9771940990884365 | validation: 4.689657169787997]
	TIME [epoch: 9.1 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1726105518924865		[learning rate: 0.0096465]
	Learning Rate: 0.00964647
	LOSS [training: 3.1726105518924865 | validation: 4.336463332571128]
	TIME [epoch: 9.09 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.03828883926399		[learning rate: 0.0096115]
	Learning Rate: 0.00961146
	LOSS [training: 3.03828883926399 | validation: 3.9233951587240936]
	TIME [epoch: 9.08 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.60204966762481		[learning rate: 0.0095766]
	Learning Rate: 0.00957658
	LOSS [training: 3.60204966762481 | validation: 3.4029663513559196]
	TIME [epoch: 9.07 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.965955764090592		[learning rate: 0.0095418]
	Learning Rate: 0.00954183
	LOSS [training: 2.965955764090592 | validation: 3.6426829785569677]
	TIME [epoch: 9.09 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1005847820286605		[learning rate: 0.0095072]
	Learning Rate: 0.0095072
	LOSS [training: 3.1005847820286605 | validation: 5.013235920720243]
	TIME [epoch: 9.06 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.33232767822429		[learning rate: 0.0094727]
	Learning Rate: 0.0094727
	LOSS [training: 3.33232767822429 | validation: 3.3600995623142804]
	TIME [epoch: 9.07 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6649253691364563		[learning rate: 0.0094383]
	Learning Rate: 0.00943832
	LOSS [training: 2.6649253691364563 | validation: 3.3927218499793383]
	TIME [epoch: 9.07 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7969294065486947		[learning rate: 0.0094041]
	Learning Rate: 0.00940407
	LOSS [training: 2.7969294065486947 | validation: 3.5847870820789787]
	TIME [epoch: 9.08 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6302516811099323		[learning rate: 0.0093699]
	Learning Rate: 0.00936994
	LOSS [training: 2.6302516811099323 | validation: 3.6987983544344627]
	TIME [epoch: 9.07 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.701029065877218		[learning rate: 0.0093359]
	Learning Rate: 0.00933594
	LOSS [training: 2.701029065877218 | validation: 3.8672779148427487]
	TIME [epoch: 9.07 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.873473585036252		[learning rate: 0.0093021]
	Learning Rate: 0.00930206
	LOSS [training: 2.873473585036252 | validation: 3.6589115397168985]
	TIME [epoch: 9.07 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6665678534745356		[learning rate: 0.0092683]
	Learning Rate: 0.0092683
	LOSS [training: 2.6665678534745356 | validation: 3.074984694550964]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0953772181345514		[learning rate: 0.0092347]
	Learning Rate: 0.00923466
	LOSS [training: 3.0953772181345514 | validation: 3.3700567114635414]
	TIME [epoch: 9.09 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6405442290805974		[learning rate: 0.0092011]
	Learning Rate: 0.00920115
	LOSS [training: 2.6405442290805974 | validation: 3.8460829520869595]
	TIME [epoch: 9.09 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7660450838213047		[learning rate: 0.0091678]
	Learning Rate: 0.00916776
	LOSS [training: 2.7660450838213047 | validation: 5.3229593713909695]
	TIME [epoch: 9.06 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.974565048099098		[learning rate: 0.0091345]
	Learning Rate: 0.00913449
	LOSS [training: 2.974565048099098 | validation: 3.2330200450845954]
	TIME [epoch: 9.08 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.631852532573436		[learning rate: 0.0091013]
	Learning Rate: 0.00910134
	LOSS [training: 2.631852532573436 | validation: 3.1274340823241373]
	TIME [epoch: 9.11 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.686156813611592		[learning rate: 0.0090683]
	Learning Rate: 0.00906831
	LOSS [training: 2.686156813611592 | validation: 3.220620011451981]
	TIME [epoch: 9.08 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.524248506748698		[learning rate: 0.0090354]
	Learning Rate: 0.0090354
	LOSS [training: 2.524248506748698 | validation: 3.36415375201632]
	TIME [epoch: 9.09 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.694302134389991		[learning rate: 0.0090026]
	Learning Rate: 0.00900261
	LOSS [training: 2.694302134389991 | validation: 3.079414156224489]
	TIME [epoch: 9.07 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.89697240277248		[learning rate: 0.0089699]
	Learning Rate: 0.00896994
	LOSS [training: 2.89697240277248 | validation: 4.028986986012674]
	TIME [epoch: 9.08 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.846388553343987		[learning rate: 0.0089374]
	Learning Rate: 0.00893739
	LOSS [training: 2.846388553343987 | validation: 3.406285418713176]
	TIME [epoch: 9.09 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.653925797959844		[learning rate: 0.008905]
	Learning Rate: 0.00890495
	LOSS [training: 2.653925797959844 | validation: 3.5440320535544902]
	TIME [epoch: 9.06 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.532212719474493		[learning rate: 0.0088726]
	Learning Rate: 0.00887263
	LOSS [training: 2.532212719474493 | validation: 3.097339416428997]
	TIME [epoch: 9.07 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.187080202011626		[learning rate: 0.0088404]
	Learning Rate: 0.00884044
	LOSS [training: 3.187080202011626 | validation: 3.7935286100215935]
	TIME [epoch: 9.08 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5945183745270786		[learning rate: 0.0088084]
	Learning Rate: 0.00880835
	LOSS [training: 2.5945183745270786 | validation: 4.698054604249167]
	TIME [epoch: 9.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9842726505094945		[learning rate: 0.0087764]
	Learning Rate: 0.00877639
	LOSS [training: 2.9842726505094945 | validation: 4.060752249498896]
	TIME [epoch: 9.08 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.788697355873947		[learning rate: 0.0087445]
	Learning Rate: 0.00874454
	LOSS [training: 2.788697355873947 | validation: 3.5864545720342433]
	TIME [epoch: 9.08 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1009063741499543		[learning rate: 0.0087128]
	Learning Rate: 0.0087128
	LOSS [training: 3.1009063741499543 | validation: 3.344703402879164]
	TIME [epoch: 9.08 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.601054034153083		[learning rate: 0.0086812]
	Learning Rate: 0.00868118
	LOSS [training: 2.601054034153083 | validation: 3.437757807039906]
	TIME [epoch: 9.09 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5279167902616253		[learning rate: 0.0086497]
	Learning Rate: 0.00864968
	LOSS [training: 2.5279167902616253 | validation: 3.1048539217644486]
	TIME [epoch: 9.08 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5484604511696025		[learning rate: 0.0086183]
	Learning Rate: 0.00861829
	LOSS [training: 2.5484604511696025 | validation: 3.9705386393628572]
	TIME [epoch: 9.08 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.661525615715779		[learning rate: 0.008587]
	Learning Rate: 0.00858701
	LOSS [training: 2.661525615715779 | validation: 3.170281052738119]
	TIME [epoch: 9.07 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9414196169825244		[learning rate: 0.0085559]
	Learning Rate: 0.00855585
	LOSS [training: 2.9414196169825244 | validation: 3.341281541963844]
	TIME [epoch: 9.11 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6442448213731433		[learning rate: 0.0085248]
	Learning Rate: 0.0085248
	LOSS [training: 2.6442448213731433 | validation: 3.0767631551974914]
	TIME [epoch: 9.08 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.788034510509919		[learning rate: 0.0084939]
	Learning Rate: 0.00849386
	LOSS [training: 2.788034510509919 | validation: 3.1052792017407675]
	TIME [epoch: 9.08 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.728253546567509		[learning rate: 0.008463]
	Learning Rate: 0.00846304
	LOSS [training: 2.728253546567509 | validation: 3.7679414618719247]
	TIME [epoch: 9.08 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4747104075779824		[learning rate: 0.0084323]
	Learning Rate: 0.00843233
	LOSS [training: 2.4747104075779824 | validation: 3.204769791404502]
	TIME [epoch: 9.09 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8648725803110335		[learning rate: 0.0084017]
	Learning Rate: 0.00840172
	LOSS [training: 2.8648725803110335 | validation: 3.2563712880193094]
	TIME [epoch: 9.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.497318478655859		[learning rate: 0.0083712]
	Learning Rate: 0.00837123
	LOSS [training: 2.497318478655859 | validation: 3.2733993802303534]
	TIME [epoch: 9.08 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9587176655480176		[learning rate: 0.0083409]
	Learning Rate: 0.00834085
	LOSS [training: 2.9587176655480176 | validation: 4.023191208716208]
	TIME [epoch: 9.09 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5714571805223443		[learning rate: 0.0083106]
	Learning Rate: 0.00831059
	LOSS [training: 2.5714571805223443 | validation: 3.375310164327865]
	TIME [epoch: 9.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4422790228119737		[learning rate: 0.0082804]
	Learning Rate: 0.00828043
	LOSS [training: 2.4422790228119737 | validation: 3.7385378521389097]
	TIME [epoch: 9.09 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.600849527973253		[learning rate: 0.0082504]
	Learning Rate: 0.00825037
	LOSS [training: 2.600849527973253 | validation: 3.388624931232521]
	TIME [epoch: 9.08 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.448579867732581		[learning rate: 0.0082204]
	Learning Rate: 0.00822043
	LOSS [training: 2.448579867732581 | validation: 3.5052160683151543]
	TIME [epoch: 9.07 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7349717000784577		[learning rate: 0.0081906]
	Learning Rate: 0.0081906
	LOSS [training: 2.7349717000784577 | validation: 3.1122666084155823]
	TIME [epoch: 9.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.632744833629258		[learning rate: 0.0081609]
	Learning Rate: 0.00816088
	LOSS [training: 2.632744833629258 | validation: 3.0764498004294936]
	TIME [epoch: 9.09 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8134335692235037		[learning rate: 0.0081313]
	Learning Rate: 0.00813126
	LOSS [training: 2.8134335692235037 | validation: 3.155562428141412]
	TIME [epoch: 9.07 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.460365509253204		[learning rate: 0.0081018]
	Learning Rate: 0.00810175
	LOSS [training: 2.460365509253204 | validation: 3.255973327951999]
	TIME [epoch: 9.08 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.603307398743115		[learning rate: 0.0080724]
	Learning Rate: 0.00807235
	LOSS [training: 2.603307398743115 | validation: 3.059323038169268]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.377075436333418		[learning rate: 0.0080431]
	Learning Rate: 0.00804305
	LOSS [training: 2.377075436333418 | validation: 3.2100289343221196]
	TIME [epoch: 9.11 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.893485938253598		[learning rate: 0.0080139]
	Learning Rate: 0.00801387
	LOSS [training: 2.893485938253598 | validation: 4.177926462913321]
	TIME [epoch: 9.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.77273804671999		[learning rate: 0.0079848]
	Learning Rate: 0.00798478
	LOSS [training: 2.77273804671999 | validation: 3.4112031532222984]
	TIME [epoch: 9.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4010020229860265		[learning rate: 0.0079558]
	Learning Rate: 0.00795581
	LOSS [training: 2.4010020229860265 | validation: 3.1645755300582437]
	TIME [epoch: 9.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3609604672925255		[learning rate: 0.0079269]
	Learning Rate: 0.00792693
	LOSS [training: 2.3609604672925255 | validation: 3.3729945842699722]
	TIME [epoch: 9.12 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.594684659053988		[learning rate: 0.0078982]
	Learning Rate: 0.00789817
	LOSS [training: 2.594684659053988 | validation: 3.522846072307236]
	TIME [epoch: 9.1 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4658644545690156		[learning rate: 0.0078695]
	Learning Rate: 0.0078695
	LOSS [training: 2.4658644545690156 | validation: 3.05016816298275]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.884159877277492		[learning rate: 0.0078409]
	Learning Rate: 0.00784094
	LOSS [training: 2.884159877277492 | validation: 3.057282099817042]
	TIME [epoch: 9.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.575471573279733		[learning rate: 0.0078125]
	Learning Rate: 0.00781249
	LOSS [training: 2.575471573279733 | validation: 3.0806188431156047]
	TIME [epoch: 9.09 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6358870950023747		[learning rate: 0.0077841]
	Learning Rate: 0.00778414
	LOSS [training: 2.6358870950023747 | validation: 3.0456501018335054]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4140428602327235		[learning rate: 0.0077559]
	Learning Rate: 0.00775589
	LOSS [training: 2.4140428602327235 | validation: 3.0808328590297815]
	TIME [epoch: 9.1 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.383927242756486		[learning rate: 0.0077277]
	Learning Rate: 0.00772774
	LOSS [training: 2.383927242756486 | validation: 4.394877910660627]
	TIME [epoch: 9.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.823372942890135		[learning rate: 0.0076997]
	Learning Rate: 0.0076997
	LOSS [training: 2.823372942890135 | validation: 3.1038092351693005]
	TIME [epoch: 9.09 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.496220265482378		[learning rate: 0.0076718]
	Learning Rate: 0.00767176
	LOSS [training: 2.496220265482378 | validation: 4.061794686856207]
	TIME [epoch: 9.09 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5260349693575264		[learning rate: 0.0076439]
	Learning Rate: 0.00764391
	LOSS [training: 2.5260349693575264 | validation: 3.4862756534355004]
	TIME [epoch: 9.11 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3476902899261414		[learning rate: 0.0076162]
	Learning Rate: 0.00761617
	LOSS [training: 2.3476902899261414 | validation: 3.0054690469608554]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.314558114319074		[learning rate: 0.0075885]
	Learning Rate: 0.00758853
	LOSS [training: 2.314558114319074 | validation: 3.3231468170511684]
	TIME [epoch: 9.1 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.623392243583748		[learning rate: 0.007561]
	Learning Rate: 0.00756099
	LOSS [training: 2.623392243583748 | validation: 3.0848622802831307]
	TIME [epoch: 9.09 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5393436023022478		[learning rate: 0.0075336]
	Learning Rate: 0.00753356
	LOSS [training: 2.5393436023022478 | validation: 3.2143175070533223]
	TIME [epoch: 9.08 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5557814045522145		[learning rate: 0.0075062]
	Learning Rate: 0.00750622
	LOSS [training: 2.5557814045522145 | validation: 3.1488489871724243]
	TIME [epoch: 9.11 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6434944970531378		[learning rate: 0.007479]
	Learning Rate: 0.00747897
	LOSS [training: 2.6434944970531378 | validation: 3.082979761055726]
	TIME [epoch: 9.09 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4296629978373803		[learning rate: 0.0074518]
	Learning Rate: 0.00745183
	LOSS [training: 2.4296629978373803 | validation: 3.0928175678923453]
	TIME [epoch: 9.09 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.501789114011358		[learning rate: 0.0074248]
	Learning Rate: 0.00742479
	LOSS [training: 2.501789114011358 | validation: 4.020854059540014]
	TIME [epoch: 9.09 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5639607995162446		[learning rate: 0.0073978]
	Learning Rate: 0.00739784
	LOSS [training: 2.5639607995162446 | validation: 3.7775425195318677]
	TIME [epoch: 9.09 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.360011407644744		[learning rate: 0.007371]
	Learning Rate: 0.007371
	LOSS [training: 2.360011407644744 | validation: 3.067876974531054]
	TIME [epoch: 9.11 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2734033777173335		[learning rate: 0.0073442]
	Learning Rate: 0.00734425
	LOSS [training: 2.2734033777173335 | validation: 3.3743965602760064]
	TIME [epoch: 9.09 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3518872453062487		[learning rate: 0.0073176]
	Learning Rate: 0.0073176
	LOSS [training: 2.3518872453062487 | validation: 3.517899525091699]
	TIME [epoch: 9.09 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6037412025813165		[learning rate: 0.007291]
	Learning Rate: 0.00729104
	LOSS [training: 2.6037412025813165 | validation: 3.4061379994111673]
	TIME [epoch: 9.09 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4208147133502664		[learning rate: 0.0072646]
	Learning Rate: 0.00726458
	LOSS [training: 2.4208147133502664 | validation: 3.631934510551491]
	TIME [epoch: 9.09 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8414952232306345		[learning rate: 0.0072382]
	Learning Rate: 0.00723822
	LOSS [training: 2.8414952232306345 | validation: 3.4464759708659605]
	TIME [epoch: 9.12 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5175113094045036		[learning rate: 0.0072119]
	Learning Rate: 0.00721195
	LOSS [training: 2.5175113094045036 | validation: 3.7519613057253496]
	TIME [epoch: 9.08 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6481193432038963		[learning rate: 0.0071858]
	Learning Rate: 0.00718578
	LOSS [training: 2.6481193432038963 | validation: 3.400827742628616]
	TIME [epoch: 9.08 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3652467984696055		[learning rate: 0.0071597]
	Learning Rate: 0.0071597
	LOSS [training: 2.3652467984696055 | validation: 3.108602906252079]
	TIME [epoch: 9.08 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.431026028773777		[learning rate: 0.0071337]
	Learning Rate: 0.00713371
	LOSS [training: 2.431026028773777 | validation: 3.4495338621248894]
	TIME [epoch: 9.08 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.639346800111288		[learning rate: 0.0071078]
	Learning Rate: 0.00710783
	LOSS [training: 2.639346800111288 | validation: 3.238579128957997]
	TIME [epoch: 9.11 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.394241976803111		[learning rate: 0.007082]
	Learning Rate: 0.00708203
	LOSS [training: 2.394241976803111 | validation: 2.996574674725049]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.345070012842134		[learning rate: 0.0070563]
	Learning Rate: 0.00705633
	LOSS [training: 2.345070012842134 | validation: 2.9331951560766107]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.301535915160704		[learning rate: 0.0070307]
	Learning Rate: 0.00703072
	LOSS [training: 2.301535915160704 | validation: 2.930863392625513]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4592693512220882		[learning rate: 0.0070052]
	Learning Rate: 0.00700521
	LOSS [training: 2.4592693512220882 | validation: 3.64331651146094]
	TIME [epoch: 9.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.563503196041225		[learning rate: 0.0069798]
	Learning Rate: 0.00697979
	LOSS [training: 2.563503196041225 | validation: 3.0597932874378904]
	TIME [epoch: 9.08 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.455958421807616		[learning rate: 0.0069545]
	Learning Rate: 0.00695446
	LOSS [training: 2.455958421807616 | validation: 2.972759019030333]
	TIME [epoch: 9.08 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.214766598751978		[learning rate: 0.0069292]
	Learning Rate: 0.00692922
	LOSS [training: 2.214766598751978 | validation: 3.263025974885144]
	TIME [epoch: 9.08 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4088380762879966		[learning rate: 0.0069041]
	Learning Rate: 0.00690407
	LOSS [training: 2.4088380762879966 | validation: 3.3690225586519853]
	TIME [epoch: 9.08 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.243463606110121		[learning rate: 0.006879]
	Learning Rate: 0.00687902
	LOSS [training: 2.243463606110121 | validation: 3.49920516719693]
	TIME [epoch: 9.09 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.345972737111137		[learning rate: 0.0068541]
	Learning Rate: 0.00685405
	LOSS [training: 2.345972737111137 | validation: 3.7839422518823094]
	TIME [epoch: 9.08 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.511715225980482		[learning rate: 0.0068292]
	Learning Rate: 0.00682918
	LOSS [training: 2.511715225980482 | validation: 3.3235877005103163]
	TIME [epoch: 9.07 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2794855329754693		[learning rate: 0.0068044]
	Learning Rate: 0.00680439
	LOSS [training: 2.2794855329754693 | validation: 2.975418286980636]
	TIME [epoch: 9.07 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4851866529339453		[learning rate: 0.0067797]
	Learning Rate: 0.0067797
	LOSS [training: 2.4851866529339453 | validation: 3.2004426451513033]
	TIME [epoch: 9.08 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.504853835441161		[learning rate: 0.0067551]
	Learning Rate: 0.0067551
	LOSS [training: 2.504853835441161 | validation: 3.5355980405811973]
	TIME [epoch: 9.09 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.33272993452059		[learning rate: 0.0067306]
	Learning Rate: 0.00673058
	LOSS [training: 2.33272993452059 | validation: 3.005146555112855]
	TIME [epoch: 9.08 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3572698631395435		[learning rate: 0.0067062]
	Learning Rate: 0.00670616
	LOSS [training: 2.3572698631395435 | validation: 3.4795991278396734]
	TIME [epoch: 9.08 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3021206000579433		[learning rate: 0.0066818]
	Learning Rate: 0.00668182
	LOSS [training: 2.3021206000579433 | validation: 3.0890921421577264]
	TIME [epoch: 9.08 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.578955538828819		[learning rate: 0.0066576]
	Learning Rate: 0.00665757
	LOSS [training: 2.578955538828819 | validation: 2.943793435716233]
	TIME [epoch: 9.08 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.509051646307578		[learning rate: 0.0066334]
	Learning Rate: 0.00663341
	LOSS [training: 2.509051646307578 | validation: 3.081324240234566]
	TIME [epoch: 9.1 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5780602548930798		[learning rate: 0.0066093]
	Learning Rate: 0.00660934
	LOSS [training: 2.5780602548930798 | validation: 2.9880356056971786]
	TIME [epoch: 9.08 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.357810446780593		[learning rate: 0.0065854]
	Learning Rate: 0.00658535
	LOSS [training: 2.357810446780593 | validation: 2.9272886805970613]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.384685038950384		[learning rate: 0.0065615]
	Learning Rate: 0.00656145
	LOSS [training: 2.384685038950384 | validation: 3.5854681409372686]
	TIME [epoch: 9.07 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4119453324916327		[learning rate: 0.0065376]
	Learning Rate: 0.00653764
	LOSS [training: 2.4119453324916327 | validation: 2.9936941945901294]
	TIME [epoch: 9.1 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.461035518063113		[learning rate: 0.0065139]
	Learning Rate: 0.00651392
	LOSS [training: 2.461035518063113 | validation: 3.06996151582166]
	TIME [epoch: 9.08 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.424967690527541		[learning rate: 0.0064903]
	Learning Rate: 0.00649028
	LOSS [training: 2.424967690527541 | validation: 3.3940159149132385]
	TIME [epoch: 9.08 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3799655328924603		[learning rate: 0.0064667]
	Learning Rate: 0.00646672
	LOSS [training: 2.3799655328924603 | validation: 3.266124095134394]
	TIME [epoch: 9.07 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5323885503574095		[learning rate: 0.0064433]
	Learning Rate: 0.00644325
	LOSS [training: 2.5323885503574095 | validation: 3.836290672162497]
	TIME [epoch: 9.07 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3931768027439646		[learning rate: 0.0064199]
	Learning Rate: 0.00641987
	LOSS [training: 2.3931768027439646 | validation: 3.002924291678455]
	TIME [epoch: 9.09 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.546388399748064		[learning rate: 0.0063966]
	Learning Rate: 0.00639657
	LOSS [training: 2.546388399748064 | validation: 3.362848186126607]
	TIME [epoch: 9.08 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3300121792052395		[learning rate: 0.0063734]
	Learning Rate: 0.00637336
	LOSS [training: 2.3300121792052395 | validation: 2.9661383936803585]
	TIME [epoch: 9.06 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2533226620213607		[learning rate: 0.0063502]
	Learning Rate: 0.00635023
	LOSS [training: 2.2533226620213607 | validation: 3.282214358548088]
	TIME [epoch: 9.07 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2270756872598585		[learning rate: 0.0063272]
	Learning Rate: 0.00632718
	LOSS [training: 2.2270756872598585 | validation: 3.307720631177515]
	TIME [epoch: 9.08 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.230466476002797		[learning rate: 0.0063042]
	Learning Rate: 0.00630422
	LOSS [training: 2.230466476002797 | validation: 3.155677357919184]
	TIME [epoch: 9.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.287410108348223		[learning rate: 0.0062813]
	Learning Rate: 0.00628134
	LOSS [training: 2.287410108348223 | validation: 3.0448843218902484]
	TIME [epoch: 9.08 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.448019934237513		[learning rate: 0.0062585]
	Learning Rate: 0.00625855
	LOSS [training: 2.448019934237513 | validation: 3.5280430520022974]
	TIME [epoch: 9.07 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.359687755033708		[learning rate: 0.0062358]
	Learning Rate: 0.00623584
	LOSS [training: 2.359687755033708 | validation: 3.9659278007035166]
	TIME [epoch: 9.08 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3407451629701326		[learning rate: 0.0062132]
	Learning Rate: 0.00621321
	LOSS [training: 2.3407451629701326 | validation: 2.956797758909869]
	TIME [epoch: 9.09 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.352498995350745		[learning rate: 0.0061907]
	Learning Rate: 0.00619066
	LOSS [training: 2.352498995350745 | validation: 3.1580168902706482]
	TIME [epoch: 9.07 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3909045541000453		[learning rate: 0.0061682]
	Learning Rate: 0.00616819
	LOSS [training: 2.3909045541000453 | validation: 3.0066618962063822]
	TIME [epoch: 9.08 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1912129774747		[learning rate: 0.0061458]
	Learning Rate: 0.00614581
	LOSS [training: 2.1912129774747 | validation: 2.933599666045124]
	TIME [epoch: 9.06 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2504742360346115		[learning rate: 0.0061235]
	Learning Rate: 0.0061235
	LOSS [training: 2.2504742360346115 | validation: 3.1949715240146404]
	TIME [epoch: 9.08 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2708684185234924		[learning rate: 0.0061013]
	Learning Rate: 0.00610128
	LOSS [training: 2.2708684185234924 | validation: 2.884155512295531]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.291400891045064		[learning rate: 0.0060791]
	Learning Rate: 0.00607914
	LOSS [training: 2.291400891045064 | validation: 2.9518109240976633]
	TIME [epoch: 9.08 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1980814394685293		[learning rate: 0.0060571]
	Learning Rate: 0.00605708
	LOSS [training: 2.1980814394685293 | validation: 2.826864763767761]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.222434749125996		[learning rate: 0.0060351]
	Learning Rate: 0.0060351
	LOSS [training: 2.222434749125996 | validation: 3.262416939972547]
	TIME [epoch: 9.08 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3585538298563584		[learning rate: 0.0060132]
	Learning Rate: 0.00601319
	LOSS [training: 2.3585538298563584 | validation: 2.8985151886108134]
	TIME [epoch: 9.09 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.351490376396611		[learning rate: 0.0059914]
	Learning Rate: 0.00599137
	LOSS [training: 2.351490376396611 | validation: 2.9053134507587766]
	TIME [epoch: 9.1 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4955134940638817		[learning rate: 0.0059696]
	Learning Rate: 0.00596963
	LOSS [training: 2.4955134940638817 | validation: 3.121020816343213]
	TIME [epoch: 9.09 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.354072482900008		[learning rate: 0.005948]
	Learning Rate: 0.00594797
	LOSS [training: 2.354072482900008 | validation: 3.045604617098875]
	TIME [epoch: 9.08 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.171704655626654		[learning rate: 0.0059264]
	Learning Rate: 0.00592638
	LOSS [training: 2.171704655626654 | validation: 2.941093677108455]
	TIME [epoch: 9.08 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4002439510539615		[learning rate: 0.0059049]
	Learning Rate: 0.00590487
	LOSS [training: 2.4002439510539615 | validation: 3.4628153905636307]
	TIME [epoch: 9.08 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2926638864852276		[learning rate: 0.0058834]
	Learning Rate: 0.00588344
	LOSS [training: 2.2926638864852276 | validation: 3.1449174963620425]
	TIME [epoch: 9.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2073311508802074		[learning rate: 0.0058621]
	Learning Rate: 0.00586209
	LOSS [training: 2.2073311508802074 | validation: 3.0767503364695004]
	TIME [epoch: 9.08 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.245249524210943		[learning rate: 0.0058408]
	Learning Rate: 0.00584082
	LOSS [training: 2.245249524210943 | validation: 3.342727881396603]
	TIME [epoch: 9.07 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.372298708403906		[learning rate: 0.0058196]
	Learning Rate: 0.00581962
	LOSS [training: 2.372298708403906 | validation: 3.104289881459046]
	TIME [epoch: 9.08 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.312313747558324		[learning rate: 0.0057985]
	Learning Rate: 0.0057985
	LOSS [training: 2.312313747558324 | validation: 3.150063566173471]
	TIME [epoch: 9.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.229386638545466		[learning rate: 0.0057775]
	Learning Rate: 0.00577746
	LOSS [training: 2.229386638545466 | validation: 3.0413491465858717]
	TIME [epoch: 9.08 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2762814970141454		[learning rate: 0.0057565]
	Learning Rate: 0.00575649
	LOSS [training: 2.2762814970141454 | validation: 2.869843191386276]
	TIME [epoch: 9.08 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.20463976183563		[learning rate: 0.0057356]
	Learning Rate: 0.0057356
	LOSS [training: 2.20463976183563 | validation: 2.8949708161527576]
	TIME [epoch: 9.08 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.321809662967436		[learning rate: 0.0057148]
	Learning Rate: 0.00571479
	LOSS [training: 2.321809662967436 | validation: 2.9307414044584235]
	TIME [epoch: 9.07 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.261780402823687		[learning rate: 0.005694]
	Learning Rate: 0.00569405
	LOSS [training: 2.261780402823687 | validation: 2.867289834354331]
	TIME [epoch: 9.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2762583595369565		[learning rate: 0.0056734]
	Learning Rate: 0.00567338
	LOSS [training: 2.2762583595369565 | validation: 2.9122059256446216]
	TIME [epoch: 9.09 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.192949908219371		[learning rate: 0.0056528]
	Learning Rate: 0.00565279
	LOSS [training: 2.192949908219371 | validation: 3.0820640203446334]
	TIME [epoch: 9.06 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.335103495285094		[learning rate: 0.0056323]
	Learning Rate: 0.00563228
	LOSS [training: 2.335103495285094 | validation: 3.0783413728570013]
	TIME [epoch: 9.08 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3518810207474408		[learning rate: 0.0056118]
	Learning Rate: 0.00561184
	LOSS [training: 2.3518810207474408 | validation: 2.8770568278992057]
	TIME [epoch: 9.08 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3991235125384263		[learning rate: 0.0055915]
	Learning Rate: 0.00559147
	LOSS [training: 2.3991235125384263 | validation: 2.9069349290997417]
	TIME [epoch: 9.09 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2891300255417417		[learning rate: 0.0055712]
	Learning Rate: 0.00557118
	LOSS [training: 2.2891300255417417 | validation: 2.9383303901268345]
	TIME [epoch: 9.09 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2389894551157483		[learning rate: 0.005551]
	Learning Rate: 0.00555096
	LOSS [training: 2.2389894551157483 | validation: 2.97672548738891]
	TIME [epoch: 9.08 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3145543563380238		[learning rate: 0.0055308]
	Learning Rate: 0.00553082
	LOSS [training: 2.3145543563380238 | validation: 2.88911135849463]
	TIME [epoch: 9.08 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.358721352159643		[learning rate: 0.0055107]
	Learning Rate: 0.00551075
	LOSS [training: 2.358721352159643 | validation: 3.177660058840699]
	TIME [epoch: 9.1 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2890310820005815		[learning rate: 0.0054907]
	Learning Rate: 0.00549075
	LOSS [training: 2.2890310820005815 | validation: 2.9516109009235874]
	TIME [epoch: 9.09 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.314885908963761		[learning rate: 0.0054708]
	Learning Rate: 0.00547082
	LOSS [training: 2.314885908963761 | validation: 3.1261870831062284]
	TIME [epoch: 9.09 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2058414083291664		[learning rate: 0.005451]
	Learning Rate: 0.00545097
	LOSS [training: 2.2058414083291664 | validation: 3.0385340308054274]
	TIME [epoch: 9.08 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1648258661279836		[learning rate: 0.0054312]
	Learning Rate: 0.00543119
	LOSS [training: 2.1648258661279836 | validation: 2.9509785755779765]
	TIME [epoch: 9.08 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.169681919515073		[learning rate: 0.0054115]
	Learning Rate: 0.00541148
	LOSS [training: 2.169681919515073 | validation: 3.1117732527956763]
	TIME [epoch: 9.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3208630095908456		[learning rate: 0.0053918]
	Learning Rate: 0.00539184
	LOSS [training: 2.3208630095908456 | validation: 2.9015825296217734]
	TIME [epoch: 9.08 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.291296302452217		[learning rate: 0.0053723]
	Learning Rate: 0.00537227
	LOSS [training: 2.291296302452217 | validation: 2.9752485505764796]
	TIME [epoch: 9.07 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.226535187101667		[learning rate: 0.0053528]
	Learning Rate: 0.00535277
	LOSS [training: 2.226535187101667 | validation: 3.117770972660149]
	TIME [epoch: 9.07 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.157811632046003		[learning rate: 0.0053333]
	Learning Rate: 0.00533335
	LOSS [training: 2.157811632046003 | validation: 4.2438443292266435]
	TIME [epoch: 9.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.380241143414286		[learning rate: 0.005314]
	Learning Rate: 0.00531399
	LOSS [training: 2.380241143414286 | validation: 3.1689812207711276]
	TIME [epoch: 9.08 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2964012425229905		[learning rate: 0.0052947]
	Learning Rate: 0.00529471
	LOSS [training: 2.2964012425229905 | validation: 2.859268983686447]
	TIME [epoch: 9.08 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3007765962809934		[learning rate: 0.0052755]
	Learning Rate: 0.00527549
	LOSS [training: 2.3007765962809934 | validation: 2.9541198312489567]
	TIME [epoch: 9.09 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0815780384034888		[learning rate: 0.0052563]
	Learning Rate: 0.00525635
	LOSS [training: 2.0815780384034888 | validation: 3.271615013993719]
	TIME [epoch: 9.08 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2078341147544096		[learning rate: 0.0052373]
	Learning Rate: 0.00523727
	LOSS [training: 2.2078341147544096 | validation: 3.0837982007089595]
	TIME [epoch: 9.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1317923834171086		[learning rate: 0.0052183]
	Learning Rate: 0.00521827
	LOSS [training: 2.1317923834171086 | validation: 3.192198669323591]
	TIME [epoch: 9.09 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.130488914030711		[learning rate: 0.0051993]
	Learning Rate: 0.00519933
	LOSS [training: 2.130488914030711 | validation: 3.4123023258764222]
	TIME [epoch: 9.09 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.321792770560814		[learning rate: 0.0051805]
	Learning Rate: 0.00518046
	LOSS [training: 2.321792770560814 | validation: 2.8551968310587945]
	TIME [epoch: 9.09 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0914493734746293		[learning rate: 0.0051617]
	Learning Rate: 0.00516166
	LOSS [training: 2.0914493734746293 | validation: 3.0569601566480262]
	TIME [epoch: 9.09 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.138090635286897		[learning rate: 0.0051429]
	Learning Rate: 0.00514293
	LOSS [training: 2.138090635286897 | validation: 3.053466098281352]
	TIME [epoch: 9.08 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.253898888024102		[learning rate: 0.0051243]
	Learning Rate: 0.00512426
	LOSS [training: 2.253898888024102 | validation: 2.9527194810767234]
	TIME [epoch: 9.08 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1540911320220695		[learning rate: 0.0051057]
	Learning Rate: 0.00510567
	LOSS [training: 2.1540911320220695 | validation: 3.100057620070812]
	TIME [epoch: 9.08 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.17107841042358		[learning rate: 0.0050871]
	Learning Rate: 0.00508714
	LOSS [training: 2.17107841042358 | validation: 2.891628353854813]
	TIME [epoch: 9.08 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.20355880217321		[learning rate: 0.0050687]
	Learning Rate: 0.00506868
	LOSS [training: 2.20355880217321 | validation: 3.605444468778953]
	TIME [epoch: 9.09 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3772976512954984		[learning rate: 0.0050503]
	Learning Rate: 0.00505028
	LOSS [training: 2.3772976512954984 | validation: 2.8369593963196693]
	TIME [epoch: 9.08 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.276581326925748		[learning rate: 0.005032]
	Learning Rate: 0.00503196
	LOSS [training: 2.276581326925748 | validation: 2.8848254960164716]
	TIME [epoch: 9.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.314939719289693		[learning rate: 0.0050137]
	Learning Rate: 0.00501369
	LOSS [training: 2.314939719289693 | validation: 2.9886099927003107]
	TIME [epoch: 9.07 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1613109715221492		[learning rate: 0.0049955]
	Learning Rate: 0.0049955
	LOSS [training: 2.1613109715221492 | validation: 2.973434670861714]
	TIME [epoch: 9.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.105043676439759		[learning rate: 0.0049774]
	Learning Rate: 0.00497737
	LOSS [training: 2.105043676439759 | validation: 2.8671018779193753]
	TIME [epoch: 9.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1031875707989363		[learning rate: 0.0049593]
	Learning Rate: 0.00495931
	LOSS [training: 2.1031875707989363 | validation: 3.2828601132941313]
	TIME [epoch: 9.09 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1915545521594018		[learning rate: 0.0049413]
	Learning Rate: 0.00494131
	LOSS [training: 2.1915545521594018 | validation: 2.9707042907566867]
	TIME [epoch: 9.08 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1272498834121154		[learning rate: 0.0049234]
	Learning Rate: 0.00492338
	LOSS [training: 2.1272498834121154 | validation: 3.728578282808967]
	TIME [epoch: 9.08 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.309095716020293		[learning rate: 0.0049055]
	Learning Rate: 0.00490551
	LOSS [training: 2.309095716020293 | validation: 3.040743586257005]
	TIME [epoch: 9.11 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.08543983581128		[learning rate: 0.0048877]
	Learning Rate: 0.00488771
	LOSS [training: 2.08543983581128 | validation: 2.9010415808497654]
	TIME [epoch: 9.08 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.213638278966827		[learning rate: 0.00487]
	Learning Rate: 0.00486997
	LOSS [training: 2.213638278966827 | validation: 2.9194169978370796]
	TIME [epoch: 9.08 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.104042121640351		[learning rate: 0.0048523]
	Learning Rate: 0.0048523
	LOSS [training: 2.104042121640351 | validation: 2.863514207353986]
	TIME [epoch: 9.09 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.030301602515222		[learning rate: 0.0048347]
	Learning Rate: 0.00483469
	LOSS [training: 2.030301602515222 | validation: 2.561654676711033]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.896436825512654		[learning rate: 0.0048171]
	Learning Rate: 0.00481714
	LOSS [training: 1.896436825512654 | validation: 2.889062535922899]
	TIME [epoch: 9.11 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8584207605691723		[learning rate: 0.0047997]
	Learning Rate: 0.00479966
	LOSS [training: 1.8584207605691723 | validation: 2.9949534477134288]
	TIME [epoch: 9.08 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8858146333805574		[learning rate: 0.0047822]
	Learning Rate: 0.00478224
	LOSS [training: 1.8858146333805574 | validation: 2.5654261298774115]
	TIME [epoch: 9.08 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8089772456202131		[learning rate: 0.0047649]
	Learning Rate: 0.00476489
	LOSS [training: 1.8089772456202131 | validation: 2.3957158369122267]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7675010011386618		[learning rate: 0.0047476]
	Learning Rate: 0.00474759
	LOSS [training: 1.7675010011386618 | validation: 2.39644843317958]
	TIME [epoch: 9.07 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.753919063555399		[learning rate: 0.0047304]
	Learning Rate: 0.00473037
	LOSS [training: 1.753919063555399 | validation: 2.3513307440691]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8466737498470824		[learning rate: 0.0047132]
	Learning Rate: 0.0047132
	LOSS [training: 1.8466737498470824 | validation: 2.545034382072532]
	TIME [epoch: 9.07 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8929200499122054		[learning rate: 0.0046961]
	Learning Rate: 0.00469609
	LOSS [training: 1.8929200499122054 | validation: 2.5231719729316513]
	TIME [epoch: 9.06 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7900521301366055		[learning rate: 0.0046791]
	Learning Rate: 0.00467905
	LOSS [training: 1.7900521301366055 | validation: 2.371095988289024]
	TIME [epoch: 9.05 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7667538451458948		[learning rate: 0.0046621]
	Learning Rate: 0.00466207
	LOSS [training: 1.7667538451458948 | validation: 2.3344933799652647]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.714864347115082		[learning rate: 0.0046452]
	Learning Rate: 0.00464515
	LOSS [training: 1.714864347115082 | validation: 2.7317473891758515]
	TIME [epoch: 9.07 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9213465720587357		[learning rate: 0.0046283]
	Learning Rate: 0.0046283
	LOSS [training: 1.9213465720587357 | validation: 2.5410721656328334]
	TIME [epoch: 9.06 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7646468444208214		[learning rate: 0.0046115]
	Learning Rate: 0.0046115
	LOSS [training: 1.7646468444208214 | validation: 2.4665616381747553]
	TIME [epoch: 9.06 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7280804300807564		[learning rate: 0.0045948]
	Learning Rate: 0.00459476
	LOSS [training: 1.7280804300807564 | validation: 2.650159629486927]
	TIME [epoch: 9.06 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8164658409498204		[learning rate: 0.0045781]
	Learning Rate: 0.00457809
	LOSS [training: 1.8164658409498204 | validation: 2.36040307919622]
	TIME [epoch: 9.08 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6651869772246897		[learning rate: 0.0045615]
	Learning Rate: 0.00456148
	LOSS [training: 1.6651869772246897 | validation: 2.468236886011617]
	TIME [epoch: 9.07 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7026443731021448		[learning rate: 0.0045449]
	Learning Rate: 0.00454492
	LOSS [training: 1.7026443731021448 | validation: 2.426345747231454]
	TIME [epoch: 9.06 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6513625466635244		[learning rate: 0.0045284]
	Learning Rate: 0.00452843
	LOSS [training: 1.6513625466635244 | validation: 2.38048849193109]
	TIME [epoch: 9.07 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6364145195140558		[learning rate: 0.004512]
	Learning Rate: 0.00451199
	LOSS [training: 1.6364145195140558 | validation: 1.9937246289884212]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6470029184455846		[learning rate: 0.0044956]
	Learning Rate: 0.00449562
	LOSS [training: 1.6470029184455846 | validation: 2.1218359766962034]
	TIME [epoch: 9.08 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7031471790734654		[learning rate: 0.0044793]
	Learning Rate: 0.0044793
	LOSS [training: 1.7031471790734654 | validation: 1.8954218953659356]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5017690093550908		[learning rate: 0.004463]
	Learning Rate: 0.00446305
	LOSS [training: 1.5017690093550908 | validation: 1.7127215604569535]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_322.pth
	Model improved!!!
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3716012503401682		[learning rate: 0.0044469]
	Learning Rate: 0.00444685
	LOSS [training: 1.3716012503401682 | validation: 1.69126879794746]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2643624527945545		[learning rate: 0.0044307]
	Learning Rate: 0.00443071
	LOSS [training: 1.2643624527945545 | validation: 1.554052365915156]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1766430719800458		[learning rate: 0.0044146]
	Learning Rate: 0.00441463
	LOSS [training: 1.1766430719800458 | validation: 1.463073014981478]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2235724915320387		[learning rate: 0.0043986]
	Learning Rate: 0.00439861
	LOSS [training: 1.2235724915320387 | validation: 1.7100791668280648]
	TIME [epoch: 9.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3356847680042447		[learning rate: 0.0043827]
	Learning Rate: 0.00438265
	LOSS [training: 1.3356847680042447 | validation: 1.8540357448268419]
	TIME [epoch: 9.09 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1845041745887155		[learning rate: 0.0043667]
	Learning Rate: 0.00436675
	LOSS [training: 1.1845041745887155 | validation: 1.5682042023329847]
	TIME [epoch: 9.09 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1003601981771463		[learning rate: 0.0043509]
	Learning Rate: 0.0043509
	LOSS [training: 1.1003601981771463 | validation: 1.287059818572591]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1567814312384819		[learning rate: 0.0043351]
	Learning Rate: 0.00433511
	LOSS [training: 1.1567814312384819 | validation: 1.2766546351322257]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.056620975833804		[learning rate: 0.0043194]
	Learning Rate: 0.00431938
	LOSS [training: 1.056620975833804 | validation: 1.1637335421034396]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0390651070631898		[learning rate: 0.0043037]
	Learning Rate: 0.0043037
	LOSS [training: 1.0390651070631898 | validation: 1.3636592525406197]
	TIME [epoch: 9.07 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0019153653834478		[learning rate: 0.0042881]
	Learning Rate: 0.00428808
	LOSS [training: 1.0019153653834478 | validation: 1.2428011761834015]
	TIME [epoch: 9.07 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1969681240969334		[learning rate: 0.0042725]
	Learning Rate: 0.00427252
	LOSS [training: 1.1969681240969334 | validation: 2.1246442801084733]
	TIME [epoch: 9.06 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.112402867196613		[learning rate: 0.004257]
	Learning Rate: 0.00425702
	LOSS [training: 1.112402867196613 | validation: 1.1644067344795723]
	TIME [epoch: 9.09 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0149472965567974		[learning rate: 0.0042416]
	Learning Rate: 0.00424157
	LOSS [training: 1.0149472965567974 | validation: 0.8913385378179977]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9217952806235248		[learning rate: 0.0042262]
	Learning Rate: 0.00422617
	LOSS [training: 0.9217952806235248 | validation: 1.1382465373860668]
	TIME [epoch: 9.07 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0955168590831164		[learning rate: 0.0042108]
	Learning Rate: 0.00421084
	LOSS [training: 1.0955168590831164 | validation: 1.5351145054532318]
	TIME [epoch: 9.08 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.999942942228361		[learning rate: 0.0041956]
	Learning Rate: 0.00419556
	LOSS [training: 0.999942942228361 | validation: 0.869995656870217]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8403877956684698		[learning rate: 0.0041803]
	Learning Rate: 0.00418033
	LOSS [training: 0.8403877956684698 | validation: 1.221422854970542]
	TIME [epoch: 9.09 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9699873401897534		[learning rate: 0.0041652]
	Learning Rate: 0.00416516
	LOSS [training: 0.9699873401897534 | validation: 1.0185473431262937]
	TIME [epoch: 9.08 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8861336511127753		[learning rate: 0.00415]
	Learning Rate: 0.00415004
	LOSS [training: 0.8861336511127753 | validation: 0.8590075620034836]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8936897679587069		[learning rate: 0.004135]
	Learning Rate: 0.00413498
	LOSS [training: 0.8936897679587069 | validation: 0.7681299619647975]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.046240518670134		[learning rate: 0.00412]
	Learning Rate: 0.00411998
	LOSS [training: 1.046240518670134 | validation: 0.964602978598923]
	TIME [epoch: 9.08 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8757948197417702		[learning rate: 0.004105]
	Learning Rate: 0.00410502
	LOSS [training: 0.8757948197417702 | validation: 0.9991455239354573]
	TIME [epoch: 9.09 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8478836979692671		[learning rate: 0.0040901]
	Learning Rate: 0.00409013
	LOSS [training: 0.8478836979692671 | validation: 0.7917928556629539]
	TIME [epoch: 9.08 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8209597084202336		[learning rate: 0.0040753]
	Learning Rate: 0.00407528
	LOSS [training: 0.8209597084202336 | validation: 0.7935543819758326]
	TIME [epoch: 9.07 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9149547297754594		[learning rate: 0.0040605]
	Learning Rate: 0.00406049
	LOSS [training: 0.9149547297754594 | validation: 0.9724031387572043]
	TIME [epoch: 9.06 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8931544948153792		[learning rate: 0.0040458]
	Learning Rate: 0.00404576
	LOSS [training: 0.8931544948153792 | validation: 0.8181652681013576]
	TIME [epoch: 9.06 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8754599787465176		[learning rate: 0.0040311]
	Learning Rate: 0.00403108
	LOSS [training: 0.8754599787465176 | validation: 0.9454323928728391]
	TIME [epoch: 9.08 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.801677512035071		[learning rate: 0.0040164]
	Learning Rate: 0.00401645
	LOSS [training: 0.801677512035071 | validation: 0.820154058922998]
	TIME [epoch: 9.08 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8594364386912154		[learning rate: 0.0040019]
	Learning Rate: 0.00400187
	LOSS [training: 0.8594364386912154 | validation: 0.8217728546944152]
	TIME [epoch: 9.07 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.791275584554087		[learning rate: 0.0039873]
	Learning Rate: 0.00398735
	LOSS [training: 0.791275584554087 | validation: 1.538393021396854]
	TIME [epoch: 9.07 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8908242622169856		[learning rate: 0.0039729]
	Learning Rate: 0.00397288
	LOSS [training: 0.8908242622169856 | validation: 1.1971401243577007]
	TIME [epoch: 9.09 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8670833914982898		[learning rate: 0.0039585]
	Learning Rate: 0.00395846
	LOSS [training: 0.8670833914982898 | validation: 0.7908745115226956]
	TIME [epoch: 9.07 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8344337275025522		[learning rate: 0.0039441]
	Learning Rate: 0.00394409
	LOSS [training: 0.8344337275025522 | validation: 0.8168613241390684]
	TIME [epoch: 9.07 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7930427084667561		[learning rate: 0.0039298]
	Learning Rate: 0.00392978
	LOSS [training: 0.7930427084667561 | validation: 1.1863716138117706]
	TIME [epoch: 9.07 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9284153122140518		[learning rate: 0.0039155]
	Learning Rate: 0.00391552
	LOSS [training: 0.9284153122140518 | validation: 0.7948789955581794]
	TIME [epoch: 9.07 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.008871730914849		[learning rate: 0.0039013]
	Learning Rate: 0.00390131
	LOSS [training: 1.008871730914849 | validation: 0.9807802222382778]
	TIME [epoch: 9.09 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8407779565490809		[learning rate: 0.0038872]
	Learning Rate: 0.00388715
	LOSS [training: 0.8407779565490809 | validation: 0.8755581898342278]
	TIME [epoch: 9.07 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7901054925953994		[learning rate: 0.003873]
	Learning Rate: 0.00387305
	LOSS [training: 0.7901054925953994 | validation: 0.9280190595862862]
	TIME [epoch: 9.08 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8040440975228483		[learning rate: 0.003859]
	Learning Rate: 0.00385899
	LOSS [training: 0.8040440975228483 | validation: 0.6875420689397145]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7661914095429763		[learning rate: 0.003845]
	Learning Rate: 0.00384499
	LOSS [training: 0.7661914095429763 | validation: 0.8221552703663423]
	TIME [epoch: 9.08 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7356452348594796		[learning rate: 0.003831]
	Learning Rate: 0.00383103
	LOSS [training: 0.7356452348594796 | validation: 0.860748471166173]
	TIME [epoch: 9.1 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9441236292105446		[learning rate: 0.0038171]
	Learning Rate: 0.00381713
	LOSS [training: 0.9441236292105446 | validation: 0.9531970035405364]
	TIME [epoch: 9.07 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.844294540392518		[learning rate: 0.0038033]
	Learning Rate: 0.00380328
	LOSS [training: 0.844294540392518 | validation: 0.9123966349415304]
	TIME [epoch: 9.08 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7902273008579134		[learning rate: 0.0037895]
	Learning Rate: 0.00378947
	LOSS [training: 0.7902273008579134 | validation: 0.7987609730668799]
	TIME [epoch: 9.07 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8984322507375083		[learning rate: 0.0037757]
	Learning Rate: 0.00377572
	LOSS [training: 0.8984322507375083 | validation: 0.9775335610990734]
	TIME [epoch: 9.08 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8209237233664503		[learning rate: 0.003762]
	Learning Rate: 0.00376202
	LOSS [training: 0.8209237233664503 | validation: 0.9547424767080024]
	TIME [epoch: 9.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7567409485634216		[learning rate: 0.0037484]
	Learning Rate: 0.00374837
	LOSS [training: 0.7567409485634216 | validation: 0.839924836871815]
	TIME [epoch: 9.08 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7486346578398985		[learning rate: 0.0037348]
	Learning Rate: 0.00373476
	LOSS [training: 0.7486346578398985 | validation: 0.9146150543027094]
	TIME [epoch: 9.08 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8121962448304801		[learning rate: 0.0037212]
	Learning Rate: 0.00372121
	LOSS [training: 0.8121962448304801 | validation: 0.6817982921196453]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8217469153567365		[learning rate: 0.0037077]
	Learning Rate: 0.00370771
	LOSS [training: 0.8217469153567365 | validation: 0.6991606131220587]
	TIME [epoch: 9.11 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7288558711340619		[learning rate: 0.0036943]
	Learning Rate: 0.00369425
	LOSS [training: 0.7288558711340619 | validation: 0.8875279354999439]
	TIME [epoch: 9.09 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7637786326203352		[learning rate: 0.0036808]
	Learning Rate: 0.00368084
	LOSS [training: 0.7637786326203352 | validation: 0.7646678302583952]
	TIME [epoch: 9.08 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7436755316783012		[learning rate: 0.0036675]
	Learning Rate: 0.00366749
	LOSS [training: 0.7436755316783012 | validation: 0.69098697796946]
	TIME [epoch: 9.08 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6599493857710319		[learning rate: 0.0036542]
	Learning Rate: 0.00365418
	LOSS [training: 0.6599493857710319 | validation: 1.0362921818013864]
	TIME [epoch: 9.09 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7360723379315294		[learning rate: 0.0036409]
	Learning Rate: 0.00364092
	LOSS [training: 0.7360723379315294 | validation: 0.9932705578137735]
	TIME [epoch: 9.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8188849206186436		[learning rate: 0.0036277]
	Learning Rate: 0.0036277
	LOSS [training: 0.8188849206186436 | validation: 0.8983266799707803]
	TIME [epoch: 9.09 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.759759914146468		[learning rate: 0.0036145]
	Learning Rate: 0.00361454
	LOSS [training: 0.759759914146468 | validation: 0.6428974860222357]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8975450562014238		[learning rate: 0.0036014]
	Learning Rate: 0.00360142
	LOSS [training: 0.8975450562014238 | validation: 0.9158119451759318]
	TIME [epoch: 9.09 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6857684554473719		[learning rate: 0.0035883]
	Learning Rate: 0.00358835
	LOSS [training: 0.6857684554473719 | validation: 0.782376457858691]
	TIME [epoch: 9.08 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7430992584983366		[learning rate: 0.0035753]
	Learning Rate: 0.00357533
	LOSS [training: 0.7430992584983366 | validation: 1.2956894358605777]
	TIME [epoch: 9.1 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7092646064686162		[learning rate: 0.0035624]
	Learning Rate: 0.00356235
	LOSS [training: 0.7092646064686162 | validation: 0.6896781971057153]
	TIME [epoch: 9.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7664632824280639		[learning rate: 0.0035494]
	Learning Rate: 0.00354942
	LOSS [training: 0.7664632824280639 | validation: 0.7979213241933646]
	TIME [epoch: 9.08 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7849428309438864		[learning rate: 0.0035365]
	Learning Rate: 0.00353654
	LOSS [training: 0.7849428309438864 | validation: 1.3050032644377945]
	TIME [epoch: 9.09 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6810448254029678		[learning rate: 0.0035237]
	Learning Rate: 0.00352371
	LOSS [training: 0.6810448254029678 | validation: 0.9610724435115119]
	TIME [epoch: 9.08 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8074089013567185		[learning rate: 0.0035109]
	Learning Rate: 0.00351092
	LOSS [training: 0.8074089013567185 | validation: 0.8256113270988822]
	TIME [epoch: 9.09 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8203832195344397		[learning rate: 0.0034982]
	Learning Rate: 0.00349818
	LOSS [training: 0.8203832195344397 | validation: 0.8481645318707947]
	TIME [epoch: 9.08 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6805457817546945		[learning rate: 0.0034855]
	Learning Rate: 0.00348548
	LOSS [training: 0.6805457817546945 | validation: 0.6221392165920748]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6944127826274901		[learning rate: 0.0034728]
	Learning Rate: 0.00347284
	LOSS [training: 0.6944127826274901 | validation: 0.6380641089954214]
	TIME [epoch: 9.09 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6803279929539169		[learning rate: 0.0034602]
	Learning Rate: 0.00346023
	LOSS [training: 0.6803279929539169 | validation: 0.9600110970436022]
	TIME [epoch: 9.1 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.727477959392744		[learning rate: 0.0034477]
	Learning Rate: 0.00344767
	LOSS [training: 0.727477959392744 | validation: 0.8385574050335793]
	TIME [epoch: 9.09 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6993015794982191		[learning rate: 0.0034352]
	Learning Rate: 0.00343516
	LOSS [training: 0.6993015794982191 | validation: 0.6849878136597518]
	TIME [epoch: 9.08 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8638031673696567		[learning rate: 0.0034227]
	Learning Rate: 0.0034227
	LOSS [training: 0.8638031673696567 | validation: 0.8753310502212004]
	TIME [epoch: 9.08 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7001917485103936		[learning rate: 0.0034103]
	Learning Rate: 0.00341028
	LOSS [training: 0.7001917485103936 | validation: 0.6500442734757648]
	TIME [epoch: 9.08 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7359528129246091		[learning rate: 0.0033979]
	Learning Rate: 0.0033979
	LOSS [training: 0.7359528129246091 | validation: 0.8045010899771121]
	TIME [epoch: 9.11 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6848338536125925		[learning rate: 0.0033856]
	Learning Rate: 0.00338557
	LOSS [training: 0.6848338536125925 | validation: 1.5179544518140105]
	TIME [epoch: 9.09 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.755060502307641		[learning rate: 0.0033733]
	Learning Rate: 0.00337328
	LOSS [training: 0.755060502307641 | validation: 0.7975607242687673]
	TIME [epoch: 9.09 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8394793132349072		[learning rate: 0.003361]
	Learning Rate: 0.00336104
	LOSS [training: 0.8394793132349072 | validation: 1.0112056351536476]
	TIME [epoch: 9.08 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8432393596484291		[learning rate: 0.0033488]
	Learning Rate: 0.00334884
	LOSS [training: 0.8432393596484291 | validation: 0.994681551614323]
	TIME [epoch: 9.08 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.640167817218441		[learning rate: 0.0033367]
	Learning Rate: 0.00333669
	LOSS [training: 0.640167817218441 | validation: 0.7816565848850252]
	TIME [epoch: 9.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7091299381857298		[learning rate: 0.0033246]
	Learning Rate: 0.00332458
	LOSS [training: 0.7091299381857298 | validation: 1.042403772677063]
	TIME [epoch: 9.08 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6420918535913697		[learning rate: 0.0033125]
	Learning Rate: 0.00331252
	LOSS [training: 0.6420918535913697 | validation: 0.6109170806521418]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_404.pth
	Model improved!!!
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6177240599694948		[learning rate: 0.0033005]
	Learning Rate: 0.00330049
	LOSS [training: 0.6177240599694948 | validation: 0.5830827096680783]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6009083732355176		[learning rate: 0.0032885]
	Learning Rate: 0.00328852
	LOSS [training: 0.6009083732355176 | validation: 0.6561051217900904]
	TIME [epoch: 9.09 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6518787711598567		[learning rate: 0.0032766]
	Learning Rate: 0.00327658
	LOSS [training: 0.6518787711598567 | validation: 0.7147677760166669]
	TIME [epoch: 9.08 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6673844612835186		[learning rate: 0.0032647]
	Learning Rate: 0.00326469
	LOSS [training: 0.6673844612835186 | validation: 0.6137523017956313]
	TIME [epoch: 9.05 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7529349137529322		[learning rate: 0.0032528]
	Learning Rate: 0.00325284
	LOSS [training: 0.7529349137529322 | validation: 0.654892559192318]
	TIME [epoch: 9.07 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.63771737412112		[learning rate: 0.003241]
	Learning Rate: 0.00324104
	LOSS [training: 0.63771737412112 | validation: 0.90779617737043]
	TIME [epoch: 9.08 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8130467849718059		[learning rate: 0.0032293]
	Learning Rate: 0.00322928
	LOSS [training: 0.8130467849718059 | validation: 0.6905868568394768]
	TIME [epoch: 9.09 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7022954702607926		[learning rate: 0.0032176]
	Learning Rate: 0.00321756
	LOSS [training: 0.7022954702607926 | validation: 0.6772372410211562]
	TIME [epoch: 9.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7010631227325433		[learning rate: 0.0032059]
	Learning Rate: 0.00320588
	LOSS [training: 0.7010631227325433 | validation: 0.7684937444842129]
	TIME [epoch: 9.08 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6402596079662026		[learning rate: 0.0031942]
	Learning Rate: 0.00319425
	LOSS [training: 0.6402596079662026 | validation: 0.6146471615276409]
	TIME [epoch: 9.08 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6606053193576231		[learning rate: 0.0031827]
	Learning Rate: 0.00318265
	LOSS [training: 0.6606053193576231 | validation: 0.5511119936695746]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5674374464927382		[learning rate: 0.0031711]
	Learning Rate: 0.0031711
	LOSS [training: 0.5674374464927382 | validation: 0.7399798540965623]
	TIME [epoch: 9.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6951565770405372		[learning rate: 0.0031596]
	Learning Rate: 0.0031596
	LOSS [training: 0.6951565770405372 | validation: 1.060037596838298]
	TIME [epoch: 9.08 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6440275490655916		[learning rate: 0.0031481]
	Learning Rate: 0.00314813
	LOSS [training: 0.6440275490655916 | validation: 0.8150552748815028]
	TIME [epoch: 9.08 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6404712029249545		[learning rate: 0.0031367]
	Learning Rate: 0.00313671
	LOSS [training: 0.6404712029249545 | validation: 0.7536208424199902]
	TIME [epoch: 9.08 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6411349168852604		[learning rate: 0.0031253]
	Learning Rate: 0.00312532
	LOSS [training: 0.6411349168852604 | validation: 1.0018082071752143]
	TIME [epoch: 9.08 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6429804949291025		[learning rate: 0.003114]
	Learning Rate: 0.00311398
	LOSS [training: 0.6429804949291025 | validation: 0.594701109103587]
	TIME [epoch: 9.09 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6338733158805987		[learning rate: 0.0031027]
	Learning Rate: 0.00310268
	LOSS [training: 0.6338733158805987 | validation: 0.8120292418987277]
	TIME [epoch: 9.07 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6582928200756308		[learning rate: 0.0030914]
	Learning Rate: 0.00309142
	LOSS [training: 0.6582928200756308 | validation: 0.6696365884801012]
	TIME [epoch: 9.08 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.619473236261505		[learning rate: 0.0030802]
	Learning Rate: 0.0030802
	LOSS [training: 0.619473236261505 | validation: 0.7351790679893393]
	TIME [epoch: 9.07 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6241491819050202		[learning rate: 0.003069]
	Learning Rate: 0.00306902
	LOSS [training: 0.6241491819050202 | validation: 0.7008533383792265]
	TIME [epoch: 9.09 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5669209699254731		[learning rate: 0.0030579]
	Learning Rate: 0.00305788
	LOSS [training: 0.5669209699254731 | validation: 0.6733432248969864]
	TIME [epoch: 9.08 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8008797755864364		[learning rate: 0.0030468]
	Learning Rate: 0.00304679
	LOSS [training: 0.8008797755864364 | validation: 0.8965560695389381]
	TIME [epoch: 9.07 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6433216418723403		[learning rate: 0.0030357]
	Learning Rate: 0.00303573
	LOSS [training: 0.6433216418723403 | validation: 0.7026934726402366]
	TIME [epoch: 9.08 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5645638069080938		[learning rate: 0.0030247]
	Learning Rate: 0.00302471
	LOSS [training: 0.5645638069080938 | validation: 0.7990039237439777]
	TIME [epoch: 9.07 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6856944394619131		[learning rate: 0.0030137]
	Learning Rate: 0.00301374
	LOSS [training: 0.6856944394619131 | validation: 0.9570444066748729]
	TIME [epoch: 9.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6714722363908077		[learning rate: 0.0030028]
	Learning Rate: 0.0030028
	LOSS [training: 0.6714722363908077 | validation: 0.6910276627330383]
	TIME [epoch: 9.07 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6330573676350348		[learning rate: 0.0029919]
	Learning Rate: 0.0029919
	LOSS [training: 0.6330573676350348 | validation: 0.6252317363929151]
	TIME [epoch: 9.07 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6608443997228627		[learning rate: 0.002981]
	Learning Rate: 0.00298104
	LOSS [training: 0.6608443997228627 | validation: 0.58247902340875]
	TIME [epoch: 9.08 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6418797590712714		[learning rate: 0.0029702]
	Learning Rate: 0.00297023
	LOSS [training: 0.6418797590712714 | validation: 0.7599079788648551]
	TIME [epoch: 9.07 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.626030594053053		[learning rate: 0.0029594]
	Learning Rate: 0.00295945
	LOSS [training: 0.626030594053053 | validation: 0.8127386413156157]
	TIME [epoch: 9.09 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5861454411887073		[learning rate: 0.0029487]
	Learning Rate: 0.00294871
	LOSS [training: 0.5861454411887073 | validation: 0.8539376504415142]
	TIME [epoch: 9.08 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6308049139972656		[learning rate: 0.002938]
	Learning Rate: 0.00293801
	LOSS [training: 0.6308049139972656 | validation: 0.6281221292311174]
	TIME [epoch: 9.08 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7300012773386994		[learning rate: 0.0029273]
	Learning Rate: 0.00292734
	LOSS [training: 0.7300012773386994 | validation: 0.6602396666029238]
	TIME [epoch: 9.07 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6396289131556638		[learning rate: 0.0029167]
	Learning Rate: 0.00291672
	LOSS [training: 0.6396289131556638 | validation: 0.6488981878031537]
	TIME [epoch: 9.07 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5990394467564163		[learning rate: 0.0029061]
	Learning Rate: 0.00290614
	LOSS [training: 0.5990394467564163 | validation: 0.6735965720877148]
	TIME [epoch: 9.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6567758292844723		[learning rate: 0.0028956]
	Learning Rate: 0.00289559
	LOSS [training: 0.6567758292844723 | validation: 0.7335587665631205]
	TIME [epoch: 9.08 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6309370105267051		[learning rate: 0.0028851]
	Learning Rate: 0.00288508
	LOSS [training: 0.6309370105267051 | validation: 0.6322804410404376]
	TIME [epoch: 9.07 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7768509505757987		[learning rate: 0.0028746]
	Learning Rate: 0.00287461
	LOSS [training: 0.7768509505757987 | validation: 0.7568876206871047]
	TIME [epoch: 9.08 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6587887322771776		[learning rate: 0.0028642]
	Learning Rate: 0.00286418
	LOSS [training: 0.6587887322771776 | validation: 0.8840418474021308]
	TIME [epoch: 9.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7198617021114272		[learning rate: 0.0028538]
	Learning Rate: 0.00285378
	LOSS [training: 0.7198617021114272 | validation: 0.5985530075271626]
	TIME [epoch: 9.08 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6559725594594681		[learning rate: 0.0028434]
	Learning Rate: 0.00284343
	LOSS [training: 0.6559725594594681 | validation: 0.9557081019455916]
	TIME [epoch: 9.08 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6756322525246655		[learning rate: 0.0028331]
	Learning Rate: 0.00283311
	LOSS [training: 0.6756322525246655 | validation: 0.6678792373120286]
	TIME [epoch: 9.08 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5616015960785447		[learning rate: 0.0028228]
	Learning Rate: 0.00282283
	LOSS [training: 0.5616015960785447 | validation: 0.8963868667336168]
	TIME [epoch: 9.08 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6575728517134618		[learning rate: 0.0028126]
	Learning Rate: 0.00281258
	LOSS [training: 0.6575728517134618 | validation: 0.8625703909850215]
	TIME [epoch: 9.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6219169457543685		[learning rate: 0.0028024]
	Learning Rate: 0.00280238
	LOSS [training: 0.6219169457543685 | validation: 0.7836462417992409]
	TIME [epoch: 9.09 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5845670967721289		[learning rate: 0.0027922]
	Learning Rate: 0.00279221
	LOSS [training: 0.5845670967721289 | validation: 0.9827388639211112]
	TIME [epoch: 9.08 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8729472256806579		[learning rate: 0.0027821]
	Learning Rate: 0.00278207
	LOSS [training: 0.8729472256806579 | validation: 0.7908782517137525]
	TIME [epoch: 9.07 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7245097597861362		[learning rate: 0.002772]
	Learning Rate: 0.00277198
	LOSS [training: 0.7245097597861362 | validation: 0.676468574372515]
	TIME [epoch: 9.11 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5710245133669243		[learning rate: 0.0027619]
	Learning Rate: 0.00276192
	LOSS [training: 0.5710245133669243 | validation: 1.0413018563871197]
	TIME [epoch: 9.08 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6622670261730025		[learning rate: 0.0027519]
	Learning Rate: 0.00275189
	LOSS [training: 0.6622670261730025 | validation: 0.6517398106949834]
	TIME [epoch: 9.07 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.605848459317328		[learning rate: 0.0027419]
	Learning Rate: 0.00274191
	LOSS [training: 0.605848459317328 | validation: 0.6476116087113847]
	TIME [epoch: 9.09 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5792066052091305		[learning rate: 0.002732]
	Learning Rate: 0.00273196
	LOSS [training: 0.5792066052091305 | validation: 0.7056919992622335]
	TIME [epoch: 9.08 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.61354478731988		[learning rate: 0.002722]
	Learning Rate: 0.00272204
	LOSS [training: 0.61354478731988 | validation: 0.679380367463532]
	TIME [epoch: 9.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5722105712332253		[learning rate: 0.0027122]
	Learning Rate: 0.00271216
	LOSS [training: 0.5722105712332253 | validation: 0.7700808057355875]
	TIME [epoch: 9.08 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6018410546907348		[learning rate: 0.0027023]
	Learning Rate: 0.00270232
	LOSS [training: 0.6018410546907348 | validation: 0.64568834576096]
	TIME [epoch: 9.08 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5907328545225996		[learning rate: 0.0026925]
	Learning Rate: 0.00269251
	LOSS [training: 0.5907328545225996 | validation: 0.607359901202617]
	TIME [epoch: 9.07 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6623258595086831		[learning rate: 0.0026827]
	Learning Rate: 0.00268274
	LOSS [training: 0.6623258595086831 | validation: 0.9592294657858078]
	TIME [epoch: 9.08 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7287786268470969		[learning rate: 0.002673]
	Learning Rate: 0.00267301
	LOSS [training: 0.7287786268470969 | validation: 0.7429468470396661]
	TIME [epoch: 9.12 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5566781668262746		[learning rate: 0.0026633]
	Learning Rate: 0.00266331
	LOSS [training: 0.5566781668262746 | validation: 0.7493795194083093]
	TIME [epoch: 9.08 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.640188907348697		[learning rate: 0.0026536]
	Learning Rate: 0.00265364
	LOSS [training: 0.640188907348697 | validation: 0.982831908098937]
	TIME [epoch: 9.08 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5731598906824574		[learning rate: 0.002644]
	Learning Rate: 0.00264401
	LOSS [training: 0.5731598906824574 | validation: 0.9367418817737745]
	TIME [epoch: 9.07 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6398912865688031		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.6398912865688031 | validation: 1.0833689685315901]
	TIME [epoch: 9.09 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6004337070832744		[learning rate: 0.0026249]
	Learning Rate: 0.00262485
	LOSS [training: 0.6004337070832744 | validation: 0.8332748903817808]
	TIME [epoch: 9.08 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6436301913178395		[learning rate: 0.0026153]
	Learning Rate: 0.00261533
	LOSS [training: 0.6436301913178395 | validation: 0.7595062939462149]
	TIME [epoch: 9.07 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5691057102039951		[learning rate: 0.0026058]
	Learning Rate: 0.00260584
	LOSS [training: 0.5691057102039951 | validation: 0.6173983033114905]
	TIME [epoch: 9.09 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6785557146759904		[learning rate: 0.0025964]
	Learning Rate: 0.00259638
	LOSS [training: 0.6785557146759904 | validation: 0.7670306237128208]
	TIME [epoch: 9.07 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6074359351952614		[learning rate: 0.002587]
	Learning Rate: 0.00258696
	LOSS [training: 0.6074359351952614 | validation: 0.8876092151594552]
	TIME [epoch: 9.1 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6771255979778349		[learning rate: 0.0025776]
	Learning Rate: 0.00257757
	LOSS [training: 0.6771255979778349 | validation: 0.6151351284149484]
	TIME [epoch: 9.07 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5660562593756858		[learning rate: 0.0025682]
	Learning Rate: 0.00256822
	LOSS [training: 0.5660562593756858 | validation: 0.6264072707933863]
	TIME [epoch: 9.07 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5597428452823706		[learning rate: 0.0025589]
	Learning Rate: 0.0025589
	LOSS [training: 0.5597428452823706 | validation: 0.6671465060418871]
	TIME [epoch: 9.08 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6453003800287984		[learning rate: 0.0025496]
	Learning Rate: 0.00254961
	LOSS [training: 0.6453003800287984 | validation: 0.647196014926333]
	TIME [epoch: 9.11 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6175851838591273		[learning rate: 0.0025404]
	Learning Rate: 0.00254036
	LOSS [training: 0.6175851838591273 | validation: 0.8396817865993473]
	TIME [epoch: 9.09 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6125128924856303		[learning rate: 0.0025311]
	Learning Rate: 0.00253114
	LOSS [training: 0.6125128924856303 | validation: 0.829708659310396]
	TIME [epoch: 9.09 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5915321643737134		[learning rate: 0.002522]
	Learning Rate: 0.00252195
	LOSS [training: 0.5915321643737134 | validation: 0.7182512901953853]
	TIME [epoch: 9.07 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5917138860069793		[learning rate: 0.0025128]
	Learning Rate: 0.0025128
	LOSS [training: 0.5917138860069793 | validation: 0.6326619962318535]
	TIME [epoch: 9.08 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6371708754257949		[learning rate: 0.0025037]
	Learning Rate: 0.00250368
	LOSS [training: 0.6371708754257949 | validation: 0.8681613336275946]
	TIME [epoch: 9.09 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5476447140907826		[learning rate: 0.0024946]
	Learning Rate: 0.00249459
	LOSS [training: 0.5476447140907826 | validation: 0.7115344786231449]
	TIME [epoch: 9.09 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5513911043112916		[learning rate: 0.0024855]
	Learning Rate: 0.00248554
	LOSS [training: 0.5513911043112916 | validation: 0.7978364379259955]
	TIME [epoch: 9.08 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6365859934916834		[learning rate: 0.0024765]
	Learning Rate: 0.00247652
	LOSS [training: 0.6365859934916834 | validation: 0.8050736001735497]
	TIME [epoch: 9.07 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6462307334601073		[learning rate: 0.0024675]
	Learning Rate: 0.00246753
	LOSS [training: 0.6462307334601073 | validation: 0.9184282362375533]
	TIME [epoch: 9.08 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5839763805814585		[learning rate: 0.0024586]
	Learning Rate: 0.00245858
	LOSS [training: 0.5839763805814585 | validation: 0.6439933538325815]
	TIME [epoch: 9.09 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5456998131965195		[learning rate: 0.0024497]
	Learning Rate: 0.00244966
	LOSS [training: 0.5456998131965195 | validation: 0.9239827984777409]
	TIME [epoch: 9.08 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6422903246983074		[learning rate: 0.0024408]
	Learning Rate: 0.00244077
	LOSS [training: 0.6422903246983074 | validation: 0.9115184536890986]
	TIME [epoch: 9.08 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6073554192605503		[learning rate: 0.0024319]
	Learning Rate: 0.00243191
	LOSS [training: 0.6073554192605503 | validation: 0.7031533104747548]
	TIME [epoch: 9.09 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6200849833258162		[learning rate: 0.0024231]
	Learning Rate: 0.00242308
	LOSS [training: 0.6200849833258162 | validation: 0.609250214143896]
	TIME [epoch: 9.11 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5849013328481838		[learning rate: 0.0024143]
	Learning Rate: 0.00241429
	LOSS [training: 0.5849013328481838 | validation: 0.8995583771476432]
	TIME [epoch: 9.09 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5904757216296063		[learning rate: 0.0024055]
	Learning Rate: 0.00240553
	LOSS [training: 0.5904757216296063 | validation: 0.8989263241054206]
	TIME [epoch: 9.07 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6494961785226898		[learning rate: 0.0023968]
	Learning Rate: 0.0023968
	LOSS [training: 0.6494961785226898 | validation: 0.7756710915293668]
	TIME [epoch: 9.09 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5297297900159046		[learning rate: 0.0023881]
	Learning Rate: 0.0023881
	LOSS [training: 0.5297297900159046 | validation: 0.6917546264561636]
	TIME [epoch: 9.08 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5764905011734978		[learning rate: 0.0023794]
	Learning Rate: 0.00237943
	LOSS [training: 0.5764905011734978 | validation: 0.7097013284887508]
	TIME [epoch: 9.09 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5398259062463922		[learning rate: 0.0023708]
	Learning Rate: 0.0023708
	LOSS [training: 0.5398259062463922 | validation: 0.6121014450328939]
	TIME [epoch: 9.08 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.626797211483106		[learning rate: 0.0023622]
	Learning Rate: 0.0023622
	LOSS [training: 0.626797211483106 | validation: 0.5799882273594966]
	TIME [epoch: 9.08 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5345551441427302		[learning rate: 0.0023536]
	Learning Rate: 0.00235362
	LOSS [training: 0.5345551441427302 | validation: 0.9991695844021065]
	TIME [epoch: 9.08 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6127801582805488		[learning rate: 0.0023451]
	Learning Rate: 0.00234508
	LOSS [training: 0.6127801582805488 | validation: 0.8822190888948388]
	TIME [epoch: 9.09 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6923609988061491		[learning rate: 0.0023366]
	Learning Rate: 0.00233657
	LOSS [training: 0.6923609988061491 | validation: 0.746114066111828]
	TIME [epoch: 9.08 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5389332081316218		[learning rate: 0.0023281]
	Learning Rate: 0.00232809
	LOSS [training: 0.5389332081316218 | validation: 0.5710148695608495]
	TIME [epoch: 9.07 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5537743666107957		[learning rate: 0.0023196]
	Learning Rate: 0.00231964
	LOSS [training: 0.5537743666107957 | validation: 0.6440505216829463]
	TIME [epoch: 9.08 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6163154730545665		[learning rate: 0.0023112]
	Learning Rate: 0.00231122
	LOSS [training: 0.6163154730545665 | validation: 0.5954189531470493]
	TIME [epoch: 9.07 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5464079651875586		[learning rate: 0.0023028]
	Learning Rate: 0.00230284
	LOSS [training: 0.5464079651875586 | validation: 0.7859958803060636]
	TIME [epoch: 9.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5517803284505993		[learning rate: 0.0022945]
	Learning Rate: 0.00229448
	LOSS [training: 0.5517803284505993 | validation: 0.5627639403292338]
	TIME [epoch: 9.07 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.509179428277539		[learning rate: 0.0022862]
	Learning Rate: 0.00228615
	LOSS [training: 0.509179428277539 | validation: 0.6651776699407286]
	TIME [epoch: 9.08 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5847530344854143		[learning rate: 0.0022779]
	Learning Rate: 0.00227786
	LOSS [training: 0.5847530344854143 | validation: 0.752843508671444]
	TIME [epoch: 9.08 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5868879387844628		[learning rate: 0.0022696]
	Learning Rate: 0.00226959
	LOSS [training: 0.5868879387844628 | validation: 1.3060799149543754]
	TIME [epoch: 9.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6089320983808016		[learning rate: 0.0022614]
	Learning Rate: 0.00226135
	LOSS [training: 0.6089320983808016 | validation: 0.735802135510814]
	TIME [epoch: 9.08 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5216020377651616		[learning rate: 0.0022531]
	Learning Rate: 0.00225315
	LOSS [training: 0.5216020377651616 | validation: 0.7288088351326266]
	TIME [epoch: 9.07 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5210551981678246		[learning rate: 0.002245]
	Learning Rate: 0.00224497
	LOSS [training: 0.5210551981678246 | validation: 0.59839102014246]
	TIME [epoch: 9.08 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5035325764659169		[learning rate: 0.0022368]
	Learning Rate: 0.00223682
	LOSS [training: 0.5035325764659169 | validation: 0.6356907155627822]
	TIME [epoch: 9.08 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.599100866040102		[learning rate: 0.0022287]
	Learning Rate: 0.00222871
	LOSS [training: 0.599100866040102 | validation: 0.691933954416011]
	TIME [epoch: 9.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8698560507387508		[learning rate: 0.0022206]
	Learning Rate: 0.00222062
	LOSS [training: 0.8698560507387508 | validation: 0.6400377123468248]
	TIME [epoch: 9.08 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5523508328974713		[learning rate: 0.0022126]
	Learning Rate: 0.00221256
	LOSS [training: 0.5523508328974713 | validation: 0.5457741924731819]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_515.pth
	Model improved!!!
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5604868873658327		[learning rate: 0.0022045]
	Learning Rate: 0.00220453
	LOSS [training: 0.5604868873658327 | validation: 0.6269443141443775]
	TIME [epoch: 9.08 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5309671650175568		[learning rate: 0.0021965]
	Learning Rate: 0.00219653
	LOSS [training: 0.5309671650175568 | validation: 0.6200371901606435]
	TIME [epoch: 9.09 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6136994317921921		[learning rate: 0.0021886]
	Learning Rate: 0.00218856
	LOSS [training: 0.6136994317921921 | validation: 0.702587396599859]
	TIME [epoch: 9.09 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5282900455112767		[learning rate: 0.0021806]
	Learning Rate: 0.00218061
	LOSS [training: 0.5282900455112767 | validation: 0.6506241881821185]
	TIME [epoch: 9.07 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6507340114732213		[learning rate: 0.0021727]
	Learning Rate: 0.0021727
	LOSS [training: 0.6507340114732213 | validation: 0.8787800310538261]
	TIME [epoch: 9.08 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5381989055475562		[learning rate: 0.0021648]
	Learning Rate: 0.00216482
	LOSS [training: 0.5381989055475562 | validation: 0.5569685482807463]
	TIME [epoch: 9.08 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5270729674503551		[learning rate: 0.002157]
	Learning Rate: 0.00215696
	LOSS [training: 0.5270729674503551 | validation: 0.6870557532684258]
	TIME [epoch: 9.09 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5814769804206961		[learning rate: 0.0021491]
	Learning Rate: 0.00214913
	LOSS [training: 0.5814769804206961 | validation: 0.929945067536962]
	TIME [epoch: 9.08 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.563446821413416		[learning rate: 0.0021413]
	Learning Rate: 0.00214133
	LOSS [training: 0.563446821413416 | validation: 0.596179006761439]
	TIME [epoch: 9.08 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.502795199191398		[learning rate: 0.0021336]
	Learning Rate: 0.00213356
	LOSS [training: 0.502795199191398 | validation: 0.6593133660010394]
	TIME [epoch: 9.06 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6014957596914672		[learning rate: 0.0021258]
	Learning Rate: 0.00212582
	LOSS [training: 0.6014957596914672 | validation: 0.6489123353711106]
	TIME [epoch: 9.08 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5100252211014532		[learning rate: 0.0021181]
	Learning Rate: 0.0021181
	LOSS [training: 0.5100252211014532 | validation: 0.7201969709972383]
	TIME [epoch: 9.09 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48051808300134863		[learning rate: 0.0021104]
	Learning Rate: 0.00211042
	LOSS [training: 0.48051808300134863 | validation: 0.6510159787581146]
	TIME [epoch: 9.08 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5354823874233934		[learning rate: 0.0021028]
	Learning Rate: 0.00210276
	LOSS [training: 0.5354823874233934 | validation: 0.6243207187354582]
	TIME [epoch: 9.09 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49099327675064774		[learning rate: 0.0020951]
	Learning Rate: 0.00209513
	LOSS [training: 0.49099327675064774 | validation: 0.6865475682372092]
	TIME [epoch: 9.09 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5245977117511896		[learning rate: 0.0020875]
	Learning Rate: 0.00208752
	LOSS [training: 0.5245977117511896 | validation: 0.6953073290258339]
	TIME [epoch: 9.08 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5330094574983718		[learning rate: 0.0020799]
	Learning Rate: 0.00207995
	LOSS [training: 0.5330094574983718 | validation: 0.8051411672075588]
	TIME [epoch: 9.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5237105087394414		[learning rate: 0.0020724]
	Learning Rate: 0.0020724
	LOSS [training: 0.5237105087394414 | validation: 1.1799798092222942]
	TIME [epoch: 9.07 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5967014600402074		[learning rate: 0.0020649]
	Learning Rate: 0.00206488
	LOSS [training: 0.5967014600402074 | validation: 0.6519773573434183]
	TIME [epoch: 9.06 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6168109417299349		[learning rate: 0.0020574]
	Learning Rate: 0.00205739
	LOSS [training: 0.6168109417299349 | validation: 0.5778115246304848]
	TIME [epoch: 9.07 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49951150119939697		[learning rate: 0.0020499]
	Learning Rate: 0.00204992
	LOSS [training: 0.49951150119939697 | validation: 0.6583384504968615]
	TIME [epoch: 9.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4987465321237988		[learning rate: 0.0020425]
	Learning Rate: 0.00204248
	LOSS [training: 0.4987465321237988 | validation: 0.9047338779642548]
	TIME [epoch: 9.09 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5626225737755505		[learning rate: 0.0020351]
	Learning Rate: 0.00203507
	LOSS [training: 0.5626225737755505 | validation: 0.6384914245413669]
	TIME [epoch: 9.08 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5487112504027921		[learning rate: 0.0020277]
	Learning Rate: 0.00202768
	LOSS [training: 0.5487112504027921 | validation: 0.6152045039926586]
	TIME [epoch: 9.08 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49825532229204395		[learning rate: 0.0020203]
	Learning Rate: 0.00202032
	LOSS [training: 0.49825532229204395 | validation: 0.7329894386534364]
	TIME [epoch: 9.07 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5833386261951665		[learning rate: 0.002013]
	Learning Rate: 0.00201299
	LOSS [training: 0.5833386261951665 | validation: 0.6591423434503699]
	TIME [epoch: 9.09 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5133908631394162		[learning rate: 0.0020057]
	Learning Rate: 0.00200569
	LOSS [training: 0.5133908631394162 | validation: 0.6210803340688518]
	TIME [epoch: 9.08 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5077997082235943		[learning rate: 0.0019984]
	Learning Rate: 0.00199841
	LOSS [training: 0.5077997082235943 | validation: 0.5453678868519791]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_543.pth
	Model improved!!!
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.500942516240799		[learning rate: 0.0019912]
	Learning Rate: 0.00199116
	LOSS [training: 0.500942516240799 | validation: 0.5547972414086975]
	TIME [epoch: 9.09 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48862108193794834		[learning rate: 0.0019839]
	Learning Rate: 0.00198393
	LOSS [training: 0.48862108193794834 | validation: 0.5499414344575128]
	TIME [epoch: 9.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5199077920455946		[learning rate: 0.0019767]
	Learning Rate: 0.00197673
	LOSS [training: 0.5199077920455946 | validation: 0.6281322366805313]
	TIME [epoch: 9.08 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.637352704478355		[learning rate: 0.0019696]
	Learning Rate: 0.00196956
	LOSS [training: 0.637352704478355 | validation: 0.7634570090854729]
	TIME [epoch: 9.08 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5658086778731367		[learning rate: 0.0019624]
	Learning Rate: 0.00196241
	LOSS [training: 0.5658086778731367 | validation: 0.5384431561707603]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4970043889184816		[learning rate: 0.0019553]
	Learning Rate: 0.00195529
	LOSS [training: 0.4970043889184816 | validation: 0.567727784847614]
	TIME [epoch: 9.08 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5557176247911519		[learning rate: 0.0019482]
	Learning Rate: 0.00194819
	LOSS [training: 0.5557176247911519 | validation: 0.6237160442904377]
	TIME [epoch: 9.1 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5360672237258273		[learning rate: 0.0019411]
	Learning Rate: 0.00194112
	LOSS [training: 0.5360672237258273 | validation: 0.5563986429990619]
	TIME [epoch: 9.08 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49172871296171455		[learning rate: 0.0019341]
	Learning Rate: 0.00193408
	LOSS [training: 0.49172871296171455 | validation: 0.6499335773434439]
	TIME [epoch: 9.08 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5020395933288204		[learning rate: 0.0019271]
	Learning Rate: 0.00192706
	LOSS [training: 0.5020395933288204 | validation: 0.6332573431512467]
	TIME [epoch: 9.08 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4898380317227301		[learning rate: 0.0019201]
	Learning Rate: 0.00192006
	LOSS [training: 0.4898380317227301 | validation: 0.6627394789163328]
	TIME [epoch: 9.08 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5101092902776146		[learning rate: 0.0019131]
	Learning Rate: 0.0019131
	LOSS [training: 0.5101092902776146 | validation: 0.646869917849416]
	TIME [epoch: 9.11 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5101378630665604		[learning rate: 0.0019062]
	Learning Rate: 0.00190615
	LOSS [training: 0.5101378630665604 | validation: 1.164355952301786]
	TIME [epoch: 9.08 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6068497198369969		[learning rate: 0.0018992]
	Learning Rate: 0.00189924
	LOSS [training: 0.6068497198369969 | validation: 1.0623418665296416]
	TIME [epoch: 9.08 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5556617414909286		[learning rate: 0.0018923]
	Learning Rate: 0.00189234
	LOSS [training: 0.5556617414909286 | validation: 0.6511960040147802]
	TIME [epoch: 9.08 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5414141690582865		[learning rate: 0.0018855]
	Learning Rate: 0.00188548
	LOSS [training: 0.5414141690582865 | validation: 0.6002289364415545]
	TIME [epoch: 9.07 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5199899349482975		[learning rate: 0.0018786]
	Learning Rate: 0.00187863
	LOSS [training: 0.5199899349482975 | validation: 0.973367788984703]
	TIME [epoch: 9.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5737369210887814		[learning rate: 0.0018718]
	Learning Rate: 0.00187182
	LOSS [training: 0.5737369210887814 | validation: 0.5630230062409207]
	TIME [epoch: 9.07 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4875642648890478		[learning rate: 0.001865]
	Learning Rate: 0.00186502
	LOSS [training: 0.4875642648890478 | validation: 0.6644277139634126]
	TIME [epoch: 9.08 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5284210583084453		[learning rate: 0.0018583]
	Learning Rate: 0.00185825
	LOSS [training: 0.5284210583084453 | validation: 0.9839123927019731]
	TIME [epoch: 9.07 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5486499027563273		[learning rate: 0.0018515]
	Learning Rate: 0.00185151
	LOSS [training: 0.5486499027563273 | validation: 0.6588325924543655]
	TIME [epoch: 9.09 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5041223453254671		[learning rate: 0.0018448]
	Learning Rate: 0.00184479
	LOSS [training: 0.5041223453254671 | validation: 0.9946459483655479]
	TIME [epoch: 9.09 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5921453901341541		[learning rate: 0.0018381]
	Learning Rate: 0.0018381
	LOSS [training: 0.5921453901341541 | validation: 0.614725185977201]
	TIME [epoch: 9.07 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5419165725989028		[learning rate: 0.0018314]
	Learning Rate: 0.00183143
	LOSS [training: 0.5419165725989028 | validation: 0.6188954472940449]
	TIME [epoch: 9.07 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6292654388770009		[learning rate: 0.0018248]
	Learning Rate: 0.00182478
	LOSS [training: 0.6292654388770009 | validation: 0.6374575529669574]
	TIME [epoch: 9.07 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5193958508166476		[learning rate: 0.0018182]
	Learning Rate: 0.00181816
	LOSS [training: 0.5193958508166476 | validation: 0.5959640976718361]
	TIME [epoch: 9.09 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.543378047144509		[learning rate: 0.0018116]
	Learning Rate: 0.00181156
	LOSS [training: 0.543378047144509 | validation: 0.5834031284540941]
	TIME [epoch: 9.08 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5064145651110212		[learning rate: 0.001805]
	Learning Rate: 0.00180499
	LOSS [training: 0.5064145651110212 | validation: 0.6852268190932165]
	TIME [epoch: 9.08 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4896228813164457		[learning rate: 0.0017984]
	Learning Rate: 0.00179844
	LOSS [training: 0.4896228813164457 | validation: 0.7236278858680738]
	TIME [epoch: 9.08 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5014335343632161		[learning rate: 0.0017919]
	Learning Rate: 0.00179191
	LOSS [training: 0.5014335343632161 | validation: 0.8633943681462926]
	TIME [epoch: 9.09 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6222671174117412		[learning rate: 0.0017854]
	Learning Rate: 0.00178541
	LOSS [training: 0.6222671174117412 | validation: 0.8375907858506719]
	TIME [epoch: 9.08 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5695922923880816		[learning rate: 0.0017789]
	Learning Rate: 0.00177893
	LOSS [training: 0.5695922923880816 | validation: 0.686796951798396]
	TIME [epoch: 9.07 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5083793390625948		[learning rate: 0.0017725]
	Learning Rate: 0.00177247
	LOSS [training: 0.5083793390625948 | validation: 0.5869999868984319]
	TIME [epoch: 9.07 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4660547764733781		[learning rate: 0.001766]
	Learning Rate: 0.00176604
	LOSS [training: 0.4660547764733781 | validation: 0.5357736345274238]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4949255918215834		[learning rate: 0.0017596]
	Learning Rate: 0.00175963
	LOSS [training: 0.4949255918215834 | validation: 0.561481324779688]
	TIME [epoch: 9.11 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5671242616224783		[learning rate: 0.0017532]
	Learning Rate: 0.00175324
	LOSS [training: 0.5671242616224783 | validation: 0.6179302306124893]
	TIME [epoch: 9.09 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5325434238579192		[learning rate: 0.0017469]
	Learning Rate: 0.00174688
	LOSS [training: 0.5325434238579192 | validation: 0.5452427851520218]
	TIME [epoch: 9.08 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4699600017614576		[learning rate: 0.0017405]
	Learning Rate: 0.00174054
	LOSS [training: 0.4699600017614576 | validation: 0.6998605781552791]
	TIME [epoch: 9.09 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49218052039073223		[learning rate: 0.0017342]
	Learning Rate: 0.00173422
	LOSS [training: 0.49218052039073223 | validation: 0.71950360012741]
	TIME [epoch: 9.08 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48282353750232837		[learning rate: 0.0017279]
	Learning Rate: 0.00172793
	LOSS [training: 0.48282353750232837 | validation: 0.6079368408507375]
	TIME [epoch: 9.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5421100503612196		[learning rate: 0.0017217]
	Learning Rate: 0.00172166
	LOSS [training: 0.5421100503612196 | validation: 0.5555721869398501]
	TIME [epoch: 9.08 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46128784437435505		[learning rate: 0.0017154]
	Learning Rate: 0.00171541
	LOSS [training: 0.46128784437435505 | validation: 0.6278410813698299]
	TIME [epoch: 9.08 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5681138041580395		[learning rate: 0.0017092]
	Learning Rate: 0.00170919
	LOSS [training: 0.5681138041580395 | validation: 0.6059528157037213]
	TIME [epoch: 9.08 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48833977486759855		[learning rate: 0.001703]
	Learning Rate: 0.00170298
	LOSS [training: 0.48833977486759855 | validation: 0.5305052422256589]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_587.pth
	Model improved!!!
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5858753086209717		[learning rate: 0.0016968]
	Learning Rate: 0.0016968
	LOSS [training: 0.5858753086209717 | validation: 0.5524445312832618]
	TIME [epoch: 9.11 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.505768361673433		[learning rate: 0.0016906]
	Learning Rate: 0.00169065
	LOSS [training: 0.505768361673433 | validation: 0.5821619116510882]
	TIME [epoch: 9.08 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45056986544125444		[learning rate: 0.0016845]
	Learning Rate: 0.00168451
	LOSS [training: 0.45056986544125444 | validation: 0.6223644223382044]
	TIME [epoch: 9.08 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5549862187967818		[learning rate: 0.0016784]
	Learning Rate: 0.0016784
	LOSS [training: 0.5549862187967818 | validation: 0.5646076480275133]
	TIME [epoch: 9.08 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5088755941304411		[learning rate: 0.0016723]
	Learning Rate: 0.00167231
	LOSS [training: 0.5088755941304411 | validation: 0.6674874847910699]
	TIME [epoch: 9.09 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4943168708180661		[learning rate: 0.0016662]
	Learning Rate: 0.00166624
	LOSS [training: 0.4943168708180661 | validation: 0.547376564379586]
	TIME [epoch: 9.09 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46588426067005545		[learning rate: 0.0016602]
	Learning Rate: 0.00166019
	LOSS [training: 0.46588426067005545 | validation: 0.7432931630786807]
	TIME [epoch: 9.08 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5531149077284706		[learning rate: 0.0016542]
	Learning Rate: 0.00165417
	LOSS [training: 0.5531149077284706 | validation: 0.6366022546372144]
	TIME [epoch: 9.08 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5085874492506123		[learning rate: 0.0016482]
	Learning Rate: 0.00164816
	LOSS [training: 0.5085874492506123 | validation: 0.5837795842700414]
	TIME [epoch: 9.08 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44457040680734455		[learning rate: 0.0016422]
	Learning Rate: 0.00164218
	LOSS [training: 0.44457040680734455 | validation: 0.6160542796251878]
	TIME [epoch: 9.09 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4730182210453571		[learning rate: 0.0016362]
	Learning Rate: 0.00163622
	LOSS [training: 0.4730182210453571 | validation: 0.67348575800813]
	TIME [epoch: 9.09 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.565746288637271		[learning rate: 0.0016303]
	Learning Rate: 0.00163028
	LOSS [training: 0.565746288637271 | validation: 0.5824549619539316]
	TIME [epoch: 9.08 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4919658004529607		[learning rate: 0.0016244]
	Learning Rate: 0.00162437
	LOSS [training: 0.4919658004529607 | validation: 0.5894239858888755]
	TIME [epoch: 9.08 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6089822052564474		[learning rate: 0.0016185]
	Learning Rate: 0.00161847
	LOSS [training: 0.6089822052564474 | validation: 0.8351251480669925]
	TIME [epoch: 9.08 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5140763091073044		[learning rate: 0.0016126]
	Learning Rate: 0.0016126
	LOSS [training: 0.5140763091073044 | validation: 0.6542397651338766]
	TIME [epoch: 9.09 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4934415952734941		[learning rate: 0.0016067]
	Learning Rate: 0.00160675
	LOSS [training: 0.4934415952734941 | validation: 0.5438372782087924]
	TIME [epoch: 9.09 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46851287232567573		[learning rate: 0.0016009]
	Learning Rate: 0.00160092
	LOSS [training: 0.46851287232567573 | validation: 0.818943554231266]
	TIME [epoch: 9.08 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5301493587037014		[learning rate: 0.0015951]
	Learning Rate: 0.00159511
	LOSS [training: 0.5301493587037014 | validation: 0.8270928829049827]
	TIME [epoch: 9.08 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5164256544070278		[learning rate: 0.0015893]
	Learning Rate: 0.00158932
	LOSS [training: 0.5164256544070278 | validation: 0.559348350210297]
	TIME [epoch: 9.08 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4530344835942225		[learning rate: 0.0015835]
	Learning Rate: 0.00158355
	LOSS [training: 0.4530344835942225 | validation: 0.540975582179907]
	TIME [epoch: 9.1 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43136168844577183		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.43136168844577183 | validation: 0.5800904333186903]
	TIME [epoch: 9.1 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44944393746066147		[learning rate: 0.0015721]
	Learning Rate: 0.00157208
	LOSS [training: 0.44944393746066147 | validation: 0.5646755990383712]
	TIME [epoch: 9.08 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44993918073623185		[learning rate: 0.0015664]
	Learning Rate: 0.00156637
	LOSS [training: 0.44993918073623185 | validation: 1.1644137500322898]
	TIME [epoch: 9.08 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.543619087193545		[learning rate: 0.0015607]
	Learning Rate: 0.00156069
	LOSS [training: 0.543619087193545 | validation: 0.5901290840712967]
	TIME [epoch: 9.08 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4439441068157574		[learning rate: 0.001555]
	Learning Rate: 0.00155502
	LOSS [training: 0.4439441068157574 | validation: 0.5442789398686668]
	TIME [epoch: 9.09 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46269567917961385		[learning rate: 0.0015494]
	Learning Rate: 0.00154938
	LOSS [training: 0.46269567917961385 | validation: 0.560730107743255]
	TIME [epoch: 9.07 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43679072912600186		[learning rate: 0.0015438]
	Learning Rate: 0.00154376
	LOSS [training: 0.43679072912600186 | validation: 0.6856262843409326]
	TIME [epoch: 9.08 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4727902240235501		[learning rate: 0.0015382]
	Learning Rate: 0.00153815
	LOSS [training: 0.4727902240235501 | validation: 0.5572009095382948]
	TIME [epoch: 9.08 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45596898030949573		[learning rate: 0.0015326]
	Learning Rate: 0.00153257
	LOSS [training: 0.45596898030949573 | validation: 0.6544189684259495]
	TIME [epoch: 9.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43972515299196946		[learning rate: 0.001527]
	Learning Rate: 0.00152701
	LOSS [training: 0.43972515299196946 | validation: 0.5146004359024283]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_617.pth
	Model improved!!!
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4991979989878995		[learning rate: 0.0015215]
	Learning Rate: 0.00152147
	LOSS [training: 0.4991979989878995 | validation: 0.5313250323563279]
	TIME [epoch: 9.09 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45188584162679507		[learning rate: 0.0015159]
	Learning Rate: 0.00151595
	LOSS [training: 0.45188584162679507 | validation: 0.6159280742393044]
	TIME [epoch: 9.08 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4710695334210939		[learning rate: 0.0015104]
	Learning Rate: 0.00151045
	LOSS [training: 0.4710695334210939 | validation: 0.5279799631411886]
	TIME [epoch: 9.08 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5275601195878379		[learning rate: 0.001505]
	Learning Rate: 0.00150496
	LOSS [training: 0.5275601195878379 | validation: 0.568332727252276]
	TIME [epoch: 9.11 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4627710177828669		[learning rate: 0.0014995]
	Learning Rate: 0.0014995
	LOSS [training: 0.4627710177828669 | validation: 0.5997710593555182]
	TIME [epoch: 9.09 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5402455118621126		[learning rate: 0.0014941]
	Learning Rate: 0.00149406
	LOSS [training: 0.5402455118621126 | validation: 0.5177628535928454]
	TIME [epoch: 9.09 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43352084800448454		[learning rate: 0.0014886]
	Learning Rate: 0.00148864
	LOSS [training: 0.43352084800448454 | validation: 0.528457341868432]
	TIME [epoch: 9.09 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5063390226513285		[learning rate: 0.0014832]
	Learning Rate: 0.00148324
	LOSS [training: 0.5063390226513285 | validation: 0.86467473145602]
	TIME [epoch: 9.09 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48466138742388826		[learning rate: 0.0014779]
	Learning Rate: 0.00147785
	LOSS [training: 0.48466138742388826 | validation: 0.581039344077564]
	TIME [epoch: 9.11 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4717726700588643		[learning rate: 0.0014725]
	Learning Rate: 0.00147249
	LOSS [training: 0.4717726700588643 | validation: 0.5849853744682599]
	TIME [epoch: 9.1 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4842580156314461		[learning rate: 0.0014671]
	Learning Rate: 0.00146715
	LOSS [training: 0.4842580156314461 | validation: 0.5526662377566531]
	TIME [epoch: 9.09 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49837499222910714		[learning rate: 0.0014618]
	Learning Rate: 0.00146182
	LOSS [training: 0.49837499222910714 | validation: 0.8734769833812197]
	TIME [epoch: 9.09 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5248510007997316		[learning rate: 0.0014565]
	Learning Rate: 0.00145652
	LOSS [training: 0.5248510007997316 | validation: 0.5480389439925965]
	TIME [epoch: 9.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45780836284282556		[learning rate: 0.0014512]
	Learning Rate: 0.00145123
	LOSS [training: 0.45780836284282556 | validation: 0.5824800455576706]
	TIME [epoch: 9.1 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47900256680172904		[learning rate: 0.001446]
	Learning Rate: 0.00144597
	LOSS [training: 0.47900256680172904 | validation: 0.6578258775589118]
	TIME [epoch: 9.09 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48330057521630226		[learning rate: 0.0014407]
	Learning Rate: 0.00144072
	LOSS [training: 0.48330057521630226 | validation: 0.5245337917458619]
	TIME [epoch: 9.09 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49279489878164207		[learning rate: 0.0014355]
	Learning Rate: 0.00143549
	LOSS [training: 0.49279489878164207 | validation: 0.6912394890865561]
	TIME [epoch: 9.1 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4929093281216141		[learning rate: 0.0014303]
	Learning Rate: 0.00143028
	LOSS [training: 0.4929093281216141 | validation: 0.5572434690541739]
	TIME [epoch: 9.11 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47368123379960536		[learning rate: 0.0014251]
	Learning Rate: 0.00142509
	LOSS [training: 0.47368123379960536 | validation: 0.9867384128782887]
	TIME [epoch: 9.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.507602006810181		[learning rate: 0.0014199]
	Learning Rate: 0.00141992
	LOSS [training: 0.507602006810181 | validation: 0.6445736378618714]
	TIME [epoch: 9.09 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4550036248180921		[learning rate: 0.0014148]
	Learning Rate: 0.00141476
	LOSS [training: 0.4550036248180921 | validation: 1.05195453126362]
	TIME [epoch: 9.09 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4966393352984156		[learning rate: 0.0014096]
	Learning Rate: 0.00140963
	LOSS [training: 0.4966393352984156 | validation: 0.5255404463590492]
	TIME [epoch: 9.09 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4805274956371212		[learning rate: 0.0014045]
	Learning Rate: 0.00140451
	LOSS [training: 0.4805274956371212 | validation: 0.6149062472262341]
	TIME [epoch: 9.11 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4714579037892084		[learning rate: 0.0013994]
	Learning Rate: 0.00139942
	LOSS [training: 0.4714579037892084 | validation: 0.5783366925589579]
	TIME [epoch: 9.09 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43250705081280116		[learning rate: 0.0013943]
	Learning Rate: 0.00139434
	LOSS [training: 0.43250705081280116 | validation: 0.589336375205316]
	TIME [epoch: 9.1 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4802131553348044		[learning rate: 0.0013893]
	Learning Rate: 0.00138928
	LOSS [training: 0.4802131553348044 | validation: 0.5054480579478535]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_643.pth
	Model improved!!!
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46472841598771114		[learning rate: 0.0013842]
	Learning Rate: 0.00138424
	LOSS [training: 0.46472841598771114 | validation: 0.49553050785515607]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42204111440443526		[learning rate: 0.0013792]
	Learning Rate: 0.00137921
	LOSS [training: 0.42204111440443526 | validation: 0.5371471114572024]
	TIME [epoch: 9.08 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43752277433667086		[learning rate: 0.0013742]
	Learning Rate: 0.00137421
	LOSS [training: 0.43752277433667086 | validation: 0.5199784338136421]
	TIME [epoch: 9.08 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43169529691668024		[learning rate: 0.0013692]
	Learning Rate: 0.00136922
	LOSS [training: 0.43169529691668024 | validation: 0.5444257860618973]
	TIME [epoch: 9.08 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5314325582818513		[learning rate: 0.0013643]
	Learning Rate: 0.00136425
	LOSS [training: 0.5314325582818513 | validation: 0.47182245460362127]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5273652976390194		[learning rate: 0.0013593]
	Learning Rate: 0.0013593
	LOSS [training: 0.5273652976390194 | validation: 0.5387884123369451]
	TIME [epoch: 9.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45098019473472706		[learning rate: 0.0013544]
	Learning Rate: 0.00135437
	LOSS [training: 0.45098019473472706 | validation: 0.47720387527098085]
	TIME [epoch: 9.07 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46657151941554176		[learning rate: 0.0013495]
	Learning Rate: 0.00134945
	LOSS [training: 0.46657151941554176 | validation: 0.4839483945825045]
	TIME [epoch: 9.08 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39534976414002343		[learning rate: 0.0013446]
	Learning Rate: 0.00134456
	LOSS [training: 0.39534976414002343 | validation: 0.7888162718435203]
	TIME [epoch: 9.07 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47373204483057485		[learning rate: 0.0013397]
	Learning Rate: 0.00133968
	LOSS [training: 0.47373204483057485 | validation: 0.531411175693244]
	TIME [epoch: 9.07 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42105191081500226		[learning rate: 0.0013348]
	Learning Rate: 0.00133481
	LOSS [training: 0.42105191081500226 | validation: 0.6950324239279473]
	TIME [epoch: 9.09 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4429441617507085		[learning rate: 0.00133]
	Learning Rate: 0.00132997
	LOSS [training: 0.4429441617507085 | validation: 0.6017941265123095]
	TIME [epoch: 9.08 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4125093979272473		[learning rate: 0.0013251]
	Learning Rate: 0.00132514
	LOSS [training: 0.4125093979272473 | validation: 0.5328433644070059]
	TIME [epoch: 9.07 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49881496417179455		[learning rate: 0.0013203]
	Learning Rate: 0.00132034
	LOSS [training: 0.49881496417179455 | validation: 0.5398210027637587]
	TIME [epoch: 9.07 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4142951953162841		[learning rate: 0.0013155]
	Learning Rate: 0.00131554
	LOSS [training: 0.4142951953162841 | validation: 0.4820688347734404]
	TIME [epoch: 9.07 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45277432869753503		[learning rate: 0.0013108]
	Learning Rate: 0.00131077
	LOSS [training: 0.45277432869753503 | validation: 0.5857333910925471]
	TIME [epoch: 9.09 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4097427052528748		[learning rate: 0.001306]
	Learning Rate: 0.00130601
	LOSS [training: 0.4097427052528748 | validation: 0.6294726389120625]
	TIME [epoch: 9.09 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4283298520415252		[learning rate: 0.0013013]
	Learning Rate: 0.00130127
	LOSS [training: 0.4283298520415252 | validation: 0.6676195734234454]
	TIME [epoch: 9.07 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46693613239814535		[learning rate: 0.0012966]
	Learning Rate: 0.00129655
	LOSS [training: 0.46693613239814535 | validation: 0.5161156850412338]
	TIME [epoch: 9.08 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4362807610723739		[learning rate: 0.0012918]
	Learning Rate: 0.00129185
	LOSS [training: 0.4362807610723739 | validation: 0.5797797161380376]
	TIME [epoch: 9.09 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46400749734824587		[learning rate: 0.0012872]
	Learning Rate: 0.00128716
	LOSS [training: 0.46400749734824587 | validation: 0.5626439243515076]
	TIME [epoch: 9.1 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44870281374196264		[learning rate: 0.0012825]
	Learning Rate: 0.00128249
	LOSS [training: 0.44870281374196264 | validation: 0.6855223260700428]
	TIME [epoch: 9.08 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42023704539681345		[learning rate: 0.0012778]
	Learning Rate: 0.00127783
	LOSS [training: 0.42023704539681345 | validation: 0.5154032495487344]
	TIME [epoch: 9.06 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4525483124172047		[learning rate: 0.0012732]
	Learning Rate: 0.00127319
	LOSS [training: 0.4525483124172047 | validation: 0.5506233176745977]
	TIME [epoch: 9.07 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44462276908703213		[learning rate: 0.0012686]
	Learning Rate: 0.00126857
	LOSS [training: 0.44462276908703213 | validation: 0.7549440174854944]
	TIME [epoch: 9.1 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4826541788060589		[learning rate: 0.001264]
	Learning Rate: 0.00126397
	LOSS [training: 0.4826541788060589 | validation: 0.5395145226191829]
	TIME [epoch: 9.08 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43245780723685645		[learning rate: 0.0012594]
	Learning Rate: 0.00125938
	LOSS [training: 0.43245780723685645 | validation: 0.5421258437823131]
	TIME [epoch: 9.08 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.445663980818768		[learning rate: 0.0012548]
	Learning Rate: 0.00125481
	LOSS [training: 0.445663980818768 | validation: 0.4999449073772496]
	TIME [epoch: 9.08 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6695782353558692		[learning rate: 0.0012503]
	Learning Rate: 0.00125026
	LOSS [training: 0.6695782353558692 | validation: 0.6227090963817781]
	TIME [epoch: 9.08 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4561352412280013		[learning rate: 0.0012457]
	Learning Rate: 0.00124572
	LOSS [training: 0.4561352412280013 | validation: 0.4956775535110284]
	TIME [epoch: 9.11 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4186753993643345		[learning rate: 0.0012412]
	Learning Rate: 0.0012412
	LOSS [training: 0.4186753993643345 | validation: 0.5179080406574151]
	TIME [epoch: 9.08 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.407481868504764		[learning rate: 0.0012367]
	Learning Rate: 0.0012367
	LOSS [training: 0.407481868504764 | validation: 0.7692207111315962]
	TIME [epoch: 9.08 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43164528878042585		[learning rate: 0.0012322]
	Learning Rate: 0.00123221
	LOSS [training: 0.43164528878042585 | validation: 0.5031310436596754]
	TIME [epoch: 9.07 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.448752724439563		[learning rate: 0.0012277]
	Learning Rate: 0.00122774
	LOSS [training: 0.448752724439563 | validation: 0.46491422044274555]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.987104337396941		[learning rate: 0.0012233]
	Learning Rate: 0.00122328
	LOSS [training: 0.987104337396941 | validation: 1.3994243463620801]
	TIME [epoch: 9.08 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5347530056318586		[learning rate: 0.0012188]
	Learning Rate: 0.00121884
	LOSS [training: 0.5347530056318586 | validation: 0.5428882379509297]
	TIME [epoch: 9.07 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43415178541164173		[learning rate: 0.0012144]
	Learning Rate: 0.00121442
	LOSS [training: 0.43415178541164173 | validation: 0.6050185041341956]
	TIME [epoch: 9.07 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4606547633802034		[learning rate: 0.00121]
	Learning Rate: 0.00121001
	LOSS [training: 0.4606547633802034 | validation: 0.5557300017145412]
	TIME [epoch: 9.07 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44503797224864783		[learning rate: 0.0012056]
	Learning Rate: 0.00120562
	LOSS [training: 0.44503797224864783 | validation: 0.61534232094056]
	TIME [epoch: 9.09 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45985667610226955		[learning rate: 0.0012012]
	Learning Rate: 0.00120125
	LOSS [training: 0.45985667610226955 | validation: 0.5439276367714088]
	TIME [epoch: 9.08 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44093853382235376		[learning rate: 0.0011969]
	Learning Rate: 0.00119689
	LOSS [training: 0.44093853382235376 | validation: 0.5115079658485495]
	TIME [epoch: 9.06 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48116709322044837		[learning rate: 0.0011925]
	Learning Rate: 0.00119254
	LOSS [training: 0.48116709322044837 | validation: 0.5115063909940383]
	TIME [epoch: 9.08 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4494594710475604		[learning rate: 0.0011882]
	Learning Rate: 0.00118821
	LOSS [training: 0.4494594710475604 | validation: 0.5741215027374194]
	TIME [epoch: 9.07 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4276929425954662		[learning rate: 0.0011839]
	Learning Rate: 0.0011839
	LOSS [training: 0.4276929425954662 | validation: 0.46231962355900214]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_687.pth
	Model improved!!!
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41796566083040476		[learning rate: 0.0011796]
	Learning Rate: 0.00117961
	LOSS [training: 0.41796566083040476 | validation: 0.5369752763102608]
	TIME [epoch: 9.09 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40673065105326706		[learning rate: 0.0011753]
	Learning Rate: 0.00117532
	LOSS [training: 0.40673065105326706 | validation: 0.6559165435048961]
	TIME [epoch: 9.06 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4560159181481997		[learning rate: 0.0011711]
	Learning Rate: 0.00117106
	LOSS [training: 0.4560159181481997 | validation: 0.5361283010154523]
	TIME [epoch: 9.07 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3994928371311311		[learning rate: 0.0011668]
	Learning Rate: 0.00116681
	LOSS [training: 0.3994928371311311 | validation: 0.4648485034636431]
	TIME [epoch: 9.06 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4206942237773054		[learning rate: 0.0011626]
	Learning Rate: 0.00116258
	LOSS [training: 0.4206942237773054 | validation: 0.6304482033696789]
	TIME [epoch: 9.09 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4336224306331527		[learning rate: 0.0011584]
	Learning Rate: 0.00115836
	LOSS [training: 0.4336224306331527 | validation: 0.5858519472775376]
	TIME [epoch: 9.07 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41446023235991153		[learning rate: 0.0011542]
	Learning Rate: 0.00115415
	LOSS [training: 0.41446023235991153 | validation: 0.5111182411444675]
	TIME [epoch: 9.07 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41166468923523747		[learning rate: 0.00115]
	Learning Rate: 0.00114996
	LOSS [training: 0.41166468923523747 | validation: 0.5217777359405372]
	TIME [epoch: 9.07 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40608768447448285		[learning rate: 0.0011458]
	Learning Rate: 0.00114579
	LOSS [training: 0.40608768447448285 | validation: 0.8103972015310729]
	TIME [epoch: 9.07 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.424495409549544		[learning rate: 0.0011416]
	Learning Rate: 0.00114163
	LOSS [training: 0.424495409549544 | validation: 0.5594794967307555]
	TIME [epoch: 9.08 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43753219419247824		[learning rate: 0.0011375]
	Learning Rate: 0.00113749
	LOSS [training: 0.43753219419247824 | validation: 0.637626086308945]
	TIME [epoch: 9.08 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4341526373212138		[learning rate: 0.0011334]
	Learning Rate: 0.00113336
	LOSS [training: 0.4341526373212138 | validation: 0.5497234582956927]
	TIME [epoch: 9.07 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4041844000915167		[learning rate: 0.0011292]
	Learning Rate: 0.00112925
	LOSS [training: 0.4041844000915167 | validation: 0.5883433111901141]
	TIME [epoch: 9.08 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48156262433577374		[learning rate: 0.0011252]
	Learning Rate: 0.00112515
	LOSS [training: 0.48156262433577374 | validation: 0.4698578234136572]
	TIME [epoch: 9.08 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4520184011165423		[learning rate: 0.0011211]
	Learning Rate: 0.00112107
	LOSS [training: 0.4520184011165423 | validation: 0.547104631409666]
	TIME [epoch: 9.09 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4001915613659837		[learning rate: 0.001117]
	Learning Rate: 0.001117
	LOSS [training: 0.4001915613659837 | validation: 0.8715935235249134]
	TIME [epoch: 9.07 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4252126670694879		[learning rate: 0.0011129]
	Learning Rate: 0.00111295
	LOSS [training: 0.4252126670694879 | validation: 0.48877981988692376]
	TIME [epoch: 9.06 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4479254444354309		[learning rate: 0.0011089]
	Learning Rate: 0.00110891
	LOSS [training: 0.4479254444354309 | validation: 0.5944286511964911]
	TIME [epoch: 9.06 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48576859947182716		[learning rate: 0.0011049]
	Learning Rate: 0.00110488
	LOSS [training: 0.48576859947182716 | validation: 0.4830384175069048]
	TIME [epoch: 9.09 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38505080618088183		[learning rate: 0.0011009]
	Learning Rate: 0.00110087
	LOSS [training: 0.38505080618088183 | validation: 0.46019412877830035]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3977737689931506		[learning rate: 0.0010969]
	Learning Rate: 0.00109688
	LOSS [training: 0.3977737689931506 | validation: 0.49559072788075387]
	TIME [epoch: 9.08 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37912077123297006		[learning rate: 0.0010929]
	Learning Rate: 0.0010929
	LOSS [training: 0.37912077123297006 | validation: 0.5275371149012777]
	TIME [epoch: 9.08 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4156431861763318		[learning rate: 0.0010889]
	Learning Rate: 0.00108893
	LOSS [training: 0.4156431861763318 | validation: 0.5282527366596311]
	TIME [epoch: 9.08 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4154872654262422		[learning rate: 0.001085]
	Learning Rate: 0.00108498
	LOSS [training: 0.4154872654262422 | validation: 0.576037298662594]
	TIME [epoch: 9.09 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4011904311734293		[learning rate: 0.001081]
	Learning Rate: 0.00108104
	LOSS [training: 0.4011904311734293 | validation: 0.45047500964112197]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_712.pth
	Model improved!!!
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4124640574801731		[learning rate: 0.0010771]
	Learning Rate: 0.00107712
	LOSS [training: 0.4124640574801731 | validation: 0.5257466029578735]
	TIME [epoch: 9.07 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.400503374520898		[learning rate: 0.0010732]
	Learning Rate: 0.00107321
	LOSS [training: 0.400503374520898 | validation: 0.47164393839194474]
	TIME [epoch: 9.35 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39878542828135577		[learning rate: 0.0010693]
	Learning Rate: 0.00106931
	LOSS [training: 0.39878542828135577 | validation: 0.5841609633236212]
	TIME [epoch: 9.09 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42881338056946694		[learning rate: 0.0010654]
	Learning Rate: 0.00106543
	LOSS [training: 0.42881338056946694 | validation: 0.543637254004208]
	TIME [epoch: 9.1 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40255318539152196		[learning rate: 0.0010616]
	Learning Rate: 0.00106157
	LOSS [training: 0.40255318539152196 | validation: 0.565749915626683]
	TIME [epoch: 9.07 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5935673647764147		[learning rate: 0.0010577]
	Learning Rate: 0.00105771
	LOSS [training: 0.5935673647764147 | validation: 0.7032710510148489]
	TIME [epoch: 9.08 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46528299874667756		[learning rate: 0.0010539]
	Learning Rate: 0.00105388
	LOSS [training: 0.46528299874667756 | validation: 0.6538077540832049]
	TIME [epoch: 9.08 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4268122844982421		[learning rate: 0.0010501]
	Learning Rate: 0.00105005
	LOSS [training: 0.4268122844982421 | validation: 0.593124241341105]
	TIME [epoch: 9.08 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42643896437310513		[learning rate: 0.0010462]
	Learning Rate: 0.00104624
	LOSS [training: 0.42643896437310513 | validation: 0.7345881846618878]
	TIME [epoch: 9.1 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4294366324687243		[learning rate: 0.0010424]
	Learning Rate: 0.00104244
	LOSS [training: 0.4294366324687243 | validation: 0.5966593510424767]
	TIME [epoch: 9.08 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41107454550459155		[learning rate: 0.0010387]
	Learning Rate: 0.00103866
	LOSS [training: 0.41107454550459155 | validation: 0.45591509788537365]
	TIME [epoch: 9.08 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44928853139874664		[learning rate: 0.0010349]
	Learning Rate: 0.00103489
	LOSS [training: 0.44928853139874664 | validation: 0.5497282821045999]
	TIME [epoch: 9.08 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42394105661984743		[learning rate: 0.0010311]
	Learning Rate: 0.00103114
	LOSS [training: 0.42394105661984743 | validation: 0.467751997446862]
	TIME [epoch: 9.1 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.436906267128281		[learning rate: 0.0010274]
	Learning Rate: 0.00102739
	LOSS [training: 0.436906267128281 | validation: 0.5075966035258015]
	TIME [epoch: 9.09 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41276163590493686		[learning rate: 0.0010237]
	Learning Rate: 0.00102367
	LOSS [training: 0.41276163590493686 | validation: 0.46538621955624515]
	TIME [epoch: 9.08 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41917536948914763		[learning rate: 0.00102]
	Learning Rate: 0.00101995
	LOSS [training: 0.41917536948914763 | validation: 0.5407019162876185]
	TIME [epoch: 9.09 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43273330006803007		[learning rate: 0.0010162]
	Learning Rate: 0.00101625
	LOSS [training: 0.43273330006803007 | validation: 0.4509764810734114]
	TIME [epoch: 9.08 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39200309010550005		[learning rate: 0.0010126]
	Learning Rate: 0.00101256
	LOSS [training: 0.39200309010550005 | validation: 0.46806580828959876]
	TIME [epoch: 9.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42199296553087573		[learning rate: 0.0010089]
	Learning Rate: 0.00100889
	LOSS [training: 0.42199296553087573 | validation: 0.46376341100447105]
	TIME [epoch: 9.08 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40796614819723553		[learning rate: 0.0010052]
	Learning Rate: 0.00100522
	LOSS [training: 0.40796614819723553 | validation: 0.6425134319058459]
	TIME [epoch: 9.08 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4464095878195168		[learning rate: 0.0010016]
	Learning Rate: 0.00100158
	LOSS [training: 0.4464095878195168 | validation: 0.501486344700425]
	TIME [epoch: 9.08 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4337547206770346		[learning rate: 0.00099794]
	Learning Rate: 0.000997942
	LOSS [training: 0.4337547206770346 | validation: 0.7013053344741823]
	TIME [epoch: 9.09 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4457612268893925		[learning rate: 0.00099432]
	Learning Rate: 0.00099432
	LOSS [training: 0.4457612268893925 | validation: 0.5078887864397925]
	TIME [epoch: 9.08 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3995773479479513		[learning rate: 0.00099071]
	Learning Rate: 0.000990712
	LOSS [training: 0.3995773479479513 | validation: 0.734770498388036]
	TIME [epoch: 9.08 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4179995426361037		[learning rate: 0.00098712]
	Learning Rate: 0.000987116
	LOSS [training: 0.4179995426361037 | validation: 0.5767413487406695]
	TIME [epoch: 9.08 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4200721231184019		[learning rate: 0.00098353]
	Learning Rate: 0.000983534
	LOSS [training: 0.4200721231184019 | validation: 0.491237702128211]
	TIME [epoch: 9.09 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40683816076227314		[learning rate: 0.00097996]
	Learning Rate: 0.000979965
	LOSS [training: 0.40683816076227314 | validation: 0.47069308189038495]
	TIME [epoch: 9.11 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38517741459531807		[learning rate: 0.00097641]
	Learning Rate: 0.000976409
	LOSS [training: 0.38517741459531807 | validation: 0.5286240118943113]
	TIME [epoch: 9.09 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4210573741659746		[learning rate: 0.00097287]
	Learning Rate: 0.000972865
	LOSS [training: 0.4210573741659746 | validation: 0.4768516315898572]
	TIME [epoch: 9.09 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4118052180985742		[learning rate: 0.00096933]
	Learning Rate: 0.000969335
	LOSS [training: 0.4118052180985742 | validation: 0.47850959425100253]
	TIME [epoch: 9.08 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4036667414220142		[learning rate: 0.00096582]
	Learning Rate: 0.000965817
	LOSS [training: 0.4036667414220142 | validation: 0.586818712747038]
	TIME [epoch: 9.09 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4842003725529386		[learning rate: 0.00096231]
	Learning Rate: 0.000962312
	LOSS [training: 0.4842003725529386 | validation: 0.5539259782947804]
	TIME [epoch: 9.09 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38504373348984033		[learning rate: 0.00095882]
	Learning Rate: 0.00095882
	LOSS [training: 0.38504373348984033 | validation: 0.42711275563246004]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_745.pth
	Model improved!!!
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4079503883266947		[learning rate: 0.00095534]
	Learning Rate: 0.00095534
	LOSS [training: 0.4079503883266947 | validation: 0.49064802551728426]
	TIME [epoch: 9.09 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3897173428774866		[learning rate: 0.00095187]
	Learning Rate: 0.000951873
	LOSS [training: 0.3897173428774866 | validation: 0.6795342043133863]
	TIME [epoch: 9.09 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4305431859456609		[learning rate: 0.00094842]
	Learning Rate: 0.000948419
	LOSS [training: 0.4305431859456609 | validation: 0.5077380132632869]
	TIME [epoch: 9.1 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.421436260839815		[learning rate: 0.00094498]
	Learning Rate: 0.000944977
	LOSS [training: 0.421436260839815 | validation: 0.5620672595525897]
	TIME [epoch: 9.09 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4438974998887411		[learning rate: 0.00094155]
	Learning Rate: 0.000941547
	LOSS [training: 0.4438974998887411 | validation: 0.5061366240535301]
	TIME [epoch: 9.09 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38860495020648206		[learning rate: 0.00093813]
	Learning Rate: 0.00093813
	LOSS [training: 0.38860495020648206 | validation: 0.5673714615534966]
	TIME [epoch: 9.09 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40363468671134245		[learning rate: 0.00093473]
	Learning Rate: 0.000934726
	LOSS [training: 0.40363468671134245 | validation: 0.7209183322243924]
	TIME [epoch: 9.1 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42555721238436933		[learning rate: 0.00093133]
	Learning Rate: 0.000931334
	LOSS [training: 0.42555721238436933 | validation: 0.5734644374470173]
	TIME [epoch: 9.11 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4076546248198455		[learning rate: 0.00092795]
	Learning Rate: 0.000927954
	LOSS [training: 0.4076546248198455 | validation: 0.5646651136330482]
	TIME [epoch: 9.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4061742193902321		[learning rate: 0.00092459]
	Learning Rate: 0.000924586
	LOSS [training: 0.4061742193902321 | validation: 0.4567445756282714]
	TIME [epoch: 9.09 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39809612761313456		[learning rate: 0.00092123]
	Learning Rate: 0.000921231
	LOSS [training: 0.39809612761313456 | validation: 0.4930949809614157]
	TIME [epoch: 9.08 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38091950090593374		[learning rate: 0.00091789]
	Learning Rate: 0.000917888
	LOSS [training: 0.38091950090593374 | validation: 0.4474095859132422]
	TIME [epoch: 9.09 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42576556933620147		[learning rate: 0.00091456]
	Learning Rate: 0.000914556
	LOSS [training: 0.42576556933620147 | validation: 0.560778808198416]
	TIME [epoch: 9.11 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39386396983356886		[learning rate: 0.00091124]
	Learning Rate: 0.000911237
	LOSS [training: 0.39386396983356886 | validation: 0.4546795396318052]
	TIME [epoch: 9.09 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4033105672849916		[learning rate: 0.00090793]
	Learning Rate: 0.000907931
	LOSS [training: 0.4033105672849916 | validation: 0.6417521043949796]
	TIME [epoch: 9.09 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4372981383822001		[learning rate: 0.00090464]
	Learning Rate: 0.000904636
	LOSS [training: 0.4372981383822001 | validation: 0.4857530648554714]
	TIME [epoch: 9.08 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3976640412901057		[learning rate: 0.00090135]
	Learning Rate: 0.000901353
	LOSS [training: 0.3976640412901057 | validation: 0.4956360110890077]
	TIME [epoch: 9.11 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41892952025329516		[learning rate: 0.00089808]
	Learning Rate: 0.000898082
	LOSS [training: 0.41892952025329516 | validation: 0.49385179799485956]
	TIME [epoch: 9.09 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.433961179204794		[learning rate: 0.00089482]
	Learning Rate: 0.000894822
	LOSS [training: 0.433961179204794 | validation: 0.5243189146218338]
	TIME [epoch: 9.09 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4397757878454258		[learning rate: 0.00089157]
	Learning Rate: 0.000891575
	LOSS [training: 0.4397757878454258 | validation: 0.49580849916226954]
	TIME [epoch: 9.09 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3748227383303498		[learning rate: 0.00088834]
	Learning Rate: 0.000888339
	LOSS [training: 0.3748227383303498 | validation: 0.4469638884130734]
	TIME [epoch: 9.1 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3978073679163622		[learning rate: 0.00088512]
	Learning Rate: 0.000885116
	LOSS [training: 0.3978073679163622 | validation: 0.46257064114599256]
	TIME [epoch: 9.12 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4105539633012881		[learning rate: 0.0008819]
	Learning Rate: 0.000881903
	LOSS [training: 0.4105539633012881 | validation: 0.48121734319129017]
	TIME [epoch: 9.08 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3896077679572296		[learning rate: 0.0008787]
	Learning Rate: 0.000878703
	LOSS [training: 0.3896077679572296 | validation: 0.44143384342139846]
	TIME [epoch: 9.08 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.409428905189744		[learning rate: 0.00087551]
	Learning Rate: 0.000875514
	LOSS [training: 0.409428905189744 | validation: 0.5968076163480028]
	TIME [epoch: 9.09 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.435327031560964		[learning rate: 0.00087234]
	Learning Rate: 0.000872337
	LOSS [training: 0.435327031560964 | validation: 0.5361761910926551]
	TIME [epoch: 9.11 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3700411809601089		[learning rate: 0.00086917]
	Learning Rate: 0.000869171
	LOSS [training: 0.3700411809601089 | validation: 0.5159152415186318]
	TIME [epoch: 9.09 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46735750744373405		[learning rate: 0.00086602]
	Learning Rate: 0.000866017
	LOSS [training: 0.46735750744373405 | validation: 0.4853245567729645]
	TIME [epoch: 9.09 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38984233307819616		[learning rate: 0.00086287]
	Learning Rate: 0.000862874
	LOSS [training: 0.38984233307819616 | validation: 0.5114336797362434]
	TIME [epoch: 9.09 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39228970555263126		[learning rate: 0.00085974]
	Learning Rate: 0.000859743
	LOSS [training: 0.39228970555263126 | validation: 0.4785083070419117]
	TIME [epoch: 9.09 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3556539380520564		[learning rate: 0.00085662]
	Learning Rate: 0.000856623
	LOSS [training: 0.3556539380520564 | validation: 0.696121724671091]
	TIME [epoch: 9.1 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41300908884399484		[learning rate: 0.00085351]
	Learning Rate: 0.000853514
	LOSS [training: 0.41300908884399484 | validation: 0.4692218564677745]
	TIME [epoch: 9.09 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39135372338144464		[learning rate: 0.00085042]
	Learning Rate: 0.000850416
	LOSS [training: 0.39135372338144464 | validation: 0.5303975145798007]
	TIME [epoch: 9.09 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38947804949912157		[learning rate: 0.00084733]
	Learning Rate: 0.00084733
	LOSS [training: 0.38947804949912157 | validation: 0.48955894986299187]
	TIME [epoch: 9.09 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39560729641175507		[learning rate: 0.00084426]
	Learning Rate: 0.000844255
	LOSS [training: 0.39560729641175507 | validation: 0.5124519916151631]
	TIME [epoch: 9.11 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37878706662942563		[learning rate: 0.00084119]
	Learning Rate: 0.000841191
	LOSS [training: 0.37878706662942563 | validation: 0.47301549021409395]
	TIME [epoch: 9.09 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41812378855733356		[learning rate: 0.00083814]
	Learning Rate: 0.000838139
	LOSS [training: 0.41812378855733356 | validation: 0.4453036240697024]
	TIME [epoch: 9.09 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3942709320130054		[learning rate: 0.0008351]
	Learning Rate: 0.000835097
	LOSS [training: 0.3942709320130054 | validation: 0.47506898272847137]
	TIME [epoch: 9.09 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4003358348819274		[learning rate: 0.00083207]
	Learning Rate: 0.000832066
	LOSS [training: 0.4003358348819274 | validation: 0.46782946931770836]
	TIME [epoch: 9.08 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36854749992449964		[learning rate: 0.00082905]
	Learning Rate: 0.000829046
	LOSS [training: 0.36854749992449964 | validation: 0.5424485027921512]
	TIME [epoch: 9.11 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3818154890895095		[learning rate: 0.00082604]
	Learning Rate: 0.000826038
	LOSS [training: 0.3818154890895095 | validation: 0.5387560904013251]
	TIME [epoch: 9.09 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3900868241609576		[learning rate: 0.00082304]
	Learning Rate: 0.00082304
	LOSS [training: 0.3900868241609576 | validation: 0.49815651217833246]
	TIME [epoch: 9.09 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37172271633345944		[learning rate: 0.00082005]
	Learning Rate: 0.000820053
	LOSS [training: 0.37172271633345944 | validation: 0.5869169502579704]
	TIME [epoch: 9.09 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38610097909662444		[learning rate: 0.00081708]
	Learning Rate: 0.000817077
	LOSS [training: 0.38610097909662444 | validation: 0.4808320661076973]
	TIME [epoch: 9.09 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39056320573605846		[learning rate: 0.00081411]
	Learning Rate: 0.000814112
	LOSS [training: 0.39056320573605846 | validation: 0.5887469133418831]
	TIME [epoch: 9.1 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4224490533635924		[learning rate: 0.00081116]
	Learning Rate: 0.000811158
	LOSS [training: 0.4224490533635924 | validation: 0.47084134549942885]
	TIME [epoch: 9.09 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3870434153890542		[learning rate: 0.00080821]
	Learning Rate: 0.000808214
	LOSS [training: 0.3870434153890542 | validation: 0.5027294429561637]
	TIME [epoch: 9.09 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3881229978326408		[learning rate: 0.00080528]
	Learning Rate: 0.000805281
	LOSS [training: 0.3881229978326408 | validation: 0.585471939032093]
	TIME [epoch: 9.09 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38912594496221653		[learning rate: 0.00080236]
	Learning Rate: 0.000802358
	LOSS [training: 0.38912594496221653 | validation: 0.5877239154554477]
	TIME [epoch: 9.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4089206998020293		[learning rate: 0.00079945]
	Learning Rate: 0.000799447
	LOSS [training: 0.4089206998020293 | validation: 0.4412143960614293]
	TIME [epoch: 9.09 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39039436362576113		[learning rate: 0.00079655]
	Learning Rate: 0.000796545
	LOSS [training: 0.39039436362576113 | validation: 0.517807579800126]
	TIME [epoch: 9.08 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38530737896821765		[learning rate: 0.00079365]
	Learning Rate: 0.000793655
	LOSS [training: 0.38530737896821765 | validation: 0.4758735388551802]
	TIME [epoch: 9.09 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4226354125721792		[learning rate: 0.00079077]
	Learning Rate: 0.000790775
	LOSS [training: 0.4226354125721792 | validation: 0.48310361798268475]
	TIME [epoch: 9.09 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4025310616919263		[learning rate: 0.0007879]
	Learning Rate: 0.000787905
	LOSS [training: 0.4025310616919263 | validation: 0.5582948618747716]
	TIME [epoch: 9.11 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4021179402635967		[learning rate: 0.00078505]
	Learning Rate: 0.000785045
	LOSS [training: 0.4021179402635967 | validation: 0.5361215834804824]
	TIME [epoch: 9.09 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37964394093794696		[learning rate: 0.0007822]
	Learning Rate: 0.000782196
	LOSS [training: 0.37964394093794696 | validation: 0.5609430883812195]
	TIME [epoch: 9.09 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3915053536091323		[learning rate: 0.00077936]
	Learning Rate: 0.000779358
	LOSS [training: 0.3915053536091323 | validation: 0.5443705187320877]
	TIME [epoch: 9.09 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4059863935705404		[learning rate: 0.00077653]
	Learning Rate: 0.000776529
	LOSS [training: 0.4059863935705404 | validation: 0.4449153008125383]
	TIME [epoch: 9.1 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40355450288746963		[learning rate: 0.00077371]
	Learning Rate: 0.000773711
	LOSS [training: 0.40355450288746963 | validation: 0.5057492946730002]
	TIME [epoch: 9.09 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36573415572605417		[learning rate: 0.0007709]
	Learning Rate: 0.000770903
	LOSS [training: 0.36573415572605417 | validation: 0.5364381985005959]
	TIME [epoch: 9.1 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.379017657520912		[learning rate: 0.00076811]
	Learning Rate: 0.000768106
	LOSS [training: 0.379017657520912 | validation: 0.4721256474950013]
	TIME [epoch: 9.1 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46303077838575646		[learning rate: 0.00076532]
	Learning Rate: 0.000765318
	LOSS [training: 0.46303077838575646 | validation: 0.4785704232001986]
	TIME [epoch: 9.09 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37734072354111203		[learning rate: 0.00076254]
	Learning Rate: 0.000762541
	LOSS [training: 0.37734072354111203 | validation: 0.4403992266347815]
	TIME [epoch: 9.11 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37938443920678644		[learning rate: 0.00075977]
	Learning Rate: 0.000759774
	LOSS [training: 0.37938443920678644 | validation: 0.519855940794052]
	TIME [epoch: 9.08 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3817809975775957		[learning rate: 0.00075702]
	Learning Rate: 0.000757016
	LOSS [training: 0.3817809975775957 | validation: 0.4633551949904348]
	TIME [epoch: 9.09 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38516402978698644		[learning rate: 0.00075427]
	Learning Rate: 0.000754269
	LOSS [training: 0.38516402978698644 | validation: 0.4580609087811783]
	TIME [epoch: 9.09 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38132341431190164		[learning rate: 0.00075153]
	Learning Rate: 0.000751532
	LOSS [training: 0.38132341431190164 | validation: 0.46838619977760854]
	TIME [epoch: 9.09 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3853904136932178		[learning rate: 0.0007488]
	Learning Rate: 0.000748804
	LOSS [training: 0.3853904136932178 | validation: 0.5242999684284912]
	TIME [epoch: 9.11 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4218702816448162		[learning rate: 0.00074609]
	Learning Rate: 0.000746087
	LOSS [training: 0.4218702816448162 | validation: 0.5517353522726051]
	TIME [epoch: 9.09 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4025250884938439		[learning rate: 0.00074338]
	Learning Rate: 0.000743379
	LOSS [training: 0.4025250884938439 | validation: 0.5324419058446304]
	TIME [epoch: 9.08 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4172839963114495		[learning rate: 0.00074068]
	Learning Rate: 0.000740682
	LOSS [training: 0.4172839963114495 | validation: 0.5409571201769969]
	TIME [epoch: 9.09 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3672813180956232		[learning rate: 0.00073799]
	Learning Rate: 0.000737994
	LOSS [training: 0.3672813180956232 | validation: 0.5249082860168663]
	TIME [epoch: 9.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40377663003247155		[learning rate: 0.00073532]
	Learning Rate: 0.000735315
	LOSS [training: 0.40377663003247155 | validation: 0.5579630700749806]
	TIME [epoch: 9.09 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4153933590609692		[learning rate: 0.00073265]
	Learning Rate: 0.000732647
	LOSS [training: 0.4153933590609692 | validation: 0.44813887974245825]
	TIME [epoch: 9.09 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39018898147608183		[learning rate: 0.00072999]
	Learning Rate: 0.000729988
	LOSS [training: 0.39018898147608183 | validation: 0.549443332932255]
	TIME [epoch: 9.09 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40223770594567887		[learning rate: 0.00072734]
	Learning Rate: 0.000727339
	LOSS [training: 0.40223770594567887 | validation: 0.4494614866122673]
	TIME [epoch: 9.09 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3683003625851508		[learning rate: 0.0007247]
	Learning Rate: 0.000724699
	LOSS [training: 0.3683003625851508 | validation: 0.4721730619047272]
	TIME [epoch: 9.11 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38414901804286206		[learning rate: 0.00072207]
	Learning Rate: 0.000722069
	LOSS [training: 0.38414901804286206 | validation: 0.5083496591691574]
	TIME [epoch: 9.09 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3758776734485947		[learning rate: 0.00071945]
	Learning Rate: 0.000719449
	LOSS [training: 0.3758776734485947 | validation: 0.5552153215527289]
	TIME [epoch: 9.08 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36809764560760616		[learning rate: 0.00071684]
	Learning Rate: 0.000716838
	LOSS [training: 0.36809764560760616 | validation: 0.4647199522533936]
	TIME [epoch: 9.09 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3857109071106189		[learning rate: 0.00071424]
	Learning Rate: 0.000714237
	LOSS [training: 0.3857109071106189 | validation: 0.4488226883449848]
	TIME [epoch: 9.1 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39336088538425484		[learning rate: 0.00071164]
	Learning Rate: 0.000711645
	LOSS [training: 0.39336088538425484 | validation: 0.5353193876036239]
	TIME [epoch: 9.1 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3658392151693804		[learning rate: 0.00070906]
	Learning Rate: 0.000709062
	LOSS [training: 0.3658392151693804 | validation: 0.5315785149480885]
	TIME [epoch: 9.09 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41624968075169255		[learning rate: 0.00070649]
	Learning Rate: 0.000706489
	LOSS [training: 0.41624968075169255 | validation: 0.5392381150500012]
	TIME [epoch: 9.09 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37042346287881966		[learning rate: 0.00070392]
	Learning Rate: 0.000703925
	LOSS [training: 0.37042346287881966 | validation: 0.4591800402272407]
	TIME [epoch: 9.1 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3897125751192514		[learning rate: 0.00070137]
	Learning Rate: 0.00070137
	LOSS [training: 0.3897125751192514 | validation: 0.4528701740965419]
	TIME [epoch: 9.12 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39457974953667385		[learning rate: 0.00069883]
	Learning Rate: 0.000698825
	LOSS [training: 0.39457974953667385 | validation: 0.5480956379640823]
	TIME [epoch: 9.1 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39734116195399694		[learning rate: 0.00069629]
	Learning Rate: 0.000696289
	LOSS [training: 0.39734116195399694 | validation: 0.5535903950105241]
	TIME [epoch: 9.1 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37884147337670815		[learning rate: 0.00069376]
	Learning Rate: 0.000693762
	LOSS [training: 0.37884147337670815 | validation: 0.5104801507818498]
	TIME [epoch: 9.09 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45889583303468734		[learning rate: 0.00069124]
	Learning Rate: 0.000691244
	LOSS [training: 0.45889583303468734 | validation: 0.5886605352942362]
	TIME [epoch: 9.09 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38786394025221804		[learning rate: 0.00068874]
	Learning Rate: 0.000688736
	LOSS [training: 0.38786394025221804 | validation: 0.49797319638429627]
	TIME [epoch: 9.11 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35763457700642604		[learning rate: 0.00068624]
	Learning Rate: 0.000686236
	LOSS [training: 0.35763457700642604 | validation: 0.4811666822129356]
	TIME [epoch: 9.09 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38465360151611994		[learning rate: 0.00068375]
	Learning Rate: 0.000683746
	LOSS [training: 0.38465360151611994 | validation: 0.5069028974017677]
	TIME [epoch: 9.1 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42774572906187924		[learning rate: 0.00068126]
	Learning Rate: 0.000681265
	LOSS [training: 0.42774572906187924 | validation: 0.5487887613130467]
	TIME [epoch: 9.09 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37630566260070125		[learning rate: 0.00067879]
	Learning Rate: 0.000678792
	LOSS [training: 0.37630566260070125 | validation: 0.5196804385330791]
	TIME [epoch: 9.11 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3910497311370618		[learning rate: 0.00067633]
	Learning Rate: 0.000676329
	LOSS [training: 0.3910497311370618 | validation: 0.46391299835583044]
	TIME [epoch: 9.1 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3943118936681208		[learning rate: 0.00067387]
	Learning Rate: 0.000673874
	LOSS [training: 0.3943118936681208 | validation: 0.5790726967064623]
	TIME [epoch: 9.09 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4154681073108413		[learning rate: 0.00067143]
	Learning Rate: 0.000671429
	LOSS [training: 0.4154681073108413 | validation: 0.46716319176416]
	TIME [epoch: 9.09 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3611643651630321		[learning rate: 0.00066899]
	Learning Rate: 0.000668992
	LOSS [training: 0.3611643651630321 | validation: 0.5173859387985222]
	TIME [epoch: 9.1 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40050822418434057		[learning rate: 0.00066656]
	Learning Rate: 0.000666564
	LOSS [training: 0.40050822418434057 | validation: 0.4597506477869061]
	TIME [epoch: 9.12 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37442787368149677		[learning rate: 0.00066415]
	Learning Rate: 0.000664145
	LOSS [training: 0.37442787368149677 | validation: 0.9293296437646283]
	TIME [epoch: 9.1 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4568362443600099		[learning rate: 0.00066174]
	Learning Rate: 0.000661735
	LOSS [training: 0.4568362443600099 | validation: 0.5455174208506576]
	TIME [epoch: 9.09 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3847664907682312		[learning rate: 0.00065933]
	Learning Rate: 0.000659334
	LOSS [training: 0.3847664907682312 | validation: 0.5809896991646331]
	TIME [epoch: 9.09 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3752277869964557		[learning rate: 0.00065694]
	Learning Rate: 0.000656941
	LOSS [training: 0.3752277869964557 | validation: 0.45912688160327597]
	TIME [epoch: 9.11 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3785298277503401		[learning rate: 0.00065456]
	Learning Rate: 0.000654557
	LOSS [training: 0.3785298277503401 | validation: 0.5151210681192355]
	TIME [epoch: 9.09 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38517005048562347		[learning rate: 0.00065218]
	Learning Rate: 0.000652182
	LOSS [training: 0.38517005048562347 | validation: 0.48629240978070853]
	TIME [epoch: 9.09 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3728585808462467		[learning rate: 0.00064981]
	Learning Rate: 0.000649815
	LOSS [training: 0.3728585808462467 | validation: 0.5234226863295811]
	TIME [epoch: 9.09 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38289095831606745		[learning rate: 0.00064746]
	Learning Rate: 0.000647456
	LOSS [training: 0.38289095831606745 | validation: 0.47458982787473847]
	TIME [epoch: 9.09 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3862401151818432		[learning rate: 0.00064511]
	Learning Rate: 0.000645107
	LOSS [training: 0.3862401151818432 | validation: 0.4838811114035426]
	TIME [epoch: 9.11 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36216823895789557		[learning rate: 0.00064277]
	Learning Rate: 0.000642766
	LOSS [training: 0.36216823895789557 | validation: 0.5566265356059041]
	TIME [epoch: 9.09 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3847061088217976		[learning rate: 0.00064043]
	Learning Rate: 0.000640433
	LOSS [training: 0.3847061088217976 | validation: 0.5255322141087254]
	TIME [epoch: 9.09 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37146655544149726		[learning rate: 0.00063811]
	Learning Rate: 0.000638109
	LOSS [training: 0.37146655544149726 | validation: 0.4759450298584925]
	TIME [epoch: 9.1 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3790969633518889		[learning rate: 0.00063579]
	Learning Rate: 0.000635793
	LOSS [training: 0.3790969633518889 | validation: 0.4604670300315793]
	TIME [epoch: 9.11 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37284296161984054		[learning rate: 0.00063349]
	Learning Rate: 0.000633486
	LOSS [training: 0.37284296161984054 | validation: 0.4958404021134047]
	TIME [epoch: 9.11 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38286748608943494		[learning rate: 0.00063119]
	Learning Rate: 0.000631187
	LOSS [training: 0.38286748608943494 | validation: 0.5487934078644537]
	TIME [epoch: 9.09 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3850110125412421		[learning rate: 0.0006289]
	Learning Rate: 0.000628896
	LOSS [training: 0.3850110125412421 | validation: 0.46897508213798644]
	TIME [epoch: 9.09 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3730588464709945		[learning rate: 0.00062661]
	Learning Rate: 0.000626614
	LOSS [training: 0.3730588464709945 | validation: 0.5738918599024294]
	TIME [epoch: 9.09 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3811798993898652		[learning rate: 0.00062434]
	Learning Rate: 0.00062434
	LOSS [training: 0.3811798993898652 | validation: 0.4607342749975919]
	TIME [epoch: 9.11 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3858779909295874		[learning rate: 0.00062207]
	Learning Rate: 0.000622074
	LOSS [training: 0.3858779909295874 | validation: 0.46582816837343105]
	TIME [epoch: 9.1 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35537830026921596		[learning rate: 0.00061982]
	Learning Rate: 0.000619816
	LOSS [training: 0.35537830026921596 | validation: 0.4911070021203283]
	TIME [epoch: 9.1 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3796094530886345		[learning rate: 0.00061757]
	Learning Rate: 0.000617567
	LOSS [training: 0.3796094530886345 | validation: 0.5626133422090109]
	TIME [epoch: 9.09 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4053972497148314		[learning rate: 0.00061533]
	Learning Rate: 0.000615326
	LOSS [training: 0.4053972497148314 | validation: 0.5479477093028946]
	TIME [epoch: 9.09 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40461447132484246		[learning rate: 0.00061309]
	Learning Rate: 0.000613093
	LOSS [training: 0.40461447132484246 | validation: 0.5103509151674042]
	TIME [epoch: 9.11 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3681434169868426		[learning rate: 0.00061087]
	Learning Rate: 0.000610868
	LOSS [training: 0.3681434169868426 | validation: 0.4754374665317154]
	TIME [epoch: 9.09 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3809961739038891		[learning rate: 0.00060865]
	Learning Rate: 0.000608651
	LOSS [training: 0.3809961739038891 | validation: 0.44829531075738227]
	TIME [epoch: 9.1 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39014278248385464		[learning rate: 0.00060644]
	Learning Rate: 0.000606442
	LOSS [training: 0.39014278248385464 | validation: 0.48623909157298456]
	TIME [epoch: 9.1 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36358975420982764		[learning rate: 0.00060424]
	Learning Rate: 0.000604242
	LOSS [training: 0.36358975420982764 | validation: 0.5114605317983774]
	TIME [epoch: 9.13 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37195454051999033		[learning rate: 0.00060205]
	Learning Rate: 0.000602049
	LOSS [training: 0.37195454051999033 | validation: 0.5303481949557047]
	TIME [epoch: 9.09 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36588921992666146		[learning rate: 0.00059986]
	Learning Rate: 0.000599864
	LOSS [training: 0.36588921992666146 | validation: 0.47084044225224864]
	TIME [epoch: 9.09 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37936007503710456		[learning rate: 0.00059769]
	Learning Rate: 0.000597687
	LOSS [training: 0.37936007503710456 | validation: 0.4734516532061235]
	TIME [epoch: 9.09 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3666406642855683		[learning rate: 0.00059552]
	Learning Rate: 0.000595518
	LOSS [training: 0.3666406642855683 | validation: 0.48712251285345204]
	TIME [epoch: 9.09 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3539040783842589		[learning rate: 0.00059336]
	Learning Rate: 0.000593357
	LOSS [training: 0.3539040783842589 | validation: 0.5122597068925219]
	TIME [epoch: 9.11 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.371205993971268		[learning rate: 0.0005912]
	Learning Rate: 0.000591203
	LOSS [training: 0.371205993971268 | validation: 0.5209151467775464]
	TIME [epoch: 9.09 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39120606128651253		[learning rate: 0.00058906]
	Learning Rate: 0.000589058
	LOSS [training: 0.39120606128651253 | validation: 0.4731809548504402]
	TIME [epoch: 9.1 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3768677914760516		[learning rate: 0.00058692]
	Learning Rate: 0.00058692
	LOSS [training: 0.3768677914760516 | validation: 0.5718604154450485]
	TIME [epoch: 9.09 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40479678844531064		[learning rate: 0.00058479]
	Learning Rate: 0.00058479
	LOSS [training: 0.40479678844531064 | validation: 0.5521320556858353]
	TIME [epoch: 9.11 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3904566673044728		[learning rate: 0.00058267]
	Learning Rate: 0.000582668
	LOSS [training: 0.3904566673044728 | validation: 0.47341073882629875]
	TIME [epoch: 9.09 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.392250090590929		[learning rate: 0.00058055]
	Learning Rate: 0.000580553
	LOSS [training: 0.392250090590929 | validation: 0.5096394230311531]
	TIME [epoch: 9.09 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3594831037098725		[learning rate: 0.00057845]
	Learning Rate: 0.000578446
	LOSS [training: 0.3594831037098725 | validation: 0.4531666589049377]
	TIME [epoch: 9.1 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.363297547674108		[learning rate: 0.00057635]
	Learning Rate: 0.000576347
	LOSS [training: 0.363297547674108 | validation: 0.5045968020401423]
	TIME [epoch: 9.1 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39118388661744585		[learning rate: 0.00057426]
	Learning Rate: 0.000574256
	LOSS [training: 0.39118388661744585 | validation: 0.6242564355196182]
	TIME [epoch: 9.1 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5253965272388988		[learning rate: 0.00057217]
	Learning Rate: 0.000572172
	LOSS [training: 0.5253965272388988 | validation: 0.5078096642813869]
	TIME [epoch: 9.09 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35374431380758276		[learning rate: 0.0005701]
	Learning Rate: 0.000570095
	LOSS [training: 0.35374431380758276 | validation: 0.5292490191494641]
	TIME [epoch: 9.09 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36349849478715407		[learning rate: 0.00056803]
	Learning Rate: 0.000568026
	LOSS [training: 0.36349849478715407 | validation: 0.4761295379217866]
	TIME [epoch: 9.09 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37336334240387997		[learning rate: 0.00056596]
	Learning Rate: 0.000565965
	LOSS [training: 0.37336334240387997 | validation: 0.5574385533052064]
	TIME [epoch: 9.09 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36083642062028587		[learning rate: 0.00056391]
	Learning Rate: 0.000563911
	LOSS [training: 0.36083642062028587 | validation: 0.5313961106906503]
	TIME [epoch: 9.1 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3665267265465097		[learning rate: 0.00056186]
	Learning Rate: 0.000561864
	LOSS [training: 0.3665267265465097 | validation: 0.5062862640901741]
	TIME [epoch: 9.09 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35277752939130375		[learning rate: 0.00055983]
	Learning Rate: 0.000559825
	LOSS [training: 0.35277752939130375 | validation: 0.4640549796837631]
	TIME [epoch: 9.08 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40360270299808026		[learning rate: 0.00055779]
	Learning Rate: 0.000557794
	LOSS [training: 0.40360270299808026 | validation: 0.4764396340274634]
	TIME [epoch: 9.09 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39040940706134264		[learning rate: 0.00055577]
	Learning Rate: 0.00055577
	LOSS [training: 0.39040940706134264 | validation: 0.4622622854200962]
	TIME [epoch: 9.11 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.361171287682161		[learning rate: 0.00055375]
	Learning Rate: 0.000553753
	LOSS [training: 0.361171287682161 | validation: 0.47615435014931207]
	TIME [epoch: 9.08 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.372592870941094		[learning rate: 0.00055174]
	Learning Rate: 0.000551743
	LOSS [training: 0.372592870941094 | validation: 0.4916090105950238]
	TIME [epoch: 9.09 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3851987199575354		[learning rate: 0.00054974]
	Learning Rate: 0.000549741
	LOSS [training: 0.3851987199575354 | validation: 0.5099592738135603]
	TIME [epoch: 9.09 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36046197926756357		[learning rate: 0.00054775]
	Learning Rate: 0.000547746
	LOSS [training: 0.36046197926756357 | validation: 0.5155448509967129]
	TIME [epoch: 9.09 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3768442384625493		[learning rate: 0.00054576]
	Learning Rate: 0.000545758
	LOSS [training: 0.3768442384625493 | validation: 0.47712374810792973]
	TIME [epoch: 9.11 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.377016880244532		[learning rate: 0.00054378]
	Learning Rate: 0.000543777
	LOSS [training: 0.377016880244532 | validation: 0.47488905277656523]
	TIME [epoch: 9.08 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37777937152189367		[learning rate: 0.0005418]
	Learning Rate: 0.000541804
	LOSS [training: 0.37777937152189367 | validation: 0.5196289661477255]
	TIME [epoch: 9.09 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37783496309738906		[learning rate: 0.00053984]
	Learning Rate: 0.000539838
	LOSS [training: 0.37783496309738906 | validation: 0.5661420690594251]
	TIME [epoch: 9.08 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3657219667695924		[learning rate: 0.00053788]
	Learning Rate: 0.000537879
	LOSS [training: 0.3657219667695924 | validation: 0.5335674476172889]
	TIME [epoch: 9.11 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36829031787657285		[learning rate: 0.00053593]
	Learning Rate: 0.000535926
	LOSS [training: 0.36829031787657285 | validation: 0.4543106874818595]
	TIME [epoch: 9.09 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35616574607100476		[learning rate: 0.00053398]
	Learning Rate: 0.000533982
	LOSS [training: 0.35616574607100476 | validation: 0.48256463029565666]
	TIME [epoch: 9.08 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36763361457356786		[learning rate: 0.00053204]
	Learning Rate: 0.000532044
	LOSS [training: 0.36763361457356786 | validation: 0.47723243917591035]
	TIME [epoch: 9.08 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3684208659795588		[learning rate: 0.00053011]
	Learning Rate: 0.000530113
	LOSS [training: 0.3684208659795588 | validation: 0.45183565085570176]
	TIME [epoch: 9.08 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3524761475595102		[learning rate: 0.00052819]
	Learning Rate: 0.000528189
	LOSS [training: 0.3524761475595102 | validation: 0.47698293174752504]
	TIME [epoch: 9.1 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35993029605331023		[learning rate: 0.00052627]
	Learning Rate: 0.000526272
	LOSS [training: 0.35993029605331023 | validation: 0.5056542406660467]
	TIME [epoch: 9.1 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3722393210226463		[learning rate: 0.00052436]
	Learning Rate: 0.000524362
	LOSS [training: 0.3722393210226463 | validation: 0.5085191487045126]
	TIME [epoch: 9.08 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3644867329410886		[learning rate: 0.00052246]
	Learning Rate: 0.00052246
	LOSS [training: 0.3644867329410886 | validation: 0.4630223113450401]
	TIME [epoch: 9.08 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34990956281368724		[learning rate: 0.00052056]
	Learning Rate: 0.000520563
	LOSS [training: 0.34990956281368724 | validation: 0.5448162059807358]
	TIME [epoch: 9.1 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35762569739670913		[learning rate: 0.00051867]
	Learning Rate: 0.000518674
	LOSS [training: 0.35762569739670913 | validation: 0.4444235108528998]
	TIME [epoch: 9.08 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.383340709144205		[learning rate: 0.00051679]
	Learning Rate: 0.000516792
	LOSS [training: 0.383340709144205 | validation: 0.7278107477603036]
	TIME [epoch: 9.08 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4184375054075927		[learning rate: 0.00051492]
	Learning Rate: 0.000514917
	LOSS [training: 0.4184375054075927 | validation: 0.44445025544116357]
	TIME [epoch: 9.08 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3819812127438679		[learning rate: 0.00051305]
	Learning Rate: 0.000513048
	LOSS [training: 0.3819812127438679 | validation: 0.4826856140959488]
	TIME [epoch: 9.08 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3618333199232906		[learning rate: 0.00051119]
	Learning Rate: 0.000511186
	LOSS [training: 0.3618333199232906 | validation: 0.5367594012852787]
	TIME [epoch: 9.1 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3502881284048717		[learning rate: 0.00050933]
	Learning Rate: 0.000509331
	LOSS [training: 0.3502881284048717 | validation: 0.4723935027245777]
	TIME [epoch: 9.08 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36854899392496226		[learning rate: 0.00050748]
	Learning Rate: 0.000507483
	LOSS [training: 0.36854899392496226 | validation: 0.46088647072913297]
	TIME [epoch: 9.08 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3630131967314326		[learning rate: 0.00050564]
	Learning Rate: 0.000505641
	LOSS [training: 0.3630131967314326 | validation: 0.44841350723124374]
	TIME [epoch: 9.08 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37411797887421383		[learning rate: 0.00050381]
	Learning Rate: 0.000503806
	LOSS [training: 0.37411797887421383 | validation: 0.45394222433187625]
	TIME [epoch: 9.09 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3305076899010734		[learning rate: 0.00050198]
	Learning Rate: 0.000501977
	LOSS [training: 0.3305076899010734 | validation: 0.432532075339687]
	TIME [epoch: 9.1 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.347899374408041		[learning rate: 0.00050016]
	Learning Rate: 0.000500156
	LOSS [training: 0.347899374408041 | validation: 0.5461494268887124]
	TIME [epoch: 9.09 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4033959432254542		[learning rate: 0.00049834]
	Learning Rate: 0.000498341
	LOSS [training: 0.4033959432254542 | validation: 0.42255477819765513]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_925.pth
	Model improved!!!
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3552792842645762		[learning rate: 0.00049653]
	Learning Rate: 0.000496532
	LOSS [training: 0.3552792842645762 | validation: 0.4817079715516607]
	TIME [epoch: 9.08 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35836550200591355		[learning rate: 0.00049473]
	Learning Rate: 0.00049473
	LOSS [training: 0.35836550200591355 | validation: 0.4584339533704954]
	TIME [epoch: 9.1 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37488053582276226		[learning rate: 0.00049293]
	Learning Rate: 0.000492935
	LOSS [training: 0.37488053582276226 | validation: 0.46194551350620233]
	TIME [epoch: 9.09 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3626900597883336		[learning rate: 0.00049115]
	Learning Rate: 0.000491146
	LOSS [training: 0.3626900597883336 | validation: 0.5605060627988381]
	TIME [epoch: 9.07 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37329001204326434		[learning rate: 0.00048936]
	Learning Rate: 0.000489364
	LOSS [training: 0.37329001204326434 | validation: 0.4746691769220707]
	TIME [epoch: 9.08 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3464275594084842		[learning rate: 0.00048759]
	Learning Rate: 0.000487588
	LOSS [training: 0.3464275594084842 | validation: 0.5620627948097401]
	TIME [epoch: 9.08 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3457727644401409		[learning rate: 0.00048582]
	Learning Rate: 0.000485818
	LOSS [training: 0.3457727644401409 | validation: 0.45633378918869016]
	TIME [epoch: 9.09 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34715217488713757		[learning rate: 0.00048406]
	Learning Rate: 0.000484055
	LOSS [training: 0.34715217488713757 | validation: 0.513904404081682]
	TIME [epoch: 9.08 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3704800308576742		[learning rate: 0.0004823]
	Learning Rate: 0.000482298
	LOSS [training: 0.3704800308576742 | validation: 0.5113835473972148]
	TIME [epoch: 9.08 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3510972208048707		[learning rate: 0.00048055]
	Learning Rate: 0.000480548
	LOSS [training: 0.3510972208048707 | validation: 0.43377645476447574]
	TIME [epoch: 9.07 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3818674941041439		[learning rate: 0.0004788]
	Learning Rate: 0.000478804
	LOSS [training: 0.3818674941041439 | validation: 0.4561604012630176]
	TIME [epoch: 9.09 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3585659221151408		[learning rate: 0.00047707]
	Learning Rate: 0.000477067
	LOSS [training: 0.3585659221151408 | validation: 0.4843372174075524]
	TIME [epoch: 9.1 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3508780576573261		[learning rate: 0.00047534]
	Learning Rate: 0.000475335
	LOSS [training: 0.3508780576573261 | validation: 0.6512593237905273]
	TIME [epoch: 9.09 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3651102212925001		[learning rate: 0.00047361]
	Learning Rate: 0.00047361
	LOSS [training: 0.3651102212925001 | validation: 0.4726403467329772]
	TIME [epoch: 9.07 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37400144072018465		[learning rate: 0.00047189]
	Learning Rate: 0.000471891
	LOSS [training: 0.37400144072018465 | validation: 0.4799596249263479]
	TIME [epoch: 9.07 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3679595827732806		[learning rate: 0.00047018]
	Learning Rate: 0.000470179
	LOSS [training: 0.3679595827732806 | validation: 0.6280356507000161]
	TIME [epoch: 9.1 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3675158517262017		[learning rate: 0.00046847]
	Learning Rate: 0.000468473
	LOSS [training: 0.3675158517262017 | validation: 0.464108396521571]
	TIME [epoch: 9.08 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3471305625661956		[learning rate: 0.00046677]
	Learning Rate: 0.000466773
	LOSS [training: 0.3471305625661956 | validation: 0.4774909155825716]
	TIME [epoch: 9.08 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40982617016932243		[learning rate: 0.00046508]
	Learning Rate: 0.000465079
	LOSS [training: 0.40982617016932243 | validation: 0.4576330853938523]
	TIME [epoch: 9.08 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33374280750403457		[learning rate: 0.00046339]
	Learning Rate: 0.000463391
	LOSS [training: 0.33374280750403457 | validation: 0.46951842263507565]
	TIME [epoch: 9.07 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35498975231272994		[learning rate: 0.00046171]
	Learning Rate: 0.000461709
	LOSS [training: 0.35498975231272994 | validation: 0.43914746591673387]
	TIME [epoch: 9.1 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34500807270235695		[learning rate: 0.00046003]
	Learning Rate: 0.000460034
	LOSS [training: 0.34500807270235695 | validation: 0.45956685569070044]
	TIME [epoch: 9.09 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3468737431349655		[learning rate: 0.00045836]
	Learning Rate: 0.000458364
	LOSS [training: 0.3468737431349655 | validation: 0.49959034523948576]
	TIME [epoch: 9.08 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3469445778007293		[learning rate: 0.0004567]
	Learning Rate: 0.000456701
	LOSS [training: 0.3469445778007293 | validation: 0.4465082706932732]
	TIME [epoch: 9.09 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3516799223225619		[learning rate: 0.00045504]
	Learning Rate: 0.000455043
	LOSS [training: 0.3516799223225619 | validation: 0.4314985817541929]
	TIME [epoch: 9.11 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3398955676165338		[learning rate: 0.00045339]
	Learning Rate: 0.000453392
	LOSS [training: 0.3398955676165338 | validation: 0.500754349344269]
	TIME [epoch: 9.1 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3499768923294604		[learning rate: 0.00045175]
	Learning Rate: 0.000451746
	LOSS [training: 0.3499768923294604 | validation: 0.48764710043980947]
	TIME [epoch: 9.09 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35001876191275494		[learning rate: 0.00045011]
	Learning Rate: 0.000450107
	LOSS [training: 0.35001876191275494 | validation: 0.4892005217050915]
	TIME [epoch: 9.09 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38180858740146845		[learning rate: 0.00044847]
	Learning Rate: 0.000448474
	LOSS [training: 0.38180858740146845 | validation: 0.5310057603875458]
	TIME [epoch: 9.08 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34662485284969125		[learning rate: 0.00044685]
	Learning Rate: 0.000446846
	LOSS [training: 0.34662485284969125 | validation: 0.5186367616897921]
	TIME [epoch: 9.11 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3542901637923678		[learning rate: 0.00044522]
	Learning Rate: 0.000445224
	LOSS [training: 0.3542901637923678 | validation: 0.43045063669975]
	TIME [epoch: 9.09 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3573594102582754		[learning rate: 0.00044361]
	Learning Rate: 0.000443609
	LOSS [training: 0.3573594102582754 | validation: 0.43296650484068977]
	TIME [epoch: 9.09 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34726284801978863		[learning rate: 0.000442]
	Learning Rate: 0.000441999
	LOSS [training: 0.34726284801978863 | validation: 0.5429667613186805]
	TIME [epoch: 9.09 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36232611586658375		[learning rate: 0.00044039]
	Learning Rate: 0.000440395
	LOSS [training: 0.36232611586658375 | validation: 0.47347915084018677]
	TIME [epoch: 9.1 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35371752628928316		[learning rate: 0.0004388]
	Learning Rate: 0.000438797
	LOSS [training: 0.35371752628928316 | validation: 0.43661664673177]
	TIME [epoch: 9.08 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4640554765465503		[learning rate: 0.0004372]
	Learning Rate: 0.000437204
	LOSS [training: 0.4640554765465503 | validation: 0.4446701725949679]
	TIME [epoch: 9.09 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37527040250809335		[learning rate: 0.00043562]
	Learning Rate: 0.000435617
	LOSS [training: 0.37527040250809335 | validation: 0.42462044304438656]
	TIME [epoch: 9.08 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36355518373343615		[learning rate: 0.00043404]
	Learning Rate: 0.000434037
	LOSS [training: 0.36355518373343615 | validation: 0.4562935162091256]
	TIME [epoch: 9.09 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36573153307615247		[learning rate: 0.00043246]
	Learning Rate: 0.000432461
	LOSS [training: 0.36573153307615247 | validation: 0.4968562166771861]
	TIME [epoch: 9.11 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3428849027969112		[learning rate: 0.00043089]
	Learning Rate: 0.000430892
	LOSS [training: 0.3428849027969112 | validation: 0.49835676548528174]
	TIME [epoch: 9.08 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35521920889885816		[learning rate: 0.00042933]
	Learning Rate: 0.000429328
	LOSS [training: 0.35521920889885816 | validation: 0.4312543841237664]
	TIME [epoch: 9.09 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34120850007430087		[learning rate: 0.00042777]
	Learning Rate: 0.00042777
	LOSS [training: 0.34120850007430087 | validation: 0.5076521918146799]
	TIME [epoch: 9.09 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36273869321457963		[learning rate: 0.00042622]
	Learning Rate: 0.000426218
	LOSS [training: 0.36273869321457963 | validation: 0.5891602314571998]
	TIME [epoch: 9.08 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.366638303084001		[learning rate: 0.00042467]
	Learning Rate: 0.000424671
	LOSS [training: 0.366638303084001 | validation: 0.45755893466548764]
	TIME [epoch: 9.1 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3498044463217613		[learning rate: 0.00042313]
	Learning Rate: 0.00042313
	LOSS [training: 0.3498044463217613 | validation: 0.436359186187231]
	TIME [epoch: 9.08 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3788052420609857		[learning rate: 0.00042159]
	Learning Rate: 0.000421594
	LOSS [training: 0.3788052420609857 | validation: 0.47624900055148645]
	TIME [epoch: 9.09 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33882425740562044		[learning rate: 0.00042006]
	Learning Rate: 0.000420064
	LOSS [training: 0.33882425740562044 | validation: 0.49967842566509774]
	TIME [epoch: 9.07 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4302798276115971		[learning rate: 0.00041854]
	Learning Rate: 0.00041854
	LOSS [training: 0.4302798276115971 | validation: 0.48544528745881144]
	TIME [epoch: 9.1 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3503777177674187		[learning rate: 0.00041702]
	Learning Rate: 0.000417021
	LOSS [training: 0.3503777177674187 | validation: 0.4394123533701932]
	TIME [epoch: 9.09 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3556027977096434		[learning rate: 0.00041551]
	Learning Rate: 0.000415508
	LOSS [training: 0.3556027977096434 | validation: 0.4511878958855051]
	TIME [epoch: 9.08 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3419192952156882		[learning rate: 0.000414]
	Learning Rate: 0.000414
	LOSS [training: 0.3419192952156882 | validation: 0.4528317799559157]
	TIME [epoch: 9.09 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35061318249142615		[learning rate: 0.0004125]
	Learning Rate: 0.000412497
	LOSS [training: 0.35061318249142615 | validation: 0.4506449502353568]
	TIME [epoch: 9.08 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3405611308067972		[learning rate: 0.000411]
	Learning Rate: 0.000411
	LOSS [training: 0.3405611308067972 | validation: 0.5625647294993184]
	TIME [epoch: 9.1 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3657391847286743		[learning rate: 0.00040951]
	Learning Rate: 0.000409509
	LOSS [training: 0.3657391847286743 | validation: 0.4354397266817689]
	TIME [epoch: 9.08 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35429357170787334		[learning rate: 0.00040802]
	Learning Rate: 0.000408023
	LOSS [training: 0.35429357170787334 | validation: 0.4848900393283745]
	TIME [epoch: 9.07 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33552366410523266		[learning rate: 0.00040654]
	Learning Rate: 0.000406542
	LOSS [training: 0.33552366410523266 | validation: 0.5161873866545664]
	TIME [epoch: 9.07 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3724449530938747		[learning rate: 0.00040507]
	Learning Rate: 0.000405067
	LOSS [training: 0.3724449530938747 | validation: 0.4720376756012108]
	TIME [epoch: 9.08 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3640589068849452		[learning rate: 0.0004036]
	Learning Rate: 0.000403597
	LOSS [training: 0.3640589068849452 | validation: 0.48527249165196307]
	TIME [epoch: 9.1 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3562267174075934		[learning rate: 0.00040213]
	Learning Rate: 0.000402132
	LOSS [training: 0.3562267174075934 | validation: 0.44707731187254784]
	TIME [epoch: 9.09 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35471089956453417		[learning rate: 0.00040067]
	Learning Rate: 0.000400672
	LOSS [training: 0.35471089956453417 | validation: 0.4791392510859372]
	TIME [epoch: 9.07 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3558868680751575		[learning rate: 0.00039922]
	Learning Rate: 0.000399218
	LOSS [training: 0.3558868680751575 | validation: 0.4647989890021191]
	TIME [epoch: 9.08 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3547677980685562		[learning rate: 0.00039777]
	Learning Rate: 0.00039777
	LOSS [training: 0.3547677980685562 | validation: 0.5884972689345283]
	TIME [epoch: 9.1 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34551456396136826		[learning rate: 0.00039633]
	Learning Rate: 0.000396326
	LOSS [training: 0.34551456396136826 | validation: 0.4247300774085673]
	TIME [epoch: 9.08 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34277998526328496		[learning rate: 0.00039489]
	Learning Rate: 0.000394888
	LOSS [training: 0.34277998526328496 | validation: 0.48016079960646985]
	TIME [epoch: 9.08 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3439589642561834		[learning rate: 0.00039345]
	Learning Rate: 0.000393455
	LOSS [training: 0.3439589642561834 | validation: 0.46573717149555033]
	TIME [epoch: 9.08 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3299307405014386		[learning rate: 0.00039203]
	Learning Rate: 0.000392027
	LOSS [training: 0.3299307405014386 | validation: 0.4734016463967567]
	TIME [epoch: 9.08 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3378957883246484		[learning rate: 0.0003906]
	Learning Rate: 0.000390604
	LOSS [training: 0.3378957883246484 | validation: 0.4545283979120692]
	TIME [epoch: 9.1 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35490265840254986		[learning rate: 0.00038919]
	Learning Rate: 0.000389187
	LOSS [training: 0.35490265840254986 | validation: 0.42437364904109176]
	TIME [epoch: 9.07 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3638374176076775		[learning rate: 0.00038777]
	Learning Rate: 0.000387774
	LOSS [training: 0.3638374176076775 | validation: 0.45129134191160936]
	TIME [epoch: 9.07 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34019937406454615		[learning rate: 0.00038637]
	Learning Rate: 0.000386367
	LOSS [training: 0.34019937406454615 | validation: 0.4415540460408769]
	TIME [epoch: 9.07 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34569949505772046		[learning rate: 0.00038496]
	Learning Rate: 0.000384965
	LOSS [training: 0.34569949505772046 | validation: 0.5192425699113318]
	TIME [epoch: 9.09 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38092406652165334		[learning rate: 0.00038357]
	Learning Rate: 0.000383568
	LOSS [training: 0.38092406652165334 | validation: 0.479421538766741]
	TIME [epoch: 9.07 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34102184265490093		[learning rate: 0.00038218]
	Learning Rate: 0.000382176
	LOSS [training: 0.34102184265490093 | validation: 0.44243521434304]
	TIME [epoch: 9.07 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35216413215707315		[learning rate: 0.00038079]
	Learning Rate: 0.000380789
	LOSS [training: 0.35216413215707315 | validation: 0.46813848439143646]
	TIME [epoch: 9.07 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34637336417181486		[learning rate: 0.00037941]
	Learning Rate: 0.000379407
	LOSS [training: 0.34637336417181486 | validation: 0.42558912421395995]
	TIME [epoch: 9.07 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3339024810596135		[learning rate: 0.00037803]
	Learning Rate: 0.00037803
	LOSS [training: 0.3339024810596135 | validation: 0.42857688617963974]
	TIME [epoch: 9.09 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.344846208233892		[learning rate: 0.00037666]
	Learning Rate: 0.000376658
	LOSS [training: 0.344846208233892 | validation: 0.49713952342801904]
	TIME [epoch: 9.09 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3422025455155432		[learning rate: 0.00037529]
	Learning Rate: 0.000375291
	LOSS [training: 0.3422025455155432 | validation: 0.4589985121741752]
	TIME [epoch: 9.08 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34777410734440267		[learning rate: 0.00037393]
	Learning Rate: 0.000373929
	LOSS [training: 0.34777410734440267 | validation: 0.4297137187504375]
	TIME [epoch: 9.08 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35032722977901176		[learning rate: 0.00037257]
	Learning Rate: 0.000372572
	LOSS [training: 0.35032722977901176 | validation: 0.45347726858039056]
	TIME [epoch: 9.07 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3610127737663889		[learning rate: 0.00037122]
	Learning Rate: 0.00037122
	LOSS [training: 0.3610127737663889 | validation: 0.43895552088737144]
	TIME [epoch: 9.09 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3334096364747649		[learning rate: 0.00036987]
	Learning Rate: 0.000369873
	LOSS [training: 0.3334096364747649 | validation: 0.4456054132262332]
	TIME [epoch: 9.07 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3279681418398935		[learning rate: 0.00036853]
	Learning Rate: 0.000368531
	LOSS [training: 0.3279681418398935 | validation: 0.5602620523050779]
	TIME [epoch: 9.07 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3740067319522459		[learning rate: 0.00036719]
	Learning Rate: 0.000367193
	LOSS [training: 0.3740067319522459 | validation: 0.4279459211225941]
	TIME [epoch: 9.07 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3487375794742502		[learning rate: 0.00036586]
	Learning Rate: 0.000365861
	LOSS [training: 0.3487375794742502 | validation: 0.43862993883229817]
	TIME [epoch: 9.1 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35418490978940326		[learning rate: 0.00036453]
	Learning Rate: 0.000364533
	LOSS [training: 0.35418490978940326 | validation: 0.4208841107646482]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1011.pth
	Model improved!!!
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34340613022308325		[learning rate: 0.00036321]
	Learning Rate: 0.00036321
	LOSS [training: 0.34340613022308325 | validation: 0.45192176179415444]
	TIME [epoch: 9.08 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3464823755771581		[learning rate: 0.00036189]
	Learning Rate: 0.000361892
	LOSS [training: 0.3464823755771581 | validation: 0.46013117695306505]
	TIME [epoch: 9.06 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3503798926287585		[learning rate: 0.00036058]
	Learning Rate: 0.000360579
	LOSS [training: 0.3503798926287585 | validation: 0.4174573948822535]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1014.pth
	Model improved!!!
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3495690294091862		[learning rate: 0.00035927]
	Learning Rate: 0.00035927
	LOSS [training: 0.3495690294091862 | validation: 0.49339752364484646]
	TIME [epoch: 9.1 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4128911154820731		[learning rate: 0.00035797]
	Learning Rate: 0.000357966
	LOSS [training: 0.4128911154820731 | validation: 0.4637373160400687]
	TIME [epoch: 9.07 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3312242006969324		[learning rate: 0.00035667]
	Learning Rate: 0.000356667
	LOSS [training: 0.3312242006969324 | validation: 0.44448089383872136]
	TIME [epoch: 9.08 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32322356482302117		[learning rate: 0.00035537]
	Learning Rate: 0.000355373
	LOSS [training: 0.32322356482302117 | validation: 0.4629914360644548]
	TIME [epoch: 9.05 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3684638660797154		[learning rate: 0.00035408]
	Learning Rate: 0.000354083
	LOSS [training: 0.3684638660797154 | validation: 0.4335055786305274]
	TIME [epoch: 9.06 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3206920895831078		[learning rate: 0.0003528]
	Learning Rate: 0.000352798
	LOSS [training: 0.3206920895831078 | validation: 0.44827690807073056]
	TIME [epoch: 9.08 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34138088236372743		[learning rate: 0.00035152]
	Learning Rate: 0.000351518
	LOSS [training: 0.34138088236372743 | validation: 0.4442279518665516]
	TIME [epoch: 9.05 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37037546076005307		[learning rate: 0.00035024]
	Learning Rate: 0.000350242
	LOSS [training: 0.37037546076005307 | validation: 0.4456630478140854]
	TIME [epoch: 9.06 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3280562872112159		[learning rate: 0.00034897]
	Learning Rate: 0.000348971
	LOSS [training: 0.3280562872112159 | validation: 0.4715556676076912]
	TIME [epoch: 9.06 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3433268025730705		[learning rate: 0.0003477]
	Learning Rate: 0.000347705
	LOSS [training: 0.3433268025730705 | validation: 0.42103206394384807]
	TIME [epoch: 9.07 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34196429567380815		[learning rate: 0.00034644]
	Learning Rate: 0.000346443
	LOSS [training: 0.34196429567380815 | validation: 0.44626873588300675]
	TIME [epoch: 9.08 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3662596398761937		[learning rate: 0.00034519]
	Learning Rate: 0.000345186
	LOSS [training: 0.3662596398761937 | validation: 0.41738367454417336]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1026.pth
	Model improved!!!
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34243579436168037		[learning rate: 0.00034393]
	Learning Rate: 0.000343933
	LOSS [training: 0.34243579436168037 | validation: 0.41869369138229606]
	TIME [epoch: 9.08 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33634392095829524		[learning rate: 0.00034268]
	Learning Rate: 0.000342685
	LOSS [training: 0.33634392095829524 | validation: 0.4643690761713306]
	TIME [epoch: 9.07 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33959873774978944		[learning rate: 0.00034144]
	Learning Rate: 0.000341441
	LOSS [training: 0.33959873774978944 | validation: 0.44057719515980226]
	TIME [epoch: 9.1 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3227907670007534		[learning rate: 0.0003402]
	Learning Rate: 0.000340202
	LOSS [training: 0.3227907670007534 | validation: 0.4061481656601494]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1030.pth
	Model improved!!!
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34008718485616335		[learning rate: 0.00033897]
	Learning Rate: 0.000338967
	LOSS [training: 0.34008718485616335 | validation: 0.44094460323820733]
	TIME [epoch: 9.07 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3389159150207129		[learning rate: 0.00033774]
	Learning Rate: 0.000337737
	LOSS [training: 0.3389159150207129 | validation: 0.43532910703863115]
	TIME [epoch: 9.06 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34217620548136635		[learning rate: 0.00033651]
	Learning Rate: 0.000336512
	LOSS [training: 0.34217620548136635 | validation: 0.4961238846150867]
	TIME [epoch: 9.07 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.349192215754082		[learning rate: 0.00033529]
	Learning Rate: 0.00033529
	LOSS [training: 0.349192215754082 | validation: 0.40070278461865166]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1034.pth
	Model improved!!!
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3441948453307504		[learning rate: 0.00033407]
	Learning Rate: 0.000334074
	LOSS [training: 0.3441948453307504 | validation: 0.44473041831483445]
	TIME [epoch: 9.07 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3385970788819682		[learning rate: 0.00033286]
	Learning Rate: 0.000332861
	LOSS [training: 0.3385970788819682 | validation: 0.4430937331649951]
	TIME [epoch: 9.08 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35741416013816685		[learning rate: 0.00033165]
	Learning Rate: 0.000331653
	LOSS [training: 0.35741416013816685 | validation: 0.44160240073360313]
	TIME [epoch: 9.08 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34592224972910923		[learning rate: 0.00033045]
	Learning Rate: 0.00033045
	LOSS [training: 0.34592224972910923 | validation: 0.4288717338304024]
	TIME [epoch: 9.07 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3345108775225039		[learning rate: 0.00032925]
	Learning Rate: 0.00032925
	LOSS [training: 0.3345108775225039 | validation: 0.45915869830958345]
	TIME [epoch: 9.08 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33561884128089814		[learning rate: 0.00032806]
	Learning Rate: 0.000328056
	LOSS [training: 0.33561884128089814 | validation: 0.4478407503503506]
	TIME [epoch: 9.08 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3430008520409445		[learning rate: 0.00032686]
	Learning Rate: 0.000326865
	LOSS [training: 0.3430008520409445 | validation: 0.46327352822747936]
	TIME [epoch: 9.07 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3280159083262951		[learning rate: 0.00032568]
	Learning Rate: 0.000325679
	LOSS [training: 0.3280159083262951 | validation: 0.42469335109555423]
	TIME [epoch: 9.08 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3405931863122318		[learning rate: 0.0003245]
	Learning Rate: 0.000324497
	LOSS [training: 0.3405931863122318 | validation: 0.4813448816356088]
	TIME [epoch: 9.08 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3525120707001191		[learning rate: 0.00032332]
	Learning Rate: 0.000323319
	LOSS [training: 0.3525120707001191 | validation: 0.4650852772036564]
	TIME [epoch: 9.09 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33386848078812087		[learning rate: 0.00032215]
	Learning Rate: 0.000322146
	LOSS [training: 0.33386848078812087 | validation: 0.4519143985299109]
	TIME [epoch: 9.07 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33614872171612414		[learning rate: 0.00032098]
	Learning Rate: 0.000320977
	LOSS [training: 0.33614872171612414 | validation: 0.45061135859100143]
	TIME [epoch: 9.07 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33500788151324556		[learning rate: 0.00031981]
	Learning Rate: 0.000319812
	LOSS [training: 0.33500788151324556 | validation: 0.4617593051190005]
	TIME [epoch: 9.06 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3207217611478911		[learning rate: 0.00031865]
	Learning Rate: 0.000318651
	LOSS [training: 0.3207217611478911 | validation: 0.4810509402328761]
	TIME [epoch: 9.07 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3239783728359542		[learning rate: 0.0003175]
	Learning Rate: 0.000317495
	LOSS [training: 0.3239783728359542 | validation: 0.47668237221003484]
	TIME [epoch: 9.1 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3461222312796383		[learning rate: 0.00031634]
	Learning Rate: 0.000316343
	LOSS [training: 0.3461222312796383 | validation: 0.46226491682416876]
	TIME [epoch: 9.08 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3529642285298191		[learning rate: 0.00031519]
	Learning Rate: 0.000315195
	LOSS [training: 0.3529642285298191 | validation: 0.4543318427656057]
	TIME [epoch: 9.07 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3257218482790621		[learning rate: 0.00031405]
	Learning Rate: 0.000314051
	LOSS [training: 0.3257218482790621 | validation: 0.5049869167724617]
	TIME [epoch: 9.07 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3343656873894308		[learning rate: 0.00031291]
	Learning Rate: 0.000312911
	LOSS [training: 0.3343656873894308 | validation: 0.4435352519378616]
	TIME [epoch: 9.09 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3292923388899073		[learning rate: 0.00031178]
	Learning Rate: 0.000311776
	LOSS [training: 0.3292923388899073 | validation: 0.43986614159659176]
	TIME [epoch: 9.07 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34800203756003656		[learning rate: 0.00031064]
	Learning Rate: 0.000310644
	LOSS [training: 0.34800203756003656 | validation: 0.44756492608338067]
	TIME [epoch: 9.08 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3398339598271502		[learning rate: 0.00030952]
	Learning Rate: 0.000309517
	LOSS [training: 0.3398339598271502 | validation: 0.42636744914915037]
	TIME [epoch: 9.08 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33330115630278756		[learning rate: 0.00030839]
	Learning Rate: 0.000308394
	LOSS [training: 0.33330115630278756 | validation: 0.42252498615488937]
	TIME [epoch: 9.07 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3490503359044956		[learning rate: 0.00030727]
	Learning Rate: 0.000307274
	LOSS [training: 0.3490503359044956 | validation: 0.43344350376163443]
	TIME [epoch: 9.09 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32149336164434905		[learning rate: 0.00030616]
	Learning Rate: 0.000306159
	LOSS [training: 0.32149336164434905 | validation: 0.4349132795481794]
	TIME [epoch: 9.07 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33154008405289437		[learning rate: 0.00030505]
	Learning Rate: 0.000305048
	LOSS [training: 0.33154008405289437 | validation: 0.4074980777611151]
	TIME [epoch: 9.07 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32084481574710355		[learning rate: 0.00030394]
	Learning Rate: 0.000303941
	LOSS [training: 0.32084481574710355 | validation: 0.43049451342009876]
	TIME [epoch: 9.07 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3280305294717689		[learning rate: 0.00030284]
	Learning Rate: 0.000302838
	LOSS [training: 0.3280305294717689 | validation: 0.45812961320860995]
	TIME [epoch: 9.09 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3321583681785771		[learning rate: 0.00030174]
	Learning Rate: 0.000301739
	LOSS [training: 0.3321583681785771 | validation: 0.406512298470552]
	TIME [epoch: 9.08 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33038068496693523		[learning rate: 0.00030064]
	Learning Rate: 0.000300644
	LOSS [training: 0.33038068496693523 | validation: 0.4563423260490855]
	TIME [epoch: 9.07 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32857624328508817		[learning rate: 0.00029955]
	Learning Rate: 0.000299553
	LOSS [training: 0.32857624328508817 | validation: 0.4689903211080887]
	TIME [epoch: 9.07 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34683046924423594		[learning rate: 0.00029847]
	Learning Rate: 0.000298466
	LOSS [training: 0.34683046924423594 | validation: 0.45329582851137457]
	TIME [epoch: 9.08 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3539144533935647		[learning rate: 0.00029738]
	Learning Rate: 0.000297383
	LOSS [training: 0.3539144533935647 | validation: 0.49574113677598297]
	TIME [epoch: 9.09 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36632515944207594		[learning rate: 0.0002963]
	Learning Rate: 0.000296304
	LOSS [training: 0.36632515944207594 | validation: 0.4313016916256943]
	TIME [epoch: 9.09 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3333781948929192		[learning rate: 0.00029523]
	Learning Rate: 0.000295228
	LOSS [training: 0.3333781948929192 | validation: 0.4499947704073859]
	TIME [epoch: 9.08 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3193457515464258		[learning rate: 0.00029416]
	Learning Rate: 0.000294157
	LOSS [training: 0.3193457515464258 | validation: 0.44255548317602966]
	TIME [epoch: 9.08 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34199091286944483		[learning rate: 0.00029309]
	Learning Rate: 0.000293089
	LOSS [training: 0.34199091286944483 | validation: 0.4153994234700363]
	TIME [epoch: 9.09 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32574624715706163		[learning rate: 0.00029203]
	Learning Rate: 0.000292026
	LOSS [training: 0.32574624715706163 | validation: 0.4298150275384529]
	TIME [epoch: 9.08 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3222900098705136		[learning rate: 0.00029097]
	Learning Rate: 0.000290966
	LOSS [training: 0.3222900098705136 | validation: 0.4374913813800394]
	TIME [epoch: 9.07 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35488100402824246		[learning rate: 0.00028991]
	Learning Rate: 0.00028991
	LOSS [training: 0.35488100402824246 | validation: 0.4942950601618733]
	TIME [epoch: 9.07 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3405929925545922		[learning rate: 0.00028886]
	Learning Rate: 0.000288858
	LOSS [training: 0.3405929925545922 | validation: 0.5074649233330293]
	TIME [epoch: 9.07 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3392283458169064		[learning rate: 0.00028781]
	Learning Rate: 0.00028781
	LOSS [training: 0.3392283458169064 | validation: 0.48217103634357616]
	TIME [epoch: 9.09 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3295652177837419		[learning rate: 0.00028677]
	Learning Rate: 0.000286765
	LOSS [training: 0.3295652177837419 | validation: 0.4399563238725763]
	TIME [epoch: 9.06 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33556356428265677		[learning rate: 0.00028572]
	Learning Rate: 0.000285724
	LOSS [training: 0.33556356428265677 | validation: 0.4590358704348126]
	TIME [epoch: 9.07 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3290892257505984		[learning rate: 0.00028469]
	Learning Rate: 0.000284688
	LOSS [training: 0.3290892257505984 | validation: 0.4375569366817952]
	TIME [epoch: 9.06 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31480578891136524		[learning rate: 0.00028365]
	Learning Rate: 0.000283654
	LOSS [training: 0.31480578891136524 | validation: 0.4246256842663275]
	TIME [epoch: 9.07 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34497976268306385		[learning rate: 0.00028263]
	Learning Rate: 0.000282625
	LOSS [training: 0.34497976268306385 | validation: 0.47163656121825887]
	TIME [epoch: 9.09 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3520677630740444		[learning rate: 0.0002816]
	Learning Rate: 0.000281599
	LOSS [training: 0.3520677630740444 | validation: 0.45408855380633556]
	TIME [epoch: 9.07 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3386666571565181		[learning rate: 0.00028058]
	Learning Rate: 0.000280577
	LOSS [training: 0.3386666571565181 | validation: 0.43742829925435955]
	TIME [epoch: 9.07 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37726640456314103		[learning rate: 0.00027956]
	Learning Rate: 0.000279559
	LOSS [training: 0.37726640456314103 | validation: 0.48159992367835625]
	TIME [epoch: 9.07 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3245371574123462		[learning rate: 0.00027854]
	Learning Rate: 0.000278545
	LOSS [training: 0.3245371574123462 | validation: 0.4085556411603789]
	TIME [epoch: 9.08 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3152462495031919		[learning rate: 0.00027753]
	Learning Rate: 0.000277534
	LOSS [training: 0.3152462495031919 | validation: 0.4800516035460617]
	TIME [epoch: 9.07 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3344298617285443		[learning rate: 0.00027653]
	Learning Rate: 0.000276527
	LOSS [training: 0.3344298617285443 | validation: 0.4655240880268765]
	TIME [epoch: 9.07 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35386186913091644		[learning rate: 0.00027552]
	Learning Rate: 0.000275523
	LOSS [training: 0.35386186913091644 | validation: 0.4630593764014319]
	TIME [epoch: 9.07 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34749219804532727		[learning rate: 0.00027452]
	Learning Rate: 0.000274523
	LOSS [training: 0.34749219804532727 | validation: 0.4591066417235313]
	TIME [epoch: 9.07 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3194773662290592		[learning rate: 0.00027353]
	Learning Rate: 0.000273527
	LOSS [training: 0.3194773662290592 | validation: 0.4489201214048544]
	TIME [epoch: 9.09 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3262757790833587		[learning rate: 0.00027253]
	Learning Rate: 0.000272534
	LOSS [training: 0.3262757790833587 | validation: 0.4077146198417714]
	TIME [epoch: 9.08 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34431062984748456		[learning rate: 0.00027155]
	Learning Rate: 0.000271545
	LOSS [training: 0.34431062984748456 | validation: 0.42059917787708145]
	TIME [epoch: 9.07 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3474869433583018		[learning rate: 0.00027056]
	Learning Rate: 0.00027056
	LOSS [training: 0.3474869433583018 | validation: 0.538659201519196]
	TIME [epoch: 9.08 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33859333924924445		[learning rate: 0.00026958]
	Learning Rate: 0.000269578
	LOSS [training: 0.33859333924924445 | validation: 0.41196108702392303]
	TIME [epoch: 9.09 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3238294852101752		[learning rate: 0.0002686]
	Learning Rate: 0.0002686
	LOSS [training: 0.3238294852101752 | validation: 0.42106624701624157]
	TIME [epoch: 9.07 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31999844073062056		[learning rate: 0.00026762]
	Learning Rate: 0.000267625
	LOSS [training: 0.31999844073062056 | validation: 0.4417567296734878]
	TIME [epoch: 9.08 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34454069739686305		[learning rate: 0.00026665]
	Learning Rate: 0.000266654
	LOSS [training: 0.34454069739686305 | validation: 0.466677889679119]
	TIME [epoch: 9.07 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3401192405899387		[learning rate: 0.00026569]
	Learning Rate: 0.000265686
	LOSS [training: 0.3401192405899387 | validation: 0.4391843598563727]
	TIME [epoch: 9.06 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3421597211379792		[learning rate: 0.00026472]
	Learning Rate: 0.000264722
	LOSS [training: 0.3421597211379792 | validation: 0.460076592961921]
	TIME [epoch: 9.08 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3312959877521422		[learning rate: 0.00026376]
	Learning Rate: 0.000263761
	LOSS [training: 0.3312959877521422 | validation: 0.5793260401460143]
	TIME [epoch: 9.05 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3744752357692858		[learning rate: 0.0002628]
	Learning Rate: 0.000262804
	LOSS [training: 0.3744752357692858 | validation: 0.45621312638875106]
	TIME [epoch: 9.07 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3366078439833487		[learning rate: 0.00026185]
	Learning Rate: 0.00026185
	LOSS [training: 0.3366078439833487 | validation: 0.434451357261635]
	TIME [epoch: 9.05 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3263578973602731		[learning rate: 0.0002609]
	Learning Rate: 0.0002609
	LOSS [training: 0.3263578973602731 | validation: 0.632214897579087]
	TIME [epoch: 9.08 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36544603391464386		[learning rate: 0.00025995]
	Learning Rate: 0.000259953
	LOSS [training: 0.36544603391464386 | validation: 0.4535976861603306]
	TIME [epoch: 9.07 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33276724244507055		[learning rate: 0.00025901]
	Learning Rate: 0.00025901
	LOSS [training: 0.33276724244507055 | validation: 0.42744245199194486]
	TIME [epoch: 9.06 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30933310419197113		[learning rate: 0.00025807]
	Learning Rate: 0.00025807
	LOSS [training: 0.30933310419197113 | validation: 0.5512807781467414]
	TIME [epoch: 9.07 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34222036366801856		[learning rate: 0.00025713]
	Learning Rate: 0.000257133
	LOSS [training: 0.34222036366801856 | validation: 0.447681928826145]
	TIME [epoch: 9.07 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32611411270356583		[learning rate: 0.0002562]
	Learning Rate: 0.0002562
	LOSS [training: 0.32611411270356583 | validation: 0.4810912215453982]
	TIME [epoch: 9.08 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3238809286892219		[learning rate: 0.00025527]
	Learning Rate: 0.00025527
	LOSS [training: 0.3238809286892219 | validation: 0.41489707296430833]
	TIME [epoch: 9.08 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33222401220991427		[learning rate: 0.00025434]
	Learning Rate: 0.000254344
	LOSS [training: 0.33222401220991427 | validation: 0.47403579428136267]
	TIME [epoch: 9.06 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32864781091832057		[learning rate: 0.00025342]
	Learning Rate: 0.000253421
	LOSS [training: 0.32864781091832057 | validation: 0.44656233077233487]
	TIME [epoch: 9.06 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3268001480949632		[learning rate: 0.0002525]
	Learning Rate: 0.000252501
	LOSS [training: 0.3268001480949632 | validation: 0.4626114625308483]
	TIME [epoch: 9.06 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3276287100547429		[learning rate: 0.00025158]
	Learning Rate: 0.000251585
	LOSS [training: 0.3276287100547429 | validation: 0.43354420889834394]
	TIME [epoch: 9.07 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3522243668316845		[learning rate: 0.00025067]
	Learning Rate: 0.000250672
	LOSS [training: 0.3522243668316845 | validation: 0.4683597582158677]
	TIME [epoch: 9.07 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3249022250612693		[learning rate: 0.00024976]
	Learning Rate: 0.000249762
	LOSS [training: 0.3249022250612693 | validation: 0.44868026192403476]
	TIME [epoch: 9.06 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3352792168205269		[learning rate: 0.00024886]
	Learning Rate: 0.000248856
	LOSS [training: 0.3352792168205269 | validation: 0.45283398088527393]
	TIME [epoch: 9.06 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500205971365771		[learning rate: 0.00024795]
	Learning Rate: 0.000247952
	LOSS [training: 0.3500205971365771 | validation: 0.49759083953737404]
	TIME [epoch: 9.06 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3300636211572457		[learning rate: 0.00024705]
	Learning Rate: 0.000247053
	LOSS [training: 0.3300636211572457 | validation: 0.4139768209353211]
	TIME [epoch: 9.08 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3255747283340236		[learning rate: 0.00024616]
	Learning Rate: 0.000246156
	LOSS [training: 0.3255747283340236 | validation: 0.457702190962098]
	TIME [epoch: 9.07 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33181018832064796		[learning rate: 0.00024526]
	Learning Rate: 0.000245263
	LOSS [training: 0.33181018832064796 | validation: 0.4330881568037341]
	TIME [epoch: 9.06 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3304348463960666		[learning rate: 0.00024437]
	Learning Rate: 0.000244373
	LOSS [training: 0.3304348463960666 | validation: 0.4865716586128265]
	TIME [epoch: 9.07 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32407099770768666		[learning rate: 0.00024349]
	Learning Rate: 0.000243486
	LOSS [training: 0.32407099770768666 | validation: 0.4380579552200029]
	TIME [epoch: 9.09 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34190513296713554		[learning rate: 0.0002426]
	Learning Rate: 0.000242602
	LOSS [training: 0.34190513296713554 | validation: 0.47635738859500204]
	TIME [epoch: 9.06 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3213893211205753		[learning rate: 0.00024172]
	Learning Rate: 0.000241722
	LOSS [training: 0.3213893211205753 | validation: 0.41215855196945794]
	TIME [epoch: 9.06 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3217058241296679		[learning rate: 0.00024084]
	Learning Rate: 0.000240845
	LOSS [training: 0.3217058241296679 | validation: 0.4204980350202677]
	TIME [epoch: 9.06 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3366930310788606		[learning rate: 0.00023997]
	Learning Rate: 0.000239971
	LOSS [training: 0.3366930310788606 | validation: 0.45240518689247444]
	TIME [epoch: 9.06 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34284730534266505		[learning rate: 0.0002391]
	Learning Rate: 0.0002391
	LOSS [training: 0.34284730534266505 | validation: 0.44710943009776005]
	TIME [epoch: 9.08 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3180153194673324		[learning rate: 0.00023823]
	Learning Rate: 0.000238232
	LOSS [training: 0.3180153194673324 | validation: 0.48934663439963616]
	TIME [epoch: 9.06 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3600626430632884		[learning rate: 0.00023737]
	Learning Rate: 0.000237367
	LOSS [training: 0.3600626430632884 | validation: 0.46970848631860684]
	TIME [epoch: 9.06 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32171069713394707		[learning rate: 0.00023651]
	Learning Rate: 0.000236506
	LOSS [training: 0.32171069713394707 | validation: 0.435234022429099]
	TIME [epoch: 9.06 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3460366759765399		[learning rate: 0.00023565]
	Learning Rate: 0.000235648
	LOSS [training: 0.3460366759765399 | validation: 0.41423617955354874]
	TIME [epoch: 9.08 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33160093547283603		[learning rate: 0.00023479]
	Learning Rate: 0.000234793
	LOSS [training: 0.33160093547283603 | validation: 0.4102492123156526]
	TIME [epoch: 9.07 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32116219903079324		[learning rate: 0.00023394]
	Learning Rate: 0.00023394
	LOSS [training: 0.32116219903079324 | validation: 0.417975870396426]
	TIME [epoch: 9.06 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.312056557365724		[learning rate: 0.00023309]
	Learning Rate: 0.000233091
	LOSS [training: 0.312056557365724 | validation: 0.43664806992354377]
	TIME [epoch: 9.07 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3382601923391396		[learning rate: 0.00023225]
	Learning Rate: 0.000232246
	LOSS [training: 0.3382601923391396 | validation: 0.4122035309013147]
	TIME [epoch: 9.07 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31781258791581085		[learning rate: 0.0002314]
	Learning Rate: 0.000231403
	LOSS [training: 0.31781258791581085 | validation: 0.44428451305614935]
	TIME [epoch: 9.08 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3048925746698785		[learning rate: 0.00023056]
	Learning Rate: 0.000230563
	LOSS [training: 0.3048925746698785 | validation: 0.4482409597432548]
	TIME [epoch: 9.07 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32805908805219164		[learning rate: 0.00022973]
	Learning Rate: 0.000229726
	LOSS [training: 0.32805908805219164 | validation: 0.4653220681341128]
	TIME [epoch: 9.06 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33474877874056636		[learning rate: 0.00022889]
	Learning Rate: 0.000228893
	LOSS [training: 0.33474877874056636 | validation: 0.4492002075653936]
	TIME [epoch: 9.06 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3264357169257091		[learning rate: 0.00022806]
	Learning Rate: 0.000228062
	LOSS [training: 0.3264357169257091 | validation: 0.4342119302677416]
	TIME [epoch: 9.06 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32812419992137576		[learning rate: 0.00022723]
	Learning Rate: 0.000227234
	LOSS [training: 0.32812419992137576 | validation: 0.4745260736790494]
	TIME [epoch: 9.09 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3285763374592306		[learning rate: 0.00022641]
	Learning Rate: 0.00022641
	LOSS [training: 0.3285763374592306 | validation: 0.42022959479597866]
	TIME [epoch: 9.06 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33474194129717405		[learning rate: 0.00022559]
	Learning Rate: 0.000225588
	LOSS [training: 0.33474194129717405 | validation: 0.39946390840891355]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1143.pth
	Model improved!!!
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3208891970676901		[learning rate: 0.00022477]
	Learning Rate: 0.000224769
	LOSS [training: 0.3208891970676901 | validation: 0.5830421134518078]
	TIME [epoch: 9.07 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33638793850366117		[learning rate: 0.00022395]
	Learning Rate: 0.000223954
	LOSS [training: 0.33638793850366117 | validation: 0.42942340519550837]
	TIME [epoch: 9.08 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32867126440323424		[learning rate: 0.00022314]
	Learning Rate: 0.000223141
	LOSS [training: 0.32867126440323424 | validation: 0.4354510782715456]
	TIME [epoch: 9.07 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31736172830120185		[learning rate: 0.00022233]
	Learning Rate: 0.000222331
	LOSS [training: 0.31736172830120185 | validation: 0.4326622804955529]
	TIME [epoch: 9.07 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3097439821883641		[learning rate: 0.00022152]
	Learning Rate: 0.000221524
	LOSS [training: 0.3097439821883641 | validation: 0.4321178992068838]
	TIME [epoch: 9.07 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33263019174939357		[learning rate: 0.00022072]
	Learning Rate: 0.00022072
	LOSS [training: 0.33263019174939357 | validation: 0.4163625527119581]
	TIME [epoch: 9.07 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31959729819671984		[learning rate: 0.00021992]
	Learning Rate: 0.000219919
	LOSS [training: 0.31959729819671984 | validation: 0.40978687838301747]
	TIME [epoch: 9.09 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32047411595447906		[learning rate: 0.00021912]
	Learning Rate: 0.000219121
	LOSS [training: 0.32047411595447906 | validation: 0.400175751973445]
	TIME [epoch: 9.06 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32582590300182346		[learning rate: 0.00021833]
	Learning Rate: 0.000218326
	LOSS [training: 0.32582590300182346 | validation: 0.5131743970638218]
	TIME [epoch: 9.06 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34805397011015116		[learning rate: 0.00021753]
	Learning Rate: 0.000217534
	LOSS [training: 0.34805397011015116 | validation: 0.41004607629149636]
	TIME [epoch: 9.06 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3246344967737618		[learning rate: 0.00021674]
	Learning Rate: 0.000216744
	LOSS [training: 0.3246344967737618 | validation: 0.41831130024830815]
	TIME [epoch: 9.07 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3172361572678156		[learning rate: 0.00021596]
	Learning Rate: 0.000215958
	LOSS [training: 0.3172361572678156 | validation: 0.42301512607588876]
	TIME [epoch: 9.08 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3069907018295872		[learning rate: 0.00021517]
	Learning Rate: 0.000215174
	LOSS [training: 0.3069907018295872 | validation: 0.420340612242278]
	TIME [epoch: 9.06 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32020308756360205		[learning rate: 0.00021439]
	Learning Rate: 0.000214393
	LOSS [training: 0.32020308756360205 | validation: 0.44124322123491794]
	TIME [epoch: 9.07 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3118032227425619		[learning rate: 0.00021361]
	Learning Rate: 0.000213615
	LOSS [training: 0.3118032227425619 | validation: 0.45233175365872164]
	TIME [epoch: 9.07 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32231365882443436		[learning rate: 0.00021284]
	Learning Rate: 0.00021284
	LOSS [training: 0.32231365882443436 | validation: 0.47459921465105503]
	TIME [epoch: 9.09 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3491302321260702		[learning rate: 0.00021207]
	Learning Rate: 0.000212067
	LOSS [training: 0.3491302321260702 | validation: 0.39597186373157023]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1160.pth
	Model improved!!!
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3117160154422497		[learning rate: 0.0002113]
	Learning Rate: 0.000211298
	LOSS [training: 0.3117160154422497 | validation: 0.42811240556118874]
	TIME [epoch: 9.09 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3210633077119942		[learning rate: 0.00021053]
	Learning Rate: 0.000210531
	LOSS [training: 0.3210633077119942 | validation: 0.4125916104892639]
	TIME [epoch: 9.08 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.320350820029227		[learning rate: 0.00020977]
	Learning Rate: 0.000209767
	LOSS [training: 0.320350820029227 | validation: 0.4312433070786047]
	TIME [epoch: 9.08 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3276723697796353		[learning rate: 0.00020901]
	Learning Rate: 0.000209006
	LOSS [training: 0.3276723697796353 | validation: 0.4243377007103145]
	TIME [epoch: 9.09 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3130738897707791		[learning rate: 0.00020825]
	Learning Rate: 0.000208247
	LOSS [training: 0.3130738897707791 | validation: 0.42465653013390764]
	TIME [epoch: 9.08 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3180229543383012		[learning rate: 0.00020749]
	Learning Rate: 0.000207491
	LOSS [training: 0.3180229543383012 | validation: 0.40148255236952746]
	TIME [epoch: 9.08 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3155758456498913		[learning rate: 0.00020674]
	Learning Rate: 0.000206738
	LOSS [training: 0.3155758456498913 | validation: 0.4613627215119984]
	TIME [epoch: 9.08 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3147742772565659		[learning rate: 0.00020599]
	Learning Rate: 0.000205988
	LOSS [training: 0.3147742772565659 | validation: 0.46074624742435005]
	TIME [epoch: 9.08 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30887267680734304		[learning rate: 0.00020524]
	Learning Rate: 0.000205241
	LOSS [training: 0.30887267680734304 | validation: 0.4352600687745481]
	TIME [epoch: 9.1 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31323458108978247		[learning rate: 0.0002045]
	Learning Rate: 0.000204496
	LOSS [training: 0.31323458108978247 | validation: 0.41257813441813507]
	TIME [epoch: 9.08 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32246431398683645		[learning rate: 0.00020375]
	Learning Rate: 0.000203754
	LOSS [training: 0.32246431398683645 | validation: 0.40812103454349075]
	TIME [epoch: 9.08 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093411584128248		[learning rate: 0.00020301]
	Learning Rate: 0.000203014
	LOSS [training: 0.3093411584128248 | validation: 0.416575039085781]
	TIME [epoch: 9.09 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3223613840521381		[learning rate: 0.00020228]
	Learning Rate: 0.000202277
	LOSS [training: 0.3223613840521381 | validation: 0.42903758889120014]
	TIME [epoch: 9.11 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3149356304649274		[learning rate: 0.00020154]
	Learning Rate: 0.000201543
	LOSS [training: 0.3149356304649274 | validation: 0.41317403168618577]
	TIME [epoch: 9.09 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3151838247875488		[learning rate: 0.00020081]
	Learning Rate: 0.000200812
	LOSS [training: 0.3151838247875488 | validation: 0.410377029229975]
	TIME [epoch: 9.09 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3137238963898349		[learning rate: 0.00020008]
	Learning Rate: 0.000200083
	LOSS [training: 0.3137238963898349 | validation: 0.4127580864493222]
	TIME [epoch: 9.08 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3267685603699174		[learning rate: 0.00019936]
	Learning Rate: 0.000199357
	LOSS [training: 0.3267685603699174 | validation: 0.3998271100845326]
	TIME [epoch: 9.09 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31902214578014604		[learning rate: 0.00019863]
	Learning Rate: 0.000198634
	LOSS [training: 0.31902214578014604 | validation: 0.4129030159521412]
	TIME [epoch: 9.11 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3108620017703089		[learning rate: 0.00019791]
	Learning Rate: 0.000197913
	LOSS [training: 0.3108620017703089 | validation: 0.4144716498815152]
	TIME [epoch: 9.09 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3124992131746149		[learning rate: 0.00019719]
	Learning Rate: 0.000197194
	LOSS [training: 0.3124992131746149 | validation: 0.4479413428200518]
	TIME [epoch: 9.11 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3258357001765929		[learning rate: 0.00019648]
	Learning Rate: 0.000196479
	LOSS [training: 0.3258357001765929 | validation: 0.39487545751951214]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1181.pth
	Model improved!!!
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3303514372975333		[learning rate: 0.00019577]
	Learning Rate: 0.000195766
	LOSS [training: 0.3303514372975333 | validation: 0.4218589101773608]
	TIME [epoch: 9.1 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33374946665708566		[learning rate: 0.00019506]
	Learning Rate: 0.000195055
	LOSS [training: 0.33374946665708566 | validation: 0.4239600136055247]
	TIME [epoch: 9.09 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34220983826447965		[learning rate: 0.00019435]
	Learning Rate: 0.000194347
	LOSS [training: 0.34220983826447965 | validation: 0.42107523175838646]
	TIME [epoch: 9.08 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32185244673039326		[learning rate: 0.00019364]
	Learning Rate: 0.000193642
	LOSS [training: 0.32185244673039326 | validation: 0.4260412982899075]
	TIME [epoch: 9.09 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3171424374429562		[learning rate: 0.00019294]
	Learning Rate: 0.000192939
	LOSS [training: 0.3171424374429562 | validation: 0.39772612090901627]
	TIME [epoch: 9.09 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3190486644122139		[learning rate: 0.00019224]
	Learning Rate: 0.000192239
	LOSS [training: 0.3190486644122139 | validation: 0.42048337202878955]
	TIME [epoch: 9.11 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093908326768383		[learning rate: 0.00019154]
	Learning Rate: 0.000191542
	LOSS [training: 0.3093908326768383 | validation: 0.39374365895421665]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1188.pth
	Model improved!!!
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33460051342237307		[learning rate: 0.00019085]
	Learning Rate: 0.000190846
	LOSS [training: 0.33460051342237307 | validation: 0.4323601471483176]
	TIME [epoch: 9.08 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30822936468465095		[learning rate: 0.00019015]
	Learning Rate: 0.000190154
	LOSS [training: 0.30822936468465095 | validation: 0.41285377549513175]
	TIME [epoch: 9.08 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3161082404775093		[learning rate: 0.00018946]
	Learning Rate: 0.000189464
	LOSS [training: 0.3161082404775093 | validation: 0.4370073150051132]
	TIME [epoch: 9.08 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32051820216403015		[learning rate: 0.00018878]
	Learning Rate: 0.000188776
	LOSS [training: 0.32051820216403015 | validation: 0.41327233934635965]
	TIME [epoch: 9.09 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32720811118576804		[learning rate: 0.00018809]
	Learning Rate: 0.000188091
	LOSS [training: 0.32720811118576804 | validation: 0.42302383120119635]
	TIME [epoch: 9.08 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31233218530836154		[learning rate: 0.00018741]
	Learning Rate: 0.000187409
	LOSS [training: 0.31233218530836154 | validation: 0.4042553136413168]
	TIME [epoch: 9.08 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33172896184729617		[learning rate: 0.00018673]
	Learning Rate: 0.000186729
	LOSS [training: 0.33172896184729617 | validation: 0.4502420730565822]
	TIME [epoch: 9.09 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3215546452153108		[learning rate: 0.00018605]
	Learning Rate: 0.000186051
	LOSS [training: 0.3215546452153108 | validation: 0.40704482772854544]
	TIME [epoch: 9.09 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32156656919564197		[learning rate: 0.00018538]
	Learning Rate: 0.000185376
	LOSS [training: 0.32156656919564197 | validation: 0.38644834359864316]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1197.pth
	Model improved!!!
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32284236550087114		[learning rate: 0.0001847]
	Learning Rate: 0.000184703
	LOSS [training: 0.32284236550087114 | validation: 0.4190920308861277]
	TIME [epoch: 9.08 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3287705045987878		[learning rate: 0.00018403]
	Learning Rate: 0.000184033
	LOSS [training: 0.3287705045987878 | validation: 0.4355549734075661]
	TIME [epoch: 9.08 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3085221528063797		[learning rate: 0.00018336]
	Learning Rate: 0.000183365
	LOSS [training: 0.3085221528063797 | validation: 0.4012103278084789]
	TIME [epoch: 9.09 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31437079185513456		[learning rate: 0.0001827]
	Learning Rate: 0.000182699
	LOSS [training: 0.31437079185513456 | validation: 0.4139235576512906]
	TIME [epoch: 9.08 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3275760773968793		[learning rate: 0.00018204]
	Learning Rate: 0.000182036
	LOSS [training: 0.3275760773968793 | validation: 0.42037245315951993]
	TIME [epoch: 9.09 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3157477147546487		[learning rate: 0.00018138]
	Learning Rate: 0.000181376
	LOSS [training: 0.3157477147546487 | validation: 0.4672932686401422]
	TIME [epoch: 9.07 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31970166625215846		[learning rate: 0.00018072]
	Learning Rate: 0.000180717
	LOSS [training: 0.31970166625215846 | validation: 0.4259358670606837]
	TIME [epoch: 9.07 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3270501240011464		[learning rate: 0.00018006]
	Learning Rate: 0.000180062
	LOSS [training: 0.3270501240011464 | validation: 0.4433924355078618]
	TIME [epoch: 9.07 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33936542225542804		[learning rate: 0.00017941]
	Learning Rate: 0.000179408
	LOSS [training: 0.33936542225542804 | validation: 0.4388856818905473]
	TIME [epoch: 9.08 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3104449166973506		[learning rate: 0.00017876]
	Learning Rate: 0.000178757
	LOSS [training: 0.3104449166973506 | validation: 0.4161025960274579]
	TIME [epoch: 9.1 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32916431709226357		[learning rate: 0.00017811]
	Learning Rate: 0.000178108
	LOSS [training: 0.32916431709226357 | validation: 0.4029050886117757]
	TIME [epoch: 9.08 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3158845287125341		[learning rate: 0.00017746]
	Learning Rate: 0.000177462
	LOSS [training: 0.3158845287125341 | validation: 0.4175869179310403]
	TIME [epoch: 9.08 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3376233793641565		[learning rate: 0.00017682]
	Learning Rate: 0.000176818
	LOSS [training: 0.3376233793641565 | validation: 0.4076003706048068]
	TIME [epoch: 9.07 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3200234181838049		[learning rate: 0.00017618]
	Learning Rate: 0.000176176
	LOSS [training: 0.3200234181838049 | validation: 0.40502354836018867]
	TIME [epoch: 9.1 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3246584319354046		[learning rate: 0.00017554]
	Learning Rate: 0.000175537
	LOSS [training: 0.3246584319354046 | validation: 0.3953192662722872]
	TIME [epoch: 9.07 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32003721633019966		[learning rate: 0.0001749]
	Learning Rate: 0.0001749
	LOSS [training: 0.32003721633019966 | validation: 0.3868920927262621]
	TIME [epoch: 9.08 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31787459944304286		[learning rate: 0.00017427]
	Learning Rate: 0.000174265
	LOSS [training: 0.31787459944304286 | validation: 0.42220063336143443]
	TIME [epoch: 9.08 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2984325322200817		[learning rate: 0.00017363]
	Learning Rate: 0.000173633
	LOSS [training: 0.2984325322200817 | validation: 0.41803484406103675]
	TIME [epoch: 9.07 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30961743714132434		[learning rate: 0.000173]
	Learning Rate: 0.000173003
	LOSS [training: 0.30961743714132434 | validation: 0.4222154827304926]
	TIME [epoch: 9.1 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31135327349490716		[learning rate: 0.00017237]
	Learning Rate: 0.000172375
	LOSS [training: 0.31135327349490716 | validation: 0.4279796945588703]
	TIME [epoch: 9.07 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3176610732050627		[learning rate: 0.00017175]
	Learning Rate: 0.000171749
	LOSS [training: 0.3176610732050627 | validation: 0.4161603498703129]
	TIME [epoch: 9.07 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3089846539265806		[learning rate: 0.00017113]
	Learning Rate: 0.000171126
	LOSS [training: 0.3089846539265806 | validation: 0.42535539180450327]
	TIME [epoch: 9.07 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3085072751995724		[learning rate: 0.0001705]
	Learning Rate: 0.000170505
	LOSS [training: 0.3085072751995724 | validation: 0.3918737240478124]
	TIME [epoch: 9.09 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31996391382093875		[learning rate: 0.00016989]
	Learning Rate: 0.000169886
	LOSS [training: 0.31996391382093875 | validation: 0.406322918212572]
	TIME [epoch: 9.09 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32810128036683023		[learning rate: 0.00016927]
	Learning Rate: 0.00016927
	LOSS [training: 0.32810128036683023 | validation: 0.38496796426195107]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1222.pth
	Model improved!!!
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31682159294165124		[learning rate: 0.00016866]
	Learning Rate: 0.000168655
	LOSS [training: 0.31682159294165124 | validation: 0.4141976841696061]
	TIME [epoch: 9.09 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32092899358085375		[learning rate: 0.00016804]
	Learning Rate: 0.000168043
	LOSS [training: 0.32092899358085375 | validation: 0.4141321737187044]
	TIME [epoch: 9.08 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31414492878117284		[learning rate: 0.00016743]
	Learning Rate: 0.000167433
	LOSS [training: 0.31414492878117284 | validation: 0.4142167890957207]
	TIME [epoch: 9.09 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3108591194178367		[learning rate: 0.00016683]
	Learning Rate: 0.000166826
	LOSS [training: 0.3108591194178367 | validation: 0.4300392498393326]
	TIME [epoch: 9.08 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30144021390872155		[learning rate: 0.00016622]
	Learning Rate: 0.00016622
	LOSS [training: 0.30144021390872155 | validation: 0.42823413050190834]
	TIME [epoch: 9.07 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31131899673667435		[learning rate: 0.00016562]
	Learning Rate: 0.000165617
	LOSS [training: 0.31131899673667435 | validation: 0.434177884070397]
	TIME [epoch: 9.06 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093584947168696		[learning rate: 0.00016502]
	Learning Rate: 0.000165016
	LOSS [training: 0.3093584947168696 | validation: 0.4548824438560405]
	TIME [epoch: 9.07 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3048317324087423		[learning rate: 0.00016442]
	Learning Rate: 0.000164417
	LOSS [training: 0.3048317324087423 | validation: 0.4140477110150856]
	TIME [epoch: 9.09 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30515573705498367		[learning rate: 0.00016382]
	Learning Rate: 0.000163821
	LOSS [training: 0.30515573705498367 | validation: 0.39576346598981604]
	TIME [epoch: 9.08 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3095008893743858		[learning rate: 0.00016323]
	Learning Rate: 0.000163226
	LOSS [training: 0.3095008893743858 | validation: 0.42909702981906683]
	TIME [epoch: 9.08 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3042360814726426		[learning rate: 0.00016263]
	Learning Rate: 0.000162634
	LOSS [training: 0.3042360814726426 | validation: 0.4147815471916775]
	TIME [epoch: 9.07 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31994138311364606		[learning rate: 0.00016204]
	Learning Rate: 0.000162043
	LOSS [training: 0.31994138311364606 | validation: 0.4177777817810697]
	TIME [epoch: 9.08 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093013353156774		[learning rate: 0.00016146]
	Learning Rate: 0.000161455
	LOSS [training: 0.3093013353156774 | validation: 0.4343515333897402]
	TIME [epoch: 9.08 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31456749936236167		[learning rate: 0.00016087]
	Learning Rate: 0.000160869
	LOSS [training: 0.31456749936236167 | validation: 0.39805769336407315]
	TIME [epoch: 9.08 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32953952445204737		[learning rate: 0.00016029]
	Learning Rate: 0.000160286
	LOSS [training: 0.32953952445204737 | validation: 0.43924231960263904]
	TIME [epoch: 9.08 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3121480451696083		[learning rate: 0.0001597]
	Learning Rate: 0.000159704
	LOSS [training: 0.3121480451696083 | validation: 0.4316943092624084]
	TIME [epoch: 9.07 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31118843761985093		[learning rate: 0.00015912]
	Learning Rate: 0.000159124
	LOSS [training: 0.31118843761985093 | validation: 0.39894780400581376]
	TIME [epoch: 9.1 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3244799759824687		[learning rate: 0.00015855]
	Learning Rate: 0.000158547
	LOSS [training: 0.3244799759824687 | validation: 0.4240444459847218]
	TIME [epoch: 9.09 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30985330566822383		[learning rate: 0.00015797]
	Learning Rate: 0.000157972
	LOSS [training: 0.30985330566822383 | validation: 0.43694466891744627]
	TIME [epoch: 9.07 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31334348930847045		[learning rate: 0.0001574]
	Learning Rate: 0.000157398
	LOSS [training: 0.31334348930847045 | validation: 0.41828177684348267]
	TIME [epoch: 9.07 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30541308101155723		[learning rate: 0.00015683]
	Learning Rate: 0.000156827
	LOSS [training: 0.30541308101155723 | validation: 0.387008721920716]
	TIME [epoch: 9.07 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3075584721554028		[learning rate: 0.00015626]
	Learning Rate: 0.000156258
	LOSS [training: 0.3075584721554028 | validation: 0.40054440304003375]
	TIME [epoch: 9.1 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30708949121122414		[learning rate: 0.00015569]
	Learning Rate: 0.000155691
	LOSS [training: 0.30708949121122414 | validation: 0.40034526571969076]
	TIME [epoch: 9.08 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3018879547809893		[learning rate: 0.00015513]
	Learning Rate: 0.000155126
	LOSS [training: 0.3018879547809893 | validation: 0.415865852727505]
	TIME [epoch: 9.08 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30662023562299084		[learning rate: 0.00015456]
	Learning Rate: 0.000154563
	LOSS [training: 0.30662023562299084 | validation: 0.4230158827379695]
	TIME [epoch: 9.08 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3260418181217071		[learning rate: 0.000154]
	Learning Rate: 0.000154002
	LOSS [training: 0.3260418181217071 | validation: 0.4103855352357125]
	TIME [epoch: 9.1 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3096536282943127		[learning rate: 0.00015344]
	Learning Rate: 0.000153443
	LOSS [training: 0.3096536282943127 | validation: 0.3829580688111149]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1249.pth
	Model improved!!!
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33175139648155644		[learning rate: 0.00015289]
	Learning Rate: 0.000152886
	LOSS [training: 0.33175139648155644 | validation: 0.4439718894304565]
	TIME [epoch: 9.08 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.311347219674628		[learning rate: 0.00015233]
	Learning Rate: 0.000152331
	LOSS [training: 0.311347219674628 | validation: 0.40930633953738926]
	TIME [epoch: 9.07 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30227808484823576		[learning rate: 0.00015178]
	Learning Rate: 0.000151779
	LOSS [training: 0.30227808484823576 | validation: 0.4111794257400271]
	TIME [epoch: 9.07 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2983983182962026		[learning rate: 0.00015123]
	Learning Rate: 0.000151228
	LOSS [training: 0.2983983182962026 | validation: 0.42714537998315455]
	TIME [epoch: 9.09 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31027584339545833		[learning rate: 0.00015068]
	Learning Rate: 0.000150679
	LOSS [training: 0.31027584339545833 | validation: 0.43008227080870387]
	TIME [epoch: 9.07 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30292028538851584		[learning rate: 0.00015013]
	Learning Rate: 0.000150132
	LOSS [training: 0.30292028538851584 | validation: 0.44453076459843033]
	TIME [epoch: 9.06 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32022542541749344		[learning rate: 0.00014959]
	Learning Rate: 0.000149587
	LOSS [training: 0.32022542541749344 | validation: 0.432055107642929]
	TIME [epoch: 9.06 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3067213742186545		[learning rate: 0.00014904]
	Learning Rate: 0.000149044
	LOSS [training: 0.3067213742186545 | validation: 0.4167307717475538]
	TIME [epoch: 9.07 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3195937750856931		[learning rate: 0.0001485]
	Learning Rate: 0.000148504
	LOSS [training: 0.3195937750856931 | validation: 0.42127078952660135]
	TIME [epoch: 9.08 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31792316654547137		[learning rate: 0.00014796]
	Learning Rate: 0.000147965
	LOSS [training: 0.31792316654547137 | validation: 0.4227479718721598]
	TIME [epoch: 9.07 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32537812734448834		[learning rate: 0.00014743]
	Learning Rate: 0.000147428
	LOSS [training: 0.32537812734448834 | validation: 0.41378886394315284]
	TIME [epoch: 9.06 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3021208014229292		[learning rate: 0.00014689]
	Learning Rate: 0.000146893
	LOSS [training: 0.3021208014229292 | validation: 0.4141443620036879]
	TIME [epoch: 9.05 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3233289421850755		[learning rate: 0.00014636]
	Learning Rate: 0.00014636
	LOSS [training: 0.3233289421850755 | validation: 0.41883789617045264]
	TIME [epoch: 9.08 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.323568997251192		[learning rate: 0.00014583]
	Learning Rate: 0.000145828
	LOSS [training: 0.323568997251192 | validation: 0.4345943549264797]
	TIME [epoch: 9.07 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3187042237561054		[learning rate: 0.0001453]
	Learning Rate: 0.000145299
	LOSS [training: 0.3187042237561054 | validation: 0.44554919321743636]
	TIME [epoch: 9.07 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3245488652510108		[learning rate: 0.00014477]
	Learning Rate: 0.000144772
	LOSS [training: 0.3245488652510108 | validation: 0.4249837403417237]
	TIME [epoch: 9.07 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30944846520030767		[learning rate: 0.00014425]
	Learning Rate: 0.000144247
	LOSS [training: 0.30944846520030767 | validation: 0.40700178073831894]
	TIME [epoch: 9.08 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3132486841061451		[learning rate: 0.00014372]
	Learning Rate: 0.000143723
	LOSS [training: 0.3132486841061451 | validation: 0.4016822249090784]
	TIME [epoch: 9.09 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30700487004967913		[learning rate: 0.0001432]
	Learning Rate: 0.000143201
	LOSS [training: 0.30700487004967913 | validation: 0.3946530868419855]
	TIME [epoch: 9.07 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.309978777159226		[learning rate: 0.00014268]
	Learning Rate: 0.000142682
	LOSS [training: 0.309978777159226 | validation: 0.397726544671832]
	TIME [epoch: 9.06 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3286300725194516		[learning rate: 0.00014216]
	Learning Rate: 0.000142164
	LOSS [training: 0.3286300725194516 | validation: 0.41306783141693104]
	TIME [epoch: 9.07 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31458303859329934		[learning rate: 0.00014165]
	Learning Rate: 0.000141648
	LOSS [training: 0.31458303859329934 | validation: 0.400733382396364]
	TIME [epoch: 9.07 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3217147869420867		[learning rate: 0.00014113]
	Learning Rate: 0.000141134
	LOSS [training: 0.3217147869420867 | validation: 0.4101963766617769]
	TIME [epoch: 9.09 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3324253980219506		[learning rate: 0.00014062]
	Learning Rate: 0.000140622
	LOSS [training: 0.3324253980219506 | validation: 0.41142591373033327]
	TIME [epoch: 9.06 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30912733465717857		[learning rate: 0.00014011]
	Learning Rate: 0.000140112
	LOSS [training: 0.30912733465717857 | validation: 0.40013084745164507]
	TIME [epoch: 9.05 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32058610967965684		[learning rate: 0.0001396]
	Learning Rate: 0.000139603
	LOSS [training: 0.32058610967965684 | validation: 0.42448738418987014]
	TIME [epoch: 9.06 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3077801324428939		[learning rate: 0.0001391]
	Learning Rate: 0.000139096
	LOSS [training: 0.3077801324428939 | validation: 0.45817724994051007]
	TIME [epoch: 9.08 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31569499213431246		[learning rate: 0.00013859]
	Learning Rate: 0.000138592
	LOSS [training: 0.31569499213431246 | validation: 0.408992470234509]
	TIME [epoch: 9.07 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33333387016362725		[learning rate: 0.00013809]
	Learning Rate: 0.000138089
	LOSS [training: 0.33333387016362725 | validation: 0.41089117620691706]
	TIME [epoch: 9.06 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3096163699924833		[learning rate: 0.00013759]
	Learning Rate: 0.000137587
	LOSS [training: 0.3096163699924833 | validation: 0.3989861486619165]
	TIME [epoch: 9.07 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3196151546106937		[learning rate: 0.00013709]
	Learning Rate: 0.000137088
	LOSS [training: 0.3196151546106937 | validation: 0.39819440375789805]
	TIME [epoch: 9.07 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2986070882645		[learning rate: 0.00013659]
	Learning Rate: 0.000136591
	LOSS [training: 0.2986070882645 | validation: 0.4208895299168428]
	TIME [epoch: 9.08 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3053889588744306		[learning rate: 0.00013609]
	Learning Rate: 0.000136095
	LOSS [training: 0.3053889588744306 | validation: 0.43919961343877567]
	TIME [epoch: 9.07 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3056398176335938		[learning rate: 0.0001356]
	Learning Rate: 0.000135601
	LOSS [training: 0.3056398176335938 | validation: 0.43064464670099734]
	TIME [epoch: 9.05 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29943498341054		[learning rate: 0.00013511]
	Learning Rate: 0.000135109
	LOSS [training: 0.29943498341054 | validation: 0.4182450019942667]
	TIME [epoch: 9.06 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30666879057641355		[learning rate: 0.00013462]
	Learning Rate: 0.000134619
	LOSS [training: 0.30666879057641355 | validation: 0.41999466031631094]
	TIME [epoch: 9.08 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3079398065062895		[learning rate: 0.00013413]
	Learning Rate: 0.00013413
	LOSS [training: 0.3079398065062895 | validation: 0.41500111428042097]
	TIME [epoch: 9.06 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3107600744486124		[learning rate: 0.00013364]
	Learning Rate: 0.000133643
	LOSS [training: 0.3107600744486124 | validation: 0.4014867801477149]
	TIME [epoch: 9.06 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3216668089566327		[learning rate: 0.00013316]
	Learning Rate: 0.000133158
	LOSS [training: 0.3216668089566327 | validation: 0.39906773916793203]
	TIME [epoch: 9.06 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093829640612161		[learning rate: 0.00013268]
	Learning Rate: 0.000132675
	LOSS [training: 0.3093829640612161 | validation: 0.49847389902045197]
	TIME [epoch: 9.05 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31135520586886234		[learning rate: 0.00013219]
	Learning Rate: 0.000132194
	LOSS [training: 0.31135520586886234 | validation: 0.41319958316526023]
	TIME [epoch: 9.09 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30437283072187815		[learning rate: 0.00013171]
	Learning Rate: 0.000131714
	LOSS [training: 0.30437283072187815 | validation: 0.42790522983108614]
	TIME [epoch: 9.06 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32997285336904525		[learning rate: 0.00013124]
	Learning Rate: 0.000131236
	LOSS [training: 0.32997285336904525 | validation: 0.4204857419206036]
	TIME [epoch: 9.06 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31056524958574894		[learning rate: 0.00013076]
	Learning Rate: 0.00013076
	LOSS [training: 0.31056524958574894 | validation: 0.4355746562362465]
	TIME [epoch: 9.06 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3212386822986152		[learning rate: 0.00013029]
	Learning Rate: 0.000130285
	LOSS [training: 0.3212386822986152 | validation: 0.4114667410317144]
	TIME [epoch: 9.07 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3154803993042531		[learning rate: 0.00012981]
	Learning Rate: 0.000129812
	LOSS [training: 0.3154803993042531 | validation: 0.4018018548120893]
	TIME [epoch: 9.08 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3088532058363585		[learning rate: 0.00012934]
	Learning Rate: 0.000129341
	LOSS [training: 0.3088532058363585 | validation: 0.43120463079493765]
	TIME [epoch: 9.05 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30430653100999594		[learning rate: 0.00012887]
	Learning Rate: 0.000128872
	LOSS [training: 0.30430653100999594 | validation: 0.4158686587101355]
	TIME [epoch: 9.06 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3128731768270464		[learning rate: 0.0001284]
	Learning Rate: 0.000128404
	LOSS [training: 0.3128731768270464 | validation: 0.39397696167790114]
	TIME [epoch: 9.06 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3103355769595973		[learning rate: 0.00012794]
	Learning Rate: 0.000127938
	LOSS [training: 0.3103355769595973 | validation: 0.4176680788200089]
	TIME [epoch: 9.07 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3069055487448191		[learning rate: 0.00012747]
	Learning Rate: 0.000127474
	LOSS [training: 0.3069055487448191 | validation: 0.4289960353879668]
	TIME [epoch: 9.06 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3062422584320536		[learning rate: 0.00012701]
	Learning Rate: 0.000127011
	LOSS [training: 0.3062422584320536 | validation: 0.39980757556135094]
	TIME [epoch: 9.06 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3063541203802694		[learning rate: 0.00012655]
	Learning Rate: 0.00012655
	LOSS [training: 0.3063541203802694 | validation: 0.404232107227098]
	TIME [epoch: 9.07 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3076436321019929		[learning rate: 0.00012609]
	Learning Rate: 0.000126091
	LOSS [training: 0.3076436321019929 | validation: 0.42224432415051233]
	TIME [epoch: 9.06 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3120929853443924		[learning rate: 0.00012563]
	Learning Rate: 0.000125633
	LOSS [training: 0.3120929853443924 | validation: 0.39866419053983293]
	TIME [epoch: 9.08 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2995448996067075		[learning rate: 0.00012518]
	Learning Rate: 0.000125178
	LOSS [training: 0.2995448996067075 | validation: 0.3906160933958086]
	TIME [epoch: 9.07 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3077240031358722		[learning rate: 0.00012472]
	Learning Rate: 0.000124723
	LOSS [training: 0.3077240031358722 | validation: 0.40835655147113137]
	TIME [epoch: 9.07 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3132133069458488		[learning rate: 0.00012427]
	Learning Rate: 0.000124271
	LOSS [training: 0.3132133069458488 | validation: 0.414954996471797]
	TIME [epoch: 9.06 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3142794056125391		[learning rate: 0.00012382]
	Learning Rate: 0.00012382
	LOSS [training: 0.3142794056125391 | validation: 0.3811112785928874]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1308.pth
	Model improved!!!
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30846221628313386		[learning rate: 0.00012337]
	Learning Rate: 0.00012337
	LOSS [training: 0.30846221628313386 | validation: 0.40756996609789053]
	TIME [epoch: 9.07 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31699009274852924		[learning rate: 0.00012292]
	Learning Rate: 0.000122923
	LOSS [training: 0.31699009274852924 | validation: 0.3954286445256604]
	TIME [epoch: 9.06 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31010166441751463		[learning rate: 0.00012248]
	Learning Rate: 0.000122476
	LOSS [training: 0.31010166441751463 | validation: 0.37466575255067064]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1311.pth
	Model improved!!!
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3142803048786935		[learning rate: 0.00012203]
	Learning Rate: 0.000122032
	LOSS [training: 0.3142803048786935 | validation: 0.4025951434771739]
	TIME [epoch: 9.07 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30889979632600445		[learning rate: 0.00012159]
	Learning Rate: 0.000121589
	LOSS [training: 0.30889979632600445 | validation: 0.38189998672214703]
	TIME [epoch: 9.09 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3072398268454779		[learning rate: 0.00012115]
	Learning Rate: 0.000121148
	LOSS [training: 0.3072398268454779 | validation: 0.4113499405517248]
	TIME [epoch: 9.06 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31144324344035706		[learning rate: 0.00012071]
	Learning Rate: 0.000120708
	LOSS [training: 0.31144324344035706 | validation: 0.40071773876283123]
	TIME [epoch: 9.06 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3063613952273193		[learning rate: 0.00012027]
	Learning Rate: 0.00012027
	LOSS [training: 0.3063613952273193 | validation: 0.4246315272092236]
	TIME [epoch: 9.06 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135019841927044		[learning rate: 0.00011983]
	Learning Rate: 0.000119834
	LOSS [training: 0.3135019841927044 | validation: 0.444636787062601]
	TIME [epoch: 9.06 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3057666796558076		[learning rate: 0.0001194]
	Learning Rate: 0.000119399
	LOSS [training: 0.3057666796558076 | validation: 0.3951940129043112]
	TIME [epoch: 9.1 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3094442057944038		[learning rate: 0.00011897]
	Learning Rate: 0.000118966
	LOSS [training: 0.3094442057944038 | validation: 0.3973980107556213]
	TIME [epoch: 9.08 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30348513392868376		[learning rate: 0.00011853]
	Learning Rate: 0.000118534
	LOSS [training: 0.30348513392868376 | validation: 0.40303198733458523]
	TIME [epoch: 9.07 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3046547795204539		[learning rate: 0.0001181]
	Learning Rate: 0.000118104
	LOSS [training: 0.3046547795204539 | validation: 0.4120462712245136]
	TIME [epoch: 9.07 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3048775148510895		[learning rate: 0.00011767]
	Learning Rate: 0.000117675
	LOSS [training: 0.3048775148510895 | validation: 0.40424554176111227]
	TIME [epoch: 9.06 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2982736177468478		[learning rate: 0.00011725]
	Learning Rate: 0.000117248
	LOSS [training: 0.2982736177468478 | validation: 0.3923650934524092]
	TIME [epoch: 9.09 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3071810691169331		[learning rate: 0.00011682]
	Learning Rate: 0.000116822
	LOSS [training: 0.3071810691169331 | validation: 0.42368303179930933]
	TIME [epoch: 9.06 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3126065111215613		[learning rate: 0.0001164]
	Learning Rate: 0.000116398
	LOSS [training: 0.3126065111215613 | validation: 0.4268495306282545]
	TIME [epoch: 9.07 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31211203508497226		[learning rate: 0.00011598]
	Learning Rate: 0.000115976
	LOSS [training: 0.31211203508497226 | validation: 0.44525072944853267]
	TIME [epoch: 9.07 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30780808755636563		[learning rate: 0.00011556]
	Learning Rate: 0.000115555
	LOSS [training: 0.30780808755636563 | validation: 0.4556268180518561]
	TIME [epoch: 9.09 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31985760750111153		[learning rate: 0.00011514]
	Learning Rate: 0.000115136
	LOSS [training: 0.31985760750111153 | validation: 0.45446948588707575]
	TIME [epoch: 9.07 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31153826987047734		[learning rate: 0.00011472]
	Learning Rate: 0.000114718
	LOSS [training: 0.31153826987047734 | validation: 0.40748118678289014]
	TIME [epoch: 9.07 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30781103790391035		[learning rate: 0.0001143]
	Learning Rate: 0.000114302
	LOSS [training: 0.30781103790391035 | validation: 0.38517717927751577]
	TIME [epoch: 9.07 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30055838283149383		[learning rate: 0.00011389]
	Learning Rate: 0.000113887
	LOSS [training: 0.30055838283149383 | validation: 0.40524799298277336]
	TIME [epoch: 9.07 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3018223413539857		[learning rate: 0.00011347]
	Learning Rate: 0.000113474
	LOSS [training: 0.3018223413539857 | validation: 0.4145123345832149]
	TIME [epoch: 9.09 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30619544665873427		[learning rate: 0.00011306]
	Learning Rate: 0.000113062
	LOSS [training: 0.30619544665873427 | validation: 0.41814511252748293]
	TIME [epoch: 9.08 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3033764375113749		[learning rate: 0.00011265]
	Learning Rate: 0.000112651
	LOSS [training: 0.3033764375113749 | validation: 0.4137009967333025]
	TIME [epoch: 9.06 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29631180482696645		[learning rate: 0.00011224]
	Learning Rate: 0.000112243
	LOSS [training: 0.29631180482696645 | validation: 0.4293621166542567]
	TIME [epoch: 9.06 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2981760540303848		[learning rate: 0.00011184]
	Learning Rate: 0.000111835
	LOSS [training: 0.2981760540303848 | validation: 0.4077632430352676]
	TIME [epoch: 9.09 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31824999361257217		[learning rate: 0.00011143]
	Learning Rate: 0.000111429
	LOSS [training: 0.31824999361257217 | validation: 0.4306938726000872]
	TIME [epoch: 9.08 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31580623956255477		[learning rate: 0.00011103]
	Learning Rate: 0.000111025
	LOSS [training: 0.31580623956255477 | validation: 0.3970129629134086]
	TIME [epoch: 9.08 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31313049331865933		[learning rate: 0.00011062]
	Learning Rate: 0.000110622
	LOSS [training: 0.31313049331865933 | validation: 0.4199018924545712]
	TIME [epoch: 9.07 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31127467574348877		[learning rate: 0.00011022]
	Learning Rate: 0.000110221
	LOSS [training: 0.31127467574348877 | validation: 0.4241672593786612]
	TIME [epoch: 9.08 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30099501975655246		[learning rate: 0.00010982]
	Learning Rate: 0.000109821
	LOSS [training: 0.30099501975655246 | validation: 0.40028114241680396]
	TIME [epoch: 9.09 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3119526551149013		[learning rate: 0.00010942]
	Learning Rate: 0.000109422
	LOSS [training: 0.3119526551149013 | validation: 0.4302069955803611]
	TIME [epoch: 9.07 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3120518405570288		[learning rate: 0.00010903]
	Learning Rate: 0.000109025
	LOSS [training: 0.3120518405570288 | validation: 0.40581159570777164]
	TIME [epoch: 9.07 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30230641354315		[learning rate: 0.00010863]
	Learning Rate: 0.000108629
	LOSS [training: 0.30230641354315 | validation: 0.3885828836305669]
	TIME [epoch: 9.08 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3109473418224972		[learning rate: 0.00010824]
	Learning Rate: 0.000108235
	LOSS [training: 0.3109473418224972 | validation: 0.4078847116125849]
	TIME [epoch: 9.08 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30576617615065704		[learning rate: 0.00010784]
	Learning Rate: 0.000107842
	LOSS [training: 0.30576617615065704 | validation: 0.4031955233144414]
	TIME [epoch: 9.09 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30910558620238776		[learning rate: 0.00010745]
	Learning Rate: 0.000107451
	LOSS [training: 0.30910558620238776 | validation: 0.4366891698782442]
	TIME [epoch: 9.08 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3105793553894364		[learning rate: 0.00010706]
	Learning Rate: 0.000107061
	LOSS [training: 0.3105793553894364 | validation: 0.40474067021362187]
	TIME [epoch: 9.07 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31230336471596387		[learning rate: 0.00010667]
	Learning Rate: 0.000106673
	LOSS [training: 0.31230336471596387 | validation: 0.41188723303701463]
	TIME [epoch: 9.07 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.308562374111157		[learning rate: 0.00010629]
	Learning Rate: 0.000106285
	LOSS [training: 0.308562374111157 | validation: 0.4046864307738117]
	TIME [epoch: 9.09 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30741167810923653		[learning rate: 0.0001059]
	Learning Rate: 0.0001059
	LOSS [training: 0.30741167810923653 | validation: 0.3993035415084342]
	TIME [epoch: 9.08 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3116729045258395		[learning rate: 0.00010552]
	Learning Rate: 0.000105515
	LOSS [training: 0.3116729045258395 | validation: 0.41681769512897077]
	TIME [epoch: 9.08 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3067085133991847		[learning rate: 0.00010513]
	Learning Rate: 0.000105132
	LOSS [training: 0.3067085133991847 | validation: 0.44059881432437353]
	TIME [epoch: 9.07 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30297187013406457		[learning rate: 0.00010475]
	Learning Rate: 0.000104751
	LOSS [training: 0.30297187013406457 | validation: 0.4073606563695486]
	TIME [epoch: 9.06 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30132354760008667		[learning rate: 0.00010437]
	Learning Rate: 0.000104371
	LOSS [training: 0.30132354760008667 | validation: 0.4166066943393665]
	TIME [epoch: 9.09 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976102613278348		[learning rate: 0.00010399]
	Learning Rate: 0.000103992
	LOSS [training: 0.2976102613278348 | validation: 0.3886795047528381]
	TIME [epoch: 9.07 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30639615432643785		[learning rate: 0.00010361]
	Learning Rate: 0.000103615
	LOSS [training: 0.30639615432643785 | validation: 0.405315579566964]
	TIME [epoch: 9.07 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3011780518191684		[learning rate: 0.00010324]
	Learning Rate: 0.000103239
	LOSS [training: 0.3011780518191684 | validation: 0.38670265255172637]
	TIME [epoch: 9.07 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29787308218542546		[learning rate: 0.00010286]
	Learning Rate: 0.000102864
	LOSS [training: 0.29787308218542546 | validation: 0.4076016130614835]
	TIME [epoch: 9.09 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3016568218697648		[learning rate: 0.00010249]
	Learning Rate: 0.000102491
	LOSS [training: 0.3016568218697648 | validation: 0.404768483074393]
	TIME [epoch: 9.07 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30525022824372955		[learning rate: 0.00010212]
	Learning Rate: 0.000102119
	LOSS [training: 0.30525022824372955 | validation: 0.40744067749413354]
	TIME [epoch: 9.07 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2949084459879875		[learning rate: 0.00010175]
	Learning Rate: 0.000101748
	LOSS [training: 0.2949084459879875 | validation: 0.4192083727686034]
	TIME [epoch: 9.06 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29694928988047176		[learning rate: 0.00010138]
	Learning Rate: 0.000101379
	LOSS [training: 0.29694928988047176 | validation: 0.4171114228139492]
	TIME [epoch: 9.06 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30379305437256926		[learning rate: 0.00010101]
	Learning Rate: 0.000101011
	LOSS [training: 0.30379305437256926 | validation: 0.42181811753583487]
	TIME [epoch: 9.08 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28759521702915164		[learning rate: 0.00010064]
	Learning Rate: 0.000100644
	LOSS [training: 0.28759521702915164 | validation: 0.39266768374101224]
	TIME [epoch: 9.06 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3051338158972928		[learning rate: 0.00010028]
	Learning Rate: 0.000100279
	LOSS [training: 0.3051338158972928 | validation: 0.3913849854130499]
	TIME [epoch: 9.06 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3014649692625821		[learning rate: 9.9915e-05]
	Learning Rate: 9.99152e-05
	LOSS [training: 0.3014649692625821 | validation: 0.4117210205294492]
	TIME [epoch: 9.07 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30627717678433136		[learning rate: 9.9553e-05]
	Learning Rate: 9.95526e-05
	LOSS [training: 0.30627717678433136 | validation: 0.3883139442473563]
	TIME [epoch: 9.08 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30273005446899054		[learning rate: 9.9191e-05]
	Learning Rate: 9.91913e-05
	LOSS [training: 0.30273005446899054 | validation: 0.404903045032066]
	TIME [epoch: 9.07 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3014805118625819		[learning rate: 9.8831e-05]
	Learning Rate: 9.88314e-05
	LOSS [training: 0.3014805118625819 | validation: 0.366608621126233]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1370.pth
	Model improved!!!
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3032195078739781		[learning rate: 9.8473e-05]
	Learning Rate: 9.84727e-05
	LOSS [training: 0.3032195078739781 | validation: 0.39715325355678677]
	TIME [epoch: 9.07 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30329228761319293		[learning rate: 9.8115e-05]
	Learning Rate: 9.81153e-05
	LOSS [training: 0.30329228761319293 | validation: 0.4176881050268988]
	TIME [epoch: 9.06 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3018721512288698		[learning rate: 9.7759e-05]
	Learning Rate: 9.77592e-05
	LOSS [training: 0.3018721512288698 | validation: 0.40306383583148947]
	TIME [epoch: 9.08 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2937484360594119		[learning rate: 9.7404e-05]
	Learning Rate: 9.74045e-05
	LOSS [training: 0.2937484360594119 | validation: 0.3913769082393037]
	TIME [epoch: 9.07 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2943451836082801		[learning rate: 9.7051e-05]
	Learning Rate: 9.7051e-05
	LOSS [training: 0.2943451836082801 | validation: 0.38575552822089165]
	TIME [epoch: 9.06 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2986194720697646		[learning rate: 9.6699e-05]
	Learning Rate: 9.66988e-05
	LOSS [training: 0.2986194720697646 | validation: 0.4137186970867962]
	TIME [epoch: 9.07 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2932572295519169		[learning rate: 9.6348e-05]
	Learning Rate: 9.63479e-05
	LOSS [training: 0.2932572295519169 | validation: 0.3943853569586059]
	TIME [epoch: 9.07 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31165921491284027		[learning rate: 9.5998e-05]
	Learning Rate: 9.59982e-05
	LOSS [training: 0.31165921491284027 | validation: 0.40132665564045367]
	TIME [epoch: 9.08 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30112110190007835		[learning rate: 9.565e-05]
	Learning Rate: 9.56499e-05
	LOSS [training: 0.30112110190007835 | validation: 0.4302903618903076]
	TIME [epoch: 9.07 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2980406203912746		[learning rate: 9.5303e-05]
	Learning Rate: 9.53027e-05
	LOSS [training: 0.2980406203912746 | validation: 0.4011176167111849]
	TIME [epoch: 9.06 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.300806802866657		[learning rate: 9.4957e-05]
	Learning Rate: 9.49569e-05
	LOSS [training: 0.300806802866657 | validation: 0.38644759227795245]
	TIME [epoch: 9.06 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30434830366214155		[learning rate: 9.4612e-05]
	Learning Rate: 9.46122e-05
	LOSS [training: 0.30434830366214155 | validation: 0.4667268824714822]
	TIME [epoch: 9.07 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3128281953040726		[learning rate: 9.4269e-05]
	Learning Rate: 9.42689e-05
	LOSS [training: 0.3128281953040726 | validation: 0.4110986804749316]
	TIME [epoch: 9.08 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30215059038682596		[learning rate: 9.3927e-05]
	Learning Rate: 9.39268e-05
	LOSS [training: 0.30215059038682596 | validation: 0.39455383522569737]
	TIME [epoch: 9.07 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29866862681859974		[learning rate: 9.3586e-05]
	Learning Rate: 9.35859e-05
	LOSS [training: 0.29866862681859974 | validation: 0.4188496282812776]
	TIME [epoch: 9.07 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30770023893161785		[learning rate: 9.3246e-05]
	Learning Rate: 9.32463e-05
	LOSS [training: 0.30770023893161785 | validation: 0.3966717878626585]
	TIME [epoch: 9.07 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2979690357945456		[learning rate: 9.2908e-05]
	Learning Rate: 9.29079e-05
	LOSS [training: 0.2979690357945456 | validation: 0.44567046864032195]
	TIME [epoch: 9.08 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30228959918500126		[learning rate: 9.2571e-05]
	Learning Rate: 9.25707e-05
	LOSS [training: 0.30228959918500126 | validation: 0.3969166953144278]
	TIME [epoch: 9.07 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954156520065186		[learning rate: 9.2235e-05]
	Learning Rate: 9.22348e-05
	LOSS [training: 0.2954156520065186 | validation: 0.4010632403480196]
	TIME [epoch: 9.06 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3012814164581588		[learning rate: 9.19e-05]
	Learning Rate: 9.19001e-05
	LOSS [training: 0.3012814164581588 | validation: 0.4470787668674271]
	TIME [epoch: 9.07 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30994397319855		[learning rate: 9.1567e-05]
	Learning Rate: 9.15665e-05
	LOSS [training: 0.30994397319855 | validation: 0.42103088460810556]
	TIME [epoch: 9.05 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3021765564232799		[learning rate: 9.1234e-05]
	Learning Rate: 9.12343e-05
	LOSS [training: 0.3021765564232799 | validation: 0.4192385285781406]
	TIME [epoch: 9.09 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2906135018312256		[learning rate: 9.0903e-05]
	Learning Rate: 9.09031e-05
	LOSS [training: 0.2906135018312256 | validation: 0.3995738542712939]
	TIME [epoch: 9.06 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2973117685444999		[learning rate: 9.0573e-05]
	Learning Rate: 9.05733e-05
	LOSS [training: 0.2973117685444999 | validation: 0.4044861750352303]
	TIME [epoch: 9.07 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3044984464903269		[learning rate: 9.0245e-05]
	Learning Rate: 9.02446e-05
	LOSS [training: 0.3044984464903269 | validation: 0.40801456857619656]
	TIME [epoch: 9.06 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.302261636353809		[learning rate: 8.9917e-05]
	Learning Rate: 8.99171e-05
	LOSS [training: 0.302261636353809 | validation: 0.42181725846565843]
	TIME [epoch: 9.09 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30542477544934604		[learning rate: 8.9591e-05]
	Learning Rate: 8.95908e-05
	LOSS [training: 0.30542477544934604 | validation: 0.41173931726225077]
	TIME [epoch: 9.09 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3059594123277619		[learning rate: 8.9266e-05]
	Learning Rate: 8.92656e-05
	LOSS [training: 0.3059594123277619 | validation: 0.4182707652349729]
	TIME [epoch: 9.08 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3137623703917502		[learning rate: 8.8942e-05]
	Learning Rate: 8.89417e-05
	LOSS [training: 0.3137623703917502 | validation: 0.3989332433169364]
	TIME [epoch: 9.07 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3074937152513561		[learning rate: 8.8619e-05]
	Learning Rate: 8.86189e-05
	LOSS [training: 0.3074937152513561 | validation: 0.4210352354188312]
	TIME [epoch: 9.07 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3144038315302409		[learning rate: 8.8297e-05]
	Learning Rate: 8.82973e-05
	LOSS [training: 0.3144038315302409 | validation: 0.3864631237446657]
	TIME [epoch: 9.07 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135699973338809		[learning rate: 8.7977e-05]
	Learning Rate: 8.79769e-05
	LOSS [training: 0.3135699973338809 | validation: 0.43902565248937864]
	TIME [epoch: 9.07 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30217218116012184		[learning rate: 8.7658e-05]
	Learning Rate: 8.76576e-05
	LOSS [training: 0.30217218116012184 | validation: 0.416098743935582]
	TIME [epoch: 9.07 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3002783745384022		[learning rate: 8.7339e-05]
	Learning Rate: 8.73395e-05
	LOSS [training: 0.3002783745384022 | validation: 0.4450646947603127]
	TIME [epoch: 9.06 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3123740024883273		[learning rate: 8.7023e-05]
	Learning Rate: 8.70225e-05
	LOSS [training: 0.3123740024883273 | validation: 0.42277920454537465]
	TIME [epoch: 9.09 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2981406689472996		[learning rate: 8.6707e-05]
	Learning Rate: 8.67067e-05
	LOSS [training: 0.2981406689472996 | validation: 0.41597194690817835]
	TIME [epoch: 9.07 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29178212635190987		[learning rate: 8.6392e-05]
	Learning Rate: 8.63921e-05
	LOSS [training: 0.29178212635190987 | validation: 0.4173539751692566]
	TIME [epoch: 9.06 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30034712268405095		[learning rate: 8.6079e-05]
	Learning Rate: 8.60785e-05
	LOSS [training: 0.30034712268405095 | validation: 0.43090904206028424]
	TIME [epoch: 9.06 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3001288085675241		[learning rate: 8.5766e-05]
	Learning Rate: 8.57661e-05
	LOSS [training: 0.3001288085675241 | validation: 0.4184313292010248]
	TIME [epoch: 9.07 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2941753723669619		[learning rate: 8.5455e-05]
	Learning Rate: 8.54549e-05
	LOSS [training: 0.2941753723669619 | validation: 0.40509424414130746]
	TIME [epoch: 9.09 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29785280127660696		[learning rate: 8.5145e-05]
	Learning Rate: 8.51448e-05
	LOSS [training: 0.29785280127660696 | validation: 0.4124795315592692]
	TIME [epoch: 9.07 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3087643129205318		[learning rate: 8.4836e-05]
	Learning Rate: 8.48358e-05
	LOSS [training: 0.3087643129205318 | validation: 0.418139359779947]
	TIME [epoch: 9.07 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892620771043345		[learning rate: 8.4528e-05]
	Learning Rate: 8.45279e-05
	LOSS [training: 0.2892620771043345 | validation: 0.3988452748843445]
	TIME [epoch: 9.06 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3086793936723388		[learning rate: 8.4221e-05]
	Learning Rate: 8.42211e-05
	LOSS [training: 0.3086793936723388 | validation: 0.4068532711477897]
	TIME [epoch: 9.07 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30594315338260936		[learning rate: 8.3916e-05]
	Learning Rate: 8.39155e-05
	LOSS [training: 0.30594315338260936 | validation: 0.41753803882905693]
	TIME [epoch: 9.06 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30779372053047094		[learning rate: 8.3611e-05]
	Learning Rate: 8.3611e-05
	LOSS [training: 0.30779372053047094 | validation: 0.424563304398758]
	TIME [epoch: 9.06 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3036515754175055		[learning rate: 8.3308e-05]
	Learning Rate: 8.33075e-05
	LOSS [training: 0.3036515754175055 | validation: 0.3975589896836755]
	TIME [epoch: 9.07 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30611104471391987		[learning rate: 8.3005e-05]
	Learning Rate: 8.30052e-05
	LOSS [training: 0.30611104471391987 | validation: 0.42234193564446687]
	TIME [epoch: 9.08 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3005824214509115		[learning rate: 8.2704e-05]
	Learning Rate: 8.2704e-05
	LOSS [training: 0.3005824214509115 | validation: 0.43488725960870966]
	TIME [epoch: 9.08 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30378949164162766		[learning rate: 8.2404e-05]
	Learning Rate: 8.24038e-05
	LOSS [training: 0.30378949164162766 | validation: 0.42756553841647144]
	TIME [epoch: 9.06 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959411345648872		[learning rate: 8.2105e-05]
	Learning Rate: 8.21048e-05
	LOSS [training: 0.2959411345648872 | validation: 0.43673808971861666]
	TIME [epoch: 9.06 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3019743436702699		[learning rate: 8.1807e-05]
	Learning Rate: 8.18068e-05
	LOSS [training: 0.3019743436702699 | validation: 0.4005788299245349]
	TIME [epoch: 9.06 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3052827798757821		[learning rate: 8.151e-05]
	Learning Rate: 8.15099e-05
	LOSS [training: 0.3052827798757821 | validation: 0.4294872592765994]
	TIME [epoch: 9.07 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30290754132139636		[learning rate: 8.1214e-05]
	Learning Rate: 8.12142e-05
	LOSS [training: 0.30290754132139636 | validation: 0.42070903392217757]
	TIME [epoch: 9.09 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30893108325126734		[learning rate: 8.0919e-05]
	Learning Rate: 8.09194e-05
	LOSS [training: 0.30893108325126734 | validation: 0.45334491494986373]
	TIME [epoch: 9.06 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30448435444351707		[learning rate: 8.0626e-05]
	Learning Rate: 8.06257e-05
	LOSS [training: 0.30448435444351707 | validation: 0.4078025347693993]
	TIME [epoch: 9.06 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3099587115673264		[learning rate: 8.0333e-05]
	Learning Rate: 8.03331e-05
	LOSS [training: 0.3099587115673264 | validation: 0.40851814996674457]
	TIME [epoch: 9.07 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30640795438660784		[learning rate: 8.0042e-05]
	Learning Rate: 8.00416e-05
	LOSS [training: 0.30640795438660784 | validation: 0.3970248950488124]
	TIME [epoch: 9.08 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2985132517018543		[learning rate: 7.9751e-05]
	Learning Rate: 7.97511e-05
	LOSS [training: 0.2985132517018543 | validation: 0.40106360379652184]
	TIME [epoch: 9.07 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2992627979600379		[learning rate: 7.9462e-05]
	Learning Rate: 7.94617e-05
	LOSS [training: 0.2992627979600379 | validation: 0.41591776084324406]
	TIME [epoch: 9.07 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.299467794123352		[learning rate: 7.9173e-05]
	Learning Rate: 7.91733e-05
	LOSS [training: 0.299467794123352 | validation: 0.4192349761033711]
	TIME [epoch: 9.06 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976880363408986		[learning rate: 7.8886e-05]
	Learning Rate: 7.8886e-05
	LOSS [training: 0.2976880363408986 | validation: 0.41833391416447674]
	TIME [epoch: 9.07 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3001758532828766		[learning rate: 7.86e-05]
	Learning Rate: 7.85997e-05
	LOSS [training: 0.3001758532828766 | validation: 0.4221532403052269]
	TIME [epoch: 9.08 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30376275520215273		[learning rate: 7.8315e-05]
	Learning Rate: 7.83145e-05
	LOSS [training: 0.30376275520215273 | validation: 0.425834079783053]
	TIME [epoch: 9.07 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30736156521333324		[learning rate: 7.803e-05]
	Learning Rate: 7.80303e-05
	LOSS [training: 0.30736156521333324 | validation: 0.3890314377541293]
	TIME [epoch: 9.07 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2936197853554533		[learning rate: 7.7747e-05]
	Learning Rate: 7.77471e-05
	LOSS [training: 0.2936197853554533 | validation: 0.4064458075741417]
	TIME [epoch: 9.07 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2930379014969039		[learning rate: 7.7465e-05]
	Learning Rate: 7.7465e-05
	LOSS [training: 0.2930379014969039 | validation: 0.4175003689709153]
	TIME [epoch: 9.08 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.297944762311608		[learning rate: 7.7184e-05]
	Learning Rate: 7.71838e-05
	LOSS [training: 0.297944762311608 | validation: 0.4060429182034736]
	TIME [epoch: 9.07 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3033889295395809		[learning rate: 7.6904e-05]
	Learning Rate: 7.69037e-05
	LOSS [training: 0.3033889295395809 | validation: 0.37493620247382164]
	TIME [epoch: 9.06 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29071063253831475		[learning rate: 7.6625e-05]
	Learning Rate: 7.66246e-05
	LOSS [training: 0.29071063253831475 | validation: 0.39755520083039975]
	TIME [epoch: 9.07 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2902529135845364		[learning rate: 7.6347e-05]
	Learning Rate: 7.63466e-05
	LOSS [training: 0.2902529135845364 | validation: 0.40001301354737295]
	TIME [epoch: 9.07 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3070104557032058		[learning rate: 7.607e-05]
	Learning Rate: 7.60695e-05
	LOSS [training: 0.3070104557032058 | validation: 0.40774606727273555]
	TIME [epoch: 9.09 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29325745296851635		[learning rate: 7.5793e-05]
	Learning Rate: 7.57935e-05
	LOSS [training: 0.29325745296851635 | validation: 0.3888076942704553]
	TIME [epoch: 9.06 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3020193631627355		[learning rate: 7.5518e-05]
	Learning Rate: 7.55184e-05
	LOSS [training: 0.3020193631627355 | validation: 0.38280092091083506]
	TIME [epoch: 9.06 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3028310057919789		[learning rate: 7.5244e-05]
	Learning Rate: 7.52443e-05
	LOSS [training: 0.3028310057919789 | validation: 0.3770098698139284]
	TIME [epoch: 9.07 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29746749179959225		[learning rate: 7.4971e-05]
	Learning Rate: 7.49712e-05
	LOSS [training: 0.29746749179959225 | validation: 0.38150391773982]
	TIME [epoch: 9.08 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2973622091804556		[learning rate: 7.4699e-05]
	Learning Rate: 7.46992e-05
	LOSS [training: 0.2973622091804556 | validation: 0.3989143263582673]
	TIME [epoch: 9.07 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29251311538728886		[learning rate: 7.4428e-05]
	Learning Rate: 7.44281e-05
	LOSS [training: 0.29251311538728886 | validation: 0.38510395985465273]
	TIME [epoch: 9.07 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29875545771189355		[learning rate: 7.4158e-05]
	Learning Rate: 7.4158e-05
	LOSS [training: 0.29875545771189355 | validation: 0.4000377410067898]
	TIME [epoch: 9.07 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29743371385048384		[learning rate: 7.3889e-05]
	Learning Rate: 7.38889e-05
	LOSS [training: 0.29743371385048384 | validation: 0.40488266727404676]
	TIME [epoch: 9.08 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3049608511594545		[learning rate: 7.3621e-05]
	Learning Rate: 7.36207e-05
	LOSS [training: 0.3049608511594545 | validation: 0.3877432251518003]
	TIME [epoch: 9.09 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2962552514970153		[learning rate: 7.3354e-05]
	Learning Rate: 7.33536e-05
	LOSS [training: 0.2962552514970153 | validation: 0.40515078399025417]
	TIME [epoch: 9.07 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954024214552851		[learning rate: 7.3087e-05]
	Learning Rate: 7.30873e-05
	LOSS [training: 0.2954024214552851 | validation: 0.40793451899261857]
	TIME [epoch: 9.07 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3002385241927331		[learning rate: 7.2822e-05]
	Learning Rate: 7.28221e-05
	LOSS [training: 0.3002385241927331 | validation: 0.3865058407692923]
	TIME [epoch: 9.06 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976400839313048		[learning rate: 7.2558e-05]
	Learning Rate: 7.25578e-05
	LOSS [training: 0.2976400839313048 | validation: 0.40387397630749095]
	TIME [epoch: 9.08 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2978861563695042		[learning rate: 7.2295e-05]
	Learning Rate: 7.22945e-05
	LOSS [training: 0.2978861563695042 | validation: 0.39524158680676835]
	TIME [epoch: 9.1 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2929031816337101		[learning rate: 7.2032e-05]
	Learning Rate: 7.20321e-05
	LOSS [training: 0.2929031816337101 | validation: 0.42519332972266927]
	TIME [epoch: 9.07 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3037022124137042		[learning rate: 7.1771e-05]
	Learning Rate: 7.17707e-05
	LOSS [training: 0.3037022124137042 | validation: 0.40569377968517656]
	TIME [epoch: 9.07 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29500583211621434		[learning rate: 7.151e-05]
	Learning Rate: 7.15103e-05
	LOSS [training: 0.29500583211621434 | validation: 0.4016298694363239]
	TIME [epoch: 9.06 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29730798517347273		[learning rate: 7.1251e-05]
	Learning Rate: 7.12508e-05
	LOSS [training: 0.29730798517347273 | validation: 0.3951997714224058]
	TIME [epoch: 9.08 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28981069179319247		[learning rate: 7.0992e-05]
	Learning Rate: 7.09922e-05
	LOSS [training: 0.28981069179319247 | validation: 0.40108222482443]
	TIME [epoch: 9.06 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30416290787480305		[learning rate: 7.0735e-05]
	Learning Rate: 7.07345e-05
	LOSS [training: 0.30416290787480305 | validation: 0.38984843229295685]
	TIME [epoch: 9.08 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30047515854400897		[learning rate: 7.0478e-05]
	Learning Rate: 7.04778e-05
	LOSS [training: 0.30047515854400897 | validation: 0.37127193786076923]
	TIME [epoch: 9.07 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2947083762385106		[learning rate: 7.0222e-05]
	Learning Rate: 7.02221e-05
	LOSS [training: 0.2947083762385106 | validation: 0.42180161254810583]
	TIME [epoch: 9.08 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3052330064002465		[learning rate: 6.9967e-05]
	Learning Rate: 6.99672e-05
	LOSS [training: 0.3052330064002465 | validation: 0.4450828052446137]
	TIME [epoch: 9.09 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29082562142123003		[learning rate: 6.9713e-05]
	Learning Rate: 6.97133e-05
	LOSS [training: 0.29082562142123003 | validation: 0.41931509288255947]
	TIME [epoch: 9.07 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.292748069523251		[learning rate: 6.946e-05]
	Learning Rate: 6.94603e-05
	LOSS [training: 0.292748069523251 | validation: 0.406490417000899]
	TIME [epoch: 9.06 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2986737069426123		[learning rate: 6.9208e-05]
	Learning Rate: 6.92083e-05
	LOSS [training: 0.2986737069426123 | validation: 0.3874904824042029]
	TIME [epoch: 9.06 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29687578563296657		[learning rate: 6.8957e-05]
	Learning Rate: 6.89571e-05
	LOSS [training: 0.29687578563296657 | validation: 0.3858046508686495]
	TIME [epoch: 9.08 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30105408786670035		[learning rate: 6.8707e-05]
	Learning Rate: 6.87068e-05
	LOSS [training: 0.30105408786670035 | validation: 0.4014105919811096]
	TIME [epoch: 9.06 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29853017690875694		[learning rate: 6.8457e-05]
	Learning Rate: 6.84575e-05
	LOSS [training: 0.29853017690875694 | validation: 0.4030926231190653]
	TIME [epoch: 9.06 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30481733963855523		[learning rate: 6.8209e-05]
	Learning Rate: 6.82091e-05
	LOSS [training: 0.30481733963855523 | validation: 0.4055704097301602]
	TIME [epoch: 9.06 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2943878976936706		[learning rate: 6.7962e-05]
	Learning Rate: 6.79615e-05
	LOSS [training: 0.2943878976936706 | validation: 0.3940155619383239]
	TIME [epoch: 9.07 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29586628273258475		[learning rate: 6.7715e-05]
	Learning Rate: 6.77149e-05
	LOSS [training: 0.29586628273258475 | validation: 0.39123239163896895]
	TIME [epoch: 9.08 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2994149176147279		[learning rate: 6.7469e-05]
	Learning Rate: 6.74692e-05
	LOSS [training: 0.2994149176147279 | validation: 0.39524845665156255]
	TIME [epoch: 9.07 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29391725710249184		[learning rate: 6.7224e-05]
	Learning Rate: 6.72243e-05
	LOSS [training: 0.29391725710249184 | validation: 0.43744544808334795]
	TIME [epoch: 9.07 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3079817546224888		[learning rate: 6.698e-05]
	Learning Rate: 6.69804e-05
	LOSS [training: 0.3079817546224888 | validation: 0.38596461151949496]
	TIME [epoch: 9.05 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30169050353150384		[learning rate: 6.6737e-05]
	Learning Rate: 6.67373e-05
	LOSS [training: 0.30169050353150384 | validation: 0.39315860306091144]
	TIME [epoch: 9.08 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3032040890615676		[learning rate: 6.6495e-05]
	Learning Rate: 6.64951e-05
	LOSS [training: 0.3032040890615676 | validation: 0.39314893719817484]
	TIME [epoch: 9.08 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3018083156205739		[learning rate: 6.6254e-05]
	Learning Rate: 6.62538e-05
	LOSS [training: 0.3018083156205739 | validation: 0.39540764634189407]
	TIME [epoch: 9.06 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3037311093473895		[learning rate: 6.6013e-05]
	Learning Rate: 6.60133e-05
	LOSS [training: 0.3037311093473895 | validation: 0.4132881006796988]
	TIME [epoch: 9.06 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2952773230735838		[learning rate: 6.5774e-05]
	Learning Rate: 6.57738e-05
	LOSS [training: 0.2952773230735838 | validation: 0.4090807375566657]
	TIME [epoch: 9.05 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31376014008003544		[learning rate: 6.5535e-05]
	Learning Rate: 6.55351e-05
	LOSS [training: 0.31376014008003544 | validation: 0.3893367379676711]
	TIME [epoch: 9.08 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2933703191196936		[learning rate: 6.5297e-05]
	Learning Rate: 6.52972e-05
	LOSS [training: 0.2933703191196936 | validation: 0.4023170953171971]
	TIME [epoch: 9.06 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2972966283203092		[learning rate: 6.506e-05]
	Learning Rate: 6.50603e-05
	LOSS [training: 0.2972966283203092 | validation: 0.406377207637841]
	TIME [epoch: 9.06 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3074254781128681		[learning rate: 6.4824e-05]
	Learning Rate: 6.48242e-05
	LOSS [training: 0.3074254781128681 | validation: 0.4084145463120866]
	TIME [epoch: 9.05 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.293321309767226		[learning rate: 6.4589e-05]
	Learning Rate: 6.45889e-05
	LOSS [training: 0.293321309767226 | validation: 0.39705733967868473]
	TIME [epoch: 9.06 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2969547212945304		[learning rate: 6.4354e-05]
	Learning Rate: 6.43545e-05
	LOSS [training: 0.2969547212945304 | validation: 0.4057391561292574]
	TIME [epoch: 9.09 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28885582360196754		[learning rate: 6.4121e-05]
	Learning Rate: 6.4121e-05
	LOSS [training: 0.28885582360196754 | validation: 0.39486827485713005]
	TIME [epoch: 9.07 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.308793565348181		[learning rate: 6.3888e-05]
	Learning Rate: 6.38883e-05
	LOSS [training: 0.308793565348181 | validation: 0.43806994616486056]
	TIME [epoch: 9.06 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29176689887854257		[learning rate: 6.3656e-05]
	Learning Rate: 6.36564e-05
	LOSS [training: 0.29176689887854257 | validation: 0.40337772087517404]
	TIME [epoch: 9.06 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2919579545619129		[learning rate: 6.3425e-05]
	Learning Rate: 6.34254e-05
	LOSS [training: 0.2919579545619129 | validation: 0.3809516752790532]
	TIME [epoch: 9.08 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3010042462058345		[learning rate: 6.3195e-05]
	Learning Rate: 6.31952e-05
	LOSS [training: 0.3010042462058345 | validation: 0.400141126855658]
	TIME [epoch: 9.07 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29345815793079716		[learning rate: 6.2966e-05]
	Learning Rate: 6.29659e-05
	LOSS [training: 0.29345815793079716 | validation: 0.39264680301339766]
	TIME [epoch: 9.06 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959811348457388		[learning rate: 6.2737e-05]
	Learning Rate: 6.27374e-05
	LOSS [training: 0.2959811348457388 | validation: 0.3993782217059132]
	TIME [epoch: 9.06 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2988692655385523		[learning rate: 6.251e-05]
	Learning Rate: 6.25097e-05
	LOSS [training: 0.2988692655385523 | validation: 0.3942064670003008]
	TIME [epoch: 9.06 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29505490279562036		[learning rate: 6.2283e-05]
	Learning Rate: 6.22828e-05
	LOSS [training: 0.29505490279562036 | validation: 0.3929120442585946]
	TIME [epoch: 9.08 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3002946327710691		[learning rate: 6.2057e-05]
	Learning Rate: 6.20568e-05
	LOSS [training: 0.3002946327710691 | validation: 0.4138365975399926]
	TIME [epoch: 9.06 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.301023525844103		[learning rate: 6.1832e-05]
	Learning Rate: 6.18316e-05
	LOSS [training: 0.301023525844103 | validation: 0.3952679792807332]
	TIME [epoch: 9.06 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30730314079913706		[learning rate: 6.1607e-05]
	Learning Rate: 6.16072e-05
	LOSS [training: 0.30730314079913706 | validation: 0.4028963353041755]
	TIME [epoch: 9.06 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2999475556795105		[learning rate: 6.1384e-05]
	Learning Rate: 6.13836e-05
	LOSS [training: 0.2999475556795105 | validation: 0.39110339091797797]
	TIME [epoch: 9.07 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2975990214250293		[learning rate: 6.1161e-05]
	Learning Rate: 6.11609e-05
	LOSS [training: 0.2975990214250293 | validation: 0.41267550074033266]
	TIME [epoch: 9.08 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30284233983911146		[learning rate: 6.0939e-05]
	Learning Rate: 6.09389e-05
	LOSS [training: 0.30284233983911146 | validation: 0.3688537524279275]
	TIME [epoch: 9.07 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30323976905402905		[learning rate: 6.0718e-05]
	Learning Rate: 6.07178e-05
	LOSS [training: 0.30323976905402905 | validation: 0.39946734681091656]
	TIME [epoch: 9.06 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2833079907477465		[learning rate: 6.0497e-05]
	Learning Rate: 6.04974e-05
	LOSS [training: 0.2833079907477465 | validation: 0.4008283422753287]
	TIME [epoch: 9.06 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30049335677211175		[learning rate: 6.0278e-05]
	Learning Rate: 6.02779e-05
	LOSS [training: 0.30049335677211175 | validation: 0.39923477288883286]
	TIME [epoch: 9.08 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31028746781904953		[learning rate: 6.0059e-05]
	Learning Rate: 6.00591e-05
	LOSS [training: 0.31028746781904953 | validation: 0.38689713694606404]
	TIME [epoch: 9.07 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29555479225261366		[learning rate: 5.9841e-05]
	Learning Rate: 5.98412e-05
	LOSS [training: 0.29555479225261366 | validation: 0.41387031431680443]
	TIME [epoch: 9.06 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31332972404329645		[learning rate: 5.9624e-05]
	Learning Rate: 5.9624e-05
	LOSS [training: 0.31332972404329645 | validation: 0.39515177715153216]
	TIME [epoch: 9.06 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.302340008098998		[learning rate: 5.9408e-05]
	Learning Rate: 5.94076e-05
	LOSS [training: 0.302340008098998 | validation: 0.39590493166626106]
	TIME [epoch: 9.06 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2987126170660052		[learning rate: 5.9192e-05]
	Learning Rate: 5.9192e-05
	LOSS [training: 0.2987126170660052 | validation: 0.39687475049338766]
	TIME [epoch: 9.09 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.291139046680832		[learning rate: 5.8977e-05]
	Learning Rate: 5.89772e-05
	LOSS [training: 0.291139046680832 | validation: 0.38700744642282164]
	TIME [epoch: 9.06 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29655385259357603		[learning rate: 5.8763e-05]
	Learning Rate: 5.87632e-05
	LOSS [training: 0.29655385259357603 | validation: 0.4023751129555878]
	TIME [epoch: 9.06 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30287890740865153		[learning rate: 5.855e-05]
	Learning Rate: 5.85499e-05
	LOSS [training: 0.30287890740865153 | validation: 0.4043771171091608]
	TIME [epoch: 9.06 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976922376342134		[learning rate: 5.8337e-05]
	Learning Rate: 5.83374e-05
	LOSS [training: 0.2976922376342134 | validation: 0.42179837227300593]
	TIME [epoch: 9.08 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2941858224388681		[learning rate: 5.8126e-05]
	Learning Rate: 5.81257e-05
	LOSS [training: 0.2941858224388681 | validation: 0.40360014082875195]
	TIME [epoch: 9.07 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28815847831276664		[learning rate: 5.7915e-05]
	Learning Rate: 5.79148e-05
	LOSS [training: 0.28815847831276664 | validation: 0.3945109051591057]
	TIME [epoch: 9.07 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3026758152578305		[learning rate: 5.7705e-05]
	Learning Rate: 5.77046e-05
	LOSS [training: 0.3026758152578305 | validation: 0.40738050242921525]
	TIME [epoch: 9.06 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3010926491838991		[learning rate: 5.7495e-05]
	Learning Rate: 5.74952e-05
	LOSS [training: 0.3010926491838991 | validation: 0.41221179256131685]
	TIME [epoch: 9.07 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29461601501864093		[learning rate: 5.7287e-05]
	Learning Rate: 5.72866e-05
	LOSS [training: 0.29461601501864093 | validation: 0.40963585421121607]
	TIME [epoch: 9.08 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30540035338116106		[learning rate: 5.7079e-05]
	Learning Rate: 5.70787e-05
	LOSS [training: 0.30540035338116106 | validation: 0.42396818070128534]
	TIME [epoch: 9.06 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2979597331761257		[learning rate: 5.6872e-05]
	Learning Rate: 5.68715e-05
	LOSS [training: 0.2979597331761257 | validation: 0.41462203823154414]
	TIME [epoch: 9.07 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.290097122925266		[learning rate: 5.6665e-05]
	Learning Rate: 5.66651e-05
	LOSS [training: 0.290097122925266 | validation: 0.4055206879349958]
	TIME [epoch: 9.06 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30581374304643394		[learning rate: 5.6459e-05]
	Learning Rate: 5.64595e-05
	LOSS [training: 0.30581374304643394 | validation: 0.39700512890026396]
	TIME [epoch: 9.09 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28978622510378005		[learning rate: 5.6255e-05]
	Learning Rate: 5.62546e-05
	LOSS [training: 0.28978622510378005 | validation: 0.4058312360366702]
	TIME [epoch: 9.07 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29423780584116677		[learning rate: 5.605e-05]
	Learning Rate: 5.60504e-05
	LOSS [training: 0.29423780584116677 | validation: 0.40812138085429583]
	TIME [epoch: 9.07 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30442117976720834		[learning rate: 5.5847e-05]
	Learning Rate: 5.5847e-05
	LOSS [training: 0.30442117976720834 | validation: 0.406036863521278]
	TIME [epoch: 9.06 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3008735080855024		[learning rate: 5.5644e-05]
	Learning Rate: 5.56444e-05
	LOSS [training: 0.3008735080855024 | validation: 0.42306189888979095]
	TIME [epoch: 9.07 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2990645378881578		[learning rate: 5.5442e-05]
	Learning Rate: 5.54424e-05
	LOSS [training: 0.2990645378881578 | validation: 0.3872877164348506]
	TIME [epoch: 9.09 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30211662506138803		[learning rate: 5.5241e-05]
	Learning Rate: 5.52412e-05
	LOSS [training: 0.30211662506138803 | validation: 0.40178404109591165]
	TIME [epoch: 9.08 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3037087171377074		[learning rate: 5.5041e-05]
	Learning Rate: 5.50407e-05
	LOSS [training: 0.3037087171377074 | validation: 0.4062281030462307]
	TIME [epoch: 9.07 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2945142538326982		[learning rate: 5.4841e-05]
	Learning Rate: 5.4841e-05
	LOSS [training: 0.2945142538326982 | validation: 0.4073842098914351]
	TIME [epoch: 9.05 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31296967284549126		[learning rate: 5.4642e-05]
	Learning Rate: 5.4642e-05
	LOSS [training: 0.31296967284549126 | validation: 0.4150108875903045]
	TIME [epoch: 9.07 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3011290843568261		[learning rate: 5.4444e-05]
	Learning Rate: 5.44437e-05
	LOSS [training: 0.3011290843568261 | validation: 0.3938309804412091]
	TIME [epoch: 9.08 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3015623815450917		[learning rate: 5.4246e-05]
	Learning Rate: 5.42461e-05
	LOSS [training: 0.3015623815450917 | validation: 0.40319466749294197]
	TIME [epoch: 9.07 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28790116772839847		[learning rate: 5.4049e-05]
	Learning Rate: 5.40492e-05
	LOSS [training: 0.28790116772839847 | validation: 0.3969745652198174]
	TIME [epoch: 9.07 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2962193008616185		[learning rate: 5.3853e-05]
	Learning Rate: 5.38531e-05
	LOSS [training: 0.2962193008616185 | validation: 0.3774559138466962]
	TIME [epoch: 9.06 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2898062611221919		[learning rate: 5.3658e-05]
	Learning Rate: 5.36577e-05
	LOSS [training: 0.2898062611221919 | validation: 0.3899756961171713]
	TIME [epoch: 9.08 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29242184329403553		[learning rate: 5.3463e-05]
	Learning Rate: 5.34629e-05
	LOSS [training: 0.29242184329403553 | validation: 0.39909691104411127]
	TIME [epoch: 9.07 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29965057904298475		[learning rate: 5.3269e-05]
	Learning Rate: 5.32689e-05
	LOSS [training: 0.29965057904298475 | validation: 0.39299840970853567]
	TIME [epoch: 9.06 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2933010412060718		[learning rate: 5.3076e-05]
	Learning Rate: 5.30756e-05
	LOSS [training: 0.2933010412060718 | validation: 0.40265881065625825]
	TIME [epoch: 9.06 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29204940603118945		[learning rate: 5.2883e-05]
	Learning Rate: 5.2883e-05
	LOSS [training: 0.29204940603118945 | validation: 0.3939390641338676]
	TIME [epoch: 9.07 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.296281067769954		[learning rate: 5.2691e-05]
	Learning Rate: 5.26911e-05
	LOSS [training: 0.296281067769954 | validation: 0.40414028217487497]
	TIME [epoch: 9.09 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2928972929933276		[learning rate: 5.25e-05]
	Learning Rate: 5.24998e-05
	LOSS [training: 0.2928972929933276 | validation: 0.39816818566086026]
	TIME [epoch: 9.07 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28792345015825666		[learning rate: 5.2309e-05]
	Learning Rate: 5.23093e-05
	LOSS [training: 0.28792345015825666 | validation: 0.3991774302118797]
	TIME [epoch: 9.06 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30054430132677934		[learning rate: 5.2119e-05]
	Learning Rate: 5.21195e-05
	LOSS [training: 0.30054430132677934 | validation: 0.39393955819986753]
	TIME [epoch: 9.06 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29206212644071655		[learning rate: 5.193e-05]
	Learning Rate: 5.19303e-05
	LOSS [training: 0.29206212644071655 | validation: 0.39160468316110464]
	TIME [epoch: 9.08 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2910063287557019		[learning rate: 5.1742e-05]
	Learning Rate: 5.17419e-05
	LOSS [training: 0.2910063287557019 | validation: 0.37843532932872753]
	TIME [epoch: 9.07 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29923604881118904		[learning rate: 5.1554e-05]
	Learning Rate: 5.15541e-05
	LOSS [training: 0.29923604881118904 | validation: 0.37549621629256735]
	TIME [epoch: 9.06 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2969522825799244		[learning rate: 5.1367e-05]
	Learning Rate: 5.1367e-05
	LOSS [training: 0.2969522825799244 | validation: 0.39519028374511056]
	TIME [epoch: 9.06 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3015681421898294		[learning rate: 5.1181e-05]
	Learning Rate: 5.11806e-05
	LOSS [training: 0.3015681421898294 | validation: 0.41054401277311114]
	TIME [epoch: 9.06 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.295201587650287		[learning rate: 5.0995e-05]
	Learning Rate: 5.09949e-05
	LOSS [training: 0.295201587650287 | validation: 0.3898108213835729]
	TIME [epoch: 9.08 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2909390310293289		[learning rate: 5.081e-05]
	Learning Rate: 5.08098e-05
	LOSS [training: 0.2909390310293289 | validation: 0.4246374036283611]
	TIME [epoch: 9.07 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28736040427690024		[learning rate: 5.0625e-05]
	Learning Rate: 5.06254e-05
	LOSS [training: 0.28736040427690024 | validation: 0.40537326955263064]
	TIME [epoch: 9.07 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3007668369706796		[learning rate: 5.0442e-05]
	Learning Rate: 5.04417e-05
	LOSS [training: 0.3007668369706796 | validation: 0.4309290060207075]
	TIME [epoch: 9.08 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3017714616409428		[learning rate: 5.0259e-05]
	Learning Rate: 5.02586e-05
	LOSS [training: 0.3017714616409428 | validation: 0.3985367358356576]
	TIME [epoch: 9.09 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29125510008353217		[learning rate: 5.0076e-05]
	Learning Rate: 5.00762e-05
	LOSS [training: 0.29125510008353217 | validation: 0.39458226563925985]
	TIME [epoch: 9.07 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29108282092779814		[learning rate: 4.9894e-05]
	Learning Rate: 4.98945e-05
	LOSS [training: 0.29108282092779814 | validation: 0.388284376650252]
	TIME [epoch: 9.06 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2947542936944966		[learning rate: 4.9713e-05]
	Learning Rate: 4.97134e-05
	LOSS [training: 0.2947542936944966 | validation: 0.40062356477253364]
	TIME [epoch: 9.05 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2840556059698282		[learning rate: 4.9533e-05]
	Learning Rate: 4.9533e-05
	LOSS [training: 0.2840556059698282 | validation: 0.3779514000924147]
	TIME [epoch: 9.06 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29492473165266186		[learning rate: 4.9353e-05]
	Learning Rate: 4.93533e-05
	LOSS [training: 0.29492473165266186 | validation: 0.40204674818147346]
	TIME [epoch: 9.08 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3022832278140094		[learning rate: 4.9174e-05]
	Learning Rate: 4.91742e-05
	LOSS [training: 0.3022832278140094 | validation: 0.39245324167372814]
	TIME [epoch: 9.08 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2916218882900804		[learning rate: 4.8996e-05]
	Learning Rate: 4.89957e-05
	LOSS [training: 0.2916218882900804 | validation: 0.3984539685218167]
	TIME [epoch: 9.06 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29142179507717936		[learning rate: 4.8818e-05]
	Learning Rate: 4.88179e-05
	LOSS [training: 0.29142179507717936 | validation: 0.38177309730232983]
	TIME [epoch: 9.07 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29767449313660216		[learning rate: 4.8641e-05]
	Learning Rate: 4.86407e-05
	LOSS [training: 0.29767449313660216 | validation: 0.37736518341149233]
	TIME [epoch: 9.07 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29059928289212067		[learning rate: 4.8464e-05]
	Learning Rate: 4.84642e-05
	LOSS [training: 0.29059928289212067 | validation: 0.4006407723355432]
	TIME [epoch: 9.07 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31589938512733584		[learning rate: 4.8288e-05]
	Learning Rate: 4.82883e-05
	LOSS [training: 0.31589938512733584 | validation: 0.388727663735496]
	TIME [epoch: 9.06 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3017634921981167		[learning rate: 4.8113e-05]
	Learning Rate: 4.81131e-05
	LOSS [training: 0.3017634921981167 | validation: 0.40003598814794356]
	TIME [epoch: 9.08 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2902975225666189		[learning rate: 4.7938e-05]
	Learning Rate: 4.79385e-05
	LOSS [training: 0.2902975225666189 | validation: 0.38562221815534503]
	TIME [epoch: 9.07 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29942382944062873		[learning rate: 4.7765e-05]
	Learning Rate: 4.77645e-05
	LOSS [training: 0.29942382944062873 | validation: 0.3885973473137372]
	TIME [epoch: 9.09 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3001117255246466		[learning rate: 4.7591e-05]
	Learning Rate: 4.75912e-05
	LOSS [training: 0.3001117255246466 | validation: 0.3896830717457157]
	TIME [epoch: 9.07 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29701593054247805		[learning rate: 4.7418e-05]
	Learning Rate: 4.74185e-05
	LOSS [training: 0.29701593054247805 | validation: 0.4025449942210046]
	TIME [epoch: 9.06 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2884784577079124		[learning rate: 4.7246e-05]
	Learning Rate: 4.72464e-05
	LOSS [training: 0.2884784577079124 | validation: 0.38689089312368274]
	TIME [epoch: 9.06 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28574990547167994		[learning rate: 4.7075e-05]
	Learning Rate: 4.70749e-05
	LOSS [training: 0.28574990547167994 | validation: 0.37880561901989485]
	TIME [epoch: 9.07 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29359529797685074		[learning rate: 4.6904e-05]
	Learning Rate: 4.69041e-05
	LOSS [training: 0.29359529797685074 | validation: 0.4065078156613325]
	TIME [epoch: 9.09 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28875727119467715		[learning rate: 4.6734e-05]
	Learning Rate: 4.67339e-05
	LOSS [training: 0.28875727119467715 | validation: 0.3895721665676442]
	TIME [epoch: 9.07 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2982216985175604		[learning rate: 4.6564e-05]
	Learning Rate: 4.65643e-05
	LOSS [training: 0.2982216985175604 | validation: 0.38737047530206775]
	TIME [epoch: 9.07 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29734640732956497		[learning rate: 4.6395e-05]
	Learning Rate: 4.63953e-05
	LOSS [training: 0.29734640732956497 | validation: 0.3988754531520359]
	TIME [epoch: 9.07 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29395966386395633		[learning rate: 4.6227e-05]
	Learning Rate: 4.62269e-05
	LOSS [training: 0.29395966386395633 | validation: 0.3996745419779085]
	TIME [epoch: 9.09 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29916336388385006		[learning rate: 4.6059e-05]
	Learning Rate: 4.60591e-05
	LOSS [training: 0.29916336388385006 | validation: 0.3840924827235126]
	TIME [epoch: 9.07 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2846816424655497		[learning rate: 4.5892e-05]
	Learning Rate: 4.5892e-05
	LOSS [training: 0.2846816424655497 | validation: 0.3895479548466762]
	TIME [epoch: 9.07 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2874742484557204		[learning rate: 4.5725e-05]
	Learning Rate: 4.57254e-05
	LOSS [training: 0.2874742484557204 | validation: 0.39408807083179015]
	TIME [epoch: 9.07 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2822233009217256		[learning rate: 4.556e-05]
	Learning Rate: 4.55595e-05
	LOSS [training: 0.2822233009217256 | validation: 0.386868803739714]
	TIME [epoch: 9.08 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29539399570324165		[learning rate: 4.5394e-05]
	Learning Rate: 4.53942e-05
	LOSS [training: 0.29539399570324165 | validation: 0.40187207859784513]
	TIME [epoch: 9.09 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29458485492346326		[learning rate: 4.5229e-05]
	Learning Rate: 4.52294e-05
	LOSS [training: 0.29458485492346326 | validation: 0.4032890483715358]
	TIME [epoch: 9.07 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29314047743777016		[learning rate: 4.5065e-05]
	Learning Rate: 4.50653e-05
	LOSS [training: 0.29314047743777016 | validation: 0.40363510617303816]
	TIME [epoch: 9.06 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3095222104507875		[learning rate: 4.4902e-05]
	Learning Rate: 4.49017e-05
	LOSS [training: 0.3095222104507875 | validation: 0.4377338111492993]
	TIME [epoch: 9.06 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28867225758191384		[learning rate: 4.4739e-05]
	Learning Rate: 4.47388e-05
	LOSS [training: 0.28867225758191384 | validation: 0.39975350033161994]
	TIME [epoch: 9.09 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29384553298060234		[learning rate: 4.4576e-05]
	Learning Rate: 4.45764e-05
	LOSS [training: 0.29384553298060234 | validation: 0.39584902743094885]
	TIME [epoch: 9.07 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2963338734045804		[learning rate: 4.4415e-05]
	Learning Rate: 4.44147e-05
	LOSS [training: 0.2963338734045804 | validation: 0.4064544313929911]
	TIME [epoch: 9.06 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2938185654738175		[learning rate: 4.4253e-05]
	Learning Rate: 4.42535e-05
	LOSS [training: 0.2938185654738175 | validation: 0.38521071207278557]
	TIME [epoch: 9.07 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28830530911971225		[learning rate: 4.4093e-05]
	Learning Rate: 4.40929e-05
	LOSS [training: 0.28830530911971225 | validation: 0.39063153895637903]
	TIME [epoch: 9.07 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2983961825333568		[learning rate: 4.3933e-05]
	Learning Rate: 4.39329e-05
	LOSS [training: 0.2983961825333568 | validation: 0.374404982967139]
	TIME [epoch: 9.08 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28195860547353274		[learning rate: 4.3773e-05]
	Learning Rate: 4.37734e-05
	LOSS [training: 0.28195860547353274 | validation: 0.3931986000449923]
	TIME [epoch: 9.07 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29578605704921646		[learning rate: 4.3615e-05]
	Learning Rate: 4.36146e-05
	LOSS [training: 0.29578605704921646 | validation: 0.3956046595305708]
	TIME [epoch: 9.07 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3013551143396029		[learning rate: 4.3456e-05]
	Learning Rate: 4.34563e-05
	LOSS [training: 0.3013551143396029 | validation: 0.39664289266793995]
	TIME [epoch: 9.08 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29557099893203265		[learning rate: 4.3299e-05]
	Learning Rate: 4.32986e-05
	LOSS [training: 0.29557099893203265 | validation: 0.3984567983352761]
	TIME [epoch: 9.08 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2998080260638129		[learning rate: 4.3141e-05]
	Learning Rate: 4.31415e-05
	LOSS [training: 0.2998080260638129 | validation: 0.3992277557866981]
	TIME [epoch: 9.07 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29602766936180824		[learning rate: 4.2985e-05]
	Learning Rate: 4.29849e-05
	LOSS [training: 0.29602766936180824 | validation: 0.4005129559152315]
	TIME [epoch: 9.07 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2863040536466141		[learning rate: 4.2829e-05]
	Learning Rate: 4.28289e-05
	LOSS [training: 0.2863040536466141 | validation: 0.39856433394021884]
	TIME [epoch: 9.07 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29025518918660753		[learning rate: 4.2673e-05]
	Learning Rate: 4.26735e-05
	LOSS [training: 0.29025518918660753 | validation: 0.39518666997588797]
	TIME [epoch: 9.07 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29360536557279837		[learning rate: 4.2519e-05]
	Learning Rate: 4.25186e-05
	LOSS [training: 0.29360536557279837 | validation: 0.39042488064388947]
	TIME [epoch: 9.09 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29076423377183747		[learning rate: 4.2364e-05]
	Learning Rate: 4.23643e-05
	LOSS [training: 0.29076423377183747 | validation: 0.41254448086701934]
	TIME [epoch: 9.07 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29434203059102476		[learning rate: 4.2211e-05]
	Learning Rate: 4.22106e-05
	LOSS [training: 0.29434203059102476 | validation: 0.394231402791755]
	TIME [epoch: 9.07 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2938623665871244		[learning rate: 4.2057e-05]
	Learning Rate: 4.20574e-05
	LOSS [training: 0.2938623665871244 | validation: 0.392933028439384]
	TIME [epoch: 9.07 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2846226422011447		[learning rate: 4.1905e-05]
	Learning Rate: 4.19047e-05
	LOSS [training: 0.2846226422011447 | validation: 0.38445475819992375]
	TIME [epoch: 9.08 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29098304432740074		[learning rate: 4.1753e-05]
	Learning Rate: 4.17527e-05
	LOSS [training: 0.29098304432740074 | validation: 0.4084951522351564]
	TIME [epoch: 9.09 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28652421225302926		[learning rate: 4.1601e-05]
	Learning Rate: 4.16012e-05
	LOSS [training: 0.28652421225302926 | validation: 0.3979062956320843]
	TIME [epoch: 9.07 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3039921822803632		[learning rate: 4.145e-05]
	Learning Rate: 4.14502e-05
	LOSS [training: 0.3039921822803632 | validation: 0.38892222519645836]
	TIME [epoch: 9.07 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3022743639440312		[learning rate: 4.13e-05]
	Learning Rate: 4.12998e-05
	LOSS [training: 0.3022743639440312 | validation: 0.38198622547621064]
	TIME [epoch: 9.07 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29749224573339406		[learning rate: 4.115e-05]
	Learning Rate: 4.11499e-05
	LOSS [training: 0.29749224573339406 | validation: 0.37313416208662853]
	TIME [epoch: 9.09 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954344257347204		[learning rate: 4.1001e-05]
	Learning Rate: 4.10005e-05
	LOSS [training: 0.2954344257347204 | validation: 0.40283166104239515]
	TIME [epoch: 9.07 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30105601998262144		[learning rate: 4.0852e-05]
	Learning Rate: 4.08517e-05
	LOSS [training: 0.30105601998262144 | validation: 0.3868265724264489]
	TIME [epoch: 9.06 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30059872340140514		[learning rate: 4.0703e-05]
	Learning Rate: 4.07035e-05
	LOSS [training: 0.30059872340140514 | validation: 0.41041243548946166]
	TIME [epoch: 9.07 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2956624599649337		[learning rate: 4.0556e-05]
	Learning Rate: 4.05558e-05
	LOSS [training: 0.2956624599649337 | validation: 0.40000787860589615]
	TIME [epoch: 9.06 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2869039951724338		[learning rate: 4.0409e-05]
	Learning Rate: 4.04086e-05
	LOSS [training: 0.2869039951724338 | validation: 0.4063867803256052]
	TIME [epoch: 9.08 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28941366229616106		[learning rate: 4.0262e-05]
	Learning Rate: 4.0262e-05
	LOSS [training: 0.28941366229616106 | validation: 0.4229606015395201]
	TIME [epoch: 9.07 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2982172645699415		[learning rate: 4.0116e-05]
	Learning Rate: 4.01158e-05
	LOSS [training: 0.2982172645699415 | validation: 0.405685059234988]
	TIME [epoch: 9.06 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2963175622860134		[learning rate: 3.997e-05]
	Learning Rate: 3.99703e-05
	LOSS [training: 0.2963175622860134 | validation: 0.39938309046539233]
	TIME [epoch: 9.07 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3012858760266405		[learning rate: 3.9825e-05]
	Learning Rate: 3.98252e-05
	LOSS [training: 0.3012858760266405 | validation: 0.3750475642126544]
	TIME [epoch: 9.09 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29785342932771036		[learning rate: 3.9681e-05]
	Learning Rate: 3.96807e-05
	LOSS [training: 0.29785342932771036 | validation: 0.3905416161935927]
	TIME [epoch: 9.08 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29763047382192265		[learning rate: 3.9537e-05]
	Learning Rate: 3.95367e-05
	LOSS [training: 0.29763047382192265 | validation: 0.40868129068725656]
	TIME [epoch: 9.07 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29060561039426597		[learning rate: 3.9393e-05]
	Learning Rate: 3.93932e-05
	LOSS [training: 0.29060561039426597 | validation: 0.39734150356745374]
	TIME [epoch: 9.07 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28729477885910965		[learning rate: 3.925e-05]
	Learning Rate: 3.92502e-05
	LOSS [training: 0.28729477885910965 | validation: 0.38966452603927165]
	TIME [epoch: 9.07 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2912752070251513		[learning rate: 3.9108e-05]
	Learning Rate: 3.91078e-05
	LOSS [training: 0.2912752070251513 | validation: 0.39129888858824363]
	TIME [epoch: 9.08 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2928795285670281		[learning rate: 3.8966e-05]
	Learning Rate: 3.89659e-05
	LOSS [training: 0.2928795285670281 | validation: 0.3981457371813064]
	TIME [epoch: 9.07 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29549344742280187		[learning rate: 3.8824e-05]
	Learning Rate: 3.88245e-05
	LOSS [training: 0.29549344742280187 | validation: 0.4050646545037845]
	TIME [epoch: 9.07 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29052028061161006		[learning rate: 3.8684e-05]
	Learning Rate: 3.86836e-05
	LOSS [training: 0.29052028061161006 | validation: 0.3799747426821446]
	TIME [epoch: 9.07 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959149559189975		[learning rate: 3.8543e-05]
	Learning Rate: 3.85432e-05
	LOSS [training: 0.2959149559189975 | validation: 0.389950146861458]
	TIME [epoch: 9.08 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3021735787462677		[learning rate: 3.8403e-05]
	Learning Rate: 3.84033e-05
	LOSS [training: 0.3021735787462677 | validation: 0.4009796543170162]
	TIME [epoch: 9.09 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2897208516164066		[learning rate: 3.8264e-05]
	Learning Rate: 3.82639e-05
	LOSS [training: 0.2897208516164066 | validation: 0.38704069998983165]
	TIME [epoch: 9.07 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3036372697738695		[learning rate: 3.8125e-05]
	Learning Rate: 3.81251e-05
	LOSS [training: 0.3036372697738695 | validation: 0.39439895822802906]
	TIME [epoch: 9.05 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2933723989568658		[learning rate: 3.7987e-05]
	Learning Rate: 3.79867e-05
	LOSS [training: 0.2933723989568658 | validation: 0.38264072454770537]
	TIME [epoch: 9.08 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29320616763486107		[learning rate: 3.7849e-05]
	Learning Rate: 3.78489e-05
	LOSS [training: 0.29320616763486107 | validation: 0.39343126639599824]
	TIME [epoch: 9.1 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2909314869861422		[learning rate: 3.7711e-05]
	Learning Rate: 3.77115e-05
	LOSS [training: 0.2909314869861422 | validation: 0.3881586287572266]
	TIME [epoch: 9.07 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2895574605421042		[learning rate: 3.7575e-05]
	Learning Rate: 3.75746e-05
	LOSS [training: 0.2895574605421042 | validation: 0.407329793572192]
	TIME [epoch: 9.08 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28814843061585826		[learning rate: 3.7438e-05]
	Learning Rate: 3.74383e-05
	LOSS [training: 0.28814843061585826 | validation: 0.40602596128258667]
	TIME [epoch: 9.07 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2887974508488034		[learning rate: 3.7302e-05]
	Learning Rate: 3.73024e-05
	LOSS [training: 0.2887974508488034 | validation: 0.40074074777503044]
	TIME [epoch: 9.06 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2981002560289051		[learning rate: 3.7167e-05]
	Learning Rate: 3.7167e-05
	LOSS [training: 0.2981002560289051 | validation: 0.41050458215310703]
	TIME [epoch: 9.09 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28626955581305047		[learning rate: 3.7032e-05]
	Learning Rate: 3.70322e-05
	LOSS [training: 0.28626955581305047 | validation: 0.3955769167853804]
	TIME [epoch: 9.06 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2880256707959162		[learning rate: 3.6898e-05]
	Learning Rate: 3.68978e-05
	LOSS [training: 0.2880256707959162 | validation: 0.3919462781391679]
	TIME [epoch: 9.07 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2820576682247221		[learning rate: 3.6764e-05]
	Learning Rate: 3.67639e-05
	LOSS [training: 0.2820576682247221 | validation: 0.38442761275841]
	TIME [epoch: 9.07 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28902649616848564		[learning rate: 3.663e-05]
	Learning Rate: 3.66304e-05
	LOSS [training: 0.28902649616848564 | validation: 0.38295564920292857]
	TIME [epoch: 9.1 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27838722542353944		[learning rate: 3.6498e-05]
	Learning Rate: 3.64975e-05
	LOSS [training: 0.27838722542353944 | validation: 0.4013375062376757]
	TIME [epoch: 9.08 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2995353962289764		[learning rate: 3.6365e-05]
	Learning Rate: 3.63651e-05
	LOSS [training: 0.2995353962289764 | validation: 0.40680558855889737]
	TIME [epoch: 9.06 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2956416996878466		[learning rate: 3.6233e-05]
	Learning Rate: 3.62331e-05
	LOSS [training: 0.2956416996878466 | validation: 0.3866443495319026]
	TIME [epoch: 9.06 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2904380104122751		[learning rate: 3.6102e-05]
	Learning Rate: 3.61016e-05
	LOSS [training: 0.2904380104122751 | validation: 0.39882664585178784]
	TIME [epoch: 9.07 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29380881178297613		[learning rate: 3.5971e-05]
	Learning Rate: 3.59706e-05
	LOSS [training: 0.29380881178297613 | validation: 0.4019455630548191]
	TIME [epoch: 9.09 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2880812067517477		[learning rate: 3.584e-05]
	Learning Rate: 3.584e-05
	LOSS [training: 0.2880812067517477 | validation: 0.4035466032724802]
	TIME [epoch: 9.08 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28264768956080893		[learning rate: 3.571e-05]
	Learning Rate: 3.571e-05
	LOSS [training: 0.28264768956080893 | validation: 0.4225421158762203]
	TIME [epoch: 9.07 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2929538331301977		[learning rate: 3.558e-05]
	Learning Rate: 3.55804e-05
	LOSS [training: 0.2929538331301977 | validation: 0.42245250688800606]
	TIME [epoch: 9.07 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954416849769105		[learning rate: 3.5451e-05]
	Learning Rate: 3.54513e-05
	LOSS [training: 0.2954416849769105 | validation: 0.41540507474498933]
	TIME [epoch: 9.09 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2903916319214883		[learning rate: 3.5323e-05]
	Learning Rate: 3.53226e-05
	LOSS [training: 0.2903916319214883 | validation: 0.4032839827592319]
	TIME [epoch: 9.07 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2948385924514127		[learning rate: 3.5194e-05]
	Learning Rate: 3.51944e-05
	LOSS [training: 0.2948385924514127 | validation: 0.3945436793225844]
	TIME [epoch: 9.07 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.299392207108985		[learning rate: 3.5067e-05]
	Learning Rate: 3.50667e-05
	LOSS [training: 0.299392207108985 | validation: 0.3942297729544099]
	TIME [epoch: 9.06 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2975521972157309		[learning rate: 3.4939e-05]
	Learning Rate: 3.49394e-05
	LOSS [training: 0.2975521972157309 | validation: 0.40789554404410816]
	TIME [epoch: 9.07 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2858246746269927		[learning rate: 3.4813e-05]
	Learning Rate: 3.48126e-05
	LOSS [training: 0.2858246746269927 | validation: 0.4166892953388549]
	TIME [epoch: 9.09 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2968176496406874		[learning rate: 3.4686e-05]
	Learning Rate: 3.46863e-05
	LOSS [training: 0.2968176496406874 | validation: 0.4004183942968424]
	TIME [epoch: 9.07 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29045235376615053		[learning rate: 3.456e-05]
	Learning Rate: 3.45604e-05
	LOSS [training: 0.29045235376615053 | validation: 0.3803876573065522]
	TIME [epoch: 9.06 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29344416999905254		[learning rate: 3.4435e-05]
	Learning Rate: 3.4435e-05
	LOSS [training: 0.29344416999905254 | validation: 0.3913426031560683]
	TIME [epoch: 9.08 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.292504571519023		[learning rate: 3.431e-05]
	Learning Rate: 3.431e-05
	LOSS [training: 0.292504571519023 | validation: 0.3843230242295798]
	TIME [epoch: 9.09 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.291355367665478		[learning rate: 3.4186e-05]
	Learning Rate: 3.41855e-05
	LOSS [training: 0.291355367665478 | validation: 0.38234045742087497]
	TIME [epoch: 9.09 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2849854505971481		[learning rate: 3.4061e-05]
	Learning Rate: 3.40615e-05
	LOSS [training: 0.2849854505971481 | validation: 0.3973916461408483]
	TIME [epoch: 9.07 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2932662433659793		[learning rate: 3.3938e-05]
	Learning Rate: 3.39378e-05
	LOSS [training: 0.2932662433659793 | validation: 0.4219181264008401]
	TIME [epoch: 9.07 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.289270407315673		[learning rate: 3.3815e-05]
	Learning Rate: 3.38147e-05
	LOSS [training: 0.289270407315673 | validation: 0.3971131433689403]
	TIME [epoch: 9.07 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2992307541789509		[learning rate: 3.3692e-05]
	Learning Rate: 3.3692e-05
	LOSS [training: 0.2992307541789509 | validation: 0.3818988499725895]
	TIME [epoch: 9.08 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2927522918040261		[learning rate: 3.357e-05]
	Learning Rate: 3.35697e-05
	LOSS [training: 0.2927522918040261 | validation: 0.40217749538203945]
	TIME [epoch: 9.07 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2910646414016256		[learning rate: 3.3448e-05]
	Learning Rate: 3.34479e-05
	LOSS [training: 0.2910646414016256 | validation: 0.3904243107321518]
	TIME [epoch: 9.06 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2822390684188165		[learning rate: 3.3326e-05]
	Learning Rate: 3.33265e-05
	LOSS [training: 0.2822390684188165 | validation: 0.40087722555051986]
	TIME [epoch: 9.07 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3000921121024548		[learning rate: 3.3206e-05]
	Learning Rate: 3.32055e-05
	LOSS [training: 0.3000921121024548 | validation: 0.39430589686519363]
	TIME [epoch: 9.06 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30367770793635257		[learning rate: 3.3085e-05]
	Learning Rate: 3.3085e-05
	LOSS [training: 0.30367770793635257 | validation: 0.39195499574944986]
	TIME [epoch: 9.07 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892810355752922		[learning rate: 3.2965e-05]
	Learning Rate: 3.2965e-05
	LOSS [training: 0.2892810355752922 | validation: 0.37364085931091034]
	TIME [epoch: 9.06 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2955253830811039		[learning rate: 3.2845e-05]
	Learning Rate: 3.28453e-05
	LOSS [training: 0.2955253830811039 | validation: 0.38199747900068887]
	TIME [epoch: 9.07 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.298230633566935		[learning rate: 3.2726e-05]
	Learning Rate: 3.27261e-05
	LOSS [training: 0.298230633566935 | validation: 0.38800965597851583]
	TIME [epoch: 9.06 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28382309544515477		[learning rate: 3.2607e-05]
	Learning Rate: 3.26074e-05
	LOSS [training: 0.28382309544515477 | validation: 0.38925633650362657]
	TIME [epoch: 9.09 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2908803944427231		[learning rate: 3.2489e-05]
	Learning Rate: 3.2489e-05
	LOSS [training: 0.2908803944427231 | validation: 0.3867680208004399]
	TIME [epoch: 9.06 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28968545968956244		[learning rate: 3.2371e-05]
	Learning Rate: 3.23711e-05
	LOSS [training: 0.28968545968956244 | validation: 0.39988945454497316]
	TIME [epoch: 9.07 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28193607855400354		[learning rate: 3.2254e-05]
	Learning Rate: 3.22537e-05
	LOSS [training: 0.28193607855400354 | validation: 0.40032690459413617]
	TIME [epoch: 9.06 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28913325395657236		[learning rate: 3.2137e-05]
	Learning Rate: 3.21366e-05
	LOSS [training: 0.28913325395657236 | validation: 0.3874140499757255]
	TIME [epoch: 9.07 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29143055080566826		[learning rate: 3.202e-05]
	Learning Rate: 3.202e-05
	LOSS [training: 0.29143055080566826 | validation: 0.3939727029498859]
	TIME [epoch: 9.09 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29686365888850225		[learning rate: 3.1904e-05]
	Learning Rate: 3.19038e-05
	LOSS [training: 0.29686365888850225 | validation: 0.3811073223049698]
	TIME [epoch: 9.07 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2809656752860986		[learning rate: 3.1788e-05]
	Learning Rate: 3.1788e-05
	LOSS [training: 0.2809656752860986 | validation: 0.39582247771556855]
	TIME [epoch: 9.07 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2944116108209849		[learning rate: 3.1673e-05]
	Learning Rate: 3.16726e-05
	LOSS [training: 0.2944116108209849 | validation: 0.40918170205034066]
	TIME [epoch: 9.07 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29022583107484573		[learning rate: 3.1558e-05]
	Learning Rate: 3.15577e-05
	LOSS [training: 0.29022583107484573 | validation: 0.39041006733622025]
	TIME [epoch: 9.09 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28475396386836155		[learning rate: 3.1443e-05]
	Learning Rate: 3.14432e-05
	LOSS [training: 0.28475396386836155 | validation: 0.39211632032120275]
	TIME [epoch: 9.06 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29086396871275116		[learning rate: 3.1329e-05]
	Learning Rate: 3.13291e-05
	LOSS [training: 0.29086396871275116 | validation: 0.40094507081142805]
	TIME [epoch: 9.06 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29597191610825174		[learning rate: 3.1215e-05]
	Learning Rate: 3.12154e-05
	LOSS [training: 0.29597191610825174 | validation: 0.3863290290825324]
	TIME [epoch: 9.07 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29595626441731765		[learning rate: 3.1102e-05]
	Learning Rate: 3.11021e-05
	LOSS [training: 0.29595626441731765 | validation: 0.38631407890389363]
	TIME [epoch: 9.07 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2950221133581787		[learning rate: 3.0989e-05]
	Learning Rate: 3.09892e-05
	LOSS [training: 0.2950221133581787 | validation: 0.4071292607864257]
	TIME [epoch: 9.09 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29054939413743586		[learning rate: 3.0877e-05]
	Learning Rate: 3.08768e-05
	LOSS [training: 0.29054939413743586 | validation: 0.39636463217856055]
	TIME [epoch: 9.07 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28946075413629324		[learning rate: 3.0765e-05]
	Learning Rate: 3.07647e-05
	LOSS [training: 0.28946075413629324 | validation: 0.41228825192749124]
	TIME [epoch: 9.06 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2961259673702329		[learning rate: 3.0653e-05]
	Learning Rate: 3.0653e-05
	LOSS [training: 0.2961259673702329 | validation: 0.3955239453341767]
	TIME [epoch: 9.06 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2857113539005533		[learning rate: 3.0542e-05]
	Learning Rate: 3.05418e-05
	LOSS [training: 0.2857113539005533 | validation: 0.4033179521246365]
	TIME [epoch: 9.07 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28791231146595336		[learning rate: 3.0431e-05]
	Learning Rate: 3.0431e-05
	LOSS [training: 0.28791231146595336 | validation: 0.39887118633089136]
	TIME [epoch: 9.07 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30045544275248665		[learning rate: 3.0321e-05]
	Learning Rate: 3.03205e-05
	LOSS [training: 0.30045544275248665 | validation: 0.40222069388836856]
	TIME [epoch: 9.06 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2819141438819591		[learning rate: 3.0211e-05]
	Learning Rate: 3.02105e-05
	LOSS [training: 0.2819141438819591 | validation: 0.38733076212250483]
	TIME [epoch: 9.06 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2911707944613828		[learning rate: 3.0101e-05]
	Learning Rate: 3.01009e-05
	LOSS [training: 0.2911707944613828 | validation: 0.3739764806994276]
	TIME [epoch: 9.06 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2913075638570736		[learning rate: 2.9992e-05]
	Learning Rate: 2.99916e-05
	LOSS [training: 0.2913075638570736 | validation: 0.3983772232407067]
	TIME [epoch: 9.07 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29302073114509364		[learning rate: 2.9883e-05]
	Learning Rate: 2.98828e-05
	LOSS [training: 0.29302073114509364 | validation: 0.38164068974802856]
	TIME [epoch: 9.06 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29004084853996337		[learning rate: 2.9774e-05]
	Learning Rate: 2.97743e-05
	LOSS [training: 0.29004084853996337 | validation: 0.4001388611896553]
	TIME [epoch: 9.04 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29643343625711005		[learning rate: 2.9666e-05]
	Learning Rate: 2.96663e-05
	LOSS [training: 0.29643343625711005 | validation: 0.3895174137152959]
	TIME [epoch: 9.05 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28505206406245204		[learning rate: 2.9559e-05]
	Learning Rate: 2.95586e-05
	LOSS [training: 0.28505206406245204 | validation: 0.3965782959259738]
	TIME [epoch: 9.06 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28995236957676895		[learning rate: 2.9451e-05]
	Learning Rate: 2.94514e-05
	LOSS [training: 0.28995236957676895 | validation: 0.38858751198401376]
	TIME [epoch: 9.08 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28785628467950053		[learning rate: 2.9344e-05]
	Learning Rate: 2.93445e-05
	LOSS [training: 0.28785628467950053 | validation: 0.40391846413110577]
	TIME [epoch: 9.06 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.292212820413323		[learning rate: 2.9238e-05]
	Learning Rate: 2.9238e-05
	LOSS [training: 0.292212820413323 | validation: 0.4029618519204945]
	TIME [epoch: 9.05 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2917747175548241		[learning rate: 2.9132e-05]
	Learning Rate: 2.91319e-05
	LOSS [training: 0.2917747175548241 | validation: 0.40747327953137946]
	TIME [epoch: 9.06 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2943770849909049		[learning rate: 2.9026e-05]
	Learning Rate: 2.90262e-05
	LOSS [training: 0.2943770849909049 | validation: 0.38816396302526235]
	TIME [epoch: 9.08 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2928897620103167		[learning rate: 2.8921e-05]
	Learning Rate: 2.89208e-05
	LOSS [training: 0.2928897620103167 | validation: 0.41317363960508213]
	TIME [epoch: 9.07 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2922427990811197		[learning rate: 2.8816e-05]
	Learning Rate: 2.88159e-05
	LOSS [training: 0.2922427990811197 | validation: 0.4091570300397235]
	TIME [epoch: 9.06 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2859179925653475		[learning rate: 2.8711e-05]
	Learning Rate: 2.87113e-05
	LOSS [training: 0.2859179925653475 | validation: 0.3859825534856358]
	TIME [epoch: 9.05 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.296080275569486		[learning rate: 2.8607e-05]
	Learning Rate: 2.86071e-05
	LOSS [training: 0.296080275569486 | validation: 0.39004225007946225]
	TIME [epoch: 9.06 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2942346301386294		[learning rate: 2.8503e-05]
	Learning Rate: 2.85033e-05
	LOSS [training: 0.2942346301386294 | validation: 0.4064596741390294]
	TIME [epoch: 9.08 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2879534008714276		[learning rate: 2.84e-05]
	Learning Rate: 2.83998e-05
	LOSS [training: 0.2879534008714276 | validation: 0.4026789500545876]
	TIME [epoch: 9.07 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29151829763573606		[learning rate: 2.8297e-05]
	Learning Rate: 2.82968e-05
	LOSS [training: 0.29151829763573606 | validation: 0.39481631457772404]
	TIME [epoch: 9.07 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.298691603323431		[learning rate: 2.8194e-05]
	Learning Rate: 2.81941e-05
	LOSS [training: 0.298691603323431 | validation: 0.40186219079599006]
	TIME [epoch: 9.05 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2961812373894529		[learning rate: 2.8092e-05]
	Learning Rate: 2.80918e-05
	LOSS [training: 0.2961812373894529 | validation: 0.3896044085559244]
	TIME [epoch: 9.07 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2969792832901324		[learning rate: 2.799e-05]
	Learning Rate: 2.79898e-05
	LOSS [training: 0.2969792832901324 | validation: 0.39468332519268673]
	TIME [epoch: 9.07 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29030118803780897		[learning rate: 2.7888e-05]
	Learning Rate: 2.78882e-05
	LOSS [training: 0.29030118803780897 | validation: 0.3827036349767902]
	TIME [epoch: 9.06 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2920292411721408		[learning rate: 2.7787e-05]
	Learning Rate: 2.7787e-05
	LOSS [training: 0.2920292411721408 | validation: 0.38684523853617075]
	TIME [epoch: 9.05 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29213244828126117		[learning rate: 2.7686e-05]
	Learning Rate: 2.76862e-05
	LOSS [training: 0.29213244828126117 | validation: 0.3680344692761874]
	TIME [epoch: 9.06 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2925769716917682		[learning rate: 2.7586e-05]
	Learning Rate: 2.75857e-05
	LOSS [training: 0.2925769716917682 | validation: 0.36635778074097247]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1721.pth
	Model improved!!!
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.295341600028045		[learning rate: 2.7486e-05]
	Learning Rate: 2.74856e-05
	LOSS [training: 0.295341600028045 | validation: 0.4009566668424135]
	TIME [epoch: 9.08 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2876027781631902		[learning rate: 2.7386e-05]
	Learning Rate: 2.73859e-05
	LOSS [training: 0.2876027781631902 | validation: 0.3896355430582169]
	TIME [epoch: 9.07 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29502653814065155		[learning rate: 2.7286e-05]
	Learning Rate: 2.72865e-05
	LOSS [training: 0.29502653814065155 | validation: 0.38932201119994486]
	TIME [epoch: 9.07 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29585479076564997		[learning rate: 2.7187e-05]
	Learning Rate: 2.71875e-05
	LOSS [training: 0.29585479076564997 | validation: 0.3890216714563971]
	TIME [epoch: 9.07 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29241796491428973		[learning rate: 2.7089e-05]
	Learning Rate: 2.70888e-05
	LOSS [training: 0.29241796491428973 | validation: 0.39754621471504165]
	TIME [epoch: 9.1 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.288939832186981		[learning rate: 2.699e-05]
	Learning Rate: 2.69905e-05
	LOSS [training: 0.288939832186981 | validation: 0.3963785362291849]
	TIME [epoch: 9.08 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29481705469459935		[learning rate: 2.6893e-05]
	Learning Rate: 2.68925e-05
	LOSS [training: 0.29481705469459935 | validation: 0.4077035114122812]
	TIME [epoch: 9.08 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29567898772639023		[learning rate: 2.6795e-05]
	Learning Rate: 2.67949e-05
	LOSS [training: 0.29567898772639023 | validation: 0.4045526502044829]
	TIME [epoch: 9.07 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.285729276984651		[learning rate: 2.6698e-05]
	Learning Rate: 2.66977e-05
	LOSS [training: 0.285729276984651 | validation: 0.3872334474539553]
	TIME [epoch: 9.07 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28976685101210126		[learning rate: 2.6601e-05]
	Learning Rate: 2.66008e-05
	LOSS [training: 0.28976685101210126 | validation: 0.40582778996732244]
	TIME [epoch: 9.09 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28870238931633263		[learning rate: 2.6504e-05]
	Learning Rate: 2.65043e-05
	LOSS [training: 0.28870238931633263 | validation: 0.3912151828224234]
	TIME [epoch: 9.07 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.296952874869376		[learning rate: 2.6408e-05]
	Learning Rate: 2.64081e-05
	LOSS [training: 0.296952874869376 | validation: 0.3860519429816912]
	TIME [epoch: 9.07 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29851912305746053		[learning rate: 2.6312e-05]
	Learning Rate: 2.63123e-05
	LOSS [training: 0.29851912305746053 | validation: 0.3937246808483805]
	TIME [epoch: 9.07 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28106361371415317		[learning rate: 2.6217e-05]
	Learning Rate: 2.62168e-05
	LOSS [training: 0.28106361371415317 | validation: 0.389554957185887]
	TIME [epoch: 9.07 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3008991553219191		[learning rate: 2.6122e-05]
	Learning Rate: 2.61216e-05
	LOSS [training: 0.3008991553219191 | validation: 0.3789118469368379]
	TIME [epoch: 9.08 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2839208516367027		[learning rate: 2.6027e-05]
	Learning Rate: 2.60268e-05
	LOSS [training: 0.2839208516367027 | validation: 0.3870163432200472]
	TIME [epoch: 9.06 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29633764329122525		[learning rate: 2.5932e-05]
	Learning Rate: 2.59324e-05
	LOSS [training: 0.29633764329122525 | validation: 0.3912356232272481]
	TIME [epoch: 9.07 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29149454711983097		[learning rate: 2.5838e-05]
	Learning Rate: 2.58383e-05
	LOSS [training: 0.29149454711983097 | validation: 0.39926651399855756]
	TIME [epoch: 9.07 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29516673844257235		[learning rate: 2.5744e-05]
	Learning Rate: 2.57445e-05
	LOSS [training: 0.29516673844257235 | validation: 0.3956816868851832]
	TIME [epoch: 9.1 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2927581394589037		[learning rate: 2.5651e-05]
	Learning Rate: 2.56511e-05
	LOSS [training: 0.2927581394589037 | validation: 0.3932178038604316]
	TIME [epoch: 9.08 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2885101942884348		[learning rate: 2.5558e-05]
	Learning Rate: 2.5558e-05
	LOSS [training: 0.2885101942884348 | validation: 0.387759303236036]
	TIME [epoch: 9.07 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2914292730087266		[learning rate: 2.5465e-05]
	Learning Rate: 2.54652e-05
	LOSS [training: 0.2914292730087266 | validation: 0.39721467692084667]
	TIME [epoch: 9.07 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3016393254632089		[learning rate: 2.5373e-05]
	Learning Rate: 2.53728e-05
	LOSS [training: 0.3016393254632089 | validation: 0.38758877740888353]
	TIME [epoch: 9.07 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2924135695434741		[learning rate: 2.5281e-05]
	Learning Rate: 2.52807e-05
	LOSS [training: 0.2924135695434741 | validation: 0.4015278986430434]
	TIME [epoch: 9.09 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29463219728100726		[learning rate: 2.5189e-05]
	Learning Rate: 2.5189e-05
	LOSS [training: 0.29463219728100726 | validation: 0.4012282208440544]
	TIME [epoch: 9.07 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28958751328374566		[learning rate: 2.5098e-05]
	Learning Rate: 2.50976e-05
	LOSS [training: 0.28958751328374566 | validation: 0.3691685025195695]
	TIME [epoch: 9.07 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2870843805305824		[learning rate: 2.5006e-05]
	Learning Rate: 2.50065e-05
	LOSS [training: 0.2870843805305824 | validation: 0.38466235961456724]
	TIME [epoch: 9.07 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2969189660513679		[learning rate: 2.4916e-05]
	Learning Rate: 2.49157e-05
	LOSS [training: 0.2969189660513679 | validation: 0.3761099100229828]
	TIME [epoch: 9.1 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29160835864074297		[learning rate: 2.4825e-05]
	Learning Rate: 2.48253e-05
	LOSS [training: 0.29160835864074297 | validation: 0.3829900889971224]
	TIME [epoch: 9.08 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2890426106102477		[learning rate: 2.4735e-05]
	Learning Rate: 2.47352e-05
	LOSS [training: 0.2890426106102477 | validation: 0.3811708059420472]
	TIME [epoch: 9.07 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2896150718122962		[learning rate: 2.4645e-05]
	Learning Rate: 2.46455e-05
	LOSS [training: 0.2896150718122962 | validation: 0.3953465114917891]
	TIME [epoch: 9.08 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29302312279193243		[learning rate: 2.4556e-05]
	Learning Rate: 2.4556e-05
	LOSS [training: 0.29302312279193243 | validation: 0.4108066609505138]
	TIME [epoch: 9.08 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29624398207078156		[learning rate: 2.4467e-05]
	Learning Rate: 2.44669e-05
	LOSS [training: 0.29624398207078156 | validation: 0.3946117166658537]
	TIME [epoch: 9.11 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29465626961783087		[learning rate: 2.4378e-05]
	Learning Rate: 2.43781e-05
	LOSS [training: 0.29465626961783087 | validation: 0.3835005775004601]
	TIME [epoch: 9.08 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2836332037294983		[learning rate: 2.429e-05]
	Learning Rate: 2.42896e-05
	LOSS [training: 0.2836332037294983 | validation: 0.3633298144029148]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1756.pth
	Model improved!!!
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2933956148823005		[learning rate: 2.4201e-05]
	Learning Rate: 2.42015e-05
	LOSS [training: 0.2933956148823005 | validation: 0.38202486075151393]
	TIME [epoch: 9.08 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2854044518981443		[learning rate: 2.4114e-05]
	Learning Rate: 2.41137e-05
	LOSS [training: 0.2854044518981443 | validation: 0.37518880562870993]
	TIME [epoch: 9.09 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2911987385051086		[learning rate: 2.4026e-05]
	Learning Rate: 2.40262e-05
	LOSS [training: 0.2911987385051086 | validation: 0.389161065159166]
	TIME [epoch: 9.08 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29719879407548355		[learning rate: 2.3939e-05]
	Learning Rate: 2.3939e-05
	LOSS [training: 0.29719879407548355 | validation: 0.38867247866894555]
	TIME [epoch: 9.07 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2920813031319661		[learning rate: 2.3852e-05]
	Learning Rate: 2.38521e-05
	LOSS [training: 0.2920813031319661 | validation: 0.3866450327212666]
	TIME [epoch: 9.08 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2930573767533704		[learning rate: 2.3766e-05]
	Learning Rate: 2.37655e-05
	LOSS [training: 0.2930573767533704 | validation: 0.38933613469406547]
	TIME [epoch: 9.08 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2772116357219711		[learning rate: 2.3679e-05]
	Learning Rate: 2.36793e-05
	LOSS [training: 0.2772116357219711 | validation: 0.40718344733725836]
	TIME [epoch: 9.09 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2908625845620214		[learning rate: 2.3593e-05]
	Learning Rate: 2.35933e-05
	LOSS [training: 0.2908625845620214 | validation: 0.4082081364667013]
	TIME [epoch: 9.08 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28672373205520163		[learning rate: 2.3508e-05]
	Learning Rate: 2.35077e-05
	LOSS [training: 0.28672373205520163 | validation: 0.37923657068249605]
	TIME [epoch: 9.08 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2785248415601594		[learning rate: 2.3422e-05]
	Learning Rate: 2.34224e-05
	LOSS [training: 0.2785248415601594 | validation: 0.4014303853298132]
	TIME [epoch: 9.09 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29602266980479297		[learning rate: 2.3337e-05]
	Learning Rate: 2.33374e-05
	LOSS [training: 0.29602266980479297 | validation: 0.3671934236062242]
	TIME [epoch: 9.08 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2950146632778419		[learning rate: 2.3253e-05]
	Learning Rate: 2.32527e-05
	LOSS [training: 0.2950146632778419 | validation: 0.3889440119189373]
	TIME [epoch: 9.1 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2897718257421373		[learning rate: 2.3168e-05]
	Learning Rate: 2.31683e-05
	LOSS [training: 0.2897718257421373 | validation: 0.3906816765417615]
	TIME [epoch: 9.08 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2849725776393527		[learning rate: 2.3084e-05]
	Learning Rate: 2.30843e-05
	LOSS [training: 0.2849725776393527 | validation: 0.3959804074952422]
	TIME [epoch: 9.08 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29148769066318053		[learning rate: 2.3e-05]
	Learning Rate: 2.30005e-05
	LOSS [training: 0.29148769066318053 | validation: 0.3946581021262406]
	TIME [epoch: 9.08 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29473854169423386		[learning rate: 2.2917e-05]
	Learning Rate: 2.2917e-05
	LOSS [training: 0.29473854169423386 | validation: 0.39818446319281575]
	TIME [epoch: 9.11 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28783543387740473		[learning rate: 2.2834e-05]
	Learning Rate: 2.28338e-05
	LOSS [training: 0.28783543387740473 | validation: 0.3988992064402169]
	TIME [epoch: 9.08 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2810031117894595		[learning rate: 2.2751e-05]
	Learning Rate: 2.2751e-05
	LOSS [training: 0.2810031117894595 | validation: 0.3812748576692206]
	TIME [epoch: 9.09 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29631964676432065		[learning rate: 2.2668e-05]
	Learning Rate: 2.26684e-05
	LOSS [training: 0.29631964676432065 | validation: 0.3886573709003977]
	TIME [epoch: 9.08 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2996304072115401		[learning rate: 2.2586e-05]
	Learning Rate: 2.25862e-05
	LOSS [training: 0.2996304072115401 | validation: 0.3984381360963718]
	TIME [epoch: 9.09 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2855932143577534		[learning rate: 2.2504e-05]
	Learning Rate: 2.25042e-05
	LOSS [training: 0.2855932143577534 | validation: 0.39203106065545734]
	TIME [epoch: 9.1 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28640571141701976		[learning rate: 2.2423e-05]
	Learning Rate: 2.24225e-05
	LOSS [training: 0.28640571141701976 | validation: 0.39834893530424664]
	TIME [epoch: 9.09 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29187249187550374		[learning rate: 2.2341e-05]
	Learning Rate: 2.23411e-05
	LOSS [training: 0.29187249187550374 | validation: 0.37123262092085396]
	TIME [epoch: 9.09 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2903480511340811		[learning rate: 2.226e-05]
	Learning Rate: 2.22601e-05
	LOSS [training: 0.2903480511340811 | validation: 0.39201122379334447]
	TIME [epoch: 9.09 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29303146303744704		[learning rate: 2.2179e-05]
	Learning Rate: 2.21793e-05
	LOSS [training: 0.29303146303744704 | validation: 0.40047108007610177]
	TIME [epoch: 9.1 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2910888805968678		[learning rate: 2.2099e-05]
	Learning Rate: 2.20988e-05
	LOSS [training: 0.2910888805968678 | validation: 0.3900271051119175]
	TIME [epoch: 9.09 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2987123058877097		[learning rate: 2.2019e-05]
	Learning Rate: 2.20186e-05
	LOSS [training: 0.2987123058877097 | validation: 0.39886890122053803]
	TIME [epoch: 9.08 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892063008303499		[learning rate: 2.1939e-05]
	Learning Rate: 2.19387e-05
	LOSS [training: 0.2892063008303499 | validation: 0.37384904061087104]
	TIME [epoch: 9.08 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29511765991309197		[learning rate: 2.1859e-05]
	Learning Rate: 2.18591e-05
	LOSS [training: 0.29511765991309197 | validation: 0.3827832216355228]
	TIME [epoch: 9.08 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2853523096157911		[learning rate: 2.178e-05]
	Learning Rate: 2.17797e-05
	LOSS [training: 0.2853523096157911 | validation: 0.38523784403348027]
	TIME [epoch: 9.1 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2856748152495347		[learning rate: 2.1701e-05]
	Learning Rate: 2.17007e-05
	LOSS [training: 0.2856748152495347 | validation: 0.3787541834833992]
	TIME [epoch: 9.09 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29277435654502393		[learning rate: 2.1622e-05]
	Learning Rate: 2.16219e-05
	LOSS [training: 0.29277435654502393 | validation: 0.39712522305725495]
	TIME [epoch: 9.08 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29180147000743273		[learning rate: 2.1543e-05]
	Learning Rate: 2.15435e-05
	LOSS [training: 0.29180147000743273 | validation: 0.39162727004980974]
	TIME [epoch: 9.08 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28656980085036443		[learning rate: 2.1465e-05]
	Learning Rate: 2.14653e-05
	LOSS [training: 0.28656980085036443 | validation: 0.39364688618139937]
	TIME [epoch: 9.08 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28356607417192137		[learning rate: 2.1387e-05]
	Learning Rate: 2.13874e-05
	LOSS [training: 0.28356607417192137 | validation: 0.403208779426785]
	TIME [epoch: 9.11 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.291586332445922		[learning rate: 2.131e-05]
	Learning Rate: 2.13098e-05
	LOSS [training: 0.291586332445922 | validation: 0.38150238615968673]
	TIME [epoch: 9.1 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2983022099400535		[learning rate: 2.1232e-05]
	Learning Rate: 2.12325e-05
	LOSS [training: 0.2983022099400535 | validation: 0.381255253580954]
	TIME [epoch: 9.09 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29398221583732614		[learning rate: 2.1155e-05]
	Learning Rate: 2.11554e-05
	LOSS [training: 0.29398221583732614 | validation: 0.39186486695395223]
	TIME [epoch: 9.1 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29137805115602144		[learning rate: 2.1079e-05]
	Learning Rate: 2.10786e-05
	LOSS [training: 0.29137805115602144 | validation: 0.39489063356660836]
	TIME [epoch: 9.11 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29237610572779643		[learning rate: 2.1002e-05]
	Learning Rate: 2.10021e-05
	LOSS [training: 0.29237610572779643 | validation: 0.38195240128462976]
	TIME [epoch: 9.09 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2973517790832827		[learning rate: 2.0926e-05]
	Learning Rate: 2.09259e-05
	LOSS [training: 0.2973517790832827 | validation: 0.3803888877142012]
	TIME [epoch: 9.08 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28420294510725697		[learning rate: 2.085e-05]
	Learning Rate: 2.085e-05
	LOSS [training: 0.28420294510725697 | validation: 0.3702590915518316]
	TIME [epoch: 9.09 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29162011028269386		[learning rate: 2.0774e-05]
	Learning Rate: 2.07743e-05
	LOSS [training: 0.29162011028269386 | validation: 0.41216987994704934]
	TIME [epoch: 9.09 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2832442551222138		[learning rate: 2.0699e-05]
	Learning Rate: 2.06989e-05
	LOSS [training: 0.2832442551222138 | validation: 0.38044315591847544]
	TIME [epoch: 9.11 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2873288338456576		[learning rate: 2.0624e-05]
	Learning Rate: 2.06238e-05
	LOSS [training: 0.2873288338456576 | validation: 0.3993928973469588]
	TIME [epoch: 9.08 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28716771300459293		[learning rate: 2.0549e-05]
	Learning Rate: 2.05489e-05
	LOSS [training: 0.28716771300459293 | validation: 0.3966128933847505]
	TIME [epoch: 9.08 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28156820928815557		[learning rate: 2.0474e-05]
	Learning Rate: 2.04744e-05
	LOSS [training: 0.28156820928815557 | validation: 0.3940954879729343]
	TIME [epoch: 9.08 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29319059113981694		[learning rate: 2.04e-05]
	Learning Rate: 2.04001e-05
	LOSS [training: 0.29319059113981694 | validation: 0.39501495061653075]
	TIME [epoch: 9.1 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29320715978246925		[learning rate: 2.0326e-05]
	Learning Rate: 2.0326e-05
	LOSS [training: 0.29320715978246925 | validation: 0.3839960049196792]
	TIME [epoch: 9.1 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29100256249137024		[learning rate: 2.0252e-05]
	Learning Rate: 2.02523e-05
	LOSS [training: 0.29100256249137024 | validation: 0.3820793001520689]
	TIME [epoch: 9.08 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28491185255373974		[learning rate: 2.0179e-05]
	Learning Rate: 2.01788e-05
	LOSS [training: 0.28491185255373974 | validation: 0.3729777261912788]
	TIME [epoch: 9.09 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28887153352340367		[learning rate: 2.0106e-05]
	Learning Rate: 2.01055e-05
	LOSS [training: 0.28887153352340367 | validation: 0.36497659215608025]
	TIME [epoch: 9.07 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.279148845450873		[learning rate: 2.0033e-05]
	Learning Rate: 2.00326e-05
	LOSS [training: 0.279148845450873 | validation: 0.3799932363809295]
	TIME [epoch: 9.09 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2823860288072676		[learning rate: 1.996e-05]
	Learning Rate: 1.99599e-05
	LOSS [training: 0.2823860288072676 | validation: 0.4076216576023648]
	TIME [epoch: 9.09 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2899905536658085		[learning rate: 1.9887e-05]
	Learning Rate: 1.98874e-05
	LOSS [training: 0.2899905536658085 | validation: 0.3789051817611493]
	TIME [epoch: 9.08 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2945403969403505		[learning rate: 1.9815e-05]
	Learning Rate: 1.98153e-05
	LOSS [training: 0.2945403969403505 | validation: 0.38607794005089013]
	TIME [epoch: 9.08 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2798223511233036		[learning rate: 1.9743e-05]
	Learning Rate: 1.97434e-05
	LOSS [training: 0.2798223511233036 | validation: 0.37482017927172395]
	TIME [epoch: 9.09 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2831978834942551		[learning rate: 1.9672e-05]
	Learning Rate: 1.96717e-05
	LOSS [training: 0.2831978834942551 | validation: 0.39071301135578085]
	TIME [epoch: 9.09 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.292069155245945		[learning rate: 1.96e-05]
	Learning Rate: 1.96003e-05
	LOSS [training: 0.292069155245945 | validation: 0.3707881472570489]
	TIME [epoch: 9.08 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2778436291392192		[learning rate: 1.9529e-05]
	Learning Rate: 1.95292e-05
	LOSS [training: 0.2778436291392192 | validation: 0.39753771025027657]
	TIME [epoch: 9.08 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28049763555917384		[learning rate: 1.9458e-05]
	Learning Rate: 1.94583e-05
	LOSS [training: 0.28049763555917384 | validation: 0.3970028956749375]
	TIME [epoch: 9.08 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2944340900652746		[learning rate: 1.9388e-05]
	Learning Rate: 1.93877e-05
	LOSS [training: 0.2944340900652746 | validation: 0.38529016941728084]
	TIME [epoch: 9.11 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29374741316664144		[learning rate: 1.9317e-05]
	Learning Rate: 1.93173e-05
	LOSS [training: 0.29374741316664144 | validation: 0.3892502220463338]
	TIME [epoch: 9.08 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29203886688732333		[learning rate: 1.9247e-05]
	Learning Rate: 1.92472e-05
	LOSS [training: 0.29203886688732333 | validation: 0.3797125717657388]
	TIME [epoch: 9.09 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2849114581882632		[learning rate: 1.9177e-05]
	Learning Rate: 1.91774e-05
	LOSS [training: 0.2849114581882632 | validation: 0.371474701857286]
	TIME [epoch: 9.07 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2900347067252396		[learning rate: 1.9108e-05]
	Learning Rate: 1.91078e-05
	LOSS [training: 0.2900347067252396 | validation: 0.38701344620427847]
	TIME [epoch: 9.08 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28195369677990245		[learning rate: 1.9038e-05]
	Learning Rate: 1.90384e-05
	LOSS [training: 0.28195369677990245 | validation: 0.37841639926946286]
	TIME [epoch: 9.1 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2852616089633811		[learning rate: 1.8969e-05]
	Learning Rate: 1.89694e-05
	LOSS [training: 0.2852616089633811 | validation: 0.3806773016152312]
	TIME [epoch: 9.07 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29003274042248606		[learning rate: 1.8901e-05]
	Learning Rate: 1.89005e-05
	LOSS [training: 0.29003274042248606 | validation: 0.40715217885910965]
	TIME [epoch: 9.08 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2875084373940278		[learning rate: 1.8832e-05]
	Learning Rate: 1.88319e-05
	LOSS [training: 0.2875084373940278 | validation: 0.3908744546225271]
	TIME [epoch: 9.08 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2878816258649775		[learning rate: 1.8764e-05]
	Learning Rate: 1.87636e-05
	LOSS [training: 0.2878816258649775 | validation: 0.38693493353134156]
	TIME [epoch: 9.1 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28287049231316064		[learning rate: 1.8695e-05]
	Learning Rate: 1.86955e-05
	LOSS [training: 0.28287049231316064 | validation: 0.3916926287470119]
	TIME [epoch: 9.09 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.295440853404098		[learning rate: 1.8628e-05]
	Learning Rate: 1.86276e-05
	LOSS [training: 0.295440853404098 | validation: 0.39426476085266565]
	TIME [epoch: 9.08 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2969928668255192		[learning rate: 1.856e-05]
	Learning Rate: 1.856e-05
	LOSS [training: 0.2969928668255192 | validation: 0.3955463396789969]
	TIME [epoch: 9.08 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2855000283228837		[learning rate: 1.8493e-05]
	Learning Rate: 1.84927e-05
	LOSS [training: 0.2855000283228837 | validation: 0.3952606677645325]
	TIME [epoch: 9.08 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2908353228739508		[learning rate: 1.8426e-05]
	Learning Rate: 1.84256e-05
	LOSS [training: 0.2908353228739508 | validation: 0.3905724421547049]
	TIME [epoch: 9.1 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2814217825405009		[learning rate: 1.8359e-05]
	Learning Rate: 1.83587e-05
	LOSS [training: 0.2814217825405009 | validation: 0.3982759985534687]
	TIME [epoch: 9.09 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2896994499956967		[learning rate: 1.8292e-05]
	Learning Rate: 1.82921e-05
	LOSS [training: 0.2896994499956967 | validation: 0.3703622632671819]
	TIME [epoch: 9.08 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2818324625196822		[learning rate: 1.8226e-05]
	Learning Rate: 1.82257e-05
	LOSS [training: 0.2818324625196822 | validation: 0.39281267146065824]
	TIME [epoch: 9.08 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29397847707419816		[learning rate: 1.816e-05]
	Learning Rate: 1.81596e-05
	LOSS [training: 0.29397847707419816 | validation: 0.38695887129492784]
	TIME [epoch: 9.1 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28121719995589134		[learning rate: 1.8094e-05]
	Learning Rate: 1.80937e-05
	LOSS [training: 0.28121719995589134 | validation: 0.3762319196951957]
	TIME [epoch: 9.08 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2880370505429674		[learning rate: 1.8028e-05]
	Learning Rate: 1.8028e-05
	LOSS [training: 0.2880370505429674 | validation: 0.3804118022452438]
	TIME [epoch: 9.09 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28882871227597373		[learning rate: 1.7963e-05]
	Learning Rate: 1.79626e-05
	LOSS [training: 0.28882871227597373 | validation: 0.4128961229720467]
	TIME [epoch: 9.08 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28908588631906157		[learning rate: 1.7897e-05]
	Learning Rate: 1.78974e-05
	LOSS [training: 0.28908588631906157 | validation: 0.3656796633355157]
	TIME [epoch: 9.08 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29091919288257134		[learning rate: 1.7832e-05]
	Learning Rate: 1.78324e-05
	LOSS [training: 0.29091919288257134 | validation: 0.38626297246327307]
	TIME [epoch: 9.1 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28800580530011594		[learning rate: 1.7768e-05]
	Learning Rate: 1.77677e-05
	LOSS [training: 0.28800580530011594 | validation: 0.36892540880426244]
	TIME [epoch: 9.08 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2946244315716318		[learning rate: 1.7703e-05]
	Learning Rate: 1.77032e-05
	LOSS [training: 0.2946244315716318 | validation: 0.3798379075101727]
	TIME [epoch: 9.08 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29636414704826913		[learning rate: 1.7639e-05]
	Learning Rate: 1.7639e-05
	LOSS [training: 0.29636414704826913 | validation: 0.39583180202145124]
	TIME [epoch: 9.08 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2921984750289631		[learning rate: 1.7575e-05]
	Learning Rate: 1.7575e-05
	LOSS [training: 0.2921984750289631 | validation: 0.3816989218073561]
	TIME [epoch: 9.09 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29232611411282083		[learning rate: 1.7511e-05]
	Learning Rate: 1.75112e-05
	LOSS [training: 0.29232611411282083 | validation: 0.37216775161467486]
	TIME [epoch: 9.1 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29547593543072387		[learning rate: 1.7448e-05]
	Learning Rate: 1.74476e-05
	LOSS [training: 0.29547593543072387 | validation: 0.3959346184772626]
	TIME [epoch: 9.08 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28536598530414653		[learning rate: 1.7384e-05]
	Learning Rate: 1.73843e-05
	LOSS [training: 0.28536598530414653 | validation: 0.39036617681841673]
	TIME [epoch: 9.08 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2909941045181685		[learning rate: 1.7321e-05]
	Learning Rate: 1.73212e-05
	LOSS [training: 0.2909941045181685 | validation: 0.38258935819639617]
	TIME [epoch: 9.07 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29379066255913333		[learning rate: 1.7258e-05]
	Learning Rate: 1.72584e-05
	LOSS [training: 0.29379066255913333 | validation: 0.403872289957403]
	TIME [epoch: 9.09 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.284219454216605		[learning rate: 1.7196e-05]
	Learning Rate: 1.71957e-05
	LOSS [training: 0.284219454216605 | validation: 0.38573152740316946]
	TIME [epoch: 9.07 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28656718687966365		[learning rate: 1.7133e-05]
	Learning Rate: 1.71333e-05
	LOSS [training: 0.28656718687966365 | validation: 0.3918775533289057]
	TIME [epoch: 9.07 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28670702655144376		[learning rate: 1.7071e-05]
	Learning Rate: 1.70712e-05
	LOSS [training: 0.28670702655144376 | validation: 0.3916087458093768]
	TIME [epoch: 9.07 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28794195481655954		[learning rate: 1.7009e-05]
	Learning Rate: 1.70092e-05
	LOSS [training: 0.28794195481655954 | validation: 0.39465203933259757]
	TIME [epoch: 9.07 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2968977466089969		[learning rate: 1.6947e-05]
	Learning Rate: 1.69475e-05
	LOSS [training: 0.2968977466089969 | validation: 0.36971438147341995]
	TIME [epoch: 9.09 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29258627205389826		[learning rate: 1.6886e-05]
	Learning Rate: 1.6886e-05
	LOSS [training: 0.29258627205389826 | validation: 0.38917235230498537]
	TIME [epoch: 9.08 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.288756480951213		[learning rate: 1.6825e-05]
	Learning Rate: 1.68247e-05
	LOSS [training: 0.288756480951213 | validation: 0.3873921572712978]
	TIME [epoch: 9.09 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29491091700558053		[learning rate: 1.6764e-05]
	Learning Rate: 1.67636e-05
	LOSS [training: 0.29491091700558053 | validation: 0.3997587337615702]
	TIME [epoch: 9.09 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28101996076733576		[learning rate: 1.6703e-05]
	Learning Rate: 1.67028e-05
	LOSS [training: 0.28101996076733576 | validation: 0.4029348410694808]
	TIME [epoch: 9.11 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29373680664237656		[learning rate: 1.6642e-05]
	Learning Rate: 1.66422e-05
	LOSS [training: 0.29373680664237656 | validation: 0.39520564530019153]
	TIME [epoch: 9.09 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2990681791469421		[learning rate: 1.6582e-05]
	Learning Rate: 1.65818e-05
	LOSS [training: 0.2990681791469421 | validation: 0.3977511865461858]
	TIME [epoch: 9.08 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2889184657814092		[learning rate: 1.6522e-05]
	Learning Rate: 1.65216e-05
	LOSS [training: 0.2889184657814092 | validation: 0.3836255272669469]
	TIME [epoch: 9.06 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2869514467984122		[learning rate: 1.6462e-05]
	Learning Rate: 1.64617e-05
	LOSS [training: 0.2869514467984122 | validation: 0.3818613735257373]
	TIME [epoch: 9.07 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28677391774832567		[learning rate: 1.6402e-05]
	Learning Rate: 1.64019e-05
	LOSS [training: 0.28677391774832567 | validation: 0.3796879193703311]
	TIME [epoch: 9.1 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.292205362966803		[learning rate: 1.6342e-05]
	Learning Rate: 1.63424e-05
	LOSS [training: 0.292205362966803 | validation: 0.40131606836736483]
	TIME [epoch: 9.07 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29203274437439725		[learning rate: 1.6283e-05]
	Learning Rate: 1.62831e-05
	LOSS [training: 0.29203274437439725 | validation: 0.37930823447097983]
	TIME [epoch: 9.07 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2859731989384583		[learning rate: 1.6224e-05]
	Learning Rate: 1.6224e-05
	LOSS [training: 0.2859731989384583 | validation: 0.37764806613318636]
	TIME [epoch: 9.07 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28871072339891607		[learning rate: 1.6165e-05]
	Learning Rate: 1.61651e-05
	LOSS [training: 0.28871072339891607 | validation: 0.40295839204447725]
	TIME [epoch: 9.09 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29617693180031435		[learning rate: 1.6106e-05]
	Learning Rate: 1.61065e-05
	LOSS [training: 0.29617693180031435 | validation: 0.39083736103913613]
	TIME [epoch: 9.07 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.284700703128011		[learning rate: 1.6048e-05]
	Learning Rate: 1.6048e-05
	LOSS [training: 0.284700703128011 | validation: 0.3918220916704426]
	TIME [epoch: 9.07 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29695271226790537		[learning rate: 1.599e-05]
	Learning Rate: 1.59898e-05
	LOSS [training: 0.29695271226790537 | validation: 0.387691921877652]
	TIME [epoch: 9.08 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892726718568638		[learning rate: 1.5932e-05]
	Learning Rate: 1.59317e-05
	LOSS [training: 0.2892726718568638 | validation: 0.39728851235167445]
	TIME [epoch: 9.08 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2888437417028071		[learning rate: 1.5874e-05]
	Learning Rate: 1.58739e-05
	LOSS [training: 0.2888437417028071 | validation: 0.37861749038109405]
	TIME [epoch: 9.1 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2889874161641256		[learning rate: 1.5816e-05]
	Learning Rate: 1.58163e-05
	LOSS [training: 0.2889874161641256 | validation: 0.37209497089530136]
	TIME [epoch: 9.08 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2971571021519518		[learning rate: 1.5759e-05]
	Learning Rate: 1.57589e-05
	LOSS [training: 0.2971571021519518 | validation: 0.3835653119374428]
	TIME [epoch: 9.07 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2851981586008338		[learning rate: 1.5702e-05]
	Learning Rate: 1.57017e-05
	LOSS [training: 0.2851981586008338 | validation: 0.3933641554563288]
	TIME [epoch: 9.07 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2907636407632115		[learning rate: 1.5645e-05]
	Learning Rate: 1.56447e-05
	LOSS [training: 0.2907636407632115 | validation: 0.38135292882407174]
	TIME [epoch: 9.09 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29301441316987314		[learning rate: 1.5588e-05]
	Learning Rate: 1.5588e-05
	LOSS [training: 0.29301441316987314 | validation: 0.3874969918848673]
	TIME [epoch: 9.08 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29390031547271894		[learning rate: 1.5531e-05]
	Learning Rate: 1.55314e-05
	LOSS [training: 0.29390031547271894 | validation: 0.3788623685239169]
	TIME [epoch: 9.07 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28593307967795456		[learning rate: 1.5475e-05]
	Learning Rate: 1.5475e-05
	LOSS [training: 0.28593307967795456 | validation: 0.3883646696698687]
	TIME [epoch: 9.06 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29241756801881374		[learning rate: 1.5419e-05]
	Learning Rate: 1.54189e-05
	LOSS [training: 0.29241756801881374 | validation: 0.376610332708152]
	TIME [epoch: 9.07 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28838734984092845		[learning rate: 1.5363e-05]
	Learning Rate: 1.53629e-05
	LOSS [training: 0.28838734984092845 | validation: 0.38911486873533846]
	TIME [epoch: 9.1 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28959200407474234		[learning rate: 1.5307e-05]
	Learning Rate: 1.53072e-05
	LOSS [training: 0.28959200407474234 | validation: 0.3836936660143835]
	TIME [epoch: 9.08 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28878754094779796		[learning rate: 1.5252e-05]
	Learning Rate: 1.52516e-05
	LOSS [training: 0.28878754094779796 | validation: 0.40067404568545173]
	TIME [epoch: 9.09 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2895045827905188		[learning rate: 1.5196e-05]
	Learning Rate: 1.51963e-05
	LOSS [training: 0.2895045827905188 | validation: 0.3790125961870025]
	TIME [epoch: 9.07 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2762724899009298		[learning rate: 1.5141e-05]
	Learning Rate: 1.51411e-05
	LOSS [training: 0.2762724899009298 | validation: 0.3844521990691764]
	TIME [epoch: 9.1 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30003216637480723		[learning rate: 1.5086e-05]
	Learning Rate: 1.50862e-05
	LOSS [training: 0.30003216637480723 | validation: 0.3975754643972925]
	TIME [epoch: 9.08 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.295740321106864		[learning rate: 1.5031e-05]
	Learning Rate: 1.50314e-05
	LOSS [training: 0.295740321106864 | validation: 0.38372513685449416]
	TIME [epoch: 9.07 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28748999395374475		[learning rate: 1.4977e-05]
	Learning Rate: 1.49769e-05
	LOSS [training: 0.28748999395374475 | validation: 0.3919257254372259]
	TIME [epoch: 9.08 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28522356703473406		[learning rate: 1.4923e-05]
	Learning Rate: 1.49225e-05
	LOSS [training: 0.28522356703473406 | validation: 0.3963565816538239]
	TIME [epoch: 9.07 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29042334291085803		[learning rate: 1.4868e-05]
	Learning Rate: 1.48684e-05
	LOSS [training: 0.29042334291085803 | validation: 0.39627359233887033]
	TIME [epoch: 9.1 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2955118027461147		[learning rate: 1.4814e-05]
	Learning Rate: 1.48144e-05
	LOSS [training: 0.2955118027461147 | validation: 0.3922671759872262]
	TIME [epoch: 9.08 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29388915891172934		[learning rate: 1.4761e-05]
	Learning Rate: 1.47606e-05
	LOSS [training: 0.29388915891172934 | validation: 0.381758401415695]
	TIME [epoch: 9.07 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2817850575355118		[learning rate: 1.4707e-05]
	Learning Rate: 1.47071e-05
	LOSS [training: 0.2817850575355118 | validation: 0.37969196864299964]
	TIME [epoch: 9.07 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2882104152857914		[learning rate: 1.4654e-05]
	Learning Rate: 1.46537e-05
	LOSS [training: 0.2882104152857914 | validation: 0.3813057942935845]
	TIME [epoch: 9.07 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2872203681138926		[learning rate: 1.4601e-05]
	Learning Rate: 1.46005e-05
	LOSS [training: 0.2872203681138926 | validation: 0.39083739722925404]
	TIME [epoch: 9.1 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29737638435878017		[learning rate: 1.4548e-05]
	Learning Rate: 1.45475e-05
	LOSS [training: 0.29737638435878017 | validation: 0.40610924055990877]
	TIME [epoch: 9.08 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.288506954282841		[learning rate: 1.4495e-05]
	Learning Rate: 1.44947e-05
	LOSS [training: 0.288506954282841 | validation: 0.3791900976430368]
	TIME [epoch: 9.08 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2842758801013814		[learning rate: 1.4442e-05]
	Learning Rate: 1.44421e-05
	LOSS [training: 0.2842758801013814 | validation: 0.3904541096914786]
	TIME [epoch: 9.07 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2969929750123782		[learning rate: 1.439e-05]
	Learning Rate: 1.43897e-05
	LOSS [training: 0.2969929750123782 | validation: 0.38269564516422255]
	TIME [epoch: 9.09 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.280226054145485		[learning rate: 1.4338e-05]
	Learning Rate: 1.43375e-05
	LOSS [training: 0.280226054145485 | validation: 0.37866580192358784]
	TIME [epoch: 9.08 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954671294023382		[learning rate: 1.4285e-05]
	Learning Rate: 1.42855e-05
	LOSS [training: 0.2954671294023382 | validation: 0.389157361614563]
	TIME [epoch: 9.08 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28075088177775015		[learning rate: 1.4234e-05]
	Learning Rate: 1.42336e-05
	LOSS [training: 0.28075088177775015 | validation: 0.3690179423708789]
	TIME [epoch: 9.07 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2898246538194201		[learning rate: 1.4182e-05]
	Learning Rate: 1.4182e-05
	LOSS [training: 0.2898246538194201 | validation: 0.3622055456139499]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1904.pth
	Model improved!!!
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2773310679154136		[learning rate: 1.4131e-05]
	Learning Rate: 1.41305e-05
	LOSS [training: 0.2773310679154136 | validation: 0.3842683341003592]
	TIME [epoch: 9.08 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29097018748782477		[learning rate: 1.4079e-05]
	Learning Rate: 1.40792e-05
	LOSS [training: 0.29097018748782477 | validation: 0.38589633108510574]
	TIME [epoch: 9.06 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29094451466166593		[learning rate: 1.4028e-05]
	Learning Rate: 1.40281e-05
	LOSS [training: 0.29094451466166593 | validation: 0.3802669767182163]
	TIME [epoch: 9.07 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2902149926687535		[learning rate: 1.3977e-05]
	Learning Rate: 1.39772e-05
	LOSS [training: 0.2902149926687535 | validation: 0.388119805463299]
	TIME [epoch: 9.06 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28475592075909795		[learning rate: 1.3927e-05]
	Learning Rate: 1.39265e-05
	LOSS [training: 0.28475592075909795 | validation: 0.39524280488837527]
	TIME [epoch: 9.07 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28607578846224946		[learning rate: 1.3876e-05]
	Learning Rate: 1.3876e-05
	LOSS [training: 0.28607578846224946 | validation: 0.39018818722599524]
	TIME [epoch: 9.09 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28374875451100917		[learning rate: 1.3826e-05]
	Learning Rate: 1.38256e-05
	LOSS [training: 0.28374875451100917 | validation: 0.392438751489247]
	TIME [epoch: 9.08 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28742476919557103		[learning rate: 1.3775e-05]
	Learning Rate: 1.37754e-05
	LOSS [training: 0.28742476919557103 | validation: 0.37975738355671834]
	TIME [epoch: 9.08 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29222005093934644		[learning rate: 1.3725e-05]
	Learning Rate: 1.37254e-05
	LOSS [training: 0.29222005093934644 | validation: 0.37396209459722196]
	TIME [epoch: 9.06 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2771046113962967		[learning rate: 1.3676e-05]
	Learning Rate: 1.36756e-05
	LOSS [training: 0.2771046113962967 | validation: 0.37346818552200634]
	TIME [epoch: 9.09 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2918468489292643		[learning rate: 1.3626e-05]
	Learning Rate: 1.3626e-05
	LOSS [training: 0.2918468489292643 | validation: 0.37892182996400203]
	TIME [epoch: 9.07 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2879633010211212		[learning rate: 1.3577e-05]
	Learning Rate: 1.35766e-05
	LOSS [training: 0.2879633010211212 | validation: 0.3844076394401213]
	TIME [epoch: 9.07 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29299173748607926		[learning rate: 1.3527e-05]
	Learning Rate: 1.35273e-05
	LOSS [training: 0.29299173748607926 | validation: 0.3833796560177433]
	TIME [epoch: 9.08 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28978178041615016		[learning rate: 1.3478e-05]
	Learning Rate: 1.34782e-05
	LOSS [training: 0.28978178041615016 | validation: 0.3822367493498417]
	TIME [epoch: 9.06 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28115940766682285		[learning rate: 1.3429e-05]
	Learning Rate: 1.34293e-05
	LOSS [training: 0.28115940766682285 | validation: 0.36189836676336107]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r2_20240219_195044/states/model_tr_study203_1919.pth
	Model improved!!!
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28430561177943736		[learning rate: 1.3381e-05]
	Learning Rate: 1.33805e-05
	LOSS [training: 0.28430561177943736 | validation: 0.397990325220811]
	TIME [epoch: 9.06 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29051507647729313		[learning rate: 1.3332e-05]
	Learning Rate: 1.3332e-05
	LOSS [training: 0.29051507647729313 | validation: 0.3739500170134079]
	TIME [epoch: 9.06 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28554399768254035		[learning rate: 1.3284e-05]
	Learning Rate: 1.32836e-05
	LOSS [training: 0.28554399768254035 | validation: 0.38075992323228647]
	TIME [epoch: 9.06 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2914440296143003		[learning rate: 1.3235e-05]
	Learning Rate: 1.32354e-05
	LOSS [training: 0.2914440296143003 | validation: 0.38142085619360866]
	TIME [epoch: 9.07 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29186525192302243		[learning rate: 1.3187e-05]
	Learning Rate: 1.31874e-05
	LOSS [training: 0.29186525192302243 | validation: 0.3858277229119517]
	TIME [epoch: 9.09 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29744586052200106		[learning rate: 1.314e-05]
	Learning Rate: 1.31395e-05
	LOSS [training: 0.29744586052200106 | validation: 0.388616082497088]
	TIME [epoch: 9.08 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2874133020367312		[learning rate: 1.3092e-05]
	Learning Rate: 1.30918e-05
	LOSS [training: 0.2874133020367312 | validation: 0.38253259653175864]
	TIME [epoch: 9.06 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2889798545969957		[learning rate: 1.3044e-05]
	Learning Rate: 1.30443e-05
	LOSS [training: 0.2889798545969957 | validation: 0.3906106888782388]
	TIME [epoch: 9.07 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29277297629612925		[learning rate: 1.2997e-05]
	Learning Rate: 1.2997e-05
	LOSS [training: 0.29277297629612925 | validation: 0.3948108532022448]
	TIME [epoch: 9.06 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30125398481112653		[learning rate: 1.295e-05]
	Learning Rate: 1.29498e-05
	LOSS [training: 0.30125398481112653 | validation: 0.3967197502267529]
	TIME [epoch: 9.08 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2908077542660067		[learning rate: 1.2903e-05]
	Learning Rate: 1.29028e-05
	LOSS [training: 0.2908077542660067 | validation: 0.39983012380937816]
	TIME [epoch: 9.06 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29150515487569884		[learning rate: 1.2856e-05]
	Learning Rate: 1.2856e-05
	LOSS [training: 0.29150515487569884 | validation: 0.3912110988789531]
	TIME [epoch: 9.06 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29924901203843596		[learning rate: 1.2809e-05]
	Learning Rate: 1.28093e-05
	LOSS [training: 0.29924901203843596 | validation: 0.3846579960640989]
	TIME [epoch: 9.07 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29757635938327837		[learning rate: 1.2763e-05]
	Learning Rate: 1.27628e-05
	LOSS [training: 0.29757635938327837 | validation: 0.38594214705842483]
	TIME [epoch: 9.07 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29385627422027544		[learning rate: 1.2717e-05]
	Learning Rate: 1.27165e-05
	LOSS [training: 0.29385627422027544 | validation: 0.39657653253728686]
	TIME [epoch: 9.08 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29633001151998145		[learning rate: 1.267e-05]
	Learning Rate: 1.26704e-05
	LOSS [training: 0.29633001151998145 | validation: 0.39653205959662785]
	TIME [epoch: 9.07 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29483758066120985		[learning rate: 1.2624e-05]
	Learning Rate: 1.26244e-05
	LOSS [training: 0.29483758066120985 | validation: 0.3925962386796814]
	TIME [epoch: 9.06 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2916890773867616		[learning rate: 1.2579e-05]
	Learning Rate: 1.25786e-05
	LOSS [training: 0.2916890773867616 | validation: 0.3832750148759327]
	TIME [epoch: 9.08 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2900533675687399		[learning rate: 1.2533e-05]
	Learning Rate: 1.25329e-05
	LOSS [training: 0.2900533675687399 | validation: 0.3893087893778736]
	TIME [epoch: 9.09 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28836330014528694		[learning rate: 1.2487e-05]
	Learning Rate: 1.24874e-05
	LOSS [training: 0.28836330014528694 | validation: 0.3852741677864483]
	TIME [epoch: 9.07 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954132088691214		[learning rate: 1.2442e-05]
	Learning Rate: 1.24421e-05
	LOSS [training: 0.2954132088691214 | validation: 0.3988901545172707]
	TIME [epoch: 9.07 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.283558490304982		[learning rate: 1.2397e-05]
	Learning Rate: 1.2397e-05
	LOSS [training: 0.283558490304982 | validation: 0.39396047097279646]
	TIME [epoch: 9.05 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2807644866307018		[learning rate: 1.2352e-05]
	Learning Rate: 1.2352e-05
	LOSS [training: 0.2807644866307018 | validation: 0.3898478130114162]
	TIME [epoch: 9.07 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2873387471388007		[learning rate: 1.2307e-05]
	Learning Rate: 1.23072e-05
	LOSS [training: 0.2873387471388007 | validation: 0.3902750185304611]
	TIME [epoch: 9.09 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2803321084626565		[learning rate: 1.2263e-05]
	Learning Rate: 1.22625e-05
	LOSS [training: 0.2803321084626565 | validation: 0.37836723493846225]
	TIME [epoch: 9.06 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2917933974636407		[learning rate: 1.2218e-05]
	Learning Rate: 1.2218e-05
	LOSS [training: 0.2917933974636407 | validation: 0.38699418138574215]
	TIME [epoch: 9.06 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28720901325381293		[learning rate: 1.2174e-05]
	Learning Rate: 1.21737e-05
	LOSS [training: 0.28720901325381293 | validation: 0.3919674994064456]
	TIME [epoch: 9.06 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28490477410319376		[learning rate: 1.2129e-05]
	Learning Rate: 1.21295e-05
	LOSS [training: 0.28490477410319376 | validation: 0.3746745974216774]
	TIME [epoch: 9.08 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2922368819256851		[learning rate: 1.2085e-05]
	Learning Rate: 1.20855e-05
	LOSS [training: 0.2922368819256851 | validation: 0.3874182894128404]
	TIME [epoch: 9.07 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2856507368781539		[learning rate: 1.2042e-05]
	Learning Rate: 1.20416e-05
	LOSS [training: 0.2856507368781539 | validation: 0.37761677716359965]
	TIME [epoch: 9.06 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29450756216360624		[learning rate: 1.1998e-05]
	Learning Rate: 1.19979e-05
	LOSS [training: 0.29450756216360624 | validation: 0.37109024591218287]
	TIME [epoch: 9.07 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28169285654827936		[learning rate: 1.1954e-05]
	Learning Rate: 1.19544e-05
	LOSS [training: 0.28169285654827936 | validation: 0.4086548957004582]
	TIME [epoch: 9.07 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28710914216496713		[learning rate: 1.1911e-05]
	Learning Rate: 1.1911e-05
	LOSS [training: 0.28710914216496713 | validation: 0.38889576793475666]
	TIME [epoch: 9.08 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28759124295877936		[learning rate: 1.1868e-05]
	Learning Rate: 1.18678e-05
	LOSS [training: 0.28759124295877936 | validation: 0.3899075947532601]
	TIME [epoch: 9.06 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2846345962784017		[learning rate: 1.1825e-05]
	Learning Rate: 1.18247e-05
	LOSS [training: 0.2846345962784017 | validation: 0.39517436456526167]
	TIME [epoch: 9.05 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28674521731447933		[learning rate: 1.1782e-05]
	Learning Rate: 1.17818e-05
	LOSS [training: 0.28674521731447933 | validation: 0.38545185206973975]
	TIME [epoch: 9.06 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2845488439557732		[learning rate: 1.1739e-05]
	Learning Rate: 1.1739e-05
	LOSS [training: 0.2845488439557732 | validation: 0.38879308249409716]
	TIME [epoch: 9.06 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2899276578739879		[learning rate: 1.1696e-05]
	Learning Rate: 1.16964e-05
	LOSS [training: 0.2899276578739879 | validation: 0.37500568886405516]
	TIME [epoch: 9.08 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28044077128097594		[learning rate: 1.1654e-05]
	Learning Rate: 1.1654e-05
	LOSS [training: 0.28044077128097594 | validation: 0.38910991542090223]
	TIME [epoch: 9.06 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28863504454155686		[learning rate: 1.1612e-05]
	Learning Rate: 1.16117e-05
	LOSS [training: 0.28863504454155686 | validation: 0.38122686588016397]
	TIME [epoch: 9.06 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28777056224356384		[learning rate: 1.157e-05]
	Learning Rate: 1.15695e-05
	LOSS [training: 0.28777056224356384 | validation: 0.37447285613266357]
	TIME [epoch: 9.06 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2849140515400888		[learning rate: 1.1528e-05]
	Learning Rate: 1.15275e-05
	LOSS [training: 0.2849140515400888 | validation: 0.37485640295893624]
	TIME [epoch: 9.07 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27925993209533506		[learning rate: 1.1486e-05]
	Learning Rate: 1.14857e-05
	LOSS [training: 0.27925993209533506 | validation: 0.3890650347246647]
	TIME [epoch: 9.06 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2925213553723422		[learning rate: 1.1444e-05]
	Learning Rate: 1.1444e-05
	LOSS [training: 0.2925213553723422 | validation: 0.37585174816016376]
	TIME [epoch: 9.07 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27715577892625876		[learning rate: 1.1402e-05]
	Learning Rate: 1.14025e-05
	LOSS [training: 0.27715577892625876 | validation: 0.39764888961879363]
	TIME [epoch: 9.06 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28516547810254755		[learning rate: 1.1361e-05]
	Learning Rate: 1.13611e-05
	LOSS [training: 0.28516547810254755 | validation: 0.3901472314773332]
	TIME [epoch: 9.06 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28445375579449345		[learning rate: 1.132e-05]
	Learning Rate: 1.13199e-05
	LOSS [training: 0.28445375579449345 | validation: 0.37549042939422583]
	TIME [epoch: 9.07 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29634273441929004		[learning rate: 1.1279e-05]
	Learning Rate: 1.12788e-05
	LOSS [training: 0.29634273441929004 | validation: 0.37313722174459496]
	TIME [epoch: 9.06 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2871176095430284		[learning rate: 1.1238e-05]
	Learning Rate: 1.12379e-05
	LOSS [training: 0.2871176095430284 | validation: 0.37758933583402726]
	TIME [epoch: 9.04 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2881476701629091		[learning rate: 1.1197e-05]
	Learning Rate: 1.11971e-05
	LOSS [training: 0.2881476701629091 | validation: 0.36384740680967664]
	TIME [epoch: 9.01 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2863604601698814		[learning rate: 1.1156e-05]
	Learning Rate: 1.11565e-05
	LOSS [training: 0.2863604601698814 | validation: 0.3717853902304016]
	TIME [epoch: 9.03 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28118367123782556		[learning rate: 1.1116e-05]
	Learning Rate: 1.1116e-05
	LOSS [training: 0.28118367123782556 | validation: 0.3809110599200783]
	TIME [epoch: 9.02 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2874513412345309		[learning rate: 1.1076e-05]
	Learning Rate: 1.10756e-05
	LOSS [training: 0.2874513412345309 | validation: 0.38463984986423716]
	TIME [epoch: 9.01 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861847677212578		[learning rate: 1.1035e-05]
	Learning Rate: 1.10354e-05
	LOSS [training: 0.2861847677212578 | validation: 0.37784854878164137]
	TIME [epoch: 9.02 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29379394529417396		[learning rate: 1.0995e-05]
	Learning Rate: 1.09954e-05
	LOSS [training: 0.29379394529417396 | validation: 0.3753010930925856]
	TIME [epoch: 9.01 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2847491684948		[learning rate: 1.0955e-05]
	Learning Rate: 1.09555e-05
	LOSS [training: 0.2847491684948 | validation: 0.39496439979027487]
	TIME [epoch: 9.03 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29184834169233576		[learning rate: 1.0916e-05]
	Learning Rate: 1.09157e-05
	LOSS [training: 0.29184834169233576 | validation: 0.38597490161157405]
	TIME [epoch: 9.02 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2936924286967424		[learning rate: 1.0876e-05]
	Learning Rate: 1.08761e-05
	LOSS [training: 0.2936924286967424 | validation: 0.36784988341694647]
	TIME [epoch: 9.01 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892082493619853		[learning rate: 1.0837e-05]
	Learning Rate: 1.08366e-05
	LOSS [training: 0.2892082493619853 | validation: 0.38585512692638807]
	TIME [epoch: 9.03 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29365657778753607		[learning rate: 1.0797e-05]
	Learning Rate: 1.07973e-05
	LOSS [training: 0.29365657778753607 | validation: 0.3824884572979046]
	TIME [epoch: 9.01 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2809073235421241		[learning rate: 1.0758e-05]
	Learning Rate: 1.07581e-05
	LOSS [training: 0.2809073235421241 | validation: 0.3807248788149851]
	TIME [epoch: 9.03 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2874592654144597		[learning rate: 1.0719e-05]
	Learning Rate: 1.07191e-05
	LOSS [training: 0.2874592654144597 | validation: 0.3704411414571134]
	TIME [epoch: 9.01 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.287549024441511		[learning rate: 1.068e-05]
	Learning Rate: 1.06802e-05
	LOSS [training: 0.287549024441511 | validation: 0.381987314893801]
	TIME [epoch: 9.01 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29014759750486063		[learning rate: 1.0641e-05]
	Learning Rate: 1.06414e-05
	LOSS [training: 0.29014759750486063 | validation: 0.37351780281238545]
	TIME [epoch: 9.01 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.293076492820821		[learning rate: 1.0603e-05]
	Learning Rate: 1.06028e-05
	LOSS [training: 0.293076492820821 | validation: 0.3718443165013724]
	TIME [epoch: 9.03 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29017820303280145		[learning rate: 1.0564e-05]
	Learning Rate: 1.05643e-05
	LOSS [training: 0.29017820303280145 | validation: 0.3796131991622915]
	TIME [epoch: 9.01 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2895981998367648		[learning rate: 1.0526e-05]
	Learning Rate: 1.0526e-05
	LOSS [training: 0.2895981998367648 | validation: 0.3762367965586333]
	TIME [epoch: 9.01 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28663610016910546		[learning rate: 1.0488e-05]
	Learning Rate: 1.04878e-05
	LOSS [training: 0.28663610016910546 | validation: 0.3860853225496943]
	TIME [epoch: 9.01 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28480389282906465		[learning rate: 1.045e-05]
	Learning Rate: 1.04497e-05
	LOSS [training: 0.28480389282906465 | validation: 0.37772497738793354]
	TIME [epoch: 9.02 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28343471553598143		[learning rate: 1.0412e-05]
	Learning Rate: 1.04118e-05
	LOSS [training: 0.28343471553598143 | validation: 0.3742229886506868]
	TIME [epoch: 9.08 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2887749673878149		[learning rate: 1.0374e-05]
	Learning Rate: 1.0374e-05
	LOSS [training: 0.2887749673878149 | validation: 0.3887503449762083]
	TIME [epoch: 9.08 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.283285314930712		[learning rate: 1.0336e-05]
	Learning Rate: 1.03364e-05
	LOSS [training: 0.283285314930712 | validation: 0.38072808419077175]
	TIME [epoch: 9.08 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28401352281477793		[learning rate: 1.0299e-05]
	Learning Rate: 1.02989e-05
	LOSS [training: 0.28401352281477793 | validation: 0.3892850205943205]
	TIME [epoch: 9.08 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27796810927991067		[learning rate: 1.0261e-05]
	Learning Rate: 1.02615e-05
	LOSS [training: 0.27796810927991067 | validation: 0.3987917608065834]
	TIME [epoch: 9.09 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2935440734274799		[learning rate: 1.0224e-05]
	Learning Rate: 1.02243e-05
	LOSS [training: 0.2935440734274799 | validation: 0.384560086718212]
	TIME [epoch: 9.07 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29798204114316196		[learning rate: 1.0187e-05]
	Learning Rate: 1.01872e-05
	LOSS [training: 0.29798204114316196 | validation: 0.37495446730380033]
	TIME [epoch: 9.09 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2897690849589345		[learning rate: 1.015e-05]
	Learning Rate: 1.01502e-05
	LOSS [training: 0.2897690849589345 | validation: 0.3975447569749699]
	TIME [epoch: 9.09 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28328204483022645		[learning rate: 1.0113e-05]
	Learning Rate: 1.01133e-05
	LOSS [training: 0.28328204483022645 | validation: 0.3917387008511612]
	TIME [epoch: 9.09 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.283353366500105		[learning rate: 1.0077e-05]
	Learning Rate: 1.00766e-05
	LOSS [training: 0.283353366500105 | validation: 0.39620552603482184]
	TIME [epoch: 9.11 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29050102733445154		[learning rate: 1.004e-05]
	Learning Rate: 1.00401e-05
	LOSS [training: 0.29050102733445154 | validation: 0.377323069025396]
	TIME [epoch: 9.09 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2855397197763059		[learning rate: 1.0004e-05]
	Learning Rate: 1.00036e-05
	LOSS [training: 0.2855397197763059 | validation: 0.37933772303844243]
	TIME [epoch: 9.09 sec]
Finished training in 18298.705 seconds.
