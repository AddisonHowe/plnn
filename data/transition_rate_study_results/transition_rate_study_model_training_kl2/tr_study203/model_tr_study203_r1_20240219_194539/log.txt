Args:
Namespace(name='model_tr_study203', outdir='out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1', training_data='data/transition_rate_studies/tr_study203/tr_study203_training/r1', validation_data='data/transition_rate_studies/tr_study203/tr_study203_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4085115234

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.755345906802516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.755345906802516 | validation: 9.14800928257473]
	TIME [epoch: 52.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.308657532875875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.308657532875875 | validation: 8.174341058844927]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.495647021981808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.495647021981808 | validation: 8.862824889362361]
	TIME [epoch: 8.43 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.8252236534652555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8252236534652555 | validation: 8.071881036195125]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.055972841877906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.055972841877906 | validation: 5.393726353415769]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.5247658340060015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5247658340060015 | validation: 5.308791759857874]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.1520404050375745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1520404050375745 | validation: 4.917973676698912]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.090441804093098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.090441804093098 | validation: 5.364170483143385]
	TIME [epoch: 8.43 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.287932604895397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.287932604895397 | validation: 5.0217404801903776]
	TIME [epoch: 8.45 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.730692649523747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.730692649523747 | validation: 4.602203580807709]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4744624042467778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4744624042467778 | validation: 5.122589783005671]
	TIME [epoch: 8.46 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.465273993789551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.465273993789551 | validation: 4.731681144450961]
	TIME [epoch: 8.43 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3372979270963454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3372979270963454 | validation: 4.63309741133417]
	TIME [epoch: 8.46 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2056378439657274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2056378439657274 | validation: 4.48186802332131]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2675241328952334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2675241328952334 | validation: 4.680828849196882]
	TIME [epoch: 8.44 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.072223026758178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.072223026758178 | validation: 4.4151707851209165]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.998659914280459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.998659914280459 | validation: 5.256891577512646]
	TIME [epoch: 8.47 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.178906324607453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.178906324607453 | validation: 5.371131406327365]
	TIME [epoch: 8.43 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.025444012049266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.025444012049266 | validation: 5.249581275751744]
	TIME [epoch: 8.43 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9389503059433593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9389503059433593 | validation: 4.298317824385306]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9809707536013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9809707536013 | validation: 3.9944140384016666]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.787487073883199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.787487073883199 | validation: 4.129554619288738]
	TIME [epoch: 8.44 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8501884378792153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8501884378792153 | validation: 4.2507770187972005]
	TIME [epoch: 8.43 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7038338766371828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7038338766371828 | validation: 4.3062619939436715]
	TIME [epoch: 8.45 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7007248389361336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7007248389361336 | validation: 4.048966800701486]
	TIME [epoch: 8.44 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7055325438336792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7055325438336792 | validation: 3.5657969102985385]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5500861865744016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5500861865744016 | validation: 3.4202991333415986]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4200514073235277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4200514073235277 | validation: 3.5931044118418063]
	TIME [epoch: 8.45 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5287750202312753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5287750202312753 | validation: 3.5503031866257238]
	TIME [epoch: 8.42 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4943720487303516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4943720487303516 | validation: 3.3417456102256744]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.465248214167596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.465248214167596 | validation: 5.244032931261078]
	TIME [epoch: 8.42 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7806481819972215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7806481819972215 | validation: 3.325750006043428]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5346389457898533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5346389457898533 | validation: 3.960107123804801]
	TIME [epoch: 8.42 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.413153366822375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.413153366822375 | validation: 3.636432894389042]
	TIME [epoch: 8.42 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.331739877249676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.331739877249676 | validation: 4.636336650035096]
	TIME [epoch: 8.43 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5743144384872756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5743144384872756 | validation: 3.463277440293493]
	TIME [epoch: 8.44 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3224426858791847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3224426858791847 | validation: 3.266160218168868]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.379938628217358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.379938628217358 | validation: 3.551042881319332]
	TIME [epoch: 8.42 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3464080516296093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3464080516296093 | validation: 3.4769995318667943]
	TIME [epoch: 8.42 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.361002577109063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.361002577109063 | validation: 3.890484027439343]
	TIME [epoch: 8.45 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.416136317395936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.416136317395936 | validation: 3.5886374911973644]
	TIME [epoch: 8.42 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3459094467696717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3459094467696717 | validation: 3.340526179842281]
	TIME [epoch: 8.41 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3638822851626093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3638822851626093 | validation: 3.216905929236073]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3748971468871813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3748971468871813 | validation: 3.6864671230400052]
	TIME [epoch: 8.45 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.33339768433598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.33339768433598 | validation: 3.470803112043961]
	TIME [epoch: 8.42 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2823644728015204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2823644728015204 | validation: 3.386766290081362]
	TIME [epoch: 8.42 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1641310053905904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1641310053905904 | validation: 3.315571901150176]
	TIME [epoch: 8.42 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.263879735570545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.263879735570545 | validation: 3.5725956713188807]
	TIME [epoch: 8.45 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.256996435873474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.256996435873474 | validation: 4.497095122854551]
	TIME [epoch: 8.42 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.276684664418983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.276684664418983 | validation: 2.986930402808234]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3352644126415933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3352644126415933 | validation: 4.181305184288454]
	TIME [epoch: 8.42 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.344193248172334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.344193248172334 | validation: 3.1091468124693584]
	TIME [epoch: 8.44 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1328083054418574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1328083054418574 | validation: 3.2799972981146377]
	TIME [epoch: 8.42 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.275756123748697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.275756123748697 | validation: 4.706963171063417]
	TIME [epoch: 8.42 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.360164844290735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.360164844290735 | validation: 3.007290384645793]
	TIME [epoch: 8.41 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0182789689258622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0182789689258622 | validation: 3.199863380267777]
	TIME [epoch: 8.42 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0825505427203117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0825505427203117 | validation: 4.88638860899758]
	TIME [epoch: 8.43 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.66304343434659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.66304343434659 | validation: 3.4627675998735326]
	TIME [epoch: 8.41 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3177685108849126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3177685108849126 | validation: 3.1897761004570313]
	TIME [epoch: 8.41 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0913622906953004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0913622906953004 | validation: 3.981207498933088]
	TIME [epoch: 8.43 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1199742149473826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1199742149473826 | validation: 3.0662543131655355]
	TIME [epoch: 8.41 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0794730600785374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0794730600785374 | validation: 2.9929468940652724]
	TIME [epoch: 8.41 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.052936062470298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.052936062470298 | validation: 2.941714807296071]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9299231093306903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9299231093306903 | validation: 2.6568735918609647]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9641676770172602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9641676770172602 | validation: 3.162280015049943]
	TIME [epoch: 8.42 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8472557720372607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8472557720372607 | validation: 2.5982226021576387]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7489150291426738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7489150291426738 | validation: 3.0601585208024744]
	TIME [epoch: 8.42 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8624775177395356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8624775177395356 | validation: 2.462377639093156]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7676274605294027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7676274605294027 | validation: 2.2055153157525997]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8167311430042592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8167311430042592 | validation: 2.702733305274841]
	TIME [epoch: 8.42 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6660190777084178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6660190777084178 | validation: 2.522803184183464]
	TIME [epoch: 8.42 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7302206871794947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7302206871794947 | validation: 2.507729740496547]
	TIME [epoch: 8.43 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7608983172510009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7608983172510009 | validation: 5.1296417166612756]
	TIME [epoch: 8.43 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.98645838612371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.98645838612371 | validation: 3.329900587287309]
	TIME [epoch: 8.41 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0177197794695365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0177197794695365 | validation: 2.7411906287051337]
	TIME [epoch: 8.42 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.729834219143506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.729834219143506 | validation: 3.829854731474193]
	TIME [epoch: 8.43 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.163094286987984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.163094286987984 | validation: 2.509777216860159]
	TIME [epoch: 8.44 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0990683382883186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0990683382883186 | validation: 4.063605251656914]
	TIME [epoch: 8.42 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.053875179335727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.053875179335727 | validation: 3.619295362133591]
	TIME [epoch: 8.42 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8364441605028106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8364441605028106 | validation: 3.403147400181966]
	TIME [epoch: 8.45 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7342920303840164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7342920303840164 | validation: 3.2399552388343147]
	TIME [epoch: 8.42 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7082636641016538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7082636641016538 | validation: 2.4910289004767203]
	TIME [epoch: 8.41 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.873957495084801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.873957495084801 | validation: 3.2076484055801027]
	TIME [epoch: 8.42 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6912732073394152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6912732073394152 | validation: 2.5255076236695997]
	TIME [epoch: 8.44 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.915125111496885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.915125111496885 | validation: 2.791838317056965]
	TIME [epoch: 8.41 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7391811706803904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7391811706803904 | validation: 3.8483397219323243]
	TIME [epoch: 8.42 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8875177320503915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8875177320503915 | validation: 2.9730751156723585]
	TIME [epoch: 8.42 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.546357480335802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.546357480335802 | validation: 5.62782955207841]
	TIME [epoch: 8.44 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2829075903742218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2829075903742218 | validation: 4.012804205624219]
	TIME [epoch: 8.42 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9934784398714804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9934784398714804 | validation: 3.7341586493975]
	TIME [epoch: 8.42 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8285034941348464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8285034941348464 | validation: 2.6457651721086695]
	TIME [epoch: 8.41 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7145294284311894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7145294284311894 | validation: 2.3650387122791647]
	TIME [epoch: 8.44 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.14939207620549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.14939207620549 | validation: 3.628401057027017]
	TIME [epoch: 8.42 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7244836946827782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7244836946827782 | validation: 3.58344649146233]
	TIME [epoch: 8.41 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0640043412518154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0640043412518154 | validation: 2.6320269975993336]
	TIME [epoch: 8.41 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.534383684370247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.534383684370247 | validation: 2.794895351310239]
	TIME [epoch: 8.45 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.140060985109173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.140060985109173 | validation: 2.53788085060666]
	TIME [epoch: 8.42 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4534756979759371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4534756979759371 | validation: 2.9661563205742336]
	TIME [epoch: 8.41 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6975297344374245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6975297344374245 | validation: 2.7578182092310115]
	TIME [epoch: 8.43 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6943605836264772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6943605836264772 | validation: 2.979424683646143]
	TIME [epoch: 8.43 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6227922991902464		[learning rate: 0.0099673]
	Learning Rate: 0.00996733
	LOSS [training: 1.6227922991902464 | validation: 2.2887706540232173]
	TIME [epoch: 8.42 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5708183817890686		[learning rate: 0.0099312]
	Learning Rate: 0.00993116
	LOSS [training: 1.5708183817890686 | validation: 3.481685786427457]
	TIME [epoch: 8.42 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.659383072169123		[learning rate: 0.0098951]
	Learning Rate: 0.00989512
	LOSS [training: 1.659383072169123 | validation: 2.229510434380974]
	TIME [epoch: 8.44 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8519593028220644		[learning rate: 0.0098592]
	Learning Rate: 0.00985921
	LOSS [training: 1.8519593028220644 | validation: 2.8804512085065546]
	TIME [epoch: 8.43 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.847476512540822		[learning rate: 0.0098234]
	Learning Rate: 0.00982343
	LOSS [training: 1.847476512540822 | validation: 3.086498961051289]
	TIME [epoch: 8.41 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8517418437579405		[learning rate: 0.0097878]
	Learning Rate: 0.00978778
	LOSS [training: 1.8517418437579405 | validation: 2.9594112166613993]
	TIME [epoch: 8.42 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7793489081109493		[learning rate: 0.0097523]
	Learning Rate: 0.00975226
	LOSS [training: 1.7793489081109493 | validation: 3.03198730087584]
	TIME [epoch: 8.44 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6469372069435255		[learning rate: 0.0097169]
	Learning Rate: 0.00971687
	LOSS [training: 1.6469372069435255 | validation: 3.457738558735275]
	TIME [epoch: 8.42 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8984332765331573		[learning rate: 0.0096816]
	Learning Rate: 0.0096816
	LOSS [training: 1.8984332765331573 | validation: 2.508291327844789]
	TIME [epoch: 8.42 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8946606596208184		[learning rate: 0.0096465]
	Learning Rate: 0.00964647
	LOSS [training: 1.8946606596208184 | validation: 2.7739216702325735]
	TIME [epoch: 8.42 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6096968879919313		[learning rate: 0.0096115]
	Learning Rate: 0.00961146
	LOSS [training: 1.6096968879919313 | validation: 2.5708363099083766]
	TIME [epoch: 8.45 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.536442711334732		[learning rate: 0.0095766]
	Learning Rate: 0.00957658
	LOSS [training: 1.536442711334732 | validation: 2.202796874828806]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.400802065788868		[learning rate: 0.0095418]
	Learning Rate: 0.00954183
	LOSS [training: 1.400802065788868 | validation: 2.564003455204557]
	TIME [epoch: 8.42 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7696310949816119		[learning rate: 0.0095072]
	Learning Rate: 0.0095072
	LOSS [training: 1.7696310949816119 | validation: 2.3692078108082013]
	TIME [epoch: 8.43 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.570864893730827		[learning rate: 0.0094727]
	Learning Rate: 0.0094727
	LOSS [training: 1.570864893730827 | validation: 3.0662153363534763]
	TIME [epoch: 8.44 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5634907063940813		[learning rate: 0.0094383]
	Learning Rate: 0.00943832
	LOSS [training: 1.5634907063940813 | validation: 2.375120934021086]
	TIME [epoch: 8.42 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5497503599965676		[learning rate: 0.0094041]
	Learning Rate: 0.00940407
	LOSS [training: 1.5497503599965676 | validation: 2.092430498400524]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7076362811280563		[learning rate: 0.0093699]
	Learning Rate: 0.00936994
	LOSS [training: 1.7076362811280563 | validation: 1.8484557138564748]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4553953473400667		[learning rate: 0.0093359]
	Learning Rate: 0.00933594
	LOSS [training: 1.4553953473400667 | validation: 2.1308408205239115]
	TIME [epoch: 8.44 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3671035143329742		[learning rate: 0.0093021]
	Learning Rate: 0.00930206
	LOSS [training: 1.3671035143329742 | validation: 5.040847837091027]
	TIME [epoch: 8.42 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9456730696993254		[learning rate: 0.0092683]
	Learning Rate: 0.0092683
	LOSS [training: 1.9456730696993254 | validation: 2.816483129458157]
	TIME [epoch: 8.41 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6796002336470675		[learning rate: 0.0092347]
	Learning Rate: 0.00923466
	LOSS [training: 1.6796002336470675 | validation: 2.4142830122743755]
	TIME [epoch: 8.42 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4807234513787844		[learning rate: 0.0092011]
	Learning Rate: 0.00920115
	LOSS [training: 1.4807234513787844 | validation: 1.9267296141702452]
	TIME [epoch: 8.44 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.378590719383275		[learning rate: 0.0091678]
	Learning Rate: 0.00916776
	LOSS [training: 1.378590719383275 | validation: 2.13700404256164]
	TIME [epoch: 8.42 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5031004244949082		[learning rate: 0.0091345]
	Learning Rate: 0.00913449
	LOSS [training: 1.5031004244949082 | validation: 2.26992826463323]
	TIME [epoch: 8.42 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3775407696082602		[learning rate: 0.0091013]
	Learning Rate: 0.00910134
	LOSS [training: 1.3775407696082602 | validation: 1.9798106997219556]
	TIME [epoch: 8.42 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3042577598450902		[learning rate: 0.0090683]
	Learning Rate: 0.00906831
	LOSS [training: 1.3042577598450902 | validation: 1.970289723725657]
	TIME [epoch: 8.44 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5251356630137072		[learning rate: 0.0090354]
	Learning Rate: 0.0090354
	LOSS [training: 1.5251356630137072 | validation: 1.8652863558925101]
	TIME [epoch: 8.41 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2071017487374887		[learning rate: 0.0090026]
	Learning Rate: 0.00900261
	LOSS [training: 1.2071017487374887 | validation: 2.1720678708591556]
	TIME [epoch: 8.41 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.28807392474796		[learning rate: 0.0089699]
	Learning Rate: 0.00896994
	LOSS [training: 1.28807392474796 | validation: 1.8960040577045183]
	TIME [epoch: 8.42 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.220234651145534		[learning rate: 0.0089374]
	Learning Rate: 0.00893739
	LOSS [training: 1.220234651145534 | validation: 2.647168011321658]
	TIME [epoch: 8.44 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2605840530484032		[learning rate: 0.008905]
	Learning Rate: 0.00890495
	LOSS [training: 1.2605840530484032 | validation: 2.308282053060653]
	TIME [epoch: 8.41 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.30302828185628		[learning rate: 0.0088726]
	Learning Rate: 0.00887263
	LOSS [training: 1.30302828185628 | validation: 1.7096159133457376]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2280511211356833		[learning rate: 0.0088404]
	Learning Rate: 0.00884044
	LOSS [training: 1.2280511211356833 | validation: 1.6892475244612115]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.546284470942906		[learning rate: 0.0088084]
	Learning Rate: 0.00880835
	LOSS [training: 1.546284470942906 | validation: 2.4082950754850634]
	TIME [epoch: 8.42 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3538741303466066		[learning rate: 0.0087764]
	Learning Rate: 0.00877639
	LOSS [training: 1.3538741303466066 | validation: 1.641895379213255]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5038212541846414		[learning rate: 0.0087445]
	Learning Rate: 0.00874454
	LOSS [training: 1.5038212541846414 | validation: 2.2523773424907594]
	TIME [epoch: 8.42 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2843030025192823		[learning rate: 0.0087128]
	Learning Rate: 0.0087128
	LOSS [training: 1.2843030025192823 | validation: 2.2214830462970494]
	TIME [epoch: 8.44 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2083463113785793		[learning rate: 0.0086812]
	Learning Rate: 0.00868118
	LOSS [training: 1.2083463113785793 | validation: 1.7738785973241216]
	TIME [epoch: 8.42 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2140378840767247		[learning rate: 0.0086497]
	Learning Rate: 0.00864968
	LOSS [training: 1.2140378840767247 | validation: 2.0710032309210225]
	TIME [epoch: 8.42 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5913563235918171		[learning rate: 0.0086183]
	Learning Rate: 0.00861829
	LOSS [training: 1.5913563235918171 | validation: 1.7283636728667582]
	TIME [epoch: 8.41 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.37827566138692		[learning rate: 0.008587]
	Learning Rate: 0.00858701
	LOSS [training: 1.37827566138692 | validation: 2.23405705250001]
	TIME [epoch: 8.42 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1744789040411432		[learning rate: 0.0085559]
	Learning Rate: 0.00855585
	LOSS [training: 1.1744789040411432 | validation: 1.9557342715252526]
	TIME [epoch: 8.43 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.406800355285297		[learning rate: 0.0085248]
	Learning Rate: 0.0085248
	LOSS [training: 1.406800355285297 | validation: 2.8812029978353704]
	TIME [epoch: 8.42 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2736250580438415		[learning rate: 0.0084939]
	Learning Rate: 0.00849386
	LOSS [training: 1.2736250580438415 | validation: 2.0664093128434455]
	TIME [epoch: 8.41 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1240847673064274		[learning rate: 0.008463]
	Learning Rate: 0.00846304
	LOSS [training: 1.1240847673064274 | validation: 2.5936501117285484]
	TIME [epoch: 8.44 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4718916812948901		[learning rate: 0.0084323]
	Learning Rate: 0.00843233
	LOSS [training: 1.4718916812948901 | validation: 2.5892966248302702]
	TIME [epoch: 8.42 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.430046450670094		[learning rate: 0.0084017]
	Learning Rate: 0.00840172
	LOSS [training: 1.430046450670094 | validation: 2.140018973128372]
	TIME [epoch: 8.41 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1875495670847749		[learning rate: 0.0083712]
	Learning Rate: 0.00837123
	LOSS [training: 1.1875495670847749 | validation: 2.3205792473838684]
	TIME [epoch: 8.42 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1452458032480417		[learning rate: 0.0083409]
	Learning Rate: 0.00834085
	LOSS [training: 1.1452458032480417 | validation: 1.8691360528783876]
	TIME [epoch: 8.43 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2102764428350237		[learning rate: 0.0083106]
	Learning Rate: 0.00831059
	LOSS [training: 1.2102764428350237 | validation: 2.477136561352851]
	TIME [epoch: 8.41 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1304425482266662		[learning rate: 0.0082804]
	Learning Rate: 0.00828043
	LOSS [training: 1.1304425482266662 | validation: 1.758682306216603]
	TIME [epoch: 8.41 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0605060879738448		[learning rate: 0.0082504]
	Learning Rate: 0.00825037
	LOSS [training: 1.0605060879738448 | validation: 1.7971331524212077]
	TIME [epoch: 8.41 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0709795238344615		[learning rate: 0.0082204]
	Learning Rate: 0.00822043
	LOSS [training: 1.0709795238344615 | validation: 1.9320583681332346]
	TIME [epoch: 8.45 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0968836271116167		[learning rate: 0.0081906]
	Learning Rate: 0.0081906
	LOSS [training: 1.0968836271116167 | validation: 2.296071636672723]
	TIME [epoch: 8.41 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4338760842331826		[learning rate: 0.0081609]
	Learning Rate: 0.00816088
	LOSS [training: 1.4338760842331826 | validation: 1.8298121502422955]
	TIME [epoch: 8.41 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.374913958962958		[learning rate: 0.0081313]
	Learning Rate: 0.00813126
	LOSS [training: 1.374913958962958 | validation: 1.64136408327159]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1790131272523752		[learning rate: 0.0081018]
	Learning Rate: 0.00810175
	LOSS [training: 1.1790131272523752 | validation: 1.5217232598629726]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.416213831045478		[learning rate: 0.0080724]
	Learning Rate: 0.00807235
	LOSS [training: 1.416213831045478 | validation: 2.589352985948733]
	TIME [epoch: 8.44 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4025186254929647		[learning rate: 0.0080431]
	Learning Rate: 0.00804305
	LOSS [training: 1.4025186254929647 | validation: 1.6590954515003284]
	TIME [epoch: 8.41 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1026150056092208		[learning rate: 0.0080139]
	Learning Rate: 0.00801387
	LOSS [training: 1.1026150056092208 | validation: 2.8111712311908916]
	TIME [epoch: 8.43 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2527751609767666		[learning rate: 0.0079848]
	Learning Rate: 0.00798478
	LOSS [training: 1.2527751609767666 | validation: 1.3208588133267116]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.523458697859848		[learning rate: 0.0079558]
	Learning Rate: 0.00795581
	LOSS [training: 1.523458697859848 | validation: 1.529531042824619]
	TIME [epoch: 8.42 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3795036699630179		[learning rate: 0.0079269]
	Learning Rate: 0.00792693
	LOSS [training: 1.3795036699630179 | validation: 1.1864226986283537]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1879581052598054		[learning rate: 0.0078982]
	Learning Rate: 0.00789817
	LOSS [training: 1.1879581052598054 | validation: 1.3999916767948988]
	TIME [epoch: 8.43 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1538826050466788		[learning rate: 0.0078695]
	Learning Rate: 0.0078695
	LOSS [training: 1.1538826050466788 | validation: 2.2462399248562663]
	TIME [epoch: 8.45 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6477958280482805		[learning rate: 0.0078409]
	Learning Rate: 0.00784094
	LOSS [training: 1.6477958280482805 | validation: 3.9381092645731592]
	TIME [epoch: 8.42 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9121230421189221		[learning rate: 0.0078125]
	Learning Rate: 0.00781249
	LOSS [training: 1.9121230421189221 | validation: 2.159511451224788]
	TIME [epoch: 8.42 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.427051534984551		[learning rate: 0.0077841]
	Learning Rate: 0.00778414
	LOSS [training: 1.427051534984551 | validation: 2.8935601470506302]
	TIME [epoch: 8.42 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5667252336144086		[learning rate: 0.0077559]
	Learning Rate: 0.00775589
	LOSS [training: 1.5667252336144086 | validation: 2.11655360593082]
	TIME [epoch: 8.45 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4122801486238852		[learning rate: 0.0077277]
	Learning Rate: 0.00772774
	LOSS [training: 1.4122801486238852 | validation: 2.60284764986267]
	TIME [epoch: 8.42 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5175939089459327		[learning rate: 0.0076997]
	Learning Rate: 0.0076997
	LOSS [training: 1.5175939089459327 | validation: 2.0579030754396004]
	TIME [epoch: 8.42 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2910185030185228		[learning rate: 0.0076718]
	Learning Rate: 0.00767176
	LOSS [training: 1.2910185030185228 | validation: 2.103440451678133]
	TIME [epoch: 8.43 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.131581085185872		[learning rate: 0.0076439]
	Learning Rate: 0.00764391
	LOSS [training: 1.131581085185872 | validation: 1.731117126340191]
	TIME [epoch: 8.43 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.012292860789446		[learning rate: 0.0076162]
	Learning Rate: 0.00761617
	LOSS [training: 1.012292860789446 | validation: 2.0237725769065555]
	TIME [epoch: 8.43 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2858195165315336		[learning rate: 0.0075885]
	Learning Rate: 0.00758853
	LOSS [training: 1.2858195165315336 | validation: 1.5314282255655185]
	TIME [epoch: 8.42 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0110348822404076		[learning rate: 0.007561]
	Learning Rate: 0.00756099
	LOSS [training: 1.0110348822404076 | validation: 1.1050085778556982]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9371364575283337		[learning rate: 0.0075336]
	Learning Rate: 0.00753356
	LOSS [training: 0.9371364575283337 | validation: 1.4491515861955957]
	TIME [epoch: 8.42 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9832566230467981		[learning rate: 0.0075062]
	Learning Rate: 0.00750622
	LOSS [training: 0.9832566230467981 | validation: 1.6929542077773256]
	TIME [epoch: 8.42 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.964307590789355		[learning rate: 0.007479]
	Learning Rate: 0.00747897
	LOSS [training: 0.964307590789355 | validation: 1.4607348252055101]
	TIME [epoch: 8.41 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9433719468976325		[learning rate: 0.0074518]
	Learning Rate: 0.00745183
	LOSS [training: 0.9433719468976325 | validation: 1.2163580159948009]
	TIME [epoch: 8.42 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4616324524845257		[learning rate: 0.0074248]
	Learning Rate: 0.00742479
	LOSS [training: 1.4616324524845257 | validation: 1.5332446622879141]
	TIME [epoch: 8.43 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.062964511484606		[learning rate: 0.0073978]
	Learning Rate: 0.00739784
	LOSS [training: 1.062964511484606 | validation: 1.2267190492277975]
	TIME [epoch: 8.41 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8872268309998438		[learning rate: 0.007371]
	Learning Rate: 0.007371
	LOSS [training: 0.8872268309998438 | validation: 1.9971109325559748]
	TIME [epoch: 8.42 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4450757549994688		[learning rate: 0.0073442]
	Learning Rate: 0.00734425
	LOSS [training: 1.4450757549994688 | validation: 2.0193640958869787]
	TIME [epoch: 8.43 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1669418390929063		[learning rate: 0.0073176]
	Learning Rate: 0.0073176
	LOSS [training: 1.1669418390929063 | validation: 1.3383685696053467]
	TIME [epoch: 8.44 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2831543116151782		[learning rate: 0.007291]
	Learning Rate: 0.00729104
	LOSS [training: 1.2831543116151782 | validation: 1.4033754394826388]
	TIME [epoch: 8.42 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.233988853062329		[learning rate: 0.0072646]
	Learning Rate: 0.00726458
	LOSS [training: 1.233988853062329 | validation: 1.7989948148600123]
	TIME [epoch: 8.41 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.120874401363872		[learning rate: 0.0072382]
	Learning Rate: 0.00723822
	LOSS [training: 1.120874401363872 | validation: 1.8246138474647071]
	TIME [epoch: 8.43 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0943562584231448		[learning rate: 0.0072119]
	Learning Rate: 0.00721195
	LOSS [training: 1.0943562584231448 | validation: 1.9662885920252466]
	TIME [epoch: 8.42 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1470400180271967		[learning rate: 0.0071858]
	Learning Rate: 0.00718578
	LOSS [training: 1.1470400180271967 | validation: 2.7927330486257462]
	TIME [epoch: 8.41 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2245271000447675		[learning rate: 0.0071597]
	Learning Rate: 0.0071597
	LOSS [training: 1.2245271000447675 | validation: 1.5284199286290798]
	TIME [epoch: 8.41 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2131457794700997		[learning rate: 0.0071337]
	Learning Rate: 0.00713371
	LOSS [training: 1.2131457794700997 | validation: 1.406290675822286]
	TIME [epoch: 8.43 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0795800202185508		[learning rate: 0.0071078]
	Learning Rate: 0.00710783
	LOSS [training: 1.0795800202185508 | validation: 1.644714773421894]
	TIME [epoch: 8.42 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1169927952688292		[learning rate: 0.007082]
	Learning Rate: 0.00708203
	LOSS [training: 1.1169927952688292 | validation: 1.6079718696137897]
	TIME [epoch: 8.41 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9439792562007193		[learning rate: 0.0070563]
	Learning Rate: 0.00705633
	LOSS [training: 0.9439792562007193 | validation: 1.5841511184150399]
	TIME [epoch: 8.42 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0490136205135934		[learning rate: 0.0070307]
	Learning Rate: 0.00703072
	LOSS [training: 1.0490136205135934 | validation: 1.407039896848052]
	TIME [epoch: 8.45 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1882377048256247		[learning rate: 0.0070052]
	Learning Rate: 0.00700521
	LOSS [training: 1.1882377048256247 | validation: 1.194168451870118]
	TIME [epoch: 8.41 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.017971205419982		[learning rate: 0.0069798]
	Learning Rate: 0.00697979
	LOSS [training: 1.017971205419982 | validation: 1.2281814122425554]
	TIME [epoch: 8.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0424739918871133		[learning rate: 0.0069545]
	Learning Rate: 0.00695446
	LOSS [training: 1.0424739918871133 | validation: 1.7981371720903891]
	TIME [epoch: 8.42 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1667359828433332		[learning rate: 0.0069292]
	Learning Rate: 0.00692922
	LOSS [training: 1.1667359828433332 | validation: 1.9058308648103477]
	TIME [epoch: 8.43 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1407319571966388		[learning rate: 0.0069041]
	Learning Rate: 0.00690407
	LOSS [training: 1.1407319571966388 | validation: 1.0638869041656316]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8482052125815457		[learning rate: 0.006879]
	Learning Rate: 0.00687902
	LOSS [training: 0.8482052125815457 | validation: 1.1461789969065608]
	TIME [epoch: 8.42 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9388107339358566		[learning rate: 0.0068541]
	Learning Rate: 0.00685405
	LOSS [training: 0.9388107339358566 | validation: 1.105922219491504]
	TIME [epoch: 8.44 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9379244027743967		[learning rate: 0.0068292]
	Learning Rate: 0.00682918
	LOSS [training: 0.9379244027743967 | validation: 1.1450255631937762]
	TIME [epoch: 8.43 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9764715084619606		[learning rate: 0.0068044]
	Learning Rate: 0.00680439
	LOSS [training: 0.9764715084619606 | validation: 1.4895704147926774]
	TIME [epoch: 8.42 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0051447077411508		[learning rate: 0.0067797]
	Learning Rate: 0.0067797
	LOSS [training: 1.0051447077411508 | validation: 1.761905799332616]
	TIME [epoch: 8.42 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8491074165967699		[learning rate: 0.0067551]
	Learning Rate: 0.0067551
	LOSS [training: 0.8491074165967699 | validation: 1.2941974496675828]
	TIME [epoch: 8.43 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9494868534398584		[learning rate: 0.0067306]
	Learning Rate: 0.00673058
	LOSS [training: 0.9494868534398584 | validation: 1.4480857675262624]
	TIME [epoch: 8.44 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9545421723869889		[learning rate: 0.0067062]
	Learning Rate: 0.00670616
	LOSS [training: 0.9545421723869889 | validation: 1.0533677147956735]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7905815833384393		[learning rate: 0.0066818]
	Learning Rate: 0.00668182
	LOSS [training: 0.7905815833384393 | validation: 0.9416165869987563]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.844257639249372		[learning rate: 0.0066576]
	Learning Rate: 0.00665757
	LOSS [training: 0.844257639249372 | validation: 1.4032013555248586]
	TIME [epoch: 8.43 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9195056832319872		[learning rate: 0.0066334]
	Learning Rate: 0.00663341
	LOSS [training: 0.9195056832319872 | validation: 0.9197567170885482]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9380321368087723		[learning rate: 0.0066093]
	Learning Rate: 0.00660934
	LOSS [training: 0.9380321368087723 | validation: 1.0995995714663198]
	TIME [epoch: 8.43 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0184904814114808		[learning rate: 0.0065854]
	Learning Rate: 0.00658535
	LOSS [training: 1.0184904814114808 | validation: 0.891865194759911]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8286684323951622		[learning rate: 0.0065615]
	Learning Rate: 0.00656145
	LOSS [training: 0.8286684323951622 | validation: 1.3449245418855464]
	TIME [epoch: 8.43 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9935003430464974		[learning rate: 0.0065376]
	Learning Rate: 0.00653764
	LOSS [training: 0.9935003430464974 | validation: 1.4261310881860028]
	TIME [epoch: 8.44 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8850211132503771		[learning rate: 0.0065139]
	Learning Rate: 0.00651392
	LOSS [training: 0.8850211132503771 | validation: 1.0796758778390405]
	TIME [epoch: 8.42 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2431921119785598		[learning rate: 0.0064903]
	Learning Rate: 0.00649028
	LOSS [training: 1.2431921119785598 | validation: 1.28844253335163]
	TIME [epoch: 8.42 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9908744374094081		[learning rate: 0.0064667]
	Learning Rate: 0.00646672
	LOSS [training: 0.9908744374094081 | validation: 1.021718366214289]
	TIME [epoch: 8.42 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8588610611758529		[learning rate: 0.0064433]
	Learning Rate: 0.00644325
	LOSS [training: 0.8588610611758529 | validation: 1.5003677581415809]
	TIME [epoch: 8.44 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1189060564723685		[learning rate: 0.0064199]
	Learning Rate: 0.00641987
	LOSS [training: 1.1189060564723685 | validation: 1.3148823994071388]
	TIME [epoch: 8.42 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.960885068384909		[learning rate: 0.0063966]
	Learning Rate: 0.00639657
	LOSS [training: 0.960885068384909 | validation: 0.9346835107385292]
	TIME [epoch: 8.42 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.925861067925412		[learning rate: 0.0063734]
	Learning Rate: 0.00637336
	LOSS [training: 0.925861067925412 | validation: 1.0255439073749117]
	TIME [epoch: 8.42 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8216555356619812		[learning rate: 0.0063502]
	Learning Rate: 0.00635023
	LOSS [training: 0.8216555356619812 | validation: 0.9666995479755158]
	TIME [epoch: 8.45 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1016581626911712		[learning rate: 0.0063272]
	Learning Rate: 0.00632718
	LOSS [training: 1.1016581626911712 | validation: 1.2043595371710907]
	TIME [epoch: 8.42 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8770031610684719		[learning rate: 0.0063042]
	Learning Rate: 0.00630422
	LOSS [training: 0.8770031610684719 | validation: 1.5202723323377212]
	TIME [epoch: 8.42 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9562752454821766		[learning rate: 0.0062813]
	Learning Rate: 0.00628134
	LOSS [training: 0.9562752454821766 | validation: 1.0769517473436059]
	TIME [epoch: 8.42 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8018145704116477		[learning rate: 0.0062585]
	Learning Rate: 0.00625855
	LOSS [training: 0.8018145704116477 | validation: 0.8371098099522909]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8095246114425338		[learning rate: 0.0062358]
	Learning Rate: 0.00623584
	LOSS [training: 0.8095246114425338 | validation: 0.9486051711753578]
	TIME [epoch: 8.42 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7353585750434246		[learning rate: 0.0062132]
	Learning Rate: 0.00621321
	LOSS [training: 0.7353585750434246 | validation: 1.4761551355870797]
	TIME [epoch: 8.42 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.944050619962671		[learning rate: 0.0061907]
	Learning Rate: 0.00619066
	LOSS [training: 0.944050619962671 | validation: 1.584938934142556]
	TIME [epoch: 8.42 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9844224176723742		[learning rate: 0.0061682]
	Learning Rate: 0.00616819
	LOSS [training: 0.9844224176723742 | validation: 0.9177233867231901]
	TIME [epoch: 8.44 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7362693304050155		[learning rate: 0.0061458]
	Learning Rate: 0.00614581
	LOSS [training: 0.7362693304050155 | validation: 2.139119583946047]
	TIME [epoch: 8.42 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8642288739888075		[learning rate: 0.0061235]
	Learning Rate: 0.0061235
	LOSS [training: 0.8642288739888075 | validation: 0.9402549429261602]
	TIME [epoch: 8.42 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8723314446591705		[learning rate: 0.0061013]
	Learning Rate: 0.00610128
	LOSS [training: 0.8723314446591705 | validation: 1.340678695474568]
	TIME [epoch: 8.41 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8292671036340493		[learning rate: 0.0060791]
	Learning Rate: 0.00607914
	LOSS [training: 0.8292671036340493 | validation: 1.4565264958935948]
	TIME [epoch: 8.45 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8743546242168895		[learning rate: 0.0060571]
	Learning Rate: 0.00605708
	LOSS [training: 0.8743546242168895 | validation: 1.1576747350279644]
	TIME [epoch: 8.43 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7219699359006972		[learning rate: 0.0060351]
	Learning Rate: 0.0060351
	LOSS [training: 0.7219699359006972 | validation: 0.8847677655257918]
	TIME [epoch: 8.42 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.84549767833285		[learning rate: 0.0060132]
	Learning Rate: 0.00601319
	LOSS [training: 0.84549767833285 | validation: 0.9372891128594449]
	TIME [epoch: 8.42 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9182489759018602		[learning rate: 0.0059914]
	Learning Rate: 0.00599137
	LOSS [training: 0.9182489759018602 | validation: 1.105325643853628]
	TIME [epoch: 8.43 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0625046687337742		[learning rate: 0.0059696]
	Learning Rate: 0.00596963
	LOSS [training: 1.0625046687337742 | validation: 1.0265297898934502]
	TIME [epoch: 8.43 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7484452152285839		[learning rate: 0.005948]
	Learning Rate: 0.00594797
	LOSS [training: 0.7484452152285839 | validation: 1.0965666788438422]
	TIME [epoch: 8.41 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6951388524110105		[learning rate: 0.0059264]
	Learning Rate: 0.00592638
	LOSS [training: 0.6951388524110105 | validation: 2.0356456707291297]
	TIME [epoch: 8.41 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9825806964258728		[learning rate: 0.0059049]
	Learning Rate: 0.00590487
	LOSS [training: 0.9825806964258728 | validation: 1.7900961919771128]
	TIME [epoch: 8.43 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9280972726911718		[learning rate: 0.0058834]
	Learning Rate: 0.00588344
	LOSS [training: 0.9280972726911718 | validation: 1.4022292514868293]
	TIME [epoch: 8.43 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9176157074406948		[learning rate: 0.0058621]
	Learning Rate: 0.00586209
	LOSS [training: 0.9176157074406948 | validation: 1.1906968051461706]
	TIME [epoch: 8.42 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7568987783278942		[learning rate: 0.0058408]
	Learning Rate: 0.00584082
	LOSS [training: 0.7568987783278942 | validation: 1.315776138692859]
	TIME [epoch: 8.42 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8634368791683465		[learning rate: 0.0058196]
	Learning Rate: 0.00581962
	LOSS [training: 0.8634368791683465 | validation: 0.8885064522265712]
	TIME [epoch: 8.42 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9120171453690494		[learning rate: 0.0057985]
	Learning Rate: 0.0057985
	LOSS [training: 0.9120171453690494 | validation: 1.3151897257540366]
	TIME [epoch: 8.44 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7280426994320053		[learning rate: 0.0057775]
	Learning Rate: 0.00577746
	LOSS [training: 0.7280426994320053 | validation: 1.2151388407147965]
	TIME [epoch: 8.41 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6990425009717478		[learning rate: 0.0057565]
	Learning Rate: 0.00575649
	LOSS [training: 0.6990425009717478 | validation: 1.0397004037722157]
	TIME [epoch: 8.42 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7025472788565515		[learning rate: 0.0057356]
	Learning Rate: 0.0057356
	LOSS [training: 0.7025472788565515 | validation: 0.9248393010468736]
	TIME [epoch: 8.42 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6746097909092377		[learning rate: 0.0057148]
	Learning Rate: 0.00571479
	LOSS [training: 0.6746097909092377 | validation: 1.1237908079660603]
	TIME [epoch: 8.46 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6847677025116421		[learning rate: 0.005694]
	Learning Rate: 0.00569405
	LOSS [training: 0.6847677025116421 | validation: 0.8897965480574692]
	TIME [epoch: 8.42 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6658823574738093		[learning rate: 0.0056734]
	Learning Rate: 0.00567338
	LOSS [training: 0.6658823574738093 | validation: 0.8223747439890728]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.661228290938243		[learning rate: 0.0056528]
	Learning Rate: 0.00565279
	LOSS [training: 0.661228290938243 | validation: 0.8785637435582445]
	TIME [epoch: 8.43 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6243374493795599		[learning rate: 0.0056323]
	Learning Rate: 0.00563228
	LOSS [training: 0.6243374493795599 | validation: 0.9405925848418399]
	TIME [epoch: 8.46 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7152737738011594		[learning rate: 0.0056118]
	Learning Rate: 0.00561184
	LOSS [training: 0.7152737738011594 | validation: 0.7695908245067624]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7447514609301159		[learning rate: 0.0055915]
	Learning Rate: 0.00559147
	LOSS [training: 0.7447514609301159 | validation: 1.3904084560129244]
	TIME [epoch: 8.41 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8294198047151677		[learning rate: 0.0055712]
	Learning Rate: 0.00557118
	LOSS [training: 0.8294198047151677 | validation: 0.8034114163025732]
	TIME [epoch: 8.41 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6705501689857976		[learning rate: 0.005551]
	Learning Rate: 0.00555096
	LOSS [training: 0.6705501689857976 | validation: 1.2270833210714553]
	TIME [epoch: 8.44 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6808948391184548		[learning rate: 0.0055308]
	Learning Rate: 0.00553082
	LOSS [training: 0.6808948391184548 | validation: 1.540903844110112]
	TIME [epoch: 8.42 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9550901645109262		[learning rate: 0.0055107]
	Learning Rate: 0.00551075
	LOSS [training: 0.9550901645109262 | validation: 1.139374123683113]
	TIME [epoch: 8.42 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7718747731813955		[learning rate: 0.0054907]
	Learning Rate: 0.00549075
	LOSS [training: 0.7718747731813955 | validation: 1.0190794609096845]
	TIME [epoch: 8.42 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.953785016324424		[learning rate: 0.0054708]
	Learning Rate: 0.00547082
	LOSS [training: 0.953785016324424 | validation: 1.1975792397373324]
	TIME [epoch: 8.43 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8038486817016077		[learning rate: 0.005451]
	Learning Rate: 0.00545097
	LOSS [training: 0.8038486817016077 | validation: 0.6658376163907607]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6002262840825969		[learning rate: 0.0054312]
	Learning Rate: 0.00543119
	LOSS [training: 0.6002262840825969 | validation: 1.061417112336959]
	TIME [epoch: 8.43 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6737995685477969		[learning rate: 0.0054115]
	Learning Rate: 0.00541148
	LOSS [training: 0.6737995685477969 | validation: 1.2934134538699191]
	TIME [epoch: 8.42 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7706602144533223		[learning rate: 0.0053918]
	Learning Rate: 0.00539184
	LOSS [training: 0.7706602144533223 | validation: 0.9180903295847338]
	TIME [epoch: 8.44 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6461133845397891		[learning rate: 0.0053723]
	Learning Rate: 0.00537227
	LOSS [training: 0.6461133845397891 | validation: 0.8582217528797453]
	TIME [epoch: 8.42 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6153586951252952		[learning rate: 0.0053528]
	Learning Rate: 0.00535277
	LOSS [training: 0.6153586951252952 | validation: 0.9432015468798542]
	TIME [epoch: 8.42 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6273036241903192		[learning rate: 0.0053333]
	Learning Rate: 0.00533335
	LOSS [training: 0.6273036241903192 | validation: 0.7850875550014019]
	TIME [epoch: 8.42 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5777480996534339		[learning rate: 0.005314]
	Learning Rate: 0.00531399
	LOSS [training: 0.5777480996534339 | validation: 1.0369647420733754]
	TIME [epoch: 8.45 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6563867193127798		[learning rate: 0.0052947]
	Learning Rate: 0.00529471
	LOSS [training: 0.6563867193127798 | validation: 0.8666156858303737]
	TIME [epoch: 8.42 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6616979324885445		[learning rate: 0.0052755]
	Learning Rate: 0.00527549
	LOSS [training: 0.6616979324885445 | validation: 1.1085921821344211]
	TIME [epoch: 8.42 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8507739228042064		[learning rate: 0.0052563]
	Learning Rate: 0.00525635
	LOSS [training: 0.8507739228042064 | validation: 1.1112918665492573]
	TIME [epoch: 8.43 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6430188496478415		[learning rate: 0.0052373]
	Learning Rate: 0.00523727
	LOSS [training: 0.6430188496478415 | validation: 0.8186684113833548]
	TIME [epoch: 8.42 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5910622381649848		[learning rate: 0.0052183]
	Learning Rate: 0.00521827
	LOSS [training: 0.5910622381649848 | validation: 0.6641402796938224]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7285193526323124		[learning rate: 0.0051993]
	Learning Rate: 0.00519933
	LOSS [training: 0.7285193526323124 | validation: 1.038053739878181]
	TIME [epoch: 8.42 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7304140302475298		[learning rate: 0.0051805]
	Learning Rate: 0.00518046
	LOSS [training: 0.7304140302475298 | validation: 1.3474306172407897]
	TIME [epoch: 8.42 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6376999563453319		[learning rate: 0.0051617]
	Learning Rate: 0.00516166
	LOSS [training: 0.6376999563453319 | validation: 0.8405471509714519]
	TIME [epoch: 8.43 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6385291517258638		[learning rate: 0.0051429]
	Learning Rate: 0.00514293
	LOSS [training: 0.6385291517258638 | validation: 1.2540982497405633]
	TIME [epoch: 8.43 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5889166013890298		[learning rate: 0.0051243]
	Learning Rate: 0.00512426
	LOSS [training: 0.5889166013890298 | validation: 0.5933308165836975]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5767310366031011		[learning rate: 0.0051057]
	Learning Rate: 0.00510567
	LOSS [training: 0.5767310366031011 | validation: 0.8637138775453156]
	TIME [epoch: 8.42 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5802361617672349		[learning rate: 0.0050871]
	Learning Rate: 0.00508714
	LOSS [training: 0.5802361617672349 | validation: 2.249986732542787]
	TIME [epoch: 8.43 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9802302767028491		[learning rate: 0.0050687]
	Learning Rate: 0.00506868
	LOSS [training: 0.9802302767028491 | validation: 0.7344544048221782]
	TIME [epoch: 8.45 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5761478620511258		[learning rate: 0.0050503]
	Learning Rate: 0.00505028
	LOSS [training: 0.5761478620511258 | validation: 1.4115995432026471]
	TIME [epoch: 8.42 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.651042627367539		[learning rate: 0.005032]
	Learning Rate: 0.00503196
	LOSS [training: 0.651042627367539 | validation: 0.9339607956305858]
	TIME [epoch: 8.42 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5708013524383864		[learning rate: 0.0050137]
	Learning Rate: 0.00501369
	LOSS [training: 0.5708013524383864 | validation: 0.9027963648727689]
	TIME [epoch: 8.42 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5398586277884199		[learning rate: 0.0049955]
	Learning Rate: 0.0049955
	LOSS [training: 0.5398586277884199 | validation: 0.8371438246131699]
	TIME [epoch: 8.45 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5260544434007917		[learning rate: 0.0049774]
	Learning Rate: 0.00497737
	LOSS [training: 0.5260544434007917 | validation: 0.7822757221951758]
	TIME [epoch: 8.42 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6243541064444729		[learning rate: 0.0049593]
	Learning Rate: 0.00495931
	LOSS [training: 0.6243541064444729 | validation: 0.6951827938296362]
	TIME [epoch: 8.42 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5327912272685402		[learning rate: 0.0049413]
	Learning Rate: 0.00494131
	LOSS [training: 0.5327912272685402 | validation: 0.8407586021764515]
	TIME [epoch: 8.42 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5094406374297155		[learning rate: 0.0049234]
	Learning Rate: 0.00492338
	LOSS [training: 0.5094406374297155 | validation: 1.0158208287724162]
	TIME [epoch: 8.46 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5098452157650104		[learning rate: 0.0049055]
	Learning Rate: 0.00490551
	LOSS [training: 0.5098452157650104 | validation: 0.8916991422062583]
	TIME [epoch: 8.42 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8247095631296686		[learning rate: 0.0048877]
	Learning Rate: 0.00488771
	LOSS [training: 0.8247095631296686 | validation: 0.8036250361019996]
	TIME [epoch: 8.42 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6449434002533374		[learning rate: 0.00487]
	Learning Rate: 0.00486997
	LOSS [training: 0.6449434002533374 | validation: 0.7024096676936413]
	TIME [epoch: 8.42 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5645156717736018		[learning rate: 0.0048523]
	Learning Rate: 0.0048523
	LOSS [training: 0.5645156717736018 | validation: 1.158749743574743]
	TIME [epoch: 8.45 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5249094543536593		[learning rate: 0.0048347]
	Learning Rate: 0.00483469
	LOSS [training: 0.5249094543536593 | validation: 1.3211621337103066]
	TIME [epoch: 8.42 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6635604823893937		[learning rate: 0.0048171]
	Learning Rate: 0.00481714
	LOSS [training: 0.6635604823893937 | validation: 0.795848019087107]
	TIME [epoch: 8.42 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5710564411208038		[learning rate: 0.0047997]
	Learning Rate: 0.00479966
	LOSS [training: 0.5710564411208038 | validation: 0.7830854124626275]
	TIME [epoch: 8.42 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5342432877639316		[learning rate: 0.0047822]
	Learning Rate: 0.00478224
	LOSS [training: 0.5342432877639316 | validation: 1.107482598330399]
	TIME [epoch: 8.46 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6676640768577444		[learning rate: 0.0047649]
	Learning Rate: 0.00476489
	LOSS [training: 0.6676640768577444 | validation: 1.0212599777819862]
	TIME [epoch: 8.43 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5600726561916918		[learning rate: 0.0047476]
	Learning Rate: 0.00474759
	LOSS [training: 0.5600726561916918 | validation: 0.9723137560354526]
	TIME [epoch: 8.42 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5033092702069664		[learning rate: 0.0047304]
	Learning Rate: 0.00473037
	LOSS [training: 0.5033092702069664 | validation: 0.7003458147519517]
	TIME [epoch: 8.42 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5083470507297044		[learning rate: 0.0047132]
	Learning Rate: 0.0047132
	LOSS [training: 0.5083470507297044 | validation: 0.5578607612511703]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5623150432339847		[learning rate: 0.0046961]
	Learning Rate: 0.00469609
	LOSS [training: 0.5623150432339847 | validation: 1.3613413092169426]
	TIME [epoch: 8.44 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.581591262688827		[learning rate: 0.0046791]
	Learning Rate: 0.00467905
	LOSS [training: 0.581591262688827 | validation: 1.365258962799469]
	TIME [epoch: 8.43 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6212059142433716		[learning rate: 0.0046621]
	Learning Rate: 0.00466207
	LOSS [training: 0.6212059142433716 | validation: 0.5847654337386037]
	TIME [epoch: 8.42 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5086518351418571		[learning rate: 0.0046452]
	Learning Rate: 0.00464515
	LOSS [training: 0.5086518351418571 | validation: 0.6598433813357921]
	TIME [epoch: 8.43 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6088610613366905		[learning rate: 0.0046283]
	Learning Rate: 0.0046283
	LOSS [training: 0.6088610613366905 | validation: 0.8674336311851796]
	TIME [epoch: 8.44 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4628128663082447		[learning rate: 0.0046115]
	Learning Rate: 0.0046115
	LOSS [training: 0.4628128663082447 | validation: 0.8237992898289312]
	TIME [epoch: 8.43 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6108412790885078		[learning rate: 0.0045948]
	Learning Rate: 0.00459476
	LOSS [training: 0.6108412790885078 | validation: 0.6098470447718711]
	TIME [epoch: 8.42 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4341787962055414		[learning rate: 0.0045781]
	Learning Rate: 0.00457809
	LOSS [training: 0.4341787962055414 | validation: 0.5325797045822236]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5279910131053285		[learning rate: 0.0045615]
	Learning Rate: 0.00456148
	LOSS [training: 0.5279910131053285 | validation: 0.8255900285334041]
	TIME [epoch: 8.45 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6120273018191236		[learning rate: 0.0045449]
	Learning Rate: 0.00454492
	LOSS [training: 0.6120273018191236 | validation: 0.5272638280650332]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5849252701656888		[learning rate: 0.0045284]
	Learning Rate: 0.00452843
	LOSS [training: 0.5849252701656888 | validation: 0.7256317683637332]
	TIME [epoch: 8.42 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5586033586942185		[learning rate: 0.004512]
	Learning Rate: 0.00451199
	LOSS [training: 0.5586033586942185 | validation: 0.4888832967762421]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5425086228072743		[learning rate: 0.0044956]
	Learning Rate: 0.00449562
	LOSS [training: 0.5425086228072743 | validation: 1.6338031089052953]
	TIME [epoch: 8.44 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6513673697098943		[learning rate: 0.0044793]
	Learning Rate: 0.0044793
	LOSS [training: 0.6513673697098943 | validation: 0.5166241223040391]
	TIME [epoch: 8.42 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4946389266413031		[learning rate: 0.004463]
	Learning Rate: 0.00446305
	LOSS [training: 0.4946389266413031 | validation: 0.7053662139870279]
	TIME [epoch: 8.42 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5354864291196582		[learning rate: 0.0044469]
	Learning Rate: 0.00444685
	LOSS [training: 0.5354864291196582 | validation: 0.560909871827318]
	TIME [epoch: 8.43 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43175876479935377		[learning rate: 0.0044307]
	Learning Rate: 0.00443071
	LOSS [training: 0.43175876479935377 | validation: 0.8605994868863271]
	TIME [epoch: 8.44 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6129596597625593		[learning rate: 0.0044146]
	Learning Rate: 0.00441463
	LOSS [training: 0.6129596597625593 | validation: 0.7445574670116278]
	TIME [epoch: 8.43 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5443948314649837		[learning rate: 0.0043986]
	Learning Rate: 0.00439861
	LOSS [training: 0.5443948314649837 | validation: 0.8127682362591504]
	TIME [epoch: 8.42 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5824458081762671		[learning rate: 0.0043827]
	Learning Rate: 0.00438265
	LOSS [training: 0.5824458081762671 | validation: 0.9543880052946663]
	TIME [epoch: 8.43 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.551642435235158		[learning rate: 0.0043667]
	Learning Rate: 0.00436675
	LOSS [training: 0.551642435235158 | validation: 0.5905716986327804]
	TIME [epoch: 8.45 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5449314191354887		[learning rate: 0.0043509]
	Learning Rate: 0.0043509
	LOSS [training: 0.5449314191354887 | validation: 1.1922297069718915]
	TIME [epoch: 8.42 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6356635029507227		[learning rate: 0.0043351]
	Learning Rate: 0.00433511
	LOSS [training: 0.6356635029507227 | validation: 0.6227593135999026]
	TIME [epoch: 8.42 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.541292892104673		[learning rate: 0.0043194]
	Learning Rate: 0.00431938
	LOSS [training: 0.541292892104673 | validation: 0.5165460755956943]
	TIME [epoch: 8.42 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4919329389280537		[learning rate: 0.0043037]
	Learning Rate: 0.0043037
	LOSS [training: 0.4919329389280537 | validation: 0.5841092506194421]
	TIME [epoch: 8.44 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5796875989584056		[learning rate: 0.0042881]
	Learning Rate: 0.00428808
	LOSS [training: 0.5796875989584056 | validation: 0.691791789700474]
	TIME [epoch: 8.42 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5958652077299598		[learning rate: 0.0042725]
	Learning Rate: 0.00427252
	LOSS [training: 0.5958652077299598 | validation: 0.6038481659961696]
	TIME [epoch: 8.42 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.453818475434268		[learning rate: 0.004257]
	Learning Rate: 0.00425702
	LOSS [training: 0.453818475434268 | validation: 0.8968593434997252]
	TIME [epoch: 8.42 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5627630780906784		[learning rate: 0.0042416]
	Learning Rate: 0.00424157
	LOSS [training: 0.5627630780906784 | validation: 0.8914451689888494]
	TIME [epoch: 8.44 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5912756582109043		[learning rate: 0.0042262]
	Learning Rate: 0.00422617
	LOSS [training: 0.5912756582109043 | validation: 0.7865936370047756]
	TIME [epoch: 8.43 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5569012934708419		[learning rate: 0.0042108]
	Learning Rate: 0.00421084
	LOSS [training: 0.5569012934708419 | validation: 0.7661876982486768]
	TIME [epoch: 8.42 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6385634927139121		[learning rate: 0.0041956]
	Learning Rate: 0.00419556
	LOSS [training: 0.6385634927139121 | validation: 0.5393641332042731]
	TIME [epoch: 8.42 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6995515769930313		[learning rate: 0.0041803]
	Learning Rate: 0.00418033
	LOSS [training: 0.6995515769930313 | validation: 0.7964494289247256]
	TIME [epoch: 8.44 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.356494780162093		[learning rate: 0.0041652]
	Learning Rate: 0.00416516
	LOSS [training: 0.356494780162093 | validation: 0.8244022464010754]
	TIME [epoch: 8.42 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5889007366749299		[learning rate: 0.00415]
	Learning Rate: 0.00415004
	LOSS [training: 0.5889007366749299 | validation: 1.0275601605369922]
	TIME [epoch: 8.42 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5078225868047673		[learning rate: 0.004135]
	Learning Rate: 0.00413498
	LOSS [training: 0.5078225868047673 | validation: 0.4587341606534079]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43188964465222257		[learning rate: 0.00412]
	Learning Rate: 0.00411998
	LOSS [training: 0.43188964465222257 | validation: 0.41429955907517135]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6891133923089653		[learning rate: 0.004105]
	Learning Rate: 0.00410502
	LOSS [training: 0.6891133923089653 | validation: 1.1069947794179613]
	TIME [epoch: 8.44 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.622177884044306		[learning rate: 0.0040901]
	Learning Rate: 0.00409013
	LOSS [training: 0.622177884044306 | validation: 0.6394714279177192]
	TIME [epoch: 8.42 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5160094862345754		[learning rate: 0.0040753]
	Learning Rate: 0.00407528
	LOSS [training: 0.5160094862345754 | validation: 0.7845490282487722]
	TIME [epoch: 8.42 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.651923595309194		[learning rate: 0.0040605]
	Learning Rate: 0.00406049
	LOSS [training: 0.651923595309194 | validation: 0.6769062911801382]
	TIME [epoch: 8.43 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4077296669070227		[learning rate: 0.0040458]
	Learning Rate: 0.00404576
	LOSS [training: 0.4077296669070227 | validation: 1.0787415842033143]
	TIME [epoch: 8.43 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41204017714773905		[learning rate: 0.0040311]
	Learning Rate: 0.00403108
	LOSS [training: 0.41204017714773905 | validation: 0.5715828880405429]
	TIME [epoch: 8.42 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4138463303346751		[learning rate: 0.0040164]
	Learning Rate: 0.00401645
	LOSS [training: 0.4138463303346751 | validation: 0.6303007203838026]
	TIME [epoch: 8.42 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4910647110453194		[learning rate: 0.0040019]
	Learning Rate: 0.00400187
	LOSS [training: 0.4910647110453194 | validation: 0.611565999981289]
	TIME [epoch: 8.44 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6971127322242286		[learning rate: 0.0039873]
	Learning Rate: 0.00398735
	LOSS [training: 0.6971127322242286 | validation: 0.7159198001168827]
	TIME [epoch: 8.43 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4304429794519306		[learning rate: 0.0039729]
	Learning Rate: 0.00397288
	LOSS [training: 0.4304429794519306 | validation: 0.512222588003473]
	TIME [epoch: 8.42 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4285616873058292		[learning rate: 0.0039585]
	Learning Rate: 0.00395846
	LOSS [training: 0.4285616873058292 | validation: 0.6869712737919591]
	TIME [epoch: 8.42 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5613762982201735		[learning rate: 0.0039441]
	Learning Rate: 0.00394409
	LOSS [training: 0.5613762982201735 | validation: 0.8550845867923309]
	TIME [epoch: 8.42 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5231200040398339		[learning rate: 0.0039298]
	Learning Rate: 0.00392978
	LOSS [training: 0.5231200040398339 | validation: 0.6292676026640185]
	TIME [epoch: 8.45 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5044947842095674		[learning rate: 0.0039155]
	Learning Rate: 0.00391552
	LOSS [training: 0.5044947842095674 | validation: 0.6189827076175864]
	TIME [epoch: 8.42 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5718286225464904		[learning rate: 0.0039013]
	Learning Rate: 0.00390131
	LOSS [training: 0.5718286225464904 | validation: 0.9274929607984319]
	TIME [epoch: 8.43 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45312462108200774		[learning rate: 0.0038872]
	Learning Rate: 0.00388715
	LOSS [training: 0.45312462108200774 | validation: 0.4090187683805975]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42949661179203186		[learning rate: 0.003873]
	Learning Rate: 0.00387305
	LOSS [training: 0.42949661179203186 | validation: 0.8990631842915285]
	TIME [epoch: 8.44 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4849295642008854		[learning rate: 0.003859]
	Learning Rate: 0.00385899
	LOSS [training: 0.4849295642008854 | validation: 0.5743277848255682]
	TIME [epoch: 8.42 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5341012674633807		[learning rate: 0.003845]
	Learning Rate: 0.00384499
	LOSS [training: 0.5341012674633807 | validation: 0.5944149713690063]
	TIME [epoch: 8.42 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5209159729307213		[learning rate: 0.003831]
	Learning Rate: 0.00383103
	LOSS [training: 0.5209159729307213 | validation: 0.5561898680239205]
	TIME [epoch: 8.42 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5301559668215317		[learning rate: 0.0038171]
	Learning Rate: 0.00381713
	LOSS [training: 0.5301559668215317 | validation: 0.47617243104834783]
	TIME [epoch: 8.46 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40183680437307406		[learning rate: 0.0038033]
	Learning Rate: 0.00380328
	LOSS [training: 0.40183680437307406 | validation: 0.7454740802590105]
	TIME [epoch: 8.42 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41483932666971607		[learning rate: 0.0037895]
	Learning Rate: 0.00378947
	LOSS [training: 0.41483932666971607 | validation: 0.47861645556959453]
	TIME [epoch: 8.43 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5045584058913827		[learning rate: 0.0037757]
	Learning Rate: 0.00377572
	LOSS [training: 0.5045584058913827 | validation: 0.6314958722035775]
	TIME [epoch: 8.42 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.436770519018889		[learning rate: 0.003762]
	Learning Rate: 0.00376202
	LOSS [training: 0.436770519018889 | validation: 0.5462998839644512]
	TIME [epoch: 8.45 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.458198517167628		[learning rate: 0.0037484]
	Learning Rate: 0.00374837
	LOSS [training: 0.458198517167628 | validation: 1.141893032745008]
	TIME [epoch: 8.43 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5001223270756769		[learning rate: 0.0037348]
	Learning Rate: 0.00373476
	LOSS [training: 0.5001223270756769 | validation: 0.7712288465865567]
	TIME [epoch: 8.43 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5929568408835199		[learning rate: 0.0037212]
	Learning Rate: 0.00372121
	LOSS [training: 0.5929568408835199 | validation: 0.7554928831673375]
	TIME [epoch: 8.42 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47633921211276026		[learning rate: 0.0037077]
	Learning Rate: 0.00370771
	LOSS [training: 0.47633921211276026 | validation: 0.9191840013569743]
	TIME [epoch: 8.44 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41834366413312		[learning rate: 0.0036943]
	Learning Rate: 0.00369425
	LOSS [training: 0.41834366413312 | validation: 0.6163922380953476]
	TIME [epoch: 8.42 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49204669549211494		[learning rate: 0.0036808]
	Learning Rate: 0.00368084
	LOSS [training: 0.49204669549211494 | validation: 0.41842093477826403]
	TIME [epoch: 8.42 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4657151136565922		[learning rate: 0.0036675]
	Learning Rate: 0.00366749
	LOSS [training: 0.4657151136565922 | validation: 0.48598571793544676]
	TIME [epoch: 8.43 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47742974324901166		[learning rate: 0.0036542]
	Learning Rate: 0.00365418
	LOSS [training: 0.47742974324901166 | validation: 0.9033128588568513]
	TIME [epoch: 8.45 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44070392137969766		[learning rate: 0.0036409]
	Learning Rate: 0.00364092
	LOSS [training: 0.44070392137969766 | validation: 0.9332670616052081]
	TIME [epoch: 8.43 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41927304680701977		[learning rate: 0.0036277]
	Learning Rate: 0.0036277
	LOSS [training: 0.41927304680701977 | validation: 0.629578601652729]
	TIME [epoch: 8.42 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4963455970374728		[learning rate: 0.0036145]
	Learning Rate: 0.00361454
	LOSS [training: 0.4963455970374728 | validation: 0.4960416862477621]
	TIME [epoch: 8.43 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.557983533152803		[learning rate: 0.0036014]
	Learning Rate: 0.00360142
	LOSS [training: 0.557983533152803 | validation: 0.9431526369733265]
	TIME [epoch: 8.44 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47372533612171175		[learning rate: 0.0035883]
	Learning Rate: 0.00358835
	LOSS [training: 0.47372533612171175 | validation: 1.0329785954676223]
	TIME [epoch: 8.43 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5868695326724083		[learning rate: 0.0035753]
	Learning Rate: 0.00357533
	LOSS [training: 0.5868695326724083 | validation: 0.4117571143250595]
	TIME [epoch: 8.42 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44391369637990674		[learning rate: 0.0035624]
	Learning Rate: 0.00356235
	LOSS [training: 0.44391369637990674 | validation: 0.7331662776090307]
	TIME [epoch: 8.42 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4348176211787892		[learning rate: 0.0035494]
	Learning Rate: 0.00354942
	LOSS [training: 0.4348176211787892 | validation: 1.1522372016738043]
	TIME [epoch: 8.45 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4442720589453252		[learning rate: 0.0035365]
	Learning Rate: 0.00353654
	LOSS [training: 0.4442720589453252 | validation: 0.7455019937857462]
	TIME [epoch: 8.43 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38056057043836017		[learning rate: 0.0035237]
	Learning Rate: 0.00352371
	LOSS [training: 0.38056057043836017 | validation: 0.9090505476719044]
	TIME [epoch: 8.42 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4631873276002465		[learning rate: 0.0035109]
	Learning Rate: 0.00351092
	LOSS [training: 0.4631873276002465 | validation: 1.0745235114895744]
	TIME [epoch: 8.42 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43432103334115935		[learning rate: 0.0034982]
	Learning Rate: 0.00349818
	LOSS [training: 0.43432103334115935 | validation: 0.54191638187954]
	TIME [epoch: 8.46 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3848975628296068		[learning rate: 0.0034855]
	Learning Rate: 0.00348548
	LOSS [training: 0.3848975628296068 | validation: 1.251666332768042]
	TIME [epoch: 8.43 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40705677416069275		[learning rate: 0.0034728]
	Learning Rate: 0.00347284
	LOSS [training: 0.40705677416069275 | validation: 0.8557074980486719]
	TIME [epoch: 8.43 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5177608463650507		[learning rate: 0.0034602]
	Learning Rate: 0.00346023
	LOSS [training: 0.5177608463650507 | validation: 1.0328296301577757]
	TIME [epoch: 8.43 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4356776953136488		[learning rate: 0.0034477]
	Learning Rate: 0.00344767
	LOSS [training: 0.4356776953136488 | validation: 0.49285203314045944]
	TIME [epoch: 8.44 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4363166018973155		[learning rate: 0.0034352]
	Learning Rate: 0.00343516
	LOSS [training: 0.4363166018973155 | validation: 0.5990493573784316]
	TIME [epoch: 8.42 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4312325293633448		[learning rate: 0.0034227]
	Learning Rate: 0.0034227
	LOSS [training: 0.4312325293633448 | validation: 0.5832997559784255]
	TIME [epoch: 8.42 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5688059765323731		[learning rate: 0.0034103]
	Learning Rate: 0.00341028
	LOSS [training: 0.5688059765323731 | validation: 0.3582940600574842]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46893699187972937		[learning rate: 0.0033979]
	Learning Rate: 0.0033979
	LOSS [training: 0.46893699187972937 | validation: 0.6895776695884326]
	TIME [epoch: 8.44 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37459997419710545		[learning rate: 0.0033856]
	Learning Rate: 0.00338557
	LOSS [training: 0.37459997419710545 | validation: 0.5620676452951978]
	TIME [epoch: 8.42 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41449394439224124		[learning rate: 0.0033733]
	Learning Rate: 0.00337328
	LOSS [training: 0.41449394439224124 | validation: 0.9722056506396145]
	TIME [epoch: 8.41 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4629820485327912		[learning rate: 0.003361]
	Learning Rate: 0.00336104
	LOSS [training: 0.4629820485327912 | validation: 0.3994751000261849]
	TIME [epoch: 8.42 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3318987624004233		[learning rate: 0.0033488]
	Learning Rate: 0.00334884
	LOSS [training: 0.3318987624004233 | validation: 1.285292942273065]
	TIME [epoch: 8.44 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4919768011328999		[learning rate: 0.0033367]
	Learning Rate: 0.00333669
	LOSS [training: 0.4919768011328999 | validation: 0.44894996339600124]
	TIME [epoch: 8.42 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38669610566335033		[learning rate: 0.0033246]
	Learning Rate: 0.00332458
	LOSS [training: 0.38669610566335033 | validation: 0.50848807874445]
	TIME [epoch: 8.42 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4568212731192068		[learning rate: 0.0033125]
	Learning Rate: 0.00331252
	LOSS [training: 0.4568212731192068 | validation: 0.6931450306108489]
	TIME [epoch: 8.42 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43728022254900106		[learning rate: 0.0033005]
	Learning Rate: 0.00330049
	LOSS [training: 0.43728022254900106 | validation: 0.4217513595109855]
	TIME [epoch: 8.44 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36628490147560094		[learning rate: 0.0032885]
	Learning Rate: 0.00328852
	LOSS [training: 0.36628490147560094 | validation: 0.6813675972260484]
	TIME [epoch: 8.42 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4022138200200739		[learning rate: 0.0032766]
	Learning Rate: 0.00327658
	LOSS [training: 0.4022138200200739 | validation: 0.6671014782339734]
	TIME [epoch: 8.42 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44964786893243386		[learning rate: 0.0032647]
	Learning Rate: 0.00326469
	LOSS [training: 0.44964786893243386 | validation: 0.6228104178840289]
	TIME [epoch: 8.44 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4067426261270608		[learning rate: 0.0032528]
	Learning Rate: 0.00325284
	LOSS [training: 0.4067426261270608 | validation: 0.5605723470070092]
	TIME [epoch: 8.42 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36130208967857047		[learning rate: 0.003241]
	Learning Rate: 0.00324104
	LOSS [training: 0.36130208967857047 | validation: 0.6283792173095821]
	TIME [epoch: 8.42 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3533976269368023		[learning rate: 0.0032293]
	Learning Rate: 0.00322928
	LOSS [training: 0.3533976269368023 | validation: 0.5848959821033195]
	TIME [epoch: 8.42 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41241576303906147		[learning rate: 0.0032176]
	Learning Rate: 0.00321756
	LOSS [training: 0.41241576303906147 | validation: 0.45023581101612853]
	TIME [epoch: 8.44 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32516868692118955		[learning rate: 0.0032059]
	Learning Rate: 0.00320588
	LOSS [training: 0.32516868692118955 | validation: 0.5904225539307314]
	TIME [epoch: 8.42 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34139848520640376		[learning rate: 0.0031942]
	Learning Rate: 0.00319425
	LOSS [training: 0.34139848520640376 | validation: 0.5387184405468066]
	TIME [epoch: 8.42 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34084482243400016		[learning rate: 0.0031827]
	Learning Rate: 0.00318265
	LOSS [training: 0.34084482243400016 | validation: 0.5713521048061859]
	TIME [epoch: 8.42 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3741126515205774		[learning rate: 0.0031711]
	Learning Rate: 0.0031711
	LOSS [training: 0.3741126515205774 | validation: 0.6811022539016248]
	TIME [epoch: 8.44 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.416861570920078		[learning rate: 0.0031596]
	Learning Rate: 0.0031596
	LOSS [training: 0.416861570920078 | validation: 0.5833855657774589]
	TIME [epoch: 8.42 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37291940492646186		[learning rate: 0.0031481]
	Learning Rate: 0.00314813
	LOSS [training: 0.37291940492646186 | validation: 0.5518750663025519]
	TIME [epoch: 8.41 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3268052968905756		[learning rate: 0.0031367]
	Learning Rate: 0.00313671
	LOSS [training: 0.3268052968905756 | validation: 0.3291808651652623]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4640059146130895		[learning rate: 0.0031253]
	Learning Rate: 0.00312532
	LOSS [training: 0.4640059146130895 | validation: 0.6552704688777968]
	TIME [epoch: 8.45 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3975208374004933		[learning rate: 0.003114]
	Learning Rate: 0.00311398
	LOSS [training: 0.3975208374004933 | validation: 0.8457770698442487]
	TIME [epoch: 8.42 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3790683116191382		[learning rate: 0.0031027]
	Learning Rate: 0.00310268
	LOSS [training: 0.3790683116191382 | validation: 0.3448687031296791]
	TIME [epoch: 8.42 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46213086147635735		[learning rate: 0.0030914]
	Learning Rate: 0.00309142
	LOSS [training: 0.46213086147635735 | validation: 0.6332008338306354]
	TIME [epoch: 8.41 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39251945013235323		[learning rate: 0.0030802]
	Learning Rate: 0.0030802
	LOSS [training: 0.39251945013235323 | validation: 0.4806715442048115]
	TIME [epoch: 8.44 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40883349916892564		[learning rate: 0.003069]
	Learning Rate: 0.00306902
	LOSS [training: 0.40883349916892564 | validation: 0.44934152071373323]
	TIME [epoch: 8.42 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3687615120035438		[learning rate: 0.0030579]
	Learning Rate: 0.00305788
	LOSS [training: 0.3687615120035438 | validation: 0.7720317867186648]
	TIME [epoch: 8.42 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3530972103958615		[learning rate: 0.0030468]
	Learning Rate: 0.00304679
	LOSS [training: 0.3530972103958615 | validation: 0.33390553978373116]
	TIME [epoch: 8.42 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32703756111521975		[learning rate: 0.0030357]
	Learning Rate: 0.00303573
	LOSS [training: 0.32703756111521975 | validation: 0.43085215431677415]
	TIME [epoch: 8.45 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.375198079933618		[learning rate: 0.0030247]
	Learning Rate: 0.00302471
	LOSS [training: 0.375198079933618 | validation: 0.6513616648205559]
	TIME [epoch: 8.42 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3369057724402958		[learning rate: 0.0030137]
	Learning Rate: 0.00301374
	LOSS [training: 0.3369057724402958 | validation: 0.5398895282752152]
	TIME [epoch: 8.42 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40502365171595694		[learning rate: 0.0030028]
	Learning Rate: 0.0030028
	LOSS [training: 0.40502365171595694 | validation: 1.0481119242948538]
	TIME [epoch: 8.41 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4249890256341258		[learning rate: 0.0029919]
	Learning Rate: 0.0029919
	LOSS [training: 0.4249890256341258 | validation: 0.6857541306785867]
	TIME [epoch: 8.45 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3504380909246918		[learning rate: 0.002981]
	Learning Rate: 0.00298104
	LOSS [training: 0.3504380909246918 | validation: 0.7036287835705579]
	TIME [epoch: 8.42 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4660141464379227		[learning rate: 0.0029702]
	Learning Rate: 0.00297023
	LOSS [training: 0.4660141464379227 | validation: 0.5247060848375036]
	TIME [epoch: 8.42 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34693590312616424		[learning rate: 0.0029594]
	Learning Rate: 0.00295945
	LOSS [training: 0.34693590312616424 | validation: 0.6439426279484861]
	TIME [epoch: 8.42 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36984261058120127		[learning rate: 0.0029487]
	Learning Rate: 0.00294871
	LOSS [training: 0.36984261058120127 | validation: 0.825723861266033]
	TIME [epoch: 8.45 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4051089667826191		[learning rate: 0.002938]
	Learning Rate: 0.00293801
	LOSS [training: 0.4051089667826191 | validation: 0.38945890117758203]
	TIME [epoch: 8.42 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3341531923179837		[learning rate: 0.0029273]
	Learning Rate: 0.00292734
	LOSS [training: 0.3341531923179837 | validation: 0.4277391499133075]
	TIME [epoch: 8.42 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37943767358630304		[learning rate: 0.0029167]
	Learning Rate: 0.00291672
	LOSS [training: 0.37943767358630304 | validation: 0.5530835949489517]
	TIME [epoch: 8.42 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4747415580214559		[learning rate: 0.0029061]
	Learning Rate: 0.00290614
	LOSS [training: 0.4747415580214559 | validation: 0.5088206506287648]
	TIME [epoch: 8.45 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26511985686145373		[learning rate: 0.0028956]
	Learning Rate: 0.00289559
	LOSS [training: 0.26511985686145373 | validation: 0.7048283278076803]
	TIME [epoch: 8.42 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3255414459146033		[learning rate: 0.0028851]
	Learning Rate: 0.00288508
	LOSS [training: 0.3255414459146033 | validation: 0.3813261520161548]
	TIME [epoch: 8.42 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2835827225966153		[learning rate: 0.0028746]
	Learning Rate: 0.00287461
	LOSS [training: 0.2835827225966153 | validation: 0.5714539723049097]
	TIME [epoch: 8.41 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35904943398916134		[learning rate: 0.0028642]
	Learning Rate: 0.00286418
	LOSS [training: 0.35904943398916134 | validation: 0.5329668384965706]
	TIME [epoch: 8.44 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3037212109205719		[learning rate: 0.0028538]
	Learning Rate: 0.00285378
	LOSS [training: 0.3037212109205719 | validation: 0.3607545247028881]
	TIME [epoch: 8.42 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3176908118672881		[learning rate: 0.0028434]
	Learning Rate: 0.00284343
	LOSS [training: 0.3176908118672881 | validation: 0.3690428291430998]
	TIME [epoch: 8.42 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5236349717960256		[learning rate: 0.0028331]
	Learning Rate: 0.00283311
	LOSS [training: 0.5236349717960256 | validation: 0.6233638252983695]
	TIME [epoch: 8.42 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41243083910960465		[learning rate: 0.0028228]
	Learning Rate: 0.00282283
	LOSS [training: 0.41243083910960465 | validation: 0.4142193792507499]
	TIME [epoch: 8.44 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36188458405568247		[learning rate: 0.0028126]
	Learning Rate: 0.00281258
	LOSS [training: 0.36188458405568247 | validation: 0.4814098904439146]
	TIME [epoch: 8.42 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2904181841904914		[learning rate: 0.0028024]
	Learning Rate: 0.00280238
	LOSS [training: 0.2904181841904914 | validation: 0.6108658883490609]
	TIME [epoch: 8.42 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36398521910662446		[learning rate: 0.0027922]
	Learning Rate: 0.00279221
	LOSS [training: 0.36398521910662446 | validation: 0.5788716724049286]
	TIME [epoch: 8.43 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3522140541247893		[learning rate: 0.0027821]
	Learning Rate: 0.00278207
	LOSS [training: 0.3522140541247893 | validation: 0.6858225238071387]
	TIME [epoch: 8.43 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3559940590001859		[learning rate: 0.002772]
	Learning Rate: 0.00277198
	LOSS [training: 0.3559940590001859 | validation: 0.35977688274478825]
	TIME [epoch: 8.42 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3192418423013027		[learning rate: 0.0027619]
	Learning Rate: 0.00276192
	LOSS [training: 0.3192418423013027 | validation: 0.586088478635594]
	TIME [epoch: 8.42 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29237466054503136		[learning rate: 0.0027519]
	Learning Rate: 0.00275189
	LOSS [training: 0.29237466054503136 | validation: 0.5110807207783825]
	TIME [epoch: 8.43 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33752549988373903		[learning rate: 0.0027419]
	Learning Rate: 0.00274191
	LOSS [training: 0.33752549988373903 | validation: 0.705723224252826]
	TIME [epoch: 8.43 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30827483804816447		[learning rate: 0.002732]
	Learning Rate: 0.00273196
	LOSS [training: 0.30827483804816447 | validation: 0.7238803135051857]
	TIME [epoch: 8.42 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38021964955535		[learning rate: 0.002722]
	Learning Rate: 0.00272204
	LOSS [training: 0.38021964955535 | validation: 0.5427770138032182]
	TIME [epoch: 8.42 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3921337814331235		[learning rate: 0.0027122]
	Learning Rate: 0.00271216
	LOSS [training: 0.3921337814331235 | validation: 0.7266024499189618]
	TIME [epoch: 8.43 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34148920215703027		[learning rate: 0.0027023]
	Learning Rate: 0.00270232
	LOSS [training: 0.34148920215703027 | validation: 0.675000335366554]
	TIME [epoch: 8.44 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49334233076630013		[learning rate: 0.0026925]
	Learning Rate: 0.00269251
	LOSS [training: 0.49334233076630013 | validation: 1.1746615471357231]
	TIME [epoch: 8.42 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38755839396397		[learning rate: 0.0026827]
	Learning Rate: 0.00268274
	LOSS [training: 0.38755839396397 | validation: 0.3374059654761229]
	TIME [epoch: 8.42 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2760493796820522		[learning rate: 0.002673]
	Learning Rate: 0.00267301
	LOSS [training: 0.2760493796820522 | validation: 0.6212375350314358]
	TIME [epoch: 8.44 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3665836464234001		[learning rate: 0.0026633]
	Learning Rate: 0.00266331
	LOSS [training: 0.3665836464234001 | validation: 0.3374712451670443]
	TIME [epoch: 8.44 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3391720242748464		[learning rate: 0.0026536]
	Learning Rate: 0.00265364
	LOSS [training: 0.3391720242748464 | validation: 0.466152122524636]
	TIME [epoch: 8.42 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3466150113588257		[learning rate: 0.002644]
	Learning Rate: 0.00264401
	LOSS [training: 0.3466150113588257 | validation: 0.36882615856448053]
	TIME [epoch: 8.42 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3573983548126585		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.3573983548126585 | validation: 0.5730544075365398]
	TIME [epoch: 8.45 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3664488821449032		[learning rate: 0.0026249]
	Learning Rate: 0.00262485
	LOSS [training: 0.3664488821449032 | validation: 0.5690831293938791]
	TIME [epoch: 8.42 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3552252812383		[learning rate: 0.0026153]
	Learning Rate: 0.00261533
	LOSS [training: 0.3552252812383 | validation: 0.5219724785098396]
	TIME [epoch: 8.42 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.282691127484428		[learning rate: 0.0026058]
	Learning Rate: 0.00260584
	LOSS [training: 0.282691127484428 | validation: 0.3527235516620705]
	TIME [epoch: 8.42 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26737054393297394		[learning rate: 0.0025964]
	Learning Rate: 0.00259638
	LOSS [training: 0.26737054393297394 | validation: 0.3351128916124144]
	TIME [epoch: 8.45 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32390155305122914		[learning rate: 0.002587]
	Learning Rate: 0.00258696
	LOSS [training: 0.32390155305122914 | validation: 0.5025635431931565]
	TIME [epoch: 8.42 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2814307255281664		[learning rate: 0.0025776]
	Learning Rate: 0.00257757
	LOSS [training: 0.2814307255281664 | validation: 0.42395532787223317]
	TIME [epoch: 8.42 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3006047165160063		[learning rate: 0.0025682]
	Learning Rate: 0.00256822
	LOSS [training: 0.3006047165160063 | validation: 0.4736948340273132]
	TIME [epoch: 8.42 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3128891800924899		[learning rate: 0.0025589]
	Learning Rate: 0.0025589
	LOSS [training: 0.3128891800924899 | validation: 0.4756622460638189]
	TIME [epoch: 8.44 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25568928376164546		[learning rate: 0.0025496]
	Learning Rate: 0.00254961
	LOSS [training: 0.25568928376164546 | validation: 0.34322009271020193]
	TIME [epoch: 8.43 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28646699779329177		[learning rate: 0.0025404]
	Learning Rate: 0.00254036
	LOSS [training: 0.28646699779329177 | validation: 0.6985897345173168]
	TIME [epoch: 8.42 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29631638788634496		[learning rate: 0.0025311]
	Learning Rate: 0.00253114
	LOSS [training: 0.29631638788634496 | validation: 0.27911611774428036]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31448031168032864		[learning rate: 0.002522]
	Learning Rate: 0.00252195
	LOSS [training: 0.31448031168032864 | validation: 0.36477986381529726]
	TIME [epoch: 8.45 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4177007837163827		[learning rate: 0.0025128]
	Learning Rate: 0.0025128
	LOSS [training: 0.4177007837163827 | validation: 0.810060465538321]
	TIME [epoch: 8.42 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3375025213166009		[learning rate: 0.0025037]
	Learning Rate: 0.00250368
	LOSS [training: 0.3375025213166009 | validation: 0.8195374610637062]
	TIME [epoch: 8.42 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3455528264626686		[learning rate: 0.0024946]
	Learning Rate: 0.00249459
	LOSS [training: 0.3455528264626686 | validation: 0.32662711525789445]
	TIME [epoch: 8.42 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30431455618279524		[learning rate: 0.0024855]
	Learning Rate: 0.00248554
	LOSS [training: 0.30431455618279524 | validation: 0.5142091801858496]
	TIME [epoch: 8.45 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34998866373687976		[learning rate: 0.0024765]
	Learning Rate: 0.00247652
	LOSS [training: 0.34998866373687976 | validation: 0.4173293668791498]
	TIME [epoch: 8.42 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41284120238641114		[learning rate: 0.0024675]
	Learning Rate: 0.00246753
	LOSS [training: 0.41284120238641114 | validation: 0.5327025447952359]
	TIME [epoch: 8.42 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2530210735133607		[learning rate: 0.0024586]
	Learning Rate: 0.00245858
	LOSS [training: 0.2530210735133607 | validation: 0.4609257749117814]
	TIME [epoch: 8.41 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27314269203896846		[learning rate: 0.0024497]
	Learning Rate: 0.00244966
	LOSS [training: 0.27314269203896846 | validation: 0.9184227765784378]
	TIME [epoch: 8.44 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31174908889016384		[learning rate: 0.0024408]
	Learning Rate: 0.00244077
	LOSS [training: 0.31174908889016384 | validation: 0.37027960942835614]
	TIME [epoch: 8.42 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.269200443921113		[learning rate: 0.0024319]
	Learning Rate: 0.00243191
	LOSS [training: 0.269200443921113 | validation: 0.5351172051472864]
	TIME [epoch: 8.42 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.303825989184779		[learning rate: 0.0024231]
	Learning Rate: 0.00242308
	LOSS [training: 0.303825989184779 | validation: 0.4616923231615339]
	TIME [epoch: 8.42 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3137376071552317		[learning rate: 0.0024143]
	Learning Rate: 0.00241429
	LOSS [training: 0.3137376071552317 | validation: 0.35812788907683435]
	TIME [epoch: 8.45 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2951733913419135		[learning rate: 0.0024055]
	Learning Rate: 0.00240553
	LOSS [training: 0.2951733913419135 | validation: 0.4094305440894406]
	TIME [epoch: 8.42 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2749508631861009		[learning rate: 0.0023968]
	Learning Rate: 0.0023968
	LOSS [training: 0.2749508631861009 | validation: 1.0197889246056395]
	TIME [epoch: 8.42 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43377307669885506		[learning rate: 0.0023881]
	Learning Rate: 0.0023881
	LOSS [training: 0.43377307669885506 | validation: 0.4724722081086284]
	TIME [epoch: 8.43 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135900392541634		[learning rate: 0.0023794]
	Learning Rate: 0.00237943
	LOSS [training: 0.3135900392541634 | validation: 1.2597842817081126]
	TIME [epoch: 8.45 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42618139916566866		[learning rate: 0.0023708]
	Learning Rate: 0.0023708
	LOSS [training: 0.42618139916566866 | validation: 0.5213506572015023]
	TIME [epoch: 8.42 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2891630531245569		[learning rate: 0.0023622]
	Learning Rate: 0.0023622
	LOSS [training: 0.2891630531245569 | validation: 0.33988686081693786]
	TIME [epoch: 8.42 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26337368104070996		[learning rate: 0.0023536]
	Learning Rate: 0.00235362
	LOSS [training: 0.26337368104070996 | validation: 0.4943955938018312]
	TIME [epoch: 8.42 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2904236304585138		[learning rate: 0.0023451]
	Learning Rate: 0.00234508
	LOSS [training: 0.2904236304585138 | validation: 0.25583045321766407]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2711356690162295		[learning rate: 0.0023366]
	Learning Rate: 0.00233657
	LOSS [training: 0.2711356690162295 | validation: 0.36993641915880465]
	TIME [epoch: 8.42 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3000236287852529		[learning rate: 0.0023281]
	Learning Rate: 0.00232809
	LOSS [training: 0.3000236287852529 | validation: 0.5393865330202885]
	TIME [epoch: 8.41 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33320450975539057		[learning rate: 0.0023196]
	Learning Rate: 0.00231964
	LOSS [training: 0.33320450975539057 | validation: 0.47229399089947044]
	TIME [epoch: 8.42 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3526186677766413		[learning rate: 0.0023112]
	Learning Rate: 0.00231122
	LOSS [training: 0.3526186677766413 | validation: 0.470107348663088]
	TIME [epoch: 8.44 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27581902088249205		[learning rate: 0.0023028]
	Learning Rate: 0.00230284
	LOSS [training: 0.27581902088249205 | validation: 0.3427734665737077]
	TIME [epoch: 8.42 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3150179236391778		[learning rate: 0.0022945]
	Learning Rate: 0.00229448
	LOSS [training: 0.3150179236391778 | validation: 0.26663888807773617]
	TIME [epoch: 8.42 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892233766187797		[learning rate: 0.0022862]
	Learning Rate: 0.00228615
	LOSS [training: 0.2892233766187797 | validation: 0.36140169482319545]
	TIME [epoch: 8.43 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26776343632180655		[learning rate: 0.0022779]
	Learning Rate: 0.00227786
	LOSS [training: 0.26776343632180655 | validation: 0.35986911686419387]
	TIME [epoch: 8.44 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25818660487575995		[learning rate: 0.0022696]
	Learning Rate: 0.00226959
	LOSS [training: 0.25818660487575995 | validation: 0.3499064797491941]
	TIME [epoch: 8.42 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33546631949922917		[learning rate: 0.0022614]
	Learning Rate: 0.00226135
	LOSS [training: 0.33546631949922917 | validation: 0.525711746143362]
	TIME [epoch: 8.41 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2632412322669552		[learning rate: 0.0022531]
	Learning Rate: 0.00225315
	LOSS [training: 0.2632412322669552 | validation: 0.48911261523556665]
	TIME [epoch: 8.43 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3134233294911352		[learning rate: 0.002245]
	Learning Rate: 0.00224497
	LOSS [training: 0.3134233294911352 | validation: 0.567174177012286]
	TIME [epoch: 8.43 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2966063863505993		[learning rate: 0.0022368]
	Learning Rate: 0.00223682
	LOSS [training: 0.2966063863505993 | validation: 0.27060368269773627]
	TIME [epoch: 8.42 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.279703786694591		[learning rate: 0.0022287]
	Learning Rate: 0.00222871
	LOSS [training: 0.279703786694591 | validation: 0.4212323132936574]
	TIME [epoch: 8.42 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23903670469429067		[learning rate: 0.0022206]
	Learning Rate: 0.00222062
	LOSS [training: 0.23903670469429067 | validation: 0.7426061615291224]
	TIME [epoch: 8.42 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3036746912741272		[learning rate: 0.0022126]
	Learning Rate: 0.00221256
	LOSS [training: 0.3036746912741272 | validation: 0.590506662488309]
	TIME [epoch: 8.43 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32126512053987183		[learning rate: 0.0022045]
	Learning Rate: 0.00220453
	LOSS [training: 0.32126512053987183 | validation: 0.4733458346089271]
	TIME [epoch: 8.41 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3188296450393077		[learning rate: 0.0021965]
	Learning Rate: 0.00219653
	LOSS [training: 0.3188296450393077 | validation: 0.48935129565581786]
	TIME [epoch: 8.41 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2708140410443463		[learning rate: 0.0021886]
	Learning Rate: 0.00218856
	LOSS [training: 0.2708140410443463 | validation: 0.4293425305797348]
	TIME [epoch: 8.43 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3007433861847833		[learning rate: 0.0021806]
	Learning Rate: 0.00218061
	LOSS [training: 0.3007433861847833 | validation: 0.28410405888390916]
	TIME [epoch: 8.42 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23643667720517678		[learning rate: 0.0021727]
	Learning Rate: 0.0021727
	LOSS [training: 0.23643667720517678 | validation: 0.4025095409784123]
	TIME [epoch: 8.42 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24328367216294383		[learning rate: 0.0021648]
	Learning Rate: 0.00216482
	LOSS [training: 0.24328367216294383 | validation: 0.39361445371821757]
	TIME [epoch: 8.41 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3786982390703296		[learning rate: 0.002157]
	Learning Rate: 0.00215696
	LOSS [training: 0.3786982390703296 | validation: 0.4048578653180074]
	TIME [epoch: 8.43 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27528473977633794		[learning rate: 0.0021491]
	Learning Rate: 0.00214913
	LOSS [training: 0.27528473977633794 | validation: 0.8127842054127947]
	TIME [epoch: 8.42 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29951805229544515		[learning rate: 0.0021413]
	Learning Rate: 0.00214133
	LOSS [training: 0.29951805229544515 | validation: 0.5615497087486513]
	TIME [epoch: 8.41 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3811992411608017		[learning rate: 0.0021336]
	Learning Rate: 0.00213356
	LOSS [training: 0.3811992411608017 | validation: 0.6598615281075109]
	TIME [epoch: 8.41 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30750657982451346		[learning rate: 0.0021258]
	Learning Rate: 0.00212582
	LOSS [training: 0.30750657982451346 | validation: 0.47078594624385756]
	TIME [epoch: 8.43 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2651405364749949		[learning rate: 0.0021181]
	Learning Rate: 0.0021181
	LOSS [training: 0.2651405364749949 | validation: 0.28724671857420814]
	TIME [epoch: 8.42 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25311396654962043		[learning rate: 0.0021104]
	Learning Rate: 0.00211042
	LOSS [training: 0.25311396654962043 | validation: 0.7526536022131646]
	TIME [epoch: 8.41 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3577753274612719		[learning rate: 0.0021028]
	Learning Rate: 0.00210276
	LOSS [training: 0.3577753274612719 | validation: 0.6414782130683478]
	TIME [epoch: 8.41 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24696875463750353		[learning rate: 0.0020951]
	Learning Rate: 0.00209513
	LOSS [training: 0.24696875463750353 | validation: 0.24420359353502497]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34771084070461694		[learning rate: 0.0020875]
	Learning Rate: 0.00208752
	LOSS [training: 0.34771084070461694 | validation: 0.5855798111141388]
	TIME [epoch: 8.43 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.269539961915055		[learning rate: 0.0020799]
	Learning Rate: 0.00207995
	LOSS [training: 0.269539961915055 | validation: 0.2802934447672979]
	TIME [epoch: 8.42 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27263150480202636		[learning rate: 0.0020724]
	Learning Rate: 0.0020724
	LOSS [training: 0.27263150480202636 | validation: 0.4906329527622073]
	TIME [epoch: 8.42 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27237652326154704		[learning rate: 0.0020649]
	Learning Rate: 0.00206488
	LOSS [training: 0.27237652326154704 | validation: 0.4977538038512435]
	TIME [epoch: 8.44 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2913931049910673		[learning rate: 0.0020574]
	Learning Rate: 0.00205739
	LOSS [training: 0.2913931049910673 | validation: 0.4054544280353445]
	TIME [epoch: 8.42 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28925090071989684		[learning rate: 0.0020499]
	Learning Rate: 0.00204992
	LOSS [training: 0.28925090071989684 | validation: 0.5775194424771259]
	TIME [epoch: 8.42 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25996824620465564		[learning rate: 0.0020425]
	Learning Rate: 0.00204248
	LOSS [training: 0.25996824620465564 | validation: 0.39458549898064665]
	TIME [epoch: 8.41 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24645537558570582		[learning rate: 0.0020351]
	Learning Rate: 0.00203507
	LOSS [training: 0.24645537558570582 | validation: 0.3662978915352314]
	TIME [epoch: 8.44 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.282482705036906		[learning rate: 0.0020277]
	Learning Rate: 0.00202768
	LOSS [training: 0.282482705036906 | validation: 0.3574718525818067]
	TIME [epoch: 8.41 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29134455357753963		[learning rate: 0.0020203]
	Learning Rate: 0.00202032
	LOSS [training: 0.29134455357753963 | validation: 0.3013550142814684]
	TIME [epoch: 8.42 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.193285377395219		[learning rate: 0.002013]
	Learning Rate: 0.00201299
	LOSS [training: 0.193285377395219 | validation: 0.34041031277046263]
	TIME [epoch: 8.42 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250774358999386		[learning rate: 0.0020057]
	Learning Rate: 0.00200569
	LOSS [training: 0.250774358999386 | validation: 0.3134616966153696]
	TIME [epoch: 8.44 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27066373149191275		[learning rate: 0.0019984]
	Learning Rate: 0.00199841
	LOSS [training: 0.27066373149191275 | validation: 0.3187084681011287]
	TIME [epoch: 8.42 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42555325761167717		[learning rate: 0.0019912]
	Learning Rate: 0.00199116
	LOSS [training: 0.42555325761167717 | validation: 0.6189822018499613]
	TIME [epoch: 8.41 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29022764690893127		[learning rate: 0.0019839]
	Learning Rate: 0.00198393
	LOSS [training: 0.29022764690893127 | validation: 0.4040190742442895]
	TIME [epoch: 8.41 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26643258062220887		[learning rate: 0.0019767]
	Learning Rate: 0.00197673
	LOSS [training: 0.26643258062220887 | validation: 0.41131095869581885]
	TIME [epoch: 8.44 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21837679328504617		[learning rate: 0.0019696]
	Learning Rate: 0.00196956
	LOSS [training: 0.21837679328504617 | validation: 0.39252488042164635]
	TIME [epoch: 8.42 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25502305670980135		[learning rate: 0.0019624]
	Learning Rate: 0.00196241
	LOSS [training: 0.25502305670980135 | validation: 0.2555434385196589]
	TIME [epoch: 8.41 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2558047874390464		[learning rate: 0.0019553]
	Learning Rate: 0.00195529
	LOSS [training: 0.2558047874390464 | validation: 0.31482187364353553]
	TIME [epoch: 8.41 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3073799172792926		[learning rate: 0.0019482]
	Learning Rate: 0.00194819
	LOSS [training: 0.3073799172792926 | validation: 0.3063018587816341]
	TIME [epoch: 8.44 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23186091312450952		[learning rate: 0.0019411]
	Learning Rate: 0.00194112
	LOSS [training: 0.23186091312450952 | validation: 0.23620468303172976]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_551.pth
	Model improved!!!
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19328161724197612		[learning rate: 0.0019341]
	Learning Rate: 0.00193408
	LOSS [training: 0.19328161724197612 | validation: 0.7087049156626494]
	TIME [epoch: 8.42 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31163948633739136		[learning rate: 0.0019271]
	Learning Rate: 0.00192706
	LOSS [training: 0.31163948633739136 | validation: 0.2796633277993613]
	TIME [epoch: 8.42 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23315229224225834		[learning rate: 0.0019201]
	Learning Rate: 0.00192006
	LOSS [training: 0.23315229224225834 | validation: 0.21510710549412296]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700103735309347		[learning rate: 0.0019131]
	Learning Rate: 0.0019131
	LOSS [training: 0.2700103735309347 | validation: 0.5710924358549428]
	TIME [epoch: 8.42 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2975889093553209		[learning rate: 0.0019062]
	Learning Rate: 0.00190615
	LOSS [training: 0.2975889093553209 | validation: 0.49743682678238543]
	TIME [epoch: 8.41 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2760045692358612		[learning rate: 0.0018992]
	Learning Rate: 0.00189924
	LOSS [training: 0.2760045692358612 | validation: 0.36236009568644856]
	TIME [epoch: 8.43 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.281928959283011		[learning rate: 0.0018923]
	Learning Rate: 0.00189234
	LOSS [training: 0.281928959283011 | validation: 0.26123047807073096]
	TIME [epoch: 8.43 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28922442850056485		[learning rate: 0.0018855]
	Learning Rate: 0.00188548
	LOSS [training: 0.28922442850056485 | validation: 0.3606706680236324]
	TIME [epoch: 8.42 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23641145880364692		[learning rate: 0.0018786]
	Learning Rate: 0.00187863
	LOSS [training: 0.23641145880364692 | validation: 0.42204778323974773]
	TIME [epoch: 8.41 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24844079565343974		[learning rate: 0.0018718]
	Learning Rate: 0.00187182
	LOSS [training: 0.24844079565343974 | validation: 0.4723824165101381]
	TIME [epoch: 8.42 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28345683066104066		[learning rate: 0.001865]
	Learning Rate: 0.00186502
	LOSS [training: 0.28345683066104066 | validation: 0.3181340553726184]
	TIME [epoch: 8.43 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22715303009545157		[learning rate: 0.0018583]
	Learning Rate: 0.00185825
	LOSS [training: 0.22715303009545157 | validation: 0.39120075629104445]
	TIME [epoch: 8.42 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2189385299108161		[learning rate: 0.0018515]
	Learning Rate: 0.00185151
	LOSS [training: 0.2189385299108161 | validation: 0.543252619403813]
	TIME [epoch: 8.42 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2104377000030245		[learning rate: 0.0018448]
	Learning Rate: 0.00184479
	LOSS [training: 0.2104377000030245 | validation: 0.27828165259937915]
	TIME [epoch: 8.42 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2433664808626907		[learning rate: 0.0018381]
	Learning Rate: 0.0018381
	LOSS [training: 0.2433664808626907 | validation: 0.5367979557779576]
	TIME [epoch: 8.44 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2770003271855923		[learning rate: 0.0018314]
	Learning Rate: 0.00183143
	LOSS [training: 0.2770003271855923 | validation: 0.39085248700920955]
	TIME [epoch: 8.41 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26078808636074097		[learning rate: 0.0018248]
	Learning Rate: 0.00182478
	LOSS [training: 0.26078808636074097 | validation: 0.40172888319403643]
	TIME [epoch: 8.41 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27983208589487696		[learning rate: 0.0018182]
	Learning Rate: 0.00181816
	LOSS [training: 0.27983208589487696 | validation: 0.37281318187177936]
	TIME [epoch: 8.42 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2407981417993695		[learning rate: 0.0018116]
	Learning Rate: 0.00181156
	LOSS [training: 0.2407981417993695 | validation: 0.42911431755679696]
	TIME [epoch: 8.43 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2355339817428283		[learning rate: 0.001805]
	Learning Rate: 0.00180499
	LOSS [training: 0.2355339817428283 | validation: 0.34618270159169223]
	TIME [epoch: 8.41 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3248408364211187		[learning rate: 0.0017984]
	Learning Rate: 0.00179844
	LOSS [training: 0.3248408364211187 | validation: 1.154230605766032]
	TIME [epoch: 8.41 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3911448170931865		[learning rate: 0.0017919]
	Learning Rate: 0.00179191
	LOSS [training: 0.3911448170931865 | validation: 0.2992126830300911]
	TIME [epoch: 8.43 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2095883248439228		[learning rate: 0.0017854]
	Learning Rate: 0.00178541
	LOSS [training: 0.2095883248439228 | validation: 0.6117745300364332]
	TIME [epoch: 8.42 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3166893710264149		[learning rate: 0.0017789]
	Learning Rate: 0.00177893
	LOSS [training: 0.3166893710264149 | validation: 0.5477478212331274]
	TIME [epoch: 8.42 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26291397121884474		[learning rate: 0.0017725]
	Learning Rate: 0.00177247
	LOSS [training: 0.26291397121884474 | validation: 0.4867210653408053]
	TIME [epoch: 8.41 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797192720066418		[learning rate: 0.001766]
	Learning Rate: 0.00176604
	LOSS [training: 0.2797192720066418 | validation: 0.28215069020172623]
	TIME [epoch: 8.44 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24910407573617474		[learning rate: 0.0017596]
	Learning Rate: 0.00175963
	LOSS [training: 0.24910407573617474 | validation: 0.33805564932619614]
	TIME [epoch: 8.41 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2374437359612583		[learning rate: 0.0017532]
	Learning Rate: 0.00175324
	LOSS [training: 0.2374437359612583 | validation: 0.45368694806185234]
	TIME [epoch: 8.41 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25499297441196694		[learning rate: 0.0017469]
	Learning Rate: 0.00174688
	LOSS [training: 0.25499297441196694 | validation: 0.23312730227655876]
	TIME [epoch: 8.41 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21422181894936504		[learning rate: 0.0017405]
	Learning Rate: 0.00174054
	LOSS [training: 0.21422181894936504 | validation: 0.3215062388966863]
	TIME [epoch: 8.43 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25838346793362515		[learning rate: 0.0017342]
	Learning Rate: 0.00173422
	LOSS [training: 0.25838346793362515 | validation: 0.35059762552276863]
	TIME [epoch: 8.41 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24333530787769844		[learning rate: 0.0017279]
	Learning Rate: 0.00172793
	LOSS [training: 0.24333530787769844 | validation: 0.5591532281390136]
	TIME [epoch: 8.41 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2483600557576558		[learning rate: 0.0017217]
	Learning Rate: 0.00172166
	LOSS [training: 0.2483600557576558 | validation: 0.3985619842563099]
	TIME [epoch: 8.41 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2522361278554562		[learning rate: 0.0017154]
	Learning Rate: 0.00171541
	LOSS [training: 0.2522361278554562 | validation: 0.24774052484887268]
	TIME [epoch: 8.43 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20798667300332027		[learning rate: 0.0017092]
	Learning Rate: 0.00170919
	LOSS [training: 0.20798667300332027 | validation: 0.372163149038755]
	TIME [epoch: 8.42 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26436435803403346		[learning rate: 0.001703]
	Learning Rate: 0.00170298
	LOSS [training: 0.26436435803403346 | validation: 0.5555404696334534]
	TIME [epoch: 8.41 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23948510668321282		[learning rate: 0.0016968]
	Learning Rate: 0.0016968
	LOSS [training: 0.23948510668321282 | validation: 0.4862463511463395]
	TIME [epoch: 8.41 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2623596382886116		[learning rate: 0.0016906]
	Learning Rate: 0.00169065
	LOSS [training: 0.2623596382886116 | validation: 0.38507423080784003]
	TIME [epoch: 8.44 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32829938161761607		[learning rate: 0.0016845]
	Learning Rate: 0.00168451
	LOSS [training: 0.32829938161761607 | validation: 0.4787376370107237]
	TIME [epoch: 8.42 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2945520703289496		[learning rate: 0.0016784]
	Learning Rate: 0.0016784
	LOSS [training: 0.2945520703289496 | validation: 0.4646095489498606]
	TIME [epoch: 8.41 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24816639318135114		[learning rate: 0.0016723]
	Learning Rate: 0.00167231
	LOSS [training: 0.24816639318135114 | validation: 0.3601287128917571]
	TIME [epoch: 8.41 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28136260278293934		[learning rate: 0.0016662]
	Learning Rate: 0.00166624
	LOSS [training: 0.28136260278293934 | validation: 0.527369465123525]
	TIME [epoch: 8.44 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23110229069899813		[learning rate: 0.0016602]
	Learning Rate: 0.00166019
	LOSS [training: 0.23110229069899813 | validation: 0.30774489131150684]
	TIME [epoch: 8.41 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24313411340647922		[learning rate: 0.0016542]
	Learning Rate: 0.00165417
	LOSS [training: 0.24313411340647922 | validation: 0.3410176294299047]
	TIME [epoch: 8.41 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31150971994555665		[learning rate: 0.0016482]
	Learning Rate: 0.00164816
	LOSS [training: 0.31150971994555665 | validation: 0.3546387197520181]
	TIME [epoch: 8.41 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21017705429950478		[learning rate: 0.0016422]
	Learning Rate: 0.00164218
	LOSS [training: 0.21017705429950478 | validation: 0.30310006722337435]
	TIME [epoch: 8.44 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2623728766942549		[learning rate: 0.0016362]
	Learning Rate: 0.00163622
	LOSS [training: 0.2623728766942549 | validation: 0.31276503917380283]
	TIME [epoch: 8.42 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26401328677286384		[learning rate: 0.0016303]
	Learning Rate: 0.00163028
	LOSS [training: 0.26401328677286384 | validation: 0.33137845413145056]
	TIME [epoch: 8.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2154439248621663		[learning rate: 0.0016244]
	Learning Rate: 0.00162437
	LOSS [training: 0.2154439248621663 | validation: 0.46899854988081013]
	TIME [epoch: 8.41 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2076859282480516		[learning rate: 0.0016185]
	Learning Rate: 0.00161847
	LOSS [training: 0.2076859282480516 | validation: 0.28535767185350497]
	TIME [epoch: 8.43 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22130167538667017		[learning rate: 0.0016126]
	Learning Rate: 0.0016126
	LOSS [training: 0.22130167538667017 | validation: 0.3567757785549871]
	TIME [epoch: 8.42 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2426399601323078		[learning rate: 0.0016067]
	Learning Rate: 0.00160675
	LOSS [training: 0.2426399601323078 | validation: 0.35211492026222413]
	TIME [epoch: 8.41 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20862731274654864		[learning rate: 0.0016009]
	Learning Rate: 0.00160092
	LOSS [training: 0.20862731274654864 | validation: 0.29670953234744263]
	TIME [epoch: 8.41 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22850961479174847		[learning rate: 0.0015951]
	Learning Rate: 0.00159511
	LOSS [training: 0.22850961479174847 | validation: 0.33737767067472957]
	TIME [epoch: 8.44 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23378816351137216		[learning rate: 0.0015893]
	Learning Rate: 0.00158932
	LOSS [training: 0.23378816351137216 | validation: 0.36927453375167807]
	TIME [epoch: 8.41 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19287889565633132		[learning rate: 0.0015835]
	Learning Rate: 0.00158355
	LOSS [training: 0.19287889565633132 | validation: 0.23009618600575238]
	TIME [epoch: 8.42 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2506214128715383		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.2506214128715383 | validation: 0.43832260415654567]
	TIME [epoch: 8.41 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2381604633407822		[learning rate: 0.0015721]
	Learning Rate: 0.00157208
	LOSS [training: 0.2381604633407822 | validation: 0.37386667714668154]
	TIME [epoch: 8.44 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3242803755025817		[learning rate: 0.0015664]
	Learning Rate: 0.00156637
	LOSS [training: 0.3242803755025817 | validation: 0.3567608181790105]
	TIME [epoch: 8.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22449957766995082		[learning rate: 0.0015607]
	Learning Rate: 0.00156069
	LOSS [training: 0.22449957766995082 | validation: 0.2501875183807023]
	TIME [epoch: 8.41 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20599037127042785		[learning rate: 0.001555]
	Learning Rate: 0.00155502
	LOSS [training: 0.20599037127042785 | validation: 0.39646397623672835]
	TIME [epoch: 8.41 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24371729725212415		[learning rate: 0.0015494]
	Learning Rate: 0.00154938
	LOSS [training: 0.24371729725212415 | validation: 0.41794351085214587]
	TIME [epoch: 8.44 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2558871385449333		[learning rate: 0.0015438]
	Learning Rate: 0.00154376
	LOSS [training: 0.2558871385449333 | validation: 0.35703958626735144]
	TIME [epoch: 8.41 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21025156836017253		[learning rate: 0.0015382]
	Learning Rate: 0.00153815
	LOSS [training: 0.21025156836017253 | validation: 0.5951766166441868]
	TIME [epoch: 8.41 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23540478980085128		[learning rate: 0.0015326]
	Learning Rate: 0.00153257
	LOSS [training: 0.23540478980085128 | validation: 0.26865537535300665]
	TIME [epoch: 8.42 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2146128835683338		[learning rate: 0.001527]
	Learning Rate: 0.00152701
	LOSS [training: 0.2146128835683338 | validation: 0.636028543154962]
	TIME [epoch: 8.44 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2286528065508091		[learning rate: 0.0015215]
	Learning Rate: 0.00152147
	LOSS [training: 0.2286528065508091 | validation: 0.19909893307916718]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19290555029696962		[learning rate: 0.0015159]
	Learning Rate: 0.00151595
	LOSS [training: 0.19290555029696962 | validation: 0.31594240946946794]
	TIME [epoch: 8.42 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24205448482058117		[learning rate: 0.0015104]
	Learning Rate: 0.00151045
	LOSS [training: 0.24205448482058117 | validation: 0.32877486144502177]
	TIME [epoch: 8.42 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20544880227706272		[learning rate: 0.001505]
	Learning Rate: 0.00150496
	LOSS [training: 0.20544880227706272 | validation: 0.27627558069127467]
	TIME [epoch: 8.43 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2138217254308467		[learning rate: 0.0014995]
	Learning Rate: 0.0014995
	LOSS [training: 0.2138217254308467 | validation: 0.38895314925637176]
	TIME [epoch: 8.41 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22026608911509746		[learning rate: 0.0014941]
	Learning Rate: 0.00149406
	LOSS [training: 0.22026608911509746 | validation: 0.31298381951585197]
	TIME [epoch: 8.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22213379806645936		[learning rate: 0.0014886]
	Learning Rate: 0.00148864
	LOSS [training: 0.22213379806645936 | validation: 0.2281666184164526]
	TIME [epoch: 8.42 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21273009197673082		[learning rate: 0.0014832]
	Learning Rate: 0.00148324
	LOSS [training: 0.21273009197673082 | validation: 0.513702063381015]
	TIME [epoch: 8.43 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21106861439249167		[learning rate: 0.0014779]
	Learning Rate: 0.00147785
	LOSS [training: 0.21106861439249167 | validation: 0.25735304855028385]
	TIME [epoch: 8.41 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18888265853433586		[learning rate: 0.0014725]
	Learning Rate: 0.00147249
	LOSS [training: 0.18888265853433586 | validation: 0.24979724094140693]
	TIME [epoch: 8.42 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20145014247116047		[learning rate: 0.0014671]
	Learning Rate: 0.00146715
	LOSS [training: 0.20145014247116047 | validation: 0.2595533071896155]
	TIME [epoch: 8.42 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21988018303832368		[learning rate: 0.0014618]
	Learning Rate: 0.00146182
	LOSS [training: 0.21988018303832368 | validation: 0.21192143187625195]
	TIME [epoch: 8.42 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16892834958443728		[learning rate: 0.0014565]
	Learning Rate: 0.00145652
	LOSS [training: 0.16892834958443728 | validation: 0.38434351268105726]
	TIME [epoch: 8.41 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22238933297417168		[learning rate: 0.0014512]
	Learning Rate: 0.00145123
	LOSS [training: 0.22238933297417168 | validation: 0.30158563126545757]
	TIME [epoch: 8.41 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17593405782682828		[learning rate: 0.001446]
	Learning Rate: 0.00144597
	LOSS [training: 0.17593405782682828 | validation: 0.32545360700779596]
	TIME [epoch: 8.44 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21435052351413586		[learning rate: 0.0014407]
	Learning Rate: 0.00144072
	LOSS [training: 0.21435052351413586 | validation: 0.3790110625852007]
	TIME [epoch: 8.41 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24644970160307236		[learning rate: 0.0014355]
	Learning Rate: 0.00143549
	LOSS [training: 0.24644970160307236 | validation: 0.21647071086933117]
	TIME [epoch: 8.41 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18177905610574568		[learning rate: 0.0014303]
	Learning Rate: 0.00143028
	LOSS [training: 0.18177905610574568 | validation: 0.25027895613108986]
	TIME [epoch: 8.42 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18879322386923428		[learning rate: 0.0014251]
	Learning Rate: 0.00142509
	LOSS [training: 0.18879322386923428 | validation: 0.18539927279008345]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_636.pth
	Model improved!!!
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19893995339985585		[learning rate: 0.0014199]
	Learning Rate: 0.00141992
	LOSS [training: 0.19893995339985585 | validation: 0.32622077659888216]
	TIME [epoch: 8.43 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2024135817414107		[learning rate: 0.0014148]
	Learning Rate: 0.00141476
	LOSS [training: 0.2024135817414107 | validation: 0.25658655280345033]
	TIME [epoch: 8.41 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17205095765024755		[learning rate: 0.0014096]
	Learning Rate: 0.00140963
	LOSS [training: 0.17205095765024755 | validation: 0.20415785551855928]
	TIME [epoch: 8.41 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1842109305063086		[learning rate: 0.0014045]
	Learning Rate: 0.00140451
	LOSS [training: 0.1842109305063086 | validation: 0.3270873278690343]
	TIME [epoch: 8.44 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21551077909406122		[learning rate: 0.0013994]
	Learning Rate: 0.00139942
	LOSS [training: 0.21551077909406122 | validation: 0.21690971668633288]
	TIME [epoch: 8.42 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1786264200927968		[learning rate: 0.0013943]
	Learning Rate: 0.00139434
	LOSS [training: 0.1786264200927968 | validation: 0.31455511889357374]
	TIME [epoch: 8.42 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19939887153038605		[learning rate: 0.0013893]
	Learning Rate: 0.00138928
	LOSS [training: 0.19939887153038605 | validation: 0.3882758650054926]
	TIME [epoch: 8.42 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.337930805036143		[learning rate: 0.0013842]
	Learning Rate: 0.00138424
	LOSS [training: 0.337930805036143 | validation: 0.23676426418370167]
	TIME [epoch: 8.45 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18309356911729044		[learning rate: 0.0013792]
	Learning Rate: 0.00137921
	LOSS [training: 0.18309356911729044 | validation: 0.25265575733043744]
	TIME [epoch: 8.42 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17741791602478751		[learning rate: 0.0013742]
	Learning Rate: 0.00137421
	LOSS [training: 0.17741791602478751 | validation: 0.2768278069535866]
	TIME [epoch: 8.41 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17359226597805755		[learning rate: 0.0013692]
	Learning Rate: 0.00136922
	LOSS [training: 0.17359226597805755 | validation: 0.2175110739494755]
	TIME [epoch: 8.41 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1952355403891019		[learning rate: 0.0013643]
	Learning Rate: 0.00136425
	LOSS [training: 0.1952355403891019 | validation: 0.2646935651870713]
	TIME [epoch: 8.44 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2848941760994243		[learning rate: 0.0013593]
	Learning Rate: 0.0013593
	LOSS [training: 0.2848941760994243 | validation: 0.32866360870878797]
	TIME [epoch: 8.42 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21444679777659537		[learning rate: 0.0013544]
	Learning Rate: 0.00135437
	LOSS [training: 0.21444679777659537 | validation: 0.3976188587217989]
	TIME [epoch: 8.41 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1751002537013487		[learning rate: 0.0013495]
	Learning Rate: 0.00134945
	LOSS [training: 0.1751002537013487 | validation: 0.5602676621264878]
	TIME [epoch: 8.41 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2819509177053216		[learning rate: 0.0013446]
	Learning Rate: 0.00134456
	LOSS [training: 0.2819509177053216 | validation: 0.291010050926652]
	TIME [epoch: 8.45 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19817422542620305		[learning rate: 0.0013397]
	Learning Rate: 0.00133968
	LOSS [training: 0.19817422542620305 | validation: 0.35605853622114536]
	TIME [epoch: 8.42 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21548020276987961		[learning rate: 0.0013348]
	Learning Rate: 0.00133481
	LOSS [training: 0.21548020276987961 | validation: 0.22012024691417187]
	TIME [epoch: 8.42 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17830336896858562		[learning rate: 0.00133]
	Learning Rate: 0.00132997
	LOSS [training: 0.17830336896858562 | validation: 0.23647869162403146]
	TIME [epoch: 8.41 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23065905994699146		[learning rate: 0.0013251]
	Learning Rate: 0.00132514
	LOSS [training: 0.23065905994699146 | validation: 0.2720565211272316]
	TIME [epoch: 8.44 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2231461964757846		[learning rate: 0.0013203]
	Learning Rate: 0.00132034
	LOSS [training: 0.2231461964757846 | validation: 0.36024014213004696]
	TIME [epoch: 8.42 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23245294944414682		[learning rate: 0.0013155]
	Learning Rate: 0.00131554
	LOSS [training: 0.23245294944414682 | validation: 0.2939702373492892]
	TIME [epoch: 8.42 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2185056804057143		[learning rate: 0.0013108]
	Learning Rate: 0.00131077
	LOSS [training: 0.2185056804057143 | validation: 0.33067664155390697]
	TIME [epoch: 8.42 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19884828121029438		[learning rate: 0.001306]
	Learning Rate: 0.00130601
	LOSS [training: 0.19884828121029438 | validation: 0.30970998835388436]
	TIME [epoch: 8.44 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17571782593009097		[learning rate: 0.0013013]
	Learning Rate: 0.00130127
	LOSS [training: 0.17571782593009097 | validation: 0.46250680097851343]
	TIME [epoch: 8.42 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16987778425084857		[learning rate: 0.0012966]
	Learning Rate: 0.00129655
	LOSS [training: 0.16987778425084857 | validation: 0.21444772597687475]
	TIME [epoch: 8.42 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1844174617742677		[learning rate: 0.0012918]
	Learning Rate: 0.00129185
	LOSS [training: 0.1844174617742677 | validation: 0.25719136697592593]
	TIME [epoch: 8.41 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1742039070556388		[learning rate: 0.0012872]
	Learning Rate: 0.00128716
	LOSS [training: 0.1742039070556388 | validation: 0.353915607100503]
	TIME [epoch: 8.45 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21416729103530469		[learning rate: 0.0012825]
	Learning Rate: 0.00128249
	LOSS [training: 0.21416729103530469 | validation: 0.2771950101252313]
	TIME [epoch: 8.42 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1892529201246131		[learning rate: 0.0012778]
	Learning Rate: 0.00127783
	LOSS [training: 0.1892529201246131 | validation: 0.2185157232031892]
	TIME [epoch: 8.41 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1919658386465138		[learning rate: 0.0012732]
	Learning Rate: 0.00127319
	LOSS [training: 0.1919658386465138 | validation: 0.3312559724928626]
	TIME [epoch: 8.41 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23064550850909754		[learning rate: 0.0012686]
	Learning Rate: 0.00126857
	LOSS [training: 0.23064550850909754 | validation: 0.1854831369042374]
	TIME [epoch: 8.45 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2069260280534606		[learning rate: 0.001264]
	Learning Rate: 0.00126397
	LOSS [training: 0.2069260280534606 | validation: 0.6264676435392982]
	TIME [epoch: 8.42 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23141873952318845		[learning rate: 0.0012594]
	Learning Rate: 0.00125938
	LOSS [training: 0.23141873952318845 | validation: 0.2673463180293127]
	TIME [epoch: 8.42 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2073995991719529		[learning rate: 0.0012548]
	Learning Rate: 0.00125481
	LOSS [training: 0.2073995991719529 | validation: 0.30534916801870804]
	TIME [epoch: 8.42 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18192315372991044		[learning rate: 0.0012503]
	Learning Rate: 0.00125026
	LOSS [training: 0.18192315372991044 | validation: 0.4614234550588291]
	TIME [epoch: 8.44 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19927940099827407		[learning rate: 0.0012457]
	Learning Rate: 0.00124572
	LOSS [training: 0.19927940099827407 | validation: 0.2431143949013539]
	TIME [epoch: 8.42 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17419444025357667		[learning rate: 0.0012412]
	Learning Rate: 0.0012412
	LOSS [training: 0.17419444025357667 | validation: 0.33671396968781775]
	TIME [epoch: 8.41 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19291329761848636		[learning rate: 0.0012367]
	Learning Rate: 0.0012367
	LOSS [training: 0.19291329761848636 | validation: 0.3012161292209256]
	TIME [epoch: 8.41 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21195493481871502		[learning rate: 0.0012322]
	Learning Rate: 0.00123221
	LOSS [training: 0.21195493481871502 | validation: 0.22107960434998575]
	TIME [epoch: 8.44 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.196463147590682		[learning rate: 0.0012277]
	Learning Rate: 0.00122774
	LOSS [training: 0.196463147590682 | validation: 0.2416351342440486]
	TIME [epoch: 8.41 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1994191731081846		[learning rate: 0.0012233]
	Learning Rate: 0.00122328
	LOSS [training: 0.1994191731081846 | validation: 0.3405276196524841]
	TIME [epoch: 8.42 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17840408675424496		[learning rate: 0.0012188]
	Learning Rate: 0.00121884
	LOSS [training: 0.17840408675424496 | validation: 0.2630733653226929]
	TIME [epoch: 8.43 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.198439721336195		[learning rate: 0.0012144]
	Learning Rate: 0.00121442
	LOSS [training: 0.198439721336195 | validation: 0.31465388846881814]
	TIME [epoch: 8.43 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23359242309397024		[learning rate: 0.00121]
	Learning Rate: 0.00121001
	LOSS [training: 0.23359242309397024 | validation: 0.4046569894378287]
	TIME [epoch: 8.41 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20669865407107352		[learning rate: 0.0012056]
	Learning Rate: 0.00120562
	LOSS [training: 0.20669865407107352 | validation: 0.20382833779957976]
	TIME [epoch: 8.42 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15346021944177934		[learning rate: 0.0012012]
	Learning Rate: 0.00120125
	LOSS [training: 0.15346021944177934 | validation: 0.3754558916358278]
	TIME [epoch: 8.42 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20647706954050954		[learning rate: 0.0011969]
	Learning Rate: 0.00119689
	LOSS [training: 0.20647706954050954 | validation: 0.1907901087476419]
	TIME [epoch: 8.43 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16777434731196525		[learning rate: 0.0011925]
	Learning Rate: 0.00119254
	LOSS [training: 0.16777434731196525 | validation: 0.3635906936781095]
	TIME [epoch: 8.42 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2236386692867523		[learning rate: 0.0011882]
	Learning Rate: 0.00118821
	LOSS [training: 0.2236386692867523 | validation: 0.22621435293270514]
	TIME [epoch: 8.42 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1595425835990037		[learning rate: 0.0011839]
	Learning Rate: 0.0011839
	LOSS [training: 0.1595425835990037 | validation: 0.39518897140594444]
	TIME [epoch: 8.42 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2224347012227136		[learning rate: 0.0011796]
	Learning Rate: 0.00117961
	LOSS [training: 0.2224347012227136 | validation: 0.23055585167660508]
	TIME [epoch: 8.42 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18738645440744536		[learning rate: 0.0011753]
	Learning Rate: 0.00117532
	LOSS [training: 0.18738645440744536 | validation: 0.6947748979798012]
	TIME [epoch: 8.41 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2750417599648124		[learning rate: 0.0011711]
	Learning Rate: 0.00117106
	LOSS [training: 0.2750417599648124 | validation: 0.41813843905267645]
	TIME [epoch: 8.41 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20400976696116285		[learning rate: 0.0011668]
	Learning Rate: 0.00116681
	LOSS [training: 0.20400976696116285 | validation: 0.20883885483266112]
	TIME [epoch: 8.43 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19940908804888674		[learning rate: 0.0011626]
	Learning Rate: 0.00116258
	LOSS [training: 0.19940908804888674 | validation: 0.3076700685180278]
	TIME [epoch: 8.42 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16376012805896245		[learning rate: 0.0011584]
	Learning Rate: 0.00115836
	LOSS [training: 0.16376012805896245 | validation: 0.1936144993535995]
	TIME [epoch: 8.42 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2953504463746034		[learning rate: 0.0011542]
	Learning Rate: 0.00115415
	LOSS [training: 0.2953504463746034 | validation: 0.5287617261219042]
	TIME [epoch: 8.41 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19972731925820691		[learning rate: 0.00115]
	Learning Rate: 0.00114996
	LOSS [training: 0.19972731925820691 | validation: 0.3226060423073287]
	TIME [epoch: 8.43 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32587997218056286		[learning rate: 0.0011458]
	Learning Rate: 0.00114579
	LOSS [training: 0.32587997218056286 | validation: 0.25870850365628295]
	TIME [epoch: 8.42 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28032574409177197		[learning rate: 0.0011416]
	Learning Rate: 0.00114163
	LOSS [training: 0.28032574409177197 | validation: 0.2585057901396699]
	TIME [epoch: 8.41 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17136969595115498		[learning rate: 0.0011375]
	Learning Rate: 0.00113749
	LOSS [training: 0.17136969595115498 | validation: 0.3450718326759341]
	TIME [epoch: 8.41 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16631285984880897		[learning rate: 0.0011334]
	Learning Rate: 0.00113336
	LOSS [training: 0.16631285984880897 | validation: 0.3007896132771387]
	TIME [epoch: 8.44 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16380551781069677		[learning rate: 0.0011292]
	Learning Rate: 0.00112925
	LOSS [training: 0.16380551781069677 | validation: 0.3555360704842493]
	TIME [epoch: 8.41 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1626094030169003		[learning rate: 0.0011252]
	Learning Rate: 0.00112515
	LOSS [training: 0.1626094030169003 | validation: 0.20378718068837276]
	TIME [epoch: 8.41 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17869797442902952		[learning rate: 0.0011211]
	Learning Rate: 0.00112107
	LOSS [training: 0.17869797442902952 | validation: 0.3293067820921378]
	TIME [epoch: 8.4 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22079753622601728		[learning rate: 0.001117]
	Learning Rate: 0.001117
	LOSS [training: 0.22079753622601728 | validation: 0.535044542579082]
	TIME [epoch: 8.44 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19145822268005822		[learning rate: 0.0011129]
	Learning Rate: 0.00111295
	LOSS [training: 0.19145822268005822 | validation: 0.39848095499197467]
	TIME [epoch: 8.42 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21859355999161348		[learning rate: 0.0011089]
	Learning Rate: 0.00110891
	LOSS [training: 0.21859355999161348 | validation: 0.21138085728371842]
	TIME [epoch: 8.41 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18389666239060704		[learning rate: 0.0011049]
	Learning Rate: 0.00110488
	LOSS [training: 0.18389666239060704 | validation: 0.1743047997697039]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_706.pth
	Model improved!!!
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20601556395381088		[learning rate: 0.0011009]
	Learning Rate: 0.00110087
	LOSS [training: 0.20601556395381088 | validation: 0.3702262708380588]
	TIME [epoch: 8.45 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18869511820978419		[learning rate: 0.0010969]
	Learning Rate: 0.00109688
	LOSS [training: 0.18869511820978419 | validation: 0.18086783408314974]
	TIME [epoch: 8.42 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1571518495554884		[learning rate: 0.0010929]
	Learning Rate: 0.0010929
	LOSS [training: 0.1571518495554884 | validation: 0.14155700024415208]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1821572161120383		[learning rate: 0.0010889]
	Learning Rate: 0.00108893
	LOSS [training: 0.1821572161120383 | validation: 0.18791546318740526]
	TIME [epoch: 8.42 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19787697635237136		[learning rate: 0.001085]
	Learning Rate: 0.00108498
	LOSS [training: 0.19787697635237136 | validation: 0.20965566296056914]
	TIME [epoch: 8.45 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17277628221919408		[learning rate: 0.001081]
	Learning Rate: 0.00108104
	LOSS [training: 0.17277628221919408 | validation: 0.2659206821617234]
	TIME [epoch: 8.42 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17797081247793184		[learning rate: 0.0010771]
	Learning Rate: 0.00107712
	LOSS [training: 0.17797081247793184 | validation: 0.17034546696220565]
	TIME [epoch: 8.41 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17109295651475048		[learning rate: 0.0010732]
	Learning Rate: 0.00107321
	LOSS [training: 0.17109295651475048 | validation: 0.256449941102041]
	TIME [epoch: 8.41 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18664961588180207		[learning rate: 0.0010693]
	Learning Rate: 0.00106931
	LOSS [training: 0.18664961588180207 | validation: 0.16437181385677646]
	TIME [epoch: 8.45 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16694512156748426		[learning rate: 0.0010654]
	Learning Rate: 0.00106543
	LOSS [training: 0.16694512156748426 | validation: 0.39323638896858903]
	TIME [epoch: 8.41 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16099090518066275		[learning rate: 0.0010616]
	Learning Rate: 0.00106157
	LOSS [training: 0.16099090518066275 | validation: 0.2902109756685781]
	TIME [epoch: 8.42 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17931399841537124		[learning rate: 0.0010577]
	Learning Rate: 0.00105771
	LOSS [training: 0.17931399841537124 | validation: 0.18463037245880237]
	TIME [epoch: 8.41 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1688244100609511		[learning rate: 0.0010539]
	Learning Rate: 0.00105388
	LOSS [training: 0.1688244100609511 | validation: 0.21572629054992482]
	TIME [epoch: 8.45 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18283553391570195		[learning rate: 0.0010501]
	Learning Rate: 0.00105005
	LOSS [training: 0.18283553391570195 | validation: 0.1596223482997821]
	TIME [epoch: 8.41 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1481753250399121		[learning rate: 0.0010462]
	Learning Rate: 0.00104624
	LOSS [training: 0.1481753250399121 | validation: 0.16680915051886935]
	TIME [epoch: 8.42 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17810662513809689		[learning rate: 0.0010424]
	Learning Rate: 0.00104244
	LOSS [training: 0.17810662513809689 | validation: 0.2771683646880335]
	TIME [epoch: 8.42 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16104404010934853		[learning rate: 0.0010387]
	Learning Rate: 0.00103866
	LOSS [training: 0.16104404010934853 | validation: 0.21183521645232234]
	TIME [epoch: 8.44 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19025749012077098		[learning rate: 0.0010349]
	Learning Rate: 0.00103489
	LOSS [training: 0.19025749012077098 | validation: 0.19128113570054653]
	TIME [epoch: 8.41 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15641467210084745		[learning rate: 0.0010311]
	Learning Rate: 0.00103114
	LOSS [training: 0.15641467210084745 | validation: 0.23095893716267626]
	TIME [epoch: 8.42 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18779634081565424		[learning rate: 0.0010274]
	Learning Rate: 0.00102739
	LOSS [training: 0.18779634081565424 | validation: 0.2166470201964102]
	TIME [epoch: 8.42 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1594503126049332		[learning rate: 0.0010237]
	Learning Rate: 0.00102367
	LOSS [training: 0.1594503126049332 | validation: 0.2831032471483894]
	TIME [epoch: 8.45 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18601841642024014		[learning rate: 0.00102]
	Learning Rate: 0.00101995
	LOSS [training: 0.18601841642024014 | validation: 0.1580178734126658]
	TIME [epoch: 8.42 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15863475601108062		[learning rate: 0.0010162]
	Learning Rate: 0.00101625
	LOSS [training: 0.15863475601108062 | validation: 0.1751749075638065]
	TIME [epoch: 8.42 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18647936843695725		[learning rate: 0.0010126]
	Learning Rate: 0.00101256
	LOSS [training: 0.18647936843695725 | validation: 0.25060454952859035]
	TIME [epoch: 8.43 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18262596871510617		[learning rate: 0.0010089]
	Learning Rate: 0.00100889
	LOSS [training: 0.18262596871510617 | validation: 0.32999175128590597]
	TIME [epoch: 8.43 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2001514885351044		[learning rate: 0.0010052]
	Learning Rate: 0.00100522
	LOSS [training: 0.2001514885351044 | validation: 0.20805545193503783]
	TIME [epoch: 8.42 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15913268265346903		[learning rate: 0.0010016]
	Learning Rate: 0.00100158
	LOSS [training: 0.15913268265346903 | validation: 0.1996531662908175]
	TIME [epoch: 8.42 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20969683112941634		[learning rate: 0.00099794]
	Learning Rate: 0.000997942
	LOSS [training: 0.20969683112941634 | validation: 0.2104511814766062]
	TIME [epoch: 8.43 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16307850005112617		[learning rate: 0.00099432]
	Learning Rate: 0.00099432
	LOSS [training: 0.16307850005112617 | validation: 0.1802996318023234]
	TIME [epoch: 8.44 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1685788505620028		[learning rate: 0.00099071]
	Learning Rate: 0.000990712
	LOSS [training: 0.1685788505620028 | validation: 0.18445357444254104]
	TIME [epoch: 8.42 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14383185898835885		[learning rate: 0.00098712]
	Learning Rate: 0.000987116
	LOSS [training: 0.14383185898835885 | validation: 0.2065448863504335]
	TIME [epoch: 8.42 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18779785508816713		[learning rate: 0.00098353]
	Learning Rate: 0.000983534
	LOSS [training: 0.18779785508816713 | validation: 0.2796584669054669]
	TIME [epoch: 8.43 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1651114644022266		[learning rate: 0.00097996]
	Learning Rate: 0.000979965
	LOSS [training: 0.1651114644022266 | validation: 0.2120399948336701]
	TIME [epoch: 8.44 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1534835481540865		[learning rate: 0.00097641]
	Learning Rate: 0.000976409
	LOSS [training: 0.1534835481540865 | validation: 0.2791094731760717]
	TIME [epoch: 8.42 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16940489147742838		[learning rate: 0.00097287]
	Learning Rate: 0.000972865
	LOSS [training: 0.16940489147742838 | validation: 0.31291208853831787]
	TIME [epoch: 8.42 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25382087250458996		[learning rate: 0.00096933]
	Learning Rate: 0.000969335
	LOSS [training: 0.25382087250458996 | validation: 0.294815570962095]
	TIME [epoch: 8.43 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15288732322098086		[learning rate: 0.00096582]
	Learning Rate: 0.000965817
	LOSS [training: 0.15288732322098086 | validation: 0.23116727732109893]
	TIME [epoch: 8.43 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16456050306214703		[learning rate: 0.00096231]
	Learning Rate: 0.000962312
	LOSS [training: 0.16456050306214703 | validation: 0.21704213671701444]
	TIME [epoch: 8.42 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1952073611525963		[learning rate: 0.00095882]
	Learning Rate: 0.00095882
	LOSS [training: 0.1952073611525963 | validation: 0.18240784513509123]
	TIME [epoch: 8.42 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12811673682757702		[learning rate: 0.00095534]
	Learning Rate: 0.00095534
	LOSS [training: 0.12811673682757702 | validation: 0.17815615758282635]
	TIME [epoch: 8.44 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1467821712132275		[learning rate: 0.00095187]
	Learning Rate: 0.000951873
	LOSS [training: 0.1467821712132275 | validation: 0.16408628440624468]
	TIME [epoch: 8.42 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17124757352052516		[learning rate: 0.00094842]
	Learning Rate: 0.000948419
	LOSS [training: 0.17124757352052516 | validation: 0.36798954679038864]
	TIME [epoch: 8.42 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17278312737901938		[learning rate: 0.00094498]
	Learning Rate: 0.000944977
	LOSS [training: 0.17278312737901938 | validation: 0.22590944401094365]
	TIME [epoch: 8.42 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1514670564143456		[learning rate: 0.00094155]
	Learning Rate: 0.000941547
	LOSS [training: 0.1514670564143456 | validation: 0.2220318269516855]
	TIME [epoch: 8.44 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.163068568457151		[learning rate: 0.00093813]
	Learning Rate: 0.00093813
	LOSS [training: 0.163068568457151 | validation: 0.33975553355030497]
	TIME [epoch: 8.42 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1509455956817172		[learning rate: 0.00093473]
	Learning Rate: 0.000934726
	LOSS [training: 0.1509455956817172 | validation: 0.23566397934551733]
	TIME [epoch: 8.42 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3756942398462809		[learning rate: 0.00093133]
	Learning Rate: 0.000931334
	LOSS [training: 0.3756942398462809 | validation: 0.24373091448722456]
	TIME [epoch: 8.42 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1320553937333748		[learning rate: 0.00092795]
	Learning Rate: 0.000927954
	LOSS [training: 0.1320553937333748 | validation: 0.23057812380625725]
	TIME [epoch: 8.44 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14972573972662562		[learning rate: 0.00092459]
	Learning Rate: 0.000924586
	LOSS [training: 0.14972573972662562 | validation: 0.2541378887292379]
	TIME [epoch: 8.42 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17047385907894874		[learning rate: 0.00092123]
	Learning Rate: 0.000921231
	LOSS [training: 0.17047385907894874 | validation: 0.2579109411229016]
	TIME [epoch: 8.42 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13805208162328308		[learning rate: 0.00091789]
	Learning Rate: 0.000917888
	LOSS [training: 0.13805208162328308 | validation: 0.1914339602300542]
	TIME [epoch: 8.41 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15642088904513501		[learning rate: 0.00091456]
	Learning Rate: 0.000914556
	LOSS [training: 0.15642088904513501 | validation: 0.2047790896041016]
	TIME [epoch: 8.44 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1737649660619006		[learning rate: 0.00091124]
	Learning Rate: 0.000911237
	LOSS [training: 0.1737649660619006 | validation: 0.237253816396513]
	TIME [epoch: 8.42 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15353520327457354		[learning rate: 0.00090793]
	Learning Rate: 0.000907931
	LOSS [training: 0.15353520327457354 | validation: 0.22607940348257496]
	TIME [epoch: 8.42 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15993397827766626		[learning rate: 0.00090464]
	Learning Rate: 0.000904636
	LOSS [training: 0.15993397827766626 | validation: 0.18406214401695065]
	TIME [epoch: 8.42 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13861146143950281		[learning rate: 0.00090135]
	Learning Rate: 0.000901353
	LOSS [training: 0.13861146143950281 | validation: 0.21706004432821646]
	TIME [epoch: 8.45 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18894100655743387		[learning rate: 0.00089808]
	Learning Rate: 0.000898082
	LOSS [training: 0.18894100655743387 | validation: 0.25912936947795673]
	TIME [epoch: 8.43 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14689451567166442		[learning rate: 0.00089482]
	Learning Rate: 0.000894822
	LOSS [training: 0.14689451567166442 | validation: 0.16769831745589533]
	TIME [epoch: 8.42 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16426281170174614		[learning rate: 0.00089157]
	Learning Rate: 0.000891575
	LOSS [training: 0.16426281170174614 | validation: 0.22229261650368665]
	TIME [epoch: 8.42 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.147823255988098		[learning rate: 0.00088834]
	Learning Rate: 0.000888339
	LOSS [training: 0.147823255988098 | validation: 0.20380644551806762]
	TIME [epoch: 8.45 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1446864549673716		[learning rate: 0.00088512]
	Learning Rate: 0.000885116
	LOSS [training: 0.1446864549673716 | validation: 0.25472640570234606]
	TIME [epoch: 8.42 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17377161428435067		[learning rate: 0.0008819]
	Learning Rate: 0.000881903
	LOSS [training: 0.17377161428435067 | validation: 0.3094613929577148]
	TIME [epoch: 8.42 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15187984200866064		[learning rate: 0.0008787]
	Learning Rate: 0.000878703
	LOSS [training: 0.15187984200866064 | validation: 0.2606412819129659]
	TIME [epoch: 8.42 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16287008761923655		[learning rate: 0.00087551]
	Learning Rate: 0.000875514
	LOSS [training: 0.16287008761923655 | validation: 0.19508776469148437]
	TIME [epoch: 8.45 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13334850777158722		[learning rate: 0.00087234]
	Learning Rate: 0.000872337
	LOSS [training: 0.13334850777158722 | validation: 0.1598509389435044]
	TIME [epoch: 8.42 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13941270360845326		[learning rate: 0.00086917]
	Learning Rate: 0.000869171
	LOSS [training: 0.13941270360845326 | validation: 0.22977095861995445]
	TIME [epoch: 8.42 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15356472041671063		[learning rate: 0.00086602]
	Learning Rate: 0.000866017
	LOSS [training: 0.15356472041671063 | validation: 0.18608857814575674]
	TIME [epoch: 8.42 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1461237536170054		[learning rate: 0.00086287]
	Learning Rate: 0.000862874
	LOSS [training: 0.1461237536170054 | validation: 0.17610835374111644]
	TIME [epoch: 8.45 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12597102781783903		[learning rate: 0.00085974]
	Learning Rate: 0.000859743
	LOSS [training: 0.12597102781783903 | validation: 0.16067360235345277]
	TIME [epoch: 8.42 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14324751014358758		[learning rate: 0.00085662]
	Learning Rate: 0.000856623
	LOSS [training: 0.14324751014358758 | validation: 0.17935222640581322]
	TIME [epoch: 8.42 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14084069113450556		[learning rate: 0.00085351]
	Learning Rate: 0.000853514
	LOSS [training: 0.14084069113450556 | validation: 0.2532475044303876]
	TIME [epoch: 8.42 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15595702155379734		[learning rate: 0.00085042]
	Learning Rate: 0.000850416
	LOSS [training: 0.15595702155379734 | validation: 0.391637242491214]
	TIME [epoch: 8.45 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16913392450051284		[learning rate: 0.00084733]
	Learning Rate: 0.00084733
	LOSS [training: 0.16913392450051284 | validation: 0.17549314162735158]
	TIME [epoch: 8.42 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1315089209340242		[learning rate: 0.00084426]
	Learning Rate: 0.000844255
	LOSS [training: 0.1315089209340242 | validation: 0.28211505456004066]
	TIME [epoch: 8.42 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1501240566093411		[learning rate: 0.00084119]
	Learning Rate: 0.000841191
	LOSS [training: 0.1501240566093411 | validation: 0.21912421716278338]
	TIME [epoch: 8.42 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15964201150591742		[learning rate: 0.00083814]
	Learning Rate: 0.000838139
	LOSS [training: 0.15964201150591742 | validation: 0.30817105542278794]
	TIME [epoch: 8.45 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13736067847201175		[learning rate: 0.0008351]
	Learning Rate: 0.000835097
	LOSS [training: 0.13736067847201175 | validation: 0.246775954928036]
	TIME [epoch: 8.42 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.162658403635624		[learning rate: 0.00083207]
	Learning Rate: 0.000832066
	LOSS [training: 0.162658403635624 | validation: 0.24291005572240099]
	TIME [epoch: 8.42 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15037434468477057		[learning rate: 0.00082905]
	Learning Rate: 0.000829046
	LOSS [training: 0.15037434468477057 | validation: 0.24278383435580803]
	TIME [epoch: 8.43 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1520444520776218		[learning rate: 0.00082604]
	Learning Rate: 0.000826038
	LOSS [training: 0.1520444520776218 | validation: 0.28425341462945186]
	TIME [epoch: 8.45 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19364960272539758		[learning rate: 0.00082304]
	Learning Rate: 0.00082304
	LOSS [training: 0.19364960272539758 | validation: 0.3021759378277121]
	TIME [epoch: 8.42 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14480704610849487		[learning rate: 0.00082005]
	Learning Rate: 0.000820053
	LOSS [training: 0.14480704610849487 | validation: 0.17451365434592309]
	TIME [epoch: 8.42 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13436851048967205		[learning rate: 0.00081708]
	Learning Rate: 0.000817077
	LOSS [training: 0.13436851048967205 | validation: 0.21424523716083796]
	TIME [epoch: 8.43 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12596996506845776		[learning rate: 0.00081411]
	Learning Rate: 0.000814112
	LOSS [training: 0.12596996506845776 | validation: 0.26553526798198124]
	TIME [epoch: 8.44 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12930036734604947		[learning rate: 0.00081116]
	Learning Rate: 0.000811158
	LOSS [training: 0.12930036734604947 | validation: 0.38831945080577523]
	TIME [epoch: 8.42 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15039705292203634		[learning rate: 0.00080821]
	Learning Rate: 0.000808214
	LOSS [training: 0.15039705292203634 | validation: 0.16295579550713102]
	TIME [epoch: 8.42 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13928336398904279		[learning rate: 0.00080528]
	Learning Rate: 0.000805281
	LOSS [training: 0.13928336398904279 | validation: 0.15895671481581441]
	TIME [epoch: 8.44 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2048705353032451		[learning rate: 0.00080236]
	Learning Rate: 0.000802358
	LOSS [training: 0.2048705353032451 | validation: 0.14233266049474097]
	TIME [epoch: 8.44 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1310151227852912		[learning rate: 0.00079945]
	Learning Rate: 0.000799447
	LOSS [training: 0.1310151227852912 | validation: 0.2321044652089043]
	TIME [epoch: 8.42 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14797078101420877		[learning rate: 0.00079655]
	Learning Rate: 0.000796545
	LOSS [training: 0.14797078101420877 | validation: 0.20981197421596828]
	TIME [epoch: 8.42 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1353429258360624		[learning rate: 0.00079365]
	Learning Rate: 0.000793655
	LOSS [training: 0.1353429258360624 | validation: 0.2417743386916179]
	TIME [epoch: 8.44 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.149216039714191		[learning rate: 0.00079077]
	Learning Rate: 0.000790775
	LOSS [training: 0.149216039714191 | validation: 0.2585825427012832]
	TIME [epoch: 8.43 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14435540610843395		[learning rate: 0.0007879]
	Learning Rate: 0.000787905
	LOSS [training: 0.14435540610843395 | validation: 0.1911479888538592]
	TIME [epoch: 8.43 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15258267187824542		[learning rate: 0.00078505]
	Learning Rate: 0.000785045
	LOSS [training: 0.15258267187824542 | validation: 0.34593056247084075]
	TIME [epoch: 8.42 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23186618082119798		[learning rate: 0.0007822]
	Learning Rate: 0.000782196
	LOSS [training: 0.23186618082119798 | validation: 0.23475565215052052]
	TIME [epoch: 8.43 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14475550717307945		[learning rate: 0.00077936]
	Learning Rate: 0.000779358
	LOSS [training: 0.14475550717307945 | validation: 0.17897846820980406]
	TIME [epoch: 8.43 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17807340930942844		[learning rate: 0.00077653]
	Learning Rate: 0.000776529
	LOSS [training: 0.17807340930942844 | validation: 0.2180505271846459]
	TIME [epoch: 8.42 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257497027063354		[learning rate: 0.00077371]
	Learning Rate: 0.000773711
	LOSS [training: 0.1257497027063354 | validation: 0.16857289255275287]
	TIME [epoch: 8.42 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1412091948426502		[learning rate: 0.0007709]
	Learning Rate: 0.000770903
	LOSS [training: 0.1412091948426502 | validation: 0.22469731106559743]
	TIME [epoch: 8.44 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15359602970307598		[learning rate: 0.00076811]
	Learning Rate: 0.000768106
	LOSS [training: 0.15359602970307598 | validation: 0.14713208721608506]
	TIME [epoch: 8.43 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13227513069702562		[learning rate: 0.00076532]
	Learning Rate: 0.000765318
	LOSS [training: 0.13227513069702562 | validation: 0.16986990662115503]
	TIME [epoch: 8.42 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12743756504681586		[learning rate: 0.00076254]
	Learning Rate: 0.000762541
	LOSS [training: 0.12743756504681586 | validation: 0.16293799985708696]
	TIME [epoch: 8.42 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1355581228670553		[learning rate: 0.00075977]
	Learning Rate: 0.000759774
	LOSS [training: 0.1355581228670553 | validation: 0.1203198178201342]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_809.pth
	Model improved!!!
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1615874967591424		[learning rate: 0.00075702]
	Learning Rate: 0.000757016
	LOSS [training: 0.1615874967591424 | validation: 0.1695610404303516]
	TIME [epoch: 8.42 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19485627075034245		[learning rate: 0.00075427]
	Learning Rate: 0.000754269
	LOSS [training: 0.19485627075034245 | validation: 0.3715240162148316]
	TIME [epoch: 8.42 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19526638377597222		[learning rate: 0.00075153]
	Learning Rate: 0.000751532
	LOSS [training: 0.19526638377597222 | validation: 0.1510521524886062]
	TIME [epoch: 8.42 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18498680364617515		[learning rate: 0.0007488]
	Learning Rate: 0.000748804
	LOSS [training: 0.18498680364617515 | validation: 0.1422395838142626]
	TIME [epoch: 8.44 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21019497107517343		[learning rate: 0.00074609]
	Learning Rate: 0.000746087
	LOSS [training: 0.21019497107517343 | validation: 0.19557575943312647]
	TIME [epoch: 8.42 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2518517214907214		[learning rate: 0.00074338]
	Learning Rate: 0.000743379
	LOSS [training: 0.2518517214907214 | validation: 0.14792499120350255]
	TIME [epoch: 8.41 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14469102689091926		[learning rate: 0.00074068]
	Learning Rate: 0.000740682
	LOSS [training: 0.14469102689091926 | validation: 0.1710356138363338]
	TIME [epoch: 8.42 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1313605227975257		[learning rate: 0.00073799]
	Learning Rate: 0.000737994
	LOSS [training: 0.1313605227975257 | validation: 0.12801028933902348]
	TIME [epoch: 8.44 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14088578031329552		[learning rate: 0.00073532]
	Learning Rate: 0.000735315
	LOSS [training: 0.14088578031329552 | validation: 0.1633157227434136]
	TIME [epoch: 8.42 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14298428745606567		[learning rate: 0.00073265]
	Learning Rate: 0.000732647
	LOSS [training: 0.14298428745606567 | validation: 0.18021243922843144]
	TIME [epoch: 8.42 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15039402112314776		[learning rate: 0.00072999]
	Learning Rate: 0.000729988
	LOSS [training: 0.15039402112314776 | validation: 0.15111012195889173]
	TIME [epoch: 8.42 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19357753932665797		[learning rate: 0.00072734]
	Learning Rate: 0.000727339
	LOSS [training: 0.19357753932665797 | validation: 0.1775668022711117]
	TIME [epoch: 8.44 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1287713056827154		[learning rate: 0.0007247]
	Learning Rate: 0.000724699
	LOSS [training: 0.1287713056827154 | validation: 0.13989787986669688]
	TIME [epoch: 8.42 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13908652563813007		[learning rate: 0.00072207]
	Learning Rate: 0.000722069
	LOSS [training: 0.13908652563813007 | validation: 0.2631959340114367]
	TIME [epoch: 8.42 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12146318566030889		[learning rate: 0.00071945]
	Learning Rate: 0.000719449
	LOSS [training: 0.12146318566030889 | validation: 0.13830954774039855]
	TIME [epoch: 8.41 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11371843239137618		[learning rate: 0.00071684]
	Learning Rate: 0.000716838
	LOSS [training: 0.11371843239137618 | validation: 0.19332401080031542]
	TIME [epoch: 8.44 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23827214292403293		[learning rate: 0.00071424]
	Learning Rate: 0.000714237
	LOSS [training: 0.23827214292403293 | validation: 0.15775597769870042]
	TIME [epoch: 8.42 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12498162325817926		[learning rate: 0.00071164]
	Learning Rate: 0.000711645
	LOSS [training: 0.12498162325817926 | validation: 0.22587649207636157]
	TIME [epoch: 8.41 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12620044386194418		[learning rate: 0.00070906]
	Learning Rate: 0.000709062
	LOSS [training: 0.12620044386194418 | validation: 0.12301790326438276]
	TIME [epoch: 8.42 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13608977709579959		[learning rate: 0.00070649]
	Learning Rate: 0.000706489
	LOSS [training: 0.13608977709579959 | validation: 0.15198206172050793]
	TIME [epoch: 8.44 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14855487114204827		[learning rate: 0.00070392]
	Learning Rate: 0.000703925
	LOSS [training: 0.14855487114204827 | validation: 0.19334313876734]
	TIME [epoch: 8.41 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1379073628950431		[learning rate: 0.00070137]
	Learning Rate: 0.00070137
	LOSS [training: 0.1379073628950431 | validation: 0.20149093252804756]
	TIME [epoch: 8.42 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16807106769027785		[learning rate: 0.00069883]
	Learning Rate: 0.000698825
	LOSS [training: 0.16807106769027785 | validation: 0.17373245698898965]
	TIME [epoch: 8.41 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1353041926432729		[learning rate: 0.00069629]
	Learning Rate: 0.000696289
	LOSS [training: 0.1353041926432729 | validation: 0.19335426242661738]
	TIME [epoch: 8.44 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16335719218485079		[learning rate: 0.00069376]
	Learning Rate: 0.000693762
	LOSS [training: 0.16335719218485079 | validation: 0.18569713072775862]
	TIME [epoch: 8.41 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11989764149161959		[learning rate: 0.00069124]
	Learning Rate: 0.000691244
	LOSS [training: 0.11989764149161959 | validation: 0.18231019860350484]
	TIME [epoch: 8.41 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1235029894315736		[learning rate: 0.00068874]
	Learning Rate: 0.000688736
	LOSS [training: 0.1235029894315736 | validation: 0.18774609861700742]
	TIME [epoch: 8.41 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13163940519497705		[learning rate: 0.00068624]
	Learning Rate: 0.000686236
	LOSS [training: 0.13163940519497705 | validation: 0.16606080802144962]
	TIME [epoch: 8.44 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12512155581588397		[learning rate: 0.00068375]
	Learning Rate: 0.000683746
	LOSS [training: 0.12512155581588397 | validation: 0.13284892866799303]
	TIME [epoch: 8.42 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16993919594654563		[learning rate: 0.00068126]
	Learning Rate: 0.000681265
	LOSS [training: 0.16993919594654563 | validation: 0.21535081087027907]
	TIME [epoch: 8.41 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15160915494802238		[learning rate: 0.00067879]
	Learning Rate: 0.000678792
	LOSS [training: 0.15160915494802238 | validation: 0.1569785217502923]
	TIME [epoch: 8.42 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18300971975973926		[learning rate: 0.00067633]
	Learning Rate: 0.000676329
	LOSS [training: 0.18300971975973926 | validation: 0.2699367008349494]
	TIME [epoch: 8.44 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1305553822184888		[learning rate: 0.00067387]
	Learning Rate: 0.000673874
	LOSS [training: 0.1305553822184888 | validation: 0.14651487493604026]
	TIME [epoch: 8.41 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1269552013716503		[learning rate: 0.00067143]
	Learning Rate: 0.000671429
	LOSS [training: 0.1269552013716503 | validation: 0.1546235372894972]
	TIME [epoch: 8.41 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11582104147007588		[learning rate: 0.00066899]
	Learning Rate: 0.000668992
	LOSS [training: 0.11582104147007588 | validation: 0.1278114270204951]
	TIME [epoch: 8.42 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1349048871089068		[learning rate: 0.00066656]
	Learning Rate: 0.000666564
	LOSS [training: 0.1349048871089068 | validation: 0.2062887938935277]
	TIME [epoch: 8.45 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10775273182250131		[learning rate: 0.00066415]
	Learning Rate: 0.000664145
	LOSS [training: 0.10775273182250131 | validation: 0.18924573941994213]
	TIME [epoch: 8.41 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14441973493267835		[learning rate: 0.00066174]
	Learning Rate: 0.000661735
	LOSS [training: 0.14441973493267835 | validation: 0.14805097707706766]
	TIME [epoch: 8.42 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14861076140844082		[learning rate: 0.00065933]
	Learning Rate: 0.000659334
	LOSS [training: 0.14861076140844082 | validation: 0.1613461482879105]
	TIME [epoch: 8.43 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10735288010012412		[learning rate: 0.00065694]
	Learning Rate: 0.000656941
	LOSS [training: 0.10735288010012412 | validation: 0.2811689107594773]
	TIME [epoch: 8.43 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1402842298867208		[learning rate: 0.00065456]
	Learning Rate: 0.000654557
	LOSS [training: 0.1402842298867208 | validation: 0.14766294633819804]
	TIME [epoch: 8.41 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1302821924436644		[learning rate: 0.00065218]
	Learning Rate: 0.000652182
	LOSS [training: 0.1302821924436644 | validation: 0.16494729378951786]
	TIME [epoch: 8.42 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12513852318576563		[learning rate: 0.00064981]
	Learning Rate: 0.000649815
	LOSS [training: 0.12513852318576563 | validation: 0.20563634362482158]
	TIME [epoch: 8.42 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11989044866421313		[learning rate: 0.00064746]
	Learning Rate: 0.000647456
	LOSS [training: 0.11989044866421313 | validation: 0.2838869487085352]
	TIME [epoch: 8.44 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13491988165799265		[learning rate: 0.00064511]
	Learning Rate: 0.000645107
	LOSS [training: 0.13491988165799265 | validation: 0.16048075355143354]
	TIME [epoch: 8.42 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11483642385514263		[learning rate: 0.00064277]
	Learning Rate: 0.000642766
	LOSS [training: 0.11483642385514263 | validation: 0.11587500929908134]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_855.pth
	Model improved!!!
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12253510765515548		[learning rate: 0.00064043]
	Learning Rate: 0.000640433
	LOSS [training: 0.12253510765515548 | validation: 0.2103894400850809]
	TIME [epoch: 8.45 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14925041955125384		[learning rate: 0.00063811]
	Learning Rate: 0.000638109
	LOSS [training: 0.14925041955125384 | validation: 0.1536374330689838]
	TIME [epoch: 8.42 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1346736703211265		[learning rate: 0.00063579]
	Learning Rate: 0.000635793
	LOSS [training: 0.1346736703211265 | validation: 0.33191809483743334]
	TIME [epoch: 8.42 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15929449061525042		[learning rate: 0.00063349]
	Learning Rate: 0.000633486
	LOSS [training: 0.15929449061525042 | validation: 0.17649926986608883]
	TIME [epoch: 8.42 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18405469090834486		[learning rate: 0.00063119]
	Learning Rate: 0.000631187
	LOSS [training: 0.18405469090834486 | validation: 0.1258962640475103]
	TIME [epoch: 8.44 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10039599527084864		[learning rate: 0.0006289]
	Learning Rate: 0.000628896
	LOSS [training: 0.10039599527084864 | validation: 0.14304311249398746]
	TIME [epoch: 8.42 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14304182888379624		[learning rate: 0.00062661]
	Learning Rate: 0.000626614
	LOSS [training: 0.14304182888379624 | validation: 0.21811663434888437]
	TIME [epoch: 8.41 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10632652627510539		[learning rate: 0.00062434]
	Learning Rate: 0.00062434
	LOSS [training: 0.10632652627510539 | validation: 0.18057397765587177]
	TIME [epoch: 8.42 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14311966126732695		[learning rate: 0.00062207]
	Learning Rate: 0.000622074
	LOSS [training: 0.14311966126732695 | validation: 0.16199476299673637]
	TIME [epoch: 8.44 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11321430723417827		[learning rate: 0.00061982]
	Learning Rate: 0.000619816
	LOSS [training: 0.11321430723417827 | validation: 0.2340908589724412]
	TIME [epoch: 8.42 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12449826118101044		[learning rate: 0.00061757]
	Learning Rate: 0.000617567
	LOSS [training: 0.12449826118101044 | validation: 0.14694385048960107]
	TIME [epoch: 8.42 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11406163461291692		[learning rate: 0.00061533]
	Learning Rate: 0.000615326
	LOSS [training: 0.11406163461291692 | validation: 0.15441306713779177]
	TIME [epoch: 8.42 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12504468519242146		[learning rate: 0.00061309]
	Learning Rate: 0.000613093
	LOSS [training: 0.12504468519242146 | validation: 0.24430631151535787]
	TIME [epoch: 8.44 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11981877966434369		[learning rate: 0.00061087]
	Learning Rate: 0.000610868
	LOSS [training: 0.11981877966434369 | validation: 0.14910526759876627]
	TIME [epoch: 8.42 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.131754102059279		[learning rate: 0.00060865]
	Learning Rate: 0.000608651
	LOSS [training: 0.131754102059279 | validation: 0.20848199646914167]
	TIME [epoch: 8.42 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11330241038495456		[learning rate: 0.00060644]
	Learning Rate: 0.000606442
	LOSS [training: 0.11330241038495456 | validation: 0.16145591400888654]
	TIME [epoch: 8.42 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11968293281228012		[learning rate: 0.00060424]
	Learning Rate: 0.000604242
	LOSS [training: 0.11968293281228012 | validation: 0.18469914234616305]
	TIME [epoch: 8.43 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11436367771722462		[learning rate: 0.00060205]
	Learning Rate: 0.000602049
	LOSS [training: 0.11436367771722462 | validation: 0.14735648223351291]
	TIME [epoch: 8.42 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11970714107061035		[learning rate: 0.00059986]
	Learning Rate: 0.000599864
	LOSS [training: 0.11970714107061035 | validation: 0.20909223244265537]
	TIME [epoch: 8.41 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12502573609738815		[learning rate: 0.00059769]
	Learning Rate: 0.000597687
	LOSS [training: 0.12502573609738815 | validation: 0.1342511184031448]
	TIME [epoch: 8.42 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12750508285510018		[learning rate: 0.00059552]
	Learning Rate: 0.000595518
	LOSS [training: 0.12750508285510018 | validation: 0.17530401691530265]
	TIME [epoch: 8.45 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10636360341120474		[learning rate: 0.00059336]
	Learning Rate: 0.000593357
	LOSS [training: 0.10636360341120474 | validation: 0.12473478941332564]
	TIME [epoch: 8.42 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11301924437001035		[learning rate: 0.0005912]
	Learning Rate: 0.000591203
	LOSS [training: 0.11301924437001035 | validation: 0.3137395638221695]
	TIME [epoch: 8.42 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12775253828166597		[learning rate: 0.00058906]
	Learning Rate: 0.000589058
	LOSS [training: 0.12775253828166597 | validation: 0.19147973058589046]
	TIME [epoch: 8.41 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12491736060494066		[learning rate: 0.00058692]
	Learning Rate: 0.00058692
	LOSS [training: 0.12491736060494066 | validation: 0.1304436808877917]
	TIME [epoch: 8.44 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1250064703791636		[learning rate: 0.00058479]
	Learning Rate: 0.00058479
	LOSS [training: 0.1250064703791636 | validation: 0.10419286022403461]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_881.pth
	Model improved!!!
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12268237564306353		[learning rate: 0.00058267]
	Learning Rate: 0.000582668
	LOSS [training: 0.12268237564306353 | validation: 0.21820998283153678]
	TIME [epoch: 8.42 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13499350115412814		[learning rate: 0.00058055]
	Learning Rate: 0.000580553
	LOSS [training: 0.13499350115412814 | validation: 0.15321922574515304]
	TIME [epoch: 8.41 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12238545648243444		[learning rate: 0.00057845]
	Learning Rate: 0.000578446
	LOSS [training: 0.12238545648243444 | validation: 0.20310862432387988]
	TIME [epoch: 8.44 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12422203388505122		[learning rate: 0.00057635]
	Learning Rate: 0.000576347
	LOSS [training: 0.12422203388505122 | validation: 0.1509682503362343]
	TIME [epoch: 8.41 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12763004558753416		[learning rate: 0.00057426]
	Learning Rate: 0.000574256
	LOSS [training: 0.12763004558753416 | validation: 0.18871169730950382]
	TIME [epoch: 8.41 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15302753122662907		[learning rate: 0.00057217]
	Learning Rate: 0.000572172
	LOSS [training: 0.15302753122662907 | validation: 0.1956564695313921]
	TIME [epoch: 8.41 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.119938646568124		[learning rate: 0.0005701]
	Learning Rate: 0.000570095
	LOSS [training: 0.119938646568124 | validation: 0.17380670139326349]
	TIME [epoch: 8.43 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10805050202983928		[learning rate: 0.00056803]
	Learning Rate: 0.000568026
	LOSS [training: 0.10805050202983928 | validation: 0.14313727247308014]
	TIME [epoch: 8.41 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10808725938959847		[learning rate: 0.00056596]
	Learning Rate: 0.000565965
	LOSS [training: 0.10808725938959847 | validation: 0.20251270778349928]
	TIME [epoch: 8.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12066696223185422		[learning rate: 0.00056391]
	Learning Rate: 0.000563911
	LOSS [training: 0.12066696223185422 | validation: 0.14968069693658773]
	TIME [epoch: 8.41 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10750972053810756		[learning rate: 0.00056186]
	Learning Rate: 0.000561864
	LOSS [training: 0.10750972053810756 | validation: 0.21171337922953798]
	TIME [epoch: 8.43 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1528515680607907		[learning rate: 0.00055983]
	Learning Rate: 0.000559825
	LOSS [training: 0.1528515680607907 | validation: 0.12405771825218648]
	TIME [epoch: 8.42 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1422869858405667		[learning rate: 0.00055779]
	Learning Rate: 0.000557794
	LOSS [training: 0.1422869858405667 | validation: 0.16265510985945597]
	TIME [epoch: 8.41 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10583893644281013		[learning rate: 0.00055577]
	Learning Rate: 0.00055577
	LOSS [training: 0.10583893644281013 | validation: 0.13846340094589293]
	TIME [epoch: 8.41 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14564794249115326		[learning rate: 0.00055375]
	Learning Rate: 0.000553753
	LOSS [training: 0.14564794249115326 | validation: 0.14087343156397444]
	TIME [epoch: 8.43 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17233826115803758		[learning rate: 0.00055174]
	Learning Rate: 0.000551743
	LOSS [training: 0.17233826115803758 | validation: 0.17621725786228665]
	TIME [epoch: 8.41 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17824605211294414		[learning rate: 0.00054974]
	Learning Rate: 0.000549741
	LOSS [training: 0.17824605211294414 | validation: 0.17330580048943756]
	TIME [epoch: 8.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1541971508624403		[learning rate: 0.00054775]
	Learning Rate: 0.000547746
	LOSS [training: 0.1541971508624403 | validation: 0.14894489606993172]
	TIME [epoch: 8.43 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14285355908447905		[learning rate: 0.00054576]
	Learning Rate: 0.000545758
	LOSS [training: 0.14285355908447905 | validation: 0.09226240448081041]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_900.pth
	Model improved!!!
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09400543054753488		[learning rate: 0.00054378]
	Learning Rate: 0.000543777
	LOSS [training: 0.09400543054753488 | validation: 0.1950377125546441]
	TIME [epoch: 8.42 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13345545075262835		[learning rate: 0.0005418]
	Learning Rate: 0.000541804
	LOSS [training: 0.13345545075262835 | validation: 0.12498861825231716]
	TIME [epoch: 8.4 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1097044946876203		[learning rate: 0.00053984]
	Learning Rate: 0.000539838
	LOSS [training: 0.1097044946876203 | validation: 0.26004370813437416]
	TIME [epoch: 8.41 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13856796646927563		[learning rate: 0.00053788]
	Learning Rate: 0.000537879
	LOSS [training: 0.13856796646927563 | validation: 0.1495737589679283]
	TIME [epoch: 8.42 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1412961483524498		[learning rate: 0.00053593]
	Learning Rate: 0.000535926
	LOSS [training: 0.1412961483524498 | validation: 0.1433022468456597]
	TIME [epoch: 8.4 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11236429811789066		[learning rate: 0.00053398]
	Learning Rate: 0.000533982
	LOSS [training: 0.11236429811789066 | validation: 0.1346263333545768]
	TIME [epoch: 8.41 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1121753391981446		[learning rate: 0.00053204]
	Learning Rate: 0.000532044
	LOSS [training: 0.1121753391981446 | validation: 0.27620164667728925]
	TIME [epoch: 8.41 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12347135044606421		[learning rate: 0.00053011]
	Learning Rate: 0.000530113
	LOSS [training: 0.12347135044606421 | validation: 0.15097651062062667]
	TIME [epoch: 8.41 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1429352987767443		[learning rate: 0.00052819]
	Learning Rate: 0.000528189
	LOSS [training: 0.1429352987767443 | validation: 0.17724704902662813]
	TIME [epoch: 8.41 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10500165727326946		[learning rate: 0.00052627]
	Learning Rate: 0.000526272
	LOSS [training: 0.10500165727326946 | validation: 0.10800316055022283]
	TIME [epoch: 8.4 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11438035040432623		[learning rate: 0.00052436]
	Learning Rate: 0.000524362
	LOSS [training: 0.11438035040432623 | validation: 0.19184001462901568]
	TIME [epoch: 8.43 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11080359273765898		[learning rate: 0.00052246]
	Learning Rate: 0.00052246
	LOSS [training: 0.11080359273765898 | validation: 0.11630400458152736]
	TIME [epoch: 8.41 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13321736849929688		[learning rate: 0.00052056]
	Learning Rate: 0.000520563
	LOSS [training: 0.13321736849929688 | validation: 0.14547832512129502]
	TIME [epoch: 8.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11116073844374612		[learning rate: 0.00051867]
	Learning Rate: 0.000518674
	LOSS [training: 0.11116073844374612 | validation: 0.15444754795475732]
	TIME [epoch: 8.41 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13068019598928493		[learning rate: 0.00051679]
	Learning Rate: 0.000516792
	LOSS [training: 0.13068019598928493 | validation: 0.12170007926067075]
	TIME [epoch: 8.42 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20167115369798627		[learning rate: 0.00051492]
	Learning Rate: 0.000514917
	LOSS [training: 0.20167115369798627 | validation: 0.14012459835868898]
	TIME [epoch: 8.41 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12048115308838041		[learning rate: 0.00051305]
	Learning Rate: 0.000513048
	LOSS [training: 0.12048115308838041 | validation: 0.18994631428565564]
	TIME [epoch: 8.41 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12136925563604792		[learning rate: 0.00051119]
	Learning Rate: 0.000511186
	LOSS [training: 0.12136925563604792 | validation: 0.17438026817287916]
	TIME [epoch: 8.41 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1144991092411988		[learning rate: 0.00050933]
	Learning Rate: 0.000509331
	LOSS [training: 0.1144991092411988 | validation: 0.11872002732345999]
	TIME [epoch: 8.43 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09404024267966977		[learning rate: 0.00050748]
	Learning Rate: 0.000507483
	LOSS [training: 0.09404024267966977 | validation: 0.1188397842386598]
	TIME [epoch: 8.41 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13207849199868932		[learning rate: 0.00050564]
	Learning Rate: 0.000505641
	LOSS [training: 0.13207849199868932 | validation: 0.10497421879020949]
	TIME [epoch: 8.41 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09674792868571407		[learning rate: 0.00050381]
	Learning Rate: 0.000503806
	LOSS [training: 0.09674792868571407 | validation: 0.11249651418989756]
	TIME [epoch: 8.41 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11079394903379265		[learning rate: 0.00050198]
	Learning Rate: 0.000501977
	LOSS [training: 0.11079394903379265 | validation: 0.12081107990602437]
	TIME [epoch: 8.43 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09824322875229997		[learning rate: 0.00050016]
	Learning Rate: 0.000500156
	LOSS [training: 0.09824322875229997 | validation: 0.16515343047940098]
	TIME [epoch: 8.42 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22741113017895637		[learning rate: 0.00049834]
	Learning Rate: 0.000498341
	LOSS [training: 0.22741113017895637 | validation: 0.10894754538434942]
	TIME [epoch: 8.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2875821806657378		[learning rate: 0.00049653]
	Learning Rate: 0.000496532
	LOSS [training: 0.2875821806657378 | validation: 0.10952861400054609]
	TIME [epoch: 8.41 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14851508951148853		[learning rate: 0.00049473]
	Learning Rate: 0.00049473
	LOSS [training: 0.14851508951148853 | validation: 0.13465717041178654]
	TIME [epoch: 8.42 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10675219209967446		[learning rate: 0.00049293]
	Learning Rate: 0.000492935
	LOSS [training: 0.10675219209967446 | validation: 0.2120177023419792]
	TIME [epoch: 8.41 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10010642008395228		[learning rate: 0.00049115]
	Learning Rate: 0.000491146
	LOSS [training: 0.10010642008395228 | validation: 0.0996214940162666]
	TIME [epoch: 8.41 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12125729386692721		[learning rate: 0.00048936]
	Learning Rate: 0.000489364
	LOSS [training: 0.12125729386692721 | validation: 0.11800132754611573]
	TIME [epoch: 8.41 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1022096296921905		[learning rate: 0.00048759]
	Learning Rate: 0.000487588
	LOSS [training: 0.1022096296921905 | validation: 0.13460635312770763]
	TIME [epoch: 8.43 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1530938643673734		[learning rate: 0.00048582]
	Learning Rate: 0.000485818
	LOSS [training: 0.1530938643673734 | validation: 0.14237543890377857]
	TIME [epoch: 8.42 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10142771340320919		[learning rate: 0.00048406]
	Learning Rate: 0.000484055
	LOSS [training: 0.10142771340320919 | validation: 0.12306008562880213]
	TIME [epoch: 8.41 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10340613938947123		[learning rate: 0.0004823]
	Learning Rate: 0.000482298
	LOSS [training: 0.10340613938947123 | validation: 0.11327418065068659]
	TIME [epoch: 8.41 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17759112085711354		[learning rate: 0.00048055]
	Learning Rate: 0.000480548
	LOSS [training: 0.17759112085711354 | validation: 0.11107007767788182]
	TIME [epoch: 8.43 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18187166672985558		[learning rate: 0.0004788]
	Learning Rate: 0.000478804
	LOSS [training: 0.18187166672985558 | validation: 0.1778732845812963]
	TIME [epoch: 8.41 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10920481658404638		[learning rate: 0.00047707]
	Learning Rate: 0.000477067
	LOSS [training: 0.10920481658404638 | validation: 0.15567446546210342]
	TIME [epoch: 8.42 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10725295701044017		[learning rate: 0.00047534]
	Learning Rate: 0.000475335
	LOSS [training: 0.10725295701044017 | validation: 0.11309457519253335]
	TIME [epoch: 8.41 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1284541402055888		[learning rate: 0.00047361]
	Learning Rate: 0.00047361
	LOSS [training: 0.1284541402055888 | validation: 0.11790221275169818]
	TIME [epoch: 8.44 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13523058755485678		[learning rate: 0.00047189]
	Learning Rate: 0.000471891
	LOSS [training: 0.13523058755485678 | validation: 0.15909466529113167]
	TIME [epoch: 8.41 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11963526378956106		[learning rate: 0.00047018]
	Learning Rate: 0.000470179
	LOSS [training: 0.11963526378956106 | validation: 0.09831196174768328]
	TIME [epoch: 8.41 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1466921439390902		[learning rate: 0.00046847]
	Learning Rate: 0.000468473
	LOSS [training: 0.1466921439390902 | validation: 0.10051068721345154]
	TIME [epoch: 8.41 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12374709231085608		[learning rate: 0.00046677]
	Learning Rate: 0.000466773
	LOSS [training: 0.12374709231085608 | validation: 0.1629210614497221]
	TIME [epoch: 8.43 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1525554153612863		[learning rate: 0.00046508]
	Learning Rate: 0.000465079
	LOSS [training: 0.1525554153612863 | validation: 0.13677211869758982]
	TIME [epoch: 8.41 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1258908147634035		[learning rate: 0.00046339]
	Learning Rate: 0.000463391
	LOSS [training: 0.1258908147634035 | validation: 0.30259430856045266]
	TIME [epoch: 8.41 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11655909154769825		[learning rate: 0.00046171]
	Learning Rate: 0.000461709
	LOSS [training: 0.11655909154769825 | validation: 0.15972125859362934]
	TIME [epoch: 8.41 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12035422942472881		[learning rate: 0.00046003]
	Learning Rate: 0.000460034
	LOSS [training: 0.12035422942472881 | validation: 0.16741764443708684]
	TIME [epoch: 8.44 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11021748770463739		[learning rate: 0.00045836]
	Learning Rate: 0.000458364
	LOSS [training: 0.11021748770463739 | validation: 0.1900962423304765]
	TIME [epoch: 8.41 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1645757446657205		[learning rate: 0.0004567]
	Learning Rate: 0.000456701
	LOSS [training: 0.1645757446657205 | validation: 0.16752631062649886]
	TIME [epoch: 8.41 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11547081092589717		[learning rate: 0.00045504]
	Learning Rate: 0.000455043
	LOSS [training: 0.11547081092589717 | validation: 0.14993807313706495]
	TIME [epoch: 8.41 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10720395186091278		[learning rate: 0.00045339]
	Learning Rate: 0.000453392
	LOSS [training: 0.10720395186091278 | validation: 0.17916819191289896]
	TIME [epoch: 8.43 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09995026988921443		[learning rate: 0.00045175]
	Learning Rate: 0.000451746
	LOSS [training: 0.09995026988921443 | validation: 0.11778917502017794]
	TIME [epoch: 8.41 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11231062267167316		[learning rate: 0.00045011]
	Learning Rate: 0.000450107
	LOSS [training: 0.11231062267167316 | validation: 0.16999084696925654]
	TIME [epoch: 8.42 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10375828399496205		[learning rate: 0.00044847]
	Learning Rate: 0.000448474
	LOSS [training: 0.10375828399496205 | validation: 0.16178174800303233]
	TIME [epoch: 8.41 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10108404154550413		[learning rate: 0.00044685]
	Learning Rate: 0.000446846
	LOSS [training: 0.10108404154550413 | validation: 0.16653847578154085]
	TIME [epoch: 8.43 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11766849236913705		[learning rate: 0.00044522]
	Learning Rate: 0.000445224
	LOSS [training: 0.11766849236913705 | validation: 0.17290475645517978]
	TIME [epoch: 8.4 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10233732663999007		[learning rate: 0.00044361]
	Learning Rate: 0.000443609
	LOSS [training: 0.10233732663999007 | validation: 0.1174887243470624]
	TIME [epoch: 8.41 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0986804419273255		[learning rate: 0.000442]
	Learning Rate: 0.000441999
	LOSS [training: 0.0986804419273255 | validation: 0.18824150632799475]
	TIME [epoch: 8.41 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10559059859005042		[learning rate: 0.00044039]
	Learning Rate: 0.000440395
	LOSS [training: 0.10559059859005042 | validation: 0.13667777547689064]
	TIME [epoch: 8.42 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12714906116894295		[learning rate: 0.0004388]
	Learning Rate: 0.000438797
	LOSS [training: 0.12714906116894295 | validation: 0.19330468779198576]
	TIME [epoch: 8.4 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14027049531336605		[learning rate: 0.0004372]
	Learning Rate: 0.000437204
	LOSS [training: 0.14027049531336605 | validation: 0.11468649516424648]
	TIME [epoch: 8.41 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10662370467931259		[learning rate: 0.00043562]
	Learning Rate: 0.000435617
	LOSS [training: 0.10662370467931259 | validation: 0.1803635960017566]
	TIME [epoch: 8.42 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12510909798780825		[learning rate: 0.00043404]
	Learning Rate: 0.000434037
	LOSS [training: 0.12510909798780825 | validation: 0.11118588888767456]
	TIME [epoch: 8.43 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11540421494864919		[learning rate: 0.00043246]
	Learning Rate: 0.000432461
	LOSS [training: 0.11540421494864919 | validation: 0.15617216131391903]
	TIME [epoch: 8.42 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1155540001360688		[learning rate: 0.00043089]
	Learning Rate: 0.000430892
	LOSS [training: 0.1155540001360688 | validation: 0.1396468256616443]
	TIME [epoch: 8.4 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11675359780477271		[learning rate: 0.00042933]
	Learning Rate: 0.000429328
	LOSS [training: 0.11675359780477271 | validation: 0.23901661928207896]
	TIME [epoch: 8.42 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12778525628241733		[learning rate: 0.00042777]
	Learning Rate: 0.00042777
	LOSS [training: 0.12778525628241733 | validation: 0.12758607303921896]
	TIME [epoch: 8.42 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11242607953573251		[learning rate: 0.00042622]
	Learning Rate: 0.000426218
	LOSS [training: 0.11242607953573251 | validation: 0.15621010284758416]
	TIME [epoch: 8.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0988207957565522		[learning rate: 0.00042467]
	Learning Rate: 0.000424671
	LOSS [training: 0.0988207957565522 | validation: 0.1390502129639145]
	TIME [epoch: 8.41 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10062285528843909		[learning rate: 0.00042313]
	Learning Rate: 0.00042313
	LOSS [training: 0.10062285528843909 | validation: 0.1574092805137375]
	TIME [epoch: 8.41 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1264766483918766		[learning rate: 0.00042159]
	Learning Rate: 0.000421594
	LOSS [training: 0.1264766483918766 | validation: 0.22229238020598235]
	TIME [epoch: 8.43 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16449695355934107		[learning rate: 0.00042006]
	Learning Rate: 0.000420064
	LOSS [training: 0.16449695355934107 | validation: 0.17931068873454598]
	TIME [epoch: 8.41 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11463669102561976		[learning rate: 0.00041854]
	Learning Rate: 0.00041854
	LOSS [training: 0.11463669102561976 | validation: 0.1301532750594914]
	TIME [epoch: 8.41 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09481813392699376		[learning rate: 0.00041702]
	Learning Rate: 0.000417021
	LOSS [training: 0.09481813392699376 | validation: 0.19616420692316944]
	TIME [epoch: 8.43 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10132699762000083		[learning rate: 0.00041551]
	Learning Rate: 0.000415508
	LOSS [training: 0.10132699762000083 | validation: 0.11503138821988523]
	TIME [epoch: 8.41 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11809654239930749		[learning rate: 0.000414]
	Learning Rate: 0.000414
	LOSS [training: 0.11809654239930749 | validation: 0.11713108469876773]
	TIME [epoch: 8.41 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09011290196596537		[learning rate: 0.0004125]
	Learning Rate: 0.000412497
	LOSS [training: 0.09011290196596537 | validation: 0.17812514989240327]
	TIME [epoch: 8.41 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10427067865041664		[learning rate: 0.000411]
	Learning Rate: 0.000411
	LOSS [training: 0.10427067865041664 | validation: 0.20823112713191377]
	TIME [epoch: 8.42 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12572811649843724		[learning rate: 0.00040951]
	Learning Rate: 0.000409509
	LOSS [training: 0.12572811649843724 | validation: 0.14216213503422398]
	TIME [epoch: 8.41 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08195865213936136		[learning rate: 0.00040802]
	Learning Rate: 0.000408023
	LOSS [training: 0.08195865213936136 | validation: 0.12291835930029582]
	TIME [epoch: 8.41 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09646450091294297		[learning rate: 0.00040654]
	Learning Rate: 0.000406542
	LOSS [training: 0.09646450091294297 | validation: 0.19689019664238355]
	TIME [epoch: 8.41 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1300484727159375		[learning rate: 0.00040507]
	Learning Rate: 0.000405067
	LOSS [training: 0.1300484727159375 | validation: 0.10281868108691503]
	TIME [epoch: 8.44 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11951274263363873		[learning rate: 0.0004036]
	Learning Rate: 0.000403597
	LOSS [training: 0.11951274263363873 | validation: 0.1086579749665802]
	TIME [epoch: 8.41 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11456470081764761		[learning rate: 0.00040213]
	Learning Rate: 0.000402132
	LOSS [training: 0.11456470081764761 | validation: 0.10479012315211247]
	TIME [epoch: 8.41 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12094509994013318		[learning rate: 0.00040067]
	Learning Rate: 0.000400672
	LOSS [training: 0.12094509994013318 | validation: 0.1518938449425495]
	TIME [epoch: 8.41 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09924421869344563		[learning rate: 0.00039922]
	Learning Rate: 0.000399218
	LOSS [training: 0.09924421869344563 | validation: 0.1443768861923675]
	TIME [epoch: 8.43 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10759969483533975		[learning rate: 0.00039777]
	Learning Rate: 0.00039777
	LOSS [training: 0.10759969483533975 | validation: 0.15370779689566136]
	TIME [epoch: 8.43 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0899476480682551		[learning rate: 0.00039633]
	Learning Rate: 0.000396326
	LOSS [training: 0.0899476480682551 | validation: 0.11083803302044734]
	TIME [epoch: 8.41 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09790202414357549		[learning rate: 0.00039489]
	Learning Rate: 0.000394888
	LOSS [training: 0.09790202414357549 | validation: 0.12582200560626686]
	TIME [epoch: 8.41 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07940040842093862		[learning rate: 0.00039345]
	Learning Rate: 0.000393455
	LOSS [training: 0.07940040842093862 | validation: 0.09880077192137103]
	TIME [epoch: 8.44 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11719787053949733		[learning rate: 0.00039203]
	Learning Rate: 0.000392027
	LOSS [training: 0.11719787053949733 | validation: 0.11991068615446246]
	TIME [epoch: 8.43 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10638368308755368		[learning rate: 0.0003906]
	Learning Rate: 0.000390604
	LOSS [training: 0.10638368308755368 | validation: 0.193328267638465]
	TIME [epoch: 8.42 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10503291344033225		[learning rate: 0.00038919]
	Learning Rate: 0.000389187
	LOSS [training: 0.10503291344033225 | validation: 0.16758455082783374]
	TIME [epoch: 8.41 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11134465245951239		[learning rate: 0.00038777]
	Learning Rate: 0.000387774
	LOSS [training: 0.11134465245951239 | validation: 0.13362196552490158]
	TIME [epoch: 8.44 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09187922273491089		[learning rate: 0.00038637]
	Learning Rate: 0.000386367
	LOSS [training: 0.09187922273491089 | validation: 0.1113328918679293]
	TIME [epoch: 8.41 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10509822010742906		[learning rate: 0.00038496]
	Learning Rate: 0.000384965
	LOSS [training: 0.10509822010742906 | validation: 0.1142027796637067]
	TIME [epoch: 8.41 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09944235227084652		[learning rate: 0.00038357]
	Learning Rate: 0.000383568
	LOSS [training: 0.09944235227084652 | validation: 0.16587463976818229]
	TIME [epoch: 8.41 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0920185795206978		[learning rate: 0.00038218]
	Learning Rate: 0.000382176
	LOSS [training: 0.0920185795206978 | validation: 0.11458004209159225]
	TIME [epoch: 8.43 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09482577472704498		[learning rate: 0.00038079]
	Learning Rate: 0.000380789
	LOSS [training: 0.09482577472704498 | validation: 0.13396903671973542]
	TIME [epoch: 8.42 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10675626886440064		[learning rate: 0.00037941]
	Learning Rate: 0.000379407
	LOSS [training: 0.10675626886440064 | validation: 0.20831756901715853]
	TIME [epoch: 8.41 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10185697181281617		[learning rate: 0.00037803]
	Learning Rate: 0.00037803
	LOSS [training: 0.10185697181281617 | validation: 0.10328051239869065]
	TIME [epoch: 8.42 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12434130778564259		[learning rate: 0.00037666]
	Learning Rate: 0.000376658
	LOSS [training: 0.12434130778564259 | validation: 0.1273698496528101]
	TIME [epoch: 8.44 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11277220321205088		[learning rate: 0.00037529]
	Learning Rate: 0.000375291
	LOSS [training: 0.11277220321205088 | validation: 0.15910385121864545]
	TIME [epoch: 8.42 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0860422135971414		[learning rate: 0.00037393]
	Learning Rate: 0.000373929
	LOSS [training: 0.0860422135971414 | validation: 0.14064611896510507]
	TIME [epoch: 8.42 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11119606763098948		[learning rate: 0.00037257]
	Learning Rate: 0.000372572
	LOSS [training: 0.11119606763098948 | validation: 0.14895691726291443]
	TIME [epoch: 8.41 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0805862216811939		[learning rate: 0.00037122]
	Learning Rate: 0.00037122
	LOSS [training: 0.0805862216811939 | validation: 0.11765202866978144]
	TIME [epoch: 8.44 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12566039380409236		[learning rate: 0.00036987]
	Learning Rate: 0.000369873
	LOSS [training: 0.12566039380409236 | validation: 0.12414869254190933]
	TIME [epoch: 8.41 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0945558580003413		[learning rate: 0.00036853]
	Learning Rate: 0.000368531
	LOSS [training: 0.0945558580003413 | validation: 0.14522947336260567]
	TIME [epoch: 8.42 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1009137837211598		[learning rate: 0.00036719]
	Learning Rate: 0.000367193
	LOSS [training: 0.1009137837211598 | validation: 0.1046027765973703]
	TIME [epoch: 8.41 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10838000659044951		[learning rate: 0.00036586]
	Learning Rate: 0.000365861
	LOSS [training: 0.10838000659044951 | validation: 0.1542166960143186]
	TIME [epoch: 8.44 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08958071368298029		[learning rate: 0.00036453]
	Learning Rate: 0.000364533
	LOSS [training: 0.08958071368298029 | validation: 0.11265845138873558]
	TIME [epoch: 8.41 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13338777600860335		[learning rate: 0.00036321]
	Learning Rate: 0.00036321
	LOSS [training: 0.13338777600860335 | validation: 0.11410845500030348]
	TIME [epoch: 8.42 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09176216929790823		[learning rate: 0.00036189]
	Learning Rate: 0.000361892
	LOSS [training: 0.09176216929790823 | validation: 0.11758442376917974]
	TIME [epoch: 8.41 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09421785885531375		[learning rate: 0.00036058]
	Learning Rate: 0.000360579
	LOSS [training: 0.09421785885531375 | validation: 0.11165071971974139]
	TIME [epoch: 8.43 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09174005204416066		[learning rate: 0.00035927]
	Learning Rate: 0.00035927
	LOSS [training: 0.09174005204416066 | validation: 0.14545558464681965]
	TIME [epoch: 8.42 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1291723865030916		[learning rate: 0.00035797]
	Learning Rate: 0.000357966
	LOSS [training: 0.1291723865030916 | validation: 0.25848544349132707]
	TIME [epoch: 8.41 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1922465136400861		[learning rate: 0.00035667]
	Learning Rate: 0.000356667
	LOSS [training: 0.1922465136400861 | validation: 0.11736195226185919]
	TIME [epoch: 8.42 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16891770465230446		[learning rate: 0.00035537]
	Learning Rate: 0.000355373
	LOSS [training: 0.16891770465230446 | validation: 0.2261758114256397]
	TIME [epoch: 8.43 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12865574768346594		[learning rate: 0.00035408]
	Learning Rate: 0.000354083
	LOSS [training: 0.12865574768346594 | validation: 0.10713037302660877]
	TIME [epoch: 8.41 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20293263761664337		[learning rate: 0.0003528]
	Learning Rate: 0.000352798
	LOSS [training: 0.20293263761664337 | validation: 0.18386567333757292]
	TIME [epoch: 8.4 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14384813155705664		[learning rate: 0.00035152]
	Learning Rate: 0.000351518
	LOSS [training: 0.14384813155705664 | validation: 0.08285608168791292]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_1021.pth
	Model improved!!!
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1046702134093068		[learning rate: 0.00035024]
	Learning Rate: 0.000350242
	LOSS [training: 0.1046702134093068 | validation: 0.0941160422538817]
	TIME [epoch: 8.43 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10165867962834238		[learning rate: 0.00034897]
	Learning Rate: 0.000348971
	LOSS [training: 0.10165867962834238 | validation: 0.15958101789646087]
	TIME [epoch: 8.41 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09699484344150477		[learning rate: 0.0003477]
	Learning Rate: 0.000347705
	LOSS [training: 0.09699484344150477 | validation: 0.1329738227599664]
	TIME [epoch: 8.41 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11786435124093167		[learning rate: 0.00034644]
	Learning Rate: 0.000346443
	LOSS [training: 0.11786435124093167 | validation: 0.12729353810658142]
	TIME [epoch: 8.41 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09671108795396884		[learning rate: 0.00034519]
	Learning Rate: 0.000345186
	LOSS [training: 0.09671108795396884 | validation: 0.12278774002687545]
	TIME [epoch: 8.43 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10953613952677428		[learning rate: 0.00034393]
	Learning Rate: 0.000343933
	LOSS [training: 0.10953613952677428 | validation: 0.215208574411491]
	TIME [epoch: 8.4 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12405583518903307		[learning rate: 0.00034268]
	Learning Rate: 0.000342685
	LOSS [training: 0.12405583518903307 | validation: 0.1252494147662042]
	TIME [epoch: 8.41 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09329884317468658		[learning rate: 0.00034144]
	Learning Rate: 0.000341441
	LOSS [training: 0.09329884317468658 | validation: 0.13506299085205375]
	TIME [epoch: 8.43 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09687756416426105		[learning rate: 0.0003402]
	Learning Rate: 0.000340202
	LOSS [training: 0.09687756416426105 | validation: 0.16779508656925418]
	TIME [epoch: 8.42 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1029999126942525		[learning rate: 0.00033897]
	Learning Rate: 0.000338967
	LOSS [training: 0.1029999126942525 | validation: 0.15966182338572435]
	TIME [epoch: 8.41 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08459607785313508		[learning rate: 0.00033774]
	Learning Rate: 0.000337737
	LOSS [training: 0.08459607785313508 | validation: 0.1195117369702692]
	TIME [epoch: 8.41 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09423170583525978		[learning rate: 0.00033651]
	Learning Rate: 0.000336512
	LOSS [training: 0.09423170583525978 | validation: 0.17257113944524544]
	TIME [epoch: 8.43 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12698124773685202		[learning rate: 0.00033529]
	Learning Rate: 0.00033529
	LOSS [training: 0.12698124773685202 | validation: 0.13310351090248185]
	TIME [epoch: 8.4 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11124907742750663		[learning rate: 0.00033407]
	Learning Rate: 0.000334074
	LOSS [training: 0.11124907742750663 | validation: 0.12686162863435924]
	TIME [epoch: 8.41 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11397648789373671		[learning rate: 0.00033286]
	Learning Rate: 0.000332861
	LOSS [training: 0.11397648789373671 | validation: 0.09044398151608679]
	TIME [epoch: 8.41 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13541729642208084		[learning rate: 0.00033165]
	Learning Rate: 0.000331653
	LOSS [training: 0.13541729642208084 | validation: 0.08167506057842627]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_1037.pth
	Model improved!!!
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0887443546297213		[learning rate: 0.00033045]
	Learning Rate: 0.00033045
	LOSS [training: 0.0887443546297213 | validation: 0.23067074254820263]
	TIME [epoch: 8.43 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1239028698618968		[learning rate: 0.00032925]
	Learning Rate: 0.00032925
	LOSS [training: 0.1239028698618968 | validation: 0.14037152590412244]
	TIME [epoch: 8.41 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08874303540866213		[learning rate: 0.00032806]
	Learning Rate: 0.000328056
	LOSS [training: 0.08874303540866213 | validation: 0.13705417293111744]
	TIME [epoch: 8.4 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09954628884536691		[learning rate: 0.00032686]
	Learning Rate: 0.000326865
	LOSS [training: 0.09954628884536691 | validation: 0.13564117107230428]
	TIME [epoch: 8.43 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09482786070783432		[learning rate: 0.00032568]
	Learning Rate: 0.000325679
	LOSS [training: 0.09482786070783432 | validation: 0.1263342517714125]
	TIME [epoch: 8.42 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09725721764513577		[learning rate: 0.0003245]
	Learning Rate: 0.000324497
	LOSS [training: 0.09725721764513577 | validation: 0.156003580421758]
	TIME [epoch: 8.41 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1122654545040019		[learning rate: 0.00032332]
	Learning Rate: 0.000323319
	LOSS [training: 0.1122654545040019 | validation: 0.14600859934564148]
	TIME [epoch: 8.42 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09247036993233586		[learning rate: 0.00032215]
	Learning Rate: 0.000322146
	LOSS [training: 0.09247036993233586 | validation: 0.12023637672886833]
	TIME [epoch: 8.43 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09192755549395557		[learning rate: 0.00032098]
	Learning Rate: 0.000320977
	LOSS [training: 0.09192755549395557 | validation: 0.16062945330222775]
	TIME [epoch: 8.41 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09295413455261449		[learning rate: 0.00031981]
	Learning Rate: 0.000319812
	LOSS [training: 0.09295413455261449 | validation: 0.14185221570959217]
	TIME [epoch: 8.42 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09722739595057157		[learning rate: 0.00031865]
	Learning Rate: 0.000318651
	LOSS [training: 0.09722739595057157 | validation: 0.14940975480127378]
	TIME [epoch: 8.41 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10525732296545609		[learning rate: 0.0003175]
	Learning Rate: 0.000317495
	LOSS [training: 0.10525732296545609 | validation: 0.11178533846461919]
	TIME [epoch: 8.44 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10047176232219021		[learning rate: 0.00031634]
	Learning Rate: 0.000316343
	LOSS [training: 0.10047176232219021 | validation: 0.15789210572558976]
	TIME [epoch: 8.42 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10313349415785085		[learning rate: 0.00031519]
	Learning Rate: 0.000315195
	LOSS [training: 0.10313349415785085 | validation: 0.23261453715435892]
	TIME [epoch: 8.41 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1038542876411804		[learning rate: 0.00031405]
	Learning Rate: 0.000314051
	LOSS [training: 0.1038542876411804 | validation: 0.15726963244357656]
	TIME [epoch: 8.41 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09419809538884759		[learning rate: 0.00031291]
	Learning Rate: 0.000312911
	LOSS [training: 0.09419809538884759 | validation: 0.09176563631922166]
	TIME [epoch: 8.43 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10882237037848219		[learning rate: 0.00031178]
	Learning Rate: 0.000311776
	LOSS [training: 0.10882237037848219 | validation: 0.14644379220213088]
	TIME [epoch: 8.4 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12915727831063722		[learning rate: 0.00031064]
	Learning Rate: 0.000310644
	LOSS [training: 0.12915727831063722 | validation: 0.08267344787893596]
	TIME [epoch: 8.41 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2336836940021064		[learning rate: 0.00030952]
	Learning Rate: 0.000309517
	LOSS [training: 0.2336836940021064 | validation: 0.2888409890242336]
	TIME [epoch: 8.41 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21919769086266108		[learning rate: 0.00030839]
	Learning Rate: 0.000308394
	LOSS [training: 0.21919769086266108 | validation: 0.13538035688777034]
	TIME [epoch: 8.43 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21104398071503677		[learning rate: 0.00030727]
	Learning Rate: 0.000307274
	LOSS [training: 0.21104398071503677 | validation: 0.15443684617846987]
	TIME [epoch: 8.41 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11580288567748462		[learning rate: 0.00030616]
	Learning Rate: 0.000306159
	LOSS [training: 0.11580288567748462 | validation: 0.12098272069846432]
	TIME [epoch: 8.41 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09468439483502408		[learning rate: 0.00030505]
	Learning Rate: 0.000305048
	LOSS [training: 0.09468439483502408 | validation: 0.11148032044192235]
	TIME [epoch: 8.4 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08497891239937787		[learning rate: 0.00030394]
	Learning Rate: 0.000303941
	LOSS [training: 0.08497891239937787 | validation: 0.11443468411624727]
	TIME [epoch: 8.43 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08178779904082274		[learning rate: 0.00030284]
	Learning Rate: 0.000302838
	LOSS [training: 0.08178779904082274 | validation: 0.07966815179445713]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_1062.pth
	Model improved!!!
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0813034461223641		[learning rate: 0.00030174]
	Learning Rate: 0.000301739
	LOSS [training: 0.0813034461223641 | validation: 0.14863077293474652]
	TIME [epoch: 8.42 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10631290951400445		[learning rate: 0.00030064]
	Learning Rate: 0.000300644
	LOSS [training: 0.10631290951400445 | validation: 0.13046285782931052]
	TIME [epoch: 8.41 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14878595966614477		[learning rate: 0.00029955]
	Learning Rate: 0.000299553
	LOSS [training: 0.14878595966614477 | validation: 0.15133464205852726]
	TIME [epoch: 8.43 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09788268355204258		[learning rate: 0.00029847]
	Learning Rate: 0.000298466
	LOSS [training: 0.09788268355204258 | validation: 0.10585739307945782]
	TIME [epoch: 8.41 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0954495438324561		[learning rate: 0.00029738]
	Learning Rate: 0.000297383
	LOSS [training: 0.0954495438324561 | validation: 0.1439567841196614]
	TIME [epoch: 8.41 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11538359362151177		[learning rate: 0.0002963]
	Learning Rate: 0.000296304
	LOSS [training: 0.11538359362151177 | validation: 0.24770293537955065]
	TIME [epoch: 8.4 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12366993748155804		[learning rate: 0.00029523]
	Learning Rate: 0.000295228
	LOSS [training: 0.12366993748155804 | validation: 0.12689519612704234]
	TIME [epoch: 8.43 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09739851764092258		[learning rate: 0.00029416]
	Learning Rate: 0.000294157
	LOSS [training: 0.09739851764092258 | validation: 0.10141104953638931]
	TIME [epoch: 8.41 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08126287310426232		[learning rate: 0.00029309]
	Learning Rate: 0.000293089
	LOSS [training: 0.08126287310426232 | validation: 0.11862993776897685]
	TIME [epoch: 8.4 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10018755444692315		[learning rate: 0.00029203]
	Learning Rate: 0.000292026
	LOSS [training: 0.10018755444692315 | validation: 0.128508779660786]
	TIME [epoch: 8.42 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08778119938649039		[learning rate: 0.00029097]
	Learning Rate: 0.000290966
	LOSS [training: 0.08778119938649039 | validation: 0.1729059206346953]
	TIME [epoch: 8.43 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10022225935841626		[learning rate: 0.00028991]
	Learning Rate: 0.00028991
	LOSS [training: 0.10022225935841626 | validation: 0.13132506281262207]
	TIME [epoch: 8.41 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09223001692396755		[learning rate: 0.00028886]
	Learning Rate: 0.000288858
	LOSS [training: 0.09223001692396755 | validation: 0.09942455741304376]
	TIME [epoch: 8.41 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08656654822649319		[learning rate: 0.00028781]
	Learning Rate: 0.00028781
	LOSS [training: 0.08656654822649319 | validation: 0.17494796852583877]
	TIME [epoch: 8.42 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09897787165721361		[learning rate: 0.00028677]
	Learning Rate: 0.000286765
	LOSS [training: 0.09897787165721361 | validation: 0.11678269552542939]
	TIME [epoch: 8.43 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08395615941806374		[learning rate: 0.00028572]
	Learning Rate: 0.000285724
	LOSS [training: 0.08395615941806374 | validation: 0.13695895954724896]
	TIME [epoch: 8.41 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08771345368698602		[learning rate: 0.00028469]
	Learning Rate: 0.000284688
	LOSS [training: 0.08771345368698602 | validation: 0.1373486164174685]
	TIME [epoch: 8.41 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08554866733649955		[learning rate: 0.00028365]
	Learning Rate: 0.000283654
	LOSS [training: 0.08554866733649955 | validation: 0.08598494753392802]
	TIME [epoch: 8.42 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09111321098938382		[learning rate: 0.00028263]
	Learning Rate: 0.000282625
	LOSS [training: 0.09111321098938382 | validation: 0.1319629306229364]
	TIME [epoch: 8.43 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1267362837177094		[learning rate: 0.0002816]
	Learning Rate: 0.000281599
	LOSS [training: 0.1267362837177094 | validation: 0.10251196813651589]
	TIME [epoch: 8.41 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17967422482605716		[learning rate: 0.00028058]
	Learning Rate: 0.000280577
	LOSS [training: 0.17967422482605716 | validation: 0.14378408480521954]
	TIME [epoch: 8.41 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08561078492891631		[learning rate: 0.00027956]
	Learning Rate: 0.000279559
	LOSS [training: 0.08561078492891631 | validation: 0.13472696589826105]
	TIME [epoch: 8.42 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11191456424340358		[learning rate: 0.00027854]
	Learning Rate: 0.000278545
	LOSS [training: 0.11191456424340358 | validation: 0.1024599214005492]
	TIME [epoch: 8.42 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16294504729471812		[learning rate: 0.00027753]
	Learning Rate: 0.000277534
	LOSS [training: 0.16294504729471812 | validation: 0.10126064666122822]
	TIME [epoch: 8.41 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17293506821768023		[learning rate: 0.00027653]
	Learning Rate: 0.000276527
	LOSS [training: 0.17293506821768023 | validation: 0.09819024873637633]
	TIME [epoch: 8.42 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13350326893962888		[learning rate: 0.00027552]
	Learning Rate: 0.000275523
	LOSS [training: 0.13350326893962888 | validation: 0.11800499503383712]
	TIME [epoch: 8.43 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1273563880835475		[learning rate: 0.00027452]
	Learning Rate: 0.000274523
	LOSS [training: 0.1273563880835475 | validation: 0.14220936358585673]
	TIME [epoch: 8.42 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11842386627962412		[learning rate: 0.00027353]
	Learning Rate: 0.000273527
	LOSS [training: 0.11842386627962412 | validation: 0.11766280416250444]
	TIME [epoch: 8.41 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37897239747014166		[learning rate: 0.00027253]
	Learning Rate: 0.000272534
	LOSS [training: 0.37897239747014166 | validation: 0.1705231105820535]
	TIME [epoch: 8.41 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27405277322528515		[learning rate: 0.00027155]
	Learning Rate: 0.000271545
	LOSS [training: 0.27405277322528515 | validation: 0.13720045693710242]
	TIME [epoch: 8.43 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12980448487790186		[learning rate: 0.00027056]
	Learning Rate: 0.00027056
	LOSS [training: 0.12980448487790186 | validation: 0.10906142963807308]
	TIME [epoch: 8.42 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12213762806511766		[learning rate: 0.00026958]
	Learning Rate: 0.000269578
	LOSS [training: 0.12213762806511766 | validation: 0.1956991904474391]
	TIME [epoch: 8.41 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12483770739582963		[learning rate: 0.0002686]
	Learning Rate: 0.0002686
	LOSS [training: 0.12483770739582963 | validation: 0.17651793088302203]
	TIME [epoch: 8.41 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10234286837421387		[learning rate: 0.00026762]
	Learning Rate: 0.000267625
	LOSS [training: 0.10234286837421387 | validation: 0.14497855628456408]
	TIME [epoch: 8.43 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08838320899480326		[learning rate: 0.00026665]
	Learning Rate: 0.000266654
	LOSS [training: 0.08838320899480326 | validation: 0.1794842607728046]
	TIME [epoch: 8.42 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14678273520869722		[learning rate: 0.00026569]
	Learning Rate: 0.000265686
	LOSS [training: 0.14678273520869722 | validation: 0.1198695249406953]
	TIME [epoch: 8.4 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13403158169126347		[learning rate: 0.00026472]
	Learning Rate: 0.000264722
	LOSS [training: 0.13403158169126347 | validation: 0.1279377427053748]
	TIME [epoch: 8.41 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11146838957110486		[learning rate: 0.00026376]
	Learning Rate: 0.000263761
	LOSS [training: 0.11146838957110486 | validation: 0.1457527796954154]
	TIME [epoch: 8.43 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18916219945080434		[learning rate: 0.0002628]
	Learning Rate: 0.000262804
	LOSS [training: 0.18916219945080434 | validation: 0.16934050887699065]
	TIME [epoch: 8.42 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11761385024973048		[learning rate: 0.00026185]
	Learning Rate: 0.00026185
	LOSS [training: 0.11761385024973048 | validation: 0.113594885186586]
	TIME [epoch: 8.4 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08357500666071846		[learning rate: 0.0002609]
	Learning Rate: 0.0002609
	LOSS [training: 0.08357500666071846 | validation: 0.08498780552032112]
	TIME [epoch: 8.41 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08722467115986424		[learning rate: 0.00025995]
	Learning Rate: 0.000259953
	LOSS [training: 0.08722467115986424 | validation: 0.1406825411943071]
	TIME [epoch: 8.43 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0772212602183382		[learning rate: 0.00025901]
	Learning Rate: 0.00025901
	LOSS [training: 0.0772212602183382 | validation: 0.1352998435290145]
	TIME [epoch: 8.41 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16259716593769885		[learning rate: 0.00025807]
	Learning Rate: 0.00025807
	LOSS [training: 0.16259716593769885 | validation: 0.12207071184481896]
	TIME [epoch: 8.41 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1061717425539243		[learning rate: 0.00025713]
	Learning Rate: 0.000257133
	LOSS [training: 0.1061717425539243 | validation: 0.09966981082951865]
	TIME [epoch: 8.41 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10233067643951432		[learning rate: 0.0002562]
	Learning Rate: 0.0002562
	LOSS [training: 0.10233067643951432 | validation: 0.09682073419327414]
	TIME [epoch: 8.43 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08774342201603126		[learning rate: 0.00025527]
	Learning Rate: 0.00025527
	LOSS [training: 0.08774342201603126 | validation: 0.1008786971713982]
	TIME [epoch: 8.41 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08398311526781765		[learning rate: 0.00025434]
	Learning Rate: 0.000254344
	LOSS [training: 0.08398311526781765 | validation: 0.09762773598181396]
	TIME [epoch: 8.41 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07677529463905916		[learning rate: 0.00025342]
	Learning Rate: 0.000253421
	LOSS [training: 0.07677529463905916 | validation: 0.10109242179218418]
	TIME [epoch: 8.41 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13579813033473948		[learning rate: 0.0002525]
	Learning Rate: 0.000252501
	LOSS [training: 0.13579813033473948 | validation: 0.07572903535116678]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_1112.pth
	Model improved!!!
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10571535857708773		[learning rate: 0.00025158]
	Learning Rate: 0.000251585
	LOSS [training: 0.10571535857708773 | validation: 0.14663060207521406]
	TIME [epoch: 8.42 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12948758258536594		[learning rate: 0.00025067]
	Learning Rate: 0.000250672
	LOSS [training: 0.12948758258536594 | validation: 0.09525372846604675]
	TIME [epoch: 8.41 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11696963114831097		[learning rate: 0.00024976]
	Learning Rate: 0.000249762
	LOSS [training: 0.11696963114831097 | validation: 0.1528173333089404]
	TIME [epoch: 8.41 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13090797458418146		[learning rate: 0.00024886]
	Learning Rate: 0.000248856
	LOSS [training: 0.13090797458418146 | validation: 0.11933984978712868]
	TIME [epoch: 8.44 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13501465753566538		[learning rate: 0.00024795]
	Learning Rate: 0.000247952
	LOSS [training: 0.13501465753566538 | validation: 0.11642786911403552]
	TIME [epoch: 8.41 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13305211569760594		[learning rate: 0.00024705]
	Learning Rate: 0.000247053
	LOSS [training: 0.13305211569760594 | validation: 0.10376530942346388]
	TIME [epoch: 8.41 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08551982706538194		[learning rate: 0.00024616]
	Learning Rate: 0.000246156
	LOSS [training: 0.08551982706538194 | validation: 0.11572375735188076]
	TIME [epoch: 8.41 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09910488339154185		[learning rate: 0.00024526]
	Learning Rate: 0.000245263
	LOSS [training: 0.09910488339154185 | validation: 0.09147606204688738]
	TIME [epoch: 8.43 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08841534631516203		[learning rate: 0.00024437]
	Learning Rate: 0.000244373
	LOSS [training: 0.08841534631516203 | validation: 0.12297970573631656]
	TIME [epoch: 8.41 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07077854848557348		[learning rate: 0.00024349]
	Learning Rate: 0.000243486
	LOSS [training: 0.07077854848557348 | validation: 0.12566974535337264]
	TIME [epoch: 8.41 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10945565562163137		[learning rate: 0.0002426]
	Learning Rate: 0.000242602
	LOSS [training: 0.10945565562163137 | validation: 0.11857039640799158]
	TIME [epoch: 8.42 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07916397684633507		[learning rate: 0.00024172]
	Learning Rate: 0.000241722
	LOSS [training: 0.07916397684633507 | validation: 0.09947147777598175]
	TIME [epoch: 8.43 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08889526386300262		[learning rate: 0.00024084]
	Learning Rate: 0.000240845
	LOSS [training: 0.08889526386300262 | validation: 0.12463811522483897]
	TIME [epoch: 8.4 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09033945700439157		[learning rate: 0.00023997]
	Learning Rate: 0.000239971
	LOSS [training: 0.09033945700439157 | validation: 0.10365995657759904]
	TIME [epoch: 8.41 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08105549051568378		[learning rate: 0.0002391]
	Learning Rate: 0.0002391
	LOSS [training: 0.08105549051568378 | validation: 0.0924986295673054]
	TIME [epoch: 8.42 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09157125607758639		[learning rate: 0.00023823]
	Learning Rate: 0.000238232
	LOSS [training: 0.09157125607758639 | validation: 0.11687685620271605]
	TIME [epoch: 8.43 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09307847182285475		[learning rate: 0.00023737]
	Learning Rate: 0.000237367
	LOSS [training: 0.09307847182285475 | validation: 0.10203408738962319]
	TIME [epoch: 8.4 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07388005089970812		[learning rate: 0.00023651]
	Learning Rate: 0.000236506
	LOSS [training: 0.07388005089970812 | validation: 0.0759606014315653]
	TIME [epoch: 8.41 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11368570141377583		[learning rate: 0.00023565]
	Learning Rate: 0.000235648
	LOSS [training: 0.11368570141377583 | validation: 0.14501949168975856]
	TIME [epoch: 8.42 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09758637414764292		[learning rate: 0.00023479]
	Learning Rate: 0.000234793
	LOSS [training: 0.09758637414764292 | validation: 0.12797581345070114]
	TIME [epoch: 8.43 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09148764769575903		[learning rate: 0.00023394]
	Learning Rate: 0.00023394
	LOSS [training: 0.09148764769575903 | validation: 0.12067179031586064]
	TIME [epoch: 8.41 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09133516140796055		[learning rate: 0.00023309]
	Learning Rate: 0.000233091
	LOSS [training: 0.09133516140796055 | validation: 0.11452013977383255]
	TIME [epoch: 8.41 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0899561040099593		[learning rate: 0.00023225]
	Learning Rate: 0.000232246
	LOSS [training: 0.0899561040099593 | validation: 0.12832107213975155]
	TIME [epoch: 8.42 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07657438796577216		[learning rate: 0.0002314]
	Learning Rate: 0.000231403
	LOSS [training: 0.07657438796577216 | validation: 0.1342854247209576]
	TIME [epoch: 8.42 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08025940430745662		[learning rate: 0.00023056]
	Learning Rate: 0.000230563
	LOSS [training: 0.08025940430745662 | validation: 0.14201898820380643]
	TIME [epoch: 8.41 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07784583482771092		[learning rate: 0.00022973]
	Learning Rate: 0.000229726
	LOSS [training: 0.07784583482771092 | validation: 0.1583160336347993]
	TIME [epoch: 8.41 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11030517547746688		[learning rate: 0.00022889]
	Learning Rate: 0.000228893
	LOSS [training: 0.11030517547746688 | validation: 0.1146016595205562]
	TIME [epoch: 8.42 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08139870219887531		[learning rate: 0.00022806]
	Learning Rate: 0.000228062
	LOSS [training: 0.08139870219887531 | validation: 0.10975285143985783]
	TIME [epoch: 8.42 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07784525709671151		[learning rate: 0.00022723]
	Learning Rate: 0.000227234
	LOSS [training: 0.07784525709671151 | validation: 0.1475841883568854]
	TIME [epoch: 8.41 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07525186415451278		[learning rate: 0.00022641]
	Learning Rate: 0.00022641
	LOSS [training: 0.07525186415451278 | validation: 0.11441754570437071]
	TIME [epoch: 8.41 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07657541767658023		[learning rate: 0.00022559]
	Learning Rate: 0.000225588
	LOSS [training: 0.07657541767658023 | validation: 0.08228975960065534]
	TIME [epoch: 8.43 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06922447058353466		[learning rate: 0.00022477]
	Learning Rate: 0.000224769
	LOSS [training: 0.06922447058353466 | validation: 0.08722652532574596]
	TIME [epoch: 8.42 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09060458735191275		[learning rate: 0.00022395]
	Learning Rate: 0.000223954
	LOSS [training: 0.09060458735191275 | validation: 0.1329348506745192]
	TIME [epoch: 8.42 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13085953162437583		[learning rate: 0.00022314]
	Learning Rate: 0.000223141
	LOSS [training: 0.13085953162437583 | validation: 0.14383828839446305]
	TIME [epoch: 8.41 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.084232711192553		[learning rate: 0.00022233]
	Learning Rate: 0.000222331
	LOSS [training: 0.084232711192553 | validation: 0.12365621030384277]
	TIME [epoch: 8.43 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10874189429822004		[learning rate: 0.00022152]
	Learning Rate: 0.000221524
	LOSS [training: 0.10874189429822004 | validation: 0.19812491155589987]
	TIME [epoch: 8.41 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11942219638171303		[learning rate: 0.00022072]
	Learning Rate: 0.00022072
	LOSS [training: 0.11942219638171303 | validation: 0.1786236985847556]
	TIME [epoch: 8.4 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07664384522033221		[learning rate: 0.00021992]
	Learning Rate: 0.000219919
	LOSS [training: 0.07664384522033221 | validation: 0.10412835925767802]
	TIME [epoch: 8.41 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07843955101418923		[learning rate: 0.00021912]
	Learning Rate: 0.000219121
	LOSS [training: 0.07843955101418923 | validation: 0.14022636361183344]
	TIME [epoch: 8.43 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09426518098963897		[learning rate: 0.00021833]
	Learning Rate: 0.000218326
	LOSS [training: 0.09426518098963897 | validation: 0.08569239156306083]
	TIME [epoch: 8.41 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08270529489581405		[learning rate: 0.00021753]
	Learning Rate: 0.000217534
	LOSS [training: 0.08270529489581405 | validation: 0.09592893399882352]
	TIME [epoch: 8.41 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07924134524996432		[learning rate: 0.00021674]
	Learning Rate: 0.000216744
	LOSS [training: 0.07924134524996432 | validation: 0.10840640066319623]
	TIME [epoch: 8.41 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11120724544452827		[learning rate: 0.00021596]
	Learning Rate: 0.000215958
	LOSS [training: 0.11120724544452827 | validation: 0.10417033365694904]
	TIME [epoch: 8.43 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07638695436219725		[learning rate: 0.00021517]
	Learning Rate: 0.000215174
	LOSS [training: 0.07638695436219725 | validation: 0.10080312488766818]
	TIME [epoch: 8.41 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0917911479275334		[learning rate: 0.00021439]
	Learning Rate: 0.000214393
	LOSS [training: 0.0917911479275334 | validation: 0.11704094099277502]
	TIME [epoch: 8.41 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12314788264062744		[learning rate: 0.00021361]
	Learning Rate: 0.000213615
	LOSS [training: 0.12314788264062744 | validation: 0.1484624336140078]
	TIME [epoch: 8.4 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11263253986954185		[learning rate: 0.00021284]
	Learning Rate: 0.00021284
	LOSS [training: 0.11263253986954185 | validation: 0.1208538195438914]
	TIME [epoch: 8.43 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10027271742049089		[learning rate: 0.00021207]
	Learning Rate: 0.000212067
	LOSS [training: 0.10027271742049089 | validation: 0.11717602479743908]
	TIME [epoch: 8.41 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09041497014276045		[learning rate: 0.0002113]
	Learning Rate: 0.000211298
	LOSS [training: 0.09041497014276045 | validation: 0.08172286216066849]
	TIME [epoch: 8.41 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07108062838309033		[learning rate: 0.00021053]
	Learning Rate: 0.000210531
	LOSS [training: 0.07108062838309033 | validation: 0.12426511645925735]
	TIME [epoch: 8.41 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13099162521335977		[learning rate: 0.00020977]
	Learning Rate: 0.000209767
	LOSS [training: 0.13099162521335977 | validation: 0.12186947860450778]
	TIME [epoch: 8.43 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0908429026055358		[learning rate: 0.00020901]
	Learning Rate: 0.000209006
	LOSS [training: 0.0908429026055358 | validation: 0.10968638515159601]
	TIME [epoch: 8.41 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.070061039590779		[learning rate: 0.00020825]
	Learning Rate: 0.000208247
	LOSS [training: 0.070061039590779 | validation: 0.09518898935782819]
	TIME [epoch: 8.41 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08561102821605755		[learning rate: 0.00020749]
	Learning Rate: 0.000207491
	LOSS [training: 0.08561102821605755 | validation: 0.09866634167402062]
	TIME [epoch: 8.41 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1104339917016822		[learning rate: 0.00020674]
	Learning Rate: 0.000206738
	LOSS [training: 0.1104339917016822 | validation: 0.11098547928787787]
	TIME [epoch: 8.44 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1621278212398533		[learning rate: 0.00020599]
	Learning Rate: 0.000205988
	LOSS [training: 0.1621278212398533 | validation: 0.20332271127148424]
	TIME [epoch: 8.41 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17446276415288367		[learning rate: 0.00020524]
	Learning Rate: 0.000205241
	LOSS [training: 0.17446276415288367 | validation: 0.12654987494716258]
	TIME [epoch: 8.41 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10307451727393113		[learning rate: 0.0002045]
	Learning Rate: 0.000204496
	LOSS [training: 0.10307451727393113 | validation: 0.12125607701910712]
	TIME [epoch: 8.41 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0876708471519264		[learning rate: 0.00020375]
	Learning Rate: 0.000203754
	LOSS [training: 0.0876708471519264 | validation: 0.0982727989887657]
	TIME [epoch: 8.44 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08222979532407634		[learning rate: 0.00020301]
	Learning Rate: 0.000203014
	LOSS [training: 0.08222979532407634 | validation: 0.11842478268444927]
	TIME [epoch: 8.41 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09087480239362569		[learning rate: 0.00020228]
	Learning Rate: 0.000202277
	LOSS [training: 0.09087480239362569 | validation: 0.1567853038883617]
	TIME [epoch: 8.41 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09281676797704239		[learning rate: 0.00020154]
	Learning Rate: 0.000201543
	LOSS [training: 0.09281676797704239 | validation: 0.12971153143989117]
	TIME [epoch: 8.41 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08871753785141316		[learning rate: 0.00020081]
	Learning Rate: 0.000200812
	LOSS [training: 0.08871753785141316 | validation: 0.12918013972633263]
	TIME [epoch: 8.44 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0805449884154515		[learning rate: 0.00020008]
	Learning Rate: 0.000200083
	LOSS [training: 0.0805449884154515 | validation: 0.11611280311419758]
	TIME [epoch: 8.41 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07953965314956248		[learning rate: 0.00019936]
	Learning Rate: 0.000199357
	LOSS [training: 0.07953965314956248 | validation: 0.10492989617175891]
	TIME [epoch: 8.41 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08351892791893047		[learning rate: 0.00019863]
	Learning Rate: 0.000198634
	LOSS [training: 0.08351892791893047 | validation: 0.1821136206361505]
	TIME [epoch: 8.41 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08177417302844606		[learning rate: 0.00019791]
	Learning Rate: 0.000197913
	LOSS [training: 0.08177417302844606 | validation: 0.09872215978747605]
	TIME [epoch: 8.43 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07844807755760536		[learning rate: 0.00019719]
	Learning Rate: 0.000197194
	LOSS [training: 0.07844807755760536 | validation: 0.15037166379314812]
	TIME [epoch: 8.41 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0749616245442267		[learning rate: 0.00019648]
	Learning Rate: 0.000196479
	LOSS [training: 0.0749616245442267 | validation: 0.09488237513416056]
	TIME [epoch: 8.4 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08611921721835157		[learning rate: 0.00019577]
	Learning Rate: 0.000195766
	LOSS [training: 0.08611921721835157 | validation: 0.12228552481861478]
	TIME [epoch: 8.42 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09389680080590848		[learning rate: 0.00019506]
	Learning Rate: 0.000195055
	LOSS [training: 0.09389680080590848 | validation: 0.12376451305301114]
	TIME [epoch: 8.43 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09612722331676878		[learning rate: 0.00019435]
	Learning Rate: 0.000194347
	LOSS [training: 0.09612722331676878 | validation: 0.10468759483828041]
	TIME [epoch: 8.41 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0885944243685392		[learning rate: 0.00019364]
	Learning Rate: 0.000193642
	LOSS [training: 0.0885944243685392 | validation: 0.12971224293921277]
	TIME [epoch: 8.41 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0796492927955007		[learning rate: 0.00019294]
	Learning Rate: 0.000192939
	LOSS [training: 0.0796492927955007 | validation: 0.09061986954563817]
	TIME [epoch: 8.41 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10656314181807824		[learning rate: 0.00019224]
	Learning Rate: 0.000192239
	LOSS [training: 0.10656314181807824 | validation: 0.14486002684186244]
	TIME [epoch: 8.43 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08824656201571324		[learning rate: 0.00019154]
	Learning Rate: 0.000191542
	LOSS [training: 0.08824656201571324 | validation: 0.07980760641814996]
	TIME [epoch: 8.41 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08831684923306835		[learning rate: 0.00019085]
	Learning Rate: 0.000190846
	LOSS [training: 0.08831684923306835 | validation: 0.08606019707416808]
	TIME [epoch: 8.41 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07450258701562464		[learning rate: 0.00019015]
	Learning Rate: 0.000190154
	LOSS [training: 0.07450258701562464 | validation: 0.11248713102882386]
	TIME [epoch: 8.42 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07844501080932739		[learning rate: 0.00018946]
	Learning Rate: 0.000189464
	LOSS [training: 0.07844501080932739 | validation: 0.138841665895088]
	TIME [epoch: 8.43 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07194681976419795		[learning rate: 0.00018878]
	Learning Rate: 0.000188776
	LOSS [training: 0.07194681976419795 | validation: 0.11569052833868892]
	TIME [epoch: 8.41 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07271242369017644		[learning rate: 0.00018809]
	Learning Rate: 0.000188091
	LOSS [training: 0.07271242369017644 | validation: 0.12180818613431642]
	TIME [epoch: 8.41 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07434372351585132		[learning rate: 0.00018741]
	Learning Rate: 0.000187409
	LOSS [training: 0.07434372351585132 | validation: 0.13115243843730168]
	TIME [epoch: 8.42 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06832892971354931		[learning rate: 0.00018673]
	Learning Rate: 0.000186729
	LOSS [training: 0.06832892971354931 | validation: 0.11359477048149269]
	TIME [epoch: 8.42 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07609752702652564		[learning rate: 0.00018605]
	Learning Rate: 0.000186051
	LOSS [training: 0.07609752702652564 | validation: 0.10974619289933916]
	TIME [epoch: 8.41 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09061586904278654		[learning rate: 0.00018538]
	Learning Rate: 0.000185376
	LOSS [training: 0.09061586904278654 | validation: 0.13169319709079544]
	TIME [epoch: 8.4 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09898102698613419		[learning rate: 0.0001847]
	Learning Rate: 0.000184703
	LOSS [training: 0.09898102698613419 | validation: 0.16666536776490531]
	TIME [epoch: 8.42 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08789396375520857		[learning rate: 0.00018403]
	Learning Rate: 0.000184033
	LOSS [training: 0.08789396375520857 | validation: 0.11154760169233437]
	TIME [epoch: 8.42 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07633954094550867		[learning rate: 0.00018336]
	Learning Rate: 0.000183365
	LOSS [training: 0.07633954094550867 | validation: 0.10505045745905886]
	TIME [epoch: 8.41 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08009754532331595		[learning rate: 0.0001827]
	Learning Rate: 0.000182699
	LOSS [training: 0.08009754532331595 | validation: 0.11803845056019208]
	TIME [epoch: 8.42 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07506351602180547		[learning rate: 0.00018204]
	Learning Rate: 0.000182036
	LOSS [training: 0.07506351602180547 | validation: 0.13677005750462684]
	TIME [epoch: 8.43 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08904460136893917		[learning rate: 0.00018138]
	Learning Rate: 0.000181376
	LOSS [training: 0.08904460136893917 | validation: 0.08323739967595636]
	TIME [epoch: 8.42 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09129692924149665		[learning rate: 0.00018072]
	Learning Rate: 0.000180717
	LOSS [training: 0.09129692924149665 | validation: 0.09421413185630745]
	TIME [epoch: 8.41 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07125007549349108		[learning rate: 0.00018006]
	Learning Rate: 0.000180062
	LOSS [training: 0.07125007549349108 | validation: 0.13503017513330726]
	TIME [epoch: 8.42 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.085750486656746		[learning rate: 0.00017941]
	Learning Rate: 0.000179408
	LOSS [training: 0.085750486656746 | validation: 0.10495679965492974]
	TIME [epoch: 8.43 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0765814711194156		[learning rate: 0.00017876]
	Learning Rate: 0.000178757
	LOSS [training: 0.0765814711194156 | validation: 0.10819470294883522]
	TIME [epoch: 8.42 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08989339473899244		[learning rate: 0.00017811]
	Learning Rate: 0.000178108
	LOSS [training: 0.08989339473899244 | validation: 0.10983861588936125]
	TIME [epoch: 8.41 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07963648233169979		[learning rate: 0.00017746]
	Learning Rate: 0.000177462
	LOSS [training: 0.07963648233169979 | validation: 0.11677970105140394]
	TIME [epoch: 8.42 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07471303787783108		[learning rate: 0.00017682]
	Learning Rate: 0.000176818
	LOSS [training: 0.07471303787783108 | validation: 0.11731573731300335]
	TIME [epoch: 8.44 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08560714984682133		[learning rate: 0.00017618]
	Learning Rate: 0.000176176
	LOSS [training: 0.08560714984682133 | validation: 0.11593333833732822]
	TIME [epoch: 8.42 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.082722391029881		[learning rate: 0.00017554]
	Learning Rate: 0.000175537
	LOSS [training: 0.082722391029881 | validation: 0.14268213187447987]
	TIME [epoch: 8.42 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08553053648828453		[learning rate: 0.0001749]
	Learning Rate: 0.0001749
	LOSS [training: 0.08553053648828453 | validation: 0.1209182497701308]
	TIME [epoch: 8.41 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0690754071588498		[learning rate: 0.00017427]
	Learning Rate: 0.000174265
	LOSS [training: 0.0690754071588498 | validation: 0.14027176914181524]
	TIME [epoch: 8.44 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10145870671377591		[learning rate: 0.00017363]
	Learning Rate: 0.000173633
	LOSS [training: 0.10145870671377591 | validation: 0.12217957154900826]
	TIME [epoch: 8.41 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08153717486311815		[learning rate: 0.000173]
	Learning Rate: 0.000173003
	LOSS [training: 0.08153717486311815 | validation: 0.12822649475842557]
	TIME [epoch: 8.41 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07578967957173932		[learning rate: 0.00017237]
	Learning Rate: 0.000172375
	LOSS [training: 0.07578967957173932 | validation: 0.09182183901158558]
	TIME [epoch: 8.41 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06936989743680141		[learning rate: 0.00017175]
	Learning Rate: 0.000171749
	LOSS [training: 0.06936989743680141 | validation: 0.09600963009726249]
	TIME [epoch: 8.44 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07230243572587915		[learning rate: 0.00017113]
	Learning Rate: 0.000171126
	LOSS [training: 0.07230243572587915 | validation: 0.07240905809503248]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_1219.pth
	Model improved!!!
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08328168455795305		[learning rate: 0.0001705]
	Learning Rate: 0.000170505
	LOSS [training: 0.08328168455795305 | validation: 0.10811994083365656]
	TIME [epoch: 8.42 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07195780222613243		[learning rate: 0.00016989]
	Learning Rate: 0.000169886
	LOSS [training: 0.07195780222613243 | validation: 0.10974259739494073]
	TIME [epoch: 8.41 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08050995296671086		[learning rate: 0.00016927]
	Learning Rate: 0.00016927
	LOSS [training: 0.08050995296671086 | validation: 0.09920196547285101]
	TIME [epoch: 8.44 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07812866835019085		[learning rate: 0.00016866]
	Learning Rate: 0.000168655
	LOSS [training: 0.07812866835019085 | validation: 0.10665153674987349]
	TIME [epoch: 8.41 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07767690683588832		[learning rate: 0.00016804]
	Learning Rate: 0.000168043
	LOSS [training: 0.07767690683588832 | validation: 0.10914849103936058]
	TIME [epoch: 8.41 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07952742596052714		[learning rate: 0.00016743]
	Learning Rate: 0.000167433
	LOSS [training: 0.07952742596052714 | validation: 0.09231601291718539]
	TIME [epoch: 8.41 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08668163587814048		[learning rate: 0.00016683]
	Learning Rate: 0.000166826
	LOSS [training: 0.08668163587814048 | validation: 0.11404684820643071]
	TIME [epoch: 8.43 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10603275875141845		[learning rate: 0.00016622]
	Learning Rate: 0.00016622
	LOSS [training: 0.10603275875141845 | validation: 0.15654996835615403]
	TIME [epoch: 8.41 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07587051899534167		[learning rate: 0.00016562]
	Learning Rate: 0.000165617
	LOSS [training: 0.07587051899534167 | validation: 0.10761801569714141]
	TIME [epoch: 8.4 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09448289891144308		[learning rate: 0.00016502]
	Learning Rate: 0.000165016
	LOSS [training: 0.09448289891144308 | validation: 0.09418360855035723]
	TIME [epoch: 8.41 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07599039592316073		[learning rate: 0.00016442]
	Learning Rate: 0.000164417
	LOSS [training: 0.07599039592316073 | validation: 0.0948427038518718]
	TIME [epoch: 8.43 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08598356345254642		[learning rate: 0.00016382]
	Learning Rate: 0.000163821
	LOSS [training: 0.08598356345254642 | validation: 0.09265995525598018]
	TIME [epoch: 8.4 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07488599992099797		[learning rate: 0.00016323]
	Learning Rate: 0.000163226
	LOSS [training: 0.07488599992099797 | validation: 0.11570840251640413]
	TIME [epoch: 8.41 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0740780595886972		[learning rate: 0.00016263]
	Learning Rate: 0.000162634
	LOSS [training: 0.0740780595886972 | validation: 0.12023190174022143]
	TIME [epoch: 8.4 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0721272177234591		[learning rate: 0.00016204]
	Learning Rate: 0.000162043
	LOSS [training: 0.0721272177234591 | validation: 0.11738397101518293]
	TIME [epoch: 8.44 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06889923573008852		[learning rate: 0.00016146]
	Learning Rate: 0.000161455
	LOSS [training: 0.06889923573008852 | validation: 0.09175560020801214]
	TIME [epoch: 8.4 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07018072221174732		[learning rate: 0.00016087]
	Learning Rate: 0.000160869
	LOSS [training: 0.07018072221174732 | validation: 0.09997870603303655]
	TIME [epoch: 8.4 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07583178724853044		[learning rate: 0.00016029]
	Learning Rate: 0.000160286
	LOSS [training: 0.07583178724853044 | validation: 0.10119151369504353]
	TIME [epoch: 8.4 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07556712187232924		[learning rate: 0.0001597]
	Learning Rate: 0.000159704
	LOSS [training: 0.07556712187232924 | validation: 0.09746930761849536]
	TIME [epoch: 8.43 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06379141954320111		[learning rate: 0.00015912]
	Learning Rate: 0.000159124
	LOSS [training: 0.06379141954320111 | validation: 0.09146027059186349]
	TIME [epoch: 8.41 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06693859268634453		[learning rate: 0.00015855]
	Learning Rate: 0.000158547
	LOSS [training: 0.06693859268634453 | validation: 0.12196749209758836]
	TIME [epoch: 8.41 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07719560771697086		[learning rate: 0.00015797]
	Learning Rate: 0.000157972
	LOSS [training: 0.07719560771697086 | validation: 0.11988760739424184]
	TIME [epoch: 8.41 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09388142052663118		[learning rate: 0.0001574]
	Learning Rate: 0.000157398
	LOSS [training: 0.09388142052663118 | validation: 0.09164920154225617]
	TIME [epoch: 8.43 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06738581406832315		[learning rate: 0.00015683]
	Learning Rate: 0.000156827
	LOSS [training: 0.06738581406832315 | validation: 0.11235807151343241]
	TIME [epoch: 8.4 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07775945036529255		[learning rate: 0.00015626]
	Learning Rate: 0.000156258
	LOSS [training: 0.07775945036529255 | validation: 0.10621239865665068]
	TIME [epoch: 8.4 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07069693229759293		[learning rate: 0.00015569]
	Learning Rate: 0.000155691
	LOSS [training: 0.07069693229759293 | validation: 0.09113965257997175]
	TIME [epoch: 8.42 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08247260328007548		[learning rate: 0.00015513]
	Learning Rate: 0.000155126
	LOSS [training: 0.08247260328007548 | validation: 0.1062380290514805]
	TIME [epoch: 8.42 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07572931641933497		[learning rate: 0.00015456]
	Learning Rate: 0.000154563
	LOSS [training: 0.07572931641933497 | validation: 0.10539874686402789]
	TIME [epoch: 8.4 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09402657170047314		[learning rate: 0.000154]
	Learning Rate: 0.000154002
	LOSS [training: 0.09402657170047314 | validation: 0.1089329221875281]
	TIME [epoch: 8.41 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09762494482560699		[learning rate: 0.00015344]
	Learning Rate: 0.000153443
	LOSS [training: 0.09762494482560699 | validation: 0.09152346120553106]
	TIME [epoch: 8.41 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13038790126137895		[learning rate: 0.00015289]
	Learning Rate: 0.000152886
	LOSS [training: 0.13038790126137895 | validation: 0.16281856989696852]
	TIME [epoch: 8.42 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07278018084953312		[learning rate: 0.00015233]
	Learning Rate: 0.000152331
	LOSS [training: 0.07278018084953312 | validation: 0.09349637078974547]
	TIME [epoch: 8.41 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09126382714235566		[learning rate: 0.00015178]
	Learning Rate: 0.000151779
	LOSS [training: 0.09126382714235566 | validation: 0.07681832960236862]
	TIME [epoch: 8.41 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08104991969013219		[learning rate: 0.00015123]
	Learning Rate: 0.000151228
	LOSS [training: 0.08104991969013219 | validation: 0.11002923785902517]
	TIME [epoch: 8.42 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09323289882729566		[learning rate: 0.00015068]
	Learning Rate: 0.000150679
	LOSS [training: 0.09323289882729566 | validation: 0.09870111008183112]
	TIME [epoch: 8.42 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1021685575335188		[learning rate: 0.00015013]
	Learning Rate: 0.000150132
	LOSS [training: 0.1021685575335188 | validation: 0.0883533177774269]
	TIME [epoch: 8.4 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08172865512804152		[learning rate: 0.00014959]
	Learning Rate: 0.000149587
	LOSS [training: 0.08172865512804152 | validation: 0.08877578865341684]
	TIME [epoch: 8.4 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07291498303886827		[learning rate: 0.00014904]
	Learning Rate: 0.000149044
	LOSS [training: 0.07291498303886827 | validation: 0.07481331419061914]
	TIME [epoch: 8.42 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12508369178665246		[learning rate: 0.0001485]
	Learning Rate: 0.000148504
	LOSS [training: 0.12508369178665246 | validation: 0.1124561940342276]
	TIME [epoch: 8.42 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15586837317216926		[learning rate: 0.00014796]
	Learning Rate: 0.000147965
	LOSS [training: 0.15586837317216926 | validation: 0.08795637404398507]
	TIME [epoch: 8.41 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11270921745217881		[learning rate: 0.00014743]
	Learning Rate: 0.000147428
	LOSS [training: 0.11270921745217881 | validation: 0.10308858215262398]
	TIME [epoch: 8.41 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0713205495216627		[learning rate: 0.00014689]
	Learning Rate: 0.000146893
	LOSS [training: 0.0713205495216627 | validation: 0.10485890263715725]
	TIME [epoch: 8.43 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06765846702608655		[learning rate: 0.00014636]
	Learning Rate: 0.00014636
	LOSS [training: 0.06765846702608655 | validation: 0.11144148999668939]
	TIME [epoch: 8.41 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08830746930202282		[learning rate: 0.00014583]
	Learning Rate: 0.000145828
	LOSS [training: 0.08830746930202282 | validation: 0.1137746597371174]
	TIME [epoch: 8.4 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07464241351802012		[learning rate: 0.0001453]
	Learning Rate: 0.000145299
	LOSS [training: 0.07464241351802012 | validation: 0.11353775617410963]
	TIME [epoch: 8.4 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07102027903662703		[learning rate: 0.00014477]
	Learning Rate: 0.000144772
	LOSS [training: 0.07102027903662703 | validation: 0.11284377065281607]
	TIME [epoch: 8.42 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09985716811309212		[learning rate: 0.00014425]
	Learning Rate: 0.000144247
	LOSS [training: 0.09985716811309212 | validation: 0.12132727391002629]
	TIME [epoch: 8.41 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11024929135858623		[learning rate: 0.00014372]
	Learning Rate: 0.000143723
	LOSS [training: 0.11024929135858623 | validation: 0.10754179569300108]
	TIME [epoch: 8.4 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10516503677813785		[learning rate: 0.0001432]
	Learning Rate: 0.000143201
	LOSS [training: 0.10516503677813785 | validation: 0.09403332874334858]
	TIME [epoch: 8.4 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09978475248661897		[learning rate: 0.00014268]
	Learning Rate: 0.000142682
	LOSS [training: 0.09978475248661897 | validation: 0.09885749378279851]
	TIME [epoch: 8.43 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13241814067356056		[learning rate: 0.00014216]
	Learning Rate: 0.000142164
	LOSS [training: 0.13241814067356056 | validation: 0.11218038511551638]
	TIME [epoch: 8.4 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09518921626503113		[learning rate: 0.00014165]
	Learning Rate: 0.000141648
	LOSS [training: 0.09518921626503113 | validation: 0.15773974927411044]
	TIME [epoch: 8.41 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07594859287648935		[learning rate: 0.00014113]
	Learning Rate: 0.000141134
	LOSS [training: 0.07594859287648935 | validation: 0.09809096776990184]
	TIME [epoch: 8.4 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07556179596719839		[learning rate: 0.00014062]
	Learning Rate: 0.000140622
	LOSS [training: 0.07556179596719839 | validation: 0.09610019900032207]
	TIME [epoch: 8.43 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07055125788338412		[learning rate: 0.00014011]
	Learning Rate: 0.000140112
	LOSS [training: 0.07055125788338412 | validation: 0.14923580027795563]
	TIME [epoch: 8.4 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07851036246358994		[learning rate: 0.0001396]
	Learning Rate: 0.000139603
	LOSS [training: 0.07851036246358994 | validation: 0.08727379934510796]
	TIME [epoch: 8.4 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10265368846330865		[learning rate: 0.0001391]
	Learning Rate: 0.000139096
	LOSS [training: 0.10265368846330865 | validation: 0.09526677861565183]
	TIME [epoch: 8.4 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08297011286582054		[learning rate: 0.00013859]
	Learning Rate: 0.000138592
	LOSS [training: 0.08297011286582054 | validation: 0.09262639489768211]
	TIME [epoch: 8.42 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12265620589271146		[learning rate: 0.00013809]
	Learning Rate: 0.000138089
	LOSS [training: 0.12265620589271146 | validation: 0.10642662887594143]
	TIME [epoch: 8.41 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09690720476382741		[learning rate: 0.00013759]
	Learning Rate: 0.000137587
	LOSS [training: 0.09690720476382741 | validation: 0.08358676453670343]
	TIME [epoch: 8.4 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1074843916961187		[learning rate: 0.00013709]
	Learning Rate: 0.000137088
	LOSS [training: 0.1074843916961187 | validation: 0.09486560166262253]
	TIME [epoch: 8.41 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10590655667635449		[learning rate: 0.00013659]
	Learning Rate: 0.000136591
	LOSS [training: 0.10590655667635449 | validation: 0.07544490113175575]
	TIME [epoch: 8.43 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12197224570380585		[learning rate: 0.00013609]
	Learning Rate: 0.000136095
	LOSS [training: 0.12197224570380585 | validation: 0.10447797952777566]
	TIME [epoch: 8.41 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15715955587551397		[learning rate: 0.0001356]
	Learning Rate: 0.000135601
	LOSS [training: 0.15715955587551397 | validation: 0.10433467045064157]
	TIME [epoch: 8.41 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12657673243783601		[learning rate: 0.00013511]
	Learning Rate: 0.000135109
	LOSS [training: 0.12657673243783601 | validation: 0.11279109729609571]
	TIME [epoch: 8.4 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09475053930614459		[learning rate: 0.00013462]
	Learning Rate: 0.000134619
	LOSS [training: 0.09475053930614459 | validation: 0.09316646738715265]
	TIME [epoch: 8.43 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09550818943662197		[learning rate: 0.00013413]
	Learning Rate: 0.00013413
	LOSS [training: 0.09550818943662197 | validation: 0.08482675126953823]
	TIME [epoch: 8.41 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09865361278581805		[learning rate: 0.00013364]
	Learning Rate: 0.000133643
	LOSS [training: 0.09865361278581805 | validation: 0.1192565753505024]
	TIME [epoch: 8.41 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10823414234103268		[learning rate: 0.00013316]
	Learning Rate: 0.000133158
	LOSS [training: 0.10823414234103268 | validation: 0.12084652654737513]
	TIME [epoch: 8.4 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1506118950060374		[learning rate: 0.00013268]
	Learning Rate: 0.000132675
	LOSS [training: 0.1506118950060374 | validation: 0.11884955550535617]
	TIME [epoch: 8.43 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09143223608692126		[learning rate: 0.00013219]
	Learning Rate: 0.000132194
	LOSS [training: 0.09143223608692126 | validation: 0.09675622599307546]
	TIME [epoch: 8.4 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10020212931137792		[learning rate: 0.00013171]
	Learning Rate: 0.000131714
	LOSS [training: 0.10020212931137792 | validation: 0.11247234670818342]
	TIME [epoch: 8.4 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1310252132340698		[learning rate: 0.00013124]
	Learning Rate: 0.000131236
	LOSS [training: 0.1310252132340698 | validation: 0.10058772854239445]
	TIME [epoch: 8.4 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12040073769883228		[learning rate: 0.00013076]
	Learning Rate: 0.00013076
	LOSS [training: 0.12040073769883228 | validation: 0.1119825440673218]
	TIME [epoch: 8.42 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0914497279989265		[learning rate: 0.00013029]
	Learning Rate: 0.000130285
	LOSS [training: 0.0914497279989265 | validation: 0.1187221872652901]
	TIME [epoch: 8.4 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07549817323323746		[learning rate: 0.00012981]
	Learning Rate: 0.000129812
	LOSS [training: 0.07549817323323746 | validation: 0.12169083927574786]
	TIME [epoch: 8.4 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07343823668506284		[learning rate: 0.00012934]
	Learning Rate: 0.000129341
	LOSS [training: 0.07343823668506284 | validation: 0.09141749357724523]
	TIME [epoch: 8.4 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07017220025295816		[learning rate: 0.00012887]
	Learning Rate: 0.000128872
	LOSS [training: 0.07017220025295816 | validation: 0.1110920473085251]
	TIME [epoch: 8.42 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10193379530306679		[learning rate: 0.0001284]
	Learning Rate: 0.000128404
	LOSS [training: 0.10193379530306679 | validation: 0.11143682686834039]
	TIME [epoch: 8.4 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07996898395446081		[learning rate: 0.00012794]
	Learning Rate: 0.000127938
	LOSS [training: 0.07996898395446081 | validation: 0.12608584595383182]
	TIME [epoch: 8.4 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08185532596690591		[learning rate: 0.00012747]
	Learning Rate: 0.000127474
	LOSS [training: 0.08185532596690591 | validation: 0.10677039321700266]
	TIME [epoch: 8.4 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07840620913709662		[learning rate: 0.00012701]
	Learning Rate: 0.000127011
	LOSS [training: 0.07840620913709662 | validation: 0.09260884785345455]
	TIME [epoch: 8.43 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09056520655037255		[learning rate: 0.00012655]
	Learning Rate: 0.00012655
	LOSS [training: 0.09056520655037255 | validation: 0.12993039348389313]
	TIME [epoch: 8.4 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08965373981145836		[learning rate: 0.00012609]
	Learning Rate: 0.000126091
	LOSS [training: 0.08965373981145836 | validation: 0.11022589748981751]
	TIME [epoch: 8.4 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13474349652914425		[learning rate: 0.00012563]
	Learning Rate: 0.000125633
	LOSS [training: 0.13474349652914425 | validation: 0.09148637824484925]
	TIME [epoch: 8.41 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.069495710406171		[learning rate: 0.00012518]
	Learning Rate: 0.000125178
	LOSS [training: 0.069495710406171 | validation: 0.098298700981199]
	TIME [epoch: 8.43 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06507592318602842		[learning rate: 0.00012472]
	Learning Rate: 0.000124723
	LOSS [training: 0.06507592318602842 | validation: 0.12440858818652267]
	TIME [epoch: 8.4 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07949093154996195		[learning rate: 0.00012427]
	Learning Rate: 0.000124271
	LOSS [training: 0.07949093154996195 | validation: 0.11233618916313973]
	TIME [epoch: 8.4 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06806771137356597		[learning rate: 0.00012382]
	Learning Rate: 0.00012382
	LOSS [training: 0.06806771137356597 | validation: 0.09382136830099559]
	TIME [epoch: 8.42 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07517146144502415		[learning rate: 0.00012337]
	Learning Rate: 0.00012337
	LOSS [training: 0.07517146144502415 | validation: 0.11696190610170623]
	TIME [epoch: 8.41 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07968612908659609		[learning rate: 0.00012292]
	Learning Rate: 0.000122923
	LOSS [training: 0.07968612908659609 | validation: 0.14007388243309632]
	TIME [epoch: 8.4 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07570593116765031		[learning rate: 0.00012248]
	Learning Rate: 0.000122476
	LOSS [training: 0.07570593116765031 | validation: 0.11137219673025758]
	TIME [epoch: 8.4 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07878141749000918		[learning rate: 0.00012203]
	Learning Rate: 0.000122032
	LOSS [training: 0.07878141749000918 | validation: 0.09397939344498804]
	TIME [epoch: 8.41 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07126832379755846		[learning rate: 0.00012159]
	Learning Rate: 0.000121589
	LOSS [training: 0.07126832379755846 | validation: 0.11189561410444204]
	TIME [epoch: 8.41 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06380151179682202		[learning rate: 0.00012115]
	Learning Rate: 0.000121148
	LOSS [training: 0.06380151179682202 | validation: 0.1074929511985975]
	TIME [epoch: 8.4 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07124110154065662		[learning rate: 0.00012071]
	Learning Rate: 0.000120708
	LOSS [training: 0.07124110154065662 | validation: 0.1017546645632255]
	TIME [epoch: 8.4 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07197954159512822		[learning rate: 0.00012027]
	Learning Rate: 0.00012027
	LOSS [training: 0.07197954159512822 | validation: 0.11781881731460878]
	TIME [epoch: 8.41 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07972573274543016		[learning rate: 0.00011983]
	Learning Rate: 0.000119834
	LOSS [training: 0.07972573274543016 | validation: 0.13049199518728694]
	TIME [epoch: 8.42 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08873924142695369		[learning rate: 0.0001194]
	Learning Rate: 0.000119399
	LOSS [training: 0.08873924142695369 | validation: 0.096313518344913]
	TIME [epoch: 8.4 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06945455743431804		[learning rate: 0.00011897]
	Learning Rate: 0.000118966
	LOSS [training: 0.06945455743431804 | validation: 0.085739293429772]
	TIME [epoch: 8.4 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06710346363878164		[learning rate: 0.00011853]
	Learning Rate: 0.000118534
	LOSS [training: 0.06710346363878164 | validation: 0.0737097137792268]
	TIME [epoch: 8.41 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08067018670583054		[learning rate: 0.0001181]
	Learning Rate: 0.000118104
	LOSS [training: 0.08067018670583054 | validation: 0.10887535754582467]
	TIME [epoch: 8.42 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609796753127906		[learning rate: 0.00011767]
	Learning Rate: 0.000117675
	LOSS [training: 0.06609796753127906 | validation: 0.09305440711059851]
	TIME [epoch: 8.41 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07352909369451971		[learning rate: 0.00011725]
	Learning Rate: 0.000117248
	LOSS [training: 0.07352909369451971 | validation: 0.08374156990899735]
	TIME [epoch: 8.4 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06948774675460509		[learning rate: 0.00011682]
	Learning Rate: 0.000116822
	LOSS [training: 0.06948774675460509 | validation: 0.10978531998757073]
	TIME [epoch: 8.42 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06834028777301468		[learning rate: 0.0001164]
	Learning Rate: 0.000116398
	LOSS [training: 0.06834028777301468 | validation: 0.08575101809430946]
	TIME [epoch: 8.4 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06963502141509782		[learning rate: 0.00011598]
	Learning Rate: 0.000115976
	LOSS [training: 0.06963502141509782 | validation: 0.08243975371460815]
	TIME [epoch: 8.4 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08073511488750065		[learning rate: 0.00011556]
	Learning Rate: 0.000115555
	LOSS [training: 0.08073511488750065 | validation: 0.08310883637988555]
	TIME [epoch: 8.4 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07977716303423973		[learning rate: 0.00011514]
	Learning Rate: 0.000115136
	LOSS [training: 0.07977716303423973 | validation: 0.09364010488268648]
	TIME [epoch: 8.43 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06831558951751951		[learning rate: 0.00011472]
	Learning Rate: 0.000114718
	LOSS [training: 0.06831558951751951 | validation: 0.12620067991492354]
	TIME [epoch: 8.41 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06723991394618198		[learning rate: 0.0001143]
	Learning Rate: 0.000114302
	LOSS [training: 0.06723991394618198 | validation: 0.08952841858442336]
	TIME [epoch: 8.4 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06693017741070131		[learning rate: 0.00011389]
	Learning Rate: 0.000113887
	LOSS [training: 0.06693017741070131 | validation: 0.10394997606275606]
	TIME [epoch: 8.41 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0788045509156576		[learning rate: 0.00011347]
	Learning Rate: 0.000113474
	LOSS [training: 0.0788045509156576 | validation: 0.09534124949615871]
	TIME [epoch: 8.42 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07130646607507488		[learning rate: 0.00011306]
	Learning Rate: 0.000113062
	LOSS [training: 0.07130646607507488 | validation: 0.12786663756168404]
	TIME [epoch: 8.4 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07177030674345422		[learning rate: 0.00011265]
	Learning Rate: 0.000112651
	LOSS [training: 0.07177030674345422 | validation: 0.09770693760237686]
	TIME [epoch: 8.41 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07208260183817664		[learning rate: 0.00011224]
	Learning Rate: 0.000112243
	LOSS [training: 0.07208260183817664 | validation: 0.08300269946440614]
	TIME [epoch: 8.4 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08870042851464084		[learning rate: 0.00011184]
	Learning Rate: 0.000111835
	LOSS [training: 0.08870042851464084 | validation: 0.10361377979676195]
	TIME [epoch: 8.42 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07595387729971907		[learning rate: 0.00011143]
	Learning Rate: 0.000111429
	LOSS [training: 0.07595387729971907 | validation: 0.07899066103426353]
	TIME [epoch: 8.4 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06133807846628064		[learning rate: 0.00011103]
	Learning Rate: 0.000111025
	LOSS [training: 0.06133807846628064 | validation: 0.08346268996943498]
	TIME [epoch: 8.4 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06606694706172077		[learning rate: 0.00011062]
	Learning Rate: 0.000110622
	LOSS [training: 0.06606694706172077 | validation: 0.08611224101558122]
	TIME [epoch: 8.4 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07049193663803696		[learning rate: 0.00011022]
	Learning Rate: 0.000110221
	LOSS [training: 0.07049193663803696 | validation: 0.0920630990956231]
	TIME [epoch: 8.43 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06329586076961077		[learning rate: 0.00010982]
	Learning Rate: 0.000109821
	LOSS [training: 0.06329586076961077 | validation: 0.10583439236454217]
	TIME [epoch: 8.41 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07814024667289673		[learning rate: 0.00010942]
	Learning Rate: 0.000109422
	LOSS [training: 0.07814024667289673 | validation: 0.0813784242091681]
	TIME [epoch: 8.4 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06494530768569581		[learning rate: 0.00010903]
	Learning Rate: 0.000109025
	LOSS [training: 0.06494530768569581 | validation: 0.07347672902627098]
	TIME [epoch: 8.4 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06729989323879557		[learning rate: 0.00010863]
	Learning Rate: 0.000108629
	LOSS [training: 0.06729989323879557 | validation: 0.0860094643597328]
	TIME [epoch: 8.42 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08223346518350723		[learning rate: 0.00010824]
	Learning Rate: 0.000108235
	LOSS [training: 0.08223346518350723 | validation: 0.08625931581073912]
	TIME [epoch: 8.4 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06867720381996427		[learning rate: 0.00010784]
	Learning Rate: 0.000107842
	LOSS [training: 0.06867720381996427 | validation: 0.09776835206672971]
	TIME [epoch: 8.4 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06568881120409625		[learning rate: 0.00010745]
	Learning Rate: 0.000107451
	LOSS [training: 0.06568881120409625 | validation: 0.09323690204841519]
	TIME [epoch: 8.4 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06403558787907136		[learning rate: 0.00010706]
	Learning Rate: 0.000107061
	LOSS [training: 0.06403558787907136 | validation: 0.08972843602706207]
	TIME [epoch: 8.42 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06413968446081927		[learning rate: 0.00010667]
	Learning Rate: 0.000106673
	LOSS [training: 0.06413968446081927 | validation: 0.07689084716436173]
	TIME [epoch: 8.4 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07108406488691126		[learning rate: 0.00010629]
	Learning Rate: 0.000106285
	LOSS [training: 0.07108406488691126 | validation: 0.10646266750235348]
	TIME [epoch: 8.4 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07329307430829936		[learning rate: 0.0001059]
	Learning Rate: 0.0001059
	LOSS [training: 0.07329307430829936 | validation: 0.10949660810353389]
	TIME [epoch: 8.4 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0814339127316368		[learning rate: 0.00010552]
	Learning Rate: 0.000105515
	LOSS [training: 0.0814339127316368 | validation: 0.07690167961425069]
	TIME [epoch: 8.42 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08488441310592224		[learning rate: 0.00010513]
	Learning Rate: 0.000105132
	LOSS [training: 0.08488441310592224 | validation: 0.07952386926335278]
	TIME [epoch: 8.4 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0814692532667582		[learning rate: 0.00010475]
	Learning Rate: 0.000104751
	LOSS [training: 0.0814692532667582 | validation: 0.0758891897334373]
	TIME [epoch: 8.4 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07563361182983126		[learning rate: 0.00010437]
	Learning Rate: 0.000104371
	LOSS [training: 0.07563361182983126 | validation: 0.0912132571104591]
	TIME [epoch: 8.4 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08389962424927026		[learning rate: 0.00010399]
	Learning Rate: 0.000103992
	LOSS [training: 0.08389962424927026 | validation: 0.09185332726112096]
	TIME [epoch: 8.43 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07624280425913031		[learning rate: 0.00010361]
	Learning Rate: 0.000103615
	LOSS [training: 0.07624280425913031 | validation: 0.0772743247552303]
	TIME [epoch: 8.4 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06696349495719853		[learning rate: 0.00010324]
	Learning Rate: 0.000103239
	LOSS [training: 0.06696349495719853 | validation: 0.09467179768269637]
	TIME [epoch: 8.4 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06720581790707422		[learning rate: 0.00010286]
	Learning Rate: 0.000102864
	LOSS [training: 0.06720581790707422 | validation: 0.07882685039229965]
	TIME [epoch: 8.4 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07769034096893433		[learning rate: 0.00010249]
	Learning Rate: 0.000102491
	LOSS [training: 0.07769034096893433 | validation: 0.0979735386072334]
	TIME [epoch: 8.43 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06583761146840228		[learning rate: 0.00010212]
	Learning Rate: 0.000102119
	LOSS [training: 0.06583761146840228 | validation: 0.09019603881717717]
	TIME [epoch: 8.4 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0719723341754817		[learning rate: 0.00010175]
	Learning Rate: 0.000101748
	LOSS [training: 0.0719723341754817 | validation: 0.09513375646796635]
	TIME [epoch: 8.4 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07565598586741529		[learning rate: 0.00010138]
	Learning Rate: 0.000101379
	LOSS [training: 0.07565598586741529 | validation: 0.09466265520196282]
	TIME [epoch: 8.4 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07653744589700946		[learning rate: 0.00010101]
	Learning Rate: 0.000101011
	LOSS [training: 0.07653744589700946 | validation: 0.08346914750254009]
	TIME [epoch: 8.42 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0826903856841489		[learning rate: 0.00010064]
	Learning Rate: 0.000100644
	LOSS [training: 0.0826903856841489 | validation: 0.0996386031414257]
	TIME [epoch: 8.4 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09907506884173585		[learning rate: 0.00010028]
	Learning Rate: 0.000100279
	LOSS [training: 0.09907506884173585 | validation: 0.1338374783424029]
	TIME [epoch: 8.4 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09788275787864867		[learning rate: 9.9915e-05]
	Learning Rate: 9.99152e-05
	LOSS [training: 0.09788275787864867 | validation: 0.08806323721427489]
	TIME [epoch: 8.41 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08383370415666516		[learning rate: 9.9553e-05]
	Learning Rate: 9.95526e-05
	LOSS [training: 0.08383370415666516 | validation: 0.09075492774411262]
	TIME [epoch: 8.43 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08360200696262572		[learning rate: 9.9191e-05]
	Learning Rate: 9.91913e-05
	LOSS [training: 0.08360200696262572 | validation: 0.1538050453041189]
	TIME [epoch: 8.4 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14271448565527273		[learning rate: 9.8831e-05]
	Learning Rate: 9.88314e-05
	LOSS [training: 0.14271448565527273 | validation: 0.08887761173833231]
	TIME [epoch: 8.41 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16627296545891124		[learning rate: 9.8473e-05]
	Learning Rate: 9.84727e-05
	LOSS [training: 0.16627296545891124 | validation: 0.1103160482575128]
	TIME [epoch: 8.41 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19542251547755346		[learning rate: 9.8115e-05]
	Learning Rate: 9.81153e-05
	LOSS [training: 0.19542251547755346 | validation: 0.10627194857996432]
	TIME [epoch: 8.42 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10988707663812666		[learning rate: 9.7759e-05]
	Learning Rate: 9.77592e-05
	LOSS [training: 0.10988707663812666 | validation: 0.09231861820119902]
	TIME [epoch: 8.4 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11554147291763468		[learning rate: 9.7404e-05]
	Learning Rate: 9.74045e-05
	LOSS [training: 0.11554147291763468 | validation: 0.08466400179512917]
	TIME [epoch: 8.4 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0817134703662549		[learning rate: 9.7051e-05]
	Learning Rate: 9.7051e-05
	LOSS [training: 0.0817134703662549 | validation: 0.10760124072885538]
	TIME [epoch: 8.41 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07782498648700616		[learning rate: 9.6699e-05]
	Learning Rate: 9.66988e-05
	LOSS [training: 0.07782498648700616 | validation: 0.09503393299251606]
	TIME [epoch: 8.42 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06999347950952335		[learning rate: 9.6348e-05]
	Learning Rate: 9.63479e-05
	LOSS [training: 0.06999347950952335 | validation: 0.1038779739705476]
	TIME [epoch: 8.4 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07144443751882168		[learning rate: 9.5998e-05]
	Learning Rate: 9.59982e-05
	LOSS [training: 0.07144443751882168 | validation: 0.11806853774998088]
	TIME [epoch: 8.4 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07806923584303463		[learning rate: 9.565e-05]
	Learning Rate: 9.56499e-05
	LOSS [training: 0.07806923584303463 | validation: 0.1003429000283214]
	TIME [epoch: 8.41 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06806104865136209		[learning rate: 9.5303e-05]
	Learning Rate: 9.53027e-05
	LOSS [training: 0.06806104865136209 | validation: 0.1138028471292494]
	TIME [epoch: 8.41 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07056869225903187		[learning rate: 9.4957e-05]
	Learning Rate: 9.49569e-05
	LOSS [training: 0.07056869225903187 | validation: 0.09732095940657573]
	TIME [epoch: 8.41 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06806848782324686		[learning rate: 9.4612e-05]
	Learning Rate: 9.46122e-05
	LOSS [training: 0.06806848782324686 | validation: 0.08223858545201526]
	TIME [epoch: 8.4 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07122495127374374		[learning rate: 9.4269e-05]
	Learning Rate: 9.42689e-05
	LOSS [training: 0.07122495127374374 | validation: 0.08742103416475241]
	TIME [epoch: 8.41 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061225832435889416		[learning rate: 9.3927e-05]
	Learning Rate: 9.39268e-05
	LOSS [training: 0.061225832435889416 | validation: 0.08832951092826638]
	TIME [epoch: 8.42 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06575353516557403		[learning rate: 9.3586e-05]
	Learning Rate: 9.35859e-05
	LOSS [training: 0.06575353516557403 | validation: 0.09818636086816696]
	TIME [epoch: 8.4 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0834572185870564		[learning rate: 9.3246e-05]
	Learning Rate: 9.32463e-05
	LOSS [training: 0.0834572185870564 | validation: 0.1100755671567156]
	TIME [epoch: 8.4 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06752339895883623		[learning rate: 9.2908e-05]
	Learning Rate: 9.29079e-05
	LOSS [training: 0.06752339895883623 | validation: 0.10606351447310991]
	TIME [epoch: 8.42 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08871084665010545		[learning rate: 9.2571e-05]
	Learning Rate: 9.25707e-05
	LOSS [training: 0.08871084665010545 | validation: 0.09899848707826142]
	TIME [epoch: 8.41 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07227309889227636		[learning rate: 9.2235e-05]
	Learning Rate: 9.22348e-05
	LOSS [training: 0.07227309889227636 | validation: 0.1184141568343982]
	TIME [epoch: 8.41 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06782221944610514		[learning rate: 9.19e-05]
	Learning Rate: 9.19001e-05
	LOSS [training: 0.06782221944610514 | validation: 0.10155531804168574]
	TIME [epoch: 8.4 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06471574471427857		[learning rate: 9.1567e-05]
	Learning Rate: 9.15665e-05
	LOSS [training: 0.06471574471427857 | validation: 0.10493975199901569]
	TIME [epoch: 8.42 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062140513411002386		[learning rate: 9.1234e-05]
	Learning Rate: 9.12343e-05
	LOSS [training: 0.062140513411002386 | validation: 0.11661558519811716]
	TIME [epoch: 8.41 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06838864615373366		[learning rate: 9.0903e-05]
	Learning Rate: 9.09031e-05
	LOSS [training: 0.06838864615373366 | validation: 0.10941698174103356]
	TIME [epoch: 8.4 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06855626244326396		[learning rate: 9.0573e-05]
	Learning Rate: 9.05733e-05
	LOSS [training: 0.06855626244326396 | validation: 0.12054072593169268]
	TIME [epoch: 8.4 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07436316667268762		[learning rate: 9.0245e-05]
	Learning Rate: 9.02446e-05
	LOSS [training: 0.07436316667268762 | validation: 0.10234494296463169]
	TIME [epoch: 8.43 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062468271903776317		[learning rate: 8.9917e-05]
	Learning Rate: 8.99171e-05
	LOSS [training: 0.062468271903776317 | validation: 0.08301165446198273]
	TIME [epoch: 8.41 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07044885471670845		[learning rate: 8.9591e-05]
	Learning Rate: 8.95908e-05
	LOSS [training: 0.07044885471670845 | validation: 0.09440963526172805]
	TIME [epoch: 8.4 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07099135701799195		[learning rate: 8.9266e-05]
	Learning Rate: 8.92656e-05
	LOSS [training: 0.07099135701799195 | validation: 0.09421111315934044]
	TIME [epoch: 8.4 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07629082165136067		[learning rate: 8.8942e-05]
	Learning Rate: 8.89417e-05
	LOSS [training: 0.07629082165136067 | validation: 0.09713882459443957]
	TIME [epoch: 8.43 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10152213910401453		[learning rate: 8.8619e-05]
	Learning Rate: 8.86189e-05
	LOSS [training: 0.10152213910401453 | validation: 0.08800586616189904]
	TIME [epoch: 8.4 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07755704245762908		[learning rate: 8.8297e-05]
	Learning Rate: 8.82973e-05
	LOSS [training: 0.07755704245762908 | validation: 0.08246721111433322]
	TIME [epoch: 8.4 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06440093172482729		[learning rate: 8.7977e-05]
	Learning Rate: 8.79769e-05
	LOSS [training: 0.06440093172482729 | validation: 0.109058482261375]
	TIME [epoch: 8.4 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07015986208810657		[learning rate: 8.7658e-05]
	Learning Rate: 8.76576e-05
	LOSS [training: 0.07015986208810657 | validation: 0.08997959076461709]
	TIME [epoch: 8.43 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07339492659603693		[learning rate: 8.7339e-05]
	Learning Rate: 8.73395e-05
	LOSS [training: 0.07339492659603693 | validation: 0.09565148820584102]
	TIME [epoch: 8.41 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07392105505801862		[learning rate: 8.7023e-05]
	Learning Rate: 8.70225e-05
	LOSS [training: 0.07392105505801862 | validation: 0.09436096025485996]
	TIME [epoch: 8.4 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11151039194772283		[learning rate: 8.6707e-05]
	Learning Rate: 8.67067e-05
	LOSS [training: 0.11151039194772283 | validation: 0.07914278999007389]
	TIME [epoch: 8.4 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08065614225026355		[learning rate: 8.6392e-05]
	Learning Rate: 8.63921e-05
	LOSS [training: 0.08065614225026355 | validation: 0.07488328156856898]
	TIME [epoch: 8.42 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10067045874516614		[learning rate: 8.6079e-05]
	Learning Rate: 8.60785e-05
	LOSS [training: 0.10067045874516614 | validation: 0.11837565241660893]
	TIME [epoch: 8.4 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.166643241880314		[learning rate: 8.5766e-05]
	Learning Rate: 8.57661e-05
	LOSS [training: 0.166643241880314 | validation: 0.11619175661833171]
	TIME [epoch: 8.41 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11002280690139361		[learning rate: 8.5455e-05]
	Learning Rate: 8.54549e-05
	LOSS [training: 0.11002280690139361 | validation: 0.09762973280500914]
	TIME [epoch: 8.4 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08016390896420883		[learning rate: 8.5145e-05]
	Learning Rate: 8.51448e-05
	LOSS [training: 0.08016390896420883 | validation: 0.06678791849198351]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_1411.pth
	Model improved!!!
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09105094851836187		[learning rate: 8.4836e-05]
	Learning Rate: 8.48358e-05
	LOSS [training: 0.09105094851836187 | validation: 0.07133136934102431]
	TIME [epoch: 8.41 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06983314324894785		[learning rate: 8.4528e-05]
	Learning Rate: 8.45279e-05
	LOSS [training: 0.06983314324894785 | validation: 0.10342616538985963]
	TIME [epoch: 8.41 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05913233644685224		[learning rate: 8.4221e-05]
	Learning Rate: 8.42211e-05
	LOSS [training: 0.05913233644685224 | validation: 0.10392965366806546]
	TIME [epoch: 8.4 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06481679476127347		[learning rate: 8.3916e-05]
	Learning Rate: 8.39155e-05
	LOSS [training: 0.06481679476127347 | validation: 0.12259518284022945]
	TIME [epoch: 8.43 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06700428542637912		[learning rate: 8.3611e-05]
	Learning Rate: 8.3611e-05
	LOSS [training: 0.06700428542637912 | validation: 0.0989649583949111]
	TIME [epoch: 8.4 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07043331851593485		[learning rate: 8.3308e-05]
	Learning Rate: 8.33075e-05
	LOSS [training: 0.07043331851593485 | validation: 0.11105690724356668]
	TIME [epoch: 8.41 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08232788420044232		[learning rate: 8.3005e-05]
	Learning Rate: 8.30052e-05
	LOSS [training: 0.08232788420044232 | validation: 0.11377125428373885]
	TIME [epoch: 8.4 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06489976083610349		[learning rate: 8.2704e-05]
	Learning Rate: 8.2704e-05
	LOSS [training: 0.06489976083610349 | validation: 0.09776500575904738]
	TIME [epoch: 8.43 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06630993704839518		[learning rate: 8.2404e-05]
	Learning Rate: 8.24038e-05
	LOSS [training: 0.06630993704839518 | validation: 0.10304869930457133]
	TIME [epoch: 8.4 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07453645216410298		[learning rate: 8.2105e-05]
	Learning Rate: 8.21048e-05
	LOSS [training: 0.07453645216410298 | validation: 0.07862281364510121]
	TIME [epoch: 8.4 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06566914642549719		[learning rate: 8.1807e-05]
	Learning Rate: 8.18068e-05
	LOSS [training: 0.06566914642549719 | validation: 0.09655452202541887]
	TIME [epoch: 8.41 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06776725042031641		[learning rate: 8.151e-05]
	Learning Rate: 8.15099e-05
	LOSS [training: 0.06776725042031641 | validation: 0.09253385585589181]
	TIME [epoch: 8.43 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06984623514090685		[learning rate: 8.1214e-05]
	Learning Rate: 8.12142e-05
	LOSS [training: 0.06984623514090685 | validation: 0.10168962025380929]
	TIME [epoch: 8.41 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06472602044085238		[learning rate: 8.0919e-05]
	Learning Rate: 8.09194e-05
	LOSS [training: 0.06472602044085238 | validation: 0.09310145371909828]
	TIME [epoch: 8.41 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06873840807739767		[learning rate: 8.0626e-05]
	Learning Rate: 8.06257e-05
	LOSS [training: 0.06873840807739767 | validation: 0.11103226779576081]
	TIME [epoch: 8.4 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06607777974023846		[learning rate: 8.0333e-05]
	Learning Rate: 8.03331e-05
	LOSS [training: 0.06607777974023846 | validation: 0.11923925809523897]
	TIME [epoch: 8.43 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07159846368790736		[learning rate: 8.0042e-05]
	Learning Rate: 8.00416e-05
	LOSS [training: 0.07159846368790736 | validation: 0.11452392482115986]
	TIME [epoch: 8.4 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06393077621178536		[learning rate: 7.9751e-05]
	Learning Rate: 7.97511e-05
	LOSS [training: 0.06393077621178536 | validation: 0.1047394469328928]
	TIME [epoch: 8.41 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07314160026857651		[learning rate: 7.9462e-05]
	Learning Rate: 7.94617e-05
	LOSS [training: 0.07314160026857651 | validation: 0.09729839193244319]
	TIME [epoch: 8.41 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07169645101213755		[learning rate: 7.9173e-05]
	Learning Rate: 7.91733e-05
	LOSS [training: 0.07169645101213755 | validation: 0.09349722422965706]
	TIME [epoch: 8.42 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062041587239846006		[learning rate: 7.8886e-05]
	Learning Rate: 7.8886e-05
	LOSS [training: 0.062041587239846006 | validation: 0.1020190701852843]
	TIME [epoch: 8.41 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06926627737708746		[learning rate: 7.86e-05]
	Learning Rate: 7.85997e-05
	LOSS [training: 0.06926627737708746 | validation: 0.11478344508475521]
	TIME [epoch: 8.41 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07290891381677192		[learning rate: 7.8315e-05]
	Learning Rate: 7.83145e-05
	LOSS [training: 0.07290891381677192 | validation: 0.11610102577068512]
	TIME [epoch: 8.42 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0716931880865805		[learning rate: 7.803e-05]
	Learning Rate: 7.80303e-05
	LOSS [training: 0.0716931880865805 | validation: 0.10077605101601238]
	TIME [epoch: 8.42 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07086152910946233		[learning rate: 7.7747e-05]
	Learning Rate: 7.77471e-05
	LOSS [training: 0.07086152910946233 | validation: 0.0902593510652906]
	TIME [epoch: 8.41 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06599049778910697		[learning rate: 7.7465e-05]
	Learning Rate: 7.7465e-05
	LOSS [training: 0.06599049778910697 | validation: 0.07825463015025091]
	TIME [epoch: 8.4 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06404192923761255		[learning rate: 7.7184e-05]
	Learning Rate: 7.71838e-05
	LOSS [training: 0.06404192923761255 | validation: 0.09324424631275538]
	TIME [epoch: 8.41 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06692055162509644		[learning rate: 7.6904e-05]
	Learning Rate: 7.69037e-05
	LOSS [training: 0.06692055162509644 | validation: 0.10023482944722975]
	TIME [epoch: 8.42 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06576048240373668		[learning rate: 7.6625e-05]
	Learning Rate: 7.66246e-05
	LOSS [training: 0.06576048240373668 | validation: 0.11558467369412599]
	TIME [epoch: 8.4 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07008581906176937		[learning rate: 7.6347e-05]
	Learning Rate: 7.63466e-05
	LOSS [training: 0.07008581906176937 | validation: 0.11304651797372564]
	TIME [epoch: 8.41 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06796796891415434		[learning rate: 7.607e-05]
	Learning Rate: 7.60695e-05
	LOSS [training: 0.06796796891415434 | validation: 0.1079556295520256]
	TIME [epoch: 8.42 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0710475564026567		[learning rate: 7.5793e-05]
	Learning Rate: 7.57935e-05
	LOSS [training: 0.0710475564026567 | validation: 0.11129095319882652]
	TIME [epoch: 8.41 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0629437070422416		[learning rate: 7.5518e-05]
	Learning Rate: 7.55184e-05
	LOSS [training: 0.0629437070422416 | validation: 0.09930873459469847]
	TIME [epoch: 8.4 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06963953194200115		[learning rate: 7.5244e-05]
	Learning Rate: 7.52443e-05
	LOSS [training: 0.06963953194200115 | validation: 0.1045114470864331]
	TIME [epoch: 8.4 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07144425673834956		[learning rate: 7.4971e-05]
	Learning Rate: 7.49712e-05
	LOSS [training: 0.07144425673834956 | validation: 0.09967560900150813]
	TIME [epoch: 8.42 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06644179813127184		[learning rate: 7.4699e-05]
	Learning Rate: 7.46992e-05
	LOSS [training: 0.06644179813127184 | validation: 0.09190379190510567]
	TIME [epoch: 8.41 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07569336030312965		[learning rate: 7.4428e-05]
	Learning Rate: 7.44281e-05
	LOSS [training: 0.07569336030312965 | validation: 0.08876214436530067]
	TIME [epoch: 8.4 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0645930180312567		[learning rate: 7.4158e-05]
	Learning Rate: 7.4158e-05
	LOSS [training: 0.0645930180312567 | validation: 0.09180366222691648]
	TIME [epoch: 8.4 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06907765699491783		[learning rate: 7.3889e-05]
	Learning Rate: 7.38889e-05
	LOSS [training: 0.06907765699491783 | validation: 0.08542557867570155]
	TIME [epoch: 8.42 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06031714302882839		[learning rate: 7.3621e-05]
	Learning Rate: 7.36207e-05
	LOSS [training: 0.06031714302882839 | validation: 0.0823849489782777]
	TIME [epoch: 8.41 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0676284344795607		[learning rate: 7.3354e-05]
	Learning Rate: 7.33536e-05
	LOSS [training: 0.0676284344795607 | validation: 0.09256454609201986]
	TIME [epoch: 8.4 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07562321195757347		[learning rate: 7.3087e-05]
	Learning Rate: 7.30873e-05
	LOSS [training: 0.07562321195757347 | validation: 0.06737694615916485]
	TIME [epoch: 8.4 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07410019482236997		[learning rate: 7.2822e-05]
	Learning Rate: 7.28221e-05
	LOSS [training: 0.07410019482236997 | validation: 0.0873461412232405]
	TIME [epoch: 8.43 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06655434212266195		[learning rate: 7.2558e-05]
	Learning Rate: 7.25578e-05
	LOSS [training: 0.06655434212266195 | validation: 0.08291889707959288]
	TIME [epoch: 8.41 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07154591990031847		[learning rate: 7.2295e-05]
	Learning Rate: 7.22945e-05
	LOSS [training: 0.07154591990031847 | validation: 0.07690018306051291]
	TIME [epoch: 8.41 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07350931967899228		[learning rate: 7.2032e-05]
	Learning Rate: 7.20321e-05
	LOSS [training: 0.07350931967899228 | validation: 0.08789414394805485]
	TIME [epoch: 8.41 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07746206795285264		[learning rate: 7.1771e-05]
	Learning Rate: 7.17707e-05
	LOSS [training: 0.07746206795285264 | validation: 0.06841145971893219]
	TIME [epoch: 8.43 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09397765860640521		[learning rate: 7.151e-05]
	Learning Rate: 7.15103e-05
	LOSS [training: 0.09397765860640521 | validation: 0.08310155723533923]
	TIME [epoch: 8.41 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11927959230001761		[learning rate: 7.1251e-05]
	Learning Rate: 7.12508e-05
	LOSS [training: 0.11927959230001761 | validation: 0.08699669159861688]
	TIME [epoch: 8.4 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09156906726211331		[learning rate: 7.0992e-05]
	Learning Rate: 7.09922e-05
	LOSS [training: 0.09156906726211331 | validation: 0.09411813157931867]
	TIME [epoch: 8.4 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0692127179099787		[learning rate: 7.0735e-05]
	Learning Rate: 7.07345e-05
	LOSS [training: 0.0692127179099787 | validation: 0.08996638018828781]
	TIME [epoch: 8.43 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06130008284512754		[learning rate: 7.0478e-05]
	Learning Rate: 7.04778e-05
	LOSS [training: 0.06130008284512754 | validation: 0.07152341512911403]
	TIME [epoch: 8.4 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08318351185508979		[learning rate: 7.0222e-05]
	Learning Rate: 7.02221e-05
	LOSS [training: 0.08318351185508979 | validation: 0.08366635892958871]
	TIME [epoch: 8.4 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12634662833574845		[learning rate: 6.9967e-05]
	Learning Rate: 6.99672e-05
	LOSS [training: 0.12634662833574845 | validation: 0.1192227105333527]
	TIME [epoch: 8.41 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11022824169528771		[learning rate: 6.9713e-05]
	Learning Rate: 6.97133e-05
	LOSS [training: 0.11022824169528771 | validation: 0.10159305609289225]
	TIME [epoch: 8.43 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07707133834878807		[learning rate: 6.946e-05]
	Learning Rate: 6.94603e-05
	LOSS [training: 0.07707133834878807 | validation: 0.09833865087562574]
	TIME [epoch: 8.4 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07046366604459085		[learning rate: 6.9208e-05]
	Learning Rate: 6.92083e-05
	LOSS [training: 0.07046366604459085 | validation: 0.0754109416829361]
	TIME [epoch: 8.4 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08006706236330631		[learning rate: 6.8957e-05]
	Learning Rate: 6.89571e-05
	LOSS [training: 0.08006706236330631 | validation: 0.07389898782996315]
	TIME [epoch: 8.4 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0691786147240662		[learning rate: 6.8707e-05]
	Learning Rate: 6.87068e-05
	LOSS [training: 0.0691786147240662 | validation: 0.0835154460977775]
	TIME [epoch: 8.43 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06818343200931157		[learning rate: 6.8457e-05]
	Learning Rate: 6.84575e-05
	LOSS [training: 0.06818343200931157 | validation: 0.09690291024556244]
	TIME [epoch: 8.4 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08771700543985883		[learning rate: 6.8209e-05]
	Learning Rate: 6.82091e-05
	LOSS [training: 0.08771700543985883 | validation: 0.08531723297555131]
	TIME [epoch: 8.41 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.093252339715326		[learning rate: 6.7962e-05]
	Learning Rate: 6.79615e-05
	LOSS [training: 0.093252339715326 | validation: 0.07762707835358862]
	TIME [epoch: 8.4 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07980745672433812		[learning rate: 6.7715e-05]
	Learning Rate: 6.77149e-05
	LOSS [training: 0.07980745672433812 | validation: 0.07561211847061555]
	TIME [epoch: 8.43 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08790955357891449		[learning rate: 6.7469e-05]
	Learning Rate: 6.74692e-05
	LOSS [training: 0.08790955357891449 | validation: 0.08575410076565969]
	TIME [epoch: 8.41 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07966724080733682		[learning rate: 6.7224e-05]
	Learning Rate: 6.72243e-05
	LOSS [training: 0.07966724080733682 | validation: 0.10237217678965163]
	TIME [epoch: 8.41 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06519009412922115		[learning rate: 6.698e-05]
	Learning Rate: 6.69804e-05
	LOSS [training: 0.06519009412922115 | validation: 0.10710451155814465]
	TIME [epoch: 8.4 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07166647116686155		[learning rate: 6.6737e-05]
	Learning Rate: 6.67373e-05
	LOSS [training: 0.07166647116686155 | validation: 0.08093716064482237]
	TIME [epoch: 8.43 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06552706138691927		[learning rate: 6.6495e-05]
	Learning Rate: 6.64951e-05
	LOSS [training: 0.06552706138691927 | validation: 0.07814473311034456]
	TIME [epoch: 8.41 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06267126125951429		[learning rate: 6.6254e-05]
	Learning Rate: 6.62538e-05
	LOSS [training: 0.06267126125951429 | validation: 0.08135127852018306]
	TIME [epoch: 8.4 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06298927833900234		[learning rate: 6.6013e-05]
	Learning Rate: 6.60133e-05
	LOSS [training: 0.06298927833900234 | validation: 0.08295683316080565]
	TIME [epoch: 8.4 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07562017427707908		[learning rate: 6.5774e-05]
	Learning Rate: 6.57738e-05
	LOSS [training: 0.07562017427707908 | validation: 0.09107644553631189]
	TIME [epoch: 8.43 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05979756299263143		[learning rate: 6.5535e-05]
	Learning Rate: 6.55351e-05
	LOSS [training: 0.05979756299263143 | validation: 0.12081447102163559]
	TIME [epoch: 8.4 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06117964311315157		[learning rate: 6.5297e-05]
	Learning Rate: 6.52972e-05
	LOSS [training: 0.06117964311315157 | validation: 0.10472298700633925]
	TIME [epoch: 8.41 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061463581986014634		[learning rate: 6.506e-05]
	Learning Rate: 6.50603e-05
	LOSS [training: 0.061463581986014634 | validation: 0.08918622753835248]
	TIME [epoch: 8.4 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06270966040326227		[learning rate: 6.4824e-05]
	Learning Rate: 6.48242e-05
	LOSS [training: 0.06270966040326227 | validation: 0.08210237129048499]
	TIME [epoch: 8.43 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0645969449848781		[learning rate: 6.4589e-05]
	Learning Rate: 6.45889e-05
	LOSS [training: 0.0645969449848781 | validation: 0.08094702388750219]
	TIME [epoch: 8.4 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06434069815167923		[learning rate: 6.4354e-05]
	Learning Rate: 6.43545e-05
	LOSS [training: 0.06434069815167923 | validation: 0.0945348058113791]
	TIME [epoch: 8.4 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06891995401028002		[learning rate: 6.4121e-05]
	Learning Rate: 6.4121e-05
	LOSS [training: 0.06891995401028002 | validation: 0.08270595925765997]
	TIME [epoch: 8.42 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058714581125563145		[learning rate: 6.3888e-05]
	Learning Rate: 6.38883e-05
	LOSS [training: 0.058714581125563145 | validation: 0.09692397134907185]
	TIME [epoch: 8.42 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0717641848496585		[learning rate: 6.3656e-05]
	Learning Rate: 6.36564e-05
	LOSS [training: 0.0717641848496585 | validation: 0.09212753974272803]
	TIME [epoch: 8.41 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06296922367085464		[learning rate: 6.3425e-05]
	Learning Rate: 6.34254e-05
	LOSS [training: 0.06296922367085464 | validation: 0.09106893532380345]
	TIME [epoch: 8.4 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05896589060898451		[learning rate: 6.3195e-05]
	Learning Rate: 6.31952e-05
	LOSS [training: 0.05896589060898451 | validation: 0.09623655982553592]
	TIME [epoch: 8.42 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06592181420633805		[learning rate: 6.2966e-05]
	Learning Rate: 6.29659e-05
	LOSS [training: 0.06592181420633805 | validation: 0.10099242408007983]
	TIME [epoch: 8.42 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723481610228018		[learning rate: 6.2737e-05]
	Learning Rate: 6.27374e-05
	LOSS [training: 0.0723481610228018 | validation: 0.09044712151664297]
	TIME [epoch: 8.41 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06745645669568465		[learning rate: 6.251e-05]
	Learning Rate: 6.25097e-05
	LOSS [training: 0.06745645669568465 | validation: 0.09238663703338384]
	TIME [epoch: 8.4 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06885779816327485		[learning rate: 6.2283e-05]
	Learning Rate: 6.22828e-05
	LOSS [training: 0.06885779816327485 | validation: 0.09934509924777926]
	TIME [epoch: 8.41 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07284559937397068		[learning rate: 6.2057e-05]
	Learning Rate: 6.20568e-05
	LOSS [training: 0.07284559937397068 | validation: 0.10585235754661992]
	TIME [epoch: 8.42 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06526837094330418		[learning rate: 6.1832e-05]
	Learning Rate: 6.18316e-05
	LOSS [training: 0.06526837094330418 | validation: 0.09185087271588661]
	TIME [epoch: 8.41 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06324461852131122		[learning rate: 6.1607e-05]
	Learning Rate: 6.16072e-05
	LOSS [training: 0.06324461852131122 | validation: 0.09066637415385156]
	TIME [epoch: 8.41 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061867761040349425		[learning rate: 6.1384e-05]
	Learning Rate: 6.13836e-05
	LOSS [training: 0.061867761040349425 | validation: 0.09500209494208384]
	TIME [epoch: 8.42 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06564352530913363		[learning rate: 6.1161e-05]
	Learning Rate: 6.11609e-05
	LOSS [training: 0.06564352530913363 | validation: 0.0995456751154696]
	TIME [epoch: 8.41 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0710428856807831		[learning rate: 6.0939e-05]
	Learning Rate: 6.09389e-05
	LOSS [training: 0.0710428856807831 | validation: 0.0989687312094108]
	TIME [epoch: 8.4 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07520098643774147		[learning rate: 6.0718e-05]
	Learning Rate: 6.07178e-05
	LOSS [training: 0.07520098643774147 | validation: 0.0979773338324206]
	TIME [epoch: 8.4 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06775612267358419		[learning rate: 6.0497e-05]
	Learning Rate: 6.04974e-05
	LOSS [training: 0.06775612267358419 | validation: 0.11133374281967304]
	TIME [epoch: 8.43 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06908573323069102		[learning rate: 6.0278e-05]
	Learning Rate: 6.02779e-05
	LOSS [training: 0.06908573323069102 | validation: 0.09279243851508787]
	TIME [epoch: 8.4 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06478383979867988		[learning rate: 6.0059e-05]
	Learning Rate: 6.00591e-05
	LOSS [training: 0.06478383979867988 | validation: 0.09609070264568068]
	TIME [epoch: 8.41 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06516543425892672		[learning rate: 5.9841e-05]
	Learning Rate: 5.98412e-05
	LOSS [training: 0.06516543425892672 | validation: 0.09595508973033584]
	TIME [epoch: 8.41 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06162390504490164		[learning rate: 5.9624e-05]
	Learning Rate: 5.9624e-05
	LOSS [training: 0.06162390504490164 | validation: 0.0974201856213694]
	TIME [epoch: 8.43 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0631766780987549		[learning rate: 5.9408e-05]
	Learning Rate: 5.94076e-05
	LOSS [training: 0.0631766780987549 | validation: 0.10190992657782916]
	TIME [epoch: 8.41 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06984790017901923		[learning rate: 5.9192e-05]
	Learning Rate: 5.9192e-05
	LOSS [training: 0.06984790017901923 | validation: 0.09192370879248225]
	TIME [epoch: 8.41 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06615808581859675		[learning rate: 5.8977e-05]
	Learning Rate: 5.89772e-05
	LOSS [training: 0.06615808581859675 | validation: 0.08452744345783539]
	TIME [epoch: 8.4 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06755557144948475		[learning rate: 5.8763e-05]
	Learning Rate: 5.87632e-05
	LOSS [training: 0.06755557144948475 | validation: 0.10637087363013004]
	TIME [epoch: 8.43 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07415722961025387		[learning rate: 5.855e-05]
	Learning Rate: 5.85499e-05
	LOSS [training: 0.07415722961025387 | validation: 0.09156992006262085]
	TIME [epoch: 8.41 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06688739728256092		[learning rate: 5.8337e-05]
	Learning Rate: 5.83374e-05
	LOSS [training: 0.06688739728256092 | validation: 0.08736648167671643]
	TIME [epoch: 8.41 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0609681558733428		[learning rate: 5.8126e-05]
	Learning Rate: 5.81257e-05
	LOSS [training: 0.0609681558733428 | validation: 0.08521444071637188]
	TIME [epoch: 8.41 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06528338604681948		[learning rate: 5.7915e-05]
	Learning Rate: 5.79148e-05
	LOSS [training: 0.06528338604681948 | validation: 0.10369987626452014]
	TIME [epoch: 8.44 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06859526776329847		[learning rate: 5.7705e-05]
	Learning Rate: 5.77046e-05
	LOSS [training: 0.06859526776329847 | validation: 0.09733172373828637]
	TIME [epoch: 8.41 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0688152071729098		[learning rate: 5.7495e-05]
	Learning Rate: 5.74952e-05
	LOSS [training: 0.0688152071729098 | validation: 0.09831337831230183]
	TIME [epoch: 8.41 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05969247004319689		[learning rate: 5.7287e-05]
	Learning Rate: 5.72866e-05
	LOSS [training: 0.05969247004319689 | validation: 0.09389057903311412]
	TIME [epoch: 8.41 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06340478583373735		[learning rate: 5.7079e-05]
	Learning Rate: 5.70787e-05
	LOSS [training: 0.06340478583373735 | validation: 0.0855503122377909]
	TIME [epoch: 8.43 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07838950952989639		[learning rate: 5.6872e-05]
	Learning Rate: 5.68715e-05
	LOSS [training: 0.07838950952989639 | validation: 0.10702251816076531]
	TIME [epoch: 8.41 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08452268825443095		[learning rate: 5.6665e-05]
	Learning Rate: 5.66651e-05
	LOSS [training: 0.08452268825443095 | validation: 0.07958305787847725]
	TIME [epoch: 8.41 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07752575432251299		[learning rate: 5.6459e-05]
	Learning Rate: 5.64595e-05
	LOSS [training: 0.07752575432251299 | validation: 0.1008701006548884]
	TIME [epoch: 8.41 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0870097701040689		[learning rate: 5.6255e-05]
	Learning Rate: 5.62546e-05
	LOSS [training: 0.0870097701040689 | validation: 0.07963067476205096]
	TIME [epoch: 8.43 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08194357459867621		[learning rate: 5.605e-05]
	Learning Rate: 5.60504e-05
	LOSS [training: 0.08194357459867621 | validation: 0.08452972720767536]
	TIME [epoch: 8.41 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07948871764358634		[learning rate: 5.5847e-05]
	Learning Rate: 5.5847e-05
	LOSS [training: 0.07948871764358634 | validation: 0.08109451724246795]
	TIME [epoch: 8.41 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08342460643653786		[learning rate: 5.5644e-05]
	Learning Rate: 5.56444e-05
	LOSS [training: 0.08342460643653786 | validation: 0.07550383726097604]
	TIME [epoch: 8.41 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09092332934732858		[learning rate: 5.5442e-05]
	Learning Rate: 5.54424e-05
	LOSS [training: 0.09092332934732858 | validation: 0.10464634949214646]
	TIME [epoch: 8.44 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13052711087082988		[learning rate: 5.5241e-05]
	Learning Rate: 5.52412e-05
	LOSS [training: 0.13052711087082988 | validation: 0.10183035744767072]
	TIME [epoch: 8.4 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.113596324773472		[learning rate: 5.5041e-05]
	Learning Rate: 5.50407e-05
	LOSS [training: 0.113596324773472 | validation: 0.0901162824011756]
	TIME [epoch: 8.41 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10192265923327733		[learning rate: 5.4841e-05]
	Learning Rate: 5.4841e-05
	LOSS [training: 0.10192265923327733 | validation: 0.09796321495272464]
	TIME [epoch: 8.41 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07763303924851168		[learning rate: 5.4642e-05]
	Learning Rate: 5.4642e-05
	LOSS [training: 0.07763303924851168 | validation: 0.10760373704344718]
	TIME [epoch: 8.44 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07366257737420173		[learning rate: 5.4444e-05]
	Learning Rate: 5.44437e-05
	LOSS [training: 0.07366257737420173 | validation: 0.07720349062656143]
	TIME [epoch: 8.41 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08229290868526104		[learning rate: 5.4246e-05]
	Learning Rate: 5.42461e-05
	LOSS [training: 0.08229290868526104 | validation: 0.0814425691883339]
	TIME [epoch: 8.41 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08331140173148152		[learning rate: 5.4049e-05]
	Learning Rate: 5.40492e-05
	LOSS [training: 0.08331140173148152 | validation: 0.07368842891289937]
	TIME [epoch: 8.4 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07534766749832975		[learning rate: 5.3853e-05]
	Learning Rate: 5.38531e-05
	LOSS [training: 0.07534766749832975 | validation: 0.09428072249672059]
	TIME [epoch: 8.43 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07470511324569963		[learning rate: 5.3658e-05]
	Learning Rate: 5.36577e-05
	LOSS [training: 0.07470511324569963 | validation: 0.07830801551832128]
	TIME [epoch: 8.41 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08318367232961452		[learning rate: 5.3463e-05]
	Learning Rate: 5.34629e-05
	LOSS [training: 0.08318367232961452 | validation: 0.11337940148603474]
	TIME [epoch: 8.41 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07216010866931058		[learning rate: 5.3269e-05]
	Learning Rate: 5.32689e-05
	LOSS [training: 0.07216010866931058 | validation: 0.10753997577561861]
	TIME [epoch: 8.42 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06500517454037366		[learning rate: 5.3076e-05]
	Learning Rate: 5.30756e-05
	LOSS [training: 0.06500517454037366 | validation: 0.08554551585772853]
	TIME [epoch: 8.43 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06304283276574443		[learning rate: 5.2883e-05]
	Learning Rate: 5.2883e-05
	LOSS [training: 0.06304283276574443 | validation: 0.0976511718699817]
	TIME [epoch: 8.41 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06617207682276138		[learning rate: 5.2691e-05]
	Learning Rate: 5.26911e-05
	LOSS [training: 0.06617207682276138 | validation: 0.09103159923735712]
	TIME [epoch: 8.41 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06339423730887303		[learning rate: 5.25e-05]
	Learning Rate: 5.24998e-05
	LOSS [training: 0.06339423730887303 | validation: 0.08805151608941367]
	TIME [epoch: 8.41 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06297265289278497		[learning rate: 5.2309e-05]
	Learning Rate: 5.23093e-05
	LOSS [training: 0.06297265289278497 | validation: 0.09336821136630638]
	TIME [epoch: 8.42 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06727592348411886		[learning rate: 5.2119e-05]
	Learning Rate: 5.21195e-05
	LOSS [training: 0.06727592348411886 | validation: 0.09289307324578189]
	TIME [epoch: 8.41 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06677549571513827		[learning rate: 5.193e-05]
	Learning Rate: 5.19303e-05
	LOSS [training: 0.06677549571513827 | validation: 0.09507169990449249]
	TIME [epoch: 8.4 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07516202150285721		[learning rate: 5.1742e-05]
	Learning Rate: 5.17419e-05
	LOSS [training: 0.07516202150285721 | validation: 0.08630758203467889]
	TIME [epoch: 8.43 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07373323520209998		[learning rate: 5.1554e-05]
	Learning Rate: 5.15541e-05
	LOSS [training: 0.07373323520209998 | validation: 0.08658925082591887]
	TIME [epoch: 8.42 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06941016447725679		[learning rate: 5.1367e-05]
	Learning Rate: 5.1367e-05
	LOSS [training: 0.06941016447725679 | validation: 0.08762828251178598]
	TIME [epoch: 8.41 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0943676870830164		[learning rate: 5.1181e-05]
	Learning Rate: 5.11806e-05
	LOSS [training: 0.0943676870830164 | validation: 0.09043810193527893]
	TIME [epoch: 8.41 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10175659735485894		[learning rate: 5.0995e-05]
	Learning Rate: 5.09949e-05
	LOSS [training: 0.10175659735485894 | validation: 0.10301416509138694]
	TIME [epoch: 8.42 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16840289515195406		[learning rate: 5.081e-05]
	Learning Rate: 5.08098e-05
	LOSS [training: 0.16840289515195406 | validation: 0.13735324657769757]
	TIME [epoch: 8.42 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.160570130347598		[learning rate: 5.0625e-05]
	Learning Rate: 5.06254e-05
	LOSS [training: 0.160570130347598 | validation: 0.09726165784571247]
	TIME [epoch: 8.41 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08360171622259002		[learning rate: 5.0442e-05]
	Learning Rate: 5.04417e-05
	LOSS [training: 0.08360171622259002 | validation: 0.08925960216677636]
	TIME [epoch: 8.41 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08582284984204992		[learning rate: 5.0259e-05]
	Learning Rate: 5.02586e-05
	LOSS [training: 0.08582284984204992 | validation: 0.09127149201525864]
	TIME [epoch: 8.42 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08394358131141347		[learning rate: 5.0076e-05]
	Learning Rate: 5.00762e-05
	LOSS [training: 0.08394358131141347 | validation: 0.08098875775412889]
	TIME [epoch: 8.43 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07437041275001369		[learning rate: 4.9894e-05]
	Learning Rate: 4.98945e-05
	LOSS [training: 0.07437041275001369 | validation: 0.10402854148812804]
	TIME [epoch: 8.41 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06315182071610212		[learning rate: 4.9713e-05]
	Learning Rate: 4.97134e-05
	LOSS [training: 0.06315182071610212 | validation: 0.10416778269307364]
	TIME [epoch: 8.41 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06596208455253229		[learning rate: 4.9533e-05]
	Learning Rate: 4.9533e-05
	LOSS [training: 0.06596208455253229 | validation: 0.10074946297024158]
	TIME [epoch: 8.42 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08410122396955677		[learning rate: 4.9353e-05]
	Learning Rate: 4.93533e-05
	LOSS [training: 0.08410122396955677 | validation: 0.07908303704129094]
	TIME [epoch: 8.41 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06524199338440269		[learning rate: 4.9174e-05]
	Learning Rate: 4.91742e-05
	LOSS [training: 0.06524199338440269 | validation: 0.07712561601554072]
	TIME [epoch: 8.41 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07156201960549421		[learning rate: 4.8996e-05]
	Learning Rate: 4.89957e-05
	LOSS [training: 0.07156201960549421 | validation: 0.07980580857853149]
	TIME [epoch: 8.4 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06742353700610096		[learning rate: 4.8818e-05]
	Learning Rate: 4.88179e-05
	LOSS [training: 0.06742353700610096 | validation: 0.0818003770390288]
	TIME [epoch: 8.42 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062410119939786755		[learning rate: 4.8641e-05]
	Learning Rate: 4.86407e-05
	LOSS [training: 0.062410119939786755 | validation: 0.08498253105730288]
	TIME [epoch: 8.41 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0600956455840526		[learning rate: 4.8464e-05]
	Learning Rate: 4.84642e-05
	LOSS [training: 0.0600956455840526 | validation: 0.07990067884328146]
	TIME [epoch: 8.41 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06914077366196812		[learning rate: 4.8288e-05]
	Learning Rate: 4.82883e-05
	LOSS [training: 0.06914077366196812 | validation: 0.07455786693941395]
	TIME [epoch: 8.41 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06555863447127483		[learning rate: 4.8113e-05]
	Learning Rate: 4.81131e-05
	LOSS [training: 0.06555863447127483 | validation: 0.08814336547008517]
	TIME [epoch: 8.43 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06540027796070402		[learning rate: 4.7938e-05]
	Learning Rate: 4.79385e-05
	LOSS [training: 0.06540027796070402 | validation: 0.08249250569650612]
	TIME [epoch: 8.42 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06460079329196625		[learning rate: 4.7765e-05]
	Learning Rate: 4.77645e-05
	LOSS [training: 0.06460079329196625 | validation: 0.08411658577410121]
	TIME [epoch: 8.41 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06519490659533925		[learning rate: 4.7591e-05]
	Learning Rate: 4.75912e-05
	LOSS [training: 0.06519490659533925 | validation: 0.08966521155845639]
	TIME [epoch: 8.41 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07446568655817037		[learning rate: 4.7418e-05]
	Learning Rate: 4.74185e-05
	LOSS [training: 0.07446568655817037 | validation: 0.08071828669102771]
	TIME [epoch: 8.43 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07098938977934263		[learning rate: 4.7246e-05]
	Learning Rate: 4.72464e-05
	LOSS [training: 0.07098938977934263 | validation: 0.09243337390036743]
	TIME [epoch: 8.42 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0811097434012658		[learning rate: 4.7075e-05]
	Learning Rate: 4.70749e-05
	LOSS [training: 0.0811097434012658 | validation: 0.08071495883191131]
	TIME [epoch: 8.4 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07302896872990165		[learning rate: 4.6904e-05]
	Learning Rate: 4.69041e-05
	LOSS [training: 0.07302896872990165 | validation: 0.09562581975140894]
	TIME [epoch: 8.41 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06568058379085899		[learning rate: 4.6734e-05]
	Learning Rate: 4.67339e-05
	LOSS [training: 0.06568058379085899 | validation: 0.08546618496191852]
	TIME [epoch: 8.43 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06369913116222878		[learning rate: 4.6564e-05]
	Learning Rate: 4.65643e-05
	LOSS [training: 0.06369913116222878 | validation: 0.08991533122529612]
	TIME [epoch: 8.41 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06377700915494805		[learning rate: 4.6395e-05]
	Learning Rate: 4.63953e-05
	LOSS [training: 0.06377700915494805 | validation: 0.0820321526408639]
	TIME [epoch: 8.4 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06139915219353056		[learning rate: 4.6227e-05]
	Learning Rate: 4.62269e-05
	LOSS [training: 0.06139915219353056 | validation: 0.07838441355035525]
	TIME [epoch: 8.41 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061594309667563574		[learning rate: 4.6059e-05]
	Learning Rate: 4.60591e-05
	LOSS [training: 0.061594309667563574 | validation: 0.08944258299367572]
	TIME [epoch: 8.43 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061684558004243786		[learning rate: 4.5892e-05]
	Learning Rate: 4.5892e-05
	LOSS [training: 0.061684558004243786 | validation: 0.09088533522189865]
	TIME [epoch: 8.41 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062036324074003904		[learning rate: 4.5725e-05]
	Learning Rate: 4.57254e-05
	LOSS [training: 0.062036324074003904 | validation: 0.0961019560195949]
	TIME [epoch: 8.41 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06389677259968704		[learning rate: 4.556e-05]
	Learning Rate: 4.55595e-05
	LOSS [training: 0.06389677259968704 | validation: 0.09835139342078633]
	TIME [epoch: 8.41 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06970788566372392		[learning rate: 4.5394e-05]
	Learning Rate: 4.53942e-05
	LOSS [training: 0.06970788566372392 | validation: 0.0887935256670221]
	TIME [epoch: 8.43 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062064573114114605		[learning rate: 4.5229e-05]
	Learning Rate: 4.52294e-05
	LOSS [training: 0.062064573114114605 | validation: 0.09985570784684529]
	TIME [epoch: 8.4 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651259082805967		[learning rate: 4.5065e-05]
	Learning Rate: 4.50653e-05
	LOSS [training: 0.0651259082805967 | validation: 0.12359066241098593]
	TIME [epoch: 8.41 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06854678745117725		[learning rate: 4.4902e-05]
	Learning Rate: 4.49017e-05
	LOSS [training: 0.06854678745117725 | validation: 0.10586776652719994]
	TIME [epoch: 8.41 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06418243475294297		[learning rate: 4.4739e-05]
	Learning Rate: 4.47388e-05
	LOSS [training: 0.06418243475294297 | validation: 0.0879835374626552]
	TIME [epoch: 8.43 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06384978601687993		[learning rate: 4.4576e-05]
	Learning Rate: 4.45764e-05
	LOSS [training: 0.06384978601687993 | validation: 0.0891336117291055]
	TIME [epoch: 8.41 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05908312404281879		[learning rate: 4.4415e-05]
	Learning Rate: 4.44147e-05
	LOSS [training: 0.05908312404281879 | validation: 0.10542737132279767]
	TIME [epoch: 8.4 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06118120134187505		[learning rate: 4.4253e-05]
	Learning Rate: 4.42535e-05
	LOSS [training: 0.06118120134187505 | validation: 0.09331719513420048]
	TIME [epoch: 8.41 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05872415432313956		[learning rate: 4.4093e-05]
	Learning Rate: 4.40929e-05
	LOSS [training: 0.05872415432313956 | validation: 0.10044717066752706]
	TIME [epoch: 8.44 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06489281905008834		[learning rate: 4.3933e-05]
	Learning Rate: 4.39329e-05
	LOSS [training: 0.06489281905008834 | validation: 0.07906670949502348]
	TIME [epoch: 8.4 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07146048277793186		[learning rate: 4.3773e-05]
	Learning Rate: 4.37734e-05
	LOSS [training: 0.07146048277793186 | validation: 0.08004507380847473]
	TIME [epoch: 8.41 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06255731168503917		[learning rate: 4.3615e-05]
	Learning Rate: 4.36146e-05
	LOSS [training: 0.06255731168503917 | validation: 0.08373310285062018]
	TIME [epoch: 8.4 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06113751053874174		[learning rate: 4.3456e-05]
	Learning Rate: 4.34563e-05
	LOSS [training: 0.06113751053874174 | validation: 0.09231697100602829]
	TIME [epoch: 8.43 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06599741157089432		[learning rate: 4.3299e-05]
	Learning Rate: 4.32986e-05
	LOSS [training: 0.06599741157089432 | validation: 0.08712869044204868]
	TIME [epoch: 8.4 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0673069156932438		[learning rate: 4.3141e-05]
	Learning Rate: 4.31415e-05
	LOSS [training: 0.0673069156932438 | validation: 0.09269134957349606]
	TIME [epoch: 8.41 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06349311286109292		[learning rate: 4.2985e-05]
	Learning Rate: 4.29849e-05
	LOSS [training: 0.06349311286109292 | validation: 0.08404018972093524]
	TIME [epoch: 8.41 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060496433302338656		[learning rate: 4.2829e-05]
	Learning Rate: 4.28289e-05
	LOSS [training: 0.060496433302338656 | validation: 0.10285387031965765]
	TIME [epoch: 8.43 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06798222357734808		[learning rate: 4.2673e-05]
	Learning Rate: 4.26735e-05
	LOSS [training: 0.06798222357734808 | validation: 0.1014173619685454]
	TIME [epoch: 8.41 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059447229395633		[learning rate: 4.2519e-05]
	Learning Rate: 4.25186e-05
	LOSS [training: 0.059447229395633 | validation: 0.09389846735717274]
	TIME [epoch: 8.4 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06497124606917856		[learning rate: 4.2364e-05]
	Learning Rate: 4.23643e-05
	LOSS [training: 0.06497124606917856 | validation: 0.08869162254663898]
	TIME [epoch: 8.4 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06363598437371513		[learning rate: 4.2211e-05]
	Learning Rate: 4.22106e-05
	LOSS [training: 0.06363598437371513 | validation: 0.10254635360514566]
	TIME [epoch: 8.42 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062394118002657276		[learning rate: 4.2057e-05]
	Learning Rate: 4.20574e-05
	LOSS [training: 0.062394118002657276 | validation: 0.08952128612068183]
	TIME [epoch: 8.41 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0603773642065908		[learning rate: 4.1905e-05]
	Learning Rate: 4.19047e-05
	LOSS [training: 0.0603773642065908 | validation: 0.0969213023227884]
	TIME [epoch: 8.4 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0690392184524418		[learning rate: 4.1753e-05]
	Learning Rate: 4.17527e-05
	LOSS [training: 0.0690392184524418 | validation: 0.09698969070961307]
	TIME [epoch: 8.41 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0642963000891002		[learning rate: 4.1601e-05]
	Learning Rate: 4.16012e-05
	LOSS [training: 0.0642963000891002 | validation: 0.09176314536227098]
	TIME [epoch: 8.42 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05966970485860971		[learning rate: 4.145e-05]
	Learning Rate: 4.14502e-05
	LOSS [training: 0.05966970485860971 | validation: 0.0938121797560247]
	TIME [epoch: 8.4 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06760032486881154		[learning rate: 4.13e-05]
	Learning Rate: 4.12998e-05
	LOSS [training: 0.06760032486881154 | validation: 0.09298188097982811]
	TIME [epoch: 8.41 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06252625563996551		[learning rate: 4.115e-05]
	Learning Rate: 4.11499e-05
	LOSS [training: 0.06252625563996551 | validation: 0.10545902375194183]
	TIME [epoch: 8.41 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651113696643248		[learning rate: 4.1001e-05]
	Learning Rate: 4.10005e-05
	LOSS [training: 0.0651113696643248 | validation: 0.10052803467804183]
	TIME [epoch: 8.42 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07198797131957162		[learning rate: 4.0852e-05]
	Learning Rate: 4.08517e-05
	LOSS [training: 0.07198797131957162 | validation: 0.08056917621329843]
	TIME [epoch: 8.41 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0689654213634768		[learning rate: 4.0703e-05]
	Learning Rate: 4.07035e-05
	LOSS [training: 0.0689654213634768 | validation: 0.08920255379723355]
	TIME [epoch: 8.41 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06499512592994297		[learning rate: 4.0556e-05]
	Learning Rate: 4.05558e-05
	LOSS [training: 0.06499512592994297 | validation: 0.08779187503521202]
	TIME [epoch: 8.42 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06785116667447386		[learning rate: 4.0409e-05]
	Learning Rate: 4.04086e-05
	LOSS [training: 0.06785116667447386 | validation: 0.10371899275291689]
	TIME [epoch: 8.42 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0628662834077637		[learning rate: 4.0262e-05]
	Learning Rate: 4.0262e-05
	LOSS [training: 0.0628662834077637 | validation: 0.08818595339759613]
	TIME [epoch: 8.41 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06753750712278292		[learning rate: 4.0116e-05]
	Learning Rate: 4.01158e-05
	LOSS [training: 0.06753750712278292 | validation: 0.09976217477391947]
	TIME [epoch: 8.4 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06304653349403223		[learning rate: 3.997e-05]
	Learning Rate: 3.99703e-05
	LOSS [training: 0.06304653349403223 | validation: 0.0998613709792558]
	TIME [epoch: 8.42 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06783388337147687		[learning rate: 3.9825e-05]
	Learning Rate: 3.98252e-05
	LOSS [training: 0.06783388337147687 | validation: 0.08923690387994146]
	TIME [epoch: 8.42 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0668185423855091		[learning rate: 3.9681e-05]
	Learning Rate: 3.96807e-05
	LOSS [training: 0.0668185423855091 | validation: 0.08740387085396295]
	TIME [epoch: 8.41 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06221732069269873		[learning rate: 3.9537e-05]
	Learning Rate: 3.95367e-05
	LOSS [training: 0.06221732069269873 | validation: 0.09129896346833882]
	TIME [epoch: 8.4 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062391254949365024		[learning rate: 3.9393e-05]
	Learning Rate: 3.93932e-05
	LOSS [training: 0.062391254949365024 | validation: 0.10212717380202975]
	TIME [epoch: 8.43 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06275137028721108		[learning rate: 3.925e-05]
	Learning Rate: 3.92502e-05
	LOSS [training: 0.06275137028721108 | validation: 0.09754665731802084]
	TIME [epoch: 8.41 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05820469893816223		[learning rate: 3.9108e-05]
	Learning Rate: 3.91078e-05
	LOSS [training: 0.05820469893816223 | validation: 0.08677082611510088]
	TIME [epoch: 8.4 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06515067433325429		[learning rate: 3.8966e-05]
	Learning Rate: 3.89659e-05
	LOSS [training: 0.06515067433325429 | validation: 0.08738662541119319]
	TIME [epoch: 8.41 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061614215376421456		[learning rate: 3.8824e-05]
	Learning Rate: 3.88245e-05
	LOSS [training: 0.061614215376421456 | validation: 0.09771901072288]
	TIME [epoch: 8.42 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06304794872311917		[learning rate: 3.8684e-05]
	Learning Rate: 3.86836e-05
	LOSS [training: 0.06304794872311917 | validation: 0.08875704752660962]
	TIME [epoch: 8.41 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0623068008052574		[learning rate: 3.8543e-05]
	Learning Rate: 3.85432e-05
	LOSS [training: 0.0623068008052574 | validation: 0.11255597686313332]
	TIME [epoch: 8.4 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06125005253032689		[learning rate: 3.8403e-05]
	Learning Rate: 3.84033e-05
	LOSS [training: 0.06125005253032689 | validation: 0.10511700650903291]
	TIME [epoch: 8.39 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06338189149192831		[learning rate: 3.8264e-05]
	Learning Rate: 3.82639e-05
	LOSS [training: 0.06338189149192831 | validation: 0.09609387283840432]
	TIME [epoch: 8.41 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0638845490850781		[learning rate: 3.8125e-05]
	Learning Rate: 3.81251e-05
	LOSS [training: 0.0638845490850781 | validation: 0.10841573247713572]
	TIME [epoch: 8.41 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06707791055072063		[learning rate: 3.7987e-05]
	Learning Rate: 3.79867e-05
	LOSS [training: 0.06707791055072063 | validation: 0.100979563750276]
	TIME [epoch: 8.4 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06551077883013792		[learning rate: 3.7849e-05]
	Learning Rate: 3.78489e-05
	LOSS [training: 0.06551077883013792 | validation: 0.08101114229762324]
	TIME [epoch: 8.41 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06375988166962435		[learning rate: 3.7711e-05]
	Learning Rate: 3.77115e-05
	LOSS [training: 0.06375988166962435 | validation: 0.09039901364704733]
	TIME [epoch: 8.43 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06596476662290442		[learning rate: 3.7575e-05]
	Learning Rate: 3.75746e-05
	LOSS [training: 0.06596476662290442 | validation: 0.0759136041659978]
	TIME [epoch: 8.4 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07040237701573608		[learning rate: 3.7438e-05]
	Learning Rate: 3.74383e-05
	LOSS [training: 0.07040237701573608 | validation: 0.08242369109738584]
	TIME [epoch: 8.4 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08003394094949462		[learning rate: 3.7302e-05]
	Learning Rate: 3.73024e-05
	LOSS [training: 0.08003394094949462 | validation: 0.07129348967268774]
	TIME [epoch: 8.39 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07391956250374361		[learning rate: 3.7167e-05]
	Learning Rate: 3.7167e-05
	LOSS [training: 0.07391956250374361 | validation: 0.08786840592408099]
	TIME [epoch: 8.42 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07752024976684072		[learning rate: 3.7032e-05]
	Learning Rate: 3.70322e-05
	LOSS [training: 0.07752024976684072 | validation: 0.09009476402917169]
	TIME [epoch: 8.42 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06214267300425822		[learning rate: 3.6898e-05]
	Learning Rate: 3.68978e-05
	LOSS [training: 0.06214267300425822 | validation: 0.0824768677281725]
	TIME [epoch: 8.4 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062239004363220975		[learning rate: 3.6764e-05]
	Learning Rate: 3.67639e-05
	LOSS [training: 0.062239004363220975 | validation: 0.08818560691693049]
	TIME [epoch: 8.41 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06542931380957548		[learning rate: 3.663e-05]
	Learning Rate: 3.66304e-05
	LOSS [training: 0.06542931380957548 | validation: 0.09056770574187788]
	TIME [epoch: 8.43 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06284746139148321		[learning rate: 3.6498e-05]
	Learning Rate: 3.64975e-05
	LOSS [training: 0.06284746139148321 | validation: 0.10381322035858329]
	TIME [epoch: 8.41 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06346484732103429		[learning rate: 3.6365e-05]
	Learning Rate: 3.63651e-05
	LOSS [training: 0.06346484732103429 | validation: 0.09550125176788599]
	TIME [epoch: 8.4 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06012101133495197		[learning rate: 3.6233e-05]
	Learning Rate: 3.62331e-05
	LOSS [training: 0.06012101133495197 | validation: 0.1055062620572507]
	TIME [epoch: 8.41 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059927251980636906		[learning rate: 3.6102e-05]
	Learning Rate: 3.61016e-05
	LOSS [training: 0.059927251980636906 | validation: 0.10378292921830574]
	TIME [epoch: 8.43 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06247400004915353		[learning rate: 3.5971e-05]
	Learning Rate: 3.59706e-05
	LOSS [training: 0.06247400004915353 | validation: 0.09082729084368873]
	TIME [epoch: 8.4 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06289447634144027		[learning rate: 3.584e-05]
	Learning Rate: 3.584e-05
	LOSS [training: 0.06289447634144027 | validation: 0.1046963020723154]
	TIME [epoch: 8.41 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06291110129513158		[learning rate: 3.571e-05]
	Learning Rate: 3.571e-05
	LOSS [training: 0.06291110129513158 | validation: 0.10379961749059675]
	TIME [epoch: 8.41 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05875577147885132		[learning rate: 3.558e-05]
	Learning Rate: 3.55804e-05
	LOSS [training: 0.05875577147885132 | validation: 0.09572427194531513]
	TIME [epoch: 8.43 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06250393866289507		[learning rate: 3.5451e-05]
	Learning Rate: 3.54513e-05
	LOSS [training: 0.06250393866289507 | validation: 0.08359090461200956]
	TIME [epoch: 8.4 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059937254848147624		[learning rate: 3.5323e-05]
	Learning Rate: 3.53226e-05
	LOSS [training: 0.059937254848147624 | validation: 0.09695264871361708]
	TIME [epoch: 8.4 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05998103698775777		[learning rate: 3.5194e-05]
	Learning Rate: 3.51944e-05
	LOSS [training: 0.05998103698775777 | validation: 0.09730495910211204]
	TIME [epoch: 8.41 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062184652924089846		[learning rate: 3.5067e-05]
	Learning Rate: 3.50667e-05
	LOSS [training: 0.062184652924089846 | validation: 0.09892450345440057]
	TIME [epoch: 8.42 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060704834727473546		[learning rate: 3.4939e-05]
	Learning Rate: 3.49394e-05
	LOSS [training: 0.060704834727473546 | validation: 0.08780545984569083]
	TIME [epoch: 8.41 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06077479315357337		[learning rate: 3.4813e-05]
	Learning Rate: 3.48126e-05
	LOSS [training: 0.06077479315357337 | validation: 0.09971810800901645]
	TIME [epoch: 8.41 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06676314155759418		[learning rate: 3.4686e-05]
	Learning Rate: 3.46863e-05
	LOSS [training: 0.06676314155759418 | validation: 0.10166204520734573]
	TIME [epoch: 8.41 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06434046838335408		[learning rate: 3.456e-05]
	Learning Rate: 3.45604e-05
	LOSS [training: 0.06434046838335408 | validation: 0.08015760442096675]
	TIME [epoch: 8.43 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06486327426577769		[learning rate: 3.4435e-05]
	Learning Rate: 3.4435e-05
	LOSS [training: 0.06486327426577769 | validation: 0.08613600472143934]
	TIME [epoch: 8.4 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06499968586175732		[learning rate: 3.431e-05]
	Learning Rate: 3.431e-05
	LOSS [training: 0.06499968586175732 | validation: 0.076344567636285]
	TIME [epoch: 8.4 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06042102568458926		[learning rate: 3.4186e-05]
	Learning Rate: 3.41855e-05
	LOSS [training: 0.06042102568458926 | validation: 0.0899546001626934]
	TIME [epoch: 8.41 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06173093555728457		[learning rate: 3.4061e-05]
	Learning Rate: 3.40615e-05
	LOSS [training: 0.06173093555728457 | validation: 0.08963504060649662]
	TIME [epoch: 8.42 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0659408519516293		[learning rate: 3.3938e-05]
	Learning Rate: 3.39378e-05
	LOSS [training: 0.0659408519516293 | validation: 0.08896998411117543]
	TIME [epoch: 8.4 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06432079498478557		[learning rate: 3.3815e-05]
	Learning Rate: 3.38147e-05
	LOSS [training: 0.06432079498478557 | validation: 0.08537948031695103]
	TIME [epoch: 8.41 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06273254950466557		[learning rate: 3.3692e-05]
	Learning Rate: 3.3692e-05
	LOSS [training: 0.06273254950466557 | validation: 0.09049670056149234]
	TIME [epoch: 8.41 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06957367959259023		[learning rate: 3.357e-05]
	Learning Rate: 3.35697e-05
	LOSS [training: 0.06957367959259023 | validation: 0.07261039135476471]
	TIME [epoch: 8.43 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06264558354444796		[learning rate: 3.3448e-05]
	Learning Rate: 3.34479e-05
	LOSS [training: 0.06264558354444796 | validation: 0.09476434141351922]
	TIME [epoch: 8.41 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061167683881691894		[learning rate: 3.3326e-05]
	Learning Rate: 3.33265e-05
	LOSS [training: 0.061167683881691894 | validation: 0.08603056780737439]
	TIME [epoch: 8.41 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06762836840441112		[learning rate: 3.3206e-05]
	Learning Rate: 3.32055e-05
	LOSS [training: 0.06762836840441112 | validation: 0.08498095381419375]
	TIME [epoch: 8.42 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06657941808328385		[learning rate: 3.3085e-05]
	Learning Rate: 3.3085e-05
	LOSS [training: 0.06657941808328385 | validation: 0.08541721059621774]
	TIME [epoch: 8.42 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06800101573552056		[learning rate: 3.2965e-05]
	Learning Rate: 3.2965e-05
	LOSS [training: 0.06800101573552056 | validation: 0.08698427549173876]
	TIME [epoch: 8.41 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06876219484799641		[learning rate: 3.2845e-05]
	Learning Rate: 3.28453e-05
	LOSS [training: 0.06876219484799641 | validation: 0.08749807323636373]
	TIME [epoch: 8.41 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06966622121475703		[learning rate: 3.2726e-05]
	Learning Rate: 3.27261e-05
	LOSS [training: 0.06966622121475703 | validation: 0.08187061753195077]
	TIME [epoch: 8.41 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07709240232904144		[learning rate: 3.2607e-05]
	Learning Rate: 3.26074e-05
	LOSS [training: 0.07709240232904144 | validation: 0.0700926475793737]
	TIME [epoch: 8.41 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07268760629134448		[learning rate: 3.2489e-05]
	Learning Rate: 3.2489e-05
	LOSS [training: 0.07268760629134448 | validation: 0.07223385493036484]
	TIME [epoch: 8.4 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0746459452655365		[learning rate: 3.2371e-05]
	Learning Rate: 3.23711e-05
	LOSS [training: 0.0746459452655365 | validation: 0.07621161299541906]
	TIME [epoch: 8.4 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09015403305600697		[learning rate: 3.2254e-05]
	Learning Rate: 3.22537e-05
	LOSS [training: 0.09015403305600697 | validation: 0.08358553921741992]
	TIME [epoch: 8.41 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07812754240537205		[learning rate: 3.2137e-05]
	Learning Rate: 3.21366e-05
	LOSS [training: 0.07812754240537205 | validation: 0.08104177966730984]
	TIME [epoch: 8.41 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08486359755961422		[learning rate: 3.202e-05]
	Learning Rate: 3.202e-05
	LOSS [training: 0.08486359755961422 | validation: 0.08079962325792651]
	TIME [epoch: 8.4 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08879387568387583		[learning rate: 3.1904e-05]
	Learning Rate: 3.19038e-05
	LOSS [training: 0.08879387568387583 | validation: 0.08531071744388796]
	TIME [epoch: 8.4 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08981651635861379		[learning rate: 3.1788e-05]
	Learning Rate: 3.1788e-05
	LOSS [training: 0.08981651635861379 | validation: 0.09070319546042835]
	TIME [epoch: 8.42 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07436443525232564		[learning rate: 3.1673e-05]
	Learning Rate: 3.16726e-05
	LOSS [training: 0.07436443525232564 | validation: 0.09070920828553714]
	TIME [epoch: 8.41 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07118089383581964		[learning rate: 3.1558e-05]
	Learning Rate: 3.15577e-05
	LOSS [training: 0.07118089383581964 | validation: 0.0885942186655038]
	TIME [epoch: 8.39 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07724063640055348		[learning rate: 3.1443e-05]
	Learning Rate: 3.14432e-05
	LOSS [training: 0.07724063640055348 | validation: 0.08372714462484035]
	TIME [epoch: 8.4 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06712065153955		[learning rate: 3.1329e-05]
	Learning Rate: 3.13291e-05
	LOSS [training: 0.06712065153955 | validation: 0.08483605228125891]
	TIME [epoch: 8.42 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06747993678910627		[learning rate: 3.1215e-05]
	Learning Rate: 3.12154e-05
	LOSS [training: 0.06747993678910627 | validation: 0.10162021198329071]
	TIME [epoch: 8.4 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09569069172523688		[learning rate: 3.1102e-05]
	Learning Rate: 3.11021e-05
	LOSS [training: 0.09569069172523688 | validation: 0.09581032804547673]
	TIME [epoch: 8.4 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10147437596097104		[learning rate: 3.0989e-05]
	Learning Rate: 3.09892e-05
	LOSS [training: 0.10147437596097104 | validation: 0.09068531952835965]
	TIME [epoch: 8.4 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10097919075370534		[learning rate: 3.0877e-05]
	Learning Rate: 3.08768e-05
	LOSS [training: 0.10097919075370534 | validation: 0.09219317159909272]
	TIME [epoch: 8.42 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09535757190620626		[learning rate: 3.0765e-05]
	Learning Rate: 3.07647e-05
	LOSS [training: 0.09535757190620626 | validation: 0.08429947280845199]
	TIME [epoch: 8.4 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07887794898995262		[learning rate: 3.0653e-05]
	Learning Rate: 3.0653e-05
	LOSS [training: 0.07887794898995262 | validation: 0.08804874908325674]
	TIME [epoch: 8.4 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07832315380541291		[learning rate: 3.0542e-05]
	Learning Rate: 3.05418e-05
	LOSS [training: 0.07832315380541291 | validation: 0.09069969603305193]
	TIME [epoch: 8.41 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08166916963705399		[learning rate: 3.0431e-05]
	Learning Rate: 3.0431e-05
	LOSS [training: 0.08166916963705399 | validation: 0.08232756931062749]
	TIME [epoch: 8.42 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07732271962075012		[learning rate: 3.0321e-05]
	Learning Rate: 3.03205e-05
	LOSS [training: 0.07732271962075012 | validation: 0.08473100814435235]
	TIME [epoch: 8.4 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08662091038676206		[learning rate: 3.0211e-05]
	Learning Rate: 3.02105e-05
	LOSS [training: 0.08662091038676206 | validation: 0.09169980392179983]
	TIME [epoch: 8.4 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08417519994895867		[learning rate: 3.0101e-05]
	Learning Rate: 3.01009e-05
	LOSS [training: 0.08417519994895867 | validation: 0.08420806161714252]
	TIME [epoch: 8.4 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07569027885911758		[learning rate: 2.9992e-05]
	Learning Rate: 2.99916e-05
	LOSS [training: 0.07569027885911758 | validation: 0.06862646959820698]
	TIME [epoch: 8.43 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07671475426638821		[learning rate: 2.9883e-05]
	Learning Rate: 2.98828e-05
	LOSS [training: 0.07671475426638821 | validation: 0.08493195397634323]
	TIME [epoch: 8.41 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0685614048514692		[learning rate: 2.9774e-05]
	Learning Rate: 2.97743e-05
	LOSS [training: 0.0685614048514692 | validation: 0.0816905430347843]
	TIME [epoch: 8.4 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06490305453031196		[learning rate: 2.9666e-05]
	Learning Rate: 2.96663e-05
	LOSS [training: 0.06490305453031196 | validation: 0.08081545095747461]
	TIME [epoch: 8.4 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07908757692971838		[learning rate: 2.9559e-05]
	Learning Rate: 2.95586e-05
	LOSS [training: 0.07908757692971838 | validation: 0.08865364676754449]
	TIME [epoch: 8.43 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06289628269116794		[learning rate: 2.9451e-05]
	Learning Rate: 2.94514e-05
	LOSS [training: 0.06289628269116794 | validation: 0.09643680925913878]
	TIME [epoch: 8.41 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07421006242000514		[learning rate: 2.9344e-05]
	Learning Rate: 2.93445e-05
	LOSS [training: 0.07421006242000514 | validation: 0.09356372260568915]
	TIME [epoch: 8.41 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06768131369939027		[learning rate: 2.9238e-05]
	Learning Rate: 2.9238e-05
	LOSS [training: 0.06768131369939027 | validation: 0.07786582275702593]
	TIME [epoch: 8.4 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06783510640003657		[learning rate: 2.9132e-05]
	Learning Rate: 2.91319e-05
	LOSS [training: 0.06783510640003657 | validation: 0.07274619455963283]
	TIME [epoch: 8.43 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07141631968099277		[learning rate: 2.9026e-05]
	Learning Rate: 2.90262e-05
	LOSS [training: 0.07141631968099277 | validation: 0.07813053324884202]
	TIME [epoch: 8.41 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06011295370007576		[learning rate: 2.8921e-05]
	Learning Rate: 2.89208e-05
	LOSS [training: 0.06011295370007576 | validation: 0.0726538767174051]
	TIME [epoch: 8.41 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06647364747066742		[learning rate: 2.8816e-05]
	Learning Rate: 2.88159e-05
	LOSS [training: 0.06647364747066742 | validation: 0.08519290209113559]
	TIME [epoch: 8.4 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06493903610248129		[learning rate: 2.8711e-05]
	Learning Rate: 2.87113e-05
	LOSS [training: 0.06493903610248129 | validation: 0.09706240199582616]
	TIME [epoch: 8.42 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06264725121281263		[learning rate: 2.8607e-05]
	Learning Rate: 2.86071e-05
	LOSS [training: 0.06264725121281263 | validation: 0.07534031138486418]
	TIME [epoch: 8.4 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06646366899494939		[learning rate: 2.8503e-05]
	Learning Rate: 2.85033e-05
	LOSS [training: 0.06646366899494939 | validation: 0.08952302808904902]
	TIME [epoch: 8.4 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07425360097490905		[learning rate: 2.84e-05]
	Learning Rate: 2.83998e-05
	LOSS [training: 0.07425360097490905 | validation: 0.08147288195654165]
	TIME [epoch: 8.4 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0680596700247817		[learning rate: 2.8297e-05]
	Learning Rate: 2.82968e-05
	LOSS [training: 0.0680596700247817 | validation: 0.08103908620322839]
	TIME [epoch: 8.42 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06864018352985005		[learning rate: 2.8194e-05]
	Learning Rate: 2.81941e-05
	LOSS [training: 0.06864018352985005 | validation: 0.0862141671575824]
	TIME [epoch: 8.4 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06954221764369845		[learning rate: 2.8092e-05]
	Learning Rate: 2.80918e-05
	LOSS [training: 0.06954221764369845 | validation: 0.08437798682095189]
	TIME [epoch: 8.4 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0615100754548352		[learning rate: 2.799e-05]
	Learning Rate: 2.79898e-05
	LOSS [training: 0.0615100754548352 | validation: 0.09407652620701958]
	TIME [epoch: 8.4 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06456023487618398		[learning rate: 2.7888e-05]
	Learning Rate: 2.78882e-05
	LOSS [training: 0.06456023487618398 | validation: 0.08781852648812172]
	TIME [epoch: 8.42 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06429016930541619		[learning rate: 2.7787e-05]
	Learning Rate: 2.7787e-05
	LOSS [training: 0.06429016930541619 | validation: 0.09421298392006552]
	TIME [epoch: 8.41 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0591389244867622		[learning rate: 2.7686e-05]
	Learning Rate: 2.76862e-05
	LOSS [training: 0.0591389244867622 | validation: 0.08345449417921653]
	TIME [epoch: 8.42 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061287580231031515		[learning rate: 2.7586e-05]
	Learning Rate: 2.75857e-05
	LOSS [training: 0.061287580231031515 | validation: 0.08155650655045683]
	TIME [epoch: 8.41 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06412058439060397		[learning rate: 2.7486e-05]
	Learning Rate: 2.74856e-05
	LOSS [training: 0.06412058439060397 | validation: 0.06557517476251014]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r1_20240219_194539/states/model_tr_study203_1722.pth
	Model improved!!!
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05741229616371629		[learning rate: 2.7386e-05]
	Learning Rate: 2.73859e-05
	LOSS [training: 0.05741229616371629 | validation: 0.09039588613785648]
	TIME [epoch: 8.41 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06470803394040504		[learning rate: 2.7286e-05]
	Learning Rate: 2.72865e-05
	LOSS [training: 0.06470803394040504 | validation: 0.09788054475405099]
	TIME [epoch: 8.41 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0652194426956811		[learning rate: 2.7187e-05]
	Learning Rate: 2.71875e-05
	LOSS [training: 0.0652194426956811 | validation: 0.07947593970772504]
	TIME [epoch: 8.42 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06178294717796549		[learning rate: 2.7089e-05]
	Learning Rate: 2.70888e-05
	LOSS [training: 0.06178294717796549 | validation: 0.0905984420757697]
	TIME [epoch: 8.43 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06431309306050205		[learning rate: 2.699e-05]
	Learning Rate: 2.69905e-05
	LOSS [training: 0.06431309306050205 | validation: 0.09290844190608416]
	TIME [epoch: 8.4 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06025250167222895		[learning rate: 2.6893e-05]
	Learning Rate: 2.68925e-05
	LOSS [training: 0.06025250167222895 | validation: 0.08156992387974656]
	TIME [epoch: 8.4 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06883067513990719		[learning rate: 2.6795e-05]
	Learning Rate: 2.67949e-05
	LOSS [training: 0.06883067513990719 | validation: 0.07796400080208561]
	TIME [epoch: 8.41 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07213666153930225		[learning rate: 2.6698e-05]
	Learning Rate: 2.66977e-05
	LOSS [training: 0.07213666153930225 | validation: 0.07874033917911503]
	TIME [epoch: 8.42 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06794277117511426		[learning rate: 2.6601e-05]
	Learning Rate: 2.66008e-05
	LOSS [training: 0.06794277117511426 | validation: 0.07413214877624207]
	TIME [epoch: 8.41 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06211663488846832		[learning rate: 2.6504e-05]
	Learning Rate: 2.65043e-05
	LOSS [training: 0.06211663488846832 | validation: 0.07585835260594434]
	TIME [epoch: 8.41 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06577141809720582		[learning rate: 2.6408e-05]
	Learning Rate: 2.64081e-05
	LOSS [training: 0.06577141809720582 | validation: 0.07763146779834947]
	TIME [epoch: 8.42 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06335563403964668		[learning rate: 2.6312e-05]
	Learning Rate: 2.63123e-05
	LOSS [training: 0.06335563403964668 | validation: 0.07670002902265141]
	TIME [epoch: 8.43 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05617050220304455		[learning rate: 2.6217e-05]
	Learning Rate: 2.62168e-05
	LOSS [training: 0.05617050220304455 | validation: 0.08352574928947809]
	TIME [epoch: 8.42 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06439478193696854		[learning rate: 2.6122e-05]
	Learning Rate: 2.61216e-05
	LOSS [training: 0.06439478193696854 | validation: 0.09285247051107207]
	TIME [epoch: 8.4 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06447228116763341		[learning rate: 2.6027e-05]
	Learning Rate: 2.60268e-05
	LOSS [training: 0.06447228116763341 | validation: 0.07753121295975492]
	TIME [epoch: 8.43 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06661081117071273		[learning rate: 2.5932e-05]
	Learning Rate: 2.59324e-05
	LOSS [training: 0.06661081117071273 | validation: 0.08365220137307447]
	TIME [epoch: 8.42 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06861365105121309		[learning rate: 2.5838e-05]
	Learning Rate: 2.58383e-05
	LOSS [training: 0.06861365105121309 | validation: 0.09372699144617623]
	TIME [epoch: 8.41 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07024029143778557		[learning rate: 2.5744e-05]
	Learning Rate: 2.57445e-05
	LOSS [training: 0.07024029143778557 | validation: 0.08413661846804432]
	TIME [epoch: 8.4 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07262119650133914		[learning rate: 2.5651e-05]
	Learning Rate: 2.56511e-05
	LOSS [training: 0.07262119650133914 | validation: 0.09019399793089308]
	TIME [epoch: 8.43 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07278362271115911		[learning rate: 2.5558e-05]
	Learning Rate: 2.5558e-05
	LOSS [training: 0.07278362271115911 | validation: 0.0930410972220729]
	TIME [epoch: 8.41 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06927954284356903		[learning rate: 2.5465e-05]
	Learning Rate: 2.54652e-05
	LOSS [training: 0.06927954284356903 | validation: 0.09607063612097007]
	TIME [epoch: 8.41 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07119880272945392		[learning rate: 2.5373e-05]
	Learning Rate: 2.53728e-05
	LOSS [training: 0.07119880272945392 | validation: 0.09292522611684312]
	TIME [epoch: 8.41 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0662713402505787		[learning rate: 2.5281e-05]
	Learning Rate: 2.52807e-05
	LOSS [training: 0.0662713402505787 | validation: 0.09527940888017268]
	TIME [epoch: 8.42 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062378866152533116		[learning rate: 2.5189e-05]
	Learning Rate: 2.5189e-05
	LOSS [training: 0.062378866152533116 | validation: 0.08535640683509069]
	TIME [epoch: 8.41 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07744167564138256		[learning rate: 2.5098e-05]
	Learning Rate: 2.50976e-05
	LOSS [training: 0.07744167564138256 | validation: 0.08201890258250291]
	TIME [epoch: 8.41 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07746515516225658		[learning rate: 2.5006e-05]
	Learning Rate: 2.50065e-05
	LOSS [training: 0.07746515516225658 | validation: 0.07815558924074423]
	TIME [epoch: 8.4 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07598254262951375		[learning rate: 2.4916e-05]
	Learning Rate: 2.49157e-05
	LOSS [training: 0.07598254262951375 | validation: 0.07513072187998308]
	TIME [epoch: 8.42 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0673929587608218		[learning rate: 2.4825e-05]
	Learning Rate: 2.48253e-05
	LOSS [training: 0.0673929587608218 | validation: 0.08740364508899698]
	TIME [epoch: 8.41 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06811374520487078		[learning rate: 2.4735e-05]
	Learning Rate: 2.47352e-05
	LOSS [training: 0.06811374520487078 | validation: 0.07393823987584323]
	TIME [epoch: 8.4 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07184262267739487		[learning rate: 2.4645e-05]
	Learning Rate: 2.46455e-05
	LOSS [training: 0.07184262267739487 | validation: 0.09298474037887447]
	TIME [epoch: 8.4 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07584798775618286		[learning rate: 2.4556e-05]
	Learning Rate: 2.4556e-05
	LOSS [training: 0.07584798775618286 | validation: 0.07500784340387037]
	TIME [epoch: 8.42 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07062023890186409		[learning rate: 2.4467e-05]
	Learning Rate: 2.44669e-05
	LOSS [training: 0.07062023890186409 | validation: 0.09242482999612152]
	TIME [epoch: 8.41 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06802768330609442		[learning rate: 2.4378e-05]
	Learning Rate: 2.43781e-05
	LOSS [training: 0.06802768330609442 | validation: 0.0822049499910858]
	TIME [epoch: 8.4 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06529859037483965		[learning rate: 2.429e-05]
	Learning Rate: 2.42896e-05
	LOSS [training: 0.06529859037483965 | validation: 0.08150972775435274]
	TIME [epoch: 8.41 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06553043766798965		[learning rate: 2.4201e-05]
	Learning Rate: 2.42015e-05
	LOSS [training: 0.06553043766798965 | validation: 0.09468673226170608]
	TIME [epoch: 8.44 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060383839750967484		[learning rate: 2.4114e-05]
	Learning Rate: 2.41137e-05
	LOSS [training: 0.060383839750967484 | validation: 0.07903309340340917]
	TIME [epoch: 8.4 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06627693987152579		[learning rate: 2.4026e-05]
	Learning Rate: 2.40262e-05
	LOSS [training: 0.06627693987152579 | validation: 0.08526111910538728]
	TIME [epoch: 8.4 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07018775695165132		[learning rate: 2.3939e-05]
	Learning Rate: 2.3939e-05
	LOSS [training: 0.07018775695165132 | validation: 0.082048272966213]
	TIME [epoch: 8.4 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06415491204651794		[learning rate: 2.3852e-05]
	Learning Rate: 2.38521e-05
	LOSS [training: 0.06415491204651794 | validation: 0.08483661568777418]
	TIME [epoch: 8.43 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07202198018695935		[learning rate: 2.3766e-05]
	Learning Rate: 2.37655e-05
	LOSS [training: 0.07202198018695935 | validation: 0.08169294765368137]
	TIME [epoch: 8.4 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08026365366734547		[learning rate: 2.3679e-05]
	Learning Rate: 2.36793e-05
	LOSS [training: 0.08026365366734547 | validation: 0.08384775989778291]
	TIME [epoch: 8.41 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08285201855225828		[learning rate: 2.3593e-05]
	Learning Rate: 2.35933e-05
	LOSS [training: 0.08285201855225828 | validation: 0.08022600917343987]
	TIME [epoch: 8.41 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06889882690739943		[learning rate: 2.3508e-05]
	Learning Rate: 2.35077e-05
	LOSS [training: 0.06889882690739943 | validation: 0.08233414053602757]
	TIME [epoch: 8.44 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07175045095427882		[learning rate: 2.3422e-05]
	Learning Rate: 2.34224e-05
	LOSS [training: 0.07175045095427882 | validation: 0.0895775917923104]
	TIME [epoch: 8.4 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08206359543693739		[learning rate: 2.3337e-05]
	Learning Rate: 2.33374e-05
	LOSS [training: 0.08206359543693739 | validation: 0.08796304603842578]
	TIME [epoch: 8.41 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0960840684512991		[learning rate: 2.3253e-05]
	Learning Rate: 2.32527e-05
	LOSS [training: 0.0960840684512991 | validation: 0.08054867458167494]
	TIME [epoch: 8.41 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09054603517668218		[learning rate: 2.3168e-05]
	Learning Rate: 2.31683e-05
	LOSS [training: 0.09054603517668218 | validation: 0.09225362825994092]
	TIME [epoch: 8.43 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08733557973664526		[learning rate: 2.3084e-05]
	Learning Rate: 2.30843e-05
	LOSS [training: 0.08733557973664526 | validation: 0.08444239079849111]
	TIME [epoch: 8.41 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08418268004021777		[learning rate: 2.3e-05]
	Learning Rate: 2.30005e-05
	LOSS [training: 0.08418268004021777 | validation: 0.07436536651042029]
	TIME [epoch: 8.41 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06615529113087834		[learning rate: 2.2917e-05]
	Learning Rate: 2.2917e-05
	LOSS [training: 0.06615529113087834 | validation: 0.07661543127715081]
	TIME [epoch: 8.42 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06846791987741352		[learning rate: 2.2834e-05]
	Learning Rate: 2.28338e-05
	LOSS [training: 0.06846791987741352 | validation: 0.0858669096791099]
	TIME [epoch: 8.43 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0629025328629936		[learning rate: 2.2751e-05]
	Learning Rate: 2.2751e-05
	LOSS [training: 0.0629025328629936 | validation: 0.0828427023989083]
	TIME [epoch: 8.4 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06474695506928246		[learning rate: 2.2668e-05]
	Learning Rate: 2.26684e-05
	LOSS [training: 0.06474695506928246 | validation: 0.08621217137157872]
	TIME [epoch: 8.4 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059038082559667505		[learning rate: 2.2586e-05]
	Learning Rate: 2.25862e-05
	LOSS [training: 0.059038082559667505 | validation: 0.08533903729023322]
	TIME [epoch: 8.41 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06868781252881358		[learning rate: 2.2504e-05]
	Learning Rate: 2.25042e-05
	LOSS [training: 0.06868781252881358 | validation: 0.09091603199806618]
	TIME [epoch: 8.43 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06065019145252094		[learning rate: 2.2423e-05]
	Learning Rate: 2.24225e-05
	LOSS [training: 0.06065019145252094 | validation: 0.09289802983753842]
	TIME [epoch: 8.4 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059500850719922616		[learning rate: 2.2341e-05]
	Learning Rate: 2.23411e-05
	LOSS [training: 0.059500850719922616 | validation: 0.07302604089673997]
	TIME [epoch: 8.4 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062273175538269956		[learning rate: 2.226e-05]
	Learning Rate: 2.22601e-05
	LOSS [training: 0.062273175538269956 | validation: 0.08395352122694555]
	TIME [epoch: 8.42 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06033988906278509		[learning rate: 2.2179e-05]
	Learning Rate: 2.21793e-05
	LOSS [training: 0.06033988906278509 | validation: 0.09520710404543783]
	TIME [epoch: 8.41 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06127928571773332		[learning rate: 2.2099e-05]
	Learning Rate: 2.20988e-05
	LOSS [training: 0.06127928571773332 | validation: 0.09632334975919425]
	TIME [epoch: 8.4 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06700092876108417		[learning rate: 2.2019e-05]
	Learning Rate: 2.20186e-05
	LOSS [training: 0.06700092876108417 | validation: 0.1128640828225548]
	TIME [epoch: 8.4 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06254220698456008		[learning rate: 2.1939e-05]
	Learning Rate: 2.19387e-05
	LOSS [training: 0.06254220698456008 | validation: 0.1079601616719833]
	TIME [epoch: 8.42 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05834844770428595		[learning rate: 2.1859e-05]
	Learning Rate: 2.18591e-05
	LOSS [training: 0.05834844770428595 | validation: 0.0979219943602057]
	TIME [epoch: 8.42 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0607314544389405		[learning rate: 2.178e-05]
	Learning Rate: 2.17797e-05
	LOSS [training: 0.0607314544389405 | validation: 0.09413700344660583]
	TIME [epoch: 8.41 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06130848891545908		[learning rate: 2.1701e-05]
	Learning Rate: 2.17007e-05
	LOSS [training: 0.06130848891545908 | validation: 0.09250432292567265]
	TIME [epoch: 8.4 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058863693371334645		[learning rate: 2.1622e-05]
	Learning Rate: 2.16219e-05
	LOSS [training: 0.058863693371334645 | validation: 0.09227324275418791]
	TIME [epoch: 8.42 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06063849647323786		[learning rate: 2.1543e-05]
	Learning Rate: 2.15435e-05
	LOSS [training: 0.06063849647323786 | validation: 0.09293692112703811]
	TIME [epoch: 8.42 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06428612183478978		[learning rate: 2.1465e-05]
	Learning Rate: 2.14653e-05
	LOSS [training: 0.06428612183478978 | validation: 0.08006601857479397]
	TIME [epoch: 8.41 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061881975091252484		[learning rate: 2.1387e-05]
	Learning Rate: 2.13874e-05
	LOSS [training: 0.061881975091252484 | validation: 0.09442278370989945]
	TIME [epoch: 8.41 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06426395829575973		[learning rate: 2.131e-05]
	Learning Rate: 2.13098e-05
	LOSS [training: 0.06426395829575973 | validation: 0.09281064068764816]
	TIME [epoch: 8.43 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06088078488711526		[learning rate: 2.1232e-05]
	Learning Rate: 2.12325e-05
	LOSS [training: 0.06088078488711526 | validation: 0.08405471816777016]
	TIME [epoch: 8.41 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062169150958658735		[learning rate: 2.1155e-05]
	Learning Rate: 2.11554e-05
	LOSS [training: 0.062169150958658735 | validation: 0.09936255221339764]
	TIME [epoch: 8.4 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06236386336210269		[learning rate: 2.1079e-05]
	Learning Rate: 2.10786e-05
	LOSS [training: 0.06236386336210269 | validation: 0.09082752954970945]
	TIME [epoch: 8.41 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06443556264649067		[learning rate: 2.1002e-05]
	Learning Rate: 2.10021e-05
	LOSS [training: 0.06443556264649067 | validation: 0.08542666331735743]
	TIME [epoch: 8.43 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.073981433706172		[learning rate: 2.0926e-05]
	Learning Rate: 2.09259e-05
	LOSS [training: 0.073981433706172 | validation: 0.081445062839165]
	TIME [epoch: 8.42 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06690842621997684		[learning rate: 2.085e-05]
	Learning Rate: 2.085e-05
	LOSS [training: 0.06690842621997684 | validation: 0.08894007831726553]
	TIME [epoch: 8.4 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06354026876797607		[learning rate: 2.0774e-05]
	Learning Rate: 2.07743e-05
	LOSS [training: 0.06354026876797607 | validation: 0.08784626422047184]
	TIME [epoch: 8.41 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07475789452907829		[learning rate: 2.0699e-05]
	Learning Rate: 2.06989e-05
	LOSS [training: 0.07475789452907829 | validation: 0.0888538386934373]
	TIME [epoch: 8.43 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06245067066269847		[learning rate: 2.0624e-05]
	Learning Rate: 2.06238e-05
	LOSS [training: 0.06245067066269847 | validation: 0.09244132158860185]
	TIME [epoch: 8.41 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059399733975568324		[learning rate: 2.0549e-05]
	Learning Rate: 2.05489e-05
	LOSS [training: 0.059399733975568324 | validation: 0.08871333886997063]
	TIME [epoch: 8.41 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06257272830253038		[learning rate: 2.0474e-05]
	Learning Rate: 2.04744e-05
	LOSS [training: 0.06257272830253038 | validation: 0.07698247401538397]
	TIME [epoch: 8.41 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0663287405480929		[learning rate: 2.04e-05]
	Learning Rate: 2.04001e-05
	LOSS [training: 0.0663287405480929 | validation: 0.0887433054733511]
	TIME [epoch: 8.42 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06310876701946737		[learning rate: 2.0326e-05]
	Learning Rate: 2.0326e-05
	LOSS [training: 0.06310876701946737 | validation: 0.08732267968832957]
	TIME [epoch: 8.42 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060090084817282105		[learning rate: 2.0252e-05]
	Learning Rate: 2.02523e-05
	LOSS [training: 0.060090084817282105 | validation: 0.09851958092332197]
	TIME [epoch: 8.41 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05795116245820202		[learning rate: 2.0179e-05]
	Learning Rate: 2.01788e-05
	LOSS [training: 0.05795116245820202 | validation: 0.08394791721910477]
	TIME [epoch: 8.4 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07051066923113301		[learning rate: 2.0106e-05]
	Learning Rate: 2.01055e-05
	LOSS [training: 0.07051066923113301 | validation: 0.08244234713583475]
	TIME [epoch: 8.42 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06322479828272924		[learning rate: 2.0033e-05]
	Learning Rate: 2.00326e-05
	LOSS [training: 0.06322479828272924 | validation: 0.08574154514158304]
	TIME [epoch: 8.41 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682750278796952		[learning rate: 1.996e-05]
	Learning Rate: 1.99599e-05
	LOSS [training: 0.0682750278796952 | validation: 0.08694578576029546]
	TIME [epoch: 8.4 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0752121280153983		[learning rate: 1.9887e-05]
	Learning Rate: 1.98874e-05
	LOSS [training: 0.0752121280153983 | validation: 0.08801402880393487]
	TIME [epoch: 8.41 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07602592804531967		[learning rate: 1.9815e-05]
	Learning Rate: 1.98153e-05
	LOSS [training: 0.07602592804531967 | validation: 0.08584985653073177]
	TIME [epoch: 8.44 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07579539274463126		[learning rate: 1.9743e-05]
	Learning Rate: 1.97434e-05
	LOSS [training: 0.07579539274463126 | validation: 0.08842617883305567]
	TIME [epoch: 8.41 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07760933272220533		[learning rate: 1.9672e-05]
	Learning Rate: 1.96717e-05
	LOSS [training: 0.07760933272220533 | validation: 0.0946002729205086]
	TIME [epoch: 8.41 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07402424468048259		[learning rate: 1.96e-05]
	Learning Rate: 1.96003e-05
	LOSS [training: 0.07402424468048259 | validation: 0.09058803110703369]
	TIME [epoch: 8.42 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06511549913726292		[learning rate: 1.9529e-05]
	Learning Rate: 1.95292e-05
	LOSS [training: 0.06511549913726292 | validation: 0.08844522462945448]
	TIME [epoch: 8.43 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0634128681655308		[learning rate: 1.9458e-05]
	Learning Rate: 1.94583e-05
	LOSS [training: 0.0634128681655308 | validation: 0.07679429842965421]
	TIME [epoch: 8.41 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07092854487286886		[learning rate: 1.9388e-05]
	Learning Rate: 1.93877e-05
	LOSS [training: 0.07092854487286886 | validation: 0.08601491474331394]
	TIME [epoch: 8.41 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06879852491902783		[learning rate: 1.9317e-05]
	Learning Rate: 1.93173e-05
	LOSS [training: 0.06879852491902783 | validation: 0.08349423647028384]
	TIME [epoch: 8.41 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07773982647318661		[learning rate: 1.9247e-05]
	Learning Rate: 1.92472e-05
	LOSS [training: 0.07773982647318661 | validation: 0.08309598844474739]
	TIME [epoch: 8.43 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06621846451088095		[learning rate: 1.9177e-05]
	Learning Rate: 1.91774e-05
	LOSS [training: 0.06621846451088095 | validation: 0.07905994119229098]
	TIME [epoch: 8.41 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06694833656328618		[learning rate: 1.9108e-05]
	Learning Rate: 1.91078e-05
	LOSS [training: 0.06694833656328618 | validation: 0.09459366562680988]
	TIME [epoch: 8.4 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06849642568898402		[learning rate: 1.9038e-05]
	Learning Rate: 1.90384e-05
	LOSS [training: 0.06849642568898402 | validation: 0.08404162870428772]
	TIME [epoch: 8.4 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07223018892858345		[learning rate: 1.8969e-05]
	Learning Rate: 1.89694e-05
	LOSS [training: 0.07223018892858345 | validation: 0.0946590946869252]
	TIME [epoch: 8.43 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07031493994253787		[learning rate: 1.8901e-05]
	Learning Rate: 1.89005e-05
	LOSS [training: 0.07031493994253787 | validation: 0.08229163604530475]
	TIME [epoch: 8.41 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06624287723907556		[learning rate: 1.8832e-05]
	Learning Rate: 1.88319e-05
	LOSS [training: 0.06624287723907556 | validation: 0.08056423084921098]
	TIME [epoch: 8.41 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06082293432502382		[learning rate: 1.8764e-05]
	Learning Rate: 1.87636e-05
	LOSS [training: 0.06082293432502382 | validation: 0.0674043303673518]
	TIME [epoch: 8.41 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07616865514777818		[learning rate: 1.8695e-05]
	Learning Rate: 1.86955e-05
	LOSS [training: 0.07616865514777818 | validation: 0.08062002730250258]
	TIME [epoch: 8.43 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07591262601936785		[learning rate: 1.8628e-05]
	Learning Rate: 1.86276e-05
	LOSS [training: 0.07591262601936785 | validation: 0.08698249116838125]
	TIME [epoch: 8.4 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09329307796958568		[learning rate: 1.856e-05]
	Learning Rate: 1.856e-05
	LOSS [training: 0.09329307796958568 | validation: 0.08277612909964205]
	TIME [epoch: 8.42 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09304692615422296		[learning rate: 1.8493e-05]
	Learning Rate: 1.84927e-05
	LOSS [training: 0.09304692615422296 | validation: 0.08881995742993497]
	TIME [epoch: 8.41 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08854065997859326		[learning rate: 1.8426e-05]
	Learning Rate: 1.84256e-05
	LOSS [training: 0.08854065997859326 | validation: 0.08051453879855161]
	TIME [epoch: 8.44 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0811572711228509		[learning rate: 1.8359e-05]
	Learning Rate: 1.83587e-05
	LOSS [training: 0.0811572711228509 | validation: 0.06853652796963619]
	TIME [epoch: 8.4 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06584135774926123		[learning rate: 1.8292e-05]
	Learning Rate: 1.82921e-05
	LOSS [training: 0.06584135774926123 | validation: 0.07983985486940462]
	TIME [epoch: 8.41 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06615307772421139		[learning rate: 1.8226e-05]
	Learning Rate: 1.82257e-05
	LOSS [training: 0.06615307772421139 | validation: 0.07700149456722723]
	TIME [epoch: 8.43 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07271868450059579		[learning rate: 1.816e-05]
	Learning Rate: 1.81596e-05
	LOSS [training: 0.07271868450059579 | validation: 0.07123499503444794]
	TIME [epoch: 8.43 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07533754056564608		[learning rate: 1.8094e-05]
	Learning Rate: 1.80937e-05
	LOSS [training: 0.07533754056564608 | validation: 0.08834530952009496]
	TIME [epoch: 8.42 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06795468553074692		[learning rate: 1.8028e-05]
	Learning Rate: 1.8028e-05
	LOSS [training: 0.06795468553074692 | validation: 0.08406487608041736]
	TIME [epoch: 8.41 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05860109393654023		[learning rate: 1.7963e-05]
	Learning Rate: 1.79626e-05
	LOSS [training: 0.05860109393654023 | validation: 0.0840373801644645]
	TIME [epoch: 8.41 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06481871873791992		[learning rate: 1.7897e-05]
	Learning Rate: 1.78974e-05
	LOSS [training: 0.06481871873791992 | validation: 0.07966945509701917]
	TIME [epoch: 8.42 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06127777055571467		[learning rate: 1.7832e-05]
	Learning Rate: 1.78324e-05
	LOSS [training: 0.06127777055571467 | validation: 0.08217613713016109]
	TIME [epoch: 8.41 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06848479548803149		[learning rate: 1.7768e-05]
	Learning Rate: 1.77677e-05
	LOSS [training: 0.06848479548803149 | validation: 0.08174503826780682]
	TIME [epoch: 8.41 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06261130873723103		[learning rate: 1.7703e-05]
	Learning Rate: 1.77032e-05
	LOSS [training: 0.06261130873723103 | validation: 0.0812670710795643]
	TIME [epoch: 8.42 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06827476163257332		[learning rate: 1.7639e-05]
	Learning Rate: 1.7639e-05
	LOSS [training: 0.06827476163257332 | validation: 0.0792988303530608]
	TIME [epoch: 8.42 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0648043751404046		[learning rate: 1.7575e-05]
	Learning Rate: 1.7575e-05
	LOSS [training: 0.0648043751404046 | validation: 0.08197046989288198]
	TIME [epoch: 8.41 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07300693816296544		[learning rate: 1.7511e-05]
	Learning Rate: 1.75112e-05
	LOSS [training: 0.07300693816296544 | validation: 0.08112761640265401]
	TIME [epoch: 8.41 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816732038256638		[learning rate: 1.7448e-05]
	Learning Rate: 1.74476e-05
	LOSS [training: 0.07816732038256638 | validation: 0.08683925294511718]
	TIME [epoch: 8.43 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07197210519896315		[learning rate: 1.7384e-05]
	Learning Rate: 1.73843e-05
	LOSS [training: 0.07197210519896315 | validation: 0.08475732795551062]
	TIME [epoch: 8.41 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06319488746635435		[learning rate: 1.7321e-05]
	Learning Rate: 1.73212e-05
	LOSS [training: 0.06319488746635435 | validation: 0.0817693746630501]
	TIME [epoch: 8.4 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0691483763677774		[learning rate: 1.7258e-05]
	Learning Rate: 1.72584e-05
	LOSS [training: 0.0691483763677774 | validation: 0.07975010146671774]
	TIME [epoch: 8.4 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07428544570901535		[learning rate: 1.7196e-05]
	Learning Rate: 1.71957e-05
	LOSS [training: 0.07428544570901535 | validation: 0.08190813745012021]
	TIME [epoch: 8.44 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07763236553655074		[learning rate: 1.7133e-05]
	Learning Rate: 1.71333e-05
	LOSS [training: 0.07763236553655074 | validation: 0.08051789086574383]
	TIME [epoch: 8.41 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07750628033646703		[learning rate: 1.7071e-05]
	Learning Rate: 1.70712e-05
	LOSS [training: 0.07750628033646703 | validation: 0.08006315101676624]
	TIME [epoch: 8.4 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08112400131166315		[learning rate: 1.7009e-05]
	Learning Rate: 1.70092e-05
	LOSS [training: 0.08112400131166315 | validation: 0.07684153109042685]
	TIME [epoch: 8.4 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08767025342062637		[learning rate: 1.6947e-05]
	Learning Rate: 1.69475e-05
	LOSS [training: 0.08767025342062637 | validation: 0.08677354508795407]
	TIME [epoch: 8.43 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08650420756770104		[learning rate: 1.6886e-05]
	Learning Rate: 1.6886e-05
	LOSS [training: 0.08650420756770104 | validation: 0.07186123246886156]
	TIME [epoch: 8.4 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07464628020021018		[learning rate: 1.6825e-05]
	Learning Rate: 1.68247e-05
	LOSS [training: 0.07464628020021018 | validation: 0.07228495669167415]
	TIME [epoch: 8.41 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0750752734333751		[learning rate: 1.6764e-05]
	Learning Rate: 1.67636e-05
	LOSS [training: 0.0750752734333751 | validation: 0.07909517739440555]
	TIME [epoch: 8.41 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06722865011491853		[learning rate: 1.6703e-05]
	Learning Rate: 1.67028e-05
	LOSS [training: 0.06722865011491853 | validation: 0.0784234941191796]
	TIME [epoch: 8.42 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07574441463385445		[learning rate: 1.6642e-05]
	Learning Rate: 1.66422e-05
	LOSS [training: 0.07574441463385445 | validation: 0.07576066996899403]
	TIME [epoch: 8.41 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07037953984341551		[learning rate: 1.6582e-05]
	Learning Rate: 1.65818e-05
	LOSS [training: 0.07037953984341551 | validation: 0.07659396019399946]
	TIME [epoch: 8.4 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07461128669826998		[learning rate: 1.6522e-05]
	Learning Rate: 1.65216e-05
	LOSS [training: 0.07461128669826998 | validation: 0.07812817419619644]
	TIME [epoch: 8.41 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06896885557635864		[learning rate: 1.6462e-05]
	Learning Rate: 1.64617e-05
	LOSS [training: 0.06896885557635864 | validation: 0.08250454494276105]
	TIME [epoch: 8.42 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06379167803071877		[learning rate: 1.6402e-05]
	Learning Rate: 1.64019e-05
	LOSS [training: 0.06379167803071877 | validation: 0.0762788873655279]
	TIME [epoch: 8.41 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06539716820868571		[learning rate: 1.6342e-05]
	Learning Rate: 1.63424e-05
	LOSS [training: 0.06539716820868571 | validation: 0.0800954317375264]
	TIME [epoch: 8.42 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06555716741501591		[learning rate: 1.6283e-05]
	Learning Rate: 1.62831e-05
	LOSS [training: 0.06555716741501591 | validation: 0.0744280206029463]
	TIME [epoch: 8.41 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06233442390947992		[learning rate: 1.6224e-05]
	Learning Rate: 1.6224e-05
	LOSS [training: 0.06233442390947992 | validation: 0.07609094099429639]
	TIME [epoch: 8.44 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07288802257866545		[learning rate: 1.6165e-05]
	Learning Rate: 1.61651e-05
	LOSS [training: 0.07288802257866545 | validation: 0.07962788747214845]
	TIME [epoch: 8.4 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061780127620920375		[learning rate: 1.6106e-05]
	Learning Rate: 1.61065e-05
	LOSS [training: 0.061780127620920375 | validation: 0.08271215850648547]
	TIME [epoch: 8.41 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06643825692987326		[learning rate: 1.6048e-05]
	Learning Rate: 1.6048e-05
	LOSS [training: 0.06643825692987326 | validation: 0.07507334000466319]
	TIME [epoch: 8.41 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06977058722182192		[learning rate: 1.599e-05]
	Learning Rate: 1.59898e-05
	LOSS [training: 0.06977058722182192 | validation: 0.08577470390754531]
	TIME [epoch: 8.44 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06683594273474786		[learning rate: 1.5932e-05]
	Learning Rate: 1.59317e-05
	LOSS [training: 0.06683594273474786 | validation: 0.08832529073043763]
	TIME [epoch: 8.41 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07460004223989894		[learning rate: 1.5874e-05]
	Learning Rate: 1.58739e-05
	LOSS [training: 0.07460004223989894 | validation: 0.08914925219964691]
	TIME [epoch: 8.4 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0760417702314112		[learning rate: 1.5816e-05]
	Learning Rate: 1.58163e-05
	LOSS [training: 0.0760417702314112 | validation: 0.08078890273500347]
	TIME [epoch: 8.4 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07063683414075221		[learning rate: 1.5759e-05]
	Learning Rate: 1.57589e-05
	LOSS [training: 0.07063683414075221 | validation: 0.08094507162486862]
	TIME [epoch: 8.43 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07220801819435332		[learning rate: 1.5702e-05]
	Learning Rate: 1.57017e-05
	LOSS [training: 0.07220801819435332 | validation: 0.08007177515617715]
	TIME [epoch: 8.41 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06960454201034202		[learning rate: 1.5645e-05]
	Learning Rate: 1.56447e-05
	LOSS [training: 0.06960454201034202 | validation: 0.08099152733850887]
	TIME [epoch: 8.4 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07526211701703249		[learning rate: 1.5588e-05]
	Learning Rate: 1.5588e-05
	LOSS [training: 0.07526211701703249 | validation: 0.07450375021677377]
	TIME [epoch: 8.39 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06656000074032932		[learning rate: 1.5531e-05]
	Learning Rate: 1.55314e-05
	LOSS [training: 0.06656000074032932 | validation: 0.07588448385001832]
	TIME [epoch: 8.43 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06986386949988445		[learning rate: 1.5475e-05]
	Learning Rate: 1.5475e-05
	LOSS [training: 0.06986386949988445 | validation: 0.08289846338092902]
	TIME [epoch: 8.4 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0695214488247899		[learning rate: 1.5419e-05]
	Learning Rate: 1.54189e-05
	LOSS [training: 0.0695214488247899 | validation: 0.08347105595437121]
	TIME [epoch: 8.4 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06221765504874789		[learning rate: 1.5363e-05]
	Learning Rate: 1.53629e-05
	LOSS [training: 0.06221765504874789 | validation: 0.08162863854895447]
	TIME [epoch: 8.41 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06847488869961799		[learning rate: 1.5307e-05]
	Learning Rate: 1.53072e-05
	LOSS [training: 0.06847488869961799 | validation: 0.08794259231941215]
	TIME [epoch: 8.44 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05904141056869322		[learning rate: 1.5252e-05]
	Learning Rate: 1.52516e-05
	LOSS [training: 0.05904141056869322 | validation: 0.0832380619844467]
	TIME [epoch: 8.42 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07742189784036839		[learning rate: 1.5196e-05]
	Learning Rate: 1.51963e-05
	LOSS [training: 0.07742189784036839 | validation: 0.08352692621458295]
	TIME [epoch: 8.41 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0647635293231929		[learning rate: 1.5141e-05]
	Learning Rate: 1.51411e-05
	LOSS [training: 0.0647635293231929 | validation: 0.09328200657566288]
	TIME [epoch: 8.4 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07191279390489336		[learning rate: 1.5086e-05]
	Learning Rate: 1.50862e-05
	LOSS [training: 0.07191279390489336 | validation: 0.08678510774515456]
	TIME [epoch: 8.43 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06571184240349048		[learning rate: 1.5031e-05]
	Learning Rate: 1.50314e-05
	LOSS [training: 0.06571184240349048 | validation: 0.09487189921573219]
	TIME [epoch: 8.41 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05944679159259804		[learning rate: 1.4977e-05]
	Learning Rate: 1.49769e-05
	LOSS [training: 0.05944679159259804 | validation: 0.08611374627061544]
	TIME [epoch: 8.4 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06687369885294452		[learning rate: 1.4923e-05]
	Learning Rate: 1.49225e-05
	LOSS [training: 0.06687369885294452 | validation: 0.07692758160522106]
	TIME [epoch: 8.42 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06337060009732329		[learning rate: 1.4868e-05]
	Learning Rate: 1.48684e-05
	LOSS [training: 0.06337060009732329 | validation: 0.09547838505521282]
	TIME [epoch: 8.42 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062244902775386746		[learning rate: 1.4814e-05]
	Learning Rate: 1.48144e-05
	LOSS [training: 0.062244902775386746 | validation: 0.08528563370017633]
	TIME [epoch: 8.4 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060527026634488515		[learning rate: 1.4761e-05]
	Learning Rate: 1.47606e-05
	LOSS [training: 0.060527026634488515 | validation: 0.07858819440872508]
	TIME [epoch: 8.41 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05686868188721329		[learning rate: 1.4707e-05]
	Learning Rate: 1.47071e-05
	LOSS [training: 0.05686868188721329 | validation: 0.08327231351100609]
	TIME [epoch: 8.42 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06558627877633857		[learning rate: 1.4654e-05]
	Learning Rate: 1.46537e-05
	LOSS [training: 0.06558627877633857 | validation: 0.08272844943808416]
	TIME [epoch: 8.42 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06071026707847815		[learning rate: 1.4601e-05]
	Learning Rate: 1.46005e-05
	LOSS [training: 0.06071026707847815 | validation: 0.07675347001999773]
	TIME [epoch: 8.41 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05738096503227397		[learning rate: 1.4548e-05]
	Learning Rate: 1.45475e-05
	LOSS [training: 0.05738096503227397 | validation: 0.07431744770791855]
	TIME [epoch: 8.4 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056892611847633986		[learning rate: 1.4495e-05]
	Learning Rate: 1.44947e-05
	LOSS [training: 0.056892611847633986 | validation: 0.08099447298578194]
	TIME [epoch: 8.42 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06542788424880779		[learning rate: 1.4442e-05]
	Learning Rate: 1.44421e-05
	LOSS [training: 0.06542788424880779 | validation: 0.07555675525848096]
	TIME [epoch: 8.42 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06745810499854858		[learning rate: 1.439e-05]
	Learning Rate: 1.43897e-05
	LOSS [training: 0.06745810499854858 | validation: 0.08043138719391887]
	TIME [epoch: 8.41 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0655243545319975		[learning rate: 1.4338e-05]
	Learning Rate: 1.43375e-05
	LOSS [training: 0.0655243545319975 | validation: 0.07729831999431198]
	TIME [epoch: 8.4 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059620583801171544		[learning rate: 1.4285e-05]
	Learning Rate: 1.42855e-05
	LOSS [training: 0.059620583801171544 | validation: 0.0747218905768624]
	TIME [epoch: 8.42 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058276246806913366		[learning rate: 1.4234e-05]
	Learning Rate: 1.42336e-05
	LOSS [training: 0.058276246806913366 | validation: 0.08938724669251215]
	TIME [epoch: 8.41 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06395605187775805		[learning rate: 1.4182e-05]
	Learning Rate: 1.4182e-05
	LOSS [training: 0.06395605187775805 | validation: 0.07641147805331583]
	TIME [epoch: 8.41 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06805444026295861		[learning rate: 1.4131e-05]
	Learning Rate: 1.41305e-05
	LOSS [training: 0.06805444026295861 | validation: 0.0833143366835451]
	TIME [epoch: 8.4 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06360562217825408		[learning rate: 1.4079e-05]
	Learning Rate: 1.40792e-05
	LOSS [training: 0.06360562217825408 | validation: 0.07916069721846264]
	TIME [epoch: 8.43 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059465904794867866		[learning rate: 1.4028e-05]
	Learning Rate: 1.40281e-05
	LOSS [training: 0.059465904794867866 | validation: 0.08084729877031957]
	TIME [epoch: 8.41 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06011990835400634		[learning rate: 1.3977e-05]
	Learning Rate: 1.39772e-05
	LOSS [training: 0.06011990835400634 | validation: 0.08441482357861496]
	TIME [epoch: 8.41 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07022967793449628		[learning rate: 1.3927e-05]
	Learning Rate: 1.39265e-05
	LOSS [training: 0.07022967793449628 | validation: 0.07937538514985155]
	TIME [epoch: 8.41 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0578457846475263		[learning rate: 1.3876e-05]
	Learning Rate: 1.3876e-05
	LOSS [training: 0.0578457846475263 | validation: 0.07761548557915061]
	TIME [epoch: 8.43 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06229132837415495		[learning rate: 1.3826e-05]
	Learning Rate: 1.38256e-05
	LOSS [training: 0.06229132837415495 | validation: 0.08856668793971283]
	TIME [epoch: 8.4 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06003329354966856		[learning rate: 1.3775e-05]
	Learning Rate: 1.37754e-05
	LOSS [training: 0.06003329354966856 | validation: 0.08637194840130391]
	TIME [epoch: 8.41 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06015834216701854		[learning rate: 1.3725e-05]
	Learning Rate: 1.37254e-05
	LOSS [training: 0.06015834216701854 | validation: 0.07122625537446214]
	TIME [epoch: 8.4 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05562579920942788		[learning rate: 1.3676e-05]
	Learning Rate: 1.36756e-05
	LOSS [training: 0.05562579920942788 | validation: 0.0919571837366954]
	TIME [epoch: 8.43 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06369147299048143		[learning rate: 1.3626e-05]
	Learning Rate: 1.3626e-05
	LOSS [training: 0.06369147299048143 | validation: 0.08571359772275505]
	TIME [epoch: 8.41 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06245239177975772		[learning rate: 1.3577e-05]
	Learning Rate: 1.35766e-05
	LOSS [training: 0.06245239177975772 | validation: 0.09177163413398234]
	TIME [epoch: 8.41 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0609174586277514		[learning rate: 1.3527e-05]
	Learning Rate: 1.35273e-05
	LOSS [training: 0.0609174586277514 | validation: 0.0821302682607552]
	TIME [epoch: 8.4 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06380738969274358		[learning rate: 1.3478e-05]
	Learning Rate: 1.34782e-05
	LOSS [training: 0.06380738969274358 | validation: 0.09134938690051705]
	TIME [epoch: 8.42 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0644028288405025		[learning rate: 1.3429e-05]
	Learning Rate: 1.34293e-05
	LOSS [training: 0.0644028288405025 | validation: 0.08381359689198886]
	TIME [epoch: 8.41 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058639001039158714		[learning rate: 1.3381e-05]
	Learning Rate: 1.33805e-05
	LOSS [training: 0.058639001039158714 | validation: 0.08263968771494327]
	TIME [epoch: 8.4 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059671592000296945		[learning rate: 1.3332e-05]
	Learning Rate: 1.3332e-05
	LOSS [training: 0.059671592000296945 | validation: 0.09081433691627235]
	TIME [epoch: 8.4 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06304827275879159		[learning rate: 1.3284e-05]
	Learning Rate: 1.32836e-05
	LOSS [training: 0.06304827275879159 | validation: 0.09847052874337779]
	TIME [epoch: 8.43 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05627194563862918		[learning rate: 1.3235e-05]
	Learning Rate: 1.32354e-05
	LOSS [training: 0.05627194563862918 | validation: 0.07681503501768855]
	TIME [epoch: 8.42 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058505532196857335		[learning rate: 1.3187e-05]
	Learning Rate: 1.31874e-05
	LOSS [training: 0.058505532196857335 | validation: 0.0777221549883975]
	TIME [epoch: 8.41 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06139946592340462		[learning rate: 1.314e-05]
	Learning Rate: 1.31395e-05
	LOSS [training: 0.06139946592340462 | validation: 0.08489405056350023]
	TIME [epoch: 8.42 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055463239229550564		[learning rate: 1.3092e-05]
	Learning Rate: 1.30918e-05
	LOSS [training: 0.055463239229550564 | validation: 0.09073295260398645]
	TIME [epoch: 8.41 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06372767079558891		[learning rate: 1.3044e-05]
	Learning Rate: 1.30443e-05
	LOSS [training: 0.06372767079558891 | validation: 0.08224361002484647]
	TIME [epoch: 8.4 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06378777097717615		[learning rate: 1.2997e-05]
	Learning Rate: 1.2997e-05
	LOSS [training: 0.06378777097717615 | validation: 0.08706868474090981]
	TIME [epoch: 8.4 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06553072147817288		[learning rate: 1.295e-05]
	Learning Rate: 1.29498e-05
	LOSS [training: 0.06553072147817288 | validation: 0.08073163877411421]
	TIME [epoch: 8.4 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05930326133972019		[learning rate: 1.2903e-05]
	Learning Rate: 1.29028e-05
	LOSS [training: 0.05930326133972019 | validation: 0.08989874496784075]
	TIME [epoch: 8.43 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06323300496065276		[learning rate: 1.2856e-05]
	Learning Rate: 1.2856e-05
	LOSS [training: 0.06323300496065276 | validation: 0.0830252799672011]
	TIME [epoch: 8.4 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058586106781422245		[learning rate: 1.2809e-05]
	Learning Rate: 1.28093e-05
	LOSS [training: 0.058586106781422245 | validation: 0.08325982873424202]
	TIME [epoch: 8.4 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05973290459982502		[learning rate: 1.2763e-05]
	Learning Rate: 1.27628e-05
	LOSS [training: 0.05973290459982502 | validation: 0.08742210020607519]
	TIME [epoch: 8.41 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06326071527147883		[learning rate: 1.2717e-05]
	Learning Rate: 1.27165e-05
	LOSS [training: 0.06326071527147883 | validation: 0.0840088507742968]
	TIME [epoch: 8.42 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0628033433494207		[learning rate: 1.267e-05]
	Learning Rate: 1.26704e-05
	LOSS [training: 0.0628033433494207 | validation: 0.08372845964062994]
	TIME [epoch: 8.4 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05832958806409487		[learning rate: 1.2624e-05]
	Learning Rate: 1.26244e-05
	LOSS [training: 0.05832958806409487 | validation: 0.07390427811329936]
	TIME [epoch: 8.4 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06978934096742477		[learning rate: 1.2579e-05]
	Learning Rate: 1.25786e-05
	LOSS [training: 0.06978934096742477 | validation: 0.08239404180953763]
	TIME [epoch: 8.4 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06170738052274109		[learning rate: 1.2533e-05]
	Learning Rate: 1.25329e-05
	LOSS [training: 0.06170738052274109 | validation: 0.07648753474729353]
	TIME [epoch: 8.42 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06151438774517395		[learning rate: 1.2487e-05]
	Learning Rate: 1.24874e-05
	LOSS [training: 0.06151438774517395 | validation: 0.08529419003132271]
	TIME [epoch: 8.4 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06393607539662235		[learning rate: 1.2442e-05]
	Learning Rate: 1.24421e-05
	LOSS [training: 0.06393607539662235 | validation: 0.08076317035336984]
	TIME [epoch: 8.39 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06504791923902982		[learning rate: 1.2397e-05]
	Learning Rate: 1.2397e-05
	LOSS [training: 0.06504791923902982 | validation: 0.07620242311354246]
	TIME [epoch: 8.4 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06664426406438055		[learning rate: 1.2352e-05]
	Learning Rate: 1.2352e-05
	LOSS [training: 0.06664426406438055 | validation: 0.08408213781171096]
	TIME [epoch: 8.42 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06143505511867357		[learning rate: 1.2307e-05]
	Learning Rate: 1.23072e-05
	LOSS [training: 0.06143505511867357 | validation: 0.0882159859350363]
	TIME [epoch: 8.4 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060287640405281825		[learning rate: 1.2263e-05]
	Learning Rate: 1.22625e-05
	LOSS [training: 0.060287640405281825 | validation: 0.0901988506896797]
	TIME [epoch: 8.4 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0562539933517513		[learning rate: 1.2218e-05]
	Learning Rate: 1.2218e-05
	LOSS [training: 0.0562539933517513 | validation: 0.08351829564905644]
	TIME [epoch: 8.4 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058743973113090084		[learning rate: 1.2174e-05]
	Learning Rate: 1.21737e-05
	LOSS [training: 0.058743973113090084 | validation: 0.09396474006049041]
	TIME [epoch: 8.42 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05548667884827487		[learning rate: 1.2129e-05]
	Learning Rate: 1.21295e-05
	LOSS [training: 0.05548667884827487 | validation: 0.09410042756002754]
	TIME [epoch: 8.4 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058876721060714544		[learning rate: 1.2085e-05]
	Learning Rate: 1.20855e-05
	LOSS [training: 0.058876721060714544 | validation: 0.0857023817410685]
	TIME [epoch: 8.4 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056081043303405964		[learning rate: 1.2042e-05]
	Learning Rate: 1.20416e-05
	LOSS [training: 0.056081043303405964 | validation: 0.08678171213852694]
	TIME [epoch: 8.41 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06460246682914789		[learning rate: 1.1998e-05]
	Learning Rate: 1.19979e-05
	LOSS [training: 0.06460246682914789 | validation: 0.0830205440464426]
	TIME [epoch: 8.4 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06136099361887828		[learning rate: 1.1954e-05]
	Learning Rate: 1.19544e-05
	LOSS [training: 0.06136099361887828 | validation: 0.08678468081749417]
	TIME [epoch: 8.4 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06128326211592601		[learning rate: 1.1911e-05]
	Learning Rate: 1.1911e-05
	LOSS [training: 0.06128326211592601 | validation: 0.07589412858034279]
	TIME [epoch: 8.39 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06331652640688194		[learning rate: 1.1868e-05]
	Learning Rate: 1.18678e-05
	LOSS [training: 0.06331652640688194 | validation: 0.08027434764257133]
	TIME [epoch: 8.42 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061749738364559846		[learning rate: 1.1825e-05]
	Learning Rate: 1.18247e-05
	LOSS [training: 0.061749738364559846 | validation: 0.07631619235233839]
	TIME [epoch: 8.41 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0596357355362776		[learning rate: 1.1782e-05]
	Learning Rate: 1.17818e-05
	LOSS [training: 0.0596357355362776 | validation: 0.08545021788817184]
	TIME [epoch: 8.39 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05921038124348632		[learning rate: 1.1739e-05]
	Learning Rate: 1.1739e-05
	LOSS [training: 0.05921038124348632 | validation: 0.08839450344152841]
	TIME [epoch: 8.4 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061185951714773326		[learning rate: 1.1696e-05]
	Learning Rate: 1.16964e-05
	LOSS [training: 0.061185951714773326 | validation: 0.08164847056560692]
	TIME [epoch: 8.4 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06636917065070408		[learning rate: 1.1654e-05]
	Learning Rate: 1.1654e-05
	LOSS [training: 0.06636917065070408 | validation: 0.08536125498118097]
	TIME [epoch: 8.41 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05909148656395509		[learning rate: 1.1612e-05]
	Learning Rate: 1.16117e-05
	LOSS [training: 0.05909148656395509 | validation: 0.08289284514121692]
	TIME [epoch: 8.39 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06397437204761966		[learning rate: 1.157e-05]
	Learning Rate: 1.15695e-05
	LOSS [training: 0.06397437204761966 | validation: 0.09461173261396001]
	TIME [epoch: 8.4 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05892867105511507		[learning rate: 1.1528e-05]
	Learning Rate: 1.15275e-05
	LOSS [training: 0.05892867105511507 | validation: 0.08247540516717859]
	TIME [epoch: 8.4 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059731020557943014		[learning rate: 1.1486e-05]
	Learning Rate: 1.14857e-05
	LOSS [training: 0.059731020557943014 | validation: 0.0832656167294216]
	TIME [epoch: 8.41 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058926915547181324		[learning rate: 1.1444e-05]
	Learning Rate: 1.1444e-05
	LOSS [training: 0.058926915547181324 | validation: 0.0849086708253537]
	TIME [epoch: 8.4 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0634344851799825		[learning rate: 1.1402e-05]
	Learning Rate: 1.14025e-05
	LOSS [training: 0.0634344851799825 | validation: 0.09177127060284783]
	TIME [epoch: 8.4 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06590404507680304		[learning rate: 1.1361e-05]
	Learning Rate: 1.13611e-05
	LOSS [training: 0.06590404507680304 | validation: 0.07091243472089206]
	TIME [epoch: 8.42 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06682779442791646		[learning rate: 1.132e-05]
	Learning Rate: 1.13199e-05
	LOSS [training: 0.06682779442791646 | validation: 0.08547854406121355]
	TIME [epoch: 8.4 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06014305060863969		[learning rate: 1.1279e-05]
	Learning Rate: 1.12788e-05
	LOSS [training: 0.06014305060863969 | validation: 0.0787812840390004]
	TIME [epoch: 8.41 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0630615435484489		[learning rate: 1.1238e-05]
	Learning Rate: 1.12379e-05
	LOSS [training: 0.0630615435484489 | validation: 0.080777218549621]
	TIME [epoch: 8.4 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06527089161843733		[learning rate: 1.1197e-05]
	Learning Rate: 1.11971e-05
	LOSS [training: 0.06527089161843733 | validation: 0.07291962008012733]
	TIME [epoch: 8.42 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057486628701272524		[learning rate: 1.1156e-05]
	Learning Rate: 1.11565e-05
	LOSS [training: 0.057486628701272524 | validation: 0.07772670867195375]
	TIME [epoch: 8.41 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05984392547600424		[learning rate: 1.1116e-05]
	Learning Rate: 1.1116e-05
	LOSS [training: 0.05984392547600424 | validation: 0.07768436977501735]
	TIME [epoch: 8.4 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06253007302007017		[learning rate: 1.1076e-05]
	Learning Rate: 1.10756e-05
	LOSS [training: 0.06253007302007017 | validation: 0.10016137632001323]
	TIME [epoch: 8.39 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06176843206312531		[learning rate: 1.1035e-05]
	Learning Rate: 1.10354e-05
	LOSS [training: 0.06176843206312531 | validation: 0.08500766379111419]
	TIME [epoch: 8.42 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058422181671851245		[learning rate: 1.0995e-05]
	Learning Rate: 1.09954e-05
	LOSS [training: 0.058422181671851245 | validation: 0.0831164001965051]
	TIME [epoch: 8.41 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05766934422949197		[learning rate: 1.0955e-05]
	Learning Rate: 1.09555e-05
	LOSS [training: 0.05766934422949197 | validation: 0.08972841450156151]
	TIME [epoch: 8.4 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061262618334061304		[learning rate: 1.0916e-05]
	Learning Rate: 1.09157e-05
	LOSS [training: 0.061262618334061304 | validation: 0.08592635617591594]
	TIME [epoch: 8.41 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054830264250768236		[learning rate: 1.0876e-05]
	Learning Rate: 1.08761e-05
	LOSS [training: 0.054830264250768236 | validation: 0.08939486574988001]
	TIME [epoch: 8.42 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05390122518906273		[learning rate: 1.0837e-05]
	Learning Rate: 1.08366e-05
	LOSS [training: 0.05390122518906273 | validation: 0.09451875233381832]
	TIME [epoch: 8.4 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06367012883218057		[learning rate: 1.0797e-05]
	Learning Rate: 1.07973e-05
	LOSS [training: 0.06367012883218057 | validation: 0.07508819452225998]
	TIME [epoch: 8.4 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06262411901182713		[learning rate: 1.0758e-05]
	Learning Rate: 1.07581e-05
	LOSS [training: 0.06262411901182713 | validation: 0.07423377624997393]
	TIME [epoch: 8.41 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06629215532449387		[learning rate: 1.0719e-05]
	Learning Rate: 1.07191e-05
	LOSS [training: 0.06629215532449387 | validation: 0.07810844418757674]
	TIME [epoch: 8.43 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05941490973874856		[learning rate: 1.068e-05]
	Learning Rate: 1.06802e-05
	LOSS [training: 0.05941490973874856 | validation: 0.0777534249705761]
	TIME [epoch: 8.41 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0673234425262671		[learning rate: 1.0641e-05]
	Learning Rate: 1.06414e-05
	LOSS [training: 0.0673234425262671 | validation: 0.07498907023951382]
	TIME [epoch: 8.4 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0671535842005584		[learning rate: 1.0603e-05]
	Learning Rate: 1.06028e-05
	LOSS [training: 0.0671535842005584 | validation: 0.08638501277675027]
	TIME [epoch: 8.41 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06895197991134429		[learning rate: 1.0564e-05]
	Learning Rate: 1.05643e-05
	LOSS [training: 0.06895197991134429 | validation: 0.08014076153291595]
	TIME [epoch: 8.43 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06734616630140325		[learning rate: 1.0526e-05]
	Learning Rate: 1.0526e-05
	LOSS [training: 0.06734616630140325 | validation: 0.08786698656003963]
	TIME [epoch: 8.4 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06854319412673869		[learning rate: 1.0488e-05]
	Learning Rate: 1.04878e-05
	LOSS [training: 0.06854319412673869 | validation: 0.09662369232069391]
	TIME [epoch: 8.4 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06779226732289396		[learning rate: 1.045e-05]
	Learning Rate: 1.04497e-05
	LOSS [training: 0.06779226732289396 | validation: 0.09287188156165246]
	TIME [epoch: 8.39 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06385444146102673		[learning rate: 1.0412e-05]
	Learning Rate: 1.04118e-05
	LOSS [training: 0.06385444146102673 | validation: 0.0775967288953326]
	TIME [epoch: 8.42 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057522847454969175		[learning rate: 1.0374e-05]
	Learning Rate: 1.0374e-05
	LOSS [training: 0.057522847454969175 | validation: 0.08466088456619547]
	TIME [epoch: 8.4 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06048202671290873		[learning rate: 1.0336e-05]
	Learning Rate: 1.03364e-05
	LOSS [training: 0.06048202671290873 | validation: 0.07942360447175946]
	TIME [epoch: 8.39 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062163376931901784		[learning rate: 1.0299e-05]
	Learning Rate: 1.02989e-05
	LOSS [training: 0.062163376931901784 | validation: 0.08328487915165775]
	TIME [epoch: 8.4 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057721296537944874		[learning rate: 1.0261e-05]
	Learning Rate: 1.02615e-05
	LOSS [training: 0.057721296537944874 | validation: 0.07638211101069078]
	TIME [epoch: 8.43 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05911305079419162		[learning rate: 1.0224e-05]
	Learning Rate: 1.02243e-05
	LOSS [training: 0.05911305079419162 | validation: 0.08947880254513912]
	TIME [epoch: 8.4 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0675989163626302		[learning rate: 1.0187e-05]
	Learning Rate: 1.01872e-05
	LOSS [training: 0.0675989163626302 | validation: 0.07928730185215008]
	TIME [epoch: 8.4 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06566915825867556		[learning rate: 1.015e-05]
	Learning Rate: 1.01502e-05
	LOSS [training: 0.06566915825867556 | validation: 0.09163329162012704]
	TIME [epoch: 8.39 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061803838101257766		[learning rate: 1.0113e-05]
	Learning Rate: 1.01133e-05
	LOSS [training: 0.061803838101257766 | validation: 0.07784971305639177]
	TIME [epoch: 8.42 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06125373540259403		[learning rate: 1.0077e-05]
	Learning Rate: 1.00766e-05
	LOSS [training: 0.06125373540259403 | validation: 0.07922428486723881]
	TIME [epoch: 8.39 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05848031333224474		[learning rate: 1.004e-05]
	Learning Rate: 1.00401e-05
	LOSS [training: 0.05848031333224474 | validation: 0.07858883547414992]
	TIME [epoch: 8.39 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06198255842640554		[learning rate: 1.0004e-05]
	Learning Rate: 1.00036e-05
	LOSS [training: 0.06198255842640554 | validation: 0.0855135654441824]
	TIME [epoch: 8.41 sec]
Finished training in 16974.759 seconds.
