Args:
Namespace(name='model_tr_study203', outdir='out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3', training_data='data/transition_rate_studies/tr_study203/tr_study203_training/r3', validation_data='data/transition_rate_studies/tr_study203/tr_study203_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1413187681

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.088008835762537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.088008835762537 | validation: 13.082852605547309]
	TIME [epoch: 98.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.708410965083871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.708410965083871 | validation: 12.800399027652878]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.297760978710194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.297760978710194 | validation: 12.888447571902503]
	TIME [epoch: 11.6 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.098569538085895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.098569538085895 | validation: 11.39452242532473]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.366493778617002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.366493778617002 | validation: 8.663907080149189]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.077035979131335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.077035979131335 | validation: 7.930431644594962]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.282917113148402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.282917113148402 | validation: 6.416308826526049]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.580562477757634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.580562477757634 | validation: 5.954708809827633]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.744741953987859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.744741953987859 | validation: 5.721129768150526]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.464592126383669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.464592126383669 | validation: 7.531303966763322]
	TIME [epoch: 11.6 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.538778951895305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.538778951895305 | validation: 5.20405666906188]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.786150163505724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.786150163505724 | validation: 5.619278843687105]
	TIME [epoch: 11.6 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.777907918393251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.777907918393251 | validation: 5.114563966705506]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.758563985347408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.758563985347408 | validation: 5.283117298953859]
	TIME [epoch: 11.6 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.542841557210389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.542841557210389 | validation: 5.379443859343944]
	TIME [epoch: 11.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.507561750516487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.507561750516487 | validation: 5.486833840172781]
	TIME [epoch: 11.6 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461143789470926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.461143789470926 | validation: 5.122361726010406]
	TIME [epoch: 11.6 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517661288194971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.517661288194971 | validation: 4.5520596588377575]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.251910113002926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.251910113002926 | validation: 6.685444805391303]
	TIME [epoch: 11.6 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.570899207468909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.570899207468909 | validation: 5.464396182386191]
	TIME [epoch: 11.7 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.278136151174772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.278136151174772 | validation: 4.541676046612825]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.09537847196416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.09537847196416 | validation: 4.353107482719353]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.068331420427671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.068331420427671 | validation: 4.504801070860781]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7036485052378705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7036485052378705 | validation: 5.107041580603069]
	TIME [epoch: 11.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0850491825984685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0850491825984685 | validation: 5.350360533544156]
	TIME [epoch: 11.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.126000959038854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.126000959038854 | validation: 4.441918277612741]
	TIME [epoch: 11.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.66823885837558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.66823885837558 | validation: 3.954280221982988]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8469448943738556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8469448943738556 | validation: 4.085051707375148]
	TIME [epoch: 11.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3938885287160536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3938885287160536 | validation: 3.8288331813336063]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.80172886030398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.80172886030398 | validation: 4.320329751234307]
	TIME [epoch: 11.7 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5079916823332185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5079916823332185 | validation: 4.200107806940002]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8249952635105258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8249952635105258 | validation: 4.27553058429214]
	TIME [epoch: 11.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.657829077923164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.657829077923164 | validation: 5.725329066937467]
	TIME [epoch: 11.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.857439842173163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.857439842173163 | validation: 4.074956472384862]
	TIME [epoch: 11.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4599308333466983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4599308333466983 | validation: 4.483563876163632]
	TIME [epoch: 11.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5479110933662588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5479110933662588 | validation: 4.418647762283157]
	TIME [epoch: 11.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9701430306800747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9701430306800747 | validation: 3.741804161864952]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4333790170451453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4333790170451453 | validation: 3.842222314450193]
	TIME [epoch: 11.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5121760566345372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5121760566345372 | validation: 3.8281009546930393]
	TIME [epoch: 11.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.489580995675053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.489580995675053 | validation: 3.70276694329334]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.500533416174599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.500533416174599 | validation: 3.7382715057243128]
	TIME [epoch: 11.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.289218420205744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.289218420205744 | validation: 4.265937393459216]
	TIME [epoch: 11.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8138569957929827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8138569957929827 | validation: 4.222893798911307]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374834344734561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.374834344734561 | validation: 4.532864517593787]
	TIME [epoch: 11.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5461063587640065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5461063587640065 | validation: 3.8856410548356894]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3841337529299875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3841337529299875 | validation: 4.192921962874022]
	TIME [epoch: 11.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.256321800555237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.256321800555237 | validation: 4.262139700634321]
	TIME [epoch: 11.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2470249865118728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2470249865118728 | validation: 4.5474318963777955]
	TIME [epoch: 11.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3830177180992127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3830177180992127 | validation: 3.8911596328858504]
	TIME [epoch: 11.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.263564391007985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.263564391007985 | validation: 3.773136047371061]
	TIME [epoch: 11.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218900935941821		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.218900935941821 | validation: 4.071687460808378]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5439514812985298		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.5439514812985298 | validation: 3.783922872027864]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0051506902432172		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.0051506902432172 | validation: 3.7097169837133124]
	TIME [epoch: 11.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2362173178955245		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.2362173178955245 | validation: 3.457029081762177]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226124665272264		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.226124665272264 | validation: 3.716328554036753]
	TIME [epoch: 11.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.128431423249328		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.128431423249328 | validation: 4.153762392836508]
	TIME [epoch: 11.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.526834712262044		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.526834712262044 | validation: 3.5018527276133113]
	TIME [epoch: 11.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.140648194460184		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.140648194460184 | validation: 3.6160857836167146]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9785013287897852		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.9785013287897852 | validation: 3.973239315881503]
	TIME [epoch: 11.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0797724353520306		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.0797724353520306 | validation: 3.4751908104336633]
	TIME [epoch: 11.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.164685523489371		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.164685523489371 | validation: 3.6007327816062698]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.256919923376746		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.256919923376746 | validation: 3.9056784908815905]
	TIME [epoch: 11.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0656615745302593		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.0656615745302593 | validation: 3.4381015593818836]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.151624112131922		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.151624112131922 | validation: 3.6840043896925967]
	TIME [epoch: 11.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7858409019297987		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.7858409019297987 | validation: 3.865496997538082]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.165254167081705		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.165254167081705 | validation: 3.4551746710103077]
	TIME [epoch: 11.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.890589511558474		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.890589511558474 | validation: 3.5669517499086436]
	TIME [epoch: 11.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9728565887075145		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.9728565887075145 | validation: 4.315137595519303]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1802318894794763		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.1802318894794763 | validation: 3.845785505553296]
	TIME [epoch: 11.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.979454449335548		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.979454449335548 | validation: 3.6966858163477276]
	TIME [epoch: 11.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.049541377743465		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.049541377743465 | validation: 3.436972236997174]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8846950196769168		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.8846950196769168 | validation: 4.014832515295994]
	TIME [epoch: 11.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250840541536523		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.250840541536523 | validation: 3.6132949396587413]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8786565531307273		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.8786565531307273 | validation: 4.112892730721025]
	TIME [epoch: 11.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.992482523674904		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.992482523674904 | validation: 3.657251878627205]
	TIME [epoch: 11.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9058045879482504		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.9058045879482504 | validation: 3.2552704987569547]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0600818123192837		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.0600818123192837 | validation: 3.380220760958214]
	TIME [epoch: 11.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7087913947815325		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.7087913947815325 | validation: 3.5514674546386296]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8171326860623007		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.8171326860623007 | validation: 3.6682041795670877]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9474689956596043		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.9474689956596043 | validation: 3.7698225425952887]
	TIME [epoch: 11.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.95829899498695		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.95829899498695 | validation: 3.5562265165174067]
	TIME [epoch: 11.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.035999002462277		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.035999002462277 | validation: 3.351119891496356]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7876956992244555		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.7876956992244555 | validation: 3.3003148488110003]
	TIME [epoch: 11.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8375485141029317		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.8375485141029317 | validation: 3.506556754330976]
	TIME [epoch: 11.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7050195678834155		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.7050195678834155 | validation: 3.3789166819697516]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.90625164854541		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.90625164854541 | validation: 4.411767320170396]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.043025877474432		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.043025877474432 | validation: 3.9390461714327603]
	TIME [epoch: 11.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.848495635204117		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.848495635204117 | validation: 3.382969565844639]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7030747046240244		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.7030747046240244 | validation: 3.598507691524084]
	TIME [epoch: 11.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.789515914819093		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.789515914819093 | validation: 3.257913105750887]
	TIME [epoch: 11.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8863149951232074		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.8863149951232074 | validation: 3.723396408632026]
	TIME [epoch: 11.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2773923009805532		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.2773923009805532 | validation: 3.3111290195000596]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8269973692620907		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.8269973692620907 | validation: 4.511611671916491]
	TIME [epoch: 11.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.503325403845425		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.503325403845425 | validation: 4.039419479613697]
	TIME [epoch: 11.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4794365754463925		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.4794365754463925 | validation: 4.229253797482271]
	TIME [epoch: 11.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9909543144986257		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.9909543144986257 | validation: 3.3754815369412374]
	TIME [epoch: 11.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.829320348726264		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.829320348726264 | validation: 3.4520750522818457]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.883547488734792		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.883547488734792 | validation: 3.3919523267509346]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.769374092495731		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.769374092495731 | validation: 3.4542864809621228]
	TIME [epoch: 11.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.634796356927984		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.634796356927984 | validation: 3.2378029164714013]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6941996229551446		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.6941996229551446 | validation: 3.578658662701505]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7789090877921288		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.7789090877921288 | validation: 3.206406315387222]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6465157697327935		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.6465157697327935 | validation: 3.2155941434007866]
	TIME [epoch: 11.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.594266636676059		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.594266636676059 | validation: 3.359341383073073]
	TIME [epoch: 11.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7036411511439686		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.7036411511439686 | validation: 3.2281393586796066]
	TIME [epoch: 11.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7095521705760874		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.7095521705760874 | validation: 3.1057575425081247]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5967051040927456		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.5967051040927456 | validation: 3.086328189070292]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5875695775792886		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.5875695775792886 | validation: 4.484276586943658]
	TIME [epoch: 11.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20166584817136		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.20166584817136 | validation: 3.586334403517728]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.634867467298248		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.634867467298248 | validation: 3.2172143485106153]
	TIME [epoch: 11.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5008720999090994		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.5008720999090994 | validation: 3.0347871779422464]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369795734624864		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.369795734624864 | validation: 6.87622187398158]
	TIME [epoch: 11.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.927960549072165		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.927960549072165 | validation: 3.741025577072967]
	TIME [epoch: 11.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5684153883355383		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.5684153883355383 | validation: 3.1148766924217512]
	TIME [epoch: 11.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3853361102593063		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.3853361102593063 | validation: 3.4902152930305737]
	TIME [epoch: 11.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.659723884836743		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.659723884836743 | validation: 2.902682405495986]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.373371942028014		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.373371942028014 | validation: 3.3573861292409597]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4343545368124855		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.4343545368124855 | validation: 2.926361888192711]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.394787339497618		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.394787339497618 | validation: 3.089303720975829]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5874461028418443		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.5874461028418443 | validation: 2.9123540955780687]
	TIME [epoch: 11.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281362591012597		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.281362591012597 | validation: 2.8319097170835796]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450447001756812		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.450447001756812 | validation: 3.0621402346416073]
	TIME [epoch: 11.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8790324007902193		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.8790324007902193 | validation: 4.796747448437714]
	TIME [epoch: 11.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2084671231541986		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.2084671231541986 | validation: 3.6855384010664087]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8212511179043176		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.8212511179043176 | validation: 2.963962152513983]
	TIME [epoch: 11.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3837238630112094		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.3837238630112094 | validation: 3.273023084263448]
	TIME [epoch: 11.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3471048529906486		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.3471048529906486 | validation: 3.218340475977515]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.518553051039677		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.518553051039677 | validation: 3.409626700326115]
	TIME [epoch: 11.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2637873783722027		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.2637873783722027 | validation: 3.0713163131305747]
	TIME [epoch: 11.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3710236767844233		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.3710236767844233 | validation: 2.992008363211744]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4018016713264867		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.4018016713264867 | validation: 2.8897690088671255]
	TIME [epoch: 11.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2860005209148664		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.2860005209148664 | validation: 3.826229195512198]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.424493436048617		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.424493436048617 | validation: 2.8932408590080345]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3124536516000758		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.3124536516000758 | validation: 2.7297595875554386]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3221852123279794		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.3221852123279794 | validation: 3.6250130855818488]
	TIME [epoch: 11.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.478270034143662		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.478270034143662 | validation: 2.9663234198092794]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2055340033859965		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.2055340033859965 | validation: 2.797096738866053]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360412634337603		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.360412634337603 | validation: 2.9157249430386676]
	TIME [epoch: 11.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.176247909368207		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.176247909368207 | validation: 2.9504644066902848]
	TIME [epoch: 11.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2146361491081947		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.2146361491081947 | validation: 3.1809309525103413]
	TIME [epoch: 11.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4056279407382357		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.4056279407382357 | validation: 2.688536819918588]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2663637831378836		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.2663637831378836 | validation: 2.85340121261881]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2136499950617416		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.2136499950617416 | validation: 2.767183165898864]
	TIME [epoch: 11.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2340768537000737		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.2340768537000737 | validation: 2.8826378568948683]
	TIME [epoch: 11.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.481389466266144		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.481389466266144 | validation: 2.710099144631016]
	TIME [epoch: 11.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1445145704424897		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.1445145704424897 | validation: 3.510599257626012]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6000071280494534		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.6000071280494534 | validation: 3.267049653970762]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6503284272671843		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.6503284272671843 | validation: 2.8091409097993143]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1595186128353814		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 2.1595186128353814 | validation: 3.1035359730959056]
	TIME [epoch: 11.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2991059742667694		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.2991059742667694 | validation: 2.647530517853653]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0986549886819184		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.0986549886819184 | validation: 2.702294003915021]
	TIME [epoch: 11.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.100395734656279		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.100395734656279 | validation: 3.520754860500869]
	TIME [epoch: 11.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2414894951753066		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.2414894951753066 | validation: 3.6010208013417526]
	TIME [epoch: 11.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.363971802050093		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.363971802050093 | validation: 2.619401228870181]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2052480090503583		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.2052480090503583 | validation: 2.6850711558316256]
	TIME [epoch: 11.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2023719268889095		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.2023719268889095 | validation: 2.6250072409872325]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0868413278883216		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.0868413278883216 | validation: 2.823165163619916]
	TIME [epoch: 11.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.099618455659587		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.099618455659587 | validation: 2.5608408565653837]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2950717949308572		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.2950717949308572 | validation: 2.8219794260253]
	TIME [epoch: 11.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1435933277320003		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.1435933277320003 | validation: 2.5790117639889463]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0454469641448383		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.0454469641448383 | validation: 2.9414872647062498]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.169021158186594		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.169021158186594 | validation: 3.0703986814516737]
	TIME [epoch: 11.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.168290785200659		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.168290785200659 | validation: 2.666827847443094]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044247986163734		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.044247986163734 | validation: 2.7437491982050393]
	TIME [epoch: 11.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0246186676507323		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.0246186676507323 | validation: 2.5207698636131206]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9471812304744542		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.9471812304744542 | validation: 3.3310193463716833]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.200467730298544		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.200467730298544 | validation: 2.82384608011244]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1426565716445944		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.1426565716445944 | validation: 2.5209487228657754]
	TIME [epoch: 11.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9038477411652415		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.9038477411652415 | validation: 2.44841754606267]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8987028813046865		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.8987028813046865 | validation: 3.0923258579528574]
	TIME [epoch: 11.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.032910340960458		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.032910340960458 | validation: 3.0178797918660645]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064402956633039		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.064402956633039 | validation: 2.637153360908609]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9997889939161932		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.9997889939161932 | validation: 2.5288607252818647]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.080688963973186		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.080688963973186 | validation: 2.6190786722396053]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9427026402018086		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.9427026402018086 | validation: 2.826744400604726]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9086835168001937		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.9086835168001937 | validation: 3.117432903296934]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2559237509999837		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.2559237509999837 | validation: 2.33491052171287]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7307746564790123		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.7307746564790123 | validation: 2.983903274438664]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3488214929458557		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.3488214929458557 | validation: 2.514204430470031]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2319837096297745		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.2319837096297745 | validation: 2.5278876421555005]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9522856707163772		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.9522856707163772 | validation: 2.678723181689319]
	TIME [epoch: 11.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.049665217050536		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.049665217050536 | validation: 3.6966890252848508]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298087137639714		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.298087137639714 | validation: 4.086557205280451]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.53437657293167		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.53437657293167 | validation: 2.9174361070837698]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248303694791998		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.248303694791998 | validation: 2.4926839372992]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.377736021220371		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.377736021220371 | validation: 2.4979095056933653]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257197473872495		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.257197473872495 | validation: 2.474297641607698]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.138574420151283		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.138574420151283 | validation: 2.6920237212218856]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9630357473792759		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.9630357473792759 | validation: 2.437612145536797]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9541875459991416		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.9541875459991416 | validation: 3.478522378701559]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.138738913214106		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.138738913214106 | validation: 2.927727862033523]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9403480435672078		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.9403480435672078 | validation: 2.477226709146438]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.738117282973165		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.738117282973165 | validation: 2.9023064140546326]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.89095616913084		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.89095616913084 | validation: 2.5995900153026668]
	TIME [epoch: 11.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0842629349114534		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.0842629349114534 | validation: 2.3227255180899]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8767422400153406		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.8767422400153406 | validation: 2.402437796338283]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7790832798243226		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.7790832798243226 | validation: 2.6592125897342167]
	TIME [epoch: 11.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.087459553565936		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.087459553565936 | validation: 3.60508487303832]
	TIME [epoch: 11.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245668349122776		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.245668349122776 | validation: 2.5885577113642326]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.83611878396518		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.83611878396518 | validation: 2.477643322618902]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8839437026942014		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.8839437026942014 | validation: 3.210884833944457]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3397390478513658		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.3397390478513658 | validation: 2.404905368343059]
	TIME [epoch: 11.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.198600697073453		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.198600697073453 | validation: 2.576359378596348]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8721579554944294		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.8721579554944294 | validation: 2.458566382863337]
	TIME [epoch: 11.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8495493774428002		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.8495493774428002 | validation: 2.339209753951485]
	TIME [epoch: 11.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7283455501601002		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.7283455501601002 | validation: 2.572787396744271]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7905853649936918		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.7905853649936918 | validation: 2.4213837486033403]
	TIME [epoch: 11.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.765084870647078		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.765084870647078 | validation: 2.574366693462259]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.794279848775262		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.794279848775262 | validation: 2.19712521192377]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.706812613714838		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.706812613714838 | validation: 2.494522002682306]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8250832260248095		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.8250832260248095 | validation: 2.3484995060994014]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7927002174052724		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.7927002174052724 | validation: 2.678529594279479]
	TIME [epoch: 11.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.796252746598424		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.796252746598424 | validation: 2.4365540240166053]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416613721783551		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.416613721783551 | validation: 2.99469001796298]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9412592682553549		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.9412592682553549 | validation: 2.271701391243651]
	TIME [epoch: 11.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.64302361859863		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.64302361859863 | validation: 2.2691686761203282]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.888259960817924		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.888259960817924 | validation: 2.2805770585904037]
	TIME [epoch: 11.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6411276889591708		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.6411276889591708 | validation: 2.6142801638170603]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0955852013617475		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.0955852013617475 | validation: 2.8340932598757944]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.882449244426443		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.882449244426443 | validation: 2.6146933619048007]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7866776179356045		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.7866776179356045 | validation: 2.200561164218984]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.801410067143088		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.801410067143088 | validation: 2.321166888110684]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8877629222256105		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.8877629222256105 | validation: 2.662166556116385]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7146841429904869		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.7146841429904869 | validation: 2.7879905638648688]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7866573616751389		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.7866573616751389 | validation: 2.3363030118180275]
	TIME [epoch: 11.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7766769386951882		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.7766769386951882 | validation: 2.4333971856339844]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.171354133086943		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.171354133086943 | validation: 2.507137099753627]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0372498766614853		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.0372498766614853 | validation: 2.3643440777507876]
	TIME [epoch: 11.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7745583697388045		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.7745583697388045 | validation: 2.2439189894168643]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9043156235055383		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.9043156235055383 | validation: 2.304744710304768]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7141961992464263		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.7141961992464263 | validation: 2.343326113576464]
	TIME [epoch: 11.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.351857387986092		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.351857387986092 | validation: 3.295444933103662]
	TIME [epoch: 11.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.195753597528492		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.195753597528492 | validation: 2.7999462839306104]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8785174466735128		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.8785174466735128 | validation: 2.7104786197767217]
	TIME [epoch: 11.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8601611896948673		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.8601611896948673 | validation: 2.585900698965247]
	TIME [epoch: 11.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8125630405002062		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.8125630405002062 | validation: 2.218752105980518]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7822472699555578		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.7822472699555578 | validation: 2.3325733060232823]
	TIME [epoch: 11.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6864129778288923		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.6864129778288923 | validation: 2.3232435482743514]
	TIME [epoch: 11.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.615788186182405		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.615788186182405 | validation: 2.4777576928953584]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6675607853540622		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.6675607853540622 | validation: 3.0461292770944977]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457422826143354		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.2457422826143354 | validation: 2.6567882233116182]
	TIME [epoch: 11.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.771882879512879		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.771882879512879 | validation: 2.517029439442104]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6828781308649772		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.6828781308649772 | validation: 2.6876108216786894]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.877261012726721		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.877261012726721 | validation: 2.5614126293760546]
	TIME [epoch: 11.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.74698030779367		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.74698030779367 | validation: 2.7806527322598003]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7591805483538108		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.7591805483538108 | validation: 2.3005184641965757]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9355122244775163		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.9355122244775163 | validation: 2.345937015902204]
	TIME [epoch: 11.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0606369744944386		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.0606369744944386 | validation: 2.2234523279424003]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7269335329719038		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.7269335329719038 | validation: 2.2796912843556254]
	TIME [epoch: 11.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.865649871094115		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.865649871094115 | validation: 2.5017798647155907]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.762161060965281		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.762161060965281 | validation: 2.6268102400222815]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7988554590306052		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.7988554590306052 | validation: 2.3929598794180107]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7948643202070822		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.7948643202070822 | validation: 2.1874993072797104]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2607508964273135		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.2607508964273135 | validation: 3.6126220033252805]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.140491535557644		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.140491535557644 | validation: 2.246206034463832]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9226182390191755		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.9226182390191755 | validation: 2.3843015157568925]
	TIME [epoch: 11.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7854325985852402		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.7854325985852402 | validation: 2.351721543040175]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.673928176271946		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.673928176271946 | validation: 2.2662817247292186]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.593029028208327		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.593029028208327 | validation: 2.4053941953765254]
	TIME [epoch: 11.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.86166683650092		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.86166683650092 | validation: 2.3142835450113384]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.920856743221856		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.920856743221856 | validation: 2.428842630341955]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8053778512096517		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.8053778512096517 | validation: 2.2647649086296218]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093939384866604		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.093939384866604 | validation: 2.4117138250162657]
	TIME [epoch: 11.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8897858104630347		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.8897858104630347 | validation: 2.4132406334862475]
	TIME [epoch: 11.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8048291445404636		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.8048291445404636 | validation: 2.243780419141863]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7415969000313332		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.7415969000313332 | validation: 2.2566010682351227]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6462626171948997		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.6462626171948997 | validation: 2.232314953533923]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6211077228286892		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.6211077228286892 | validation: 2.961885144668172]
	TIME [epoch: 11.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8620866306045538		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.8620866306045538 | validation: 2.309694454307601]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7070427124318117		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.7070427124318117 | validation: 2.907885180173513]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.802970980639889		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.802970980639889 | validation: 2.33672215435251]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6452719582416835		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.6452719582416835 | validation: 2.1937091882537865]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7280128451818253		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.7280128451818253 | validation: 2.192250242145821]
	TIME [epoch: 11.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.573104013766575		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.573104013766575 | validation: 2.2232634304652046]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.109714887136594		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.109714887136594 | validation: 2.3509272715043683]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9094984245126276		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.9094984245126276 | validation: 2.40805384014016]
	TIME [epoch: 11.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6959779497167224		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.6959779497167224 | validation: 2.4008624483783128]
	TIME [epoch: 11.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7557126697505863		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.7557126697505863 | validation: 2.6179422324831374]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6344549499948697		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.6344549499948697 | validation: 2.323615423616516]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.708775885523877		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.708775885523877 | validation: 2.34230655854672]
	TIME [epoch: 11.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6786633765429644		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.6786633765429644 | validation: 2.3098619067417503]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5934756475169791		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.5934756475169791 | validation: 2.6150224208221178]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6706640388980258		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.6706640388980258 | validation: 2.422060128223133]
	TIME [epoch: 11.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7222077274469176		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.7222077274469176 | validation: 2.5711231422082466]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6811162543846025		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.6811162543846025 | validation: 2.3405357692707605]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6924216451140697		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.6924216451140697 | validation: 2.275256205039507]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.739030401631788		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.739030401631788 | validation: 2.1748998255931338]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6918345611791406		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.6918345611791406 | validation: 2.6427995973803924]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8369387899115694		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.8369387899115694 | validation: 2.953095699717534]
	TIME [epoch: 11.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8854938392443215		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.8854938392443215 | validation: 2.730629262824808]
	TIME [epoch: 11.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6621376452614383		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.6621376452614383 | validation: 2.2744439978729236]
	TIME [epoch: 11.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.564797291031851		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.564797291031851 | validation: 2.2009016508832002]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5576389889369822		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.5576389889369822 | validation: 2.2823543535287047]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6668221721054648		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.6668221721054648 | validation: 2.3963664847950805]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.592178013057124		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.592178013057124 | validation: 3.398078103241003]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1293028275635275		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.1293028275635275 | validation: 2.5197198831292007]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5344077034166377		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.5344077034166377 | validation: 2.573612979651598]
	TIME [epoch: 11.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6013430706698433		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.6013430706698433 | validation: 2.5295456767399167]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6999742765889159		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.6999742765889159 | validation: 2.1212826654083576]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5749134144630905		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.5749134144630905 | validation: 2.195188732418631]
	TIME [epoch: 11.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5577638443302741		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.5577638443302741 | validation: 2.1984439510585374]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6033672033188089		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.6033672033188089 | validation: 2.2984171559546183]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5574550444025987		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.5574550444025987 | validation: 2.5252767107125993]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.590412324904509		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.590412324904509 | validation: 2.2171574943179895]
	TIME [epoch: 11.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.631391031383		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.631391031383 | validation: 2.229520108383847]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5564457957715443		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.5564457957715443 | validation: 2.5997329752615315]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5680127216511441		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.5680127216511441 | validation: 2.18762963291958]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7824367644554653		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.7824367644554653 | validation: 3.5534699883586915]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0668761966612346		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.0668761966612346 | validation: 2.24286763375534]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5054326161806681		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.5054326161806681 | validation: 2.2107671986163884]
	TIME [epoch: 11.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5006226164668621		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.5006226164668621 | validation: 2.2212878160312464]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5507693047193425		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.5507693047193425 | validation: 2.077003474392093]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5224775376877164		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.5224775376877164 | validation: 2.5014620267265486]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.627933605127902		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.627933605127902 | validation: 2.3502550877739474]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7191687593983216		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.7191687593983216 | validation: 2.14326815073997]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.497281625505451		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.497281625505451 | validation: 2.1941621004402667]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5277038812203942		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.5277038812203942 | validation: 2.3767911631777854]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8072812837017458		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.8072812837017458 | validation: 2.17623973159061]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4871841536461563		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.4871841536461563 | validation: 2.1641070226079933]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5397194092477868		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.5397194092477868 | validation: 2.140451067171422]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4870670423852106		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.4870670423852106 | validation: 2.1233270320503115]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4813717345998623		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.4813717345998623 | validation: 2.264779761303207]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.541817965552339		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.541817965552339 | validation: 2.2931351877049724]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.572978376404851		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.572978376404851 | validation: 2.3169471660462104]
	TIME [epoch: 11.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5225679086557442		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.5225679086557442 | validation: 2.3462817684816737]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5099712930974958		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.5099712930974958 | validation: 2.2557357757867673]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.543478995854489		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.543478995854489 | validation: 2.150963230259294]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.52326350838797		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.52326350838797 | validation: 2.0522542422657986]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0449905332835954		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.0449905332835954 | validation: 2.3015542709375523]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4984446871902661		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.4984446871902661 | validation: 2.099986007865299]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5092858480611893		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.5092858480611893 | validation: 2.115943837895173]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5020035175490274		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.5020035175490274 | validation: 2.1587671996814297]
	TIME [epoch: 11.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4567955710644789		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.4567955710644789 | validation: 2.542772621333968]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6621373803274244		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.6621373803274244 | validation: 2.822184918088443]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7030389857572965		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.7030389857572965 | validation: 2.5547396620935183]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.686519414430954		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.686519414430954 | validation: 2.1297961195058366]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.465392736405943		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.465392736405943 | validation: 2.322560088594112]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7004744391609241		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.7004744391609241 | validation: 2.245357125500958]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7190799856495724		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.7190799856495724 | validation: 2.370027684597587]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.472690812292512		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.472690812292512 | validation: 2.314717057914216]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4583436586931076		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.4583436586931076 | validation: 2.776251544477325]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7112412627230666		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.7112412627230666 | validation: 2.873852321427877]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7268390087266139		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.7268390087266139 | validation: 2.486758999881662]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5933902500526231		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.5933902500526231 | validation: 2.554996406626596]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6268285661794872		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.6268285661794872 | validation: 2.451432307460315]
	TIME [epoch: 11.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7009206759920799		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.7009206759920799 | validation: 2.3969733677537035]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.596016084723602		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.596016084723602 | validation: 2.2395521252417647]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4983610592577232		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.4983610592577232 | validation: 2.150795956344574]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4693111996503978		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.4693111996503978 | validation: 2.3193045437380007]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5594290332769023		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.5594290332769023 | validation: 2.054407423314242]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4753422195131585		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.4753422195131585 | validation: 2.2333044822668113]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7591847257959436		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.7591847257959436 | validation: 2.309275729059848]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.676222265413504		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.676222265413504 | validation: 2.14643841186022]
	TIME [epoch: 11.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6382738272250044		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.6382738272250044 | validation: 2.181303062976078]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5687696924871697		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.5687696924871697 | validation: 2.101850788355002]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.446040316037419		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.446040316037419 | validation: 2.364763026075086]
	TIME [epoch: 11.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.482611517456096		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.482611517456096 | validation: 2.558457564208499]
	TIME [epoch: 11.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5680306688473258		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.5680306688473258 | validation: 2.312457235202701]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4571874427750893		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.4571874427750893 | validation: 2.228611762138006]
	TIME [epoch: 11.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4580962175591263		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.4580962175591263 | validation: 2.4381851953386686]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.534966649353262		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.534966649353262 | validation: 2.0911763892478668]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5775459468924233		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.5775459468924233 | validation: 2.090262281181996]
	TIME [epoch: 11.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.488532458332501		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.488532458332501 | validation: 2.3308460105466042]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4269339414915774		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.4269339414915774 | validation: 2.051712226623584]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6470485717484638		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.6470485717484638 | validation: 2.13906143883758]
	TIME [epoch: 11.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.598981035621216		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.598981035621216 | validation: 2.2483893848940184]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.610055088109058		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.610055088109058 | validation: 2.385211204142441]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5226394150373528		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.5226394150373528 | validation: 2.3981149262787698]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.628285592910256		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.628285592910256 | validation: 2.7274729491605147]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6872258661791397		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.6872258661791397 | validation: 2.206549599634517]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4021668571745223		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.4021668571745223 | validation: 2.0857758550164895]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4214605383326453		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.4214605383326453 | validation: 2.3434452319071273]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4510385531740086		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.4510385531740086 | validation: 2.4623799270297555]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5831243459750928		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.5831243459750928 | validation: 2.11809595734308]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5033432274988199		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.5033432274988199 | validation: 2.0330744267048964]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_375.pth
	Model improved!!!
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4286986592908344		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.4286986592908344 | validation: 2.1818399566989957]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4603000769111574		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.4603000769111574 | validation: 2.185924291423737]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4988037193537416		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.4988037193537416 | validation: 2.029173049231616]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6374183274106957		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.6374183274106957 | validation: 2.206840310559554]
	TIME [epoch: 11.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6372890332176595		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.6372890332176595 | validation: 2.147848000148098]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5707725666668473		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.5707725666668473 | validation: 2.0810107707770085]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.515977128295098		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.515977128295098 | validation: 2.602860024575223]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4738738801073872		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.4738738801073872 | validation: 2.1108128508841757]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7691318548974966		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.7691318548974966 | validation: 2.4832661886456635]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5319716502071723		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.5319716502071723 | validation: 2.195720320854568]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4186695539998815		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.4186695539998815 | validation: 2.0870530134159644]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4249001303770712		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.4249001303770712 | validation: 2.090958533530237]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5088623847420266		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.5088623847420266 | validation: 2.1831346128061226]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4674294848668368		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.4674294848668368 | validation: 2.4415008980164057]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4718105986203822		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.4718105986203822 | validation: 2.1367163641586577]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.419797017879261		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.419797017879261 | validation: 2.285826559737072]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.502386212693343		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.502386212693343 | validation: 3.4435244629419572]
	TIME [epoch: 11.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8617170310768367		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.8617170310768367 | validation: 2.221132326830292]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.362792612350874		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.362792612350874 | validation: 2.1428672822643837]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3730919596006903		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.3730919596006903 | validation: 2.102337391660449]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8715092056549056		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.8715092056549056 | validation: 2.658014038646765]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7094151204544386		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.7094151204544386 | validation: 2.270805947223536]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4013978912878104		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.4013978912878104 | validation: 2.320279134469454]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4632179045090243		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.4632179045090243 | validation: 2.5570228045618637]
	TIME [epoch: 11.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.491986631167175		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.491986631167175 | validation: 2.2661106209885147]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4205177495566692		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.4205177495566692 | validation: 2.2091349542356955]
	TIME [epoch: 11.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5207554309231766		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.5207554309231766 | validation: 2.1413966975250274]
	TIME [epoch: 11.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4850060888276033		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.4850060888276033 | validation: 2.0702125029215215]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4274127515236816		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.4274127515236816 | validation: 2.048370564531373]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3946547890822543		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.3946547890822543 | validation: 2.01129417986731]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3466436925325174		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.3466436925325174 | validation: 2.646918288613106]
	TIME [epoch: 11.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6519222246271723		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.6519222246271723 | validation: 2.1754050909258074]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3146268208301712		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.3146268208301712 | validation: 2.075103940502475]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3969187034871777		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.3969187034871777 | validation: 2.149293866606688]
	TIME [epoch: 11.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5414940620477868		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.5414940620477868 | validation: 2.3043093917088777]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4500766073487386		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.4500766073487386 | validation: 2.401426172191757]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4913947889835306		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.4913947889835306 | validation: 3.0087566573313542]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7061873559490364		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.7061873559490364 | validation: 2.1930554962247277]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.448852198822348		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.448852198822348 | validation: 2.2803092262481703]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.350959163486133		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.350959163486133 | validation: 2.0319361115736916]
	TIME [epoch: 11.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4866592332697017		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.4866592332697017 | validation: 2.0921620488625785]
	TIME [epoch: 11.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3248133724012126		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.3248133724012126 | validation: 2.1648214934716457]
	TIME [epoch: 11.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3593301018899415		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.3593301018899415 | validation: 2.024096583451707]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4412392261621996		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.4412392261621996 | validation: 2.121844499832252]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4043661710331112		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.4043661710331112 | validation: 2.062353246804172]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4758832977186804		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.4758832977186804 | validation: 2.054865999309917]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.344720421770151		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.344720421770151 | validation: 2.0653345579187268]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3583115510366772		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.3583115510366772 | validation: 2.4370072082128154]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5872057920962603		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.5872057920962603 | validation: 2.4773255658330338]
	TIME [epoch: 11.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6059234027575777		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.6059234027575777 | validation: 2.2515794905684676]
	TIME [epoch: 11.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4416151070858891		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.4416151070858891 | validation: 2.266783874599804]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.43968706749155		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.43968706749155 | validation: 2.1337665044834115]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.443924610076977		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.443924610076977 | validation: 2.3310359735753345]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3948403528041529		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.3948403528041529 | validation: 2.205969076242993]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3278397254871883		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.3278397254871883 | validation: 2.5341307250826537]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4291072625314643		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.4291072625314643 | validation: 2.0779931814010264]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3317317984912047		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.3317317984912047 | validation: 2.146957027016819]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.322882120290785		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.322882120290785 | validation: 2.1490373501909175]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2939732301136067		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.2939732301136067 | validation: 2.51543563849252]
	TIME [epoch: 11.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.487757219575042		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.487757219575042 | validation: 2.7492556570456315]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5361246270029678		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.5361246270029678 | validation: 2.1060339021000742]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4498786458925332		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.4498786458925332 | validation: 2.168772824108181]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.367386376816649		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.367386376816649 | validation: 2.0167876468733494]
	TIME [epoch: 11.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3616296877178622		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.3616296877178622 | validation: 2.193360916269007]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3523946002704301		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.3523946002704301 | validation: 2.4395404088578236]
	TIME [epoch: 11.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.463897809441859		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.463897809441859 | validation: 2.2171154942829183]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.384451699955665		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.384451699955665 | validation: 2.2729998851737867]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4219244420671497		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.4219244420671497 | validation: 2.358338082667047]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4775698925192413		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.4775698925192413 | validation: 2.1223792291616954]
	TIME [epoch: 11.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3397806010257336		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.3397806010257336 | validation: 2.014917982876729]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6675967370110554		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.6675967370110554 | validation: 2.0422755384165785]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3530837415387502		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.3530837415387502 | validation: 1.9910574167626802]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_447.pth
	Model improved!!!
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4755625704151445		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.4755625704151445 | validation: 2.1332689360568207]
	TIME [epoch: 11.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3413369180207442		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.3413369180207442 | validation: 2.2261171706351677]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4581392675673779		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.4581392675673779 | validation: 2.0515058257466836]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2959582064069193		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.2959582064069193 | validation: 2.7005837418112275]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5709242386196152		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.5709242386196152 | validation: 2.09966587617795]
	TIME [epoch: 11.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.36012513820401		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.36012513820401 | validation: 2.0886065680427084]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4375030472003707		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.4375030472003707 | validation: 2.083353391926855]
	TIME [epoch: 11.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3180819483242943		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.3180819483242943 | validation: 2.5814083073217966]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4695766108876955		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.4695766108876955 | validation: 2.45725749890541]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4234904357796423		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.4234904357796423 | validation: 2.013579338919139]
	TIME [epoch: 11.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3348879541092629		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.3348879541092629 | validation: 2.0816008862084256]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4304214898664822		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.4304214898664822 | validation: 2.0628975898432653]
	TIME [epoch: 11.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4265347399750465		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.4265347399750465 | validation: 2.036307091219667]
	TIME [epoch: 11.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.386193816177565		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.386193816177565 | validation: 1.9985745302012956]
	TIME [epoch: 11.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2832065036456		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.2832065036456 | validation: 2.5213175073206147]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4951325874695351		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.4951325874695351 | validation: 2.164193672400139]
	TIME [epoch: 11.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3357856811730953		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.3357856811730953 | validation: 2.4312821194665752]
	TIME [epoch: 11.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4685562034985584		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.4685562034985584 | validation: 2.207449583137067]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.37387605630396		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.37387605630396 | validation: 2.0495024997846114]
	TIME [epoch: 11.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3621653865373984		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.3621653865373984 | validation: 2.1221434526781433]
	TIME [epoch: 11.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.338889988286848		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.338889988286848 | validation: 2.1086516158485686]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.713767940383268		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.713767940383268 | validation: 2.156539162470831]
	TIME [epoch: 11.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4965496579831454		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.4965496579831454 | validation: 2.150493022166956]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.337249723428785		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.337249723428785 | validation: 1.9854770765116934]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3111911855349838		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.3111911855349838 | validation: 2.089030889175045]
	TIME [epoch: 11.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3586434086681973		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.3586434086681973 | validation: 2.0167174701011907]
	TIME [epoch: 11.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2934897139354335		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.2934897139354335 | validation: 2.202180082416648]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3511285952576726		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.3511285952576726 | validation: 2.1077256816223517]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.307267892145767		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.307267892145767 | validation: 2.1634157985126112]
	TIME [epoch: 11.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6010099220040583		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.6010099220040583 | validation: 1.9910708082545692]
	TIME [epoch: 11.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6141428228465848		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.6141428228465848 | validation: 2.0127920883961496]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.260729586788846		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.260729586788846 | validation: 1.9662756495546239]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3813211468861983		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.3813211468861983 | validation: 2.0559000354004993]
	TIME [epoch: 11.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3221928414370183		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.3221928414370183 | validation: 2.1250699782831366]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3285916527219972		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.3285916527219972 | validation: 1.9497560217088827]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3571491820827442		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.3571491820827442 | validation: 2.0932203001588316]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3439232478702015		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.3439232478702015 | validation: 2.030159140044928]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2704206144165564		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.2704206144165564 | validation: 2.0943227137403597]
	TIME [epoch: 11.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3378776933076861		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.3378776933076861 | validation: 2.623929923479866]
	TIME [epoch: 11.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4959920741560953		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.4959920741560953 | validation: 2.2838311053748295]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3110228880883077		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.3110228880883077 | validation: 2.1132215134698993]
	TIME [epoch: 11.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2866158576330935		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.2866158576330935 | validation: 1.9334105248764943]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3530006824972536		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.3530006824972536 | validation: 2.080064324780417]
	TIME [epoch: 11.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4120405133442415		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.4120405133442415 | validation: 3.1142586747595016]
	TIME [epoch: 11.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.837189472511307		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.837189472511307 | validation: 2.025310336659068]
	TIME [epoch: 11.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.29363283881661		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.29363283881661 | validation: 1.9484249043026387]
	TIME [epoch: 11.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3678484812137959		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.3678484812137959 | validation: 2.046763409535951]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2784198786830832		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.2784198786830832 | validation: 2.0989912424770476]
	TIME [epoch: 11.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3599282843369283		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.3599282843369283 | validation: 2.0820149872892335]
	TIME [epoch: 11.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.279663984864464		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.279663984864464 | validation: 1.9585699953078723]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.302087986764752		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.302087986764752 | validation: 1.988915588326057]
	TIME [epoch: 11.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.293674626183317		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.293674626183317 | validation: 1.9580334155607375]
	TIME [epoch: 11.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3892302215309953		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.3892302215309953 | validation: 2.0502382411202267]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3207242820206369		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.3207242820206369 | validation: 1.970800187668595]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3553965648645225		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.3553965648645225 | validation: 1.990619917080029]
	TIME [epoch: 11.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.348862016544499		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.348862016544499 | validation: 2.050847500702292]
	TIME [epoch: 11.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.288839765512338		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.288839765512338 | validation: 1.9870185639846136]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.270928068859067		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.270928068859067 | validation: 2.1936476984974416]
	TIME [epoch: 11.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5672605594776265		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.5672605594776265 | validation: 2.038451109745832]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2879073924694198		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.2879073924694198 | validation: 2.265900553492395]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.429916272526313		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.429916272526313 | validation: 1.9787943356668527]
	TIME [epoch: 11.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2685837137769698		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.2685837137769698 | validation: 2.0440374766439366]
	TIME [epoch: 11.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.280326127989618		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.280326127989618 | validation: 2.051381486826873]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.354149677101864		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.354149677101864 | validation: 2.112528878877005]
	TIME [epoch: 11.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2595355233622545		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.2595355233622545 | validation: 2.2753322267139415]
	TIME [epoch: 11.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3750043193511443		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.3750043193511443 | validation: 2.355087446446846]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.365288771326901		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.365288771326901 | validation: 1.993459945918288]
	TIME [epoch: 11.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3221022822522863		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.3221022822522863 | validation: 1.921877402707761]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_515.pth
	Model improved!!!
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3130461540608553		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.3130461540608553 | validation: 2.057392691944775]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2752497988388003		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.2752497988388003 | validation: 1.9776100795663651]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4349519496107281		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.4349519496107281 | validation: 2.258604103498676]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3523111354131767		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.3523111354131767 | validation: 2.0141523460120645]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.214065231938064		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.214065231938064 | validation: 2.372803611025518]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3616385199651466		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.3616385199651466 | validation: 1.9559214220152858]
	TIME [epoch: 11.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2891234708310222		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.2891234708310222 | validation: 1.9539175414622367]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2106573769513695		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.2106573769513695 | validation: 2.135809480537706]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3721251581752978		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.3721251581752978 | validation: 1.9818782626574176]
	TIME [epoch: 11.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.293056540102462		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.293056540102462 | validation: 1.9902000877663641]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2243078133849044		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.2243078133849044 | validation: 1.9630736096749155]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3011060561529475		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.3011060561529475 | validation: 2.0476736136546365]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3056367963898659		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.3056367963898659 | validation: 1.9875231355682945]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3152442493737604		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.3152442493737604 | validation: 1.9341331547136924]
	TIME [epoch: 11.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3772189810299602		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.3772189810299602 | validation: 1.990673246309357]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2883763726906763		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.2883763726906763 | validation: 2.0766796191365784]
	TIME [epoch: 11.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2824594261256204		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.2824594261256204 | validation: 1.9331585961314033]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2496659843647946		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.2496659843647946 | validation: 2.1215759439723394]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3424980619401536		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.3424980619401536 | validation: 2.0470335419408805]
	TIME [epoch: 11.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2770193084011907		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.2770193084011907 | validation: 2.117815034457519]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2563240711118193		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 1.2563240711118193 | validation: 2.0438249738787384]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3413606132156786		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 1.3413606132156786 | validation: 2.0028940780470212]
	TIME [epoch: 11.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2806880409616035		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 1.2806880409616035 | validation: 2.109303436118638]
	TIME [epoch: 11.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2766806862424662		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 1.2766806862424662 | validation: 2.023565040779699]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2802460234424466		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.2802460234424466 | validation: 1.9644250560343324]
	TIME [epoch: 11.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2587862250798572		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.2587862250798572 | validation: 2.0664098816808267]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3724482991592446		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 1.3724482991592446 | validation: 1.981755282536975]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.223150039852781		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.223150039852781 | validation: 1.9847497292605527]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3036788292625936		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 1.3036788292625936 | validation: 1.9817303300689366]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3823178474400213		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.3823178474400213 | validation: 2.0359488901682052]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2627623874320022		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.2627623874320022 | validation: 1.9678647464897177]
	TIME [epoch: 11.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2170651306434876		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.2170651306434876 | validation: 2.243730240661765]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3574761312609795		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.3574761312609795 | validation: 1.9400788286822335]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2779457750589869		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.2779457750589869 | validation: 2.0383807083491585]
	TIME [epoch: 11.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3068681100278847		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.3068681100278847 | validation: 1.9687174157038358]
	TIME [epoch: 11.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2612551831617802		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.2612551831617802 | validation: 1.9897157948038555]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2636452921299535		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 1.2636452921299535 | validation: 2.072603682438022]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3040275854035923		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.3040275854035923 | validation: 2.0536148095367706]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2278941952603257		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 1.2278941952603257 | validation: 1.932094182699231]
	TIME [epoch: 11.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.193347066908707		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.193347066908707 | validation: 1.9400298460401733]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2355720967227566		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.2355720967227566 | validation: 1.9437902978635344]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3237671440031302		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 1.3237671440031302 | validation: 2.0470845542179235]
	TIME [epoch: 11.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.416237890086438		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.416237890086438 | validation: 1.9266298740940628]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3004941642435874		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.3004941642435874 | validation: 2.100931503947905]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3162393117592577		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.3162393117592577 | validation: 1.9113897858457731]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2277695051179265		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 1.2277695051179265 | validation: 1.9230268950142695]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.315337283068444		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.315337283068444 | validation: 1.9784936473925216]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2652224786976973		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 1.2652224786976973 | validation: 2.0620707398020177]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2124437322660844		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 1.2124437322660844 | validation: 1.976176880540579]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2648941670109408		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.2648941670109408 | validation: 1.9068572014278267]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2036038767661184		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.2036038767661184 | validation: 2.05003868303742]
	TIME [epoch: 11.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2556521036673403		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.2556521036673403 | validation: 1.946574766141285]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3136619379884173		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.3136619379884173 | validation: 2.1167400305175748]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.25560923276361		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.25560923276361 | validation: 1.9582678473619104]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2417100292866161		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.2417100292866161 | validation: 1.9050653287573516]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2238513687119683		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.2238513687119683 | validation: 2.0501258111898726]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3430903746694467		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.3430903746694467 | validation: 2.021469130361888]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2426471486022082		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.2426471486022082 | validation: 2.020901943246732]
	TIME [epoch: 11.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.264912803812041		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 1.264912803812041 | validation: 2.204638015334826]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2555499017209775		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 1.2555499017209775 | validation: 1.9990931514642656]
	TIME [epoch: 11.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2954229032696176		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 1.2954229032696176 | validation: 2.075436011794572]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2260746905689195		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 1.2260746905689195 | validation: 2.082890581277794]
	TIME [epoch: 11.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3875336472759212		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 1.3875336472759212 | validation: 1.967793563888452]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2183814672628883		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 1.2183814672628883 | validation: 2.0738777401372483]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2489536090444013		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.2489536090444013 | validation: 1.9521174625640998]
	TIME [epoch: 11.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1822757490922187		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 1.1822757490922187 | validation: 2.171831468839692]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2815925290703685		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.2815925290703685 | validation: 2.110380604394679]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2534096026612505		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 1.2534096026612505 | validation: 1.9314562773961093]
	TIME [epoch: 11.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2103327564082613		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 1.2103327564082613 | validation: 2.2329495273717153]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3607824093284162		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.3607824093284162 | validation: 1.9473462078528831]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.345735432876448		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 1.345735432876448 | validation: 2.4248532129848437]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3670844734307124		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 1.3670844734307124 | validation: 1.9454040090340392]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2845683889832997		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.2845683889832997 | validation: 2.0474570534520944]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2403924317909758		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.2403924317909758 | validation: 2.0399273966161964]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242023112823788		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 1.242023112823788 | validation: 1.9901525113947176]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.241061289962221		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.241061289962221 | validation: 1.981479165320144]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3043297528273436		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 1.3043297528273436 | validation: 1.9768173434888712]
	TIME [epoch: 11.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3011166537251209		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 1.3011166537251209 | validation: 1.949845423436579]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425613081530424		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.2425613081530424 | validation: 2.0559360071106774]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2727827725944583		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 1.2727827725944583 | validation: 1.966284016923437]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245127890656125		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 1.245127890656125 | validation: 2.191615514302307]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.310647217800883		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 1.310647217800883 | validation: 1.9172241654889735]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1889926557557917		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.1889926557557917 | validation: 1.9333109005121636]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.287257725447431		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.287257725447431 | validation: 2.047404339689918]
	TIME [epoch: 11.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2788520810379227		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 1.2788520810379227 | validation: 2.115147883597381]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2308339685563847		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.2308339685563847 | validation: 1.9560615656195586]
	TIME [epoch: 11.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.168946382637151		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 1.168946382637151 | validation: 1.9755957065604726]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1948796562943782		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 1.1948796562943782 | validation: 1.9594429445891488]
	TIME [epoch: 11.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.189933859299318		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 1.189933859299318 | validation: 2.1094130937435067]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.303224148969988		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 1.303224148969988 | validation: 1.9653086446538766]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3468084019031747		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.3468084019031747 | validation: 1.9353071753432718]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2512612402541121		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 1.2512612402541121 | validation: 2.15247620033257]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3057409533636593		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 1.3057409533636593 | validation: 1.9623359554472581]
	TIME [epoch: 11.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.295077980680218		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 1.295077980680218 | validation: 1.9977049800171742]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.19236210309499		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 1.19236210309499 | validation: 1.9241674205559895]
	TIME [epoch: 11.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2086471483372034		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 1.2086471483372034 | validation: 1.9976484350727628]
	TIME [epoch: 11.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1890378985995487		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 1.1890378985995487 | validation: 1.9908241716794524]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.193307145201744		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 1.193307145201744 | validation: 2.2082419848171115]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3763803372822727		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 1.3763803372822727 | validation: 1.9428299831209237]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1602769177069243		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 1.1602769177069243 | validation: 1.9005382816719811]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2179790425359256		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 1.2179790425359256 | validation: 1.958836787267998]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.170517119052976		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 1.170517119052976 | validation: 1.9584344097940847]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1893161960650676		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 1.1893161960650676 | validation: 1.957013504197169]
	TIME [epoch: 11.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1709702008462441		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 1.1709702008462441 | validation: 2.028658894811692]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.216065951635753		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 1.216065951635753 | validation: 1.9143831856149778]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1679230138959307		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 1.1679230138959307 | validation: 1.9227349072726745]
	TIME [epoch: 11.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274843199095857		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 1.274843199095857 | validation: 2.068012331390294]
	TIME [epoch: 11.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4390230493989355		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.4390230493989355 | validation: 1.920604716851338]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3211641771628089		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 1.3211641771628089 | validation: 2.126382993144572]
	TIME [epoch: 11.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2928042326340958		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 1.2928042326340958 | validation: 2.1456937333592823]
	TIME [epoch: 11.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3019281391548934		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 1.3019281391548934 | validation: 1.8854919893782423]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1857497313177996		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 1.1857497313177996 | validation: 2.060537257121344]
	TIME [epoch: 11.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239215292956752		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.239215292956752 | validation: 1.912329320536228]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2016586429940108		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 1.2016586429940108 | validation: 1.9005285750173158]
	TIME [epoch: 11.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3032848614278634		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.3032848614278634 | validation: 1.9968359452579671]
	TIME [epoch: 11.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2046679589779616		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 1.2046679589779616 | validation: 1.934882303992166]
	TIME [epoch: 11.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1719956567813714		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 1.1719956567813714 | validation: 1.9394922148358127]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2270507813835683		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 1.2270507813835683 | validation: 2.2789897799521235]
	TIME [epoch: 11.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.254019168609726		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 1.254019168609726 | validation: 1.8978800852082827]
	TIME [epoch: 11.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2208025482446412		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 1.2208025482446412 | validation: 1.8870335936979257]
	TIME [epoch: 11.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1894376005864653		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 1.1894376005864653 | validation: 1.9545066993534983]
	TIME [epoch: 11.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3631900621690696		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 1.3631900621690696 | validation: 1.9232218845301057]
	TIME [epoch: 11.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.266265441506261		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 1.266265441506261 | validation: 1.9221506183484542]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1933625416290083		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.1933625416290083 | validation: 1.907497439483891]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1546756376006266		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.1546756376006266 | validation: 1.9239329939761525]
	TIME [epoch: 11.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2250958853427476		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.2250958853427476 | validation: 1.9606402949930972]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2374097615364446		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 1.2374097615364446 | validation: 1.9120823714506496]
	TIME [epoch: 11.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2009911815071996		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 1.2009911815071996 | validation: 2.1426378458315476]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2558619092208363		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.2558619092208363 | validation: 1.9638146529172755]
	TIME [epoch: 11.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2073532222867092		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.2073532222867092 | validation: 1.8958521676392028]
	TIME [epoch: 11.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1798896252315096		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 1.1798896252315096 | validation: 2.047116887362473]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1967350287714238		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 1.1967350287714238 | validation: 2.0463365913080604]
	TIME [epoch: 11.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2711414757495085		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.2711414757495085 | validation: 1.89758362413753]
	TIME [epoch: 11.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1722922125296213		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.1722922125296213 | validation: 1.9595227903138466]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1635247422869914		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 1.1635247422869914 | validation: 1.886933016252365]
	TIME [epoch: 11.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150738463582764		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 1.150738463582764 | validation: 1.890505530236282]
	TIME [epoch: 11.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1569711726433427		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 1.1569711726433427 | validation: 1.93217862055104]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229364474183864		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 1.229364474183864 | validation: 1.9093297218522371]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1889386523829835		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 1.1889386523829835 | validation: 1.9334325464638804]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1812212617342097		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 1.1812212617342097 | validation: 1.9146277278926929]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1686148923034685		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 1.1686148923034685 | validation: 1.9083074800650572]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1792006020808259		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 1.1792006020808259 | validation: 1.955276320817208]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1988455265264935		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 1.1988455265264935 | validation: 1.904386762245008]
	TIME [epoch: 11.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2557732916100437		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 1.2557732916100437 | validation: 1.9249451378984435]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1928499482278259		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 1.1928499482278259 | validation: 1.8883220015635689]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2688033973482153		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 1.2688033973482153 | validation: 1.9174699995832103]
	TIME [epoch: 11.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1537643579035846		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 1.1537643579035846 | validation: 1.9445014584333546]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2101707852081693		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 1.2101707852081693 | validation: 1.881265883077834]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_663.pth
	Model improved!!!
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1813786223405534		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.1813786223405534 | validation: 2.015797743202353]
	TIME [epoch: 11.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.356919438961717		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 1.356919438961717 | validation: 2.1498325580147872]
	TIME [epoch: 11.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3506812048109196		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 1.3506812048109196 | validation: 2.11875443394621]
	TIME [epoch: 11.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2081952214045444		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 1.2081952214045444 | validation: 1.91227594342954]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1458012590547284		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 1.1458012590547284 | validation: 1.9546833435244155]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.219078287748156		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 1.219078287748156 | validation: 1.8812237238886327]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_669.pth
	Model improved!!!
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1889555583825187		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 1.1889555583825187 | validation: 1.902174645169107]
	TIME [epoch: 11.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.189937232183559		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 1.189937232183559 | validation: 1.8968652546039986]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2975808210814084		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 1.2975808210814084 | validation: 1.8967951198190418]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2478392819660358		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 1.2478392819660358 | validation: 1.9156061339869097]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1692723464089814		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 1.1692723464089814 | validation: 1.9300778159493077]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1390733456047304		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 1.1390733456047304 | validation: 2.240541254478566]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2713152854071277		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 1.2713152854071277 | validation: 1.8845775971653047]
	TIME [epoch: 11.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1549631454866676		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 1.1549631454866676 | validation: 1.9814273729454828]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1520401283637425		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 1.1520401283637425 | validation: 1.8996230609662552]
	TIME [epoch: 11.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.179083596590758		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 1.179083596590758 | validation: 1.9275199245639079]
	TIME [epoch: 11.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1734519019249623		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 1.1734519019249623 | validation: 1.987103604354075]
	TIME [epoch: 11.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1938446489044947		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 1.1938446489044947 | validation: 2.0133181258168027]
	TIME [epoch: 11.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.241048999446296		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 1.241048999446296 | validation: 1.8940217942006201]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1775577830898132		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 1.1775577830898132 | validation: 2.054640194991841]
	TIME [epoch: 11.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.199217137725174		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.199217137725174 | validation: 1.959502493725786]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2181113223266538		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 1.2181113223266538 | validation: 1.8856657760623716]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.156382320364346		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.156382320364346 | validation: 1.9295662900314432]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2299615944169269		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 1.2299615944169269 | validation: 2.0155320236491625]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1868039621392663		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 1.1868039621392663 | validation: 1.9755102239162736]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161021715518431		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 1.161021715518431 | validation: 1.8915980074707617]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1414031499312154		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 1.1414031499312154 | validation: 1.8945184177980066]
	TIME [epoch: 11.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1609365792576165		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 1.1609365792576165 | validation: 2.028181306407593]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2379226734098525		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 1.2379226734098525 | validation: 1.931568830241945]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1632519884022243		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 1.1632519884022243 | validation: 1.907952578301813]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2123036767073612		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 1.2123036767073612 | validation: 1.985200330672625]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1702408366658017		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 1.1702408366658017 | validation: 2.148885552903844]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2255823586111014		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 1.2255823586111014 | validation: 1.9656680892315155]
	TIME [epoch: 11.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2450571885015258		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 1.2450571885015258 | validation: 2.0613812764018085]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3148587635152977		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 1.3148587635152977 | validation: 1.910544428497337]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.173970177528337		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 1.173970177528337 | validation: 1.902831396731952]
	TIME [epoch: 11.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1717207331204702		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 1.1717207331204702 | validation: 1.8943207267079794]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1413015974918417		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 1.1413015974918417 | validation: 1.9164145549967637]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1638986164713931		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 1.1638986164713931 | validation: 1.8830539282082555]
	TIME [epoch: 11.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1459382549448422		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 1.1459382549448422 | validation: 1.894905136320288]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1500635671803126		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 1.1500635671803126 | validation: 2.026419861691711]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.202780532435041		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 1.202780532435041 | validation: 1.9254105755845046]
	TIME [epoch: 11.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139757180783259		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 1.139757180783259 | validation: 1.978983598948749]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2074142602369133		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 1.2074142602369133 | validation: 1.883081847656123]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1635938769945973		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 1.1635938769945973 | validation: 1.9304408612992376]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1973557098754328		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 1.1973557098754328 | validation: 1.9471287661124024]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1694032180014415		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 1.1694032180014415 | validation: 1.885867196981765]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1348585381652647		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 1.1348585381652647 | validation: 1.9777748579253467]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.228274426267799		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 1.228274426267799 | validation: 1.9605863673400694]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144298658022575		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 1.144298658022575 | validation: 2.0674954624115416]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2106808675817562		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 1.2106808675817562 | validation: 1.9140906706511556]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1780457385348453		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 1.1780457385348453 | validation: 1.9460836784047082]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1494260912509748		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 1.1494260912509748 | validation: 1.9091127712520273]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1797325380816166		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 1.1797325380816166 | validation: 1.8899575656057375]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1605122606953593		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 1.1605122606953593 | validation: 2.0987626753970288]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2100212339245224		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 1.2100212339245224 | validation: 1.918961594592753]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1542165562205238		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 1.1542165562205238 | validation: 1.8746839166804796]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_720.pth
	Model improved!!!
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.136066485568108		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 1.136066485568108 | validation: 1.9026518129012726]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1531111768177023		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 1.1531111768177023 | validation: 1.9485150619459541]
	TIME [epoch: 11.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1910293873613385		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 1.1910293873613385 | validation: 1.8726517014384305]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_723.pth
	Model improved!!!
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2213731606450278		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 1.2213731606450278 | validation: 1.9416529346757236]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1720062258364903		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 1.1720062258364903 | validation: 2.1987619064248474]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2702372190819058		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 1.2702372190819058 | validation: 2.002177997225976]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1605384669295256		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 1.1605384669295256 | validation: 1.9228177630039733]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1825896173671386		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 1.1825896173671386 | validation: 2.0076911143008163]
	TIME [epoch: 11.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.211948189458996		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 1.211948189458996 | validation: 1.8879916354795765]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1628395415283999		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 1.1628395415283999 | validation: 1.9407153017302323]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.182787578757956		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 1.182787578757956 | validation: 1.8835783496294212]
	TIME [epoch: 11.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1481171313539738		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 1.1481171313539738 | validation: 1.9181522529753017]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1558153148028707		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 1.1558153148028707 | validation: 1.9122489149537256]
	TIME [epoch: 11.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.199123300932745		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 1.199123300932745 | validation: 1.972776524250831]
	TIME [epoch: 11.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2228573978817234		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 1.2228573978817234 | validation: 1.890993361450169]
	TIME [epoch: 11.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161471898901401		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 1.161471898901401 | validation: 1.8993764077558364]
	TIME [epoch: 11.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1561795243326103		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 1.1561795243326103 | validation: 2.2042629019770095]
	TIME [epoch: 11.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2962614315885614		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 1.2962614315885614 | validation: 1.9053650497201937]
	TIME [epoch: 11.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.214002705583246		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 1.214002705583246 | validation: 1.8643525269551517]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_739.pth
	Model improved!!!
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1253753529650494		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 1.1253753529650494 | validation: 1.9096207557697429]
	TIME [epoch: 11.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1783921402991742		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 1.1783921402991742 | validation: 1.8781398750334353]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.238644946182698		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 1.238644946182698 | validation: 1.8712264179643257]
	TIME [epoch: 11.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137714255625563		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 1.137714255625563 | validation: 2.0215780573383983]
	TIME [epoch: 11.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1820297515342157		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 1.1820297515342157 | validation: 2.015493174993558]
	TIME [epoch: 11.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1637268922575903		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 1.1637268922575903 | validation: 1.871485562366954]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1694891380091836		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 1.1694891380091836 | validation: 1.88193592995081]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1539749751922783		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 1.1539749751922783 | validation: 1.8595097051789662]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_747.pth
	Model improved!!!
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3599630735301884		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 1.3599630735301884 | validation: 1.8953530814188515]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1441078054471923		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 1.1441078054471923 | validation: 1.9026456007341759]
	TIME [epoch: 11.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1314594663648216		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 1.1314594663648216 | validation: 1.8794444642763466]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1264614981062997		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 1.1264614981062997 | validation: 1.8870535138067752]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1272609227861223		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 1.1272609227861223 | validation: 1.8551363282715736]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_752.pth
	Model improved!!!
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1341096272579878		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 1.1341096272579878 | validation: 1.9277330145320235]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1657805819236808		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 1.1657805819236808 | validation: 1.8597421514399792]
	TIME [epoch: 11.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1923576719580353		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 1.1923576719580353 | validation: 2.0111082637144357]
	TIME [epoch: 11.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1560237355316696		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 1.1560237355316696 | validation: 1.9062214467330238]
	TIME [epoch: 11.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375046304731247		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 1.1375046304731247 | validation: 1.9277843643096364]
	TIME [epoch: 11.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1395609937804052		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 1.1395609937804052 | validation: 1.9403201087147883]
	TIME [epoch: 11.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1511886301214285		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 1.1511886301214285 | validation: 1.9272469104085406]
	TIME [epoch: 11.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1448480400188614		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 1.1448480400188614 | validation: 1.9415361651852936]
	TIME [epoch: 11.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1564166634010522		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 1.1564166634010522 | validation: 1.9097101727130528]
	TIME [epoch: 11.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1832973016896773		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 1.1832973016896773 | validation: 1.8764572128386285]
	TIME [epoch: 11.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1387012724564225		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 1.1387012724564225 | validation: 1.8698299509634593]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.152419758993239		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 1.152419758993239 | validation: 1.880815658870243]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1180384716367215		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 1.1180384716367215 | validation: 1.899089289121191]
	TIME [epoch: 11.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1286935947578027		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 1.1286935947578027 | validation: 2.032877060999659]
	TIME [epoch: 11.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.20444699124351		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 1.20444699124351 | validation: 1.865996797534562]
	TIME [epoch: 11.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1391792078874001		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 1.1391792078874001 | validation: 1.8923428549049723]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1400687613454905		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 1.1400687613454905 | validation: 1.9100684162218022]
	TIME [epoch: 11.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1190311201127654		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 1.1190311201127654 | validation: 1.8683748893589591]
	TIME [epoch: 11.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2243279788078558		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 1.2243279788078558 | validation: 1.8889704030098977]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1604688783904573		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 1.1604688783904573 | validation: 1.966740515350864]
	TIME [epoch: 11.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1682521796901233		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 1.1682521796901233 | validation: 1.892514853165076]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1165610625453066		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 1.1165610625453066 | validation: 1.8770667802307444]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1541558868131117		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 1.1541558868131117 | validation: 1.8818148977745233]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1329183956084008		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 1.1329183956084008 | validation: 1.90166602042627]
	TIME [epoch: 11.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1818663699800243		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 1.1818663699800243 | validation: 2.0020681219312433]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143768797550797		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 1.143768797550797 | validation: 1.9068386410703344]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1296468598214462		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 1.1296468598214462 | validation: 1.8808963110787733]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144036344361027		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 1.144036344361027 | validation: 1.8667376507831315]
	TIME [epoch: 11.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1673168287383715		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 1.1673168287383715 | validation: 1.8697998794012616]
	TIME [epoch: 11.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1307754945420254		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 1.1307754945420254 | validation: 1.9157279586180431]
	TIME [epoch: 11.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1390414450470776		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 1.1390414450470776 | validation: 1.9482629956133357]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1583446737137728		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 1.1583446737137728 | validation: 1.9030345739387202]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1985132395632805		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 1.1985132395632805 | validation: 1.9168465676300372]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1343639725024757		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 1.1343639725024757 | validation: 1.9026334548895616]
	TIME [epoch: 11.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1460708331172962		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 1.1460708331172962 | validation: 1.9694346351442173]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.183276905693954		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 1.183276905693954 | validation: 1.9161651129668906]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154350274203462		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 1.154350274203462 | validation: 1.883154924420179]
	TIME [epoch: 11.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1396438639283226		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 1.1396438639283226 | validation: 1.8838519536426304]
	TIME [epoch: 11.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154484675304365		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 1.154484675304365 | validation: 1.9126600209294975]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144024191720615		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 1.144024191720615 | validation: 1.8873202891947687]
	TIME [epoch: 11.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.171101631842497		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 1.171101631842497 | validation: 1.8591455486920216]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140338272266633		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 1.140338272266633 | validation: 1.8702090899640067]
	TIME [epoch: 11.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376315546451572		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 1.1376315546451572 | validation: 1.868758097856964]
	TIME [epoch: 11.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1328237652081228		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 1.1328237652081228 | validation: 1.8908460788381825]
	TIME [epoch: 11.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1484427790527367		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 1.1484427790527367 | validation: 1.889535822288412]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1617087969610629		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 1.1617087969610629 | validation: 1.9033622222775985]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1315863129429762		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 1.1315863129429762 | validation: 1.8763165005753961]
	TIME [epoch: 11.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1335271047042867		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 1.1335271047042867 | validation: 1.8688283104283456]
	TIME [epoch: 11.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.119306367773747		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 1.119306367773747 | validation: 1.8703136969275653]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1203086111089033		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 1.1203086111089033 | validation: 1.9561956347094287]
	TIME [epoch: 11.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1480716737439274		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 1.1480716737439274 | validation: 1.8697619621911543]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153306388636775		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 1.153306388636775 | validation: 1.9032441017583965]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1186562767328752		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 1.1186562767328752 | validation: 1.8874956077360003]
	TIME [epoch: 11.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1105021079493331		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 1.1105021079493331 | validation: 1.8539513067974371]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_806.pth
	Model improved!!!
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.115075622402026		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 1.115075622402026 | validation: 1.8677420906695406]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1214192506568041		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 1.1214192506568041 | validation: 1.8535326389344478]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_808.pth
	Model improved!!!
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1673431851504061		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 1.1673431851504061 | validation: 1.9059829285372676]
	TIME [epoch: 11.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1197285155315604		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 1.1197285155315604 | validation: 1.8421520040387214]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1773695400327895		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 1.1773695400327895 | validation: 1.8816455123344487]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1233959902592494		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 1.1233959902592494 | validation: 1.8815282559346855]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.106079684475167		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 1.106079684475167 | validation: 1.9309913192904244]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1577529941005325		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 1.1577529941005325 | validation: 1.8907369090726778]
	TIME [epoch: 11.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1233828983884082		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 1.1233828983884082 | validation: 1.8478114797723344]
	TIME [epoch: 11.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0925005229944744		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 1.0925005229944744 | validation: 1.9145437761260238]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1358577330053754		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 1.1358577330053754 | validation: 1.9425962863769526]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1262309750618176		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 1.1262309750618176 | validation: 1.895738110264038]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.114882163778818		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 1.114882163778818 | validation: 1.956255653401388]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1311435987367982		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 1.1311435987367982 | validation: 1.8551294010659314]
	TIME [epoch: 11.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1090945081451504		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 1.1090945081451504 | validation: 1.8595366511422555]
	TIME [epoch: 11.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1261745462955437		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 1.1261745462955437 | validation: 1.8691304202581467]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1440046334448182		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 1.1440046334448182 | validation: 1.8792404685713553]
	TIME [epoch: 11.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1100180657952687		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 1.1100180657952687 | validation: 1.885779800642842]
	TIME [epoch: 11.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1895913620530367		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 1.1895913620530367 | validation: 1.9170883349956052]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1318298511880376		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 1.1318298511880376 | validation: 1.9182975339492254]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.121108515922079		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 1.121108515922079 | validation: 1.8787565511663942]
	TIME [epoch: 11.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1133160709010055		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 1.1133160709010055 | validation: 1.8408940843086412]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_828.pth
	Model improved!!!
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1083134359645461		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 1.1083134359645461 | validation: 1.8539829956368958]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1211755403216088		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 1.1211755403216088 | validation: 2.062880529953118]
	TIME [epoch: 11.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2099547667472974		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 1.2099547667472974 | validation: 1.9331087124279007]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1665798693994747		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 1.1665798693994747 | validation: 1.9915261254437269]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1705264699354552		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 1.1705264699354552 | validation: 1.909320953069317]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154701194572752		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 1.154701194572752 | validation: 1.8584723517505848]
	TIME [epoch: 11.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.121058500769566		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 1.121058500769566 | validation: 1.9134715942839455]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.128862402816844		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 1.128862402816844 | validation: 1.992391945333401]
	TIME [epoch: 11.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150845124990388		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 1.150845124990388 | validation: 1.8545544058375965]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.120394429668241		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 1.120394429668241 | validation: 1.9413811090238662]
	TIME [epoch: 11.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1509838198723696		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 1.1509838198723696 | validation: 1.9436443615941965]
	TIME [epoch: 11.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150182657531315		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 1.150182657531315 | validation: 1.881943556089193]
	TIME [epoch: 11.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.103060486034284		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 1.103060486034284 | validation: 1.8545993908093266]
	TIME [epoch: 11.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1001462163163933		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 1.1001462163163933 | validation: 1.8767433141903889]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.111737675859216		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 1.111737675859216 | validation: 1.8625619854618207]
	TIME [epoch: 11.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1040695613819662		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 1.1040695613819662 | validation: 1.9222979078031586]
	TIME [epoch: 11.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.168104773228952		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 1.168104773228952 | validation: 1.9086635632395577]
	TIME [epoch: 11.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1362099735380893		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 1.1362099735380893 | validation: 1.8605584399847601]
	TIME [epoch: 11.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1280262029218093		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 1.1280262029218093 | validation: 1.8480250252511814]
	TIME [epoch: 11.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.097701659038113		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 1.097701659038113 | validation: 1.8542617910056272]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1287837462955108		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 1.1287837462955108 | validation: 1.8331813886137596]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_849.pth
	Model improved!!!
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1051910078074467		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 1.1051910078074467 | validation: 1.8723490131117584]
	TIME [epoch: 11.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1054518894857666		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 1.1054518894857666 | validation: 1.922779769449632]
	TIME [epoch: 11.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.113674236318237		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 1.113674236318237 | validation: 1.8467325794828668]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1242850885490205		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 1.1242850885490205 | validation: 1.8647562611754445]
	TIME [epoch: 11.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.105283744888356		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 1.105283744888356 | validation: 1.911206379248786]
	TIME [epoch: 11.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1249025843933604		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 1.1249025843933604 | validation: 1.8552901581806134]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1234018870859113		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 1.1234018870859113 | validation: 1.8786069253894087]
	TIME [epoch: 11.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.108264409313152		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 1.108264409313152 | validation: 1.901400174825189]
	TIME [epoch: 11.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1362619691566163		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 1.1362619691566163 | validation: 1.906044988189728]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.115336779192326		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 1.115336779192326 | validation: 1.8767215338684147]
	TIME [epoch: 11.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1194080166080096		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 1.1194080166080096 | validation: 1.859236105311311]
	TIME [epoch: 11.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1174666271454574		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 1.1174666271454574 | validation: 1.9082235274460209]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.122050394988242		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 1.122050394988242 | validation: 1.8773794708254594]
	TIME [epoch: 11.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1096193819514275		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 1.1096193819514275 | validation: 1.8919584304630264]
	TIME [epoch: 11.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0966065294727054		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 1.0966065294727054 | validation: 1.870407980800247]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1257792796887558		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 1.1257792796887558 | validation: 1.9334592389805576]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1508456116545223		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 1.1508456116545223 | validation: 1.8682235244137269]
	TIME [epoch: 11.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1338413362444646		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 1.1338413362444646 | validation: 1.8812169643574026]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1375859968773292		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 1.1375859968773292 | validation: 1.8429652649718833]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1488980099815225		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 1.1488980099815225 | validation: 1.8768083525682817]
	TIME [epoch: 11.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0980782204895871		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 1.0980782204895871 | validation: 1.8884147399166675]
	TIME [epoch: 11.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0985522682579116		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 1.0985522682579116 | validation: 1.861374502418193]
	TIME [epoch: 11.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1104505010395522		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 1.1104505010395522 | validation: 1.886793937845477]
	TIME [epoch: 11.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140818447727757		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 1.140818447727757 | validation: 1.8594277653198836]
	TIME [epoch: 11.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.106248324242774		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 1.106248324242774 | validation: 1.8588126914222607]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1149439075808245		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 1.1149439075808245 | validation: 1.8808736000695232]
	TIME [epoch: 11.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1340474771076783		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 1.1340474771076783 | validation: 1.8664566674166807]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137790723733495		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 1.137790723733495 | validation: 1.8720201001823562]
	TIME [epoch: 11.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1114324422256565		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 1.1114324422256565 | validation: 1.8657261596617425]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.113558254640362		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 1.113558254640362 | validation: 1.8749797242580115]
	TIME [epoch: 11.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1219894771648637		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 1.1219894771648637 | validation: 1.8680152721374512]
	TIME [epoch: 11.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1042997599647246		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 1.1042997599647246 | validation: 1.8585764215518823]
	TIME [epoch: 11.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146113757328623		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 1.146113757328623 | validation: 1.8417261010124182]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0990610181532943		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 1.0990610181532943 | validation: 1.8457410474496403]
	TIME [epoch: 11.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1068043964043652		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 1.1068043964043652 | validation: 1.8471234817824496]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1050276346155103		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 1.1050276346155103 | validation: 1.8421171363230604]
	TIME [epoch: 11.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0879444460531609		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 1.0879444460531609 | validation: 1.8490832314020582]
	TIME [epoch: 11.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1409411553548208		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 1.1409411553548208 | validation: 1.838326166257776]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1239511473061994		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 1.1239511473061994 | validation: 1.863135291124777]
	TIME [epoch: 11.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0882912679190286		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 1.0882912679190286 | validation: 1.933521052190778]
	TIME [epoch: 11.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1218881699181922		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 1.1218881699181922 | validation: 1.8504526811599724]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1053724322386005		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 1.1053724322386005 | validation: 1.8500843075558897]
	TIME [epoch: 11.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0958413406964447		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 1.0958413406964447 | validation: 1.8645998185793462]
	TIME [epoch: 11.6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0961985982058247		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 1.0961985982058247 | validation: 1.8630852585638276]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.095621144396357		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 1.095621144396357 | validation: 1.8695974225941547]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1709579434307749		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 1.1709579434307749 | validation: 1.9168025549665344]
	TIME [epoch: 11.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1280092351493998		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 1.1280092351493998 | validation: 1.8470057671215054]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1215461755381573		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 1.1215461755381573 | validation: 1.926601668502023]
	TIME [epoch: 11.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1607087773472342		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 1.1607087773472342 | validation: 2.0900846800819033]
	TIME [epoch: 11.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2002973563429795		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 1.2002973563429795 | validation: 1.9092639391607025]
	TIME [epoch: 11.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1525385310480936		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 1.1525385310480936 | validation: 1.8451353433357136]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.124890260241098		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 1.124890260241098 | validation: 1.9157697515739358]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1186520770770025		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 1.1186520770770025 | validation: 1.8461444807143297]
	TIME [epoch: 11.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1003791773695373		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 1.1003791773695373 | validation: 1.8634163048728887]
	TIME [epoch: 11.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0973259547096972		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 1.0973259547096972 | validation: 1.8926836911439988]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.128216490610904		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 1.128216490610904 | validation: 1.8490268067649223]
	TIME [epoch: 11.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.118867848700357		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 1.118867848700357 | validation: 1.853209036782709]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0875897354750603		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 1.0875897354750603 | validation: 1.8874283756554064]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1040090088294603		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 1.1040090088294603 | validation: 1.8444380911230227]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141984336839998		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 1.141984336839998 | validation: 1.9362878183004046]
	TIME [epoch: 11.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.118593092948938		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 1.118593092948938 | validation: 1.8481808161727622]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0916772866957558		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 1.0916772866957558 | validation: 1.8447211114863808]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1060667179099508		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 1.1060667179099508 | validation: 1.8294018801912708]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_912.pth
	Model improved!!!
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0985057737779955		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 1.0985057737779955 | validation: 1.8775316524051737]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1499695666284473		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 1.1499695666284473 | validation: 1.860080960379047]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1078540774854764		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 1.1078540774854764 | validation: 1.840368226204316]
	TIME [epoch: 11.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0925545233959073		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 1.0925545233959073 | validation: 1.873240943368424]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1015517871710725		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 1.1015517871710725 | validation: 1.828602431811193]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_917.pth
	Model improved!!!
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0867438523370512		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 1.0867438523370512 | validation: 1.8705858334276428]
	TIME [epoch: 11.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1291013439831397		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 1.1291013439831397 | validation: 1.8798131945370724]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1096624203311127		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 1.1096624203311127 | validation: 1.94722039426525]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1209234845965028		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 1.1209234845965028 | validation: 1.8346376808647593]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0857792024691868		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 1.0857792024691868 | validation: 1.839049315772249]
	TIME [epoch: 11.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0993894717922659		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 1.0993894717922659 | validation: 1.8587546140466658]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1205865453682986		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 1.1205865453682986 | validation: 1.8797928793156669]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.151112729280093		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 1.151112729280093 | validation: 1.852085861985937]
	TIME [epoch: 11.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1101988518696113		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 1.1101988518696113 | validation: 1.8310974007970096]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0920009105268944		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 1.0920009105268944 | validation: 1.865947037407384]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1065642190621239		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 1.1065642190621239 | validation: 1.8586573952554368]
	TIME [epoch: 11.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1170075468867608		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 1.1170075468867608 | validation: 1.8790854452100425]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1171191466239418		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 1.1171191466239418 | validation: 1.8456953240884475]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1012717531181258		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 1.1012717531181258 | validation: 1.8496586303925795]
	TIME [epoch: 11.6 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0927283427313195		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 1.0927283427313195 | validation: 1.8537396360265854]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1177189280894846		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 1.1177189280894846 | validation: 1.8556585157910919]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.104263342926987		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 1.104263342926987 | validation: 1.8415937606638448]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1087476497410993		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 1.1087476497410993 | validation: 1.8494328647261244]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0976793036202186		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 1.0976793036202186 | validation: 1.8470837020635509]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0796467094339952		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 1.0796467094339952 | validation: 1.8525194366218642]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0895958804810797		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 1.0895958804810797 | validation: 1.8551040290483667]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0838048606109976		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 1.0838048606109976 | validation: 1.8511070096333566]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1118138032877993		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 1.1118138032877993 | validation: 1.920819366312139]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1831876737889346		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 1.1831876737889346 | validation: 1.8818090200935838]
	TIME [epoch: 11.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1047463094623542		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 1.1047463094623542 | validation: 1.892792276247913]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1125591232548238		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 1.1125591232548238 | validation: 1.8443701161407926]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0985669273365537		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 1.0985669273365537 | validation: 1.8577019463735212]
	TIME [epoch: 11.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1030829150401606		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 1.1030829150401606 | validation: 1.8529273626418725]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0915086352222536		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 1.0915086352222536 | validation: 1.8495455352971153]
	TIME [epoch: 11.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1514069286124098		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 1.1514069286124098 | validation: 1.8526214866448418]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0763112428978594		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 1.0763112428978594 | validation: 1.8357813313409042]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0840319078925034		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 1.0840319078925034 | validation: 1.9309680883340101]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.127421608897452		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 1.127421608897452 | validation: 1.9339428800374598]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1552821136397045		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 1.1552821136397045 | validation: 1.848170189021357]
	TIME [epoch: 11.6 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0814447541484602		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 1.0814447541484602 | validation: 1.8317043082715156]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0821717686345476		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 1.0821717686345476 | validation: 1.8679229799529784]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1087331837920997		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 1.1087331837920997 | validation: 1.845755155154218]
	TIME [epoch: 11.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1082363811954876		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 1.1082363811954876 | validation: 1.9404284903432243]
	TIME [epoch: 11.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140916240887533		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 1.140916240887533 | validation: 1.8723147062830987]
	TIME [epoch: 11.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1302963158981232		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 1.1302963158981232 | validation: 1.9468356244775045]
	TIME [epoch: 11.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145096186727922		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 1.145096186727922 | validation: 1.8450515184931147]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0912233171375372		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 1.0912233171375372 | validation: 1.864552301098636]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0984479543356656		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 1.0984479543356656 | validation: 1.851914749231621]
	TIME [epoch: 11.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1185171029154808		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 1.1185171029154808 | validation: 1.9117060294388932]
	TIME [epoch: 11.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1183797538469027		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 1.1183797538469027 | validation: 1.8754048711416027]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1057514692051646		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 1.1057514692051646 | validation: 1.8501715973997264]
	TIME [epoch: 11.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1014671110653385		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 1.1014671110653385 | validation: 1.8416960534286864]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0844275729404895		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 1.0844275729404895 | validation: 1.8479388177915241]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0950563140075094		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 1.0950563140075094 | validation: 1.8603695415775416]
	TIME [epoch: 11.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0918853556588841		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 1.0918853556588841 | validation: 1.8356576908709779]
	TIME [epoch: 11.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0835707702902082		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 1.0835707702902082 | validation: 1.8551029219076764]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1028583168531187		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 1.1028583168531187 | validation: 1.8396173739997614]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1223675382868612		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 1.1223675382868612 | validation: 1.864310369454061]
	TIME [epoch: 11.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0929902978859116		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 1.0929902978859116 | validation: 1.863442521777212]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1231921809839376		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 1.1231921809839376 | validation: 1.901148617632518]
	TIME [epoch: 11.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1282035762241478		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 1.1282035762241478 | validation: 1.843712451823589]
	TIME [epoch: 11.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0932371073066995		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 1.0932371073066995 | validation: 1.8877371886157597]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1037513867848736		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 1.1037513867848736 | validation: 1.8809877679276605]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.116155970573136		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 1.116155970573136 | validation: 1.8528264414402953]
	TIME [epoch: 11.6 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0872664135685213		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 1.0872664135685213 | validation: 1.8622466351809701]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082974399541855		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 1.082974399541855 | validation: 1.841619494732246]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1040275025577335		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 1.1040275025577335 | validation: 1.8816140273780426]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178369777005336		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 1.178369777005336 | validation: 1.8462198810199764]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1107716243103831		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 1.1107716243103831 | validation: 1.8445187800245628]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0906076049986138		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 1.0906076049986138 | validation: 1.8499132720591447]
	TIME [epoch: 11.6 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0896871987262193		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 1.0896871987262193 | validation: 1.8583184881519967]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1024708245950303		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 1.1024708245950303 | validation: 1.8941696466639797]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.085712077265333		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 1.085712077265333 | validation: 1.832072400223287]
	TIME [epoch: 11.6 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0886417934888226		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 1.0886417934888226 | validation: 1.8397770765790684]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.101983439102596		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 1.101983439102596 | validation: 1.8548244658604958]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086955684969042		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 1.086955684969042 | validation: 1.8546383091284526]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.079075839362899		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 1.079075839362899 | validation: 1.8728274593300234]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0830451543576047		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 1.0830451543576047 | validation: 1.844384456566399]
	TIME [epoch: 11.6 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0971855453913364		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 1.0971855453913364 | validation: 1.8694926098677087]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.106001968214341		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 1.106001968214341 | validation: 1.8377215585889644]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1022098534730773		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 1.1022098534730773 | validation: 1.8432894604277363]
	TIME [epoch: 11.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.091644491622413		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 1.091644491622413 | validation: 1.8360501149087691]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1098976233511708		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 1.1098976233511708 | validation: 1.8470942619109567]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0957583374857411		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 1.0957583374857411 | validation: 1.8500388482222945]
	TIME [epoch: 11.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102027679645223		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 1.102027679645223 | validation: 1.868281277247246]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0985173083926032		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 1.0985173083926032 | validation: 1.8411233894198697]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.134734811238677		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 1.134734811238677 | validation: 1.8519011970635075]
	TIME [epoch: 11.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0937416195003629		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 1.0937416195003629 | validation: 1.8324576177744347]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0910907530237708		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 1.0910907530237708 | validation: 1.871708822333938]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0921026747245375		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 1.0921026747245375 | validation: 1.8184536040719221]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1002.pth
	Model improved!!!
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.083917662184347		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 1.083917662184347 | validation: 1.83293124824421]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0898957763546657		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 1.0898957763546657 | validation: 1.855418911435005]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0987959015040172		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 1.0987959015040172 | validation: 1.8485379152412156]
	TIME [epoch: 11.6 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.092606882607613		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 1.092606882607613 | validation: 1.8519208737139274]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.108637843559926		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 1.108637843559926 | validation: 1.8450461011410288]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1027025319893258		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 1.1027025319893258 | validation: 1.8356545944832763]
	TIME [epoch: 11.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0748549573689086		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 1.0748549573689086 | validation: 1.8428797328499784]
	TIME [epoch: 11.6 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0737301670725052		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 1.0737301670725052 | validation: 1.8401154357457017]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0867753914567564		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 1.0867753914567564 | validation: 1.8394667419384474]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0874177787719526		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 1.0874177787719526 | validation: 1.9138340065126769]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1299733193366928		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 1.1299733193366928 | validation: 1.8344623809376992]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0872313651758012		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 1.0872313651758012 | validation: 1.8380227882339608]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0776214604766718		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 1.0776214604766718 | validation: 1.8383385520708293]
	TIME [epoch: 11.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1249900850206704		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 1.1249900850206704 | validation: 1.9040852079459132]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1173936784325882		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 1.1173936784325882 | validation: 1.8471976920774649]
	TIME [epoch: 11.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0910549118765713		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 1.0910549118765713 | validation: 1.8334857470767398]
	TIME [epoch: 11.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0855846053353768		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 1.0855846053353768 | validation: 1.8363182496255355]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0912204111895596		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 1.0912204111895596 | validation: 1.8228555548003271]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0871185471594262		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 1.0871185471594262 | validation: 1.8348762621059131]
	TIME [epoch: 11.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0903204669429853		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 1.0903204669429853 | validation: 1.8408842054399188]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0937983879763042		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 1.0937983879763042 | validation: 1.8544844466203503]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0946644772520702		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 1.0946644772520702 | validation: 1.8380045708888089]
	TIME [epoch: 11.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1097218339000503		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 1.1097218339000503 | validation: 1.8434280184636205]
	TIME [epoch: 11.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0817908237296152		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 1.0817908237296152 | validation: 1.842634711431802]
	TIME [epoch: 11.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0753150315734248		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 1.0753150315734248 | validation: 1.822753511962448]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081640593218233		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 1.081640593218233 | validation: 1.8582860213111212]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0899572381369078		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 1.0899572381369078 | validation: 1.8427242400865909]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0832037351359727		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 1.0832037351359727 | validation: 1.8325690798901872]
	TIME [epoch: 11.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1022757217746615		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 1.1022757217746615 | validation: 1.8461338488500634]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0900621384063842		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 1.0900621384063842 | validation: 1.8470627402531952]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.078723391121934		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 1.078723391121934 | validation: 1.8462300367969653]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.076582714952386		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 1.076582714952386 | validation: 1.8417863270955384]
	TIME [epoch: 11.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0825766346131243		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 1.0825766346131243 | validation: 1.843889426107636]
	TIME [epoch: 11.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1138788140830858		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 1.1138788140830858 | validation: 1.8350800341305167]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.092353362152737		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 1.092353362152737 | validation: 1.8375078302168022]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075718840077671		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 1.075718840077671 | validation: 1.8543605141355037]
	TIME [epoch: 11.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1032799661954842		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 1.1032799661954842 | validation: 1.8795295697493106]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0869330137893727		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 1.0869330137893727 | validation: 1.839244954931793]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.084494713122217		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 1.084494713122217 | validation: 1.821452507778816]
	TIME [epoch: 11.6 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0791971389663688		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 1.0791971389663688 | validation: 1.8417262076015133]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0903892455361084		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 1.0903892455361084 | validation: 1.8600127184720745]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0964732290783359		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 1.0964732290783359 | validation: 1.84533351738761]
	TIME [epoch: 11.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0835530159756754		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 1.0835530159756754 | validation: 1.884490398263927]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1052270728407416		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 1.1052270728407416 | validation: 1.8375148733961257]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0811404332195864		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 1.0811404332195864 | validation: 1.8644597231994948]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0898178474337226		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 1.0898178474337226 | validation: 1.8632620380224845]
	TIME [epoch: 11.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1201902995129618		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 1.1201902995129618 | validation: 1.8485226721557952]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0859334058728916		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 1.0859334058728916 | validation: 1.8318732239463906]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0765629044179958		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 1.0765629044179958 | validation: 1.8446739046144256]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1065138328291702		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 1.1065138328291702 | validation: 1.8506019757736396]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0778711952178133		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 1.0778711952178133 | validation: 1.8610425417182155]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0782192282230207		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 1.0782192282230207 | validation: 1.8313957303678918]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0955429893095443		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 1.0955429893095443 | validation: 1.8230652045743403]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0760872786818483		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 1.0760872786818483 | validation: 1.8384047806365118]
	TIME [epoch: 11.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0877102051921266		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 1.0877102051921266 | validation: 1.8438108842019874]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1075920713457574		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 1.1075920713457574 | validation: 1.8942695574947608]
	TIME [epoch: 11.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1188884003477226		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 1.1188884003477226 | validation: 1.8554510812417284]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0869297310603596		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 1.0869297310603596 | validation: 1.8715828277730495]
	TIME [epoch: 11.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1249533694039382		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 1.1249533694039382 | validation: 1.8512574815793819]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0859961271949778		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 1.0859961271949778 | validation: 1.8835414439913976]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.090435952691032		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 1.090435952691032 | validation: 1.842727540250965]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.099680443641735		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 1.099680443641735 | validation: 1.8650199323692618]
	TIME [epoch: 11.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1085402802480384		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 1.1085402802480384 | validation: 1.8588232870247063]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0953810287656975		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 1.0953810287656975 | validation: 1.8290326203116172]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07092720652463		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 1.07092720652463 | validation: 1.8622891324265387]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0980003010286161		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 1.0980003010286161 | validation: 1.830769919443129]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0789436269829382		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 1.0789436269829382 | validation: 1.844807824285]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1087775876781465		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 1.1087775876781465 | validation: 1.8463470301374407]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0874575441967171		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 1.0874575441967171 | validation: 1.8525413436500677]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0858848787025672		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 1.0858848787025672 | validation: 1.832685270778149]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.110360699541097		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 1.110360699541097 | validation: 1.865217056249868]
	TIME [epoch: 11.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0886670752366652		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 1.0886670752366652 | validation: 1.8275845254046423]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0773718508309202		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 1.0773718508309202 | validation: 1.8636601336491219]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0873779753308621		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 1.0873779753308621 | validation: 1.8526704447109938]
	TIME [epoch: 11.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0922890693132663		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 1.0922890693132663 | validation: 1.8426287906459984]
	TIME [epoch: 11.6 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0961650384094805		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 1.0961650384094805 | validation: 1.8251447169536608]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0956438546636533		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 1.0956438546636533 | validation: 1.8277494884554992]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0843981752810985		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 1.0843981752810985 | validation: 1.8849422364478514]
	TIME [epoch: 11.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0862072863433812		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 1.0862072863433812 | validation: 1.8380683310119585]
	TIME [epoch: 11.6 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0879826595885498		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 1.0879826595885498 | validation: 1.8341178635722175]
	TIME [epoch: 11.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0765485724566486		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 1.0765485724566486 | validation: 1.8339598555393701]
	TIME [epoch: 11.6 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0722864561649608		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 1.0722864561649608 | validation: 1.8516213851263976]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0950527113202342		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 1.0950527113202342 | validation: 1.8643662287670273]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0729060141364077		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 1.0729060141364077 | validation: 1.8556179058767408]
	TIME [epoch: 11.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0775314182552649		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 1.0775314182552649 | validation: 1.852200603492657]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1045168325799555		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 1.1045168325799555 | validation: 1.9140156449447128]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0978987700171605		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 1.0978987700171605 | validation: 1.817419464212573]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1089.pth
	Model improved!!!
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.077779902927841		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 1.077779902927841 | validation: 1.8355918786521666]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.122090488897134		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 1.122090488897134 | validation: 1.854855895731787]
	TIME [epoch: 11.6 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.089065471530353		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 1.089065471530353 | validation: 1.8493310603320559]
	TIME [epoch: 11.6 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.113863545648928		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 1.113863545648928 | validation: 1.8176979540938596]
	TIME [epoch: 11.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0847318156869181		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 1.0847318156869181 | validation: 1.8269563375841973]
	TIME [epoch: 11.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0867871370270874		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 1.0867871370270874 | validation: 1.8371298210696207]
	TIME [epoch: 11.6 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0814178486343935		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 1.0814178486343935 | validation: 1.837244310555635]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0970218299720704		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 1.0970218299720704 | validation: 1.8878560271061895]
	TIME [epoch: 11.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1170788883574705		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 1.1170788883574705 | validation: 1.8389437410556404]
	TIME [epoch: 11.6 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1021962887395778		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 1.1021962887395778 | validation: 1.8296624980395713]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0843524123193296		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 1.0843524123193296 | validation: 1.8534255376943167]
	TIME [epoch: 11.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086910461737634		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 1.086910461737634 | validation: 1.8614399034462512]
	TIME [epoch: 11.6 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0813262818175227		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 1.0813262818175227 | validation: 1.8464842263101637]
	TIME [epoch: 11.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0907942182401853		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 1.0907942182401853 | validation: 1.8299353946321126]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1052812988761949		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 1.1052812988761949 | validation: 1.8310889203848126]
	TIME [epoch: 11.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0982091871933601		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 1.0982091871933601 | validation: 1.8623725725419922]
	TIME [epoch: 11.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0882558456037246		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 1.0882558456037246 | validation: 1.8406261309683793]
	TIME [epoch: 11.6 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.090114602363824		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 1.090114602363824 | validation: 1.8389689510062652]
	TIME [epoch: 11.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0778508791925103		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 1.0778508791925103 | validation: 1.8254598030493296]
	TIME [epoch: 11.6 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0762172876962444		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 1.0762172876962444 | validation: 1.8507749295494202]
	TIME [epoch: 11.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0987231909876676		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 1.0987231909876676 | validation: 1.84510581942353]
	TIME [epoch: 11.6 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0874891478322954		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 1.0874891478322954 | validation: 1.8238477226846368]
	TIME [epoch: 11.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0834944178856039		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 1.0834944178856039 | validation: 1.8254658384822195]
	TIME [epoch: 11.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.11310575919782		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 1.11310575919782 | validation: 1.8605137080880922]
	TIME [epoch: 11.6 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.084201644011351		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 1.084201644011351 | validation: 1.832385185318629]
	TIME [epoch: 11.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.079971349748292		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 1.079971349748292 | validation: 1.8304625869864992]
	TIME [epoch: 11.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0969320343186322		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 1.0969320343186322 | validation: 1.831750723429698]
	TIME [epoch: 11.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0736879641046015		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 1.0736879641046015 | validation: 1.8970306753045507]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1037131383245606		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 1.1037131383245606 | validation: 1.8301891207219712]
	TIME [epoch: 11.6 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.088488807165522		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 1.088488807165522 | validation: 1.84913977348766]
	TIME [epoch: 11.6 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0792038230910885		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 1.0792038230910885 | validation: 1.839755146972954]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0835579962590456		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 1.0835579962590456 | validation: 1.838262717622759]
	TIME [epoch: 11.6 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0905408929197897		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 1.0905408929197897 | validation: 1.8334633353951477]
	TIME [epoch: 11.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0692712666738649		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 1.0692712666738649 | validation: 1.845381250994205]
	TIME [epoch: 11.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0764624384395707		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 1.0764624384395707 | validation: 1.8257363421235562]
	TIME [epoch: 11.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0687645323006065		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 1.0687645323006065 | validation: 1.8257237121767513]
	TIME [epoch: 11.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1239925813119678		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 1.1239925813119678 | validation: 1.868779198623926]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0973089346035787		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 1.0973089346035787 | validation: 1.8556110720057908]
	TIME [epoch: 11.6 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0803535379614004		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 1.0803535379614004 | validation: 1.8450572913209464]
	TIME [epoch: 11.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0826732973396813		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 1.0826732973396813 | validation: 1.8340947645313075]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0778242621544751		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 1.0778242621544751 | validation: 1.839690547867993]
	TIME [epoch: 11.6 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0873313502208342		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 1.0873313502208342 | validation: 1.8265546224235538]
	TIME [epoch: 11.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067157658524993		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 1.067157658524993 | validation: 1.8277486395467692]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.074377402128289		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 1.074377402128289 | validation: 1.8246677237374056]
	TIME [epoch: 11.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0926842874872074		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 1.0926842874872074 | validation: 1.8604472216151766]
	TIME [epoch: 11.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.078457567827993		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 1.078457567827993 | validation: 1.832809644537536]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0720879766896398		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 1.0720879766896398 | validation: 1.8373844172750047]
	TIME [epoch: 11.6 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0803914868877704		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 1.0803914868877704 | validation: 1.833421344342053]
	TIME [epoch: 11.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0742090196563447		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 1.0742090196563447 | validation: 1.8916162756233712]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0892075913761141		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 1.0892075913761141 | validation: 1.8514648226386294]
	TIME [epoch: 11.6 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0777048082692873		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 1.0777048082692873 | validation: 1.8259582276410533]
	TIME [epoch: 11.6 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0691411602515761		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 1.0691411602515761 | validation: 1.834831616003193]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.077329075933567		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 1.077329075933567 | validation: 1.8316329599844097]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0837705705939773		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 1.0837705705939773 | validation: 1.8299735143272495]
	TIME [epoch: 11.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0839894979736224		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 1.0839894979736224 | validation: 1.8417150726963598]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0808334124493482		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 1.0808334124493482 | validation: 1.827113715306399]
	TIME [epoch: 11.6 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0798782682375183		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 1.0798782682375183 | validation: 1.812545978251521]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1146.pth
	Model improved!!!
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.072450493436352		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 1.072450493436352 | validation: 1.840004316982638]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0884379638661243		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 1.0884379638661243 | validation: 1.8388475330439065]
	TIME [epoch: 11.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0843844729451169		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 1.0843844729451169 | validation: 1.831652144692214]
	TIME [epoch: 11.6 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.076594608100221		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 1.076594608100221 | validation: 1.8229831106216008]
	TIME [epoch: 11.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07717217022651		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 1.07717217022651 | validation: 1.831025118579006]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0783027522187982		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 1.0783027522187982 | validation: 1.832802287705476]
	TIME [epoch: 11.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0917982258721475		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 1.0917982258721475 | validation: 1.8258247909506287]
	TIME [epoch: 11.6 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0661946954962347		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 1.0661946954962347 | validation: 1.8372202987068336]
	TIME [epoch: 11.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0856279121648629		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 1.0856279121648629 | validation: 1.8433352236482756]
	TIME [epoch: 11.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0749878438663343		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 1.0749878438663343 | validation: 1.832597962810438]
	TIME [epoch: 11.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0874121779739485		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 1.0874121779739485 | validation: 1.8329493152863365]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0738024530871588		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 1.0738024530871588 | validation: 1.8658240714911825]
	TIME [epoch: 11.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0821262076426617		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 1.0821262076426617 | validation: 1.8281634625926533]
	TIME [epoch: 11.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0874548952140586		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 1.0874548952140586 | validation: 1.821119537769582]
	TIME [epoch: 11.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07312551550719		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 1.07312551550719 | validation: 1.83037341112888]
	TIME [epoch: 11.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0720778408020895		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 1.0720778408020895 | validation: 1.8298971597163864]
	TIME [epoch: 11.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075255968122048		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 1.075255968122048 | validation: 1.8324273591240923]
	TIME [epoch: 11.6 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0773123661917963		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 1.0773123661917963 | validation: 1.8277772577267697]
	TIME [epoch: 11.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0741199228840461		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 1.0741199228840461 | validation: 1.8406168635718956]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0754998095746988		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 1.0754998095746988 | validation: 1.8338731803071668]
	TIME [epoch: 11.6 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0791375391100322		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 1.0791375391100322 | validation: 1.8260446995381296]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0772843394023532		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 1.0772843394023532 | validation: 1.8561740901437318]
	TIME [epoch: 11.6 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0907771870673704		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 1.0907771870673704 | validation: 1.8305031035309218]
	TIME [epoch: 11.6 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0696393670861923		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 1.0696393670861923 | validation: 1.8263912935664246]
	TIME [epoch: 11.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1170804331942539		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 1.1170804331942539 | validation: 1.9878133227170043]
	TIME [epoch: 11.6 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1449567302423491		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 1.1449567302423491 | validation: 1.8497072609416159]
	TIME [epoch: 11.6 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0871582780885471		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 1.0871582780885471 | validation: 1.8284358205320768]
	TIME [epoch: 11.6 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0668040138370007		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 1.0668040138370007 | validation: 1.8357950882380658]
	TIME [epoch: 11.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0699716818724443		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 1.0699716818724443 | validation: 1.8225350798111049]
	TIME [epoch: 11.6 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0736009026780604		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 1.0736009026780604 | validation: 1.8311547574189468]
	TIME [epoch: 11.6 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0901793150119925		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 1.0901793150119925 | validation: 1.8763058852535253]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086592872629308		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 1.086592872629308 | validation: 1.8177614449816344]
	TIME [epoch: 11.6 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0729037743892613		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 1.0729037743892613 | validation: 1.8351258166451507]
	TIME [epoch: 11.6 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0733019307107607		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 1.0733019307107607 | validation: 1.8293029277544264]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0813453990579474		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 1.0813453990579474 | validation: 1.8317692994345658]
	TIME [epoch: 11.6 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0715702401322482		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 1.0715702401322482 | validation: 1.821235691054181]
	TIME [epoch: 11.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0715597873228042		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 1.0715597873228042 | validation: 1.8344198406192085]
	TIME [epoch: 11.6 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.070129818484565		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 1.070129818484565 | validation: 1.8387035457809904]
	TIME [epoch: 11.6 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0902999964824216		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 1.0902999964824216 | validation: 1.8403726284521043]
	TIME [epoch: 11.6 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0836281700300912		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 1.0836281700300912 | validation: 1.8723315950928765]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0854045375639831		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 1.0854045375639831 | validation: 1.8339385796919863]
	TIME [epoch: 11.6 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0905261679806266		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 1.0905261679806266 | validation: 1.8399660202657528]
	TIME [epoch: 11.6 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0904229958359197		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 1.0904229958359197 | validation: 1.8453375279825843]
	TIME [epoch: 11.6 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0763126293292178		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 1.0763126293292178 | validation: 1.839538974547574]
	TIME [epoch: 11.6 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0768468993131526		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 1.0768468993131526 | validation: 1.8421613875024725]
	TIME [epoch: 11.6 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0930729107656374		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 1.0930729107656374 | validation: 1.8453777550845576]
	TIME [epoch: 11.6 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.076541698704659		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 1.076541698704659 | validation: 1.837514429432832]
	TIME [epoch: 11.6 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0843021827900423		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 1.0843021827900423 | validation: 1.8199377080663646]
	TIME [epoch: 11.6 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0687823894548583		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 1.0687823894548583 | validation: 1.8240027423105845]
	TIME [epoch: 11.6 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0710350853630106		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 1.0710350853630106 | validation: 1.8354019157847048]
	TIME [epoch: 11.6 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0732010485693955		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 1.0732010485693955 | validation: 1.8359823423509118]
	TIME [epoch: 11.6 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0887515631880365		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 1.0887515631880365 | validation: 1.8377867192613673]
	TIME [epoch: 11.6 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0843859060913101		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 1.0843859060913101 | validation: 1.8499051002138804]
	TIME [epoch: 11.6 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0890380084341842		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 1.0890380084341842 | validation: 1.9041572043851938]
	TIME [epoch: 11.6 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.096998827610298		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 1.096998827610298 | validation: 1.848016122243587]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0764667411175286		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 1.0764667411175286 | validation: 1.8326226481694263]
	TIME [epoch: 11.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075004642531324		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 1.075004642531324 | validation: 1.8377814272504094]
	TIME [epoch: 11.6 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0881301607723928		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 1.0881301607723928 | validation: 1.8530603645789154]
	TIME [epoch: 11.6 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0741016297412296		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 1.0741016297412296 | validation: 1.83791487387311]
	TIME [epoch: 11.6 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0775575951816123		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 1.0775575951816123 | validation: 1.8452667453302605]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.073970493477568		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 1.073970493477568 | validation: 1.848225692185411]
	TIME [epoch: 11.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0860684849926616		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 1.0860684849926616 | validation: 1.8490980716827792]
	TIME [epoch: 11.6 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0840219510037463		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 1.0840219510037463 | validation: 1.837571063885704]
	TIME [epoch: 11.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0674982059663765		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 1.0674982059663765 | validation: 1.8306685947477679]
	TIME [epoch: 11.6 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0828012930163438		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 1.0828012930163438 | validation: 1.8328524516773348]
	TIME [epoch: 11.6 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.073345646620587		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 1.073345646620587 | validation: 1.8201255750846144]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0729368967885298		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 1.0729368967885298 | validation: 1.8314101956146445]
	TIME [epoch: 11.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0730761390861199		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 1.0730761390861199 | validation: 1.865286848330611]
	TIME [epoch: 11.6 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0940331463973179		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 1.0940331463973179 | validation: 1.8240576809759514]
	TIME [epoch: 11.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.074949998368529		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 1.074949998368529 | validation: 1.8283748391853316]
	TIME [epoch: 11.6 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0688086068054903		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 1.0688086068054903 | validation: 1.8272867844595915]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0717573656455703		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 1.0717573656455703 | validation: 1.8261956392871834]
	TIME [epoch: 11.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0776939524212168		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 1.0776939524212168 | validation: 1.818004991989244]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0759628941762451		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 1.0759628941762451 | validation: 1.861360789404573]
	TIME [epoch: 11.6 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.084875163258187		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 1.084875163258187 | validation: 1.825160912994445]
	TIME [epoch: 11.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0834630067810478		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 1.0834630067810478 | validation: 1.8204087945836438]
	TIME [epoch: 11.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0681739268919341		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 1.0681739268919341 | validation: 1.8228668108337582]
	TIME [epoch: 11.6 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0765555075615765		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 1.0765555075615765 | validation: 1.8303410166980132]
	TIME [epoch: 11.6 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0765604869674066		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 1.0765604869674066 | validation: 1.8428377873236066]
	TIME [epoch: 11.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0933985947997638		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 1.0933985947997638 | validation: 1.8986700812083763]
	TIME [epoch: 11.6 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0989463360814584		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 1.0989463360814584 | validation: 1.8338874177476965]
	TIME [epoch: 11.6 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07855103396498		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 1.07855103396498 | validation: 1.8262416850801777]
	TIME [epoch: 11.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0734960715778952		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 1.0734960715778952 | validation: 1.8215286306618657]
	TIME [epoch: 11.6 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.077446315208387		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 1.077446315208387 | validation: 1.8350789963437533]
	TIME [epoch: 11.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.074967134810283		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 1.074967134810283 | validation: 1.8291371726599628]
	TIME [epoch: 11.6 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0729306914864383		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 1.0729306914864383 | validation: 1.8236533323695994]
	TIME [epoch: 11.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0703310092872484		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 1.0703310092872484 | validation: 1.8711882805738689]
	TIME [epoch: 11.6 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0813961996719659		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 1.0813961996719659 | validation: 1.8297545006689]
	TIME [epoch: 11.6 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0779309325617126		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 1.0779309325617126 | validation: 1.8430090330327438]
	TIME [epoch: 11.6 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0792392912714086		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 1.0792392912714086 | validation: 1.8279175291013496]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0682211124303396		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 1.0682211124303396 | validation: 1.8342269726604477]
	TIME [epoch: 11.6 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0811975135690577		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 1.0811975135690577 | validation: 1.823271052814948]
	TIME [epoch: 11.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0830671176823397		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 1.0830671176823397 | validation: 1.8390304942274838]
	TIME [epoch: 11.6 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0942726489434724		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 1.0942726489434724 | validation: 1.8318087902827223]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0716365921733877		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 1.0716365921733877 | validation: 1.8302795869532549]
	TIME [epoch: 11.6 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0669133758086005		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 1.0669133758086005 | validation: 1.8208652779524601]
	TIME [epoch: 11.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075156800070392		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 1.075156800070392 | validation: 1.8429436723605208]
	TIME [epoch: 11.6 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0857162369476048		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 1.0857162369476048 | validation: 1.863995914866303]
	TIME [epoch: 11.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0785226360516336		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 1.0785226360516336 | validation: 1.830347160923904]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0713623922791657		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 1.0713623922791657 | validation: 1.837526446251772]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0716281208755727		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 1.0716281208755727 | validation: 1.8324635806016991]
	TIME [epoch: 11.6 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.069223311740036		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 1.069223311740036 | validation: 1.8264095495143189]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0665940594547225		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 1.0665940594547225 | validation: 1.827757137222057]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0706838425851204		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 1.0706838425851204 | validation: 1.828443904024359]
	TIME [epoch: 11.6 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0727014221532125		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 1.0727014221532125 | validation: 1.8528273619471416]
	TIME [epoch: 11.6 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.074358819536321		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 1.074358819536321 | validation: 1.8211443737711905]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0702000741192803		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 1.0702000741192803 | validation: 1.827603806914147]
	TIME [epoch: 11.6 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0839904998665546		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 1.0839904998665546 | validation: 1.8572695009284803]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082601131619842		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 1.082601131619842 | validation: 1.829534961810844]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0766987262004393		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 1.0766987262004393 | validation: 1.835623068679941]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0719142458388833		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 1.0719142458388833 | validation: 1.827377529786434]
	TIME [epoch: 11.6 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075241203897305		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 1.075241203897305 | validation: 1.819994081135568]
	TIME [epoch: 11.6 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0833379549551727		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 1.0833379549551727 | validation: 1.8325433552727668]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0895306260354871		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 1.0895306260354871 | validation: 1.8464812662017105]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0897724016123496		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 1.0897724016123496 | validation: 1.8320005379354714]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0759047214674113		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 1.0759047214674113 | validation: 1.8364295838074305]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0848440295508142		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 1.0848440295508142 | validation: 1.842398802779255]
	TIME [epoch: 11.6 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0760327532709633		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 1.0760327532709633 | validation: 1.8155596207163718]
	TIME [epoch: 11.6 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0658352068986086		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 1.0658352068986086 | validation: 1.829100692809208]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0981536988887723		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 1.0981536988887723 | validation: 1.8364079723800715]
	TIME [epoch: 11.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0819650328310226		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 1.0819650328310226 | validation: 1.8260770033977094]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0647298400719891		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 1.0647298400719891 | validation: 1.8290107024344544]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07004845084322		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 1.07004845084322 | validation: 1.8219817083765255]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0687094094293137		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 1.0687094094293137 | validation: 1.8429956727451153]
	TIME [epoch: 11.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0753050628879754		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 1.0753050628879754 | validation: 1.8326881575208689]
	TIME [epoch: 11.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0631419435884761		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 1.0631419435884761 | validation: 1.8252618482930227]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0667019255847041		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 1.0667019255847041 | validation: 1.843327472043213]
	TIME [epoch: 11.6 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0723732719421193		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 1.0723732719421193 | validation: 1.8396461363254235]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0689896821116784		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 1.0689896821116784 | validation: 1.8354437862980382]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067398254814124		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 1.067398254814124 | validation: 1.8289470079242314]
	TIME [epoch: 11.6 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.071687511394704		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 1.071687511394704 | validation: 1.8293654006746678]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0745538343873111		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 1.0745538343873111 | validation: 1.8318727260392087]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066472637771137		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 1.066472637771137 | validation: 1.8252245474756372]
	TIME [epoch: 11.6 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0651991299622816		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 1.0651991299622816 | validation: 1.8280155426078866]
	TIME [epoch: 11.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0652731985833959		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 1.0652731985833959 | validation: 1.8191326546529645]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067874603861633		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 1.067874603861633 | validation: 1.8571458374531482]
	TIME [epoch: 11.6 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0763932843384767		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 1.0763932843384767 | validation: 1.8235708422063295]
	TIME [epoch: 11.6 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0671068147559013		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 1.0671068147559013 | validation: 1.8184527821563226]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.069418211067198		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 1.069418211067198 | validation: 1.8368072235629336]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655779516703618		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 1.0655779516703618 | validation: 1.823448574207191]
	TIME [epoch: 11.6 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0708514436897052		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 1.0708514436897052 | validation: 1.8209983740232207]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0646652519235178		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 1.0646652519235178 | validation: 1.8305343698499215]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0687015433072302		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 1.0687015433072302 | validation: 1.8290735973400525]
	TIME [epoch: 11.6 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0737682346258208		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 1.0737682346258208 | validation: 1.8255266130711971]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0666089912682306		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 1.0666089912682306 | validation: 1.838752326511314]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0877334983322422		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 1.0877334983322422 | validation: 1.834166616615193]
	TIME [epoch: 11.6 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0763990136426413		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 1.0763990136426413 | validation: 1.8119879535052497]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1293.pth
	Model improved!!!
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0717718433488712		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 1.0717718433488712 | validation: 1.8469533322337484]
	TIME [epoch: 11.6 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0797778417448978		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 1.0797778417448978 | validation: 1.8246188420536524]
	TIME [epoch: 11.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067986590329971		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 1.067986590329971 | validation: 1.828770553673758]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0670814014745504		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 1.0670814014745504 | validation: 1.8416147335913786]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082540684354787		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 1.082540684354787 | validation: 1.8385713852384464]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0675449534703896		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 1.0675449534703896 | validation: 1.8196726415581612]
	TIME [epoch: 11.6 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0676280425130287		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 1.0676280425130287 | validation: 1.826088239827596]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639986077188275		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 1.0639986077188275 | validation: 1.8279696262912262]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0653848704713422		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 1.0653848704713422 | validation: 1.8294825286832548]
	TIME [epoch: 11.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0785755022129178		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 1.0785755022129178 | validation: 1.8260595121979122]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0739174409862726		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 1.0739174409862726 | validation: 1.8286560677445227]
	TIME [epoch: 11.6 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067164706017097		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 1.067164706017097 | validation: 1.822446056786847]
	TIME [epoch: 11.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0735337517017973		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 1.0735337517017973 | validation: 1.836168241859642]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0843847303880925		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 1.0843847303880925 | validation: 1.8295303597989314]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0652665850139482		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 1.0652665850139482 | validation: 1.8168614712315696]
	TIME [epoch: 11.6 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0698161024605861		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 1.0698161024605861 | validation: 1.8246913999130094]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0675022118073416		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 1.0675022118073416 | validation: 1.8213155101623983]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0676959249554794		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 1.0676959249554794 | validation: 1.8528992687680725]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0831878450738905		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 1.0831878450738905 | validation: 1.8325865088253388]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0636861913220972		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 1.0636861913220972 | validation: 1.826076887157586]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655313302684017		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 1.0655313302684017 | validation: 1.829458888734715]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0675843447409474		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 1.0675843447409474 | validation: 1.8153600167386055]
	TIME [epoch: 11.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655016912002415		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 1.0655016912002415 | validation: 1.8218520114218126]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0760901975759702		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 1.0760901975759702 | validation: 1.817923102482265]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0686047099550848		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 1.0686047099550848 | validation: 1.837335603847005]
	TIME [epoch: 11.6 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0752314865324935		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 1.0752314865324935 | validation: 1.8275513109502144]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0646793057417383		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 1.0646793057417383 | validation: 1.8115442699393998]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1320.pth
	Model improved!!!
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065833939110501		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 1.065833939110501 | validation: 1.81766438296722]
	TIME [epoch: 11.6 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0582238010944662		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 1.0582238010944662 | validation: 1.827145637320748]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0810643229636967		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 1.0810643229636967 | validation: 1.8705068014836632]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0753489230990654		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 1.0753489230990654 | validation: 1.825977617803543]
	TIME [epoch: 11.6 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0769844223881164		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 1.0769844223881164 | validation: 1.814125639289279]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0650284317399503		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 1.0650284317399503 | validation: 1.8255535407462944]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0727978804298681		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 1.0727978804298681 | validation: 1.8234600181024612]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0619249486505826		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 1.0619249486505826 | validation: 1.8265631970949687]
	TIME [epoch: 11.6 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065524542807718		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 1.065524542807718 | validation: 1.816693789335274]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0668647800608473		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 1.0668647800608473 | validation: 1.8290546529488632]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639427995536637		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 1.0639427995536637 | validation: 1.8312413254261057]
	TIME [epoch: 11.6 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064573588627689		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 1.064573588627689 | validation: 1.823680087979902]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068628591099689		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 1.068628591099689 | validation: 1.8208752880482377]
	TIME [epoch: 11.6 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0638939148042148		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 1.0638939148042148 | validation: 1.831468363004118]
	TIME [epoch: 11.6 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0661143453484647		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 1.0661143453484647 | validation: 1.832103460107928]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0713663473409927		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 1.0713663473409927 | validation: 1.8217935465947395]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0848746840073402		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 1.0848746840073402 | validation: 1.8244937702890542]
	TIME [epoch: 11.6 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0663241463309232		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 1.0663241463309232 | validation: 1.831383051732872]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0682824144063074		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 1.0682824144063074 | validation: 1.8316668638152762]
	TIME [epoch: 11.6 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0690958252370844		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 1.0690958252370844 | validation: 1.822335760007224]
	TIME [epoch: 11.6 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0687440532398316		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 1.0687440532398316 | validation: 1.8397835835659313]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0677679174606336		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 1.0677679174606336 | validation: 1.8214847404755972]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0663262744642548		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 1.0663262744642548 | validation: 1.8202428533265766]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0621572078105932		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 1.0621572078105932 | validation: 1.8222470470945544]
	TIME [epoch: 11.6 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061491141587068		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 1.061491141587068 | validation: 1.8295697547113574]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0747183414151031		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 1.0747183414151031 | validation: 1.8365543933335948]
	TIME [epoch: 11.6 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0698684765946307		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 1.0698684765946307 | validation: 1.8231927700584662]
	TIME [epoch: 11.6 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0667336820724556		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 1.0667336820724556 | validation: 1.8285872958511027]
	TIME [epoch: 11.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0640365847044706		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 1.0640365847044706 | validation: 1.8259673659772575]
	TIME [epoch: 11.6 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0732089056718421		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 1.0732089056718421 | validation: 1.8192783101679175]
	TIME [epoch: 11.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0654649417339965		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 1.0654649417339965 | validation: 1.8274992620120765]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0652300419839558		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 1.0652300419839558 | validation: 1.8250334267910842]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064162156574073		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 1.064162156574073 | validation: 1.8395745074953505]
	TIME [epoch: 11.6 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0638242726312042		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 1.0638242726312042 | validation: 1.82423815287928]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066882667508291		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 1.066882667508291 | validation: 1.8302000783548966]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624497331300655		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 1.0624497331300655 | validation: 1.826536957426082]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0671297706416492		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 1.0671297706416492 | validation: 1.8189714564203405]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0676469352499105		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 1.0676469352499105 | validation: 1.8332669448408576]
	TIME [epoch: 11.6 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0743542685104321		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 1.0743542685104321 | validation: 1.8611533874868484]
	TIME [epoch: 11.6 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07913630364446		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 1.07913630364446 | validation: 1.8329904896942009]
	TIME [epoch: 11.6 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656346393495308		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 1.0656346393495308 | validation: 1.8233862213812626]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0669677869062595		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 1.0669677869062595 | validation: 1.8215094126330513]
	TIME [epoch: 11.6 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639995613474051		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 1.0639995613474051 | validation: 1.8457637752349882]
	TIME [epoch: 11.6 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0737114624589412		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 1.0737114624589412 | validation: 1.807783369068382]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1364.pth
	Model improved!!!
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0640425699585305		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 1.0640425699585305 | validation: 1.8148453932577322]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0717294667784605		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 1.0717294667784605 | validation: 1.8190187761207437]
	TIME [epoch: 11.6 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0660763616679207		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 1.0660763616679207 | validation: 1.823885144904612]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0663170980015497		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 1.0663170980015497 | validation: 1.8278595555000425]
	TIME [epoch: 11.6 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0670019044011267		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 1.0670019044011267 | validation: 1.8338425785653432]
	TIME [epoch: 11.6 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655518897459488		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 1.0655518897459488 | validation: 1.828572126385764]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0612221079575983		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 1.0612221079575983 | validation: 1.8144582995675185]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0671338890399489		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 1.0671338890399489 | validation: 1.8181756426806193]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.070032983593128		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 1.070032983593128 | validation: 1.823429856989388]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0725569368019885		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 1.0725569368019885 | validation: 1.821276556839181]
	TIME [epoch: 11.6 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0647672818434983		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 1.0647672818434983 | validation: 1.8198077234426961]
	TIME [epoch: 11.6 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0682753314463012		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 1.0682753314463012 | validation: 1.8192908422603562]
	TIME [epoch: 11.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0698540245996828		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 1.0698540245996828 | validation: 1.855214332960286]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0769536647430598		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 1.0769536647430598 | validation: 1.8215004854137165]
	TIME [epoch: 11.6 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.071756720859831		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 1.071756720859831 | validation: 1.8266548959083395]
	TIME [epoch: 11.6 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0641561566058855		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 1.0641561566058855 | validation: 1.8189225487110237]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0642683486810363		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 1.0642683486810363 | validation: 1.8369893617687307]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068111847400981		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 1.068111847400981 | validation: 1.8241270996435344]
	TIME [epoch: 11.6 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067355307567919		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 1.067355307567919 | validation: 1.8208227858322397]
	TIME [epoch: 11.6 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0728072751995852		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 1.0728072751995852 | validation: 1.8218780254729803]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0705273064972771		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 1.0705273064972771 | validation: 1.8292579650482652]
	TIME [epoch: 11.6 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0633384961477028		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 1.0633384961477028 | validation: 1.8319314915872642]
	TIME [epoch: 11.6 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060427790174551		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 1.060427790174551 | validation: 1.8200049485044543]
	TIME [epoch: 11.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632045668080552		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 1.0632045668080552 | validation: 1.826117095618507]
	TIME [epoch: 11.6 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598369103379477		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 1.0598369103379477 | validation: 1.8151014881628331]
	TIME [epoch: 11.6 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580051144186875		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 1.0580051144186875 | validation: 1.821016974747816]
	TIME [epoch: 11.6 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0651620087107674		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 1.0651620087107674 | validation: 1.8402808068860288]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0630032800353622		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 1.0630032800353622 | validation: 1.832122058522489]
	TIME [epoch: 11.6 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062705605578602		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 1.062705605578602 | validation: 1.817617067487231]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0699088614993615		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 1.0699088614993615 | validation: 1.832966421501908]
	TIME [epoch: 11.6 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0634191929460395		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 1.0634191929460395 | validation: 1.8192094681781814]
	TIME [epoch: 11.6 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.073481004713924		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 1.073481004713924 | validation: 1.8162702140465627]
	TIME [epoch: 11.6 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.08546882245511		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 1.08546882245511 | validation: 1.8338912383461545]
	TIME [epoch: 11.6 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0838748038093344		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 1.0838748038093344 | validation: 1.814076099542824]
	TIME [epoch: 11.6 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0713721734715842		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 1.0713721734715842 | validation: 1.8142415259190958]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656201886094772		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 1.0656201886094772 | validation: 1.8176602422893575]
	TIME [epoch: 11.6 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0841213321080638		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 1.0841213321080638 | validation: 1.8432410430509316]
	TIME [epoch: 11.6 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0846646844199066		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 1.0846646844199066 | validation: 1.8200277829858522]
	TIME [epoch: 11.6 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.077873774817105		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 1.077873774817105 | validation: 1.8229972591015249]
	TIME [epoch: 11.6 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.069863094870181		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 1.069863094870181 | validation: 1.8240065255599587]
	TIME [epoch: 11.6 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0737451351249048		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 1.0737451351249048 | validation: 1.8267691070324696]
	TIME [epoch: 11.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0657218764342673		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 1.0657218764342673 | validation: 1.8214744704842216]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0560383287917912		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 1.0560383287917912 | validation: 1.8147933637354141]
	TIME [epoch: 11.6 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0665698583014462		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 1.0665698583014462 | validation: 1.8201061208254785]
	TIME [epoch: 11.6 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0665025093557168		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 1.0665025093557168 | validation: 1.8276504730215146]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0629721882444658		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 1.0629721882444658 | validation: 1.823125839004996]
	TIME [epoch: 11.6 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0616598678219733		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 1.0616598678219733 | validation: 1.8182105137637858]
	TIME [epoch: 11.6 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067237486549817		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 1.067237486549817 | validation: 1.8169923005095]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06306224439983		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 1.06306224439983 | validation: 1.821211564696601]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0645635537067326		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 1.0645635537067326 | validation: 1.8185610175410645]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0642477337115093		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 1.0642477337115093 | validation: 1.831975870670838]
	TIME [epoch: 11.6 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06779872838465		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 1.06779872838465 | validation: 1.8163888921689715]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617889095431576		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 1.0617889095431576 | validation: 1.8244256629540578]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0633976309067334		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 1.0633976309067334 | validation: 1.828524658689121]
	TIME [epoch: 11.6 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0708883124701427		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 1.0708883124701427 | validation: 1.8472697629398185]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0707821846863852		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 1.0707821846863852 | validation: 1.8201719244604782]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06325992168431		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 1.06325992168431 | validation: 1.8436382226853139]
	TIME [epoch: 11.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0801397875732057		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 1.0801397875732057 | validation: 1.8451474764357556]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066384555969959		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 1.066384555969959 | validation: 1.8315091506292571]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0661768543731245		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 1.0661768543731245 | validation: 1.8166082195831974]
	TIME [epoch: 11.6 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068906413523382		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 1.068906413523382 | validation: 1.8259054535760373]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058463224313956		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 1.058463224313956 | validation: 1.8282557773913715]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0628547287437962		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 1.0628547287437962 | validation: 1.8224459197611245]
	TIME [epoch: 11.6 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0645699147788101		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 1.0645699147788101 | validation: 1.8165486702501505]
	TIME [epoch: 11.6 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0609991172093272		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 1.0609991172093272 | validation: 1.8182712240512564]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617317084929534		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 1.0617317084929534 | validation: 1.8075086782506673]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1430.pth
	Model improved!!!
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625951799028444		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 1.0625951799028444 | validation: 1.84243326792211]
	TIME [epoch: 11.6 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0820249463578433		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 1.0820249463578433 | validation: 1.8377255128140868]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0764588866860156		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 1.0764588866860156 | validation: 1.8202987689232066]
	TIME [epoch: 11.6 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0676810456478645		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 1.0676810456478645 | validation: 1.82529264557209]
	TIME [epoch: 11.6 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617728642157003		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 1.0617728642157003 | validation: 1.8155303677972958]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0710001843343013		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 1.0710001843343013 | validation: 1.83025683691812]
	TIME [epoch: 11.6 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.072020694791078		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 1.072020694791078 | validation: 1.826501012550605]
	TIME [epoch: 11.6 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0619758234404315		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 1.0619758234404315 | validation: 1.8221769139039834]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0634823663581878		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 1.0634823663581878 | validation: 1.8266108717921536]
	TIME [epoch: 11.6 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068054304578445		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 1.068054304578445 | validation: 1.8188561699555659]
	TIME [epoch: 11.6 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0642326632996493		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 1.0642326632996493 | validation: 1.8231096769670592]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617654205828815		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 1.0617654205828815 | validation: 1.8176465638762307]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064391465116394		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 1.064391465116394 | validation: 1.804813187284783]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1443.pth
	Model improved!!!
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0626221474847553		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 1.0626221474847553 | validation: 1.8275157437273313]
	TIME [epoch: 11.6 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625554594467563		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 1.0625554594467563 | validation: 1.8105071575027634]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0670524576436702		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 1.0670524576436702 | validation: 1.819776112922657]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0723904448522645		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 1.0723904448522645 | validation: 1.8188046156448332]
	TIME [epoch: 11.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598848203888103		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 1.0598848203888103 | validation: 1.8299301156006607]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0691140068678153		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 1.0691140068678153 | validation: 1.8327882610353614]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0650220283963474		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 1.0650220283963474 | validation: 1.829069051981]
	TIME [epoch: 11.6 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656195096197427		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 1.0656195096197427 | validation: 1.832084262294857]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0596413840113335		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 1.0596413840113335 | validation: 1.8201396557071683]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0643705243414734		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 1.0643705243414734 | validation: 1.8301459171209242]
	TIME [epoch: 11.6 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063841313816512		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 1.063841313816512 | validation: 1.8133995275782258]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0640174813128946		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 1.0640174813128946 | validation: 1.816916786654839]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0638818371300554		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 1.0638818371300554 | validation: 1.8197203125564465]
	TIME [epoch: 11.6 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617010812674168		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 1.0617010812674168 | validation: 1.8154241052005518]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062308005223696		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 1.062308005223696 | validation: 1.820067705666798]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0644042586752314		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 1.0644042586752314 | validation: 1.8108495205873119]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0597962396562373		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 1.0597962396562373 | validation: 1.8190774694630616]
	TIME [epoch: 11.6 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0597078152001125		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 1.0597078152001125 | validation: 1.8218364032317527]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580499877311493		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 1.0580499877311493 | validation: 1.8223532175448247]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0630010524944875		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 1.0630010524944875 | validation: 1.8240084698944459]
	TIME [epoch: 11.6 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0645043622974995		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 1.0645043622974995 | validation: 1.8226715765300485]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065826373746163		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 1.065826373746163 | validation: 1.8277073651264995]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0633137873256486		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 1.0633137873256486 | validation: 1.8299673846377595]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639266594875079		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 1.0639266594875079 | validation: 1.8248690679011959]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639495905518026		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 1.0639495905518026 | validation: 1.8310263988481748]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067914710559523		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 1.067914710559523 | validation: 1.8286631650315155]
	TIME [epoch: 11.6 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0600809422751398		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 1.0600809422751398 | validation: 1.826263645600953]
	TIME [epoch: 11.6 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064138215508354		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 1.064138215508354 | validation: 1.818166320757899]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0609853309017168		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 1.0609853309017168 | validation: 1.8174680524614681]
	TIME [epoch: 11.6 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589629411112846		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 1.0589629411112846 | validation: 1.8219559161123855]
	TIME [epoch: 11.6 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064172040856107		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 1.064172040856107 | validation: 1.8177315350504748]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0605062707517123		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 1.0605062707517123 | validation: 1.8158160346625989]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0654780800553736		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 1.0654780800553736 | validation: 1.8268714531265704]
	TIME [epoch: 11.6 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.070160727199862		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 1.070160727199862 | validation: 1.823951849494992]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0811641949261703		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 1.0811641949261703 | validation: 1.816053668157924]
	TIME [epoch: 11.6 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0679554782570244		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 1.0679554782570244 | validation: 1.8259104891374216]
	TIME [epoch: 11.6 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598713604458512		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 1.0598713604458512 | validation: 1.8170025370759788]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0633430696194992		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 1.0633430696194992 | validation: 1.8128085308861301]
	TIME [epoch: 11.6 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0615683724832383		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 1.0615683724832383 | validation: 1.8070462113474828]
	TIME [epoch: 11.6 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065494569175725		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 1.065494569175725 | validation: 1.8309586780550402]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065325660664699		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 1.065325660664699 | validation: 1.8162995554167856]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639540842756803		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 1.0639540842756803 | validation: 1.8249340489605772]
	TIME [epoch: 11.6 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062749301366555		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 1.062749301366555 | validation: 1.8170243850467682]
	TIME [epoch: 11.6 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0599246694840387		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 1.0599246694840387 | validation: 1.8180923567531213]
	TIME [epoch: 11.6 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0648941109659387		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 1.0648941109659387 | validation: 1.8220037287945048]
	TIME [epoch: 11.6 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0651360829678733		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 1.0651360829678733 | validation: 1.809807073138174]
	TIME [epoch: 11.6 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0719354841819793		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 1.0719354841819793 | validation: 1.8225423015497553]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0646837377125475		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 1.0646837377125475 | validation: 1.8223303624691563]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0588255213136337		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 1.0588255213136337 | validation: 1.8339528566057655]
	TIME [epoch: 11.6 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0719883129114676		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 1.0719883129114676 | validation: 1.8262078209315047]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0643031761787778		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 1.0643031761787778 | validation: 1.8345161614781]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0660859471488828		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 1.0660859471488828 | validation: 1.8208997264831925]
	TIME [epoch: 11.6 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05561728793334		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 1.05561728793334 | validation: 1.8323524067729182]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0679749019230722		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 1.0679749019230722 | validation: 1.8183468744549212]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063482837921286		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 1.063482837921286 | validation: 1.8203440226190513]
	TIME [epoch: 11.6 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0633823830459925		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 1.0633823830459925 | validation: 1.8160856659336475]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618211606216885		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 1.0618211606216885 | validation: 1.8333566612980803]
	TIME [epoch: 11.6 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065751834596686		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 1.065751834596686 | validation: 1.8337986980407976]
	TIME [epoch: 11.6 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0711845386073195		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 1.0711845386073195 | validation: 1.818655851631407]
	TIME [epoch: 11.6 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063477914765425		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 1.063477914765425 | validation: 1.816340744408945]
	TIME [epoch: 11.6 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598540132742058		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 1.0598540132742058 | validation: 1.8300800018744752]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0567910523524164		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 1.0567910523524164 | validation: 1.8287019116824308]
	TIME [epoch: 11.6 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0630917934858755		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 1.0630917934858755 | validation: 1.826010355068816]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0640074230813297		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 1.0640074230813297 | validation: 1.8189702480193264]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0594261088848524		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 1.0594261088848524 | validation: 1.81890755716076]
	TIME [epoch: 11.6 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0664253277728777		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 1.0664253277728777 | validation: 1.8399267014769805]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065192278144322		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 1.065192278144322 | validation: 1.829266730649639]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0602659039211757		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 1.0602659039211757 | validation: 1.8369531903439855]
	TIME [epoch: 11.6 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0698880225132288		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 1.0698880225132288 | validation: 1.8396935323838748]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0674069014685548		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 1.0674069014685548 | validation: 1.8200450274422284]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0648343476211273		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 1.0648343476211273 | validation: 1.81802027288853]
	TIME [epoch: 11.6 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.069772963623431		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 1.069772963623431 | validation: 1.8226817766501637]
	TIME [epoch: 11.6 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0673309094814971		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 1.0673309094814971 | validation: 1.8132443742896083]
	TIME [epoch: 11.6 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656257012909633		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 1.0656257012909633 | validation: 1.8306956046390095]
	TIME [epoch: 11.6 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0630878082162691		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 1.0630878082162691 | validation: 1.8290592597421396]
	TIME [epoch: 11.6 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617635405489478		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 1.0617635405489478 | validation: 1.825976615755687]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0653854768652669		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 1.0653854768652669 | validation: 1.8207709758823978]
	TIME [epoch: 11.6 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062092226579279		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 1.062092226579279 | validation: 1.8157933296083466]
	TIME [epoch: 11.6 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05966671240866		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 1.05966671240866 | validation: 1.8291041489440016]
	TIME [epoch: 11.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0594898792053093		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 1.0594898792053093 | validation: 1.8214907013427089]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0597480986225059		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 1.0597480986225059 | validation: 1.8164274560468059]
	TIME [epoch: 11.6 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0587449013787629		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 1.0587449013787629 | validation: 1.830455293608276]
	TIME [epoch: 11.6 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060322493745246		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 1.060322493745246 | validation: 1.8235456623850177]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0609580592903245		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 1.0609580592903245 | validation: 1.828562813875875]
	TIME [epoch: 11.6 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632471851306635		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 1.0632471851306635 | validation: 1.8239447674500242]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632895892323586		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 1.0632895892323586 | validation: 1.818827725157753]
	TIME [epoch: 11.6 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06636415295837		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 1.06636415295837 | validation: 1.8354712223252017]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0612550894727173		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 1.0612550894727173 | validation: 1.820026996291889]
	TIME [epoch: 11.6 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0597110098531752		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 1.0597110098531752 | validation: 1.8176938798656779]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060610274581748		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 1.060610274581748 | validation: 1.8169719187841942]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639232332155921		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 1.0639232332155921 | validation: 1.82593770253499]
	TIME [epoch: 11.6 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062169291608129		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 1.062169291608129 | validation: 1.8365919422247736]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067309616935157		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 1.067309616935157 | validation: 1.8173725549543602]
	TIME [epoch: 11.6 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05649746008878		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 1.05649746008878 | validation: 1.8225589036227885]
	TIME [epoch: 11.6 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058710588536182		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 1.058710588536182 | validation: 1.8136363936497784]
	TIME [epoch: 11.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0616311196402832		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 1.0616311196402832 | validation: 1.818627643728]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606337141503501		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 1.0606337141503501 | validation: 1.8175162197658392]
	TIME [epoch: 11.6 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067445332712135		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 1.067445332712135 | validation: 1.8196925418473777]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0679824867105743		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 1.0679824867105743 | validation: 1.8249973447707992]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0645107821658095		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 1.0645107821658095 | validation: 1.823636083890819]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0622216205237387		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 1.0622216205237387 | validation: 1.8203819341201501]
	TIME [epoch: 11.6 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0585587351332904		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 1.0585587351332904 | validation: 1.8094118150100824]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0600293235704485		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 1.0600293235704485 | validation: 1.826644942030618]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617727081623878		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 1.0617727081623878 | validation: 1.815823242630816]
	TIME [epoch: 11.6 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056166009622485		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 1.056166009622485 | validation: 1.8158253113203648]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059266325056641		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 1.059266325056641 | validation: 1.8242624620602887]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058123366052411		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 1.058123366052411 | validation: 1.8231458714003048]
	TIME [epoch: 11.6 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0579059336001673		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 1.0579059336001673 | validation: 1.8149550154493312]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0569876058684933		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 1.0569876058684933 | validation: 1.8303402394425299]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625919768415857		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 1.0625919768415857 | validation: 1.816154435400043]
	TIME [epoch: 11.6 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0631491653258307		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 1.0631491653258307 | validation: 1.8151812605029147]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0613259633804368		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 1.0613259633804368 | validation: 1.8254657105433358]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0636972923864212		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 1.0636972923864212 | validation: 1.8196915379615224]
	TIME [epoch: 11.6 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0642427292881018		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 1.0642427292881018 | validation: 1.8291234320643532]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0619971435510542		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 1.0619971435510542 | validation: 1.8241561266456792]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0643058381539905		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 1.0643058381539905 | validation: 1.8224872709805897]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0610547736057403		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 1.0610547736057403 | validation: 1.8313954135608197]
	TIME [epoch: 11.6 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0668142282279665		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 1.0668142282279665 | validation: 1.822342186101875]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065422943959281		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 1.065422943959281 | validation: 1.818265379463303]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632515235426452		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 1.0632515235426452 | validation: 1.8213658674624567]
	TIME [epoch: 11.6 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0673629735621681		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 1.0673629735621681 | validation: 1.8285672275847091]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0619081468157356		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 1.0619081468157356 | validation: 1.8207810212249433]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0648391127110823		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 1.0648391127110823 | validation: 1.8211419552732582]
	TIME [epoch: 11.6 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0619574184976106		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 1.0619574184976106 | validation: 1.8220732882610537]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0642013163009232		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 1.0642013163009232 | validation: 1.8071639921048837]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623514715180704		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 1.0623514715180704 | validation: 1.8200408916194377]
	TIME [epoch: 11.6 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066795907436488		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 1.066795907436488 | validation: 1.8287830274276993]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0659745554489268		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 1.0659745554489268 | validation: 1.8200385175554556]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655748176387112		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 1.0655748176387112 | validation: 1.82823395795185]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.078393747944781		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 1.078393747944781 | validation: 1.8165849297596008]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623318131729065		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 1.0623318131729065 | validation: 1.8138571713826952]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064282718681175		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 1.064282718681175 | validation: 1.814073978063405]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066566139222568		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 1.066566139222568 | validation: 1.8127814629052297]
	TIME [epoch: 11.6 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0622554073648383		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 1.0622554073648383 | validation: 1.8099547629324053]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589637500336455		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 1.0589637500336455 | validation: 1.810191981931718]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0670541089925825		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 1.0670541089925825 | validation: 1.8234615313455147]
	TIME [epoch: 11.6 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0712466077600857		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 1.0712466077600857 | validation: 1.8222840609520428]
	TIME [epoch: 11.6 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0627590472014596		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 1.0627590472014596 | validation: 1.8223701870283933]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057248973941642		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 1.057248973941642 | validation: 1.8173344955777406]
	TIME [epoch: 11.6 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061822542267381		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 1.061822542267381 | validation: 1.8244618515616093]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057605919536989		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 1.057605919536989 | validation: 1.8152069605975234]
	TIME [epoch: 11.6 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624729036331517		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 1.0624729036331517 | validation: 1.8218010430076346]
	TIME [epoch: 11.6 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059800606807709		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 1.059800606807709 | validation: 1.823102433436385]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058137329632356		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 1.058137329632356 | validation: 1.8255728016842414]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0620903613784047		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 1.0620903613784047 | validation: 1.8187013958604141]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0586717464833257		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 1.0586717464833257 | validation: 1.8265000518526089]
	TIME [epoch: 11.6 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601875424089227		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 1.0601875424089227 | validation: 1.814716778153878]
	TIME [epoch: 11.6 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0674323303991597		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 1.0674323303991597 | validation: 1.8220572224065545]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0680457460863475		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 1.0680457460863475 | validation: 1.8149090545381454]
	TIME [epoch: 11.6 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0620142333629627		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 1.0620142333629627 | validation: 1.818828295927317]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0572768666631773		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 1.0572768666631773 | validation: 1.8162778560023063]
	TIME [epoch: 11.6 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0628016055739387		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 1.0628016055739387 | validation: 1.822093316338864]
	TIME [epoch: 11.6 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623323318776814		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 1.0623323318776814 | validation: 1.8220122820062772]
	TIME [epoch: 11.6 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059176235363686		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 1.059176235363686 | validation: 1.8164279091808115]
	TIME [epoch: 11.6 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0611454951492374		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 1.0611454951492374 | validation: 1.8166471796036825]
	TIME [epoch: 11.6 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0600603401666122		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 1.0600603401666122 | validation: 1.8277620844788858]
	TIME [epoch: 11.6 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058864541366404		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 1.058864541366404 | validation: 1.8149385520298609]
	TIME [epoch: 11.6 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0627795247082763		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 1.0627795247082763 | validation: 1.8254039284099497]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0634925150814105		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 1.0634925150814105 | validation: 1.824992702479605]
	TIME [epoch: 11.6 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0682317943355508		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 1.0682317943355508 | validation: 1.8212680657721627]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0621027048500673		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 1.0621027048500673 | validation: 1.8082081792644442]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0588389159580838		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 1.0588389159580838 | validation: 1.8215491618483959]
	TIME [epoch: 11.6 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0568558898344513		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 1.0568558898344513 | validation: 1.8125216424801676]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0614174904176155		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 1.0614174904176155 | validation: 1.816905382146876]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0602001323956753		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 1.0602001323956753 | validation: 1.8279726381173695]
	TIME [epoch: 11.6 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623612764190764		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 1.0623612764190764 | validation: 1.8142893121161208]
	TIME [epoch: 11.6 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0596799554788254		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 1.0596799554788254 | validation: 1.8187171914299327]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0596218271964781		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 1.0596218271964781 | validation: 1.82487369937804]
	TIME [epoch: 11.6 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063729788473353		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 1.063729788473353 | validation: 1.8290342859186817]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0658154384393492		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 1.0658154384393492 | validation: 1.8298661968971845]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592085727926965		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 1.0592085727926965 | validation: 1.8261372255277706]
	TIME [epoch: 11.6 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0610297492644176		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 1.0610297492644176 | validation: 1.8170730595812308]
	TIME [epoch: 11.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0635860472580885		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 1.0635860472580885 | validation: 1.8197784930431133]
	TIME [epoch: 11.6 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618274968200243		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 1.0618274968200243 | validation: 1.812855744168607]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065197480459783		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 1.065197480459783 | validation: 1.8165574285042658]
	TIME [epoch: 11.6 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0664839769959666		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 1.0664839769959666 | validation: 1.8180673248086674]
	TIME [epoch: 11.6 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0600513935289582		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 1.0600513935289582 | validation: 1.8163837540411334]
	TIME [epoch: 11.6 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062862451221505		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 1.062862451221505 | validation: 1.830083152386115]
	TIME [epoch: 11.6 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606603225698104		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 1.0606603225698104 | validation: 1.8171643050576116]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0579174935728899		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 1.0579174935728899 | validation: 1.8271242123714297]
	TIME [epoch: 11.6 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639554453503577		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 1.0639554453503577 | validation: 1.826480491055201]
	TIME [epoch: 11.6 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0634929146472765		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 1.0634929146472765 | validation: 1.8268041102121677]
	TIME [epoch: 11.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0663398976336889		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 1.0663398976336889 | validation: 1.8310865072468079]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0663903729698894		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 1.0663903729698894 | validation: 1.83351786209519]
	TIME [epoch: 11.6 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0693468808550608		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 1.0693468808550608 | validation: 1.8470990918703212]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0787106650480403		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 1.0787106650480403 | validation: 1.8399232011517455]
	TIME [epoch: 11.6 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0612379297095274		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 1.0612379297095274 | validation: 1.817457096927702]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601555883551095		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 1.0601555883551095 | validation: 1.819762432240765]
	TIME [epoch: 11.6 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0595939088071638		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 1.0595939088071638 | validation: 1.82673948278931]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0630261992327439		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 1.0630261992327439 | validation: 1.8264557317891241]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06671624247031		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 1.06671624247031 | validation: 1.8167844729382665]
	TIME [epoch: 11.6 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.065331011795201		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 1.065331011795201 | validation: 1.8289542220033574]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066235364355131		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 1.066235364355131 | validation: 1.8179312125212679]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639085560297286		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 1.0639085560297286 | validation: 1.822194234349484]
	TIME [epoch: 11.6 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632392559913126		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 1.0632392559913126 | validation: 1.8234409241741276]
	TIME [epoch: 11.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0621801102770811		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 1.0621801102770811 | validation: 1.815610893680871]
	TIME [epoch: 11.6 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0627488996914596		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 1.0627488996914596 | validation: 1.8145555692873665]
	TIME [epoch: 11.6 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0621668064569805		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 1.0621668064569805 | validation: 1.8176209434924118]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0648418581416426		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 1.0648418581416426 | validation: 1.8134184550689594]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0670978425326865		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 1.0670978425326865 | validation: 1.8262673568897032]
	TIME [epoch: 11.6 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0627895634665938		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 1.0627895634665938 | validation: 1.8281533282367735]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0668487552357586		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 1.0668487552357586 | validation: 1.8301286964082937]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.073243132258901		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 1.073243132258901 | validation: 1.8272556676979548]
	TIME [epoch: 11.6 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0652701027801879		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 1.0652701027801879 | validation: 1.8304858637346422]
	TIME [epoch: 11.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068417798843776		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 1.068417798843776 | validation: 1.829781291598997]
	TIME [epoch: 11.6 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617870638816678		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 1.0617870638816678 | validation: 1.814952375169279]
	TIME [epoch: 11.6 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0629522423241395		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 1.0629522423241395 | validation: 1.8179924888883676]
	TIME [epoch: 11.6 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0657286141462787		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 1.0657286141462787 | validation: 1.824746994115026]
	TIME [epoch: 11.6 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625141792878632		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 1.0625141792878632 | validation: 1.8213612670664012]
	TIME [epoch: 11.6 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589002653477013		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 1.0589002653477013 | validation: 1.8143317212127756]
	TIME [epoch: 11.6 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0588986936241174		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 1.0588986936241174 | validation: 1.8233654305333258]
	TIME [epoch: 11.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606163249067138		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 1.0606163249067138 | validation: 1.819402924261503]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0603863408720033		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 1.0603863408720033 | validation: 1.8218949699866858]
	TIME [epoch: 11.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064587092956087		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 1.064587092956087 | validation: 1.8346506127768236]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0659672360301782		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 1.0659672360301782 | validation: 1.834232280001055]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064204042064056		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 1.064204042064056 | validation: 1.8321057567441048]
	TIME [epoch: 11.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056811636880599		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 1.056811636880599 | validation: 1.8210577963280397]
	TIME [epoch: 11.6 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0591806679926699		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 1.0591806679926699 | validation: 1.8217625866800489]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580151797184227		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 1.0580151797184227 | validation: 1.8303227640115751]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062639927747659		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 1.062639927747659 | validation: 1.8311439642750322]
	TIME [epoch: 11.6 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0653654931489456		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 1.0653654931489456 | validation: 1.8279391651397938]
	TIME [epoch: 11.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0582353261954591		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 1.0582353261954591 | validation: 1.8240100609987935]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060882755340082		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 1.060882755340082 | validation: 1.8252301230534653]
	TIME [epoch: 11.6 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059357148541757		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 1.059357148541757 | validation: 1.8146080878400472]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0620894771087372		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 1.0620894771087372 | validation: 1.817770625956518]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0619874971332608		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 1.0619874971332608 | validation: 1.815375078725288]
	TIME [epoch: 11.6 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0593742097030512		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 1.0593742097030512 | validation: 1.8290950479336834]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0565357852103665		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 1.0565357852103665 | validation: 1.8191288865278257]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0613084671692756		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 1.0613084671692756 | validation: 1.8232205145621898]
	TIME [epoch: 11.6 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063701888662448		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 1.063701888662448 | validation: 1.8190217428918392]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0574391079206742		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 1.0574391079206742 | validation: 1.816495489464598]
	TIME [epoch: 11.6 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624379379152342		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 1.0624379379152342 | validation: 1.8142177547077734]
	TIME [epoch: 11.6 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0604556057268617		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 1.0604556057268617 | validation: 1.810614033793992]
	TIME [epoch: 11.6 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058984529483026		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 1.058984529483026 | validation: 1.8062112812404818]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0616743952372378		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 1.0616743952372378 | validation: 1.8197969668973517]
	TIME [epoch: 11.6 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624690723426142		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 1.0624690723426142 | validation: 1.8197491181263272]
	TIME [epoch: 11.6 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0689927908802732		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 1.0689927908802732 | validation: 1.816633697848333]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0642722156652622		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 1.0642722156652622 | validation: 1.8193503683192638]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580620324790457		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 1.0580620324790457 | validation: 1.8187861849975797]
	TIME [epoch: 11.6 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059620539518392		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 1.059620539518392 | validation: 1.8214536201415754]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0594137776565091		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 1.0594137776565091 | validation: 1.8229721779625379]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05810561329156		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 1.05810561329156 | validation: 1.8206655307299862]
	TIME [epoch: 11.6 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583404033849217		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 1.0583404033849217 | validation: 1.822812610710793]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598816370812858		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 1.0598816370812858 | validation: 1.8159158548998682]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0553497379093006		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 1.0553497379093006 | validation: 1.8251759902718385]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057874468111553		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 1.057874468111553 | validation: 1.8312081694297804]
	TIME [epoch: 11.6 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0654115060625864		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 1.0654115060625864 | validation: 1.8414690916933365]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0628574718922765		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 1.0628574718922765 | validation: 1.8181498451936953]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623643358944381		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 1.0623643358944381 | validation: 1.8225039171109694]
	TIME [epoch: 11.6 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0630815915245024		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 1.0630815915245024 | validation: 1.8203034007656111]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0634102567819537		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 1.0634102567819537 | validation: 1.8205006273274793]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0616934899112378		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 1.0616934899112378 | validation: 1.8248074462267787]
	TIME [epoch: 11.6 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06197378485397		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 1.06197378485397 | validation: 1.818788462435203]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057528948206704		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 1.057528948206704 | validation: 1.816459002302479]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0567227442263918		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 1.0567227442263918 | validation: 1.8243293369266627]
	TIME [epoch: 11.6 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590267791036188		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 1.0590267791036188 | validation: 1.8110735634880069]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0627878195330864		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 1.0627878195330864 | validation: 1.824911629576538]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583688315453477		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 1.0583688315453477 | validation: 1.8104278796149726]
	TIME [epoch: 11.6 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0612468296657198		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 1.0612468296657198 | validation: 1.8118516813095868]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058100330829185		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 1.058100330829185 | validation: 1.8133068648630797]
	TIME [epoch: 11.6 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0597010004721112		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 1.0597010004721112 | validation: 1.8152744160719925]
	TIME [epoch: 11.6 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0545850651465403		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 1.0545850651465403 | validation: 1.8171903186759384]
	TIME [epoch: 11.6 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063621628802086		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 1.063621628802086 | validation: 1.8187582702966183]
	TIME [epoch: 11.6 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0562084361268975		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 1.0562084361268975 | validation: 1.827561472191049]
	TIME [epoch: 11.6 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0591077262437967		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 1.0591077262437967 | validation: 1.8060562895257135]
	TIME [epoch: 11.6 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624460777100913		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 1.0624460777100913 | validation: 1.8189598031177758]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592366042722916		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 1.0592366042722916 | validation: 1.823310745765247]
	TIME [epoch: 11.6 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0620329844804015		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 1.0620329844804015 | validation: 1.8159276054859985]
	TIME [epoch: 11.6 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0554974760707396		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 1.0554974760707396 | validation: 1.8225969504011743]
	TIME [epoch: 11.6 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0586852156739093		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 1.0586852156739093 | validation: 1.808450066948156]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060294024769106		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 1.060294024769106 | validation: 1.8250896242586498]
	TIME [epoch: 11.6 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058398372866958		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 1.058398372866958 | validation: 1.8259608205021058]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0552513777521222		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 1.0552513777521222 | validation: 1.8198774631460368]
	TIME [epoch: 11.6 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0591976476128884		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 1.0591976476128884 | validation: 1.8253656739345527]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056389291048814		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 1.056389291048814 | validation: 1.8179313317146553]
	TIME [epoch: 11.6 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0608044062783426		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 1.0608044062783426 | validation: 1.8207851142707534]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06671676164911		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 1.06671676164911 | validation: 1.8177487759664468]
	TIME [epoch: 11.6 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0631997519275584		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 1.0631997519275584 | validation: 1.810436095526451]
	TIME [epoch: 11.6 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063376770487689		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 1.063376770487689 | validation: 1.8113509683904538]
	TIME [epoch: 11.6 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0634865518129093		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 1.0634865518129093 | validation: 1.8200097961455766]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060009664908527		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 1.060009664908527 | validation: 1.8153650751485948]
	TIME [epoch: 11.6 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0658531742433603		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 1.0658531742433603 | validation: 1.8128702350630752]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0608456279511818		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 1.0608456279511818 | validation: 1.8121835070370973]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0599544762221074		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 1.0599544762221074 | validation: 1.817231114341741]
	TIME [epoch: 11.6 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062711378568266		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 1.062711378568266 | validation: 1.8186856916821494]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625665323909483		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 1.0625665323909483 | validation: 1.82201630089964]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062182927879809		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 1.062182927879809 | validation: 1.8185350127470485]
	TIME [epoch: 11.6 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0559111096163676		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 1.0559111096163676 | validation: 1.8233104515874297]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0565205392180954		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 1.0565205392180954 | validation: 1.8152669579885627]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0587334744591341		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 1.0587334744591341 | validation: 1.8212824301222108]
	TIME [epoch: 11.6 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0585027415133292		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 1.0585027415133292 | validation: 1.8274673876380723]
	TIME [epoch: 11.6 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0558488988839938		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 1.0558488988839938 | validation: 1.816728244528218]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057948735932078		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 1.057948735932078 | validation: 1.8208107495533588]
	TIME [epoch: 11.6 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062037576508071		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 1.062037576508071 | validation: 1.8198301181658363]
	TIME [epoch: 11.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058060999534184		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 1.058060999534184 | validation: 1.8217158349452747]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598558061778536		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 1.0598558061778536 | validation: 1.8189382723267844]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0608817645104365		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 1.0608817645104365 | validation: 1.8203740401184914]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0611296668556964		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 1.0611296668556964 | validation: 1.8244983753377915]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601188723844153		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 1.0601188723844153 | validation: 1.821213567985307]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592693091063088		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 1.0592693091063088 | validation: 1.822635377835498]
	TIME [epoch: 11.6 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057858182453135		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 1.057858182453135 | validation: 1.8201570509295955]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0596636387661467		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 1.0596636387661467 | validation: 1.8197114161074257]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0608173683318747		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 1.0608173683318747 | validation: 1.823616972783912]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0633692332065579		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 1.0633692332065579 | validation: 1.8207188374976528]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056909584859806		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 1.056909584859806 | validation: 1.8297472370240457]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0614041006446628		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 1.0614041006446628 | validation: 1.8273005722481857]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606918256023108		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 1.0606918256023108 | validation: 1.836139932249459]
	TIME [epoch: 11.6 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067335779429261		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 1.067335779429261 | validation: 1.8345086009457081]
	TIME [epoch: 11.6 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061740854318566		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 1.061740854318566 | validation: 1.8303451683644916]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0616028605875987		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 1.0616028605875987 | validation: 1.8263631584124427]
	TIME [epoch: 11.6 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057608241626319		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 1.057608241626319 | validation: 1.8239502290625367]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059997779981543		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 1.059997779981543 | validation: 1.830147746424563]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0640898601013002		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 1.0640898601013002 | validation: 1.8191447240076353]
	TIME [epoch: 11.6 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0593737693723255		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 1.0593737693723255 | validation: 1.815247233303032]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0569748413170563		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 1.0569748413170563 | validation: 1.8135799857317678]
	TIME [epoch: 11.6 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606910895896082		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 1.0606910895896082 | validation: 1.8205487751888745]
	TIME [epoch: 11.6 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576519244873077		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 1.0576519244873077 | validation: 1.8133084019548458]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0572312795160983		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 1.0572312795160983 | validation: 1.8213192138230878]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0605578826892186		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 1.0605578826892186 | validation: 1.8279075340620767]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592411781214917		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 1.0592411781214917 | validation: 1.8225727270380525]
	TIME [epoch: 11.6 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576010742547972		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 1.0576010742547972 | validation: 1.827829160558995]
	TIME [epoch: 11.6 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589187792143182		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 1.0589187792143182 | validation: 1.816107247041998]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0574934507930411		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 1.0574934507930411 | validation: 1.8137070276442133]
	TIME [epoch: 11.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0587936370297564		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 1.0587936370297564 | validation: 1.8127418282254382]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059456020649884		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 1.059456020649884 | validation: 1.8151528248631024]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0600967349298442		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 1.0600967349298442 | validation: 1.8313487406570115]
	TIME [epoch: 11.6 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0641821393680562		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 1.0641821393680562 | validation: 1.821500920536198]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.055665210745539		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 1.055665210745539 | validation: 1.8168012637167386]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0566823282562543		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 1.0566823282562543 | validation: 1.8117579576120233]
	TIME [epoch: 11.6 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589593221046498		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 1.0589593221046498 | validation: 1.8139353875105704]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0565472419635624		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 1.0565472419635624 | validation: 1.8153012205124242]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0578680470478632		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 1.0578680470478632 | validation: 1.8228477678699448]
	TIME [epoch: 11.6 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0569587395866953		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 1.0569587395866953 | validation: 1.8133910850620851]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05773778881311		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 1.05773778881311 | validation: 1.8133181461425685]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060935574622141		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 1.060935574622141 | validation: 1.814908014167036]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0600965695165332		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 1.0600965695165332 | validation: 1.8141052496293677]
	TIME [epoch: 11.6 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0578553564552844		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 1.0578553564552844 | validation: 1.8236276809499063]
	TIME [epoch: 11.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059035629028739		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 1.059035629028739 | validation: 1.8192064100584286]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618420013856347		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 1.0618420013856347 | validation: 1.8215317989074526]
	TIME [epoch: 11.6 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0654902260106522		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 1.0654902260106522 | validation: 1.8180541069743918]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059413788916085		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 1.059413788916085 | validation: 1.819136182335826]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063022713140241		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 1.063022713140241 | validation: 1.8248376774434178]
	TIME [epoch: 11.6 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618242232296555		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 1.0618242232296555 | validation: 1.8117870834264795]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058377000960433		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 1.058377000960433 | validation: 1.8170025589786118]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057841222838981		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 1.057841222838981 | validation: 1.827085806338704]
	TIME [epoch: 11.6 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060489012569401		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 1.060489012569401 | validation: 1.820973042484882]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05889633994508		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 1.05889633994508 | validation: 1.8186584038749016]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05918443070614		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 1.05918443070614 | validation: 1.8165093495936255]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059999284867193		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 1.059999284867193 | validation: 1.8093728146012802]
	TIME [epoch: 11.6 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580988137687197		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 1.0580988137687197 | validation: 1.8108920274176217]
	TIME [epoch: 11.6 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0612524774366117		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 1.0612524774366117 | validation: 1.8129658439889336]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0599113937829432		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 1.0599113937829432 | validation: 1.8185818119910482]
	TIME [epoch: 11.6 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618603445461048		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 1.0618603445461048 | validation: 1.8134030559189567]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060056470099574		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 1.060056470099574 | validation: 1.823388728447543]
	TIME [epoch: 11.6 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606595141439945		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 1.0606595141439945 | validation: 1.8252834209162294]
	TIME [epoch: 11.6 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0578014436651786		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 1.0578014436651786 | validation: 1.8217505098965467]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0570520931861374		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 1.0570520931861374 | validation: 1.8212889260238887]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0567577895718987		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 1.0567577895718987 | validation: 1.8191808186326193]
	TIME [epoch: 11.6 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056676245848864		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 1.056676245848864 | validation: 1.8131813070978178]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0547388226159609		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 1.0547388226159609 | validation: 1.8164677071316981]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057206076040595		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 1.057206076040595 | validation: 1.8172529247365357]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059604061711444		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 1.059604061711444 | validation: 1.8048858019091651]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0588656400214977		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 1.0588656400214977 | validation: 1.821430008949328]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0605838043885334		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 1.0605838043885334 | validation: 1.8272893970649573]
	TIME [epoch: 11.6 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057180942200747		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 1.057180942200747 | validation: 1.8160866571179242]
	TIME [epoch: 11.6 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061964085978936		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 1.061964085978936 | validation: 1.8207632435383538]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058195130761059		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 1.058195130761059 | validation: 1.8134992902019895]
	TIME [epoch: 11.6 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0634917472544698		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 1.0634917472544698 | validation: 1.810407661425932]
	TIME [epoch: 11.6 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062996833689445		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 1.062996833689445 | validation: 1.815025560086525]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0612404545655454		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 1.0612404545655454 | validation: 1.818865794261765]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0605918434876718		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 1.0605918434876718 | validation: 1.8151198104454125]
	TIME [epoch: 11.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060569085495969		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 1.060569085495969 | validation: 1.8158260937182933]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0575451321601828		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 1.0575451321601828 | validation: 1.8058882113612051]
	TIME [epoch: 11.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061170684734848		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 1.061170684734848 | validation: 1.8270832575780578]
	TIME [epoch: 11.6 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583211318061134		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 1.0583211318061134 | validation: 1.8150778458318335]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.054595270473712		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 1.054595270473712 | validation: 1.8223919404672353]
	TIME [epoch: 11.6 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056436546279622		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 1.056436546279622 | validation: 1.8216341768298971]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584564326862027		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 1.0584564326862027 | validation: 1.8225844222148606]
	TIME [epoch: 11.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0572176305982408		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 1.0572176305982408 | validation: 1.8229345291569035]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0599683478231625		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 1.0599683478231625 | validation: 1.8065337387063645]
	TIME [epoch: 11.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625117800784962		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 1.0625117800784962 | validation: 1.8223574471460324]
	TIME [epoch: 11.6 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0575031238011332		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 1.0575031238011332 | validation: 1.8118394586960127]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061698311663967		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 1.061698311663967 | validation: 1.8158911422150228]
	TIME [epoch: 11.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0605153698580105		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 1.0605153698580105 | validation: 1.8274214464741834]
	TIME [epoch: 11.6 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0588833473950339		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 1.0588833473950339 | validation: 1.8187852487183145]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057957537596313		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 1.057957537596313 | validation: 1.8292403044801586]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0616376356690143		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 1.0616376356690143 | validation: 1.823186246060323]
	TIME [epoch: 11.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058875053677919		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 1.058875053677919 | validation: 1.8199738058230837]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0586904095296759		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 1.0586904095296759 | validation: 1.8161463107376432]
	TIME [epoch: 11.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0585100077659257		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 1.0585100077659257 | validation: 1.8254538465418182]
	TIME [epoch: 11.6 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592091015539178		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 1.0592091015539178 | validation: 1.8222714669450577]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576167632248301		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 1.0576167632248301 | validation: 1.8252692644899515]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0588402924927047		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 1.0588402924927047 | validation: 1.8238193548348178]
	TIME [epoch: 11.6 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0557778884115092		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 1.0557778884115092 | validation: 1.814614973899112]
	TIME [epoch: 11.6 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0608197501720562		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 1.0608197501720562 | validation: 1.8278266246241288]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0579318946056504		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 1.0579318946056504 | validation: 1.8231792736628538]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0586267164517746		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 1.0586267164517746 | validation: 1.8154369957557805]
	TIME [epoch: 11.6 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576261828542113		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 1.0576261828542113 | validation: 1.8248118887455769]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0550268489407115		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 1.0550268489407115 | validation: 1.8260890726822312]
	TIME [epoch: 11.6 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601036190106383		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 1.0601036190106383 | validation: 1.8149060427430517]
	TIME [epoch: 11.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584496985048162		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 1.0584496985048162 | validation: 1.817069537631598]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0569651448675499		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 1.0569651448675499 | validation: 1.8186773957497924]
	TIME [epoch: 11.6 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057247709325499		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 1.057247709325499 | validation: 1.8137632853439953]
	TIME [epoch: 11.6 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584614405755852		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 1.0584614405755852 | validation: 1.824935353242981]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0582839927534125		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 1.0582839927534125 | validation: 1.817878251113214]
	TIME [epoch: 11.6 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592805422939398		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 1.0592805422939398 | validation: 1.8116794460998187]
	TIME [epoch: 11.6 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623415345092813		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 1.0623415345092813 | validation: 1.8208266405843971]
	TIME [epoch: 11.6 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0582664301026876		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 1.0582664301026876 | validation: 1.8185295568598838]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0587737711199776		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 1.0587737711199776 | validation: 1.819308564950936]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0582479906947224		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 1.0582479906947224 | validation: 1.8152630371317013]
	TIME [epoch: 11.6 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063198189390867		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 1.063198189390867 | validation: 1.8111855291030656]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0647877768969156		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 1.0647877768969156 | validation: 1.812064884531871]
	TIME [epoch: 11.6 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0626808876009441		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 1.0626808876009441 | validation: 1.816182370171485]
	TIME [epoch: 11.6 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057927977978888		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 1.057927977978888 | validation: 1.8198598844690554]
	TIME [epoch: 11.6 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.054263402690447		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 1.054263402690447 | validation: 1.8171536954796488]
	TIME [epoch: 11.6 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0586023990413063		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 1.0586023990413063 | validation: 1.8210600898500078]
	TIME [epoch: 11.6 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0564099692701086		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 1.0564099692701086 | validation: 1.826740001393241]
	TIME [epoch: 11.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0602696571178325		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 1.0602696571178325 | validation: 1.8162503706677973]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0570118025163826		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 1.0570118025163826 | validation: 1.8156262669746734]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583488646069161		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 1.0583488646069161 | validation: 1.815932835686612]
	TIME [epoch: 11.6 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0581903783130553		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 1.0581903783130553 | validation: 1.8142750802644037]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598251046190634		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 1.0598251046190634 | validation: 1.8131385725934894]
	TIME [epoch: 11.6 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576982901558944		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 1.0576982901558944 | validation: 1.8131477544235304]
	TIME [epoch: 11.6 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0605754638529028		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 1.0605754638529028 | validation: 1.8157207430688374]
	TIME [epoch: 11.6 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0563365387604555		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 1.0563365387604555 | validation: 1.8161067921010243]
	TIME [epoch: 11.6 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0642864082597825		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 1.0642864082597825 | validation: 1.8132401186313845]
	TIME [epoch: 11.6 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0568068503316854		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 1.0568068503316854 | validation: 1.8139578332195259]
	TIME [epoch: 11.6 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0620837254501936		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 1.0620837254501936 | validation: 1.8169071261863972]
	TIME [epoch: 11.6 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0575897437581196		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 1.0575897437581196 | validation: 1.814368681463622]
	TIME [epoch: 11.6 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601350608044897		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 1.0601350608044897 | validation: 1.8150044093473257]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584384156125686		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 1.0584384156125686 | validation: 1.8203701663506666]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0575680657836581		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 1.0575680657836581 | validation: 1.817340702415795]
	TIME [epoch: 11.6 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056005283641889		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 1.056005283641889 | validation: 1.8151705223250003]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0610311293763641		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 1.0610311293763641 | validation: 1.8177159851044058]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0554807816324983		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 1.0554807816324983 | validation: 1.8107548001440388]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592220357241493		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 1.0592220357241493 | validation: 1.807848348448777]
	TIME [epoch: 11.6 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583418180005664		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 1.0583418180005664 | validation: 1.813584304128957]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0563256683472158		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 1.0563256683472158 | validation: 1.8160079572821288]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0632976440882655		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 1.0632976440882655 | validation: 1.8162089481119963]
	TIME [epoch: 11.6 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0577410809061978		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 1.0577410809061978 | validation: 1.8185811890819628]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576064454021927		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 1.0576064454021927 | validation: 1.815154596405025]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0563715085343577		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 1.0563715085343577 | validation: 1.8155106300183115]
	TIME [epoch: 11.6 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584812464031823		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 1.0584812464031823 | validation: 1.8209767734410869]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0587992892748095		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 1.0587992892748095 | validation: 1.8224764746626199]
	TIME [epoch: 11.6 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0585503128569265		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 1.0585503128569265 | validation: 1.8153281754109047]
	TIME [epoch: 11.6 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0602936197668404		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 1.0602936197668404 | validation: 1.815908144965306]
	TIME [epoch: 11.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0574881436642936		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 1.0574881436642936 | validation: 1.8182315464312893]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576324424882961		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 1.0576324424882961 | validation: 1.8165019105218227]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0596568480774216		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 1.0596568480774216 | validation: 1.8142531595907334]
	TIME [epoch: 11.6 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062437713657208		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 1.062437713657208 | validation: 1.8140866812866498]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590273785674362		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 1.0590273785674362 | validation: 1.8165800232554683]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0630829380125537		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 1.0630829380125537 | validation: 1.8180414145874135]
	TIME [epoch: 11.6 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0636387654018165		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 1.0636387654018165 | validation: 1.8240192050620727]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064445698538509		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 1.064445698538509 | validation: 1.8196761678264881]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0626153431430034		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 1.0626153431430034 | validation: 1.814544724384211]
	TIME [epoch: 11.6 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063570150401492		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 1.063570150401492 | validation: 1.814581360066116]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0652538470231414		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 1.0652538470231414 | validation: 1.8212202169744172]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064283602765823		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 1.064283602765823 | validation: 1.8063434664592881]
	TIME [epoch: 11.6 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0615161363654466		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 1.0615161363654466 | validation: 1.8092478882810576]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062011685988819		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 1.062011685988819 | validation: 1.8148673028648765]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066078747039234		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 1.066078747039234 | validation: 1.8109892947037967]
	TIME [epoch: 11.6 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060575807572122		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 1.060575807572122 | validation: 1.8191574360706435]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0621557866183133		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 1.0621557866183133 | validation: 1.8163891655841358]
	TIME [epoch: 11.6 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0593414616883108		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 1.0593414616883108 | validation: 1.8171593712543235]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061170723833391		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 1.061170723833391 | validation: 1.8036491106878458]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r3_20240310_044559/states/model_tr_study203_1908.pth
	Model improved!!!
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0560705574929985		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 1.0560705574929985 | validation: 1.8232547044897245]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601030754610572		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 1.0601030754610572 | validation: 1.8228064790287348]
	TIME [epoch: 11.6 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0573660377999408		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 1.0573660377999408 | validation: 1.8212871960672194]
	TIME [epoch: 11.6 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.063466084206295		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 1.063466084206295 | validation: 1.8277964465504248]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062536334131138		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 1.062536334131138 | validation: 1.8323877388045997]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0627259324905534		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 1.0627259324905534 | validation: 1.8199592157046822]
	TIME [epoch: 11.6 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0571728239279554		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 1.0571728239279554 | validation: 1.8177989140551265]
	TIME [epoch: 11.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0591802502392134		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 1.0591802502392134 | validation: 1.8157259590804622]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0566134772914937		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 1.0566134772914937 | validation: 1.827784753696027]
	TIME [epoch: 11.6 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062032029992561		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 1.062032029992561 | validation: 1.8217924097869216]
	TIME [epoch: 11.6 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0609571974446894		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 1.0609571974446894 | validation: 1.817905332379421]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0599638538306562		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 1.0599638538306562 | validation: 1.8217546677515142]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0598338484426306		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 1.0598338484426306 | validation: 1.8212379733572923]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0564349914411055		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 1.0564349914411055 | validation: 1.8173920544211373]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060614754237582		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 1.060614754237582 | validation: 1.8135013129789541]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0573029686855024		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 1.0573029686855024 | validation: 1.813980076189314]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0556307363429607		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 1.0556307363429607 | validation: 1.820546163039645]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059144215683549		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 1.059144215683549 | validation: 1.823435582201186]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583221343821292		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 1.0583221343821292 | validation: 1.8316787324036878]
	TIME [epoch: 11.6 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601694449155792		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 1.0601694449155792 | validation: 1.8212833123454866]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0588114928018535		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 1.0588114928018535 | validation: 1.8218063326956855]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0586800810493655		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 1.0586800810493655 | validation: 1.8226885715963093]
	TIME [epoch: 11.6 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059060641526082		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 1.059060641526082 | validation: 1.8207670038200297]
	TIME [epoch: 11.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0554301744815147		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 1.0554301744815147 | validation: 1.8219020771807837]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0544598878439602		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 1.0544598878439602 | validation: 1.8100315913771388]
	TIME [epoch: 11.6 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057866380363093		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 1.057866380363093 | validation: 1.8171746402713933]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062314088917723		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 1.062314088917723 | validation: 1.8175739961382638]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624289368851432		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 1.0624289368851432 | validation: 1.8135554824098323]
	TIME [epoch: 11.6 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639658908615073		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 1.0639658908615073 | validation: 1.8206393317509275]
	TIME [epoch: 11.6 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0575637796304105		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 1.0575637796304105 | validation: 1.8096022243036947]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0597584372721292		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 1.0597584372721292 | validation: 1.808204442406804]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058645088182809		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 1.058645088182809 | validation: 1.8131423496604613]
	TIME [epoch: 11.6 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060691377941998		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 1.060691377941998 | validation: 1.8193249528680224]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0551324933914723		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 1.0551324933914723 | validation: 1.8177430150485276]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0611536078981412		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 1.0611536078981412 | validation: 1.8179568753375699]
	TIME [epoch: 11.6 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0582645373581188		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 1.0582645373581188 | validation: 1.8154672012485902]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0577145403993224		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 1.0577145403993224 | validation: 1.825284279098168]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0587540919467342		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 1.0587540919467342 | validation: 1.813080638694692]
	TIME [epoch: 11.6 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583672106183681		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 1.0583672106183681 | validation: 1.8165431681743713]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056501024348614		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 1.056501024348614 | validation: 1.8131555302243476]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0575044329780496		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 1.0575044329780496 | validation: 1.816816827471183]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0596075210217728		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 1.0596075210217728 | validation: 1.8109686843358643]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0553123682307943		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 1.0553123682307943 | validation: 1.8166275703001349]
	TIME [epoch: 11.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0549298582638138		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 1.0549298582638138 | validation: 1.8167070303156276]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0577464274588306		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 1.0577464274588306 | validation: 1.8144720994356949]
	TIME [epoch: 11.6 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0567585250103235		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 1.0567585250103235 | validation: 1.8187596888033664]
	TIME [epoch: 11.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0561655051836905		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 1.0561655051836905 | validation: 1.8146552187530751]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0573104275778769		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 1.0573104275778769 | validation: 1.8153008368828645]
	TIME [epoch: 11.6 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059145718562386		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 1.059145718562386 | validation: 1.8192011290035606]
	TIME [epoch: 11.6 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0549470526289075		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 1.0549470526289075 | validation: 1.8204897810455811]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0555234431021348		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 1.0555234431021348 | validation: 1.8086588934213925]
	TIME [epoch: 11.6 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0552638884653804		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 1.0552638884653804 | validation: 1.8240134440257816]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580772895734756		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 1.0580772895734756 | validation: 1.8214333921754542]
	TIME [epoch: 11.6 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0561692378944099		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 1.0561692378944099 | validation: 1.81937155433839]
	TIME [epoch: 11.6 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059915683896167		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 1.059915683896167 | validation: 1.8176128606726383]
	TIME [epoch: 11.6 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0601494048727014		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 1.0601494048727014 | validation: 1.819876489145767]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0574194213255752		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 1.0574194213255752 | validation: 1.807670046742346]
	TIME [epoch: 11.6 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059560429980865		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 1.059560429980865 | validation: 1.8153508996329373]
	TIME [epoch: 11.6 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0602097952762548		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 1.0602097952762548 | validation: 1.8196944325265167]
	TIME [epoch: 11.6 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580994366223433		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 1.0580994366223433 | validation: 1.820107314030601]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062174743243283		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 1.062174743243283 | validation: 1.8174346451335865]
	TIME [epoch: 11.6 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0609164394380821		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 1.0609164394380821 | validation: 1.8185768406667029]
	TIME [epoch: 11.6 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583922363419074		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 1.0583922363419074 | validation: 1.820166818930162]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0615161543435638		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 1.0615161543435638 | validation: 1.8218088091498692]
	TIME [epoch: 11.6 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056509235551687		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 1.056509235551687 | validation: 1.8176695145899557]
	TIME [epoch: 11.6 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617956225027563		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 1.0617956225027563 | validation: 1.8196630988739957]
	TIME [epoch: 11.6 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0610702480321246		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 1.0610702480321246 | validation: 1.8210934163654873]
	TIME [epoch: 11.6 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0618233541876485		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 1.0618233541876485 | validation: 1.807422779816149]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0605415244854457		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 1.0605415244854457 | validation: 1.816997099077488]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0602314443805125		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 1.0602314443805125 | validation: 1.820731886692302]
	TIME [epoch: 11.6 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0578209322437935		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 1.0578209322437935 | validation: 1.8192140143394853]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0565278628248078		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 1.0565278628248078 | validation: 1.823472537148838]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0581344822664895		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 1.0581344822664895 | validation: 1.81475197840803]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061319824729594		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 1.061319824729594 | validation: 1.813477243625701]
	TIME [epoch: 11.6 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058406710032033		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 1.058406710032033 | validation: 1.81267607383332]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590347883457423		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 1.0590347883457423 | validation: 1.809704578856596]
	TIME [epoch: 11.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057896379416453		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 1.057896379416453 | validation: 1.8195914959600392]
	TIME [epoch: 11.6 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061322922151283		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 1.061322922151283 | validation: 1.813017008768665]
	TIME [epoch: 11.6 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589246213924073		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 1.0589246213924073 | validation: 1.8159630071234008]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061762725368107		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 1.061762725368107 | validation: 1.82325607195153]
	TIME [epoch: 11.6 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0556632859852566		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 1.0556632859852566 | validation: 1.8104820124774024]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606624468679728		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 1.0606624468679728 | validation: 1.815805880786757]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583543486685767		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 1.0583543486685767 | validation: 1.8193548645200213]
	TIME [epoch: 11.6 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.060413927264727		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 1.060413927264727 | validation: 1.8152352089237211]
	TIME [epoch: 11.6 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0586832408260256		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 1.0586832408260256 | validation: 1.824399869147013]
	TIME [epoch: 11.6 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0563585283123371		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 1.0563585283123371 | validation: 1.8148490762041203]
	TIME [epoch: 11.6 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0573672247404196		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 1.0573672247404196 | validation: 1.816433866439625]
	TIME [epoch: 11.6 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0541852201499369		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 1.0541852201499369 | validation: 1.8242808100090053]
	TIME [epoch: 11.6 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0550888529440299		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 1.0550888529440299 | validation: 1.8200763338398047]
	TIME [epoch: 11.6 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0570583923979053		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 1.0570583923979053 | validation: 1.8179136477472233]
	TIME [epoch: 11.6 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059355371311063		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 1.059355371311063 | validation: 1.8224590744224285]
	TIME [epoch: 11.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0600769925183826		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 1.0600769925183826 | validation: 1.8275491365230792]
	TIME [epoch: 11.6 sec]
Finished training in 23348.947 seconds.
