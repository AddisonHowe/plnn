Args:
Namespace(name='model_tr_study203', outdir='out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0', training_data='data/transition_rate_studies/tr_study203/tr_study203_training/r0', validation_data='data/transition_rate_studies/tr_study203/tr_study203_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3008829325

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.034925060426758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.034925060426758 | validation: 11.929997673501047]
	TIME [epoch: 100 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.807446195243939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.807446195243939 | validation: 12.865243022932594]
	TIME [epoch: 11.5 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.433891915478885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.433891915478885 | validation: 12.219203890672079]
	TIME [epoch: 11.5 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.977310301767302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.977310301767302 | validation: 9.230410121566031]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.179490448424001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.179490448424001 | validation: 10.038778740387533]
	TIME [epoch: 11.5 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.273044211059833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.273044211059833 | validation: 6.60099602473007]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.82656111559597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.82656111559597 | validation: 5.582334762793517]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.295753099431864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.295753099431864 | validation: 4.9488300886187835]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.153471060285542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.153471060285542 | validation: 4.766952475407478]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6301131710632335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6301131710632335 | validation: 4.4654348528051555]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2623392029211296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2623392029211296 | validation: 4.604260691566817]
	TIME [epoch: 11.5 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.371563601770007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.371563601770007 | validation: 4.689570409644019]
	TIME [epoch: 11.5 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.539577029018701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.539577029018701 | validation: 5.493495352067978]
	TIME [epoch: 11.6 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.682710902698806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.682710902698806 | validation: 4.295926329898001]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.542766512784079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.542766512784079 | validation: 5.055659987562662]
	TIME [epoch: 11.5 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.556503028974248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.556503028974248 | validation: 4.211125998808513]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.646861566307265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.646861566307265 | validation: 4.408626172001542]
	TIME [epoch: 11.5 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.286037950670107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.286037950670107 | validation: 5.044975832145167]
	TIME [epoch: 11.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.263130366321248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.263130366321248 | validation: 4.150234414527947]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.013588466818295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.013588466818295 | validation: 4.990025116357421]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.497470401953784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.497470401953784 | validation: 4.391566066130451]
	TIME [epoch: 11.5 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.364217005903818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.364217005903818 | validation: 3.9898170743990278]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.150609422529502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.150609422529502 | validation: 4.370918347819684]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.03198078272416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.03198078272416 | validation: 5.276465993891292]
	TIME [epoch: 11.5 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2010203844103104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2010203844103104 | validation: 4.119177153525244]
	TIME [epoch: 11.5 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.013773183996275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.013773183996275 | validation: 3.810957576074362]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.992654006379927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.992654006379927 | validation: 4.083271150375234]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.958435811048476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.958435811048476 | validation: 4.356592477325797]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.665157678292684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.665157678292684 | validation: 3.6316726660832432]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.031142280287498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.031142280287498 | validation: 4.254488662270108]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.825613777448529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.825613777448529 | validation: 3.5949330997287463]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.739739738686131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.739739738686131 | validation: 3.9364613537175206]
	TIME [epoch: 11.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.729829681464266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.729829681464266 | validation: 3.9567203821057992]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.544563172740352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.544563172740352 | validation: 4.186308522925011]
	TIME [epoch: 11.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6413899070328855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6413899070328855 | validation: 5.25425063708321]
	TIME [epoch: 11.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.015612382288156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.015612382288156 | validation: 3.687935591533087]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.317047312687601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.317047312687601 | validation: 4.119364312128698]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.576832681849979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.576832681849979 | validation: 4.995908427273126]
	TIME [epoch: 11.5 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.582318480009082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.582318480009082 | validation: 3.6708394744972406]
	TIME [epoch: 11.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468626183290069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.468626183290069 | validation: 3.2619902988433185]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.431509269674005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.431509269674005 | validation: 3.2373783326149823]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.317584595531472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.317584595531472 | validation: 3.1654040509966066]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476735391009406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.476735391009406 | validation: 3.3269798396913655]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.283332504182606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.283332504182606 | validation: 3.37881442643844]
	TIME [epoch: 11.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2383341949107995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2383341949107995 | validation: 3.214903309245946]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0591167835896025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0591167835896025 | validation: 3.9694228691344655]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.309454829724029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.309454829724029 | validation: 3.5359928696916776]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.243105133528089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.243105133528089 | validation: 3.3854389594376744]
	TIME [epoch: 11.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.167950084349417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.167950084349417 | validation: 3.1686506547770086]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.008099325043705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.008099325043705 | validation: 3.0698158601000363]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.233956560989853		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.233956560989853 | validation: 2.8861567259111975]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.185438904525108		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.185438904525108 | validation: 2.9951954094056283]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9894169751710757		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.9894169751710757 | validation: 3.0169373793317233]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9060039514826816		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.9060039514826816 | validation: 3.782583138968159]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9864258641084973		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.9864258641084973 | validation: 2.6416575379166107]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.18720045325239		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.18720045325239 | validation: 2.749295252388976]
	TIME [epoch: 11.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8684792739197698		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.8684792739197698 | validation: 3.699525578667562]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.22217808227453		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.22217808227453 | validation: 2.771866235023604]
	TIME [epoch: 11.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6914564598420094		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.6914564598420094 | validation: 3.0376651118505094]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.048363791189676		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.048363791189676 | validation: 2.6869007087256866]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.913372393947032		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.913372393947032 | validation: 2.869002903850973]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.837794836785361		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.837794836785361 | validation: 2.6387301336012743]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8003884419272014		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.8003884419272014 | validation: 3.5037031949990114]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.020399201531239		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.020399201531239 | validation: 3.4725398480510568]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8373784975050467		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.8373784975050467 | validation: 2.6662297125683803]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.008209973150184		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.008209973150184 | validation: 2.594938014587181]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.848101946155455		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.848101946155455 | validation: 2.683408724438542]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8343338025289335		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.8343338025289335 | validation: 2.5834744642278786]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9024521698499584		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.9024521698499584 | validation: 2.5458120603790086]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8495747428677904		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.8495747428677904 | validation: 3.6918802292183255]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8749183774811153		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.8749183774811153 | validation: 2.6573669736326715]
	TIME [epoch: 11.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7833002831231446		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.7833002831231446 | validation: 2.759493034350457]
	TIME [epoch: 11.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7823902231906867		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.7823902231906867 | validation: 2.563743974144186]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7337987680884877		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.7337987680884877 | validation: 2.501575713502086]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6124523058477465		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.6124523058477465 | validation: 4.151614001244876]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.012111555996482		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.012111555996482 | validation: 2.4704105786998642]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7611955612294965		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.7611955612294965 | validation: 2.669955736060131]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.514039453570353		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.514039453570353 | validation: 2.4097230749022125]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5833606803732074		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.5833606803732074 | validation: 2.886884220163271]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.624597141516735		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.624597141516735 | validation: 2.9333775846305774]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.677492467106582		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.677492467106582 | validation: 2.746670685566449]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6194965386297886		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.6194965386297886 | validation: 2.648577046526848]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5726402870388174		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.5726402870388174 | validation: 2.4307326785619865]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5463626020486023		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.5463626020486023 | validation: 2.299678869257463]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.542237227307676		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.542237227307676 | validation: 2.959272659763302]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.683167583735874		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.683167583735874 | validation: 2.5655090578946806]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3917990917550633		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.3917990917550633 | validation: 2.2918329556749266]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5639447211960786		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.5639447211960786 | validation: 2.486328382274785]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.509931862895926		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.509931862895926 | validation: 2.7119666415474786]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.530233136783182		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.530233136783182 | validation: 2.311448722178881]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.581444078188075		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.581444078188075 | validation: 2.5070495287377974]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.465727989008931		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.465727989008931 | validation: 2.5560910257184917]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5076878358693833		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.5076878358693833 | validation: 2.484783680506455]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.478826058134111		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.478826058134111 | validation: 2.5981302263264423]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.514193930309888		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.514193930309888 | validation: 2.2146897393572464]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.403426425791183		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.403426425791183 | validation: 2.4221846751709393]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.475738585052801		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.475738585052801 | validation: 2.2323536075925774]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.364039722260817		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.364039722260817 | validation: 2.2553105648762823]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4121790584421157		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.4121790584421157 | validation: 2.569125091606146]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4831895095182066		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.4831895095182066 | validation: 2.6774065742270885]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3435512839563817		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.3435512839563817 | validation: 2.560452364265249]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3778365699718482		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.3778365699718482 | validation: 2.5228710942686625]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3463762618743127		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.3463762618743127 | validation: 2.1629808348174207]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5066812388733464		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.5066812388733464 | validation: 2.3616003630720224]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.363705186837464		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.363705186837464 | validation: 2.2827708581623747]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2399070457195767		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.2399070457195767 | validation: 2.2154063307050786]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1849898622982296		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.1849898622982296 | validation: 2.01771675908237]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.50488055023885		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.50488055023885 | validation: 2.2556408117999305]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.428499828366757		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.428499828366757 | validation: 2.6038939390197573]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.344713017453562		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.344713017453562 | validation: 2.4900727528571163]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3443582118543924		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.3443582118543924 | validation: 2.2778863339391497]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2802682990861545		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.2802682990861545 | validation: 2.6699916495304894]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2832685076695816		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.2832685076695816 | validation: 2.1513741560309847]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3322329449121155		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.3322329449121155 | validation: 2.268345228484769]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3753717233233593		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.3753717233233593 | validation: 2.035840121976795]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1829153228135483		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.1829153228135483 | validation: 2.5613174567848533]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.332033056080407		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.332033056080407 | validation: 2.3070928816011658]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.262625626201748		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.262625626201748 | validation: 2.2065679124062534]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2990857057922867		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.2990857057922867 | validation: 2.19069737237884]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.25441624684871		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.25441624684871 | validation: 2.7819300545250214]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4612815842819282		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.4612815842819282 | validation: 2.320209239221248]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.281440173021159		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.281440173021159 | validation: 2.160436929668455]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2304556647672875		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.2304556647672875 | validation: 2.7119187197401526]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.235532634469746		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.235532634469746 | validation: 2.1832125892287793]
	TIME [epoch: 11.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4677936402846528		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.4677936402846528 | validation: 2.1140851693969114]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.146837749957879		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.146837749957879 | validation: 2.285172887095173]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2289497263908142		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.2289497263908142 | validation: 1.9980601382754664]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2083668463335293		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.2083668463335293 | validation: 1.9890442454940875]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.118919550757406		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.118919550757406 | validation: 2.323600040599121]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1294075014784215		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.1294075014784215 | validation: 2.962186294991368]
	TIME [epoch: 11.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3116211813959824		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.3116211813959824 | validation: 1.9938785279234084]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1037369424614702		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.1037369424614702 | validation: 2.320914803352275]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1824561059473964		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.1824561059473964 | validation: 2.1133289855269974]
	TIME [epoch: 11.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.05612868890398		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.05612868890398 | validation: 2.5102801495125595]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.087439101927495		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.087439101927495 | validation: 2.799721199560001]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378651061655241		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.378651061655241 | validation: 2.064521832494682]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1375849366237394		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.1375849366237394 | validation: 1.9368317182829677]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2565401137279393		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.2565401137279393 | validation: 2.4148904800469566]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.133887338147891		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.133887338147891 | validation: 2.109428673801373]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.315363306405399		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.315363306405399 | validation: 2.025631870872001]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0440650401059495		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.0440650401059495 | validation: 2.2933017228431365]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.115628151181667		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.115628151181667 | validation: 2.235156664339622]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219306146275593		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.219306146275593 | validation: 2.197067232272872]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3284962112827303		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.3284962112827303 | validation: 1.9163887732590557]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.109597035168461		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.109597035168461 | validation: 2.1306342201338664]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.044341696576861		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.044341696576861 | validation: 2.0019106677702054]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.48256278435009		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.48256278435009 | validation: 2.0909414912211064]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.016815412318144		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.016815412318144 | validation: 1.8936334305145237]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.11103817877955		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.11103817877955 | validation: 1.902067743592989]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.08780437119723		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.08780437119723 | validation: 1.8915123591974092]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.010963501599159		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.010963501599159 | validation: 2.4161157642494517]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.149527283768075		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.149527283768075 | validation: 2.253351521396897]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1215154243427436		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.1215154243427436 | validation: 2.189039335975124]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.140142004924768		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.140142004924768 | validation: 2.5551693140597114]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1240202262689767		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.1240202262689767 | validation: 2.113683322381965]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9436720569012076		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.9436720569012076 | validation: 2.0815975860190408]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20814153917204		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.20814153917204 | validation: 1.8291871931248609]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.023069955774893		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.023069955774893 | validation: 2.067546288901074]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0863224287999875		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.0863224287999875 | validation: 2.4156562655165947]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0318360427484		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.0318360427484 | validation: 1.974019955452502]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.069770719853959		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.069770719853959 | validation: 1.8886040909343031]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.170742498175973		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.170742498175973 | validation: 1.835901098117699]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.985154655055388		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.985154655055388 | validation: 1.7924826415241775]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0765811132952003		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.0765811132952003 | validation: 1.9532564582656533]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0298047878087586		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.0298047878087586 | validation: 1.9465511511292934]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.00886421646182		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.00886421646182 | validation: 1.8610233577389983]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9045984114490286		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.9045984114490286 | validation: 2.6745024784507594]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.143388546731012		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.143388546731012 | validation: 2.0374497595798737]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.971516124059324		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.971516124059324 | validation: 2.1399959380962996]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1248301337224147		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.1248301337224147 | validation: 1.8685653423391568]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0092698809820266		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.0092698809820266 | validation: 1.8298599580071877]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0265300568856186		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.0265300568856186 | validation: 2.0610744603559716]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.166332979167607		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.166332979167607 | validation: 2.158125293711122]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.057684942330498		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.057684942330498 | validation: 1.808505233048093]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.916421960531764		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.916421960531764 | validation: 2.3522064410315906]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1731683306271203		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.1731683306271203 | validation: 1.9618783264843587]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.003302643640899		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.003302643640899 | validation: 2.306229074537929]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1484104965640967		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.1484104965640967 | validation: 2.048390663865926]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9995328547926254		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.9995328547926254 | validation: 2.565783590681348]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0976471512344674		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.0976471512344674 | validation: 1.7905087365007537]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.943538610325772		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.943538610325772 | validation: 1.7605009589170948]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3275086073809943		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.3275086073809943 | validation: 2.002321072534662]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0417615834975074		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.0417615834975074 | validation: 1.99674845084051]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.994065532227861		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.994065532227861 | validation: 1.8945836780655998]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0006544249351057		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.0006544249351057 | validation: 1.9962163876146792]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.915115601480342		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.915115601480342 | validation: 1.8048397000819971]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.929987415409901		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.929987415409901 | validation: 1.8706815389761453]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8725511660411214		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.8725511660411214 | validation: 2.339041761000252]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.142109089851098		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.142109089851098 | validation: 2.09559357814852]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0292281440515856		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.0292281440515856 | validation: 1.8602302236066965]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.999479677583837		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.999479677583837 | validation: 1.8466277192960554]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.906619893984559		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.906619893984559 | validation: 2.081051533211406]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.034434769821377		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.034434769821377 | validation: 1.8272850257291493]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8765437895431085		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.8765437895431085 | validation: 2.1097335742583057]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9809927644253964		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.9809927644253964 | validation: 1.966425217278217]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9529310266512168		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.9529310266512168 | validation: 1.8695538533941447]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0131448274223622		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.0131448274223622 | validation: 2.022626467056861]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.933241661779137		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.933241661779137 | validation: 1.8032810338296192]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.870621479015221		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.870621479015221 | validation: 1.8217561660408084]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.007189239473248		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.007189239473248 | validation: 2.065387502329173]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9558907337660987		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.9558907337660987 | validation: 2.006550171938238]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.93926069912844		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.93926069912844 | validation: 1.78692509470004]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.938498859335939		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.938498859335939 | validation: 3.049917661556131]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3549486271789766		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.3549486271789766 | validation: 2.4765502383071714]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.170085544703863		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.170085544703863 | validation: 1.789447954748853]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9101886391438043		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.9101886391438043 | validation: 1.8916069108891147]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9320801827820526		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.9320801827820526 | validation: 1.7897827439357212]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9051063161322133		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.9051063161322133 | validation: 1.7481845673949932]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7758286344104093		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.7758286344104093 | validation: 1.6914758549876467]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8927781489838553		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.8927781489838553 | validation: 1.8989089511031143]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.871916737236602		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.871916737236602 | validation: 1.760023503714765]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.827428993584313		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.827428993584313 | validation: 1.9477102318847608]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9222445678311533		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.9222445678311533 | validation: 1.6814471766655055]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8967472800293943		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.8967472800293943 | validation: 1.793869570058522]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.847762348487949		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.847762348487949 | validation: 1.8737436485062267]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9902311166616116		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.9902311166616116 | validation: 1.9863702783653003]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9138664486557935		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.9138664486557935 | validation: 2.043866380652051]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.072832335736855		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.072832335736855 | validation: 1.7376816488959133]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8019092073270473		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 2.8019092073270473 | validation: 1.9001922806000864]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9177617451751874		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.9177617451751874 | validation: 1.86504873788597]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8670274951014276		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.8670274951014276 | validation: 1.8421547953563124]
	TIME [epoch: 11.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8693253446622453		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.8693253446622453 | validation: 1.6794357215260909]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8072062959444195		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.8072062959444195 | validation: 2.1780187517206677]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.154840808955034		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 3.154840808955034 | validation: 2.262544685682014]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9647655211670703		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.9647655211670703 | validation: 1.881583914034874]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.18282256449978		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 3.18282256449978 | validation: 2.0887732284378053]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.045194931538378		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 3.045194931538378 | validation: 1.722342388507484]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8508581280291656		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.8508581280291656 | validation: 1.859621309783163]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.839680780430606		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.839680780430606 | validation: 2.244986239559917]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.964285075530418		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.964285075530418 | validation: 1.7063796942599458]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7404241576466766		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.7404241576466766 | validation: 2.2233568286496865]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.953614056193108		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.953614056193108 | validation: 2.030113351453124]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.871065999801035		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.871065999801035 | validation: 1.6916321281141393]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.746013295628892		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.746013295628892 | validation: 1.8962880139602862]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9416626145340263		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.9416626145340263 | validation: 1.7409176143777891]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8882635502736043		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.8882635502736043 | validation: 2.0374576044217627]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8542421590300413		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.8542421590300413 | validation: 1.9509678535155355]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8551945125046747		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.8551945125046747 | validation: 1.6838053288379946]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.770384794259508		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.770384794259508 | validation: 2.4814057713333217]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.007118987865226		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 3.007118987865226 | validation: 1.969281073844236]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8137069136807997		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.8137069136807997 | validation: 1.7719300188631646]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.843224136123048		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.843224136123048 | validation: 1.7539031448386555]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.835243285761257		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.835243285761257 | validation: 1.6837224019422368]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7489457384686355		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.7489457384686355 | validation: 1.7652063947179295]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9051651075246623		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.9051651075246623 | validation: 1.9106924164642534]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.955180637401509		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.955180637401509 | validation: 2.1333793325164128]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8797939890396766		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.8797939890396766 | validation: 1.9189635014422237]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.908555856326528		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.908555856326528 | validation: 1.6411998263372494]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7251274400698002		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 2.7251274400698002 | validation: 1.7738129414357395]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8552299518283197		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.8552299518283197 | validation: 2.001125608467614]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8636239025821		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.8636239025821 | validation: 1.8199597429927632]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8382068857465055		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.8382068857465055 | validation: 2.0734652457611267]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8721103101977423		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.8721103101977423 | validation: 1.7642614222162212]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.868249171542365		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.868249171542365 | validation: 1.725052407852906]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7531934041108723		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.7531934041108723 | validation: 1.8231578825102035]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.793407804353359		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.793407804353359 | validation: 1.6718440070563685]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.704587230179544		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 2.704587230179544 | validation: 1.8372737789233626]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80434279127116		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.80434279127116 | validation: 1.764807047806386]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8334610677808705		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.8334610677808705 | validation: 1.7988389577700736]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7765130919470566		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.7765130919470566 | validation: 1.9377641826932221]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.788766487003663		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.788766487003663 | validation: 2.1377972124590037]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8611623414615472		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.8611623414615472 | validation: 1.7229849930640968]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.856586572737122		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.856586572737122 | validation: 1.59398576903594]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8194734428318715		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.8194734428318715 | validation: 1.7914235083823002]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7384760033254345		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.7384760033254345 | validation: 1.674562472332263]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.758872661424266		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 2.758872661424266 | validation: 2.0390610187024514]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8592760542881317		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 2.8592760542881317 | validation: 1.7216997967808245]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7553665034716603		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.7553665034716603 | validation: 1.6705761361708762]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.754567938478987		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.754567938478987 | validation: 1.6693281041679517]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7924215609797		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.7924215609797 | validation: 1.9002264553243056]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.822835039181819		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.822835039181819 | validation: 1.7155632215043926]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.73504901025716		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.73504901025716 | validation: 1.8316893751585468]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.789911356062576		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.789911356062576 | validation: 1.6512592218928501]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.69653326028807		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.69653326028807 | validation: 1.74188556033899]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8576783820317213		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.8576783820317213 | validation: 1.625591889084584]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9156036610877294		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.9156036610877294 | validation: 2.1651719622427046]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.809976034173801		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.809976034173801 | validation: 1.7276136771836006]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.819937826663902		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.819937826663902 | validation: 1.6053134315142976]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.776715031973299		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.776715031973299 | validation: 1.6389262814004726]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.772757620383505		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 2.772757620383505 | validation: 1.6789464981385638]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7190432607477373		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.7190432607477373 | validation: 2.006955963581471]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8117642993107115		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.8117642993107115 | validation: 1.7565602818442256]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7767052919622848		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.7767052919622848 | validation: 1.724522041511376]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7222318245908523		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.7222318245908523 | validation: 1.8659831165486318]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805321486761624		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.805321486761624 | validation: 1.867453928203533]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.680891125417763		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.680891125417763 | validation: 1.9668655051415516]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.82308479863604		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.82308479863604 | validation: 1.6140980347024345]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.810855696555676		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.810855696555676 | validation: 1.6417492322330174]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7153440174220504		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.7153440174220504 | validation: 1.5896243017086766]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.864477546051213		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.864477546051213 | validation: 1.674295910709234]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.734274758346231		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.734274758346231 | validation: 1.9443706662507907]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.788650209625527		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.788650209625527 | validation: 1.5925484569137702]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.724493345242781		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.724493345242781 | validation: 2.018033119596983]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8156117714534292		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.8156117714534292 | validation: 1.6189823826597831]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.719485463978206		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.719485463978206 | validation: 1.6665841944040694]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7602715603766206		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.7602715603766206 | validation: 1.6697130074112514]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8486025564014397		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.8486025564014397 | validation: 1.569812461694044]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_297.pth
	Model improved!!!
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6939602596423944		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.6939602596423944 | validation: 1.738805891518329]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7453644823594177		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.7453644823594177 | validation: 1.9666180109445897]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.722227972683512		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.722227972683512 | validation: 2.0328192586883636]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.796433026100222		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.796433026100222 | validation: 1.7411257496798274]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8487305278240957		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.8487305278240957 | validation: 1.6215630390760718]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7178952917961903		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.7178952917961903 | validation: 1.678291386379238]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7507269724657797		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.7507269724657797 | validation: 2.214449156471379]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9107517418571573		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 2.9107517418571573 | validation: 1.8300419322754389]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.755663544933407		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.755663544933407 | validation: 1.7335850634670937]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7253512312776706		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.7253512312776706 | validation: 1.6846664191267615]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7050896515704457		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.7050896515704457 | validation: 1.6100050490330562]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7132898955154943		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.7132898955154943 | validation: 1.7904064485697528]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7096460885126836		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.7096460885126836 | validation: 1.9110662611856817]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7364032874215276		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.7364032874215276 | validation: 1.7922212659486485]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.713712391960585		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.713712391960585 | validation: 1.9694126198154065]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.734215849387381		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 2.734215849387381 | validation: 1.681458064861597]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7220496732945554		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.7220496732945554 | validation: 1.7050838491442761]
	TIME [epoch: 11.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7331270479765504		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.7331270479765504 | validation: 1.8729679285503564]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.724282726376234		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.724282726376234 | validation: 1.7279978370768247]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7363546189564776		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.7363546189564776 | validation: 1.702008450465235]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.765831741133252		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.765831741133252 | validation: 1.596825769270606]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6742298870075683		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 2.6742298870075683 | validation: 1.6925721219977201]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.662124456944478		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.662124456944478 | validation: 1.726679242743333]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.703946759966035		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.703946759966035 | validation: 1.841119952009338]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7127040462326297		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.7127040462326297 | validation: 1.6491709316211267]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7327487677500617		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.7327487677500617 | validation: 1.597729446373828]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6707556194099964		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.6707556194099964 | validation: 1.8660808135134097]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.762297527688141		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 2.762297527688141 | validation: 1.5615409947993482]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6493203271954227		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.6493203271954227 | validation: 1.733596370952921]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6341267208033616		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.6341267208033616 | validation: 2.0126748700102373]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.791149307118588		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 2.791149307118588 | validation: 1.570355993664611]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6429922697332286		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.6429922697332286 | validation: 1.5756954969467125]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6452623699675173		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 2.6452623699675173 | validation: 2.001586846659811]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.759293390104678		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 2.759293390104678 | validation: 1.7056477791157247]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.695991837541194		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 2.695991837541194 | validation: 1.520182005306629]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.751939187653184		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.751939187653184 | validation: 1.6048320096756459]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6594698436214523		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.6594698436214523 | validation: 1.8620915254114756]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6984497703938826		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 2.6984497703938826 | validation: 1.5478475095735766]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.594410281040158		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.594410281040158 | validation: 1.5181989278659018]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5862444664692426		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 2.5862444664692426 | validation: 1.811732738930266]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.642746387664659		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 2.642746387664659 | validation: 1.5005429152048597]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.612634460031136		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 2.612634460031136 | validation: 1.6133003371531762]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6258632120287295		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 2.6258632120287295 | validation: 1.6592373626303158]
	TIME [epoch: 11.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.626155160366664		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 2.626155160366664 | validation: 1.5722042621811736]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.722368855966188		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 2.722368855966188 | validation: 1.6805968971031737]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.629101562780374		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 2.629101562780374 | validation: 1.8605891247012403]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.698792578616207		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 2.698792578616207 | validation: 1.5177723656696984]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5999297669923496		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.5999297669923496 | validation: 1.806782130937373]
	TIME [epoch: 11.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.660613551905329		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 2.660613551905329 | validation: 1.5079267915149475]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6096368417007323		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 2.6096368417007323 | validation: 1.6084844070860924]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6144392612520493		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 2.6144392612520493 | validation: 1.4639215102281673]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6461490577262925		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 2.6461490577262925 | validation: 1.5119304379463623]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6315254167324627		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 2.6315254167324627 | validation: 1.6880331400993371]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2084574788605797		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 3.2084574788605797 | validation: 1.4800948718221174]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6414782264283674		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 2.6414782264283674 | validation: 1.5857375300043253]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.629131914792112		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 2.629131914792112 | validation: 1.5214879290050771]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.625430233027642		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.625430233027642 | validation: 1.7923261236124948]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6581281741051175		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 2.6581281741051175 | validation: 1.5608067177127938]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.60484008398921		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.60484008398921 | validation: 1.5353763608370383]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5542720962400987		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 2.5542720962400987 | validation: 1.612257192474001]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5851156673844224		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 2.5851156673844224 | validation: 1.6556315335457654]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5733106370348207		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.5733106370348207 | validation: 1.5348610284477706]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.595325261307811		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 2.595325261307811 | validation: 1.5598228730860055]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6846477573272907		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 2.6846477573272907 | validation: 1.8096525014947968]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.590957287789224		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 2.590957287789224 | validation: 1.4530726244430552]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.612175151629269		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.612175151629269 | validation: 1.4736491774455345]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5430023121663705		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.5430023121663705 | validation: 1.5295718582151137]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.60891290544866		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.60891290544866 | validation: 1.7813620597433115]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6723891336261385		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 2.6723891336261385 | validation: 1.4831358000627097]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5919346230201876		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.5919346230201876 | validation: 1.5945394764657095]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5669516106221026		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 2.5669516106221026 | validation: 1.569884826772848]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.553054872535628		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 2.553054872535628 | validation: 1.455285992297291]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5575089150269066		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 2.5575089150269066 | validation: 1.4963246282779201]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.734724158103986		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 2.734724158103986 | validation: 1.8129351508634137]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6143446146716594		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 2.6143446146716594 | validation: 1.8856245853560831]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.81932616911678		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 2.81932616911678 | validation: 1.5663571714051086]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.540785155835206		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 2.540785155835206 | validation: 1.4810705760518965]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.562705704890929		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 2.562705704890929 | validation: 1.6688265008002654]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6220423388043295		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 2.6220423388043295 | validation: 1.513499892727558]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5348975943748377		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 2.5348975943748377 | validation: 1.4822979696584657]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6263125966223666		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 2.6263125966223666 | validation: 1.8201857876233434]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6718371472206552		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 2.6718371472206552 | validation: 1.536353643123618]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.589181753972992		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 2.589181753972992 | validation: 1.4503357569138178]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.512120450579282		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 2.512120450579282 | validation: 1.6246451177251788]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5906716714158393		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 2.5906716714158393 | validation: 1.5019551738956756]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5560350552853817		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 2.5560350552853817 | validation: 1.5643538955645153]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5512056258338465		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 2.5512056258338465 | validation: 1.4719680838301465]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5488580575361595		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 2.5488580575361595 | validation: 1.4372158104431947]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5691338836587927		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 2.5691338836587927 | validation: 1.4609610765363277]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.56816023656514		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 2.56816023656514 | validation: 1.6185771018353814]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5914102804253853		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 2.5914102804253853 | validation: 1.4253277105560136]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6437569710639828		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 2.6437569710639828 | validation: 1.955740355135154]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6887311516437045		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 2.6887311516437045 | validation: 1.4177103351796772]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8240784686723654		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 2.8240784686723654 | validation: 1.6953483320232112]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6176774802079836		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 2.6176774802079836 | validation: 1.4434002979517875]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5140352251294042		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 2.5140352251294042 | validation: 1.5353626344988993]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.534110131514125		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 2.534110131514125 | validation: 1.578749754308966]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5670219189555215		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 2.5670219189555215 | validation: 1.5336767322226421]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6737701388361534		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 2.6737701388361534 | validation: 1.6185737074245186]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.745252127801946		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 2.745252127801946 | validation: 1.4305488384284113]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5099449992728684		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 2.5099449992728684 | validation: 1.5065235416207825]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.796194939121898		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 2.796194939121898 | validation: 1.5359605329856925]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5106502375915336		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 2.5106502375915336 | validation: 1.7558135689017842]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.595602664260387		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 2.595602664260387 | validation: 1.450116094618972]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5934143043938667		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 2.5934143043938667 | validation: 1.6255271816595933]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5256072336951156		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 2.5256072336951156 | validation: 1.4344659452345938]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.511006136108685		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 2.511006136108685 | validation: 1.6065560020575265]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5805941676977975		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 2.5805941676977975 | validation: 1.4507620728656534]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.556782754869533		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 2.556782754869533 | validation: 1.480226712754656]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5535220882416527		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 2.5535220882416527 | validation: 1.5553080055559962]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6601236894326883		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 2.6601236894326883 | validation: 1.4128930330328349]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5877194525521032		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 2.5877194525521032 | validation: 1.4285302317480482]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6799265230574245		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 2.6799265230574245 | validation: 1.480245722199146]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.50527899569632		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 2.50527899569632 | validation: 1.561978116155501]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5284955674365865		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 2.5284955674365865 | validation: 1.513430593211038]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5136503943467545		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 2.5136503943467545 | validation: 1.5249054472113903]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5297521305833497		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 2.5297521305833497 | validation: 1.451877648605492]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5294437309978437		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 2.5294437309978437 | validation: 1.4218125416811613]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5266588012464313		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 2.5266588012464313 | validation: 1.652502146157418]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5444459175147522		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 2.5444459175147522 | validation: 1.4912805342954607]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5236330869353454		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 2.5236330869353454 | validation: 1.8295698157432005]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5837153767383514		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 2.5837153767383514 | validation: 1.4399988693023622]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.584830724356318		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 2.584830724356318 | validation: 1.594132510432415]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6501324249825062		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 2.6501324249825062 | validation: 1.4108132140979353]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.64834956688002		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 2.64834956688002 | validation: 1.3939142127341813]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.639487604082598		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 2.639487604082598 | validation: 1.452833255476538]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5250539261961182		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 2.5250539261961182 | validation: 1.5546141628020673]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.507680903980657		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 2.507680903980657 | validation: 1.7084040199077641]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.609276976655808		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 2.609276976655808 | validation: 1.3969401240951493]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4572468168778716		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 2.4572468168778716 | validation: 1.5117890299535433]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5322546201977056		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 2.5322546201977056 | validation: 1.8379322086238938]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.737951751181815		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 2.737951751181815 | validation: 1.8954663360631627]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6330743025048515		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 2.6330743025048515 | validation: 1.420497835783965]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.513063083535194		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 2.513063083535194 | validation: 1.4524445810897515]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.57212646707955		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 2.57212646707955 | validation: 1.419267823822209]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.509245295126012		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 2.509245295126012 | validation: 1.419660095031892]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6029142972884536		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 2.6029142972884536 | validation: 1.5003471434510678]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5236276241039546		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 2.5236276241039546 | validation: 1.433435244515376]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4825337921240402		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 2.4825337921240402 | validation: 1.5075821882068265]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5375946625041452		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 2.5375946625041452 | validation: 1.4840648648875219]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.639618631416557		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 2.639618631416557 | validation: 1.7818858871116385]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.570833793379683		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 2.570833793379683 | validation: 1.3718102150432006]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4920893406554505		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 2.4920893406554505 | validation: 1.6241520948627397]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.607884731044711		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 2.607884731044711 | validation: 1.7926751622494368]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.621595381814645		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 2.621595381814645 | validation: 1.4172019449931927]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.50790045657061		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 2.50790045657061 | validation: 1.4570298525755236]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.553242022000046		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 2.553242022000046 | validation: 1.3924230669445785]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4557120632829457		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 2.4557120632829457 | validation: 1.402678539543196]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.567643633452965		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 2.567643633452965 | validation: 1.5425633738592055]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5883149729943686		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 2.5883149729943686 | validation: 1.3767367155300738]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6205888343622097		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 2.6205888343622097 | validation: 1.3904067247959069]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5021965105343704		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 2.5021965105343704 | validation: 1.6515008055737732]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5106645849115092		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 2.5106645849115092 | validation: 1.3966664301713325]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.490439150983635		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 2.490439150983635 | validation: 1.365575553200088]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.463773736566404		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 2.463773736566404 | validation: 1.473356402993962]
	TIME [epoch: 11.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.491459531635169		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 2.491459531635169 | validation: 1.460989572102864]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4348488226136165		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 2.4348488226136165 | validation: 1.3914095723468165]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.430292025568444		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 2.430292025568444 | validation: 1.6211972791849878]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.597250343175177		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 2.597250343175177 | validation: 1.5372090917734471]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4893916371855473		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 2.4893916371855473 | validation: 1.3876316904372012]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4534195297058448		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 2.4534195297058448 | validation: 1.3680883819181309]
	TIME [epoch: 11.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4403321928755632		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 2.4403321928755632 | validation: 1.382640659460365]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4514888290765082		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 2.4514888290765082 | validation: 1.414436963547027]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4493481224876943		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 2.4493481224876943 | validation: 1.5979174706492714]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5102597707834686		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 2.5102597707834686 | validation: 1.435011447035757]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4482247277135936		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 2.4482247277135936 | validation: 1.4482393236086915]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4426060767335374		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 2.4426060767335374 | validation: 1.4658542850880611]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5048604848953495		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 2.5048604848953495 | validation: 1.4505327593677342]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.458081413327914		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 2.458081413327914 | validation: 1.392300319757655]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5068559899102496		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 2.5068559899102496 | validation: 1.3993302619859151]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.470022753268942		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 2.470022753268942 | validation: 1.374715984226061]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5004184265958616		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 2.5004184265958616 | validation: 1.365501649039964]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4784331063275813		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 2.4784331063275813 | validation: 1.3529618186967662]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_470.pth
	Model improved!!!
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4885462790523567		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 2.4885462790523567 | validation: 1.4988375361291713]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4999515631500344		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 2.4999515631500344 | validation: 1.3513299591937529]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.758976248851841		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 2.758976248851841 | validation: 1.4154662281082022]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450042930382989		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 2.450042930382989 | validation: 1.3835217245506]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4136120619385664		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 2.4136120619385664 | validation: 1.5404812411700348]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4951465725271618		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 2.4951465725271618 | validation: 1.3721366135442292]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4364968565405136		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 2.4364968565405136 | validation: 1.6578821076906556]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5264912711558836		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 2.5264912711558836 | validation: 1.7604983414852604]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.500890531189796		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 2.500890531189796 | validation: 1.4869698731655892]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.447270364075816		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 2.447270364075816 | validation: 1.4088429033924945]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4582847597727615		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 2.4582847597727615 | validation: 1.4989547368484812]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.509543864826493		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 2.509543864826493 | validation: 1.3448403315206878]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.394770258454942		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 2.394770258454942 | validation: 1.5591394825391893]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.486550739403577		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 2.486550739403577 | validation: 1.6567945490142608]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.514099242815206		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 2.514099242815206 | validation: 1.6311922409594894]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5352813789794606		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 2.5352813789794606 | validation: 1.376791205444539]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4208223747276123		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 2.4208223747276123 | validation: 1.343774223582726]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.553463369942725		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 2.553463369942725 | validation: 1.4238231320711687]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4647870330443125		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 2.4647870330443125 | validation: 1.659567599393321]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.515221128406924		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 2.515221128406924 | validation: 1.4023364950358632]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4312954714763864		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 2.4312954714763864 | validation: 1.3474142593780192]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.485003095119897		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 2.485003095119897 | validation: 1.3605379281627143]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.411672887279299		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 2.411672887279299 | validation: 1.3530347818694899]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.45679938558032		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 2.45679938558032 | validation: 1.7437506144801194]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.556090237656118		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 2.556090237656118 | validation: 1.4795939994867167]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4430038960341003		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 2.4430038960341003 | validation: 1.4244242717107458]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.447521776915803		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 2.447521776915803 | validation: 1.3828247169526375]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.393062321121781		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 2.393062321121781 | validation: 1.6251184568663024]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4691344571975167		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 2.4691344571975167 | validation: 1.4968192661120372]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.52971322731537		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 2.52971322731537 | validation: 1.4902667725810779]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4911997051124404		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 2.4911997051124404 | validation: 1.4003860855301336]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.460407330284809		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 2.460407330284809 | validation: 1.8260713076490862]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.57859217508613		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 2.57859217508613 | validation: 1.3956536163157534]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.412121150686956		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 2.412121150686956 | validation: 1.378206444697094]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4096156321120503		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 2.4096156321120503 | validation: 1.3497372223430266]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.417327530495135		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 2.417327530495135 | validation: 1.6572573893363438]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.468008777898608		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 2.468008777898608 | validation: 1.4054617278889618]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4727840816886255		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 2.4727840816886255 | validation: 1.3869602711016105]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4194900103346066		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 2.4194900103346066 | validation: 1.3975738603291432]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4169589835927514		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 2.4169589835927514 | validation: 1.3812146214946852]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.442562542623863		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 2.442562542623863 | validation: 1.4383646790075633]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4053992083916156		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 2.4053992083916156 | validation: 1.3310309072728665]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3934258687136345		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 2.3934258687136345 | validation: 1.4048092303034867]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.472702971881544		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 2.472702971881544 | validation: 1.3082165496720657]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.41194415107716		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 2.41194415107716 | validation: 1.514479315442518]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4234638453218817		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 2.4234638453218817 | validation: 1.395169224042549]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4170901790848		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 2.4170901790848 | validation: 1.3333022238272807]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4460195203032096		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 2.4460195203032096 | validation: 1.4454129566426652]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.418376043052483		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 2.418376043052483 | validation: 1.330486793541337]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420307246524524		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 2.420307246524524 | validation: 1.5624788769649858]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.504853212961421		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 2.504853212961421 | validation: 1.5252363750233868]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4979605124156583		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 2.4979605124156583 | validation: 1.4161505049970038]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4171303461975113		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 2.4171303461975113 | validation: 1.4230926084762325]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.418249179020442		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 2.418249179020442 | validation: 1.4089558120391679]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4009526301985726		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 2.4009526301985726 | validation: 1.419589492845878]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.505003325623716		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 2.505003325623716 | validation: 1.6534012108867953]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.510826575708832		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 2.510826575708832 | validation: 1.3815056598127229]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4181393565318037		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 2.4181393565318037 | validation: 1.5111111696924426]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5008827637554663		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 2.5008827637554663 | validation: 1.3698045089424795]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.409900700617724		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 2.409900700617724 | validation: 1.3755359350861847]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3786668908371107		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 2.3786668908371107 | validation: 1.3910600507856856]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416532660235708		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 2.416532660235708 | validation: 1.3305158615967196]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.388153570692533		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 2.388153570692533 | validation: 1.3460048912240727]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.426454001011218		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 2.426454001011218 | validation: 1.3285840227148515]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.490672317090391		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 2.490672317090391 | validation: 1.4833385125496403]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4123720092926195		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 2.4123720092926195 | validation: 1.354790754815788]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.500572257962265		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 2.500572257962265 | validation: 1.434180195346401]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4744521203900205		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 2.4744521203900205 | validation: 1.660464922493847]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5041295925933533		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 2.5041295925933533 | validation: 1.3854678133184897]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4476177610868426		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 2.4476177610868426 | validation: 1.306478466658939]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_540.pth
	Model improved!!!
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.461786512410952		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 2.461786512410952 | validation: 1.3534056519998496]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4113637133432757		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 2.4113637133432757 | validation: 1.6561713180666937]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.523870730598464		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 2.523870730598464 | validation: 1.495802425764637]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.503244489926442		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 2.503244489926442 | validation: 1.3584819306427232]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420254953212975		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 2.420254953212975 | validation: 1.3150246464656363]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4482381800519946		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 2.4482381800519946 | validation: 1.424904155922671]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4146701337313576		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 2.4146701337313576 | validation: 1.3753865948202342]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4726911187265315		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 2.4726911187265315 | validation: 1.339887812970718]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.374229378558467		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 2.374229378558467 | validation: 1.3662310290977187]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.405328137674129		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 2.405328137674129 | validation: 1.574567142794968]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.441799645027424		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 2.441799645027424 | validation: 1.3672667808678176]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37653709682099		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 2.37653709682099 | validation: 1.3581459034099583]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4054997009892176		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 2.4054997009892176 | validation: 1.5174691735176646]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4259705197652983		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 2.4259705197652983 | validation: 1.4591463786721885]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435883816762903		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 2.435883816762903 | validation: 1.3198906912397896]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.41803631526459		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 2.41803631526459 | validation: 1.4119176157520645]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4228338048727767		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 2.4228338048727767 | validation: 1.308258203489432]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375500845362985		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 2.375500845362985 | validation: 1.5841499541784918]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5273053777152468		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 2.5273053777152468 | validation: 1.3770704901780146]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.386041275152693		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 2.386041275152693 | validation: 1.2966261881504255]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4020184813607877		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 2.4020184813607877 | validation: 1.4299463585271832]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4362549955367294		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 2.4362549955367294 | validation: 1.331443418064951]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4457737911124404		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 2.4457737911124404 | validation: 1.3198750233645018]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3755227543440762		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 2.3755227543440762 | validation: 1.3027129506422233]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.438858693617026		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 2.438858693617026 | validation: 1.3561415286274427]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4231003144815406		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 2.4231003144815406 | validation: 1.3108553639523153]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4025882023383187		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 2.4025882023383187 | validation: 1.3957854357389874]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4429727635875165		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 2.4429727635875165 | validation: 1.3187798157887776]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.383879264811575		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 2.383879264811575 | validation: 1.2913124514534848]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_569.pth
	Model improved!!!
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4175733851462597		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 2.4175733851462597 | validation: 1.3028668683059499]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420381605110773		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 2.420381605110773 | validation: 1.3697818449062278]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4020865525634503		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 2.4020865525634503 | validation: 1.4155330167358107]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395331953871369		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 2.395331953871369 | validation: 1.3139721559393167]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3635307519308686		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 2.3635307519308686 | validation: 1.3423926637526886]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4066606317371106		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 2.4066606317371106 | validation: 1.3037066247621263]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4492499706688635		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 2.4492499706688635 | validation: 1.2914397733248857]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4071610335043996		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 2.4071610335043996 | validation: 1.367246487133661]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4295418330510965		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 2.4295418330510965 | validation: 1.3958500513173437]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4881130318270737		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 2.4881130318270737 | validation: 1.491460100831812]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4399514467945287		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 2.4399514467945287 | validation: 1.3302625611193926]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3593270889142404		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 2.3593270889142404 | validation: 1.3537619249419794]
	TIME [epoch: 11.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3633387646519353		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 2.3633387646519353 | validation: 1.5069543233887794]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4683015280780936		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 2.4683015280780936 | validation: 1.4285696653817597]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4340418606736867		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 2.4340418606736867 | validation: 1.3301179239815257]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.351598722782485		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 2.351598722782485 | validation: 1.3222710349827873]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.374624025157294		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 2.374624025157294 | validation: 1.3900420812007155]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.458956664517993		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 2.458956664517993 | validation: 1.3449347332759072]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3934735467845005		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 2.3934735467845005 | validation: 1.3839589764335836]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.391659577284602		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 2.391659577284602 | validation: 1.309407663531016]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3708464804465605		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 2.3708464804465605 | validation: 1.297468033422573]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4429112728216285		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 2.4429112728216285 | validation: 1.394739116756739]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4001910487693885		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 2.4001910487693885 | validation: 1.4820169011384525]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4154196742044913		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 2.4154196742044913 | validation: 1.31513408277239]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3877583090693335		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 2.3877583090693335 | validation: 1.3246182214589926]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.388255132698057		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 2.388255132698057 | validation: 1.2978849593422002]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3569427543916803		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 2.3569427543916803 | validation: 1.3041592367548174]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.446846292896122		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 2.446846292896122 | validation: 1.4507362714835241]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4712758657018212		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 2.4712758657018212 | validation: 1.3370651398689615]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3852395808747966		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 2.3852395808747966 | validation: 1.2751572169245695]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.40557211305357		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 2.40557211305357 | validation: 1.3406654228525596]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3638897555417255		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 2.3638897555417255 | validation: 1.2950875492756877]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.359639166600977		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 2.359639166600977 | validation: 1.2878927887921787]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3436375509810974		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 2.3436375509810974 | validation: 1.4046981743246254]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4118363814545734		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 2.4118363814545734 | validation: 1.3117790427368217]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3581854048448276		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 2.3581854048448276 | validation: 1.3043332318033054]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354801578874084		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 2.354801578874084 | validation: 1.3561317337596654]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.39744518936241		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 2.39744518936241 | validation: 1.3135655878875292]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416470730194389		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 2.416470730194389 | validation: 1.3438993485130766]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.376911040853279		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 2.376911040853279 | validation: 1.3155469474605486]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.490451086942087		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 2.490451086942087 | validation: 1.2883656734383153]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.36979178067843		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 2.36979178067843 | validation: 1.51459372586587]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4403362194593505		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 2.4403362194593505 | validation: 1.3730631099350625]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3792152593339617		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 2.3792152593339617 | validation: 1.3253824510512606]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340963946133455		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 2.340963946133455 | validation: 1.4270223770998056]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.383538617163011		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 2.383538617163011 | validation: 1.3156325225861225]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.367281491490524		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 2.367281491490524 | validation: 1.352866222579516]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.393975331843142		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 2.393975331843142 | validation: 1.306191050809953]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3843827278314893		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 2.3843827278314893 | validation: 1.3199470776425688]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3532319760559273		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 2.3532319760559273 | validation: 1.3360232742175668]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.486430011457213		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 2.486430011457213 | validation: 1.36240974321483]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3885116576003718		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 2.3885116576003718 | validation: 1.310889758572287]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3580857003297617		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 2.3580857003297617 | validation: 1.2983568168540705]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3817386751992204		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 2.3817386751992204 | validation: 1.3170982543248766]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.399198840143103		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 2.399198840143103 | validation: 1.2870196494012978]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4265522960927624		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 2.4265522960927624 | validation: 1.3859409775489393]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.38212501431843		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 2.38212501431843 | validation: 1.3083180799919183]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346855590837473		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 2.346855590837473 | validation: 1.2895813412768926]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3901486287125824		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 2.3901486287125824 | validation: 1.4467991561824065]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.392488084966091		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 2.392488084966091 | validation: 1.3182395303882717]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3755956895281973		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 2.3755956895281973 | validation: 1.3246210792401143]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350044460704099		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 2.350044460704099 | validation: 1.2682234604686258]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_631.pth
	Model improved!!!
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.404125234441258		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 2.404125234441258 | validation: 1.2779196584659436]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3941056358501855		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 2.3941056358501855 | validation: 1.3604355985816796]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3839290775865267		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 2.3839290775865267 | validation: 1.2818073787231714]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.385711124541807		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 2.385711124541807 | validation: 1.308226952087465]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3422434994322234		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 2.3422434994322234 | validation: 1.2990263958433514]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3545491027375376		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 2.3545491027375376 | validation: 1.3033962545996591]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3812353566515614		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 2.3812353566515614 | validation: 1.3346347300759709]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369888813985383		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 2.369888813985383 | validation: 1.2752880905431168]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3485841855151817		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 2.3485841855151817 | validation: 1.3171994155183615]
	TIME [epoch: 11.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3835686873040594		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 2.3835686873040594 | validation: 1.365285851248696]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4295397310230102		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 2.4295397310230102 | validation: 1.4792612346432394]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4032377525036		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 2.4032377525036 | validation: 1.2992524845917006]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368897533024686		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 2.368897533024686 | validation: 1.2701945822314153]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3196374032285654		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 2.3196374032285654 | validation: 1.3548804928705334]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4231596942397426		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 2.4231596942397426 | validation: 1.2782213342796949]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3582343130735848		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 2.3582343130735848 | validation: 1.4432198045777522]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4863946895088285		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 2.4863946895088285 | validation: 1.4997946116666954]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.376639718431903		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 2.376639718431903 | validation: 1.354795371335091]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.388580823546219		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 2.388580823546219 | validation: 1.39354097301041]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3796363524231836		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 2.3796363524231836 | validation: 1.4336435018629772]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3835157731781567		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 2.3835157731781567 | validation: 1.2780888337824143]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3310608698000435		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 2.3310608698000435 | validation: 1.2782016203714954]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346959085879144		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 2.346959085879144 | validation: 1.3323353048159998]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.367743531412424		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 2.367743531412424 | validation: 1.2774739112642153]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.356150960266935		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 2.356150960266935 | validation: 1.3151513766242706]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379467437883224		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 2.379467437883224 | validation: 1.2746685680058276]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3498148894926336		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 2.3498148894926336 | validation: 1.2759535234245971]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.348988800926427		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 2.348988800926427 | validation: 1.257948586360722]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_659.pth
	Model improved!!!
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335057690388181		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 2.335057690388181 | validation: 1.3990517731557879]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3650339597362793		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 2.3650339597362793 | validation: 1.2776402436719374]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3472386607756834		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 2.3472386607756834 | validation: 1.6214179390510544]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.487776516700412		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 2.487776516700412 | validation: 1.4422027205437216]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3603416665619483		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 2.3603416665619483 | validation: 1.2894972008147676]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3455678509364266		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 2.3455678509364266 | validation: 1.3548801475231362]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4077891476528026		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 2.4077891476528026 | validation: 1.2589687452901048]
	TIME [epoch: 11.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.370449028314592		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 2.370449028314592 | validation: 1.2798538867546037]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3457509653528		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 2.3457509653528 | validation: 1.3695085542253675]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4121189338386166		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 2.4121189338386166 | validation: 1.2923448912848994]
	TIME [epoch: 11.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3386569945863322		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 2.3386569945863322 | validation: 1.265934208769226]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3364611532447075		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 2.3364611532447075 | validation: 1.3163879135623808]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3577076450168875		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 2.3577076450168875 | validation: 1.2645754558377253]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.347711101982424		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 2.347711101982424 | validation: 1.2771177679893762]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4297258333103566		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 2.4297258333103566 | validation: 1.2633594884000305]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4071695968304896		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 2.4071695968304896 | validation: 1.2663399449796744]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3315789466745818		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 2.3315789466745818 | validation: 1.2695814306616309]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3444985915543297		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 2.3444985915543297 | validation: 1.2943205784060825]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358837997485057		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 2.358837997485057 | validation: 1.259632520307545]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3234983084975322		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 2.3234983084975322 | validation: 1.3116200327559786]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3871681164421537		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 2.3871681164421537 | validation: 1.2580217835626064]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3360662739255686		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 2.3360662739255686 | validation: 1.2966754183847347]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3546865098307252		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 2.3546865098307252 | validation: 1.2691077363638592]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315587108033778		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 2.315587108033778 | validation: 1.2531487942248363]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3957911408128356		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 2.3957911408128356 | validation: 1.3320868718768746]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.367394521694258		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 2.367394521694258 | validation: 1.3024659916099501]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3397079382933654		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 2.3397079382933654 | validation: 1.3101006019219363]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.327304171442215		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 2.327304171442215 | validation: 1.3709917168468808]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3585000630777877		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 2.3585000630777877 | validation: 1.2634097594640887]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.347576213448602		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 2.347576213448602 | validation: 1.2606895465061352]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3397891777901707		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 2.3397891777901707 | validation: 1.3355101033969001]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3314333930811073		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 2.3314333930811073 | validation: 1.301290392556579]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3298394963522795		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 2.3298394963522795 | validation: 1.294441444348711]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.377644984109184		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 2.377644984109184 | validation: 1.2789091474999876]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4591490955566773		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 2.4591490955566773 | validation: 1.303313067950837]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3250953859024692		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 2.3250953859024692 | validation: 1.2806292969094406]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375568755230875		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 2.375568755230875 | validation: 1.337807358711295]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3238839764321924		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 2.3238839764321924 | validation: 1.2759673748810554]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323501907714901		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 2.323501907714901 | validation: 1.3042471340514312]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3510159162242203		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 2.3510159162242203 | validation: 1.3938300578421126]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.390228938105119		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 2.390228938105119 | validation: 1.3651639057885712]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.412226671667593		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 2.412226671667593 | validation: 1.2859090044232881]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335422877922231		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 2.335422877922231 | validation: 1.2828712477844864]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3510663605409907		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 2.3510663605409907 | validation: 1.3406690866576372]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395435313636208		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 2.395435313636208 | validation: 1.4444081812629992]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.407949276489837		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 2.407949276489837 | validation: 1.3166556514777685]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.349281789697201		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 2.349281789697201 | validation: 1.2804511246966575]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3146752871069474		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 2.3146752871069474 | validation: 1.2750503282793821]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31352105095384		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 2.31352105095384 | validation: 1.2803814585096853]
	TIME [epoch: 11.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3331246208361485		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 2.3331246208361485 | validation: 1.2700107673140528]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309151488814969		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 2.309151488814969 | validation: 1.2742269583210981]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3333510023317094		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 2.3333510023317094 | validation: 1.3537816505651958]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3507250975096468		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 2.3507250975096468 | validation: 1.241484298782854]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_712.pth
	Model improved!!!
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300620689955237		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 2.300620689955237 | validation: 1.29597223101032]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.329678752257456		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 2.329678752257456 | validation: 1.2707959378344869]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.347004915756597		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 2.347004915756597 | validation: 1.2513274515712618]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311839329895406		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 2.311839329895406 | validation: 1.2602755382596385]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.334029789607311		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 2.334029789607311 | validation: 1.2526372634920906]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3282007120932886		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 2.3282007120932886 | validation: 1.3557137878467922]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3475456003722224		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 2.3475456003722224 | validation: 1.2758231423633806]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308638657246866		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 2.308638657246866 | validation: 1.3640841854925332]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420799730865019		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 2.420799730865019 | validation: 1.2474255849395892]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3450363687449842		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 2.3450363687449842 | validation: 1.2818568858644925]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3286561864524042		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 2.3286561864524042 | validation: 1.2823002945276671]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3388921569146865		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 2.3388921569146865 | validation: 1.2395868640249246]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_724.pth
	Model improved!!!
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.331945152650409		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 2.331945152650409 | validation: 1.2864790786250877]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3483473549391283		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 2.3483473549391283 | validation: 1.2403342344863193]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32435419817964		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 2.32435419817964 | validation: 1.3747159839180092]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3391519610399163		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 2.3391519610399163 | validation: 1.288754173667995]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3255735835235614		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 2.3255735835235614 | validation: 1.2689311458049537]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3382434211643783		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 2.3382434211643783 | validation: 1.266581147525599]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3240759196159466		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 2.3240759196159466 | validation: 1.3083693598305115]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3424158221463456		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 2.3424158221463456 | validation: 1.285177751796475]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3467480425807197		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 2.3467480425807197 | validation: 1.3095268606049089]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3195069993964457		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 2.3195069993964457 | validation: 1.2358401448284115]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3025240100645323		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 2.3025240100645323 | validation: 1.2701629101032217]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3223586969133363		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 2.3223586969133363 | validation: 1.2440766132077763]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3255414574868167		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 2.3255414574868167 | validation: 1.2941037076676518]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344162361374914		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 2.344162361374914 | validation: 1.3760150660922572]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3359774028681177		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 2.3359774028681177 | validation: 1.2790353000381962]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.319762359393703		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 2.319762359393703 | validation: 1.319577587726568]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3166406526656047		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 2.3166406526656047 | validation: 1.3156221900830178]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31483218358506		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 2.31483218358506 | validation: 1.2848842500295572]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4416812445043456		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 2.4416812445043456 | validation: 1.3312536704780433]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.39656896392677		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 2.39656896392677 | validation: 1.4068741370453064]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3840836887304473		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 2.3840836887304473 | validation: 1.469672367216196]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3977709565534817		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 2.3977709565534817 | validation: 1.3722373154724539]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3650427912647163		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 2.3650427912647163 | validation: 1.2447318774245586]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3036981658728246		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 2.3036981658728246 | validation: 1.2476956282184362]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3016195866805327		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 2.3016195866805327 | validation: 1.2434313361645881]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3245534394063965		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 2.3245534394063965 | validation: 1.3243120772913477]
	TIME [epoch: 11.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3749619874734256		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 2.3749619874734256 | validation: 1.3857738722040416]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340838615192074		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 2.340838615192074 | validation: 1.2392629084675533]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310073883033371		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 2.310073883033371 | validation: 1.294117445455272]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.356841622661233		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 2.356841622661233 | validation: 1.322232695626393]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3194424990582947		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 2.3194424990582947 | validation: 1.2789396933968369]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307111631624039		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 2.307111631624039 | validation: 1.2459275452038412]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300045362363882		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 2.300045362363882 | validation: 1.2741789706974311]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317164409475253		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 2.317164409475253 | validation: 1.2521230886923278]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.352123979227258		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 2.352123979227258 | validation: 1.3538626758141634]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322613989699943		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 2.322613989699943 | validation: 1.241455479386558]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30023286522139		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 2.30023286522139 | validation: 1.2588963253248897]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3539335503504586		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 2.3539335503504586 | validation: 1.2553270747621408]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325122062335361		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 2.325122062335361 | validation: 1.2474671108330235]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3023018736110865		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 2.3023018736110865 | validation: 1.2352528364016198]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_764.pth
	Model improved!!!
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313045622946408		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 2.313045622946408 | validation: 1.2848133749665656]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323244239780656		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 2.323244239780656 | validation: 1.2521171107159759]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3478794300268575		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 2.3478794300268575 | validation: 1.2699981812424617]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3050835226711768		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 2.3050835226711768 | validation: 1.2679211308448695]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323299299719803		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 2.323299299719803 | validation: 1.2344795045932868]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3079043234738137		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 2.3079043234738137 | validation: 1.2486551563585078]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.316175205181012		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 2.316175205181012 | validation: 1.2259838657025979]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_771.pth
	Model improved!!!
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3902132683364887		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 2.3902132683364887 | validation: 1.2834533693495493]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321937001406661		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 2.321937001406661 | validation: 1.2413861035422533]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2984013727767096		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 2.2984013727767096 | validation: 1.2768526812492713]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310229207977379		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 2.310229207977379 | validation: 1.252219969992321]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344777760134881		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 2.344777760134881 | validation: 1.325953722656376]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335688921768263		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 2.335688921768263 | validation: 1.237953692531516]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3110654592533075		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 2.3110654592533075 | validation: 1.2493761020984508]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3095573944978844		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 2.3095573944978844 | validation: 1.2496418668323421]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3269508220633917		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 2.3269508220633917 | validation: 1.231479104405393]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307085560463575		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 2.307085560463575 | validation: 1.2670619710729207]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32260989593858		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 2.32260989593858 | validation: 1.2683353269440834]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328645827047699		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 2.328645827047699 | validation: 1.2364898322908127]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296929337822432		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 2.296929337822432 | validation: 1.2522313348252745]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304488765807935		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 2.304488765807935 | validation: 1.2846929305013324]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3143680371305733		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 2.3143680371305733 | validation: 1.2399718880115456]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312149175347944		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 2.312149175347944 | validation: 1.2668376905965884]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2987148793688257		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 2.2987148793688257 | validation: 1.2908128146426356]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3033687380262844		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 2.3033687380262844 | validation: 1.2812094155862903]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3187818426197313		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 2.3187818426197313 | validation: 1.4862318618973387]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3956905393728456		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 2.3956905393728456 | validation: 1.2297347508886924]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293917715864629		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 2.293917715864629 | validation: 1.261518683355936]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3013793806697596		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 2.3013793806697596 | validation: 1.3348836710788934]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.341283968188934		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 2.341283968188934 | validation: 1.2483230666272664]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3328999376008817		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 2.3328999376008817 | validation: 1.233186791515206]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295843226308284		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 2.295843226308284 | validation: 1.2642986174486381]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2912429222771094		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 2.2912429222771094 | validation: 1.2332025760138592]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302439161733668		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 2.302439161733668 | validation: 1.298203606094629]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.332691017239772		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 2.332691017239772 | validation: 1.2563004539396156]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3098833668395136		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 2.3098833668395136 | validation: 1.2673068347254606]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3327206718953315		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 2.3327206718953315 | validation: 1.2628360985228961]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3308420220529156		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 2.3308420220529156 | validation: 1.2588185211242031]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288582220828656		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 2.288582220828656 | validation: 1.2588273431290278]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294994665832584		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 2.294994665832584 | validation: 1.2924723627325756]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3293305763089434		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 2.3293305763089434 | validation: 1.3087542667880012]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306385199392004		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 2.306385199392004 | validation: 1.2339774329637003]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3351566987978494		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 2.3351566987978494 | validation: 1.3130674494871197]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314084149559563		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 2.314084149559563 | validation: 1.2378198322122014]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2992784692293764		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 2.2992784692293764 | validation: 1.3021419350506447]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3072080317849433		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 2.3072080317849433 | validation: 1.281305778818509]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305789063778948		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 2.305789063778948 | validation: 1.2910296464101014]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3590312631832893		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 2.3590312631832893 | validation: 1.331342859868617]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3243506472829063		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 2.3243506472829063 | validation: 1.226923980018011]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281283071919461		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 2.281283071919461 | validation: 1.256128523937968]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3001122356335104		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 2.3001122356335104 | validation: 1.2252580228045904]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_815.pth
	Model improved!!!
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2759977762252634		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 2.2759977762252634 | validation: 1.2483940805699079]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291285013798567		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 2.291285013798567 | validation: 1.273575184803751]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2920661132343096		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 2.2920661132343096 | validation: 1.217691887368024]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2911639048079455		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 2.2911639048079455 | validation: 1.238143152759996]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2986523009156867		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 2.2986523009156867 | validation: 1.2778491412307336]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3075015286642877		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 2.3075015286642877 | validation: 1.2396395302727015]
	TIME [epoch: 11.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2966682120323845		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 2.2966682120323845 | validation: 1.2351257765242751]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2851985065563953		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 2.2851985065563953 | validation: 1.2545866831051258]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2884396701408183		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 2.2884396701408183 | validation: 1.2605755164374381]
	TIME [epoch: 11.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305869220143974		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 2.305869220143974 | validation: 1.2812966186583146]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2976432399152578		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 2.2976432399152578 | validation: 1.2523896149372076]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2909720487381513		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 2.2909720487381513 | validation: 1.2274879279688966]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.283459422443072		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 2.283459422443072 | validation: 1.2378207404589172]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302531207029338		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 2.302531207029338 | validation: 1.2205479811859459]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298070990290217		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 2.298070990290217 | validation: 1.2403716715082411]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302888520773047		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 2.302888520773047 | validation: 1.2694876899309901]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3025037829501165		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 2.3025037829501165 | validation: 1.225608053389731]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3148851660489447		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 2.3148851660489447 | validation: 1.2742830537481427]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3051935674604698		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 2.3051935674604698 | validation: 1.2553978951342541]
	TIME [epoch: 11.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2873294654177077		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 2.2873294654177077 | validation: 1.232718064417997]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282789124418766		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 2.282789124418766 | validation: 1.2515710712787533]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3006586122357007		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 2.3006586122357007 | validation: 1.2234149623063957]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2850462197040127		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 2.2850462197040127 | validation: 1.2648539950679354]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3064378789734477		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 2.3064378789734477 | validation: 1.2201183664749078]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301989315836602		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 2.301989315836602 | validation: 1.2220356128259309]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309238533647345		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 2.309238533647345 | validation: 1.2764687545309965]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301087014589906		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 2.301087014589906 | validation: 1.3390002201801883]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308391092704707		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 2.308391092704707 | validation: 1.2347716801668096]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284161180490577		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 2.284161180490577 | validation: 1.2601460804448854]
	TIME [epoch: 11.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284690530703675		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 2.284690530703675 | validation: 1.2326728275080097]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3111123121377863		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 2.3111123121377863 | validation: 1.2842135104508139]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301184880524392		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 2.301184880524392 | validation: 1.2572531346345424]
	TIME [epoch: 11.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.342077732144725		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 2.342077732144725 | validation: 1.3014451104648654]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3200357795923985		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 2.3200357795923985 | validation: 1.2427955691782928]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304669384958901		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 2.304669384958901 | validation: 1.2779450991086108]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298241135933095		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 2.298241135933095 | validation: 1.257489285407705]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2979259441107143		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 2.2979259441107143 | validation: 1.3113524324600345]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32068582499729		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 2.32068582499729 | validation: 1.2675453803778443]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310118364806011		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 2.310118364806011 | validation: 1.223346841205386]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2826689363183754		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 2.2826689363183754 | validation: 1.2247002913320924]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2854563946223014		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 2.2854563946223014 | validation: 1.2620376840908107]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3087757327787006		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 2.3087757327787006 | validation: 1.3823994989526267]
	TIME [epoch: 11.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3352957059506902		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 2.3352957059506902 | validation: 1.2458548272879304]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3025420323731947		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 2.3025420323731947 | validation: 1.2474648574564906]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288535629154147		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 2.288535629154147 | validation: 1.2476259866263604]
	TIME [epoch: 11.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2929478326528416		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 2.2929478326528416 | validation: 1.2752718681679052]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3319639092061806		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 2.3319639092061806 | validation: 1.2134429253490664]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_862.pth
	Model improved!!!
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2946842718069678		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 2.2946842718069678 | validation: 1.2422049546740115]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2763087004687526		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 2.2763087004687526 | validation: 1.229409340548454]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27692278005199		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 2.27692278005199 | validation: 1.22618448304095]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2745459481635084		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 2.2745459481635084 | validation: 1.234160658083337]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2813561244019143		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 2.2813561244019143 | validation: 1.268726831422063]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2929691310299445		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 2.2929691310299445 | validation: 1.2136089597045838]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2913632244692375		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 2.2913632244692375 | validation: 1.2417683940307642]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32502712558737		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 2.32502712558737 | validation: 1.2075553976507056]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_870.pth
	Model improved!!!
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2886569646857664		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 2.2886569646857664 | validation: 1.2163040664160374]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3172080382939155		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 2.3172080382939155 | validation: 1.218103537719957]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2863193214859137		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 2.2863193214859137 | validation: 1.2471525927918747]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3121755774178903		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 2.3121755774178903 | validation: 1.2484381080135156]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321271251722329		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 2.321271251722329 | validation: 1.220657351660421]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282178537319025		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 2.282178537319025 | validation: 1.2599708017692037]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311628860708368		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 2.311628860708368 | validation: 1.235678390453982]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290628493691831		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 2.290628493691831 | validation: 1.2373160497473514]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3140406832226077		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 2.3140406832226077 | validation: 1.2894363688364712]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303578539187645		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 2.303578539187645 | validation: 1.22844697469531]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2756268246816447		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 2.2756268246816447 | validation: 1.2198633908781513]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2823469358908812		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 2.2823469358908812 | validation: 1.2524921177911998]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298161202186861		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 2.298161202186861 | validation: 1.2324237839536867]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3526500228003657		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 2.3526500228003657 | validation: 1.2702824990683186]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29503667752327		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 2.29503667752327 | validation: 1.226563318032736]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295972418543294		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 2.295972418543294 | validation: 1.2737443606999237]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3040212206673263		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 2.3040212206673263 | validation: 1.2511296585131522]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2955717427254756		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 2.2955717427254756 | validation: 1.2272631055545606]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2815750862490587		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 2.2815750862490587 | validation: 1.2194318397649797]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300936210741808		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 2.300936210741808 | validation: 1.2282622382488513]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288724601896336		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 2.288724601896336 | validation: 1.2165837953741772]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2812743117798995		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 2.2812743117798995 | validation: 1.2714537697538295]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293354074358599		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 2.293354074358599 | validation: 1.2115274368145206]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3245258654236878		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 2.3245258654236878 | validation: 1.2136104600740718]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289087765935788		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 2.289087765935788 | validation: 1.2363923913364394]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297423824077014		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 2.297423824077014 | validation: 1.226105886453626]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27031191804742		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 2.27031191804742 | validation: 1.285114028145191]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2964621244029266		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 2.2964621244029266 | validation: 1.2499400397579894]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306604971095441		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 2.306604971095441 | validation: 1.2722200636559517]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29429196750777		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 2.29429196750777 | validation: 1.2347417282490116]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296581973886206		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 2.296581973886206 | validation: 1.2728935219424153]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287120941502256		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 2.287120941502256 | validation: 1.225214735369419]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2715539410876078		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 2.2715539410876078 | validation: 1.2320027824048905]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275429003680066		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 2.275429003680066 | validation: 1.2125485161944807]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2950913278206837		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 2.2950913278206837 | validation: 1.2971743127564248]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3028955337155823		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 2.3028955337155823 | validation: 1.2272408180250247]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284273274396266		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 2.284273274396266 | validation: 1.2293537112062165]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287439150164291		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 2.287439150164291 | validation: 1.2259733790621203]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288105053003785		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 2.288105053003785 | validation: 1.2718612883517215]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3256216982565023		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 2.3256216982565023 | validation: 1.2266432837718468]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2937011449735		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 2.2937011449735 | validation: 1.2433061968736763]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3007806271681064		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 2.3007806271681064 | validation: 1.2320377072828452]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311288059877607		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 2.311288059877607 | validation: 1.2382862509313521]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2936145068772524		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 2.2936145068772524 | validation: 1.222238838270205]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2938800089952256		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 2.2938800089952256 | validation: 1.23032274093358]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281348538437304		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 2.281348538437304 | validation: 1.2197901353968852]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310465597497128		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 2.310465597497128 | validation: 1.243652254041695]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27813613912776		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 2.27813613912776 | validation: 1.2315189328351652]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290694085252678		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 2.290694085252678 | validation: 1.2754468826187333]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289490946518999		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 2.289490946518999 | validation: 1.220415364115098]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291789327763091		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 2.291789327763091 | validation: 1.2617924990123135]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3423242208908364		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 2.3423242208908364 | validation: 1.2205895993940024]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282133611047228		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 2.282133611047228 | validation: 1.2335006727606892]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276418687598392		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 2.276418687598392 | validation: 1.2179244688540594]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272947094541189		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 2.272947094541189 | validation: 1.2178104003119927]
	TIME [epoch: 11.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2714737126309217		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 2.2714737126309217 | validation: 1.212090246252987]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276728494148634		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 2.276728494148634 | validation: 1.2171530644023707]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269994679802958		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 2.269994679802958 | validation: 1.2433044263933257]
	TIME [epoch: 11.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295597546970963		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 2.295597546970963 | validation: 1.287603370684665]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307227762747636		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 2.307227762747636 | validation: 1.2171254424187834]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3209272238617826		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 2.3209272238617826 | validation: 1.3263064967294458]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306484771183922		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 2.306484771183922 | validation: 1.2262541529047577]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2726819549256434		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 2.2726819549256434 | validation: 1.2636371035622829]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299688976787701		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 2.299688976787701 | validation: 1.2592799926713452]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298709906034449		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 2.298709906034449 | validation: 1.264472723087146]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2864727195419454		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 2.2864727195419454 | validation: 1.2544826519373664]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287018107160656		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 2.287018107160656 | validation: 1.2144809465004263]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2751378732582594		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 2.2751378732582594 | validation: 1.2588533486121338]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3001665492026477		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 2.3001665492026477 | validation: 1.217230780918516]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3122331494290775		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 2.3122331494290775 | validation: 1.253752107021436]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28368806552771		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 2.28368806552771 | validation: 1.2176490502424604]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2800199056357715		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 2.2800199056357715 | validation: 1.2083313010606207]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282376040054883		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 2.282376040054883 | validation: 1.2406999015892175]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2906357165620466		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 2.2906357165620466 | validation: 1.2151435398378996]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290334398687833		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 2.290334398687833 | validation: 1.230204279794473]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276641052810643		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 2.276641052810643 | validation: 1.2375599074804071]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30630739095844		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 2.30630739095844 | validation: 1.2625669312756589]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290963452786267		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 2.290963452786267 | validation: 1.2510110571769233]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277194254883651		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 2.277194254883651 | validation: 1.234729842902048]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29370500800346		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 2.29370500800346 | validation: 1.2889228703728923]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3029759144378197		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 2.3029759144378197 | validation: 1.2190291556758295]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280126447814336		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 2.280126447814336 | validation: 1.2443163712787937]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303752591375096		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 2.303752591375096 | validation: 1.2400533589171108]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.271253923814811		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 2.271253923814811 | validation: 1.2338980755726394]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287304506435636		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 2.287304506435636 | validation: 1.234603731620806]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298658721449453		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 2.298658721449453 | validation: 1.2127061758863673]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2730226374688005		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 2.2730226374688005 | validation: 1.217629773901944]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270133041060257		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 2.270133041060257 | validation: 1.2628926244017114]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280330379464168		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 2.280330379464168 | validation: 1.2396189062157565]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306412686207512		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 2.306412686207512 | validation: 1.274702696115872]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300822613702638		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 2.300822613702638 | validation: 1.2550882465474438]
	TIME [epoch: 11.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2896003353657		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 2.2896003353657 | validation: 1.2247005054086184]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301519324757167		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 2.301519324757167 | validation: 1.2262401132114809]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28025325242899		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 2.28025325242899 | validation: 1.252152685716438]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281797772460694		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 2.281797772460694 | validation: 1.2061398572955155]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_965.pth
	Model improved!!!
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2686361662157033		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 2.2686361662157033 | validation: 1.247357030052107]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282186557527124		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 2.282186557527124 | validation: 1.239827411676392]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290381398709804		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 2.290381398709804 | validation: 1.2156052753573325]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267955676541823		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 2.267955676541823 | validation: 1.2090977960477036]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289938193344242		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 2.289938193344242 | validation: 1.2534164934992467]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2826213184758872		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 2.2826213184758872 | validation: 1.289494713285481]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3226193726394664		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 2.3226193726394664 | validation: 1.2557969093546242]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2796490233885685		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 2.2796490233885685 | validation: 1.2554246565564897]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2873811422230994		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 2.2873811422230994 | validation: 1.2332446283508973]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2701338817962577		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 2.2701338817962577 | validation: 1.2127486542442762]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270195427207617		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 2.270195427207617 | validation: 1.241680288603825]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2887039747909914		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 2.2887039747909914 | validation: 1.239581999445271]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2749465349276834		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 2.2749465349276834 | validation: 1.2325352586418454]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298683751513858		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 2.298683751513858 | validation: 1.2165474277358619]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269048416314301		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 2.269048416314301 | validation: 1.2334375346053705]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2827897074673493		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 2.2827897074673493 | validation: 1.227137873056792]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278598385599599		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 2.278598385599599 | validation: 1.218279305994559]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293127167812773		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 2.293127167812773 | validation: 1.2450389422831671]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2858567382728006		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 2.2858567382728006 | validation: 1.2149607169908563]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276574870117607		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 2.276574870117607 | validation: 1.2506650776178319]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279405450940931		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 2.279405450940931 | validation: 1.282799078276985]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.38426037117044		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 2.38426037117044 | validation: 1.2768111612901236]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2821081184755005		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 2.2821081184755005 | validation: 1.2428530609787296]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2862345358281884		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 2.2862345358281884 | validation: 1.2222925594035225]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2710046172406924		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 2.2710046172406924 | validation: 1.243647440457605]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3111593587732746		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 2.3111593587732746 | validation: 1.2314903642502701]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.283305932449823		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 2.283305932449823 | validation: 1.2269294395990082]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268991236295404		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 2.268991236295404 | validation: 1.214108731817762]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268323419362352		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 2.268323419362352 | validation: 1.2727107097953256]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3110455842917568		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 2.3110455842917568 | validation: 1.2142287686523863]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2769310119708184		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 2.2769310119708184 | validation: 1.2494615075205247]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2999623466092958		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 2.2999623466092958 | validation: 1.2515747872532899]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2743204443856038		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 2.2743204443856038 | validation: 1.2082390698549323]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269926387526298		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 2.269926387526298 | validation: 1.2111369163945378]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2633163936230463		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 2.2633163936230463 | validation: 1.2282964669726533]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2771235994879966		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 2.2771235994879966 | validation: 1.2387100098914323]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2820709388860605		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 2.2820709388860605 | validation: 1.3184996531445887]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328723907118156		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 2.328723907118156 | validation: 1.230661110236944]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2876070529358836		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 2.2876070529358836 | validation: 1.214959963123653]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281010509857843		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 2.281010509857843 | validation: 1.229596441912128]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306393024402505		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 2.306393024402505 | validation: 1.2275413357597167]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27424114259696		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 2.27424114259696 | validation: 1.2264007819592215]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2861526382658552		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 2.2861526382658552 | validation: 1.2215603059425086]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2698206505934975		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 2.2698206505934975 | validation: 1.2116830477578608]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2849090594646957		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 2.2849090594646957 | validation: 1.2280874036176601]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2783523782679698		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 2.2783523782679698 | validation: 1.2481736937384154]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2879017423376915		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 2.2879017423376915 | validation: 1.2265423856458972]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288100290527596		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 2.288100290527596 | validation: 1.2315891214290386]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275690460323022		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 2.275690460323022 | validation: 1.2748014595579609]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303406444576649		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 2.303406444576649 | validation: 1.2330224729314752]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2704852342804696		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 2.2704852342804696 | validation: 1.2134178124433392]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2809833044476306		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 2.2809833044476306 | validation: 1.2212971596572317]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2720546313509753		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 2.2720546313509753 | validation: 1.2290323446000542]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27612818215197		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 2.27612818215197 | validation: 1.229101096406824]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286444397079702		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 2.286444397079702 | validation: 1.2545325375297636]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2728237530078563		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 2.2728237530078563 | validation: 1.2115046144729766]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2874324912242545		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 2.2874324912242545 | validation: 1.2400415641465836]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2673791288460907		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 2.2673791288460907 | validation: 1.2103693518061822]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2713345722503737		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 2.2713345722503737 | validation: 1.2225470958174376]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2738109375868465		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 2.2738109375868465 | validation: 1.2063771558850895]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273325580602902		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 2.273325580602902 | validation: 1.221882323706712]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2746942980324967		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 2.2746942980324967 | validation: 1.2192519229299703]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2680433685704067		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 2.2680433685704067 | validation: 1.2081723301956298]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2719317506441863		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 2.2719317506441863 | validation: 1.2228256511951887]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2728652481122644		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 2.2728652481122644 | validation: 1.2113699032277865]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265294828703227		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 2.265294828703227 | validation: 1.2069044084215326]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2650248518188016		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 2.2650248518188016 | validation: 1.213068160632262]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2848452325235504		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 2.2848452325235504 | validation: 1.212642008199339]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266043631999964		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 2.266043631999964 | validation: 1.227181344074588]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2712939752096535		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 2.2712939752096535 | validation: 1.2021193003822717]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1035.pth
	Model improved!!!
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277131432993574		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 2.277131432993574 | validation: 1.201983025682782]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1036.pth
	Model improved!!!
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2745856642054223		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 2.2745856642054223 | validation: 1.2277555560700324]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2750351572925416		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 2.2750351572925416 | validation: 1.2171727495822853]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265807080442114		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 2.265807080442114 | validation: 1.2222819312377415]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2777336525162193		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 2.2777336525162193 | validation: 1.2449446679584206]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2842715036003183		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 2.2842715036003183 | validation: 1.247485397873678]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2845931399558954		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 2.2845931399558954 | validation: 1.2165103849863583]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2664258710749907		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 2.2664258710749907 | validation: 1.2237312124928728]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270732410865178		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 2.270732410865178 | validation: 1.2164591315033066]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275904666215963		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 2.275904666215963 | validation: 1.2239820141823552]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268295005230662		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 2.268295005230662 | validation: 1.21722343510287]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285558788937069		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 2.285558788937069 | validation: 1.2162165783073446]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2687359776234537		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 2.2687359776234537 | validation: 1.21009764743306]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2630879299053346		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 2.2630879299053346 | validation: 1.2142656017983264]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264891486949132		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 2.264891486949132 | validation: 1.2046046150822132]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284007565478656		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 2.284007565478656 | validation: 1.2088049555203577]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27156317147164		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 2.27156317147164 | validation: 1.2032580893404994]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2652986363365804		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 2.2652986363365804 | validation: 1.2067298254298648]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2639905365731963		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 2.2639905365731963 | validation: 1.2035588972912359]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270338274006384		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 2.270338274006384 | validation: 1.2179736278503552]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280008960337563		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 2.280008960337563 | validation: 1.2174508785480964]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294022488257254		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 2.294022488257254 | validation: 1.2369987399748177]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278816136215122		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 2.278816136215122 | validation: 1.227641472371648]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272316143882629		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 2.272316143882629 | validation: 1.2018521863575342]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1059.pth
	Model improved!!!
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274618612026937		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 2.274618612026937 | validation: 1.2597567009029453]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2744660681882474		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 2.2744660681882474 | validation: 1.211209189863242]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2661391416885275		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 2.2661391416885275 | validation: 1.2073548215326322]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261182778754745		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 2.261182778754745 | validation: 1.1992228919081094]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1063.pth
	Model improved!!!
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267684034862835		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 2.267684034862835 | validation: 1.2328444230760436]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2816957883304716		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 2.2816957883304716 | validation: 1.2206492365815205]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2642974914823206		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 2.2642974914823206 | validation: 1.2227630760858108]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2742107452947806		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 2.2742107452947806 | validation: 1.2456619725831604]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2854058830995925		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 2.2854058830995925 | validation: 1.227691612108786]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2750631733063607		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 2.2750631733063607 | validation: 1.218967444137943]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264014919939581		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 2.264014919939581 | validation: 1.218800720934372]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278388970797475		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 2.278388970797475 | validation: 1.2120172641804876]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2727736186098193		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 2.2727736186098193 | validation: 1.2113783582635986]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2615761482141195		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 2.2615761482141195 | validation: 1.2462808240528436]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289824552666679		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 2.289824552666679 | validation: 1.2068847895963757]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280084047905582		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 2.280084047905582 | validation: 1.2099299091432554]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2623498904787267		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 2.2623498904787267 | validation: 1.2077560750505238]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2601935058253293		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 2.2601935058253293 | validation: 1.2052521831726308]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2662650241450897		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 2.2662650241450897 | validation: 1.2193776654465598]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270574310983961		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 2.270574310983961 | validation: 1.2139809660308813]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2662387231342422		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 2.2662387231342422 | validation: 1.2014421166183242]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.271631291688257		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 2.271631291688257 | validation: 1.2202505303298612]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2654364187348035		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 2.2654364187348035 | validation: 1.2127383254653024]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2694502524393556		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 2.2694502524393556 | validation: 1.2224069600380782]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3025286340097173		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 2.3025286340097173 | validation: 1.2149559612241194]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2714209611256564		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 2.2714209611256564 | validation: 1.2305855808117216]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2733974193764968		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 2.2733974193764968 | validation: 1.2287709662942357]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2722067039790494		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 2.2722067039790494 | validation: 1.203423487808373]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2595539038833907		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 2.2595539038833907 | validation: 1.2295764246232144]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2643846897880655		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 2.2643846897880655 | validation: 1.2064283739984805]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266344570463581		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 2.266344570463581 | validation: 1.2199941654117952]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2604211950278756		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 2.2604211950278756 | validation: 1.2152230594673479]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2794313191444058		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 2.2794313191444058 | validation: 1.2528958656546114]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3012752169599398		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 2.3012752169599398 | validation: 1.2576544215385344]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2786039042002715		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 2.2786039042002715 | validation: 1.2151539124550856]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276415287682304		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 2.276415287682304 | validation: 1.214586296303329]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2736783424652254		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 2.2736783424652254 | validation: 1.2375663155957584]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2655866829287237		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 2.2655866829287237 | validation: 1.2026346170570787]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262430336154339		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 2.262430336154339 | validation: 1.208705104116695]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264632117824363		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 2.264632117824363 | validation: 1.205180006524766]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269584311427293		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 2.269584311427293 | validation: 1.2463761594792155]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2720044109010815		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 2.2720044109010815 | validation: 1.207565750997826]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2685014762752704		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 2.2685014762752704 | validation: 1.2088524262896827]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2631922252290217		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 2.2631922252290217 | validation: 1.193675417181053]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1103.pth
	Model improved!!!
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273695057229107		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 2.273695057229107 | validation: 1.2143491173769814]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2692370018543637		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 2.2692370018543637 | validation: 1.205617557550301]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265165738924207		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 2.265165738924207 | validation: 1.2319689233097595]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270818596108627		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 2.270818596108627 | validation: 1.2076406132333897]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2713338822317066		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 2.2713338822317066 | validation: 1.2321484151809934]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2615130779941244		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 2.2615130779941244 | validation: 1.1994738097133852]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274478561652892		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 2.274478561652892 | validation: 1.1961549332901629]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2606367679220405		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 2.2606367679220405 | validation: 1.2284694066129507]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264537926712443		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 2.264537926712443 | validation: 1.2102013699943133]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274444269358837		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 2.274444269358837 | validation: 1.227551549779142]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289308098291139		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 2.289308098291139 | validation: 1.2101365710519647]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2616868811261917		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 2.2616868811261917 | validation: 1.2229820442838075]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2875001413325844		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 2.2875001413325844 | validation: 1.2261737155609729]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262505211367262		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 2.262505211367262 | validation: 1.203274977458646]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261853048724669		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 2.261853048724669 | validation: 1.2053328844915325]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2567674907909905		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 2.2567674907909905 | validation: 1.2121553154442735]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26155015702842		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 2.26155015702842 | validation: 1.2011581492367693]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263507651643497		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 2.263507651643497 | validation: 1.1997107369364235]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268289395266887		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 2.268289395266887 | validation: 1.237143132793923]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293274961367687		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 2.293274961367687 | validation: 1.2334641633319188]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258531025379077		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 2.258531025379077 | validation: 1.205137566220891]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.259131327268573		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 2.259131327268573 | validation: 1.2043963441746068]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2861251627485855		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 2.2861251627485855 | validation: 1.2223901478369943]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2718564769569407		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 2.2718564769569407 | validation: 1.2093377691842826]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262687764118916		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 2.262687764118916 | validation: 1.2059195142195525]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2631022831410523		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 2.2631022831410523 | validation: 1.2088933435652753]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2713153999972175		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 2.2713153999972175 | validation: 1.2160534887502075]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2612372025567713		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 2.2612372025567713 | validation: 1.2028119714569794]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2626890267105275		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 2.2626890267105275 | validation: 1.2079072408377205]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2547911352810006		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 2.2547911352810006 | validation: 1.2063192099524616]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260717855096687		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 2.260717855096687 | validation: 1.207155386795435]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260689889798409		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 2.260689889798409 | validation: 1.2148604983236713]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2657833556720965		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 2.2657833556720965 | validation: 1.2028658607947587]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262363617511648		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 2.262363617511648 | validation: 1.208651352523958]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2634707102070415		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 2.2634707102070415 | validation: 1.2011553436187106]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265601798514495		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 2.265601798514495 | validation: 1.2211237706138254]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267803030598811		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 2.267803030598811 | validation: 1.211719449183711]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2649938139893		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 2.2649938139893 | validation: 1.2136317325349668]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261534527598597		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 2.261534527598597 | validation: 1.2019005570590158]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2545732850404763		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 2.2545732850404763 | validation: 1.2170863479487761]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2615579494530733		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 2.2615579494530733 | validation: 1.1990633068320378]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2587819079323674		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 2.2587819079323674 | validation: 1.208839267266869]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277088820752791		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 2.277088820752791 | validation: 1.208705577055523]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2537548941190018		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 2.2537548941190018 | validation: 1.1940309540812937]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.270829110178156		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 2.270829110178156 | validation: 1.2109920365066806]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2610540228561207		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 2.2610540228561207 | validation: 1.1917267666711562]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1149.pth
	Model improved!!!
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254650871053582		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 2.254650871053582 | validation: 1.20527123565451]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2661313997001713		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 2.2661313997001713 | validation: 1.2130830732262519]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2657286835697867		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 2.2657286835697867 | validation: 1.203192063197289]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260737338983166		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 2.260737338983166 | validation: 1.208636307663102]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264756833395615		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 2.264756833395615 | validation: 1.2057600681132628]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2647695085591923		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 2.2647695085591923 | validation: 1.2123537714550896]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2579719816659387		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 2.2579719816659387 | validation: 1.2038786863808457]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2595836644000147		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 2.2595836644000147 | validation: 1.2193426955759212]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2811302756005145		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 2.2811302756005145 | validation: 1.205088055182024]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2603344102149503		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 2.2603344102149503 | validation: 1.2209287034177445]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263348708194428		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 2.263348708194428 | validation: 1.2012371127505255]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2738643242913867		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 2.2738643242913867 | validation: 1.2409386744746207]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2945600833066333		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 2.2945600833066333 | validation: 1.2602249488722623]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269923019415567		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 2.269923019415567 | validation: 1.2063131162180853]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2598742553755633		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 2.2598742553755633 | validation: 1.200417595970536]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2574900795108968		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 2.2574900795108968 | validation: 1.1960414154867827]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262914957693552		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 2.262914957693552 | validation: 1.2272135045756138]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2844583194869754		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 2.2844583194869754 | validation: 1.2123085403654867]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2671574185556675		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 2.2671574185556675 | validation: 1.2010365344194285]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2558368098159756		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 2.2558368098159756 | validation: 1.1916455332194305]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1169.pth
	Model improved!!!
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2589517788551037		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 2.2589517788551037 | validation: 1.2066853528905035]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2636215584628476		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 2.2636215584628476 | validation: 1.2095900482228812]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262121435041086		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 2.262121435041086 | validation: 1.205422250804145]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2550483578382416		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 2.2550483578382416 | validation: 1.2024343102335233]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2564411986927424		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 2.2564411986927424 | validation: 1.203133341029692]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2603930605173024		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 2.2603930605173024 | validation: 1.1993235606753796]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.259840561956537		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 2.259840561956537 | validation: 1.2051492149401375]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275001377007196		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 2.275001377007196 | validation: 1.2446205947565454]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277332977694872		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 2.277332977694872 | validation: 1.2166257231607225]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2659485411297418		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 2.2659485411297418 | validation: 1.20068806956961]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263473625429144		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 2.263473625429144 | validation: 1.2055774593026025]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.27481976600594		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 2.27481976600594 | validation: 1.197775737913869]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2608432979363284		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 2.2608432979363284 | validation: 1.1965341208735902]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255453561773127		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 2.255453561773127 | validation: 1.2103124747854972]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2679416426081467		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 2.2679416426081467 | validation: 1.2192681038706676]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2650105252448265		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 2.2650105252448265 | validation: 1.190630481843929]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1185.pth
	Model improved!!!
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252456055436687		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 2.252456055436687 | validation: 1.203060760987869]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2604573417091625		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 2.2604573417091625 | validation: 1.2136492722309606]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258820537288947		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 2.258820537288947 | validation: 1.2024076849922452]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2649280894907715		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 2.2649280894907715 | validation: 1.2066964044721156]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2606439639346916		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 2.2606439639346916 | validation: 1.2004891990281548]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.265143800698249		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 2.265143800698249 | validation: 1.2066645670082963]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2632520644420695		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 2.2632520644420695 | validation: 1.2017378563930377]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255596227642961		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 2.255596227642961 | validation: 1.203966426708296]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2608006582626743		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 2.2608006582626743 | validation: 1.2047457810746165]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260481023953786		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 2.260481023953786 | validation: 1.2098191713654627]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257216299577296		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 2.257216299577296 | validation: 1.209638946126355]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2734269793507282		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 2.2734269793507282 | validation: 1.2019023039118264]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2607013403148817		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 2.2607013403148817 | validation: 1.2205746407069895]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276600771977126		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 2.276600771977126 | validation: 1.214442704559976]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2622977307759173		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 2.2622977307759173 | validation: 1.1974053198279635]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2567665359872304		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 2.2567665359872304 | validation: 1.221760741404287]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2655213470739186		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 2.2655213470739186 | validation: 1.2170750721498933]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263399431980499		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 2.263399431980499 | validation: 1.2061058776825273]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258578995904875		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 2.258578995904875 | validation: 1.1993596884914373]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2562177198773052		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 2.2562177198773052 | validation: 1.2069019953890554]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26091921165599		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 2.26091921165599 | validation: 1.2106345912433043]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2560497159123023		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 2.2560497159123023 | validation: 1.212953414681528]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25791637982841		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 2.25791637982841 | validation: 1.2317511244854595]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264761946885955		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 2.264761946885955 | validation: 1.2057203063856858]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255832415761848		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 2.255832415761848 | validation: 1.2144338120042317]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274859336519248		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 2.274859336519248 | validation: 1.2122774251490611]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2645125353998066		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 2.2645125353998066 | validation: 1.1980156610005086]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26112657608075		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 2.26112657608075 | validation: 1.2165955188818327]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257416757618625		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 2.257416757618625 | validation: 1.2027837582785172]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2553882585925282		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 2.2553882585925282 | validation: 1.2069064602368877]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2589835827282845		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 2.2589835827282845 | validation: 1.1962211594919743]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2615436567764746		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 2.2615436567764746 | validation: 1.2070477944529545]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258815056812133		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 2.258815056812133 | validation: 1.2128415333255107]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2662459519292963		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 2.2662459519292963 | validation: 1.2455722745440372]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308080467506102		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 2.308080467506102 | validation: 1.241297594131909]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266819040116136		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 2.266819040116136 | validation: 1.2008442910829666]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2575101247061364		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 2.2575101247061364 | validation: 1.2086908735158195]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256177273197492		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 2.256177273197492 | validation: 1.2105060702698682]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263938536897327		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 2.263938536897327 | validation: 1.2266780062446074]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2743103407971277		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 2.2743103407971277 | validation: 1.2269281987529703]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258198358188024		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 2.258198358188024 | validation: 1.1949863640142675]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2589212252514024		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 2.2589212252514024 | validation: 1.2214577725964078]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2694927942135803		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 2.2694927942135803 | validation: 1.1991116233146404]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263222928390701		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 2.263222928390701 | validation: 1.224631364449805]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25516173408295		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 2.25516173408295 | validation: 1.212814296077864]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264430883615148		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 2.264430883615148 | validation: 1.202965459386886]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258760338365669		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 2.258760338365669 | validation: 1.2030586932381784]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2621932320712714		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 2.2621932320712714 | validation: 1.2189377007959497]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260330067423596		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 2.260330067423596 | validation: 1.2011983375306998]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264848563525753		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 2.264848563525753 | validation: 1.1943919830347312]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2557508998164257		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 2.2557508998164257 | validation: 1.197887621582971]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255265228431967		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 2.255265228431967 | validation: 1.1989003617439484]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2650141757200304		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 2.2650141757200304 | validation: 1.2172400385259052]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264125637960792		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 2.264125637960792 | validation: 1.2023990087961733]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2602913867367183		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 2.2602913867367183 | validation: 1.2090182493597645]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2533099094518105		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 2.2533099094518105 | validation: 1.2031303869392052]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254678158247182		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 2.254678158247182 | validation: 1.2070993747886263]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2747163401612904		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 2.2747163401612904 | validation: 1.2153521753727403]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262627150680027		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 2.262627150680027 | validation: 1.2116860011761883]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26007024359667		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 2.26007024359667 | validation: 1.1928696713491205]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254165257912856		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 2.254165257912856 | validation: 1.198075404326383]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258295606553519		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 2.258295606553519 | validation: 1.2048485266134106]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2586230921088957		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 2.2586230921088957 | validation: 1.2144211405116498]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264726245819862		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 2.264726245819862 | validation: 1.2100135126918157]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2607075086385406		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 2.2607075086385406 | validation: 1.2018554455810015]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2552773259857415		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 2.2552773259857415 | validation: 1.2250986885178041]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267217112353571		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 2.267217112353571 | validation: 1.2359903726749013]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2607660384295585		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 2.2607660384295585 | validation: 1.202562323067375]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261826568975442		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 2.261826568975442 | validation: 1.230367910174449]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2795685228069202		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 2.2795685228069202 | validation: 1.206284453869298]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262542805044128		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 2.262542805044128 | validation: 1.228628182061452]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2808676062045397		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 2.2808676062045397 | validation: 1.2083772343424286]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257935150380894		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 2.257935150380894 | validation: 1.2082648609664752]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2650729455841767		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 2.2650729455841767 | validation: 1.233531567170056]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262023307002882		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 2.262023307002882 | validation: 1.203767527926466]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2586879530632005		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 2.2586879530632005 | validation: 1.2130465506395465]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2535447104176223		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 2.2535447104176223 | validation: 1.1991312235126406]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25556378004631		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 2.25556378004631 | validation: 1.2148397730596698]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2524316971021388		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 2.2524316971021388 | validation: 1.206848163467905]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252604386644885		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 2.252604386644885 | validation: 1.212010957174982]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2613126249782347		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 2.2613126249782347 | validation: 1.2083216380720827]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2552302094456795		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 2.2552302094456795 | validation: 1.2112428454195]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257964683605163		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 2.257964683605163 | validation: 1.208869520574178]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2595716004415394		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 2.2595716004415394 | validation: 1.2087296014116315]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2553664987510555		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 2.2553664987510555 | validation: 1.2058521808192553]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256853009914242		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 2.256853009914242 | validation: 1.20997449615706]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258120896430872		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 2.258120896430872 | validation: 1.2039603246608395]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2785765639862334		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 2.2785765639862334 | validation: 1.2052392138661248]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2534027923490014		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 2.2534027923490014 | validation: 1.2093012057860058]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2551629879244075		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 2.2551629879244075 | validation: 1.1936192052396566]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2559546795973997		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 2.2559546795973997 | validation: 1.1974246303095262]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2552125545457575		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 2.2552125545457575 | validation: 1.2075969039617775]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251531717810023		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 2.251531717810023 | validation: 1.20576930777673]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256609200685557		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 2.256609200685557 | validation: 1.2005489965722231]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2562846549236184		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 2.2562846549236184 | validation: 1.2066667276846939]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2537590637493223		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 2.2537590637493223 | validation: 1.2083275286846504]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260643050902396		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 2.260643050902396 | validation: 1.2076819614228067]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2647826083381997		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 2.2647826083381997 | validation: 1.2199164036907817]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267022419837446		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 2.267022419837446 | validation: 1.2027958577036426]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26222739617656		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 2.26222739617656 | validation: 1.2079746113090468]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260618815450611		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 2.260618815450611 | validation: 1.2151382286984924]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2572018432991032		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 2.2572018432991032 | validation: 1.1977912180274266]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2507516915809846		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 2.2507516915809846 | validation: 1.1943803722773492]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258663435238505		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 2.258663435238505 | validation: 1.216350547379516]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275832428655443		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 2.275832428655443 | validation: 1.221744308316102]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.269260669396166		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 2.269260669396166 | validation: 1.22907112682812]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274449238842493		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 2.274449238842493 | validation: 1.2054816417692638]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2596714334445633		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 2.2596714334445633 | validation: 1.199898795796298]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249797030729507		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 2.249797030729507 | validation: 1.1948814180757472]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253465667430234		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 2.253465667430234 | validation: 1.202893305100314]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.274246829524409		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 2.274246829524409 | validation: 1.2403009843662363]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2732766315237143		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 2.2732766315237143 | validation: 1.2040622070802611]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2630006545873993		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 2.2630006545873993 | validation: 1.1945258811848367]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251483983794963		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 2.251483983794963 | validation: 1.2008415272387607]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2518938431998716		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 2.2518938431998716 | validation: 1.2023415386562533]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2675057056927233		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 2.2675057056927233 | validation: 1.196710848819897]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253657629165709		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 2.253657629165709 | validation: 1.2040239255702574]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2509941091207173		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 2.2509941091207173 | validation: 1.2036382870474025]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.263149784839558		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 2.263149784839558 | validation: 1.2053266038820751]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2596679354905227		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 2.2596679354905227 | validation: 1.2008405319786406]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2536595329799		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 2.2536595329799 | validation: 1.1968361527175742]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25531066506673		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 2.25531066506673 | validation: 1.2049851053808502]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2525098529927092		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 2.2525098529927092 | validation: 1.1996609208566034]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2636671558697863		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 2.2636671558697863 | validation: 1.198162131779427]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254181781102998		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 2.254181781102998 | validation: 1.2029236475890326]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260179078177451		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 2.260179078177451 | validation: 1.207945276000153]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256894949352628		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 2.256894949352628 | validation: 1.198719980335746]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2500811654423742		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 2.2500811654423742 | validation: 1.2043484814568919]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25608313876283		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 2.25608313876283 | validation: 1.207021311015131]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2532096122221166		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 2.2532096122221166 | validation: 1.193166735132164]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252938883823589		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 2.252938883823589 | validation: 1.1976538360308207]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2558898385245705		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 2.2558898385245705 | validation: 1.2087866466960728]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2656764666225615		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 2.2656764666225615 | validation: 1.19412752127644]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2532409463963163		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 2.2532409463963163 | validation: 1.2022002815734285]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2552465799385577		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 2.2552465799385577 | validation: 1.1989502704975248]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2586587531014777		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 2.2586587531014777 | validation: 1.1939961456342183]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2535042789249156		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 2.2535042789249156 | validation: 1.2063170860747883]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254505605605506		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 2.254505605605506 | validation: 1.1909996548487594]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250440787046054		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 2.250440787046054 | validation: 1.1988295189598062]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2486977034628035		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 2.2486977034628035 | validation: 1.1970824305388312]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251139154567469		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 2.251139154567469 | validation: 1.1988199190292743]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2514039977656957		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 2.2514039977656957 | validation: 1.1882280168831922]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1327.pth
	Model improved!!!
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257497265208289		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 2.257497265208289 | validation: 1.2084529605145755]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2563748090271516		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 2.2563748090271516 | validation: 1.1992345785723635]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2521556052102722		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 2.2521556052102722 | validation: 1.1954332746663396]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2510322767175093		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 2.2510322767175093 | validation: 1.2108549344367272]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2658800714973104		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 2.2658800714973104 | validation: 1.2106605256972243]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256977335530218		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 2.256977335530218 | validation: 1.2032736778198292]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2522807761095045		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 2.2522807761095045 | validation: 1.205815409624412]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2492357823068057		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 2.2492357823068057 | validation: 1.2041408687259751]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2543272376723142		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 2.2543272376723142 | validation: 1.2015022337137746]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258166845623237		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 2.258166845623237 | validation: 1.2134843973155163]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.266930273766973		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 2.266930273766973 | validation: 1.1935837605496287]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2588771289637872		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 2.2588771289637872 | validation: 1.1956825790482208]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2500704227396437		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 2.2500704227396437 | validation: 1.1976300874946844]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2562264460052304		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 2.2562264460052304 | validation: 1.1999404728861387]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251607205075317		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 2.251607205075317 | validation: 1.1992676888826517]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2560149974091352		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 2.2560149974091352 | validation: 1.209860452065058]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252396977788071		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 2.252396977788071 | validation: 1.2053909913788556]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253645436072953		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 2.253645436072953 | validation: 1.209217311079595]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2526742212204836		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 2.2526742212204836 | validation: 1.200205581075232]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2581217656247525		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 2.2581217656247525 | validation: 1.2076660917500674]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.255358832547663		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 2.255358832547663 | validation: 1.2015093700605404]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.26032248358953		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 2.26032248358953 | validation: 1.1979379736944946]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2544491206013477		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 2.2544491206013477 | validation: 1.2043490593358608]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2603027091768046		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 2.2603027091768046 | validation: 1.1982934082982803]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2558345147387637		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 2.2558345147387637 | validation: 1.1906827733327423]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2516634965128217		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 2.2516634965128217 | validation: 1.1901089029495198]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247505912793654		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 2.247505912793654 | validation: 1.2001735681865926]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2585747175344064		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 2.2585747175344064 | validation: 1.2038535808325699]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2494609999116846		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 2.2494609999116846 | validation: 1.1920389316597397]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248457725682543		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 2.248457725682543 | validation: 1.200291168924414]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246842785399144		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 2.246842785399144 | validation: 1.1950532289236548]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2513497024324978		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 2.2513497024324978 | validation: 1.192263329822933]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25247066105671		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 2.25247066105671 | validation: 1.1986080594164208]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2569989615624686		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 2.2569989615624686 | validation: 1.18387093279956]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1361.pth
	Model improved!!!
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251331634537798		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 2.251331634537798 | validation: 1.1982714275196753]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251241010600028		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 2.251241010600028 | validation: 1.1968788660143725]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248589319122099		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 2.248589319122099 | validation: 1.1877909229362855]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.256699411818839		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 2.256699411818839 | validation: 1.2039897955057104]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2530848107818615		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 2.2530848107818615 | validation: 1.193669441878234]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2518650623843026		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 2.2518650623843026 | validation: 1.1947049311419609]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254077354474254		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 2.254077354474254 | validation: 1.2001347920092729]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.24741822312279		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 2.24741822312279 | validation: 1.1909766010169296]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2535584705509315		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 2.2535584705509315 | validation: 1.1987642099485982]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.264845931530894		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 2.264845931530894 | validation: 1.2239048399669121]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252868661578949		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 2.252868661578949 | validation: 1.1921170081680754]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251157641382707		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 2.251157641382707 | validation: 1.1940602841794956]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251902667876123		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 2.251902667876123 | validation: 1.190520272058627]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.24825891986416		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 2.24825891986416 | validation: 1.1935037685420207]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2567361718477574		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 2.2567361718477574 | validation: 1.1940392235289279]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253061605562756		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 2.253061605562756 | validation: 1.1945126923628182]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2489326985801523		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 2.2489326985801523 | validation: 1.1897233069780666]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247376088757536		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 2.247376088757536 | validation: 1.2044242620236694]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2510345743097577		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 2.2510345743097577 | validation: 1.1977737045447197]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2506356612161658		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 2.2506356612161658 | validation: 1.195164580130641]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2497178078977447		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 2.2497178078977447 | validation: 1.2011436447895454]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2512264276903395		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 2.2512264276903395 | validation: 1.1954935123850856]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257846779125947		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 2.257846779125947 | validation: 1.2035855131263753]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2504795931873414		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 2.2504795931873414 | validation: 1.1906208412159536]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250075397312145		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 2.250075397312145 | validation: 1.1977045733591862]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2490124553270983		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 2.2490124553270983 | validation: 1.1923902889510398]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2496285433590177		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 2.2496285433590177 | validation: 1.1926122890295972]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249401432789064		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 2.249401432789064 | validation: 1.1943730712849554]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254626255939784		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 2.254626255939784 | validation: 1.2052636941267147]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260585888829179		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 2.260585888829179 | validation: 1.193157886269773]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258609310024251		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 2.258609310024251 | validation: 1.1949261435261544]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2533568146770113		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 2.2533568146770113 | validation: 1.191749563617974]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2531338689414167		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 2.2531338689414167 | validation: 1.2081209864243008]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2551399122750033		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 2.2551399122750033 | validation: 1.2087077416943959]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253520211204444		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 2.253520211204444 | validation: 1.1862588855258287]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464787308542378		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 2.2464787308542378 | validation: 1.1924972824989735]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2488548028196353		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 2.2488548028196353 | validation: 1.1975407716879338]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2506982770700295		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 2.2506982770700295 | validation: 1.197531393141768]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252847729915452		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 2.252847729915452 | validation: 1.2035199453724226]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250818880766092		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 2.250818880766092 | validation: 1.20181454394406]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2490044389745734		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 2.2490044389745734 | validation: 1.1985338576120128]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2588552555492214		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 2.2588552555492214 | validation: 1.2270758063551535]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2549769270514153		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 2.2549769270514153 | validation: 1.1926758952707952]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253086092525284		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 2.253086092525284 | validation: 1.1923780834371198]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251704620586955		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 2.251704620586955 | validation: 1.1884286814938043]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261950217430472		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 2.261950217430472 | validation: 1.201715128866517]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2512876594386086		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 2.2512876594386086 | validation: 1.1970933616789403]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249648858526387		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 2.249648858526387 | validation: 1.1987609489567805]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246221014849368		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 2.246221014849368 | validation: 1.1874475517471974]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253783094682869		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 2.253783094682869 | validation: 1.19426920457444]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2518289356933443		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 2.2518289356933443 | validation: 1.1996092595389698]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2471842107147597		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 2.2471842107147597 | validation: 1.1916893327635933]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253803019318828		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 2.253803019318828 | validation: 1.195124639993008]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2492048077587072		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 2.2492048077587072 | validation: 1.199389261799652]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2486892498745776		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 2.2486892498745776 | validation: 1.197438371708546]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2481387993672133		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 2.2481387993672133 | validation: 1.1981932482154343]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251596401510563		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 2.251596401510563 | validation: 1.1972426249541182]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260227447669712		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 2.260227447669712 | validation: 1.2034893590446292]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2560353378465843		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 2.2560353378465843 | validation: 1.1940096037567152]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457961045936035		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 2.2457961045936035 | validation: 1.1991831027880222]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2500244811048065		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 2.2500244811048065 | validation: 1.2025288117487223]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2552609377198563		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 2.2552609377198563 | validation: 1.2062446964408635]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262191866059989		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 2.262191866059989 | validation: 1.2046412568835667]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25722148733788		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 2.25722148733788 | validation: 1.1930596318271216]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2489397590761477		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 2.2489397590761477 | validation: 1.1954096362278017]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250804137301311		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 2.250804137301311 | validation: 1.1961093688402449]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250187249096104		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 2.250187249096104 | validation: 1.198288208745544]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2495457560387186		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 2.2495457560387186 | validation: 1.1936140244155784]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2531402710048156		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 2.2531402710048156 | validation: 1.1972322743717407]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2493078694376734		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 2.2493078694376734 | validation: 1.2040081783440295]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2509220732725392		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 2.2509220732725392 | validation: 1.1951746531429348]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250423149892129		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 2.250423149892129 | validation: 1.2048951309705904]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2542955685896		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 2.2542955685896 | validation: 1.1988564080330573]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2485215450548672		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 2.2485215450548672 | validation: 1.1997555322006452]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2491974745533354		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 2.2491974745533354 | validation: 1.190872214362964]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248638446200058		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 2.248638446200058 | validation: 1.1967027297797814]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2490233983646215		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 2.2490233983646215 | validation: 1.1964967521343155]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245897942150179		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 2.245897942150179 | validation: 1.2079356860331498]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2486966517086744		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 2.2486966517086744 | validation: 1.1973523933051577]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2496436881011066		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 2.2496436881011066 | validation: 1.1954076399270337]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2465518159868436		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 2.2465518159868436 | validation: 1.1934805135351978]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2529532050160084		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 2.2529532050160084 | validation: 1.185002211630828]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2491097390768147		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 2.2491097390768147 | validation: 1.18750199268178]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2476134242987182		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 2.2476134242987182 | validation: 1.1945434736098246]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2478703563399485		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 2.2478703563399485 | validation: 1.1913323495463226]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2500038950743377		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 2.2500038950743377 | validation: 1.1931872693163053]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2487969707123705		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 2.2487969707123705 | validation: 1.1964191264118993]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248812119478561		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 2.248812119478561 | validation: 1.1901346083410516]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472578366450837		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 2.2472578366450837 | validation: 1.1865340858160491]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.24769459330997		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 2.24769459330997 | validation: 1.2010404257754848]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250163332039987		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 2.250163332039987 | validation: 1.1954931564930271]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2511134045368086		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 2.2511134045368086 | validation: 1.1982498551622356]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2530404372303607		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 2.2530404372303607 | validation: 1.2088933700865376]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2544600048737014		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 2.2544600048737014 | validation: 1.2013593240542677]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2501405317187055		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 2.2501405317187055 | validation: 1.1939416543973094]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2516687103302044		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 2.2516687103302044 | validation: 1.1968146428526008]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248787393745265		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 2.248787393745265 | validation: 1.1833422686336368]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1458.pth
	Model improved!!!
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2481653554419974		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 2.2481653554419974 | validation: 1.2056994487034285]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2473096612089436		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 2.2473096612089436 | validation: 1.210030184448801]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2492168598173143		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 2.2492168598173143 | validation: 1.1905291372687716]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2490681065544957		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 2.2490681065544957 | validation: 1.185354348454192]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460831500570513		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 2.2460831500570513 | validation: 1.19038971222855]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2487520324511117		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 2.2487520324511117 | validation: 1.1961080883390602]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2476013929074425		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 2.2476013929074425 | validation: 1.1990336362390326]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248303401752926		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 2.248303401752926 | validation: 1.1809203284787344]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1466.pth
	Model improved!!!
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2524075255866576		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 2.2524075255866576 | validation: 1.2061085261299616]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2564665760088407		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 2.2564665760088407 | validation: 1.1961605313073476]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2550554998582073		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 2.2550554998582073 | validation: 1.1962198571547236]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2435037553018136		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 2.2435037553018136 | validation: 1.195997962579998]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2486395910225374		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 2.2486395910225374 | validation: 1.1874236502246813]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2489990299412663		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 2.2489990299412663 | validation: 1.192780898247084]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2531205929155904		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 2.2531205929155904 | validation: 1.1849872080231432]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2478424499661966		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 2.2478424499661966 | validation: 1.2007236274785755]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2535633784181344		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 2.2535633784181344 | validation: 1.2046200311068915]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2485363314225273		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 2.2485363314225273 | validation: 1.2150348812730247]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2619179275437578		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 2.2619179275437578 | validation: 1.2174450467741575]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2590597370857717		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 2.2590597370857717 | validation: 1.2035824308273422]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2497726028225706		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 2.2497726028225706 | validation: 1.198732481906619]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244360461181532		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 2.244360461181532 | validation: 1.193870017261332]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2497114380009506		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 2.2497114380009506 | validation: 1.183285410954133]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250019356940963		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 2.250019356940963 | validation: 1.1885328416844876]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.24805793885134		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 2.24805793885134 | validation: 1.1970079742982445]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2504929544247307		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 2.2504929544247307 | validation: 1.1889081528628496]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2479610291352947		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 2.2479610291352947 | validation: 1.2030480505226584]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248654614910854		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 2.248654614910854 | validation: 1.1885693075550803]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2556098778783555		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 2.2556098778783555 | validation: 1.189669718404147]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2496625564677424		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 2.2496625564677424 | validation: 1.1952996984950468]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2469143036538144		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 2.2469143036538144 | validation: 1.2008019798950769]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.24761531330627		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 2.24761531330627 | validation: 1.197622980084757]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455847735481753		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 2.2455847735481753 | validation: 1.1931079558368194]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2476361878153797		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 2.2476361878153797 | validation: 1.1905998611188306]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249740702886386		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 2.249740702886386 | validation: 1.1852615817224912]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2484426922995135		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 2.2484426922995135 | validation: 1.1916310119570475]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2425785294834575		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 2.2425785294834575 | validation: 1.1853865458924244]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247358216375939		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 2.247358216375939 | validation: 1.1841855941164061]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2462725151707703		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 2.2462725151707703 | validation: 1.194070651780515]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2435192607390073		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 2.2435192607390073 | validation: 1.1947987186398847]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2554441560663845		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 2.2554441560663845 | validation: 1.1957849650739905]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2569203195469028		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 2.2569203195469028 | validation: 1.1805804903056762]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1500.pth
	Model improved!!!
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251505459124256		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 2.251505459124256 | validation: 1.2007590921288782]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249396038133748		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 2.249396038133748 | validation: 1.1865265818738315]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247722327146407		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 2.247722327146407 | validation: 1.1940850269338168]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2510094579709996		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 2.2510094579709996 | validation: 1.2008909773225898]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2503472607622212		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 2.2503472607622212 | validation: 1.1952524488527223]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460289611886317		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 2.2460289611886317 | validation: 1.1874327901445885]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2462594219840444		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 2.2462594219840444 | validation: 1.1899176460639544]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2522241610019114		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 2.2522241610019114 | validation: 1.1883375269082674]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2480652551042164		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 2.2480652551042164 | validation: 1.1851289613195224]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2471875602030025		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 2.2471875602030025 | validation: 1.2078040870470095]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250446322866194		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 2.250446322866194 | validation: 1.2007649993996696]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254788758208462		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 2.254788758208462 | validation: 1.194119287536866]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25365336244471		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 2.25365336244471 | validation: 1.2056195149581184]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2638639835611		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 2.2638639835611 | validation: 1.2018916179068382]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249435855041699		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 2.249435855041699 | validation: 1.1997207334106716]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2515117395563093		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 2.2515117395563093 | validation: 1.1987956593199405]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251307162731497		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 2.251307162731497 | validation: 1.1949077605751601]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2473072689711575		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 2.2473072689711575 | validation: 1.1974557308920635]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2527250362568476		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 2.2527250362568476 | validation: 1.1861802762433038]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2463674344637803		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 2.2463674344637803 | validation: 1.1908810610712304]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2524074976271606		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 2.2524074976271606 | validation: 1.194172229781326]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247393767858973		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 2.247393767858973 | validation: 1.1993333374241357]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464204938319527		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 2.2464204938319527 | validation: 1.1926125627467121]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457601936910834		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 2.2457601936910834 | validation: 1.1981793145387871]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247773729045919		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 2.247773729045919 | validation: 1.1905942036046078]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.24929203127359		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 2.24929203127359 | validation: 1.1923259927180336]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251439613330056		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 2.251439613330056 | validation: 1.189409892997233]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247279309248484		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 2.247279309248484 | validation: 1.1942361449909056]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2478666297788603		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 2.2478666297788603 | validation: 1.192041800951593]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2470647242348125		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 2.2470647242348125 | validation: 1.1928348108809173]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247758300324773		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 2.247758300324773 | validation: 1.1946311311197837]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253268616865693		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 2.253268616865693 | validation: 1.188123593300021]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2506739157035494		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 2.2506739157035494 | validation: 1.1829689771415368]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460902917612997		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 2.2460902917612997 | validation: 1.1899843287074883]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2468134883935544		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 2.2468134883935544 | validation: 1.1843330122213873]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246824986217258		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 2.246824986217258 | validation: 1.1891113717790736]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246834755341276		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 2.246834755341276 | validation: 1.1883471502648124]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246309812558157		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 2.246309812558157 | validation: 1.1795477162138301]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1538.pth
	Model improved!!!
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245622772447933		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 2.245622772447933 | validation: 1.1924007978046711]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457223132095683		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 2.2457223132095683 | validation: 1.1978753201356411]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2505287875240763		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 2.2505287875240763 | validation: 1.1954086928849497]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251710916442609		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 2.251710916442609 | validation: 1.2010895353850186]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2508721923289605		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 2.2508721923289605 | validation: 1.1898566168759208]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244175431462673		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 2.244175431462673 | validation: 1.1916189407530753]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247926661132922		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 2.247926661132922 | validation: 1.187571897138366]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2469463364519022		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 2.2469463364519022 | validation: 1.1926938278478678]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2467286983752937		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 2.2467286983752937 | validation: 1.1872570713536532]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2484772016389134		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 2.2484772016389134 | validation: 1.1878186274238849]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246913305608034		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 2.246913305608034 | validation: 1.1817521855874125]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247442073758011		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 2.247442073758011 | validation: 1.1897219846740168]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464264149413484		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 2.2464264149413484 | validation: 1.194296168514868]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250339782598942		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 2.250339782598942 | validation: 1.1901628581742703]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2516837407717922		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 2.2516837407717922 | validation: 1.199035820999914]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249912985652		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 2.249912985652 | validation: 1.195042721946123]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2508718192501744		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 2.2508718192501744 | validation: 1.193728443386687]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2512418357511788		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 2.2512418357511788 | validation: 1.1959114859615638]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2504147105637777		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 2.2504147105637777 | validation: 1.1875696176139725]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2462984092215392		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 2.2462984092215392 | validation: 1.1829867519578219]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247105055114876		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 2.247105055114876 | validation: 1.190673930324194]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2500682016377014		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 2.2500682016377014 | validation: 1.1964175360985914]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249740105849162		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 2.249740105849162 | validation: 1.185406824031133]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2506416225646593		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 2.2506416225646593 | validation: 1.1941759865344879]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250133648142046		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 2.250133648142046 | validation: 1.1887160145494162]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2501542583422838		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 2.2501542583422838 | validation: 1.1874421110675428]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2495507528152445		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 2.2495507528152445 | validation: 1.1892008930983518]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249263740386811		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 2.249263740386811 | validation: 1.1875544105529785]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2493842839735705		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 2.2493842839735705 | validation: 1.186615242687632]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2467126916375926		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 2.2467126916375926 | validation: 1.1779411534437525]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study203/model_tr_study203_r0_20240310_044559/states/model_tr_study203_1568.pth
	Model improved!!!
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2445735575058134		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 2.2445735575058134 | validation: 1.1847053833283454]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472200258512567		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 2.2472200258512567 | validation: 1.2001151420646392]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2474833213473313		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 2.2474833213473313 | validation: 1.1836358022230367]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.24825356396592		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 2.24825356396592 | validation: 1.1885529917276494]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2454185982109545		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 2.2454185982109545 | validation: 1.1840888616048826]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2495444431172933		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 2.2495444431172933 | validation: 1.195579144599655]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2477432057101217		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 2.2477432057101217 | validation: 1.1902930142204937]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2448480115195313		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 2.2448480115195313 | validation: 1.19384733448465]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247120256510468		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 2.247120256510468 | validation: 1.191528043746883]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2440580566859856		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 2.2440580566859856 | validation: 1.1928235299325547]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250030587569693		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 2.250030587569693 | validation: 1.194401238341802]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2505462589048153		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 2.2505462589048153 | validation: 1.1881661420791472]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253261142985752		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 2.253261142985752 | validation: 1.1948582812758997]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2537637028267197		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 2.2537637028267197 | validation: 1.1947007604361697]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2555643500054603		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 2.2555643500054603 | validation: 1.1935673411273064]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249835538425546		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 2.249835538425546 | validation: 1.1919413511901806]
	TIME [epoch: 11.6 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2475716572125273		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 2.2475716572125273 | validation: 1.193758500394749]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246799228281069		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 2.246799228281069 | validation: 1.1877924115915874]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2499375572354525		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 2.2499375572354525 | validation: 1.1948185665559765]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2539144740244375		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 2.2539144740244375 | validation: 1.1911224320914784]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251487666530684		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 2.251487666530684 | validation: 1.195888222380671]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246506893923817		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 2.246506893923817 | validation: 1.1938341841339437]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246871151262355		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 2.246871151262355 | validation: 1.1969147039491312]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2473628627589006		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 2.2473628627589006 | validation: 1.187834714026505]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2452622960642348		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 2.2452622960642348 | validation: 1.1996359754337136]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248888024308229		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 2.248888024308229 | validation: 1.1956808773495273]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2515493054977975		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 2.2515493054977975 | validation: 1.1871368148624317]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2453952371921324		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 2.2453952371921324 | validation: 1.193337489779576]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2518302389371425		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 2.2518302389371425 | validation: 1.2051984620677765]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2549352230362834		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 2.2549352230362834 | validation: 1.2000810350935367]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258386278783475		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 2.258386278783475 | validation: 1.204907884880107]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258713728748031		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 2.258713728748031 | validation: 1.2027946389705273]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.258758194801376		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 2.258758194801376 | validation: 1.2041077259716122]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25992803902042		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 2.25992803902042 | validation: 1.2090826154200218]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261676729945119		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 2.261676729945119 | validation: 1.1994227666847241]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.260118896309111		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 2.260118896309111 | validation: 1.1991783694660862]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2509640873292023		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 2.2509640873292023 | validation: 1.1938469418838675]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2479687814941047		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 2.2479687814941047 | validation: 1.1977932873759525]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2499542485803032		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 2.2499542485803032 | validation: 1.2005477385386683]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249144569372521		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 2.249144569372521 | validation: 1.1948036051448123]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2436933333810245		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 2.2436933333810245 | validation: 1.1966215572027197]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2458071210020956		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 2.2458071210020956 | validation: 1.1955378230924079]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246840359191366		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 2.246840359191366 | validation: 1.2011402865430345]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2466346872742724		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 2.2466346872742724 | validation: 1.189280862655949]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2445166667911813		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 2.2445166667911813 | validation: 1.1949155414787487]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248202769488274		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 2.248202769488274 | validation: 1.1921230954736042]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247341625366967		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 2.247341625366967 | validation: 1.1965310497394976]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457545316818526		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 2.2457545316818526 | validation: 1.185782014158563]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2459722620484612		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 2.2459722620484612 | validation: 1.1863065186746349]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250108612256195		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 2.250108612256195 | validation: 1.1900973359163947]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249082653779638		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 2.249082653779638 | validation: 1.1892133353580645]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2456123107180455		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 2.2456123107180455 | validation: 1.186508557748378]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2451274766826366		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 2.2451274766826366 | validation: 1.1849647606843132]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2456016341566074		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 2.2456016341566074 | validation: 1.1915082832686719]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455139763167233		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 2.2455139763167233 | validation: 1.1939607819470128]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246670910120131		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 2.246670910120131 | validation: 1.1904639633545955]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2463419687378936		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 2.2463419687378936 | validation: 1.18895240708639]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248491954879639		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 2.248491954879639 | validation: 1.1958730996326252]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2443674336638817		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 2.2443674336638817 | validation: 1.195234485050318]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472157778176918		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 2.2472157778176918 | validation: 1.1851529881495682]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248437053049509		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 2.248437053049509 | validation: 1.198214201477833]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2468011321188035		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 2.2468011321188035 | validation: 1.1900075990159673]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2502425766236542		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 2.2502425766236542 | validation: 1.1923122763840592]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2498243510195697		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 2.2498243510195697 | validation: 1.198263869151738]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254586711136259		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 2.254586711136259 | validation: 1.196871537240495]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2517264776497807		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 2.2517264776497807 | validation: 1.1794579991129757]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253220980797347		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 2.253220980797347 | validation: 1.197849806320106]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2539092912038083		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 2.2539092912038083 | validation: 1.195607653422924]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246308665804336		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 2.246308665804336 | validation: 1.18828375060767]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2486235847528606		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 2.2486235847528606 | validation: 1.1910512639079454]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248890331691702		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 2.248890331691702 | validation: 1.195779078682384]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2520664322037827		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 2.2520664322037827 | validation: 1.1881858986681568]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2482002040654137		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 2.2482002040654137 | validation: 1.1886021817345551]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2499810350487386		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 2.2499810350487386 | validation: 1.2015674098968467]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2461246350664927		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 2.2461246350664927 | validation: 1.1845497761085775]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2435866933327566		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 2.2435866933327566 | validation: 1.197501241833981]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2473591636242065		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 2.2473591636242065 | validation: 1.1942564661496529]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246119686013814		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 2.246119686013814 | validation: 1.185048303599942]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2471355553335317		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 2.2471355553335317 | validation: 1.1837250842755718]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472473527863217		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 2.2472473527863217 | validation: 1.19149276528039]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464278863119094		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 2.2464278863119094 | validation: 1.1950553290973098]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245432749277132		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 2.245432749277132 | validation: 1.1885555664101068]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246970651482411		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 2.246970651482411 | validation: 1.183368430113923]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249317172908627		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 2.249317172908627 | validation: 1.188471865262949]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472629663767836		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 2.2472629663767836 | validation: 1.1902310655048003]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244209687559138		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 2.244209687559138 | validation: 1.191982286565703]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247291033788984		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 2.247291033788984 | validation: 1.1887454440337208]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244926105150266		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 2.244926105150266 | validation: 1.1918179497797399]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464169783179195		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 2.2464169783179195 | validation: 1.1897009609750504]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2505006896298245		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 2.2505006896298245 | validation: 1.1871696094909403]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2441470736680236		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 2.2441470736680236 | validation: 1.1862254431004997]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2477801396955197		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 2.2477801396955197 | validation: 1.1864149981828325]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2437140581668142		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 2.2437140581668142 | validation: 1.1935962204889026]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2454048505021373		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 2.2454048505021373 | validation: 1.1898756150920742]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246410736659061		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 2.246410736659061 | validation: 1.2016596553879897]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244436003232591		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 2.244436003232591 | validation: 1.2043861006349121]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2451972737143517		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 2.2451972737143517 | validation: 1.1984740524158364]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250556924725999		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 2.250556924725999 | validation: 1.199775385957708]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245679955056331		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 2.245679955056331 | validation: 1.2001827882358946]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457768735952737		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 2.2457768735952737 | validation: 1.1963267760204388]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460148674011977		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 2.2460148674011977 | validation: 1.1952842159312105]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248909433044671		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 2.248909433044671 | validation: 1.1933637531139676]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2480605406540395		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 2.2480605406540395 | validation: 1.1920532219545166]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246195953940764		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 2.246195953940764 | validation: 1.197823444311374]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2413128479490965		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 2.2413128479490965 | validation: 1.194807072181878]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250663823323239		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 2.250663823323239 | validation: 1.1911085347225607]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2458765348581364		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 2.2458765348581364 | validation: 1.186051127568825]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245342326873231		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 2.245342326873231 | validation: 1.1897021898991909]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2458629400014902		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 2.2458629400014902 | validation: 1.1910510459850872]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246985520959484		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 2.246985520959484 | validation: 1.1919107208487691]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242292527157984		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 2.242292527157984 | validation: 1.1806465366572616]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460986893282984		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 2.2460986893282984 | validation: 1.196398612248998]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2428975394501482		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 2.2428975394501482 | validation: 1.1828987423147153]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2453984795361484		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 2.2453984795361484 | validation: 1.1876165484129708]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2462379000787163		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 2.2462379000787163 | validation: 1.193011144269836]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2473709516510563		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 2.2473709516510563 | validation: 1.1995115643946932]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464169619723506		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 2.2464169619723506 | validation: 1.1973080361152924]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249365885796525		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 2.249365885796525 | validation: 1.190412923904202]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2485815616957505		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 2.2485815616957505 | validation: 1.1928572149837033]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245355558436712		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 2.245355558436712 | validation: 1.1850074090444858]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2452296317736735		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 2.2452296317736735 | validation: 1.1989542329980043]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.252847050482712		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 2.252847050482712 | validation: 1.1969259432721568]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250217462616707		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 2.250217462616707 | validation: 1.1979115933401567]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2485144695721324		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 2.2485144695721324 | validation: 1.1906532753137788]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2470228143217295		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 2.2470228143217295 | validation: 1.1881833761422405]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245571976643224		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 2.245571976643224 | validation: 1.1857698436329358]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248748575387229		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 2.248748575387229 | validation: 1.1866879885694728]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2454758406718565		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 2.2454758406718565 | validation: 1.1860690464563568]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246770846410328		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 2.246770846410328 | validation: 1.1807539295653748]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460602029612224		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 2.2460602029612224 | validation: 1.182253251374527]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245215378418063		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 2.245215378418063 | validation: 1.1935008182229627]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248392943421191		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 2.248392943421191 | validation: 1.1910587663944572]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2421212821797205		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 2.2421212821797205 | validation: 1.1925714856273075]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472650011538584		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 2.2472650011538584 | validation: 1.1848539451199307]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247871962208464		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 2.247871962208464 | validation: 1.1780749478844545]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2415826241980277		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 2.2415826241980277 | validation: 1.196243817461891]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247435511883621		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 2.247435511883621 | validation: 1.194466878275968]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247712698321264		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 2.247712698321264 | validation: 1.1903457617387556]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.250502509070306		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 2.250502509070306 | validation: 1.1965817421341671]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457370510832253		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 2.2457370510832253 | validation: 1.1810875559379388]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2450585813793387		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 2.2450585813793387 | validation: 1.1917367942434558]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248713662932768		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 2.248713662932768 | validation: 1.1928628021543035]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464490303971454		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 2.2464490303971454 | validation: 1.1929271812131854]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244692517333763		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 2.244692517333763 | validation: 1.1865482240415954]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2481471977545997		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 2.2481471977545997 | validation: 1.1892756085812144]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2485144403284387		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 2.2485144403284387 | validation: 1.1894550373535198]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2465675161136685		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 2.2465675161136685 | validation: 1.1904375188920802]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2468067586674323		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 2.2468067586674323 | validation: 1.1911953211432202]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2469425056732257		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 2.2469425056732257 | validation: 1.1891511492124656]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2489341642412524		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 2.2489341642412524 | validation: 1.1879497456497015]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2463199453695024		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 2.2463199453695024 | validation: 1.1889351109747257]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245694510685264		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 2.245694510685264 | validation: 1.2007377757910962]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2476711543925045		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 2.2476711543925045 | validation: 1.1887343293406603]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2488645248355335		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 2.2488645248355335 | validation: 1.193351480475915]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247803165806734		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 2.247803165806734 | validation: 1.1997338705969824]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245915305761809		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 2.245915305761809 | validation: 1.1952094901111359]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2451649405837433		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 2.2451649405837433 | validation: 1.1879622671985786]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2458591215312103		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 2.2458591215312103 | validation: 1.1889851592220504]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2449507433088653		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 2.2449507433088653 | validation: 1.1860698527265456]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243160223030109		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 2.243160223030109 | validation: 1.1802760036800317]
	TIME [epoch: 11.4 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2441410563241853		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 2.2441410563241853 | validation: 1.1963908675131474]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244867454281014		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 2.244867454281014 | validation: 1.1893976791581433]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2435311329655905		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 2.2435311329655905 | validation: 1.1969945419304273]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2440545328029335		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 2.2440545328029335 | validation: 1.1889652006429376]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247050345092778		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 2.247050345092778 | validation: 1.1849840341231046]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2444713039387847		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 2.2444713039387847 | validation: 1.187039386379396]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2466839720918776		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 2.2466839720918776 | validation: 1.191320774846072]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243923050052122		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 2.243923050052122 | validation: 1.1874065535524256]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.24012319369219		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 2.24012319369219 | validation: 1.2030845703886912]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2440855518611356		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 2.2440855518611356 | validation: 1.195335363136682]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245275357948857		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 2.245275357948857 | validation: 1.1856103592726333]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248684200249768		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 2.248684200249768 | validation: 1.1910263876518448]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464642802924915		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 2.2464642802924915 | validation: 1.1890150072415606]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2468742542324165		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 2.2468742542324165 | validation: 1.1839701869496637]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246175024846902		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 2.246175024846902 | validation: 1.1862376946258102]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243707346012821		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 2.243707346012821 | validation: 1.1872400168167558]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2467607072605036		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 2.2467607072605036 | validation: 1.1892358904496951]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247580832066835		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 2.247580832066835 | validation: 1.185767691721387]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242820338727		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 2.242820338727 | validation: 1.184376304515792]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247486886106421		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 2.247486886106421 | validation: 1.1907983714506944]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2442491796533828		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 2.2442491796533828 | validation: 1.1905614594349252]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244539257363222		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 2.244539257363222 | validation: 1.190461055006173]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2485303984210443		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 2.2485303984210443 | validation: 1.1908652420823962]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2449181138277092		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 2.2449181138277092 | validation: 1.1916905724797118]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245202107083447		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 2.245202107083447 | validation: 1.1978310785291435]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246791394616012		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 2.246791394616012 | validation: 1.1984865984259647]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2478467368459114		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 2.2478467368459114 | validation: 1.189786522450236]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455020843881783		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 2.2455020843881783 | validation: 1.194048364242533]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244197316291681		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 2.244197316291681 | validation: 1.1969210193531052]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2469132325728087		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 2.2469132325728087 | validation: 1.189060899839339]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2483658696910767		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 2.2483658696910767 | validation: 1.1855848396176756]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246716386502726		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 2.246716386502726 | validation: 1.1976330862527738]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2440185929713414		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 2.2440185929713414 | validation: 1.183045026188185]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249338751553152		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 2.249338751553152 | validation: 1.187832802119604]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243337151881424		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 2.243337151881424 | validation: 1.1858115976764523]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460934768331566		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 2.2460934768331566 | validation: 1.191643593899906]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246097854933383		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 2.246097854933383 | validation: 1.1892060621821388]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2477721107756867		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 2.2477721107756867 | validation: 1.1933061869628585]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2442056971443876		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 2.2442056971443876 | validation: 1.1999728092062751]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2450320311609917		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 2.2450320311609917 | validation: 1.1838243709867928]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464869206553795		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 2.2464869206553795 | validation: 1.1855305348842615]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247927228574822		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 2.247927228574822 | validation: 1.1908875536271422]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2479091089373404		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 2.2479091089373404 | validation: 1.2017966668016393]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460472856457336		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 2.2460472856457336 | validation: 1.191514729169033]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2504508699907952		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 2.2504508699907952 | validation: 1.1859493237056336]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2550886133495758		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 2.2550886133495758 | validation: 1.1914547135433322]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2516147031749076		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 2.2516147031749076 | validation: 1.1943139270417709]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2445462293544183		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 2.2445462293544183 | validation: 1.1836509715150123]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2418944314768794		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 2.2418944314768794 | validation: 1.185749358502414]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2465970905711616		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 2.2465970905711616 | validation: 1.1850686970133923]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2439389155357388		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 2.2439389155357388 | validation: 1.1944239485976373]
	TIME [epoch: 11.6 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2484124620903607		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 2.2484124620903607 | validation: 1.1945845835618563]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2469736652652372		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 2.2469736652652372 | validation: 1.1891686005880202]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244749643912715		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 2.244749643912715 | validation: 1.1915553766729425]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248129165495473		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 2.248129165495473 | validation: 1.1914378809927157]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245553866541314		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 2.245553866541314 | validation: 1.1872076755020486]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246779199583931		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 2.246779199583931 | validation: 1.1994959521036035]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244392219743582		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 2.244392219743582 | validation: 1.1971157613918817]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243931298663682		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 2.243931298663682 | validation: 1.185873386998076]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2447190361266007		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 2.2447190361266007 | validation: 1.1916376657712229]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246228456542769		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 2.246228456542769 | validation: 1.193692991053821]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2473701131776673		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 2.2473701131776673 | validation: 1.1859145291805406]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457548456586998		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 2.2457548456586998 | validation: 1.1922448266713896]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460187660752693		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 2.2460187660752693 | validation: 1.190526019199756]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243306060607769		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 2.243306060607769 | validation: 1.180939514552535]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246812006138688		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 2.246812006138688 | validation: 1.1971115221817568]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243494501657602		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 2.243494501657602 | validation: 1.1816671346285825]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2441055834412094		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 2.2441055834412094 | validation: 1.1906591036516485]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455376275925323		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 2.2455376275925323 | validation: 1.192074249454109]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242669058267917		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 2.242669058267917 | validation: 1.188281699942407]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246457481743181		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 2.246457481743181 | validation: 1.192546906713714]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245332094115872		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 2.245332094115872 | validation: 1.1902560176733463]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2431509373353036		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 2.2431509373353036 | validation: 1.1941487267748088]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243826252203983		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 2.243826252203983 | validation: 1.1914841784035497]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243954471063634		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 2.243954471063634 | validation: 1.1907265264531086]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245672095351717		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 2.245672095351717 | validation: 1.195265584259749]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245774811429915		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 2.245774811429915 | validation: 1.1949647139671915]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2463715923765357		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 2.2463715923765357 | validation: 1.1891634792446448]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2481768223706564		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 2.2481768223706564 | validation: 1.1816646638674027]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2450495546407367		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 2.2450495546407367 | validation: 1.1799664558910183]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2480607507388997		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 2.2480607507388997 | validation: 1.1921316189560094]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2451314553441004		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 2.2451314553441004 | validation: 1.1934485140507354]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472137178132003		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 2.2472137178132003 | validation: 1.189430864693852]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2442775470794927		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 2.2442775470794927 | validation: 1.1783628935735353]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464901499406413		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 2.2464901499406413 | validation: 1.187150523732999]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242953396536494		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 2.242953396536494 | validation: 1.1921725744785192]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247406680601344		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 2.247406680601344 | validation: 1.188935435451332]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2445743582728817		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 2.2445743582728817 | validation: 1.1900732340070557]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245605536972338		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 2.245605536972338 | validation: 1.1842963028550468]
	TIME [epoch: 11.4 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245460243681361		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 2.245460243681361 | validation: 1.1946079659016378]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243709540253228		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 2.243709540253228 | validation: 1.197706152295555]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245610125479904		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 2.245610125479904 | validation: 1.1921992711533254]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246191145996249		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 2.246191145996249 | validation: 1.191654309463067]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247505096359496		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 2.247505096359496 | validation: 1.1846059228815942]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245460491449946		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 2.245460491449946 | validation: 1.1925195979201209]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245207624438524		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 2.245207624438524 | validation: 1.190441161596343]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464941460498817		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 2.2464941460498817 | validation: 1.1819703797318488]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2452065289703502		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 2.2452065289703502 | validation: 1.1960183097136468]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2452257917181013		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 2.2452257917181013 | validation: 1.1878082385335713]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2447587337617487		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 2.2447587337617487 | validation: 1.1937940326312042]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242857690318305		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 2.242857690318305 | validation: 1.1833794784313691]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2451937921240157		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 2.2451937921240157 | validation: 1.1940885715138965]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2506338855350387		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 2.2506338855350387 | validation: 1.1934022224748282]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2418965857554074		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 2.2418965857554074 | validation: 1.1981114629863752]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246186246183017		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 2.246186246183017 | validation: 1.1911833456780776]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244898879610947		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 2.244898879610947 | validation: 1.1893979407563395]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244499820603445		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 2.244499820603445 | validation: 1.1890759249767962]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2461717090744333		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 2.2461717090744333 | validation: 1.1823141082895408]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2423597465563825		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 2.2423597465563825 | validation: 1.1872042250262598]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455172304959103		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 2.2455172304959103 | validation: 1.187261678522198]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.24833106584102		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 2.24833106584102 | validation: 1.1933640078581171]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2498408286588347		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 2.2498408286588347 | validation: 1.1902816165151375]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2434504977636274		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 2.2434504977636274 | validation: 1.1831719705575148]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243518692681626		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 2.243518692681626 | validation: 1.1867799932081255]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2454635371524283		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 2.2454635371524283 | validation: 1.1831440652494285]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2478891172322597		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 2.2478891172322597 | validation: 1.1853446396309044]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245728379204864		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 2.245728379204864 | validation: 1.1870691896756795]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247110162169414		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 2.247110162169414 | validation: 1.1854596432912934]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2493728150973427		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 2.2493728150973427 | validation: 1.1904591161566571]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2460389363334006		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 2.2460389363334006 | validation: 1.1897282921279266]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242628145359921		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 2.242628145359921 | validation: 1.187142893877324]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2486436415821442		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 2.2486436415821442 | validation: 1.1985957891773031]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2436241615529635		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 2.2436241615529635 | validation: 1.1888576891424227]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2436559516744		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 2.2436559516744 | validation: 1.1779763303364978]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245164002911383		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 2.245164002911383 | validation: 1.1902861099739759]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244669770994256		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 2.244669770994256 | validation: 1.1884206934620098]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2475997957120857		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 2.2475997957120857 | validation: 1.1934241269172612]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246733652799656		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 2.246733652799656 | validation: 1.1904163000116808]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2450510624089235		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 2.2450510624089235 | validation: 1.186029631033781]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246616244599104		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 2.246616244599104 | validation: 1.1962164201469403]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248268166145843		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 2.248268166145843 | validation: 1.1906438865642013]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2462389882035927		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 2.2462389882035927 | validation: 1.1969517869431692]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2485923289246807		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 2.2485923289246807 | validation: 1.193080095806595]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247636649730417		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 2.247636649730417 | validation: 1.1994836337638617]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242632110374994		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 2.242632110374994 | validation: 1.183769749333039]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246559271543961		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 2.246559271543961 | validation: 1.1988275003032258]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245133368351049		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 2.245133368351049 | validation: 1.1905686468984522]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2485056079515173		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 2.2485056079515173 | validation: 1.191312661438384]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2427762823433905		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 2.2427762823433905 | validation: 1.192173068674444]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249701688278026		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 2.249701688278026 | validation: 1.184709712784269]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2461243338085017		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 2.2461243338085017 | validation: 1.1932415556284313]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472421071351603		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 2.2472421071351603 | validation: 1.1980476143241117]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248844000901995		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 2.248844000901995 | validation: 1.1937709761095172]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2470458921563607		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 2.2470458921563607 | validation: 1.1878004480298656]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245957457902176		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 2.245957457902176 | validation: 1.1822808311749546]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2466472449283987		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 2.2466472449283987 | validation: 1.1913091607510284]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242987142458511		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 2.242987142458511 | validation: 1.1874495820313817]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247030173007821		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 2.247030173007821 | validation: 1.182638655835536]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2442821010570104		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 2.2442821010570104 | validation: 1.1903932033777558]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243838756003513		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 2.243838756003513 | validation: 1.1957620824524038]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2462035149098107		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 2.2462035149098107 | validation: 1.1915993255303776]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243892859719588		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 2.243892859719588 | validation: 1.1858310137978643]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2450336987074784		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 2.2450336987074784 | validation: 1.1817277391135474]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2420021706894		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 2.2420021706894 | validation: 1.1898205330147644]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248697140708856		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 2.248697140708856 | validation: 1.189302770334609]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2441611456816215		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 2.2441611456816215 | validation: 1.1899719134975617]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455353180071422		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 2.2455353180071422 | validation: 1.1843515842845804]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247551219682511		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 2.247551219682511 | validation: 1.1843573723749043]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2452732658428904		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 2.2452732658428904 | validation: 1.1858802062796736]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2436040478834647		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 2.2436040478834647 | validation: 1.1848795537791275]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2481998025762766		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 2.2481998025762766 | validation: 1.19113516369988]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455412258034424		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 2.2455412258034424 | validation: 1.1858608841607103]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246558112745207		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 2.246558112745207 | validation: 1.1982871261596508]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245521543237157		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 2.245521543237157 | validation: 1.1930331127689666]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243450682629287		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 2.243450682629287 | validation: 1.19529630043111]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242593810525298		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 2.242593810525298 | validation: 1.1864870238231582]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2424342399534893		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 2.2424342399534893 | validation: 1.1818643078179165]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2448124981206936		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 2.2448124981206936 | validation: 1.188497589763239]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2445412889441227		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 2.2445412889441227 | validation: 1.1846671869173282]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243401434885765		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 2.243401434885765 | validation: 1.185489524488068]
	TIME [epoch: 11.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2472834394338053		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 2.2472834394338053 | validation: 1.1863529136124238]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2459596665629413		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 2.2459596665629413 | validation: 1.1909097470275891]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2488483886913633		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 2.2488483886913633 | validation: 1.1927329489670024]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2452818054240575		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 2.2452818054240575 | validation: 1.1893557747586263]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248953401014042		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 2.248953401014042 | validation: 1.1857733457874298]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247084795091343		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 2.247084795091343 | validation: 1.193860785611376]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2443100399094136		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 2.2443100399094136 | validation: 1.1830875709347262]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2474474507584237		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 2.2474474507584237 | validation: 1.1861076589637782]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2458007495919894		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 2.2458007495919894 | validation: 1.1856966575938404]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244668978087276		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 2.244668978087276 | validation: 1.1946270646476296]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2439328647408487		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 2.2439328647408487 | validation: 1.1838307078364796]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245383162712131		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 2.245383162712131 | validation: 1.1873423899153606]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2483133756918683		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 2.2483133756918683 | validation: 1.1857301449819024]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247546403201401		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 2.247546403201401 | validation: 1.1826169588525433]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246496957224451		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 2.246496957224451 | validation: 1.1861424305605197]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245851440856229		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 2.245851440856229 | validation: 1.1951592098952284]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2452756855633598		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 2.2452756855633598 | validation: 1.1870604051593288]
	TIME [epoch: 11.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2431696924056816		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 2.2431696924056816 | validation: 1.1837809669434232]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.241746362044473		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 2.241746362044473 | validation: 1.1832394819511571]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2456675431018587		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 2.2456675431018587 | validation: 1.1889203538053443]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2428402161450665		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 2.2428402161450665 | validation: 1.1899091097104528]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2457694871315605		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 2.2457694871315605 | validation: 1.1865480481326582]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2467456002878285		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 2.2467456002878285 | validation: 1.1873029209157868]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245092526420679		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 2.245092526420679 | validation: 1.1894549747359082]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243978404709383		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 2.243978404709383 | validation: 1.1981606920595087]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242193897256963		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 2.242193897256963 | validation: 1.1815042458947356]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247242815011241		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 2.247242815011241 | validation: 1.1937073878950526]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244918615147694		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 2.244918615147694 | validation: 1.1898101156146257]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2449159013370528		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 2.2449159013370528 | validation: 1.1867330770267406]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2458055006877675		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 2.2458055006877675 | validation: 1.1909434252436182]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246343083665164		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 2.246343083665164 | validation: 1.1841790310543885]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2461655815249273		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 2.2461655815249273 | validation: 1.1913541030595534]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2461941463693247		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 2.2461941463693247 | validation: 1.1924927614686263]
	TIME [epoch: 11.5 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.240756310830565		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 2.240756310830565 | validation: 1.1826773494122502]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2429836043054556		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 2.2429836043054556 | validation: 1.185200020481077]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2425786866470103		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 2.2425786866470103 | validation: 1.190013335985145]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2451071361156703		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 2.2451071361156703 | validation: 1.1927328636938952]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2449641644993394		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 2.2449641644993394 | validation: 1.1860346014808423]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244215247545173		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 2.244215247545173 | validation: 1.1902951804638595]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245570514525254		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 2.245570514525254 | validation: 1.1852104453454992]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2437201665847875		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 2.2437201665847875 | validation: 1.1948402953318256]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2446892429120595		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 2.2446892429120595 | validation: 1.1906798024537437]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2449438854488717		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 2.2449438854488717 | validation: 1.1907788356384603]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244954699030628		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 2.244954699030628 | validation: 1.1887433948766002]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242542020845601		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 2.242542020845601 | validation: 1.1906735973579226]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2489143996079664		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 2.2489143996079664 | validation: 1.1917730107955773]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2447860654171974		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 2.2447860654171974 | validation: 1.1879690841971162]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464686041879274		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 2.2464686041879274 | validation: 1.18967129329178]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2453992779038012		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 2.2453992779038012 | validation: 1.1912486229306236]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2482168942089156		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 2.2482168942089156 | validation: 1.197334452802757]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244394149534962		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 2.244394149534962 | validation: 1.193635563973042]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243909503590794		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 2.243909503590794 | validation: 1.188759781863871]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248187410924741		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 2.248187410924741 | validation: 1.1896925941604302]
	TIME [epoch: 11.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.241322138505968		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 2.241322138505968 | validation: 1.1857525623055658]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2456288357654737		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 2.2456288357654737 | validation: 1.195873489984853]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243433849237231		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 2.243433849237231 | validation: 1.1887529107391703]
	TIME [epoch: 11.6 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2467234478822937		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 2.2467234478822937 | validation: 1.1900972163858983]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2450222026381628		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 2.2450222026381628 | validation: 1.192344447936325]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2468239816163367		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 2.2468239816163367 | validation: 1.1853828045945982]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2458788539366825		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 2.2458788539366825 | validation: 1.1789288452927837]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2465412336635042		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 2.2465412336635042 | validation: 1.1865724607223236]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455044469834142		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 2.2455044469834142 | validation: 1.1921864603785606]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246712269335766		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 2.246712269335766 | validation: 1.1931777691151186]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245169939956482		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 2.245169939956482 | validation: 1.1865082010779768]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2423923672858783		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 2.2423923672858783 | validation: 1.1922405539985377]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243995310882395		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 2.243995310882395 | validation: 1.1885305688808125]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2476578298335004		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 2.2476578298335004 | validation: 1.1856279889889367]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242742690551029		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 2.242742690551029 | validation: 1.1878855858626765]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2446925136974323		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 2.2446925136974323 | validation: 1.1904539235004423]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248649715786317		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 2.248649715786317 | validation: 1.1946154183017288]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2445147281003752		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 2.2445147281003752 | validation: 1.1903253452436031]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2429979488721767		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 2.2429979488721767 | validation: 1.1863862862635326]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2432271814235434		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 2.2432271814235434 | validation: 1.1940552240337683]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2413201154533366		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 2.2413201154533366 | validation: 1.1933975563746584]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2464932578349597		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 2.2464932578349597 | validation: 1.1883393324805858]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2455507111882187		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 2.2455507111882187 | validation: 1.1891563512467438]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.251345770945198		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 2.251345770945198 | validation: 1.192026423188077]
	TIME [epoch: 11.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2466067927601747		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 2.2466067927601747 | validation: 1.189515054460084]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242763719146752		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 2.242763719146752 | validation: 1.1940953840635995]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2417850876378704		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 2.2417850876378704 | validation: 1.1927136040394677]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243716942009622		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 2.243716942009622 | validation: 1.1909702726582654]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244568224107356		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 2.244568224107356 | validation: 1.193187194939244]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2456426525555475		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 2.2456426525555475 | validation: 1.1848627210151288]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243795477266337		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 2.243795477266337 | validation: 1.1885334220463708]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2442660142652207		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 2.2442660142652207 | validation: 1.1892370948107813]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2461398523839984		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 2.2461398523839984 | validation: 1.1826261348455427]
	TIME [epoch: 11.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2458355149698206		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 2.2458355149698206 | validation: 1.1921845834395788]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2486004141344065		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 2.2486004141344065 | validation: 1.1878047982845732]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2401009581425764		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 2.2401009581425764 | validation: 1.1880753149537058]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2450583289408055		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 2.2450583289408055 | validation: 1.1900353562462216]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.247667971658199		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 2.247667971658199 | validation: 1.1837685455100695]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2413714003202188		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 2.2413714003202188 | validation: 1.194113242755476]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2425356486323906		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 2.2425356486323906 | validation: 1.1914547897537349]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244560547121126		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 2.244560547121126 | validation: 1.1890145742499045]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245703952177732		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 2.245703952177732 | validation: 1.1857532970652185]
	TIME [epoch: 11.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2477248554742215		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 2.2477248554742215 | validation: 1.1948490539048007]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.238810950040728		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 2.238810950040728 | validation: 1.1864301888647224]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2471117813978085		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 2.2471117813978085 | validation: 1.189330966113423]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2440243947203085		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 2.2440243947203085 | validation: 1.1901188880825582]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2443996007310583		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 2.2443996007310583 | validation: 1.189917700419811]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2440016160766367		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 2.2440016160766367 | validation: 1.191190391917662]
	TIME [epoch: 11.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242338065526225		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 2.242338065526225 | validation: 1.1858555784765625]
	TIME [epoch: 11.5 sec]
Finished training in 23219.248 seconds.
