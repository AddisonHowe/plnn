Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r1', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2202600033

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.522580431267297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.522580431267297 | validation: 12.326238890990563]
	TIME [epoch: 54.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.250589390915739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.250589390915739 | validation: 11.844540856947432]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.676276610015819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.676276610015819 | validation: 10.6494553455592]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.445179746805453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.445179746805453 | validation: 9.37858596397407]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.655136357731642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.655136357731642 | validation: 8.42777009567631]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.265511187215484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.265511187215484 | validation: 8.450245872808273]
	TIME [epoch: 9.76 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.698470418872722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.698470418872722 | validation: 7.107588547171463]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.898474154850088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.898474154850088 | validation: 7.671662776731121]
	TIME [epoch: 9.72 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.291328687042823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.291328687042823 | validation: 6.275078441751291]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.916151076117868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.916151076117868 | validation: 6.370284003789196]
	TIME [epoch: 9.76 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.528162114659262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.528162114659262 | validation: 6.4518748966066815]
	TIME [epoch: 9.73 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6625272774482225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6625272774482225 | validation: 5.624670645291312]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.3220202108378984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3220202108378984 | validation: 5.916367351988287]
	TIME [epoch: 9.75 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.813209381805514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.813209381805514 | validation: 5.333209373529606]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.708361498845857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.708361498845857 | validation: 5.154715558868962]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.812640707638664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.812640707638664 | validation: 6.247634978569228]
	TIME [epoch: 9.74 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.929258095073397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.929258095073397 | validation: 6.947729476569498]
	TIME [epoch: 9.75 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.163157497161896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.163157497161896 | validation: 5.26134685727553]
	TIME [epoch: 9.73 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.586344444459465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.586344444459465 | validation: 6.125836415310572]
	TIME [epoch: 9.72 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.76138004065005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.76138004065005 | validation: 4.989232059683489]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.541976105853644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.541976105853644 | validation: 4.747283681892405]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.245583186648162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.245583186648162 | validation: 5.103360530168103]
	TIME [epoch: 9.74 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.23932150247363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.23932150247363 | validation: 4.595498982798676]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.946747480622167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.946747480622167 | validation: 4.5702583998515145]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.932782843814368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.932782843814368 | validation: 4.258606290095128]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.2135446314250755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2135446314250755 | validation: 4.452821233035406]
	TIME [epoch: 9.73 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7071149563617425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7071149563617425 | validation: 4.088373156091446]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.372942289496382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.372942289496382 | validation: 4.329559175615562]
	TIME [epoch: 9.75 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.472448310022981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.472448310022981 | validation: 3.6496446959133237]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.459562380705106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.459562380705106 | validation: 3.919754445091643]
	TIME [epoch: 9.73 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.253987881813275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.253987881813275 | validation: 6.015857365921506]
	TIME [epoch: 9.74 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.770276494258509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.770276494258509 | validation: 3.912251756499929]
	TIME [epoch: 9.72 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.154236239191838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.154236239191838 | validation: 3.7967182780939983]
	TIME [epoch: 9.73 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.348813462606293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.348813462606293 | validation: 3.7085863695957637]
	TIME [epoch: 9.74 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.977683452390342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.977683452390342 | validation: 3.590962621100493]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.083673033759505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.083673033759505 | validation: 3.23144195297224]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8899803347711464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8899803347711464 | validation: 5.0708616252827134]
	TIME [epoch: 9.72 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.120533327066931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.120533327066931 | validation: 4.102626838914865]
	TIME [epoch: 9.74 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.23529310588623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.23529310588623 | validation: 4.84959102915166]
	TIME [epoch: 9.73 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.335452903956539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.335452903956539 | validation: 4.263528709060069]
	TIME [epoch: 9.73 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.389423845642116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.389423845642116 | validation: 3.52501261341304]
	TIME [epoch: 9.75 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.0072752826875995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0072752826875995 | validation: 3.2861421006498466]
	TIME [epoch: 9.73 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.203130225602541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.203130225602541 | validation: 4.512592177137472]
	TIME [epoch: 9.74 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.314975573174135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.314975573174135 | validation: 3.2592974456600587]
	TIME [epoch: 9.72 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.435685604807684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.435685604807684 | validation: 4.260692914956439]
	TIME [epoch: 9.74 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.300263433171235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.300263433171235 | validation: 4.00044001921437]
	TIME [epoch: 9.72 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.913543247180158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.913543247180158 | validation: 3.6944854862766783]
	TIME [epoch: 9.72 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9367534887489164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9367534887489164 | validation: 3.466972289570315]
	TIME [epoch: 9.73 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.73494055232347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.73494055232347 | validation: 3.628701630716818]
	TIME [epoch: 9.73 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.09382674260115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.09382674260115 | validation: 3.1396840557833765]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7751875272921014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7751875272921014 | validation: 4.773214840434736]
	TIME [epoch: 9.72 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.502779800208684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.502779800208684 | validation: 3.915594901179428]
	TIME [epoch: 9.75 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2846058329750925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2846058329750925 | validation: 3.581802485047761]
	TIME [epoch: 9.72 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7268276583175792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7268276583175792 | validation: 4.794975277141557]
	TIME [epoch: 9.72 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.057937880259816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.057937880259816 | validation: 3.167499608252575]
	TIME [epoch: 9.74 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.911635555910968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.911635555910968 | validation: 4.028913596907781]
	TIME [epoch: 9.74 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.202531628585932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.202531628585932 | validation: 4.038327334898834]
	TIME [epoch: 9.73 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8560868283378875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8560868283378875 | validation: 3.035939968316651]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6784576200866512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6784576200866512 | validation: 3.2920971261026764]
	TIME [epoch: 9.75 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.613632841873888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.613632841873888 | validation: 3.207613560903833]
	TIME [epoch: 9.72 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.174820142976255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.174820142976255 | validation: 3.7746307485212682]
	TIME [epoch: 9.72 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.862246140508052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.862246140508052 | validation: 3.4552060700901386]
	TIME [epoch: 9.72 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7996509046854583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7996509046854583 | validation: 2.9363749134312185]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.447780333994909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.447780333994909 | validation: 3.2300486678158156]
	TIME [epoch: 9.74 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.769358460096729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.769358460096729 | validation: 5.943950089864311]
	TIME [epoch: 9.74 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.631145024333335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.631145024333335 | validation: 3.167276744623012]
	TIME [epoch: 9.75 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9233057166465577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9233057166465577 | validation: 4.312001328260853]
	TIME [epoch: 9.73 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.20891633778704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.20891633778704 | validation: 3.4097367464666304]
	TIME [epoch: 9.73 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9395206830874288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9395206830874288 | validation: 4.059753069295472]
	TIME [epoch: 9.73 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9853178873732356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9853178873732356 | validation: 3.175716324356451]
	TIME [epoch: 9.75 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6402282810184827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6402282810184827 | validation: 3.4151125071166533]
	TIME [epoch: 9.74 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.554966622424307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.554966622424307 | validation: 3.2527452610135983]
	TIME [epoch: 9.73 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.522576411727365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.522576411727365 | validation: 3.223690746965323]
	TIME [epoch: 9.75 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.001979755318574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.001979755318574 | validation: 3.4587066760382066]
	TIME [epoch: 9.73 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.596604579858451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.596604579858451 | validation: 3.0753314649821006]
	TIME [epoch: 9.73 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.60921523119827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.60921523119827 | validation: 2.9053462964920573]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4401329730192836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4401329730192836 | validation: 3.228990666926801]
	TIME [epoch: 9.74 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.665488259650085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.665488259650085 | validation: 2.7957411079244867]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5567443515571378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5567443515571378 | validation: 2.8244242761149123]
	TIME [epoch: 9.72 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.669336812725819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.669336812725819 | validation: 2.709999616273675]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.139984373073611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.139984373073611 | validation: 4.263560986916063]
	TIME [epoch: 9.72 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.008525914899463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.008525914899463 | validation: 2.815697367234333]
	TIME [epoch: 9.72 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5388217604960737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5388217604960737 | validation: 2.9237312719491944]
	TIME [epoch: 9.71 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3883353905822426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3883353905822426 | validation: 3.0599885492730268]
	TIME [epoch: 9.72 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.99408378557846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.99408378557846 | validation: 4.094114441487155]
	TIME [epoch: 9.71 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.948772933126886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.948772933126886 | validation: 2.7640776529239077]
	TIME [epoch: 9.72 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.235946394025609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.235946394025609 | validation: 4.268571655029303]
	TIME [epoch: 9.72 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.03518894284821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.03518894284821 | validation: 2.9281198574775495]
	TIME [epoch: 9.73 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6458835030106194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6458835030106194 | validation: 4.421162512464413]
	TIME [epoch: 9.72 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.886616391082188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.886616391082188 | validation: 2.8065662841909593]
	TIME [epoch: 9.72 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.386688918886189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.386688918886189 | validation: 3.252551492853554]
	TIME [epoch: 9.73 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.323724648776769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.323724648776769 | validation: 3.901342278244233]
	TIME [epoch: 9.71 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.936038352266178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.936038352266178 | validation: 2.9272255669850984]
	TIME [epoch: 9.71 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.779943380701404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.779943380701404 | validation: 2.8557446695075077]
	TIME [epoch: 9.71 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.513374161703338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.513374161703338 | validation: 3.133341216168202]
	TIME [epoch: 9.73 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4273892432321538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4273892432321538 | validation: 3.779690388791374]
	TIME [epoch: 9.71 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.51308605297197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.51308605297197 | validation: 3.143444060559709]
	TIME [epoch: 9.72 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.433716512509875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.433716512509875 | validation: 3.040295251515272]
	TIME [epoch: 9.72 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.296109123407921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.296109123407921 | validation: 2.8132262511059376]
	TIME [epoch: 9.72 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.483543976021738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.483543976021738 | validation: 2.663095848340287]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4472368431902654		[learning rate: 0.009971]
	Learning Rate: 0.00997096
	LOSS [training: 3.4472368431902654 | validation: 3.055287755928158]
	TIME [epoch: 9.72 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.316669677440706		[learning rate: 0.0099348]
	Learning Rate: 0.00993477
	LOSS [training: 3.316669677440706 | validation: 3.0997321109542026]
	TIME [epoch: 9.75 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3953838907645584		[learning rate: 0.0098987]
	Learning Rate: 0.00989872
	LOSS [training: 3.3953838907645584 | validation: 3.3328518981776223]
	TIME [epoch: 9.72 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1683302791238255		[learning rate: 0.0098628]
	Learning Rate: 0.00986279
	LOSS [training: 4.1683302791238255 | validation: 4.116251538240954]
	TIME [epoch: 9.72 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.607224827355035		[learning rate: 0.009827]
	Learning Rate: 0.009827
	LOSS [training: 4.607224827355035 | validation: 3.595579762121239]
	TIME [epoch: 9.74 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6885485647097425		[learning rate: 0.0097913]
	Learning Rate: 0.00979134
	LOSS [training: 3.6885485647097425 | validation: 2.710221055181832]
	TIME [epoch: 9.73 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3968143739131555		[learning rate: 0.0097558]
	Learning Rate: 0.00975581
	LOSS [training: 3.3968143739131555 | validation: 2.9155120350909103]
	TIME [epoch: 9.72 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.350335052347435		[learning rate: 0.0097204]
	Learning Rate: 0.0097204
	LOSS [training: 3.350335052347435 | validation: 2.7194106718332542]
	TIME [epoch: 9.73 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2723475102195714		[learning rate: 0.0096851]
	Learning Rate: 0.00968513
	LOSS [training: 3.2723475102195714 | validation: 3.557965091438711]
	TIME [epoch: 9.74 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4114912637997215		[learning rate: 0.00965]
	Learning Rate: 0.00964998
	LOSS [training: 3.4114912637997215 | validation: 2.93775038354367]
	TIME [epoch: 9.73 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.366507221708935		[learning rate: 0.009615]
	Learning Rate: 0.00961496
	LOSS [training: 3.366507221708935 | validation: 3.306517690651834]
	TIME [epoch: 9.72 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.330258201194526		[learning rate: 0.0095801]
	Learning Rate: 0.00958006
	LOSS [training: 3.330258201194526 | validation: 2.8327555281265915]
	TIME [epoch: 9.73 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2926903468729902		[learning rate: 0.0095453]
	Learning Rate: 0.0095453
	LOSS [training: 3.2926903468729902 | validation: 3.2262881188728865]
	TIME [epoch: 9.74 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.334443028831015		[learning rate: 0.0095107]
	Learning Rate: 0.00951066
	LOSS [training: 3.334443028831015 | validation: 2.8049398555963707]
	TIME [epoch: 9.72 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2721392141857804		[learning rate: 0.0094761]
	Learning Rate: 0.00947614
	LOSS [training: 3.2721392141857804 | validation: 3.991911594618946]
	TIME [epoch: 9.73 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4808666304044613		[learning rate: 0.0094418]
	Learning Rate: 0.00944175
	LOSS [training: 3.4808666304044613 | validation: 3.067733329948588]
	TIME [epoch: 9.74 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.210229017144498		[learning rate: 0.0094075]
	Learning Rate: 0.00940749
	LOSS [training: 3.210229017144498 | validation: 2.686602497616308]
	TIME [epoch: 9.73 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2113078793564895		[learning rate: 0.0093733]
	Learning Rate: 0.00937335
	LOSS [training: 3.2113078793564895 | validation: 4.395539610377656]
	TIME [epoch: 9.73 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4607554334445005		[learning rate: 0.0093393]
	Learning Rate: 0.00933933
	LOSS [training: 3.4607554334445005 | validation: 3.7162510226380756]
	TIME [epoch: 9.73 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3985220726873955		[learning rate: 0.0093054]
	Learning Rate: 0.00930544
	LOSS [training: 3.3985220726873955 | validation: 2.9154650031459277]
	TIME [epoch: 9.74 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.129373586494223		[learning rate: 0.0092717]
	Learning Rate: 0.00927167
	LOSS [training: 3.129373586494223 | validation: 2.86255759713061]
	TIME [epoch: 9.73 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3229552767849126		[learning rate: 0.009238]
	Learning Rate: 0.00923802
	LOSS [training: 3.3229552767849126 | validation: 2.532168113600955]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.494962395711852		[learning rate: 0.0092045]
	Learning Rate: 0.0092045
	LOSS [training: 3.494962395711852 | validation: 3.663056224183616]
	TIME [epoch: 9.73 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3579455899424433		[learning rate: 0.0091711]
	Learning Rate: 0.00917109
	LOSS [training: 3.3579455899424433 | validation: 3.1345175500318945]
	TIME [epoch: 9.72 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.31202299697066		[learning rate: 0.0091378]
	Learning Rate: 0.00913781
	LOSS [training: 3.31202299697066 | validation: 3.134278725978547]
	TIME [epoch: 9.72 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.291227345848372		[learning rate: 0.0091046]
	Learning Rate: 0.00910465
	LOSS [training: 3.291227345848372 | validation: 2.627099422920805]
	TIME [epoch: 9.72 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2024056703380213		[learning rate: 0.0090716]
	Learning Rate: 0.00907161
	LOSS [training: 3.2024056703380213 | validation: 2.4137204101149274]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1196865256205597		[learning rate: 0.0090387]
	Learning Rate: 0.00903868
	LOSS [training: 3.1196865256205597 | validation: 3.060028596581692]
	TIME [epoch: 9.72 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1789191890629347		[learning rate: 0.0090059]
	Learning Rate: 0.00900588
	LOSS [training: 3.1789191890629347 | validation: 2.4772857085313196]
	TIME [epoch: 9.72 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0907869335169544		[learning rate: 0.0089732]
	Learning Rate: 0.0089732
	LOSS [training: 3.0907869335169544 | validation: 2.718735673821839]
	TIME [epoch: 9.73 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.101840827002186		[learning rate: 0.0089406]
	Learning Rate: 0.00894064
	LOSS [training: 3.101840827002186 | validation: 2.5103642730613407]
	TIME [epoch: 9.72 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2318744740234564		[learning rate: 0.0089082]
	Learning Rate: 0.00890819
	LOSS [training: 3.2318744740234564 | validation: 2.635374987896245]
	TIME [epoch: 9.72 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.051008513075974		[learning rate: 0.0088759]
	Learning Rate: 0.00887586
	LOSS [training: 3.051008513075974 | validation: 2.5045459682777094]
	TIME [epoch: 9.72 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.113002410486972		[learning rate: 0.0088437]
	Learning Rate: 0.00884365
	LOSS [training: 3.113002410486972 | validation: 3.23998128208153]
	TIME [epoch: 9.73 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0560558493790757		[learning rate: 0.0088116]
	Learning Rate: 0.00881156
	LOSS [training: 3.0560558493790757 | validation: 2.3615734185229273]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.28188717745194		[learning rate: 0.0087796]
	Learning Rate: 0.00877958
	LOSS [training: 3.28188717745194 | validation: 4.0112301348168]
	TIME [epoch: 9.71 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.436340181166858		[learning rate: 0.0087477]
	Learning Rate: 0.00874772
	LOSS [training: 3.436340181166858 | validation: 2.6326060831910136]
	TIME [epoch: 9.73 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.052151540538598		[learning rate: 0.008716]
	Learning Rate: 0.00871597
	LOSS [training: 3.052151540538598 | validation: 4.8274042955388925]
	TIME [epoch: 9.71 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.068611645000895		[learning rate: 0.0086843]
	Learning Rate: 0.00868434
	LOSS [training: 4.068611645000895 | validation: 2.537544447094161]
	TIME [epoch: 9.71 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5621934497926295		[learning rate: 0.0086528]
	Learning Rate: 0.00865282
	LOSS [training: 3.5621934497926295 | validation: 3.8069869086756474]
	TIME [epoch: 9.71 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3922210563753494		[learning rate: 0.0086214]
	Learning Rate: 0.00862142
	LOSS [training: 3.3922210563753494 | validation: 3.452018933196907]
	TIME [epoch: 9.73 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1436082187239327		[learning rate: 0.0085901]
	Learning Rate: 0.00859013
	LOSS [training: 3.1436082187239327 | validation: 2.6790471623959444]
	TIME [epoch: 9.71 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.432361396176192		[learning rate: 0.008559]
	Learning Rate: 0.00855896
	LOSS [training: 3.432361396176192 | validation: 2.807622480752619]
	TIME [epoch: 9.71 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6375894660850605		[learning rate: 0.0085279]
	Learning Rate: 0.0085279
	LOSS [training: 3.6375894660850605 | validation: 3.7910890853938555]
	TIME [epoch: 9.71 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6038102212459164		[learning rate: 0.008497]
	Learning Rate: 0.00849695
	LOSS [training: 3.6038102212459164 | validation: 2.5596919365969812]
	TIME [epoch: 9.73 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3000164168100534		[learning rate: 0.0084661]
	Learning Rate: 0.00846612
	LOSS [training: 3.3000164168100534 | validation: 3.3730431732302852]
	TIME [epoch: 9.71 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.398209040064562		[learning rate: 0.0084354]
	Learning Rate: 0.00843539
	LOSS [training: 3.398209040064562 | validation: 4.0496698684142585]
	TIME [epoch: 9.71 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9236058075149822		[learning rate: 0.0084048]
	Learning Rate: 0.00840478
	LOSS [training: 3.9236058075149822 | validation: 2.9258647767445787]
	TIME [epoch: 9.73 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.034484759644326		[learning rate: 0.0083743]
	Learning Rate: 0.00837428
	LOSS [training: 3.034484759644326 | validation: 2.6238586289302623]
	TIME [epoch: 9.71 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2018942648340074		[learning rate: 0.0083439]
	Learning Rate: 0.00834389
	LOSS [training: 3.2018942648340074 | validation: 2.3531173952838818]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0725384311565582		[learning rate: 0.0083136]
	Learning Rate: 0.00831361
	LOSS [training: 3.0725384311565582 | validation: 2.4130302828835046]
	TIME [epoch: 9.71 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9222333104265075		[learning rate: 0.0082834]
	Learning Rate: 0.00828344
	LOSS [training: 2.9222333104265075 | validation: 3.104367325437055]
	TIME [epoch: 9.72 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1541077489751093		[learning rate: 0.0082534]
	Learning Rate: 0.00825338
	LOSS [training: 3.1541077489751093 | validation: 2.7385317646048066]
	TIME [epoch: 9.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.960218069654222		[learning rate: 0.0082234]
	Learning Rate: 0.00822342
	LOSS [training: 2.960218069654222 | validation: 3.122997105744423]
	TIME [epoch: 9.71 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.561856715662496		[learning rate: 0.0081936]
	Learning Rate: 0.00819358
	LOSS [training: 3.561856715662496 | validation: 2.3729140421237225]
	TIME [epoch: 9.72 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.132939827816611		[learning rate: 0.0081638]
	Learning Rate: 0.00816384
	LOSS [training: 3.132939827816611 | validation: 2.2056875288991984]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6128533119730966		[learning rate: 0.0081342]
	Learning Rate: 0.00813422
	LOSS [training: 3.6128533119730966 | validation: 3.12595913210952]
	TIME [epoch: 9.71 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3976569213491374		[learning rate: 0.0081047]
	Learning Rate: 0.0081047
	LOSS [training: 3.3976569213491374 | validation: 2.831942623914366]
	TIME [epoch: 9.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.296468351566271		[learning rate: 0.0080753]
	Learning Rate: 0.00807529
	LOSS [training: 3.296468351566271 | validation: 3.3193389923013856]
	TIME [epoch: 9.73 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3835232937042092		[learning rate: 0.008046]
	Learning Rate: 0.00804598
	LOSS [training: 3.3835232937042092 | validation: 2.339601945097941]
	TIME [epoch: 9.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0436542962141435		[learning rate: 0.0080168]
	Learning Rate: 0.00801678
	LOSS [training: 3.0436542962141435 | validation: 2.4756246192746345]
	TIME [epoch: 9.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9007968865653457		[learning rate: 0.0079877]
	Learning Rate: 0.00798769
	LOSS [training: 2.9007968865653457 | validation: 2.897684209076717]
	TIME [epoch: 9.71 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.489573133092969		[learning rate: 0.0079587]
	Learning Rate: 0.0079587
	LOSS [training: 3.489573133092969 | validation: 2.7688176528546347]
	TIME [epoch: 9.72 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0509861232672377		[learning rate: 0.0079298]
	Learning Rate: 0.00792982
	LOSS [training: 3.0509861232672377 | validation: 3.0441309792918174]
	TIME [epoch: 9.71 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.19573546022288		[learning rate: 0.007901]
	Learning Rate: 0.00790104
	LOSS [training: 3.19573546022288 | validation: 2.5412488910731867]
	TIME [epoch: 9.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.950040454740058		[learning rate: 0.0078724]
	Learning Rate: 0.00787237
	LOSS [training: 2.950040454740058 | validation: 2.3338472320664168]
	TIME [epoch: 9.73 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.835490673951562		[learning rate: 0.0078438]
	Learning Rate: 0.0078438
	LOSS [training: 2.835490673951562 | validation: 2.5176987372020476]
	TIME [epoch: 9.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7860283006818145		[learning rate: 0.0078153]
	Learning Rate: 0.00781533
	LOSS [training: 2.7860283006818145 | validation: 2.514548909078915]
	TIME [epoch: 9.71 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9074592115596873		[learning rate: 0.007787]
	Learning Rate: 0.00778697
	LOSS [training: 2.9074592115596873 | validation: 2.1758051925201243]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2233935096141892		[learning rate: 0.0077587]
	Learning Rate: 0.00775871
	LOSS [training: 3.2233935096141892 | validation: 4.262168474620047]
	TIME [epoch: 9.74 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.493666380325989		[learning rate: 0.0077306]
	Learning Rate: 0.00773055
	LOSS [training: 3.493666380325989 | validation: 2.1806069596154964]
	TIME [epoch: 9.71 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2101530563543137		[learning rate: 0.0077025]
	Learning Rate: 0.0077025
	LOSS [training: 3.2101530563543137 | validation: 4.537302808848325]
	TIME [epoch: 9.72 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.824602447058818		[learning rate: 0.0076745]
	Learning Rate: 0.00767455
	LOSS [training: 3.824602447058818 | validation: 2.4514858706965756]
	TIME [epoch: 9.73 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2267854177676085		[learning rate: 0.0076467]
	Learning Rate: 0.00764669
	LOSS [training: 3.2267854177676085 | validation: 3.5500024138164954]
	TIME [epoch: 9.71 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4057745439769227		[learning rate: 0.0076189]
	Learning Rate: 0.00761894
	LOSS [training: 3.4057745439769227 | validation: 2.5795387672433607]
	TIME [epoch: 9.72 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.314837579362373		[learning rate: 0.0075913]
	Learning Rate: 0.00759129
	LOSS [training: 3.314837579362373 | validation: 3.2088626554022674]
	TIME [epoch: 9.72 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2464093289443907		[learning rate: 0.0075637]
	Learning Rate: 0.00756374
	LOSS [training: 3.2464093289443907 | validation: 2.2771075446965123]
	TIME [epoch: 9.74 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0641658118908324		[learning rate: 0.0075363]
	Learning Rate: 0.00753629
	LOSS [training: 3.0641658118908324 | validation: 2.85504438102816]
	TIME [epoch: 9.71 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9465598001973685		[learning rate: 0.0075089]
	Learning Rate: 0.00750895
	LOSS [training: 2.9465598001973685 | validation: 2.541346619643608]
	TIME [epoch: 9.72 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.45127816562792		[learning rate: 0.0074817]
	Learning Rate: 0.00748169
	LOSS [training: 3.45127816562792 | validation: 2.237723744702622]
	TIME [epoch: 9.73 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.159339463278237		[learning rate: 0.0074545]
	Learning Rate: 0.00745454
	LOSS [training: 3.159339463278237 | validation: 3.6303465276205773]
	TIME [epoch: 9.73 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5423918786637936		[learning rate: 0.0074275]
	Learning Rate: 0.00742749
	LOSS [training: 3.5423918786637936 | validation: 2.332467769912162]
	TIME [epoch: 9.72 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1327260312591845		[learning rate: 0.0074005]
	Learning Rate: 0.00740054
	LOSS [training: 3.1327260312591845 | validation: 2.8256105847156254]
	TIME [epoch: 9.72 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.174687217486629		[learning rate: 0.0073737]
	Learning Rate: 0.00737368
	LOSS [training: 3.174687217486629 | validation: 2.353330526309475]
	TIME [epoch: 9.74 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0950037617953243		[learning rate: 0.0073469]
	Learning Rate: 0.00734692
	LOSS [training: 3.0950037617953243 | validation: 2.5975795556488923]
	TIME [epoch: 9.72 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.018443976151017		[learning rate: 0.0073203]
	Learning Rate: 0.00732026
	LOSS [training: 3.018443976151017 | validation: 2.2214990346500647]
	TIME [epoch: 9.73 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8687006069676704		[learning rate: 0.0072937]
	Learning Rate: 0.00729369
	LOSS [training: 2.8687006069676704 | validation: 2.456731826190562]
	TIME [epoch: 9.73 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9127853510098283		[learning rate: 0.0072672]
	Learning Rate: 0.00726722
	LOSS [training: 2.9127853510098283 | validation: 2.1280885134312983]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0779819794863594		[learning rate: 0.0072408]
	Learning Rate: 0.00724085
	LOSS [training: 3.0779819794863594 | validation: 3.458574068114458]
	TIME [epoch: 9.73 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.269220781339059		[learning rate: 0.0072146]
	Learning Rate: 0.00721457
	LOSS [training: 3.269220781339059 | validation: 2.328554867130143]
	TIME [epoch: 9.72 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.00502816217194		[learning rate: 0.0071884]
	Learning Rate: 0.00718839
	LOSS [training: 3.00502816217194 | validation: 4.307349034248385]
	TIME [epoch: 9.72 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7400965435045443		[learning rate: 0.0071623]
	Learning Rate: 0.0071623
	LOSS [training: 3.7400965435045443 | validation: 2.4626733355762425]
	TIME [epoch: 9.72 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8747950531000708		[learning rate: 0.0071363]
	Learning Rate: 0.00713631
	LOSS [training: 2.8747950531000708 | validation: 2.307713854017352]
	TIME [epoch: 9.72 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7952664862855574		[learning rate: 0.0071104]
	Learning Rate: 0.00711041
	LOSS [training: 2.7952664862855574 | validation: 2.5652325808488223]
	TIME [epoch: 9.73 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7661150640489187		[learning rate: 0.0070846]
	Learning Rate: 0.00708461
	LOSS [training: 2.7661150640489187 | validation: 2.96461600548368]
	TIME [epoch: 9.75 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.82058178933476		[learning rate: 0.0070589]
	Learning Rate: 0.0070589
	LOSS [training: 2.82058178933476 | validation: 2.6564102894223054]
	TIME [epoch: 9.73 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7602899449094567		[learning rate: 0.0070333]
	Learning Rate: 0.00703328
	LOSS [training: 2.7602899449094567 | validation: 3.573567759205247]
	TIME [epoch: 9.74 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.736304828873741		[learning rate: 0.0070078]
	Learning Rate: 0.00700776
	LOSS [training: 3.736304828873741 | validation: 2.278678316528454]
	TIME [epoch: 9.74 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3112197428236776		[learning rate: 0.0069823]
	Learning Rate: 0.00698232
	LOSS [training: 3.3112197428236776 | validation: 2.9916908396556425]
	TIME [epoch: 9.72 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.900483178185717		[learning rate: 0.006957]
	Learning Rate: 0.00695698
	LOSS [training: 2.900483178185717 | validation: 2.5012539593591856]
	TIME [epoch: 9.72 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.097547140919082		[learning rate: 0.0069317]
	Learning Rate: 0.00693174
	LOSS [training: 3.097547140919082 | validation: 2.1991076738676587]
	TIME [epoch: 9.73 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.188353804072295		[learning rate: 0.0069066]
	Learning Rate: 0.00690658
	LOSS [training: 3.188353804072295 | validation: 2.913062037555479]
	TIME [epoch: 9.75 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.181255399529637		[learning rate: 0.0068815]
	Learning Rate: 0.00688152
	LOSS [training: 3.181255399529637 | validation: 2.353655405322766]
	TIME [epoch: 9.73 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.834900751335505		[learning rate: 0.0068565]
	Learning Rate: 0.00685654
	LOSS [training: 2.834900751335505 | validation: 2.3165427391982907]
	TIME [epoch: 9.71 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1230840009237952		[learning rate: 0.0068317]
	Learning Rate: 0.00683166
	LOSS [training: 3.1230840009237952 | validation: 2.341960920154246]
	TIME [epoch: 9.73 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.987617646958949		[learning rate: 0.0068069]
	Learning Rate: 0.00680687
	LOSS [training: 2.987617646958949 | validation: 3.2930886120403713]
	TIME [epoch: 9.72 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.428377164686888		[learning rate: 0.0067822]
	Learning Rate: 0.00678217
	LOSS [training: 3.428377164686888 | validation: 2.3403781108803816]
	TIME [epoch: 9.72 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.264309397669815		[learning rate: 0.0067576]
	Learning Rate: 0.00675755
	LOSS [training: 3.264309397669815 | validation: 2.3380725271613483]
	TIME [epoch: 9.71 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7173859859264295		[learning rate: 0.006733]
	Learning Rate: 0.00673303
	LOSS [training: 2.7173859859264295 | validation: 2.273930894005804]
	TIME [epoch: 9.75 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.912943017387935		[learning rate: 0.0067086]
	Learning Rate: 0.00670859
	LOSS [training: 2.912943017387935 | validation: 3.0387368262410495]
	TIME [epoch: 9.73 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1544249308284362		[learning rate: 0.0066842]
	Learning Rate: 0.00668425
	LOSS [training: 3.1544249308284362 | validation: 2.84140700946007]
	TIME [epoch: 9.72 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1747058497832663		[learning rate: 0.00666]
	Learning Rate: 0.00665999
	LOSS [training: 3.1747058497832663 | validation: 2.3008162432696815]
	TIME [epoch: 9.73 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.896788440614808		[learning rate: 0.0066358]
	Learning Rate: 0.00663582
	LOSS [training: 2.896788440614808 | validation: 2.9737344365943277]
	TIME [epoch: 9.74 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.024333734316718		[learning rate: 0.0066117]
	Learning Rate: 0.00661174
	LOSS [training: 3.024333734316718 | validation: 2.582308499653349]
	TIME [epoch: 9.71 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.909136273782102		[learning rate: 0.0065877]
	Learning Rate: 0.00658775
	LOSS [training: 2.909136273782102 | validation: 2.183430786106698]
	TIME [epoch: 9.72 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9491811531955716		[learning rate: 0.0065638]
	Learning Rate: 0.00656384
	LOSS [training: 2.9491811531955716 | validation: 2.619483748945846]
	TIME [epoch: 9.73 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.900967448316119		[learning rate: 0.00654]
	Learning Rate: 0.00654002
	LOSS [training: 2.900967448316119 | validation: 2.1765795840089264]
	TIME [epoch: 9.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.95878280256945		[learning rate: 0.0065163]
	Learning Rate: 0.00651628
	LOSS [training: 2.95878280256945 | validation: 2.6095682320477125]
	TIME [epoch: 9.72 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7670748684484163		[learning rate: 0.0064926]
	Learning Rate: 0.00649264
	LOSS [training: 2.7670748684484163 | validation: 2.742631999964694]
	TIME [epoch: 9.72 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7957192719511026		[learning rate: 0.0064691]
	Learning Rate: 0.00646907
	LOSS [training: 2.7957192719511026 | validation: 2.583289242164417]
	TIME [epoch: 9.74 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.761317999263351		[learning rate: 0.0064456]
	Learning Rate: 0.0064456
	LOSS [training: 2.761317999263351 | validation: 2.373174583254153]
	TIME [epoch: 9.72 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9858130287977938		[learning rate: 0.0064222]
	Learning Rate: 0.00642221
	LOSS [training: 2.9858130287977938 | validation: 2.248088383239324]
	TIME [epoch: 9.73 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0313394698337954		[learning rate: 0.0063989]
	Learning Rate: 0.0063989
	LOSS [training: 3.0313394698337954 | validation: 2.4222447647865013]
	TIME [epoch: 9.74 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0823085831523818		[learning rate: 0.0063757]
	Learning Rate: 0.00637568
	LOSS [training: 3.0823085831523818 | validation: 2.172544124241039]
	TIME [epoch: 9.72 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8040219719718165		[learning rate: 0.0063525]
	Learning Rate: 0.00635254
	LOSS [training: 2.8040219719718165 | validation: 3.0191465101424217]
	TIME [epoch: 9.72 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.891289826827967		[learning rate: 0.0063295]
	Learning Rate: 0.00632949
	LOSS [training: 2.891289826827967 | validation: 3.087543758233894]
	TIME [epoch: 9.71 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0178666646247305		[learning rate: 0.0063065]
	Learning Rate: 0.00630652
	LOSS [training: 3.0178666646247305 | validation: 2.3149606239471012]
	TIME [epoch: 9.73 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.768583985425842		[learning rate: 0.0062836]
	Learning Rate: 0.00628363
	LOSS [training: 2.768583985425842 | validation: 2.2264586173521645]
	TIME [epoch: 9.72 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7858348403284316		[learning rate: 0.0062608]
	Learning Rate: 0.00626082
	LOSS [training: 2.7858348403284316 | validation: 2.4358303624025646]
	TIME [epoch: 9.73 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7738233209491696		[learning rate: 0.0062381]
	Learning Rate: 0.0062381
	LOSS [training: 2.7738233209491696 | validation: 2.699925920353077]
	TIME [epoch: 9.73 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.75720779213728		[learning rate: 0.0062155]
	Learning Rate: 0.00621547
	LOSS [training: 2.75720779213728 | validation: 2.7366682971632317]
	TIME [epoch: 9.73 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.793480438310057		[learning rate: 0.0061929]
	Learning Rate: 0.00619291
	LOSS [training: 2.793480438310057 | validation: 2.0951975152870386]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.822486117973346		[learning rate: 0.0061704]
	Learning Rate: 0.00617043
	LOSS [training: 2.822486117973346 | validation: 4.631187562018758]
	TIME [epoch: 9.72 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.636300432486241		[learning rate: 0.006148]
	Learning Rate: 0.00614804
	LOSS [training: 3.636300432486241 | validation: 2.217711328337684]
	TIME [epoch: 9.74 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8701543187792713		[learning rate: 0.0061257]
	Learning Rate: 0.00612573
	LOSS [training: 2.8701543187792713 | validation: 4.804107271228104]
	TIME [epoch: 9.73 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5186871171815026		[learning rate: 0.0061035]
	Learning Rate: 0.0061035
	LOSS [training: 3.5186871171815026 | validation: 2.214677363029929]
	TIME [epoch: 9.72 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.154697034589015		[learning rate: 0.0060814]
	Learning Rate: 0.00608135
	LOSS [training: 3.154697034589015 | validation: 2.686493411646635]
	TIME [epoch: 9.73 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.954926746595448		[learning rate: 0.0060593]
	Learning Rate: 0.00605928
	LOSS [training: 2.954926746595448 | validation: 2.162197055140643]
	TIME [epoch: 9.73 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8215283467800587		[learning rate: 0.0060373]
	Learning Rate: 0.00603729
	LOSS [training: 2.8215283467800587 | validation: 2.661792115741732]
	TIME [epoch: 9.73 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7533778402539575		[learning rate: 0.0060154]
	Learning Rate: 0.00601538
	LOSS [training: 2.7533778402539575 | validation: 2.301509604095307]
	TIME [epoch: 9.73 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6967709505500568		[learning rate: 0.0059936]
	Learning Rate: 0.00599355
	LOSS [training: 2.6967709505500568 | validation: 3.0603226789673017]
	TIME [epoch: 9.74 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.103914717068087		[learning rate: 0.0059718]
	Learning Rate: 0.0059718
	LOSS [training: 3.103914717068087 | validation: 2.2397974229827136]
	TIME [epoch: 9.71 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1448888204112206		[learning rate: 0.0059501]
	Learning Rate: 0.00595013
	LOSS [training: 3.1448888204112206 | validation: 2.703996412276863]
	TIME [epoch: 9.72 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7408574241464434		[learning rate: 0.0059285]
	Learning Rate: 0.00592853
	LOSS [training: 2.7408574241464434 | validation: 2.960911966047011]
	TIME [epoch: 9.72 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7736519016977517		[learning rate: 0.005907]
	Learning Rate: 0.00590702
	LOSS [training: 2.7736519016977517 | validation: 2.07490551686799]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6479486590943013		[learning rate: 0.0058856]
	Learning Rate: 0.00588558
	LOSS [training: 2.6479486590943013 | validation: 2.730806481586075]
	TIME [epoch: 9.95 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.910323072342772		[learning rate: 0.0058642]
	Learning Rate: 0.00586422
	LOSS [training: 2.910323072342772 | validation: 2.3111816035969004]
	TIME [epoch: 9.73 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6737685570028837		[learning rate: 0.0058429]
	Learning Rate: 0.00584294
	LOSS [training: 2.6737685570028837 | validation: 2.2996714606308477]
	TIME [epoch: 9.74 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.737758048292659		[learning rate: 0.0058217]
	Learning Rate: 0.00582174
	LOSS [training: 2.737758048292659 | validation: 2.31845619009905]
	TIME [epoch: 9.73 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8876619365176874		[learning rate: 0.0058006]
	Learning Rate: 0.00580061
	LOSS [training: 2.8876619365176874 | validation: 2.884156088732124]
	TIME [epoch: 9.73 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0628967339207693		[learning rate: 0.0057796]
	Learning Rate: 0.00577956
	LOSS [training: 3.0628967339207693 | validation: 2.1469955779991587]
	TIME [epoch: 9.73 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7423280426381926		[learning rate: 0.0057586]
	Learning Rate: 0.00575859
	LOSS [training: 2.7423280426381926 | validation: 2.15304417984641]
	TIME [epoch: 9.75 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8365427081828773		[learning rate: 0.0057377]
	Learning Rate: 0.00573769
	LOSS [training: 2.8365427081828773 | validation: 3.3596085575326415]
	TIME [epoch: 9.73 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.045392468557172		[learning rate: 0.0057169]
	Learning Rate: 0.00571686
	LOSS [training: 3.045392468557172 | validation: 2.3996779857262562]
	TIME [epoch: 9.73 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6875815525234765		[learning rate: 0.0056961]
	Learning Rate: 0.00569612
	LOSS [training: 2.6875815525234765 | validation: 2.4109311426401443]
	TIME [epoch: 9.74 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7245055011096335		[learning rate: 0.0056754]
	Learning Rate: 0.00567545
	LOSS [training: 2.7245055011096335 | validation: 2.3723953674093132]
	TIME [epoch: 9.74 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7243155947347732		[learning rate: 0.0056548]
	Learning Rate: 0.00565485
	LOSS [training: 2.7243155947347732 | validation: 2.167123092100204]
	TIME [epoch: 9.73 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6695376042304013		[learning rate: 0.0056343]
	Learning Rate: 0.00563433
	LOSS [training: 2.6695376042304013 | validation: 2.1398405881083726]
	TIME [epoch: 9.72 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7091004179716167		[learning rate: 0.0056139]
	Learning Rate: 0.00561388
	LOSS [training: 2.7091004179716167 | validation: 3.211800062417325]
	TIME [epoch: 9.74 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0146923154422987		[learning rate: 0.0055935]
	Learning Rate: 0.00559351
	LOSS [training: 3.0146923154422987 | validation: 2.1294678901542063]
	TIME [epoch: 9.73 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7950802350803126		[learning rate: 0.0055732]
	Learning Rate: 0.00557321
	LOSS [training: 2.7950802350803126 | validation: 2.5098844585712894]
	TIME [epoch: 9.72 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8261683061338156		[learning rate: 0.005553]
	Learning Rate: 0.00555298
	LOSS [training: 2.8261683061338156 | validation: 2.1820528526663554]
	TIME [epoch: 9.74 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6920696015784795		[learning rate: 0.0055328]
	Learning Rate: 0.00553283
	LOSS [training: 2.6920696015784795 | validation: 2.8996435330357917]
	TIME [epoch: 9.73 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8976771265215886		[learning rate: 0.0055128]
	Learning Rate: 0.00551275
	LOSS [training: 2.8976771265215886 | validation: 2.2462991168469717]
	TIME [epoch: 9.73 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.719280843648325		[learning rate: 0.0054927]
	Learning Rate: 0.00549274
	LOSS [training: 2.719280843648325 | validation: 2.0304620786617766]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6686278799687373		[learning rate: 0.0054728]
	Learning Rate: 0.00547281
	LOSS [training: 2.6686278799687373 | validation: 2.168558600140757]
	TIME [epoch: 9.75 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.695009901518136		[learning rate: 0.005453]
	Learning Rate: 0.00545295
	LOSS [training: 2.695009901518136 | validation: 2.122837260018784]
	TIME [epoch: 9.73 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.700638912625045		[learning rate: 0.0054332]
	Learning Rate: 0.00543316
	LOSS [training: 2.700638912625045 | validation: 2.184449384057911]
	TIME [epoch: 9.73 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6623752744195057		[learning rate: 0.0054134]
	Learning Rate: 0.00541344
	LOSS [training: 2.6623752744195057 | validation: 2.6691547650151732]
	TIME [epoch: 9.75 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.693485734460995		[learning rate: 0.0053938]
	Learning Rate: 0.0053938
	LOSS [training: 2.693485734460995 | validation: 2.1034930971380086]
	TIME [epoch: 9.74 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6324780823333755		[learning rate: 0.0053742]
	Learning Rate: 0.00537422
	LOSS [training: 2.6324780823333755 | validation: 2.6035779708636437]
	TIME [epoch: 9.73 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7328352503567976		[learning rate: 0.0053547]
	Learning Rate: 0.00535472
	LOSS [training: 2.7328352503567976 | validation: 2.1314609412984846]
	TIME [epoch: 9.75 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6266334741546276		[learning rate: 0.0053353]
	Learning Rate: 0.00533529
	LOSS [training: 2.6266334741546276 | validation: 2.4140822869450282]
	TIME [epoch: 9.74 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6450808167792497		[learning rate: 0.0053159]
	Learning Rate: 0.00531593
	LOSS [training: 2.6450808167792497 | validation: 2.6662278824231618]
	TIME [epoch: 9.73 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9392052390754957		[learning rate: 0.0052966]
	Learning Rate: 0.00529663
	LOSS [training: 2.9392052390754957 | validation: 2.0953682887659846]
	TIME [epoch: 9.73 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7136142756042503		[learning rate: 0.0052774]
	Learning Rate: 0.00527741
	LOSS [training: 2.7136142756042503 | validation: 3.2515245694622137]
	TIME [epoch: 9.75 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.978772108097029		[learning rate: 0.0052583]
	Learning Rate: 0.00525826
	LOSS [training: 2.978772108097029 | validation: 2.096316867261978]
	TIME [epoch: 9.73 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6137445378347053		[learning rate: 0.0052392]
	Learning Rate: 0.00523918
	LOSS [training: 2.6137445378347053 | validation: 2.3756516290793566]
	TIME [epoch: 9.73 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6307701288737193		[learning rate: 0.0052202]
	Learning Rate: 0.00522017
	LOSS [training: 2.6307701288737193 | validation: 2.1709170294164704]
	TIME [epoch: 9.75 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6848962925918145		[learning rate: 0.0052012]
	Learning Rate: 0.00520122
	LOSS [training: 2.6848962925918145 | validation: 2.7465661558939485]
	TIME [epoch: 9.73 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.718360157082908		[learning rate: 0.0051823]
	Learning Rate: 0.00518234
	LOSS [training: 2.718360157082908 | validation: 2.052287402436673]
	TIME [epoch: 9.73 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5617492583350745		[learning rate: 0.0051635]
	Learning Rate: 0.00516354
	LOSS [training: 2.5617492583350745 | validation: 2.114298866993823]
	TIME [epoch: 9.73 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.991741036234994		[learning rate: 0.0051448]
	Learning Rate: 0.0051448
	LOSS [training: 2.991741036234994 | validation: 2.0439272046295587]
	TIME [epoch: 9.75 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.686597467163795		[learning rate: 0.0051261]
	Learning Rate: 0.00512613
	LOSS [training: 2.686597467163795 | validation: 2.1775645098472167]
	TIME [epoch: 9.73 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.755521456159072		[learning rate: 0.0051075]
	Learning Rate: 0.00510753
	LOSS [training: 2.755521456159072 | validation: 2.3851807075383915]
	TIME [epoch: 9.73 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.696738391336118		[learning rate: 0.005089]
	Learning Rate: 0.00508899
	LOSS [training: 2.696738391336118 | validation: 2.1713860472880486]
	TIME [epoch: 9.75 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6496249218003642		[learning rate: 0.0050705]
	Learning Rate: 0.00507052
	LOSS [training: 2.6496249218003642 | validation: 3.5339476412416353]
	TIME [epoch: 9.73 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2799128914258637		[learning rate: 0.0050521]
	Learning Rate: 0.00505212
	LOSS [training: 3.2799128914258637 | validation: 3.0317163835088077]
	TIME [epoch: 9.73 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8724235241567895		[learning rate: 0.0050338]
	Learning Rate: 0.00503379
	LOSS [training: 2.8724235241567895 | validation: 2.0634515761601926]
	TIME [epoch: 9.74 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.676075098990332		[learning rate: 0.0050155]
	Learning Rate: 0.00501552
	LOSS [training: 2.676075098990332 | validation: 2.200775064605235]
	TIME [epoch: 9.73 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6313893968658393		[learning rate: 0.0049973]
	Learning Rate: 0.00499732
	LOSS [training: 2.6313893968658393 | validation: 2.1964174030398227]
	TIME [epoch: 9.73 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.726281071867679		[learning rate: 0.0049792]
	Learning Rate: 0.00497918
	LOSS [training: 2.726281071867679 | validation: 2.064149628369473]
	TIME [epoch: 9.73 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.531757490995229		[learning rate: 0.0049611]
	Learning Rate: 0.00496111
	LOSS [training: 2.531757490995229 | validation: 2.703276000106024]
	TIME [epoch: 9.74 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6748840509570475		[learning rate: 0.0049431]
	Learning Rate: 0.00494311
	LOSS [training: 2.6748840509570475 | validation: 2.482008297217044]
	TIME [epoch: 9.72 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8934740838664617		[learning rate: 0.0049252]
	Learning Rate: 0.00492517
	LOSS [training: 2.8934740838664617 | validation: 2.028989598260809]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0052898414397666		[learning rate: 0.0049073]
	Learning Rate: 0.00490729
	LOSS [training: 3.0052898414397666 | validation: 2.7613309204062775]
	TIME [epoch: 9.74 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8708417607078487		[learning rate: 0.0048895]
	Learning Rate: 0.00488948
	LOSS [training: 2.8708417607078487 | validation: 2.0358965020334407]
	TIME [epoch: 9.73 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6678360836878525		[learning rate: 0.0048717]
	Learning Rate: 0.00487174
	LOSS [training: 2.6678360836878525 | validation: 2.0292796031879257]
	TIME [epoch: 9.72 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.531936658049835		[learning rate: 0.0048541]
	Learning Rate: 0.00485406
	LOSS [training: 2.531936658049835 | validation: 2.096703761779066]
	TIME [epoch: 9.72 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5314852276542616		[learning rate: 0.0048364]
	Learning Rate: 0.00483645
	LOSS [training: 2.5314852276542616 | validation: 2.558592060886137]
	TIME [epoch: 9.73 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.599093123755874		[learning rate: 0.0048189]
	Learning Rate: 0.00481889
	LOSS [training: 2.599093123755874 | validation: 2.476002710033494]
	TIME [epoch: 9.71 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6233902705310177		[learning rate: 0.0048014]
	Learning Rate: 0.00480141
	LOSS [training: 2.6233902705310177 | validation: 2.34841124095976]
	TIME [epoch: 9.72 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.602413473335453		[learning rate: 0.004784]
	Learning Rate: 0.00478398
	LOSS [training: 2.602413473335453 | validation: 2.140407369593526]
	TIME [epoch: 9.74 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.678916417061603		[learning rate: 0.0047666]
	Learning Rate: 0.00476662
	LOSS [training: 2.678916417061603 | validation: 2.312463130593374]
	TIME [epoch: 9.72 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5884956959752636		[learning rate: 0.0047493]
	Learning Rate: 0.00474932
	LOSS [training: 2.5884956959752636 | validation: 1.9980612498011807]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.50190506757264		[learning rate: 0.0047321]
	Learning Rate: 0.00473209
	LOSS [training: 2.50190506757264 | validation: 2.303111588300831]
	TIME [epoch: 9.74 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7628313039775336		[learning rate: 0.0047149]
	Learning Rate: 0.00471491
	LOSS [training: 2.7628313039775336 | validation: 1.990509331817247]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6022965535349365		[learning rate: 0.0046978]
	Learning Rate: 0.0046978
	LOSS [training: 2.6022965535349365 | validation: 2.147712937781483]
	TIME [epoch: 9.72 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5505569663436445		[learning rate: 0.0046808]
	Learning Rate: 0.00468075
	LOSS [training: 2.5505569663436445 | validation: 2.0186542587981267]
	TIME [epoch: 9.72 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5222703028278306		[learning rate: 0.0046638]
	Learning Rate: 0.00466377
	LOSS [training: 2.5222703028278306 | validation: 2.0656194523635136]
	TIME [epoch: 9.75 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.560871121559108		[learning rate: 0.0046468]
	Learning Rate: 0.00464684
	LOSS [training: 2.560871121559108 | validation: 1.98137838997539]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.793086130817522		[learning rate: 0.00463]
	Learning Rate: 0.00462998
	LOSS [training: 2.793086130817522 | validation: 2.1422085722339546]
	TIME [epoch: 9.72 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.557591538173974		[learning rate: 0.0046132]
	Learning Rate: 0.00461318
	LOSS [training: 2.557591538173974 | validation: 2.348008367781723]
	TIME [epoch: 9.74 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.660976262694553		[learning rate: 0.0045964]
	Learning Rate: 0.00459643
	LOSS [training: 2.660976262694553 | validation: 2.008137360393976]
	TIME [epoch: 9.72 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.494543778075802		[learning rate: 0.0045798]
	Learning Rate: 0.00457975
	LOSS [training: 2.494543778075802 | validation: 2.4380415187084044]
	TIME [epoch: 9.73 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.594080380663037		[learning rate: 0.0045631]
	Learning Rate: 0.00456313
	LOSS [training: 2.594080380663037 | validation: 2.1933183715251654]
	TIME [epoch: 9.73 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5410361948547715		[learning rate: 0.0045466]
	Learning Rate: 0.00454657
	LOSS [training: 2.5410361948547715 | validation: 2.1582084815611338]
	TIME [epoch: 9.73 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.509008170156107		[learning rate: 0.0045301]
	Learning Rate: 0.00453007
	LOSS [training: 2.509008170156107 | validation: 2.038670722621447]
	TIME [epoch: 9.72 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.523918504478639		[learning rate: 0.0045136]
	Learning Rate: 0.00451363
	LOSS [training: 2.523918504478639 | validation: 2.1157237259438206]
	TIME [epoch: 9.72 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.573356550922721		[learning rate: 0.0044973]
	Learning Rate: 0.00449725
	LOSS [training: 2.573356550922721 | validation: 2.952463903358405]
	TIME [epoch: 9.74 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8561373459322787		[learning rate: 0.0044809]
	Learning Rate: 0.00448093
	LOSS [training: 2.8561373459322787 | validation: 2.042598078977114]
	TIME [epoch: 9.72 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.610649723508753		[learning rate: 0.0044647]
	Learning Rate: 0.00446467
	LOSS [training: 2.610649723508753 | validation: 2.111818116123962]
	TIME [epoch: 9.72 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.558821095527674		[learning rate: 0.0044485]
	Learning Rate: 0.00444847
	LOSS [training: 2.558821095527674 | validation: 2.2664684434720677]
	TIME [epoch: 9.73 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5649801525537193		[learning rate: 0.0044323]
	Learning Rate: 0.00443232
	LOSS [training: 2.5649801525537193 | validation: 2.156720065113877]
	TIME [epoch: 9.72 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5768035718669804		[learning rate: 0.0044162]
	Learning Rate: 0.00441624
	LOSS [training: 2.5768035718669804 | validation: 2.372706835884051]
	TIME [epoch: 9.71 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.745785151780948		[learning rate: 0.0044002]
	Learning Rate: 0.00440021
	LOSS [training: 2.745785151780948 | validation: 2.122342821838558]
	TIME [epoch: 9.72 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.204567566147625		[learning rate: 0.0043842]
	Learning Rate: 0.00438424
	LOSS [training: 3.204567566147625 | validation: 2.0195730457894965]
	TIME [epoch: 9.74 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.569496940245508		[learning rate: 0.0043683]
	Learning Rate: 0.00436833
	LOSS [training: 2.569496940245508 | validation: 2.329528873010538]
	TIME [epoch: 9.72 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.631726759246841		[learning rate: 0.0043525]
	Learning Rate: 0.00435248
	LOSS [training: 2.631726759246841 | validation: 1.965994939073583]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4993742766706597		[learning rate: 0.0043367]
	Learning Rate: 0.00433668
	LOSS [training: 2.4993742766706597 | validation: 2.172946510733322]
	TIME [epoch: 9.74 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5165726959527834		[learning rate: 0.0043209]
	Learning Rate: 0.00432095
	LOSS [training: 2.5165726959527834 | validation: 1.9531179625974369]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5456495527945577		[learning rate: 0.0043053]
	Learning Rate: 0.00430527
	LOSS [training: 2.5456495527945577 | validation: 2.0961635716518128]
	TIME [epoch: 9.72 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.530916008678795		[learning rate: 0.0042896]
	Learning Rate: 0.00428964
	LOSS [training: 2.530916008678795 | validation: 2.1306588618332056]
	TIME [epoch: 9.73 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.698520199654658		[learning rate: 0.0042741]
	Learning Rate: 0.00427407
	LOSS [training: 2.698520199654658 | validation: 2.030540191084505]
	TIME [epoch: 9.72 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8410349870257874		[learning rate: 0.0042586]
	Learning Rate: 0.00425856
	LOSS [training: 2.8410349870257874 | validation: 2.111391859816296]
	TIME [epoch: 9.71 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.493650468266548		[learning rate: 0.0042431]
	Learning Rate: 0.00424311
	LOSS [training: 2.493650468266548 | validation: 2.2310655834854765]
	TIME [epoch: 9.71 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5876519164099077		[learning rate: 0.0042277]
	Learning Rate: 0.00422771
	LOSS [training: 2.5876519164099077 | validation: 1.9247630279299737]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_337.pth
	Model improved!!!
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5386042073697275		[learning rate: 0.0042124]
	Learning Rate: 0.00421237
	LOSS [training: 2.5386042073697275 | validation: 1.9560797360327797]
	TIME [epoch: 9.73 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6564437251423443		[learning rate: 0.0041971]
	Learning Rate: 0.00419708
	LOSS [training: 2.6564437251423443 | validation: 2.2896284249740635]
	TIME [epoch: 9.72 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.559506871824242		[learning rate: 0.0041818]
	Learning Rate: 0.00418185
	LOSS [training: 2.559506871824242 | validation: 2.1435608132133903]
	TIME [epoch: 9.74 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4868249040488952		[learning rate: 0.0041667]
	Learning Rate: 0.00416667
	LOSS [training: 2.4868249040488952 | validation: 2.3187037619700126]
	TIME [epoch: 9.72 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6585434859407853		[learning rate: 0.0041516]
	Learning Rate: 0.00415155
	LOSS [training: 2.6585434859407853 | validation: 2.2727314239904555]
	TIME [epoch: 9.72 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.67454675058402		[learning rate: 0.0041365]
	Learning Rate: 0.00413649
	LOSS [training: 2.67454675058402 | validation: 2.022168618644711]
	TIME [epoch: 9.73 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.57790331229429		[learning rate: 0.0041215]
	Learning Rate: 0.00412147
	LOSS [training: 2.57790331229429 | validation: 2.370551713095194]
	TIME [epoch: 9.74 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.788055931177174		[learning rate: 0.0041065]
	Learning Rate: 0.00410652
	LOSS [training: 2.788055931177174 | validation: 2.1646806176633198]
	TIME [epoch: 9.72 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6423684103623115		[learning rate: 0.0040916]
	Learning Rate: 0.00409161
	LOSS [training: 2.6423684103623115 | validation: 1.9510206903054705]
	TIME [epoch: 9.72 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.667780132732882		[learning rate: 0.0040768]
	Learning Rate: 0.00407677
	LOSS [training: 2.667780132732882 | validation: 2.2352037296627394]
	TIME [epoch: 9.74 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.555298403094467		[learning rate: 0.004062]
	Learning Rate: 0.00406197
	LOSS [training: 2.555298403094467 | validation: 1.9606941141830692]
	TIME [epoch: 9.72 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8223439943900916		[learning rate: 0.0040472]
	Learning Rate: 0.00404723
	LOSS [training: 2.8223439943900916 | validation: 2.331636693657442]
	TIME [epoch: 9.72 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5193549150590604		[learning rate: 0.0040325]
	Learning Rate: 0.00403254
	LOSS [training: 2.5193549150590604 | validation: 2.07592901545763]
	TIME [epoch: 9.74 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.534861792180786		[learning rate: 0.0040179]
	Learning Rate: 0.00401791
	LOSS [training: 2.534861792180786 | validation: 2.014399316574632]
	TIME [epoch: 9.73 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.649422495849562		[learning rate: 0.0040033]
	Learning Rate: 0.00400333
	LOSS [training: 2.649422495849562 | validation: 2.168093706893816]
	TIME [epoch: 9.73 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.562676022245984		[learning rate: 0.0039888]
	Learning Rate: 0.0039888
	LOSS [training: 2.562676022245984 | validation: 2.241733747096404]
	TIME [epoch: 9.72 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.497851845305734		[learning rate: 0.0039743]
	Learning Rate: 0.00397432
	LOSS [training: 2.497851845305734 | validation: 2.0693132685051268]
	TIME [epoch: 9.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.544035173286712		[learning rate: 0.0039599]
	Learning Rate: 0.0039599
	LOSS [training: 2.544035173286712 | validation: 2.0362985217331517]
	TIME [epoch: 9.74 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.509611189873584		[learning rate: 0.0039455]
	Learning Rate: 0.00394553
	LOSS [training: 2.509611189873584 | validation: 2.1345860520847375]
	TIME [epoch: 9.73 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4452602440336895		[learning rate: 0.0039312]
	Learning Rate: 0.00393121
	LOSS [training: 2.4452602440336895 | validation: 2.4097496635620352]
	TIME [epoch: 9.75 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.512302416611352		[learning rate: 0.0039169]
	Learning Rate: 0.00391694
	LOSS [training: 2.512302416611352 | validation: 2.2480050424955103]
	TIME [epoch: 9.73 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5389094525178653		[learning rate: 0.0039027]
	Learning Rate: 0.00390273
	LOSS [training: 2.5389094525178653 | validation: 2.712358921453251]
	TIME [epoch: 9.73 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.893519058473074		[learning rate: 0.0038886]
	Learning Rate: 0.00388857
	LOSS [training: 2.893519058473074 | validation: 2.02081111931651]
	TIME [epoch: 9.75 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5195890976907536		[learning rate: 0.0038745]
	Learning Rate: 0.00387445
	LOSS [training: 2.5195890976907536 | validation: 2.756544002022433]
	TIME [epoch: 9.74 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7095777531551795		[learning rate: 0.0038604]
	Learning Rate: 0.00386039
	LOSS [training: 2.7095777531551795 | validation: 2.0072928535666335]
	TIME [epoch: 9.73 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.589385520252234		[learning rate: 0.0038464]
	Learning Rate: 0.00384638
	LOSS [training: 2.589385520252234 | validation: 2.1440505232503635]
	TIME [epoch: 9.74 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.505010920324457		[learning rate: 0.0038324]
	Learning Rate: 0.00383242
	LOSS [training: 2.505010920324457 | validation: 2.362115099302402]
	TIME [epoch: 9.76 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4932912980719997		[learning rate: 0.0038185]
	Learning Rate: 0.00381852
	LOSS [training: 2.4932912980719997 | validation: 2.0327102598549254]
	TIME [epoch: 9.74 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4741297936226667		[learning rate: 0.0038047]
	Learning Rate: 0.00380466
	LOSS [training: 2.4741297936226667 | validation: 2.58943354632051]
	TIME [epoch: 9.73 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5401349254263668		[learning rate: 0.0037909]
	Learning Rate: 0.00379085
	LOSS [training: 2.5401349254263668 | validation: 2.2886447960922722]
	TIME [epoch: 9.74 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.525980623356642		[learning rate: 0.0037771]
	Learning Rate: 0.00377709
	LOSS [training: 2.525980623356642 | validation: 1.965722778082908]
	TIME [epoch: 9.73 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6717111834025977		[learning rate: 0.0037634]
	Learning Rate: 0.00376339
	LOSS [training: 2.6717111834025977 | validation: 2.170774696661191]
	TIME [epoch: 9.72 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4862841131179327		[learning rate: 0.0037497]
	Learning Rate: 0.00374973
	LOSS [training: 2.4862841131179327 | validation: 2.3503637406747084]
	TIME [epoch: 9.74 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.576293489746964		[learning rate: 0.0037361]
	Learning Rate: 0.00373612
	LOSS [training: 2.576293489746964 | validation: 1.9336603543782644]
	TIME [epoch: 9.75 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5849274370261037		[learning rate: 0.0037226]
	Learning Rate: 0.00372256
	LOSS [training: 2.5849274370261037 | validation: 2.078584250167535]
	TIME [epoch: 9.73 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.540847471907819		[learning rate: 0.0037091]
	Learning Rate: 0.00370905
	LOSS [training: 2.540847471907819 | validation: 2.1103669994367515]
	TIME [epoch: 9.73 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4397240418737627		[learning rate: 0.0036956]
	Learning Rate: 0.00369559
	LOSS [training: 2.4397240418737627 | validation: 2.0988623640534394]
	TIME [epoch: 9.75 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5069347183411432		[learning rate: 0.0036822]
	Learning Rate: 0.00368218
	LOSS [training: 2.5069347183411432 | validation: 2.1493021784148527]
	TIME [epoch: 9.73 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.424813443437015		[learning rate: 0.0036688]
	Learning Rate: 0.00366882
	LOSS [training: 2.424813443437015 | validation: 1.9821773790030586]
	TIME [epoch: 9.73 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.503015012795366		[learning rate: 0.0036555]
	Learning Rate: 0.0036555
	LOSS [training: 2.503015012795366 | validation: 1.8968356006574056]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_377.pth
	Model improved!!!
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4723687204810547		[learning rate: 0.0036422]
	Learning Rate: 0.00364224
	LOSS [training: 2.4723687204810547 | validation: 1.91378631416132]
	TIME [epoch: 9.73 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.525346230973502		[learning rate: 0.003629]
	Learning Rate: 0.00362902
	LOSS [training: 2.525346230973502 | validation: 1.8947055089240052]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4778841902445246		[learning rate: 0.0036159]
	Learning Rate: 0.00361585
	LOSS [training: 2.4778841902445246 | validation: 1.9155971851858087]
	TIME [epoch: 9.73 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4403622750140364		[learning rate: 0.0036027]
	Learning Rate: 0.00360273
	LOSS [training: 2.4403622750140364 | validation: 2.423661191671979]
	TIME [epoch: 9.75 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6900033701438564		[learning rate: 0.0035897]
	Learning Rate: 0.00358965
	LOSS [training: 2.6900033701438564 | validation: 2.189802326785827]
	TIME [epoch: 9.73 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4646018857521454		[learning rate: 0.0035766]
	Learning Rate: 0.00357663
	LOSS [training: 2.4646018857521454 | validation: 2.1895803347650102]
	TIME [epoch: 9.73 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4668199242415403		[learning rate: 0.0035636]
	Learning Rate: 0.00356365
	LOSS [training: 2.4668199242415403 | validation: 2.005217911531104]
	TIME [epoch: 9.75 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.488052191271959		[learning rate: 0.0035507]
	Learning Rate: 0.00355072
	LOSS [training: 2.488052191271959 | validation: 1.991865565059449]
	TIME [epoch: 9.73 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5195488244399162		[learning rate: 0.0035378]
	Learning Rate: 0.00353783
	LOSS [training: 2.5195488244399162 | validation: 2.341858846407409]
	TIME [epoch: 9.73 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5793059401005456		[learning rate: 0.003525]
	Learning Rate: 0.00352499
	LOSS [training: 2.5793059401005456 | validation: 1.9609129211424468]
	TIME [epoch: 9.73 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5475188449011843		[learning rate: 0.0035122]
	Learning Rate: 0.0035122
	LOSS [training: 2.5475188449011843 | validation: 1.962754252265529]
	TIME [epoch: 9.74 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5167227817895665		[learning rate: 0.0034995]
	Learning Rate: 0.00349945
	LOSS [training: 2.5167227817895665 | validation: 2.62110389638232]
	TIME [epoch: 9.73 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6540771132372702		[learning rate: 0.0034868]
	Learning Rate: 0.00348675
	LOSS [training: 2.6540771132372702 | validation: 1.9424686436227883]
	TIME [epoch: 9.73 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6706160435218216		[learning rate: 0.0034741]
	Learning Rate: 0.0034741
	LOSS [training: 2.6706160435218216 | validation: 2.3009612188650617]
	TIME [epoch: 9.74 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.547140994821904		[learning rate: 0.0034615]
	Learning Rate: 0.00346149
	LOSS [training: 2.547140994821904 | validation: 1.981207371005386]
	TIME [epoch: 9.73 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.514881501878289		[learning rate: 0.0034489]
	Learning Rate: 0.00344893
	LOSS [training: 2.514881501878289 | validation: 2.06712467835179]
	TIME [epoch: 9.73 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5075495746285914		[learning rate: 0.0034364]
	Learning Rate: 0.00343641
	LOSS [training: 2.5075495746285914 | validation: 1.9431933312349703]
	TIME [epoch: 9.74 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4408199281269103		[learning rate: 0.0034239]
	Learning Rate: 0.00342394
	LOSS [training: 2.4408199281269103 | validation: 1.822604579802035]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_395.pth
	Model improved!!!
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2669826667299304		[learning rate: 0.0034115]
	Learning Rate: 0.00341152
	LOSS [training: 2.2669826667299304 | validation: 1.7634536925843123]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1630821836087377		[learning rate: 0.0033991]
	Learning Rate: 0.00339914
	LOSS [training: 2.1630821836087377 | validation: 1.878123454956002]
	TIME [epoch: 9.72 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.243865526461983		[learning rate: 0.0033868]
	Learning Rate: 0.0033868
	LOSS [training: 2.243865526461983 | validation: 1.7736447456667572]
	TIME [epoch: 9.74 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2491028667496575		[learning rate: 0.0033745]
	Learning Rate: 0.00337451
	LOSS [training: 2.2491028667496575 | validation: 1.853619897287107]
	TIME [epoch: 9.72 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2506231270657526		[learning rate: 0.0033623]
	Learning Rate: 0.00336226
	LOSS [training: 2.2506231270657526 | validation: 1.6740865145462136]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.298970816394575		[learning rate: 0.0033501]
	Learning Rate: 0.00335006
	LOSS [training: 2.298970816394575 | validation: 1.6287863767850674]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.241305865356691		[learning rate: 0.0033379]
	Learning Rate: 0.0033379
	LOSS [training: 2.241305865356691 | validation: 1.7747551657094014]
	TIME [epoch: 9.72 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1228195691820866		[learning rate: 0.0033258]
	Learning Rate: 0.00332579
	LOSS [training: 2.1228195691820866 | validation: 1.5708137116273582]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0914057519769726		[learning rate: 0.0033137]
	Learning Rate: 0.00331372
	LOSS [training: 2.0914057519769726 | validation: 1.701683990404951]
	TIME [epoch: 9.74 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0044423190738465		[learning rate: 0.0033017]
	Learning Rate: 0.00330169
	LOSS [training: 2.0044423190738465 | validation: 1.565357528583719]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9586788362900456		[learning rate: 0.0032897]
	Learning Rate: 0.00328971
	LOSS [training: 1.9586788362900456 | validation: 2.0033287922363248]
	TIME [epoch: 9.72 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.079004063766251		[learning rate: 0.0032778]
	Learning Rate: 0.00327777
	LOSS [training: 2.079004063766251 | validation: 1.5574296418003695]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.934495983681827		[learning rate: 0.0032659]
	Learning Rate: 0.00326588
	LOSS [training: 1.934495983681827 | validation: 1.7795937208913521]
	TIME [epoch: 9.73 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9166009004112143		[learning rate: 0.003254]
	Learning Rate: 0.00325403
	LOSS [training: 1.9166009004112143 | validation: 1.6935032748013725]
	TIME [epoch: 9.71 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5091530148923438		[learning rate: 0.0032422]
	Learning Rate: 0.00324222
	LOSS [training: 1.5091530148923438 | validation: 2.3056901477571903]
	TIME [epoch: 9.71 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6406684318425537		[learning rate: 0.0032305]
	Learning Rate: 0.00323045
	LOSS [training: 1.6406684318425537 | validation: 1.5921269106900844]
	TIME [epoch: 9.74 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5606408669844216		[learning rate: 0.0032187]
	Learning Rate: 0.00321873
	LOSS [training: 1.5606408669844216 | validation: 1.574286014988732]
	TIME [epoch: 9.73 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4108108002306536		[learning rate: 0.003207]
	Learning Rate: 0.00320705
	LOSS [training: 1.4108108002306536 | validation: 1.7824779078073039]
	TIME [epoch: 9.72 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5622127889018846		[learning rate: 0.0031954]
	Learning Rate: 0.00319541
	LOSS [training: 1.5622127889018846 | validation: 1.5594293105336419]
	TIME [epoch: 9.72 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5080498996951603		[learning rate: 0.0031838]
	Learning Rate: 0.00318381
	LOSS [training: 1.5080498996951603 | validation: 1.610835621465257]
	TIME [epoch: 9.71 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4256272532770924		[learning rate: 0.0031723]
	Learning Rate: 0.00317226
	LOSS [training: 1.4256272532770924 | validation: 1.7677937288001595]
	TIME [epoch: 9.71 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5313565866085717		[learning rate: 0.0031607]
	Learning Rate: 0.00316075
	LOSS [training: 1.5313565866085717 | validation: 1.5974805954803695]
	TIME [epoch: 9.71 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5285335078214288		[learning rate: 0.0031493]
	Learning Rate: 0.00314927
	LOSS [training: 1.5285335078214288 | validation: 1.8202436099258532]
	TIME [epoch: 9.72 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.481204529732009		[learning rate: 0.0031378]
	Learning Rate: 0.00313785
	LOSS [training: 1.481204529732009 | validation: 1.5066505219331014]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.676536092730517		[learning rate: 0.0031265]
	Learning Rate: 0.00312646
	LOSS [training: 1.676536092730517 | validation: 1.644009514164617]
	TIME [epoch: 9.71 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4266438211525496		[learning rate: 0.0031151]
	Learning Rate: 0.00311511
	LOSS [training: 1.4266438211525496 | validation: 1.5453304947035487]
	TIME [epoch: 9.73 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5341166360167453		[learning rate: 0.0031038]
	Learning Rate: 0.00310381
	LOSS [training: 1.5341166360167453 | validation: 1.7144556943712428]
	TIME [epoch: 9.71 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3929242175893928		[learning rate: 0.0030925]
	Learning Rate: 0.00309254
	LOSS [training: 1.3929242175893928 | validation: 1.6399000375035846]
	TIME [epoch: 9.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5661811142431021		[learning rate: 0.0030813]
	Learning Rate: 0.00308132
	LOSS [training: 1.5661811142431021 | validation: 1.8384851431391134]
	TIME [epoch: 9.71 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5033267036862945		[learning rate: 0.0030701]
	Learning Rate: 0.00307014
	LOSS [training: 1.5033267036862945 | validation: 1.5883922263895038]
	TIME [epoch: 9.73 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4098746604610877		[learning rate: 0.003059]
	Learning Rate: 0.003059
	LOSS [training: 1.4098746604610877 | validation: 1.9958949707814997]
	TIME [epoch: 9.71 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.507410944349008		[learning rate: 0.0030479]
	Learning Rate: 0.0030479
	LOSS [training: 1.507410944349008 | validation: 1.4324709969494342]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_427.pth
	Model improved!!!
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3570166200802039		[learning rate: 0.0030368]
	Learning Rate: 0.00303683
	LOSS [training: 1.3570166200802039 | validation: 1.5055098235148603]
	TIME [epoch: 9.73 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3355101083394398		[learning rate: 0.0030258]
	Learning Rate: 0.00302581
	LOSS [training: 1.3355101083394398 | validation: 1.5239785555083405]
	TIME [epoch: 9.95 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3623380764444994		[learning rate: 0.0030148]
	Learning Rate: 0.00301483
	LOSS [training: 1.3623380764444994 | validation: 1.4407245289225425]
	TIME [epoch: 9.73 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3585352306811271		[learning rate: 0.0030039]
	Learning Rate: 0.00300389
	LOSS [training: 1.3585352306811271 | validation: 1.53587981411111]
	TIME [epoch: 9.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.35299623467236		[learning rate: 0.002993]
	Learning Rate: 0.00299299
	LOSS [training: 1.35299623467236 | validation: 1.549586474086516]
	TIME [epoch: 9.73 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4357045743254335		[learning rate: 0.0029821]
	Learning Rate: 0.00298213
	LOSS [training: 1.4357045743254335 | validation: 1.8200618045345593]
	TIME [epoch: 9.73 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4489061708319324		[learning rate: 0.0029713]
	Learning Rate: 0.00297131
	LOSS [training: 1.4489061708319324 | validation: 1.336083272860036]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3762846439720495		[learning rate: 0.0029605]
	Learning Rate: 0.00296052
	LOSS [training: 1.3762846439720495 | validation: 1.3161943978313604]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3685067609005988		[learning rate: 0.0029498]
	Learning Rate: 0.00294978
	LOSS [training: 1.3685067609005988 | validation: 1.6995102673548383]
	TIME [epoch: 9.72 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5202217382868186		[learning rate: 0.0029391]
	Learning Rate: 0.00293907
	LOSS [training: 1.5202217382868186 | validation: 1.4519910991160654]
	TIME [epoch: 9.72 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3244692771829778		[learning rate: 0.0029284]
	Learning Rate: 0.00292841
	LOSS [training: 1.3244692771829778 | validation: 1.664723800387715]
	TIME [epoch: 9.75 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.510442133463944		[learning rate: 0.0029178]
	Learning Rate: 0.00291778
	LOSS [training: 1.510442133463944 | validation: 1.3066646292527413]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.305013488283965		[learning rate: 0.0029072]
	Learning Rate: 0.00290719
	LOSS [training: 1.305013488283965 | validation: 1.4048964229046152]
	TIME [epoch: 9.73 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4095653316381167		[learning rate: 0.0028966]
	Learning Rate: 0.00289664
	LOSS [training: 1.4095653316381167 | validation: 1.411376582594205]
	TIME [epoch: 9.74 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.365641020297334		[learning rate: 0.0028861]
	Learning Rate: 0.00288613
	LOSS [training: 1.365641020297334 | validation: 1.2611501520437565]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4075341734191458		[learning rate: 0.0028757]
	Learning Rate: 0.00287566
	LOSS [training: 1.4075341734191458 | validation: 1.3193904638828076]
	TIME [epoch: 9.73 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.655735118189685		[learning rate: 0.0028652]
	Learning Rate: 0.00286522
	LOSS [training: 1.655735118189685 | validation: 1.293900441691695]
	TIME [epoch: 9.72 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2947446848045303		[learning rate: 0.0028548]
	Learning Rate: 0.00285482
	LOSS [training: 1.2947446848045303 | validation: 1.44337993982198]
	TIME [epoch: 9.75 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3267138391460611		[learning rate: 0.0028445]
	Learning Rate: 0.00284446
	LOSS [training: 1.3267138391460611 | validation: 1.2806319852978545]
	TIME [epoch: 9.73 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3084739277020683		[learning rate: 0.0028341]
	Learning Rate: 0.00283414
	LOSS [training: 1.3084739277020683 | validation: 1.2421179064426544]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_447.pth
	Model improved!!!
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2995623010832225		[learning rate: 0.0028239]
	Learning Rate: 0.00282385
	LOSS [training: 1.2995623010832225 | validation: 1.422022934653199]
	TIME [epoch: 9.74 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2545423109093528		[learning rate: 0.0028136]
	Learning Rate: 0.00281361
	LOSS [training: 1.2545423109093528 | validation: 1.2762949203632004]
	TIME [epoch: 9.73 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2517824622653588		[learning rate: 0.0028034]
	Learning Rate: 0.00280339
	LOSS [training: 1.2517824622653588 | validation: 1.3303702823722217]
	TIME [epoch: 9.75 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.243993049134111		[learning rate: 0.0027932]
	Learning Rate: 0.00279322
	LOSS [training: 1.243993049134111 | validation: 1.147980456392757]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3262946828180964		[learning rate: 0.0027831]
	Learning Rate: 0.00278308
	LOSS [training: 1.3262946828180964 | validation: 1.1447221781348105]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_452.pth
	Model improved!!!
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3048681893594845		[learning rate: 0.002773]
	Learning Rate: 0.00277298
	LOSS [training: 1.3048681893594845 | validation: 1.2485657455236472]
	TIME [epoch: 9.72 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5646295225833924		[learning rate: 0.0027629]
	Learning Rate: 0.00276292
	LOSS [training: 1.5646295225833924 | validation: 1.4157541710335442]
	TIME [epoch: 9.72 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2406089206122553		[learning rate: 0.0027529]
	Learning Rate: 0.00275289
	LOSS [training: 1.2406089206122553 | validation: 1.1010890117582153]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3006961365759755		[learning rate: 0.0027429]
	Learning Rate: 0.0027429
	LOSS [training: 1.3006961365759755 | validation: 1.2448505708402868]
	TIME [epoch: 9.74 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2890061859511366		[learning rate: 0.0027329]
	Learning Rate: 0.00273295
	LOSS [training: 1.2890061859511366 | validation: 1.1706112548922203]
	TIME [epoch: 9.73 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2288412222873482		[learning rate: 0.002723]
	Learning Rate: 0.00272303
	LOSS [training: 1.2288412222873482 | validation: 1.04383382943723]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2363389163136353		[learning rate: 0.0027131]
	Learning Rate: 0.00271315
	LOSS [training: 1.2363389163136353 | validation: 1.0732717753801708]
	TIME [epoch: 9.74 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1653526214486905		[learning rate: 0.0027033]
	Learning Rate: 0.0027033
	LOSS [training: 1.1653526214486905 | validation: 1.0307643639989934]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.116489280670779		[learning rate: 0.0026935]
	Learning Rate: 0.00269349
	LOSS [training: 1.116489280670779 | validation: 1.389202012978637]
	TIME [epoch: 9.76 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2887992782031426		[learning rate: 0.0026837]
	Learning Rate: 0.00268372
	LOSS [training: 1.2887992782031426 | validation: 1.5593035190336204]
	TIME [epoch: 9.74 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1989866764501818		[learning rate: 0.002674]
	Learning Rate: 0.00267398
	LOSS [training: 1.1989866764501818 | validation: 1.2935439704975562]
	TIME [epoch: 9.73 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1155503571410834		[learning rate: 0.0026643]
	Learning Rate: 0.00266427
	LOSS [training: 1.1155503571410834 | validation: 1.4833706492662262]
	TIME [epoch: 9.72 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.134322792836402		[learning rate: 0.0026546]
	Learning Rate: 0.00265461
	LOSS [training: 1.134322792836402 | validation: 1.016814835762649]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0117994823567784		[learning rate: 0.002645]
	Learning Rate: 0.00264497
	LOSS [training: 1.0117994823567784 | validation: 1.1763862271012122]
	TIME [epoch: 9.73 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0516303386138297		[learning rate: 0.0026354]
	Learning Rate: 0.00263537
	LOSS [training: 1.0516303386138297 | validation: 1.1602846664218962]
	TIME [epoch: 9.73 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2662779587994326		[learning rate: 0.0026258]
	Learning Rate: 0.00262581
	LOSS [training: 1.2662779587994326 | validation: 1.0981621638177765]
	TIME [epoch: 9.75 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.016564723702461		[learning rate: 0.0026163]
	Learning Rate: 0.00261628
	LOSS [training: 1.016564723702461 | validation: 1.0689157578301482]
	TIME [epoch: 9.73 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0813257493840274		[learning rate: 0.0026068]
	Learning Rate: 0.00260679
	LOSS [training: 1.0813257493840274 | validation: 1.2688600617957042]
	TIME [epoch: 9.73 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0672782340832947		[learning rate: 0.0025973]
	Learning Rate: 0.00259733
	LOSS [training: 1.0672782340832947 | validation: 1.2505668572275335]
	TIME [epoch: 9.73 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1325321886887756		[learning rate: 0.0025879]
	Learning Rate: 0.0025879
	LOSS [training: 1.1325321886887756 | validation: 1.240269994604371]
	TIME [epoch: 9.75 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1228126676869332		[learning rate: 0.0025785]
	Learning Rate: 0.00257851
	LOSS [training: 1.1228126676869332 | validation: 1.0508395372162431]
	TIME [epoch: 9.73 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9880123341578531		[learning rate: 0.0025691]
	Learning Rate: 0.00256915
	LOSS [training: 0.9880123341578531 | validation: 1.3950973865131286]
	TIME [epoch: 9.73 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0008863563202826		[learning rate: 0.0025598]
	Learning Rate: 0.00255983
	LOSS [training: 1.0008863563202826 | validation: 1.317371741574245]
	TIME [epoch: 9.75 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0136703779086627		[learning rate: 0.0025505]
	Learning Rate: 0.00255054
	LOSS [training: 1.0136703779086627 | validation: 1.2355808938419786]
	TIME [epoch: 9.73 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0413356044339577		[learning rate: 0.0025413]
	Learning Rate: 0.00254128
	LOSS [training: 1.0413356044339577 | validation: 1.7831652375761105]
	TIME [epoch: 9.73 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1087804078912684		[learning rate: 0.0025321]
	Learning Rate: 0.00253206
	LOSS [training: 1.1087804078912684 | validation: 1.1642663691911654]
	TIME [epoch: 9.74 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0257741281660806		[learning rate: 0.0025229]
	Learning Rate: 0.00252287
	LOSS [training: 1.0257741281660806 | validation: 1.0175039369985044]
	TIME [epoch: 9.74 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0217930253937757		[learning rate: 0.0025137]
	Learning Rate: 0.00251371
	LOSS [training: 1.0217930253937757 | validation: 1.110219047368515]
	TIME [epoch: 9.73 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.972878042761702		[learning rate: 0.0025046]
	Learning Rate: 0.00250459
	LOSS [training: 0.972878042761702 | validation: 1.0453081650624234]
	TIME [epoch: 9.74 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.051116057518637		[learning rate: 0.0024955]
	Learning Rate: 0.0024955
	LOSS [training: 1.051116057518637 | validation: 1.1467701485685993]
	TIME [epoch: 9.75 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0145730859104856		[learning rate: 0.0024864]
	Learning Rate: 0.00248645
	LOSS [training: 1.0145730859104856 | validation: 1.1214147331075761]
	TIME [epoch: 9.74 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9514163914053487		[learning rate: 0.0024774]
	Learning Rate: 0.00247742
	LOSS [training: 0.9514163914053487 | validation: 1.0971368664327958]
	TIME [epoch: 9.73 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9143299289439104		[learning rate: 0.0024684]
	Learning Rate: 0.00246843
	LOSS [training: 0.9143299289439104 | validation: 1.07382372577367]
	TIME [epoch: 9.75 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.018303169925209		[learning rate: 0.0024595]
	Learning Rate: 0.00245947
	LOSS [training: 1.018303169925209 | validation: 1.1271087177614088]
	TIME [epoch: 9.73 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9080734247792888		[learning rate: 0.0024505]
	Learning Rate: 0.00245055
	LOSS [training: 0.9080734247792888 | validation: 1.1369582498281912]
	TIME [epoch: 9.73 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9485584575566592		[learning rate: 0.0024417]
	Learning Rate: 0.00244165
	LOSS [training: 0.9485584575566592 | validation: 1.0729582856372364]
	TIME [epoch: 9.73 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9395332664517037		[learning rate: 0.0024328]
	Learning Rate: 0.00243279
	LOSS [training: 0.9395332664517037 | validation: 1.022007574664813]
	TIME [epoch: 9.75 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9037708667954266		[learning rate: 0.002424]
	Learning Rate: 0.00242396
	LOSS [training: 0.9037708667954266 | validation: 1.0497894448591591]
	TIME [epoch: 9.73 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9142942106019021		[learning rate: 0.0024152]
	Learning Rate: 0.00241517
	LOSS [training: 0.9142942106019021 | validation: 1.0030672838109536]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_491.pth
	Model improved!!!
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8618211755383595		[learning rate: 0.0024064]
	Learning Rate: 0.0024064
	LOSS [training: 0.8618211755383595 | validation: 0.9906822114504639]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8514898559133641		[learning rate: 0.0023977]
	Learning Rate: 0.00239767
	LOSS [training: 0.8514898559133641 | validation: 1.2013593248553511]
	TIME [epoch: 9.72 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9364067522445183		[learning rate: 0.002389]
	Learning Rate: 0.00238897
	LOSS [training: 0.9364067522445183 | validation: 0.9760883325938992]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8398448379873538		[learning rate: 0.0023803]
	Learning Rate: 0.0023803
	LOSS [training: 0.8398448379873538 | validation: 1.0832028661383195]
	TIME [epoch: 9.73 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9496794166732757		[learning rate: 0.0023717]
	Learning Rate: 0.00237166
	LOSS [training: 0.9496794166732757 | validation: 1.0679344608069334]
	TIME [epoch: 9.72 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8790000292996242		[learning rate: 0.0023631]
	Learning Rate: 0.00236305
	LOSS [training: 0.8790000292996242 | validation: 1.0855072855649008]
	TIME [epoch: 9.72 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9011777370438798		[learning rate: 0.0023545]
	Learning Rate: 0.00235448
	LOSS [training: 0.9011777370438798 | validation: 1.1478952802064182]
	TIME [epoch: 9.72 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8616500378487665		[learning rate: 0.0023459]
	Learning Rate: 0.00234593
	LOSS [training: 0.8616500378487665 | validation: 1.436590974582322]
	TIME [epoch: 9.74 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.933529091694426		[learning rate: 0.0023374]
	Learning Rate: 0.00233742
	LOSS [training: 0.933529091694426 | validation: 1.0792592975875932]
	TIME [epoch: 9.72 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9324566259778884		[learning rate: 0.0023289]
	Learning Rate: 0.00232894
	LOSS [training: 0.9324566259778884 | validation: 1.0637928468668278]
	TIME [epoch: 9.72 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.854038368428115		[learning rate: 0.0023205]
	Learning Rate: 0.00232049
	LOSS [training: 0.854038368428115 | validation: 1.1172277293063761]
	TIME [epoch: 9.74 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8722548099330268		[learning rate: 0.0023121]
	Learning Rate: 0.00231206
	LOSS [training: 0.8722548099330268 | validation: 1.0137722184667448]
	TIME [epoch: 9.73 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8229525981238153		[learning rate: 0.0023037]
	Learning Rate: 0.00230367
	LOSS [training: 0.8229525981238153 | validation: 1.0187758734556265]
	TIME [epoch: 9.72 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8135259961741935		[learning rate: 0.0022953]
	Learning Rate: 0.00229531
	LOSS [training: 0.8135259961741935 | validation: 1.072059447952207]
	TIME [epoch: 9.73 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8360782609276486		[learning rate: 0.002287]
	Learning Rate: 0.00228698
	LOSS [training: 0.8360782609276486 | validation: 1.0030067274575043]
	TIME [epoch: 9.73 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.920372072976577		[learning rate: 0.0022787]
	Learning Rate: 0.00227868
	LOSS [training: 0.920372072976577 | validation: 1.0858457058234858]
	TIME [epoch: 9.72 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9781681427089204		[learning rate: 0.0022704]
	Learning Rate: 0.00227042
	LOSS [training: 0.9781681427089204 | validation: 1.230687606337494]
	TIME [epoch: 9.72 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8686414161170152		[learning rate: 0.0022622]
	Learning Rate: 0.00226218
	LOSS [training: 0.8686414161170152 | validation: 1.0668439374626493]
	TIME [epoch: 9.75 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9701435045671698		[learning rate: 0.002254]
	Learning Rate: 0.00225397
	LOSS [training: 0.9701435045671698 | validation: 1.0017164820573978]
	TIME [epoch: 9.73 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.89169186706185		[learning rate: 0.0022458]
	Learning Rate: 0.00224579
	LOSS [training: 0.89169186706185 | validation: 1.1145176136864943]
	TIME [epoch: 9.72 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7735561200880632		[learning rate: 0.0022376]
	Learning Rate: 0.00223764
	LOSS [training: 0.7735561200880632 | validation: 1.024821716134356]
	TIME [epoch: 9.74 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7630663160764519		[learning rate: 0.0022295]
	Learning Rate: 0.00222952
	LOSS [training: 0.7630663160764519 | validation: 1.1609892712810885]
	TIME [epoch: 9.73 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8766304609202686		[learning rate: 0.0022214]
	Learning Rate: 0.00222142
	LOSS [training: 0.8766304609202686 | validation: 1.0316383419335597]
	TIME [epoch: 9.72 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.780524883296886		[learning rate: 0.0022134]
	Learning Rate: 0.00221336
	LOSS [training: 0.780524883296886 | validation: 1.203181134958875]
	TIME [epoch: 9.72 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7785224191606208		[learning rate: 0.0022053]
	Learning Rate: 0.00220533
	LOSS [training: 0.7785224191606208 | validation: 0.9446873008374875]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_516.pth
	Model improved!!!
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9670488460347444		[learning rate: 0.0021973]
	Learning Rate: 0.00219733
	LOSS [training: 0.9670488460347444 | validation: 0.9309063341918156]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_517.pth
	Model improved!!!
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8242227660866428		[learning rate: 0.0021894]
	Learning Rate: 0.00218935
	LOSS [training: 0.8242227660866428 | validation: 1.3038759412908332]
	TIME [epoch: 9.72 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8074980355534087		[learning rate: 0.0021814]
	Learning Rate: 0.00218141
	LOSS [training: 0.8074980355534087 | validation: 0.9678011170326304]
	TIME [epoch: 9.73 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8335673408689276		[learning rate: 0.0021735]
	Learning Rate: 0.00217349
	LOSS [training: 0.8335673408689276 | validation: 1.0840670462324022]
	TIME [epoch: 9.71 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8442874595088409		[learning rate: 0.0021656]
	Learning Rate: 0.0021656
	LOSS [training: 0.8442874595088409 | validation: 1.1154266281037286]
	TIME [epoch: 9.72 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7988727244469847		[learning rate: 0.0021577]
	Learning Rate: 0.00215774
	LOSS [training: 0.7988727244469847 | validation: 0.9951331408767133]
	TIME [epoch: 9.72 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7427339994100112		[learning rate: 0.0021499]
	Learning Rate: 0.00214991
	LOSS [training: 0.7427339994100112 | validation: 0.981670247675529]
	TIME [epoch: 9.73 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7347806670701936		[learning rate: 0.0021421]
	Learning Rate: 0.00214211
	LOSS [training: 0.7347806670701936 | validation: 1.175984633962353]
	TIME [epoch: 9.72 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7922881993998127		[learning rate: 0.0021343]
	Learning Rate: 0.00213434
	LOSS [training: 0.7922881993998127 | validation: 0.9678047591585528]
	TIME [epoch: 9.71 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8458335381204627		[learning rate: 0.0021266]
	Learning Rate: 0.00212659
	LOSS [training: 0.8458335381204627 | validation: 1.061673408687337]
	TIME [epoch: 9.73 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7269011763189731		[learning rate: 0.0021189]
	Learning Rate: 0.00211887
	LOSS [training: 0.7269011763189731 | validation: 0.9958504010701715]
	TIME [epoch: 9.73 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.717579541489748		[learning rate: 0.0021112]
	Learning Rate: 0.00211119
	LOSS [training: 0.717579541489748 | validation: 1.1594187951732238]
	TIME [epoch: 9.72 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8111983938547935		[learning rate: 0.0021035]
	Learning Rate: 0.00210352
	LOSS [training: 0.8111983938547935 | validation: 0.9112409434678861]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9539271958635203		[learning rate: 0.0020959]
	Learning Rate: 0.00209589
	LOSS [training: 0.9539271958635203 | validation: 1.7599777961399699]
	TIME [epoch: 9.73 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9445993895286724		[learning rate: 0.0020883]
	Learning Rate: 0.00208828
	LOSS [training: 0.9445993895286724 | validation: 0.9971238222516092]
	TIME [epoch: 9.72 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7260057484255695		[learning rate: 0.0020807]
	Learning Rate: 0.00208071
	LOSS [training: 0.7260057484255695 | validation: 1.068552831710096]
	TIME [epoch: 9.72 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7618949387525478		[learning rate: 0.0020732]
	Learning Rate: 0.00207315
	LOSS [training: 0.7618949387525478 | validation: 0.9484549029515777]
	TIME [epoch: 9.73 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8214345210229306		[learning rate: 0.0020656]
	Learning Rate: 0.00206563
	LOSS [training: 0.8214345210229306 | validation: 0.9759156644419165]
	TIME [epoch: 9.72 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7739824458172608		[learning rate: 0.0020581]
	Learning Rate: 0.00205813
	LOSS [training: 0.7739824458172608 | validation: 0.9637723064484651]
	TIME [epoch: 9.73 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.762968684813009		[learning rate: 0.0020507]
	Learning Rate: 0.00205067
	LOSS [training: 0.762968684813009 | validation: 0.9800803643501166]
	TIME [epoch: 9.74 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7650717586034297		[learning rate: 0.0020432]
	Learning Rate: 0.00204322
	LOSS [training: 0.7650717586034297 | validation: 0.9445770171647272]
	TIME [epoch: 9.72 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7945000537769863		[learning rate: 0.0020358]
	Learning Rate: 0.00203581
	LOSS [training: 0.7945000537769863 | validation: 1.0412489764217474]
	TIME [epoch: 9.72 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.762466283836076		[learning rate: 0.0020284]
	Learning Rate: 0.00202842
	LOSS [training: 0.762466283836076 | validation: 0.9604186159580194]
	TIME [epoch: 9.74 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.822010251839018		[learning rate: 0.0020211]
	Learning Rate: 0.00202106
	LOSS [training: 0.822010251839018 | validation: 0.8785416660904001]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_540.pth
	Model improved!!!
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7415289483834611		[learning rate: 0.0020137]
	Learning Rate: 0.00201372
	LOSS [training: 0.7415289483834611 | validation: 1.0499684039260082]
	TIME [epoch: 9.72 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.717697530005417		[learning rate: 0.0020064]
	Learning Rate: 0.00200642
	LOSS [training: 0.717697530005417 | validation: 0.944305032237061]
	TIME [epoch: 9.73 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7170646941094734		[learning rate: 0.0019991]
	Learning Rate: 0.00199913
	LOSS [training: 0.7170646941094734 | validation: 1.2666172432207021]
	TIME [epoch: 9.75 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8028805983967493		[learning rate: 0.0019919]
	Learning Rate: 0.00199188
	LOSS [training: 0.8028805983967493 | validation: 0.9735125251891436]
	TIME [epoch: 9.72 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7503418537083572		[learning rate: 0.0019847]
	Learning Rate: 0.00198465
	LOSS [training: 0.7503418537083572 | validation: 1.1865946269217285]
	TIME [epoch: 9.72 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7701764769293522		[learning rate: 0.0019774]
	Learning Rate: 0.00197745
	LOSS [training: 0.7701764769293522 | validation: 0.9266046703673257]
	TIME [epoch: 9.74 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7422133960953212		[learning rate: 0.0019703]
	Learning Rate: 0.00197027
	LOSS [training: 0.7422133960953212 | validation: 1.0477156893672823]
	TIME [epoch: 9.72 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.724653756344601		[learning rate: 0.0019631]
	Learning Rate: 0.00196312
	LOSS [training: 0.724653756344601 | validation: 0.9897218266585764]
	TIME [epoch: 9.72 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7198491985135991		[learning rate: 0.001956]
	Learning Rate: 0.001956
	LOSS [training: 0.7198491985135991 | validation: 0.9014628426777079]
	TIME [epoch: 9.73 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7117436886927486		[learning rate: 0.0019489]
	Learning Rate: 0.0019489
	LOSS [training: 0.7117436886927486 | validation: 1.0493867806058368]
	TIME [epoch: 9.73 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7142715651264661		[learning rate: 0.0019418]
	Learning Rate: 0.00194183
	LOSS [training: 0.7142715651264661 | validation: 0.913119085704013]
	TIME [epoch: 9.71 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6956241090991249		[learning rate: 0.0019348]
	Learning Rate: 0.00193478
	LOSS [training: 0.6956241090991249 | validation: 0.8546064169899904]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.741167680750721		[learning rate: 0.0019278]
	Learning Rate: 0.00192776
	LOSS [training: 0.741167680750721 | validation: 1.0713924789126412]
	TIME [epoch: 9.75 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.743438719952292		[learning rate: 0.0019208]
	Learning Rate: 0.00192076
	LOSS [training: 0.743438719952292 | validation: 0.9372654399184143]
	TIME [epoch: 9.73 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7239477208284723		[learning rate: 0.0019138]
	Learning Rate: 0.00191379
	LOSS [training: 0.7239477208284723 | validation: 0.976107471976878]
	TIME [epoch: 9.73 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.749598718046362		[learning rate: 0.0019068]
	Learning Rate: 0.00190685
	LOSS [training: 0.749598718046362 | validation: 0.922535775347228]
	TIME [epoch: 9.75 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7736389823762214		[learning rate: 0.0018999]
	Learning Rate: 0.00189993
	LOSS [training: 0.7736389823762214 | validation: 1.1113191144019996]
	TIME [epoch: 9.74 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7269662948244486		[learning rate: 0.001893]
	Learning Rate: 0.00189303
	LOSS [training: 0.7269662948244486 | validation: 0.8928947468696538]
	TIME [epoch: 9.73 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7404441647507026		[learning rate: 0.0018862]
	Learning Rate: 0.00188616
	LOSS [training: 0.7404441647507026 | validation: 0.9186711035247344]
	TIME [epoch: 9.73 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6884883508399259		[learning rate: 0.0018793]
	Learning Rate: 0.00187932
	LOSS [training: 0.6884883508399259 | validation: 1.0424338979386294]
	TIME [epoch: 9.75 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8377310398653993		[learning rate: 0.0018725]
	Learning Rate: 0.0018725
	LOSS [training: 0.8377310398653993 | validation: 1.0124390610534122]
	TIME [epoch: 9.74 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6445270004342589		[learning rate: 0.0018657]
	Learning Rate: 0.0018657
	LOSS [training: 0.6445270004342589 | validation: 0.9193052519674365]
	TIME [epoch: 9.74 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.743376479871794		[learning rate: 0.0018589]
	Learning Rate: 0.00185893
	LOSS [training: 0.743376479871794 | validation: 0.9597745996122328]
	TIME [epoch: 9.75 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6855789948144208		[learning rate: 0.0018522]
	Learning Rate: 0.00185218
	LOSS [training: 0.6855789948144208 | validation: 0.9045694395552838]
	TIME [epoch: 9.74 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6498997938893337		[learning rate: 0.0018455]
	Learning Rate: 0.00184546
	LOSS [training: 0.6498997938893337 | validation: 1.0331757150081646]
	TIME [epoch: 9.74 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7132034515887812		[learning rate: 0.0018388]
	Learning Rate: 0.00183877
	LOSS [training: 0.7132034515887812 | validation: 0.9340257882052985]
	TIME [epoch: 9.74 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7291517956865355		[learning rate: 0.0018321]
	Learning Rate: 0.00183209
	LOSS [training: 0.7291517956865355 | validation: 0.9308256576669546]
	TIME [epoch: 9.75 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6854458588806478		[learning rate: 0.0018254]
	Learning Rate: 0.00182544
	LOSS [training: 0.6854458588806478 | validation: 0.9333863756199735]
	TIME [epoch: 9.74 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6904527889805457		[learning rate: 0.0018188]
	Learning Rate: 0.00181882
	LOSS [training: 0.6904527889805457 | validation: 0.8803867735060065]
	TIME [epoch: 9.73 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6446543295766322		[learning rate: 0.0018122]
	Learning Rate: 0.00181222
	LOSS [training: 0.6446543295766322 | validation: 0.897274231624469]
	TIME [epoch: 9.75 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6828683349155823		[learning rate: 0.0018056]
	Learning Rate: 0.00180564
	LOSS [training: 0.6828683349155823 | validation: 0.9547938051548022]
	TIME [epoch: 9.73 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6783668174701077		[learning rate: 0.0017991]
	Learning Rate: 0.00179909
	LOSS [training: 0.6783668174701077 | validation: 0.8710762617646407]
	TIME [epoch: 9.73 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6594224253826881		[learning rate: 0.0017926]
	Learning Rate: 0.00179256
	LOSS [training: 0.6594224253826881 | validation: 0.9503510798075243]
	TIME [epoch: 9.74 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7334349916646685		[learning rate: 0.0017861]
	Learning Rate: 0.00178605
	LOSS [training: 0.7334349916646685 | validation: 0.8793553480596445]
	TIME [epoch: 9.74 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6787458617946907		[learning rate: 0.0017796]
	Learning Rate: 0.00177957
	LOSS [training: 0.6787458617946907 | validation: 1.0852680310807332]
	TIME [epoch: 9.73 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6749073636668397		[learning rate: 0.0017731]
	Learning Rate: 0.00177311
	LOSS [training: 0.6749073636668397 | validation: 0.92873716775424]
	TIME [epoch: 9.73 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6931533009922483		[learning rate: 0.0017667]
	Learning Rate: 0.00176668
	LOSS [training: 0.6931533009922483 | validation: 0.8964497811201025]
	TIME [epoch: 9.75 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7016456202021881		[learning rate: 0.0017603]
	Learning Rate: 0.00176027
	LOSS [training: 0.7016456202021881 | validation: 0.895481450122964]
	TIME [epoch: 9.73 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6539783078724946		[learning rate: 0.0017539]
	Learning Rate: 0.00175388
	LOSS [training: 0.6539783078724946 | validation: 1.0806912473369252]
	TIME [epoch: 9.73 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6925566578264437		[learning rate: 0.0017475]
	Learning Rate: 0.00174752
	LOSS [training: 0.6925566578264437 | validation: 0.8717899642527897]
	TIME [epoch: 9.75 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6731660082747052		[learning rate: 0.0017412]
	Learning Rate: 0.00174117
	LOSS [training: 0.6731660082747052 | validation: 0.9153420053297662]
	TIME [epoch: 9.74 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.750810987731207		[learning rate: 0.0017349]
	Learning Rate: 0.00173486
	LOSS [training: 0.750810987731207 | validation: 0.8805438947070209]
	TIME [epoch: 9.73 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8307865389440936		[learning rate: 0.0017286]
	Learning Rate: 0.00172856
	LOSS [training: 0.8307865389440936 | validation: 1.0788903732244042]
	TIME [epoch: 9.74 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.769106151570276		[learning rate: 0.0017223]
	Learning Rate: 0.00172229
	LOSS [training: 0.769106151570276 | validation: 0.9549433724992448]
	TIME [epoch: 9.74 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6947672937995366		[learning rate: 0.001716]
	Learning Rate: 0.00171604
	LOSS [training: 0.6947672937995366 | validation: 0.8981876617896952]
	TIME [epoch: 9.73 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6928087028309847		[learning rate: 0.0017098]
	Learning Rate: 0.00170981
	LOSS [training: 0.6928087028309847 | validation: 0.9564896132861921]
	TIME [epoch: 9.73 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6757078626787061		[learning rate: 0.0017036]
	Learning Rate: 0.0017036
	LOSS [training: 0.6757078626787061 | validation: 0.8840142100035141]
	TIME [epoch: 9.75 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.68119795648316		[learning rate: 0.0016974]
	Learning Rate: 0.00169742
	LOSS [training: 0.68119795648316 | validation: 0.9170772274676767]
	TIME [epoch: 9.73 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7109151918017333		[learning rate: 0.0016913]
	Learning Rate: 0.00169126
	LOSS [training: 0.7109151918017333 | validation: 1.1522392890761004]
	TIME [epoch: 9.73 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6749385864194855		[learning rate: 0.0016851]
	Learning Rate: 0.00168512
	LOSS [training: 0.6749385864194855 | validation: 0.9873509442309711]
	TIME [epoch: 9.75 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7036337020542833		[learning rate: 0.001679]
	Learning Rate: 0.00167901
	LOSS [training: 0.7036337020542833 | validation: 1.0084324108621254]
	TIME [epoch: 9.73 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7007087152326055		[learning rate: 0.0016729]
	Learning Rate: 0.00167291
	LOSS [training: 0.7007087152326055 | validation: 0.9120977288574927]
	TIME [epoch: 9.73 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7616391569095444		[learning rate: 0.0016668]
	Learning Rate: 0.00166684
	LOSS [training: 0.7616391569095444 | validation: 1.2715620079559713]
	TIME [epoch: 9.73 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7859798711043887		[learning rate: 0.0016608]
	Learning Rate: 0.00166079
	LOSS [training: 0.7859798711043887 | validation: 0.8889975252004524]
	TIME [epoch: 9.75 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6873824336885457		[learning rate: 0.0016548]
	Learning Rate: 0.00165477
	LOSS [training: 0.6873824336885457 | validation: 0.9034629177253684]
	TIME [epoch: 9.73 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.668235199170296		[learning rate: 0.0016488]
	Learning Rate: 0.00164876
	LOSS [training: 0.668235199170296 | validation: 1.014405779871612]
	TIME [epoch: 9.73 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6690057626319372		[learning rate: 0.0016428]
	Learning Rate: 0.00164278
	LOSS [training: 0.6690057626319372 | validation: 1.0612186801533756]
	TIME [epoch: 9.75 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7137896132713669		[learning rate: 0.0016368]
	Learning Rate: 0.00163682
	LOSS [training: 0.7137896132713669 | validation: 0.9369949810937204]
	TIME [epoch: 9.74 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6751976650684819		[learning rate: 0.0016309]
	Learning Rate: 0.00163088
	LOSS [training: 0.6751976650684819 | validation: 0.9715724467717365]
	TIME [epoch: 9.73 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7494942614181507		[learning rate: 0.001625]
	Learning Rate: 0.00162496
	LOSS [training: 0.7494942614181507 | validation: 1.0560071086680274]
	TIME [epoch: 9.74 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7032422765769208		[learning rate: 0.0016191]
	Learning Rate: 0.00161906
	LOSS [training: 0.7032422765769208 | validation: 1.0867572575171414]
	TIME [epoch: 9.74 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7153489263911703		[learning rate: 0.0016132]
	Learning Rate: 0.00161319
	LOSS [training: 0.7153489263911703 | validation: 0.8934593509623658]
	TIME [epoch: 9.73 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7496418512908473		[learning rate: 0.0016073]
	Learning Rate: 0.00160733
	LOSS [training: 0.7496418512908473 | validation: 0.8941722350768305]
	TIME [epoch: 9.73 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7479606755091355		[learning rate: 0.0016015]
	Learning Rate: 0.0016015
	LOSS [training: 0.7479606755091355 | validation: 0.9454049448534325]
	TIME [epoch: 9.75 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6537437421387002		[learning rate: 0.0015957]
	Learning Rate: 0.00159569
	LOSS [training: 0.6537437421387002 | validation: 1.0464059678779192]
	TIME [epoch: 9.73 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6818155120860323		[learning rate: 0.0015899]
	Learning Rate: 0.00158989
	LOSS [training: 0.6818155120860323 | validation: 0.840748159467411]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_606.pth
	Model improved!!!
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6626099330895864		[learning rate: 0.0015841]
	Learning Rate: 0.00158413
	LOSS [training: 0.6626099330895864 | validation: 0.9243241389326073]
	TIME [epoch: 9.74 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.650969509519168		[learning rate: 0.0015784]
	Learning Rate: 0.00157838
	LOSS [training: 0.650969509519168 | validation: 0.844929974486989]
	TIME [epoch: 9.73 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6788274626046784		[learning rate: 0.0015726]
	Learning Rate: 0.00157265
	LOSS [training: 0.6788274626046784 | validation: 0.9121400897356833]
	TIME [epoch: 9.73 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6598673855803114		[learning rate: 0.0015669]
	Learning Rate: 0.00156694
	LOSS [training: 0.6598673855803114 | validation: 0.9459961764860417]
	TIME [epoch: 9.72 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6867348593719066		[learning rate: 0.0015613]
	Learning Rate: 0.00156125
	LOSS [training: 0.6867348593719066 | validation: 0.9493851123258205]
	TIME [epoch: 9.74 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6512189502304031		[learning rate: 0.0015556]
	Learning Rate: 0.00155559
	LOSS [training: 0.6512189502304031 | validation: 0.8798087997504456]
	TIME [epoch: 9.72 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6642948584472138		[learning rate: 0.0015499]
	Learning Rate: 0.00154994
	LOSS [training: 0.6642948584472138 | validation: 0.8573985137734873]
	TIME [epoch: 9.72 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8163049403273496		[learning rate: 0.0015443]
	Learning Rate: 0.00154432
	LOSS [training: 0.8163049403273496 | validation: 0.8492188627023591]
	TIME [epoch: 9.74 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6529263167484832		[learning rate: 0.0015387]
	Learning Rate: 0.00153871
	LOSS [training: 0.6529263167484832 | validation: 0.8915962755317165]
	TIME [epoch: 9.73 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6668019598254622		[learning rate: 0.0015331]
	Learning Rate: 0.00153313
	LOSS [training: 0.6668019598254622 | validation: 0.8117079064713332]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6923053661511672		[learning rate: 0.0015276]
	Learning Rate: 0.00152757
	LOSS [training: 0.6923053661511672 | validation: 0.8927573650748352]
	TIME [epoch: 9.74 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6687658445225628		[learning rate: 0.001522]
	Learning Rate: 0.00152202
	LOSS [training: 0.6687658445225628 | validation: 0.8739930712755469]
	TIME [epoch: 9.72 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6377637595382092		[learning rate: 0.0015165]
	Learning Rate: 0.0015165
	LOSS [training: 0.6377637595382092 | validation: 0.8913348352541499]
	TIME [epoch: 9.72 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6535558545730076		[learning rate: 0.001511]
	Learning Rate: 0.001511
	LOSS [training: 0.6535558545730076 | validation: 0.9342976669448451]
	TIME [epoch: 9.71 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6942774021432151		[learning rate: 0.0015055]
	Learning Rate: 0.00150551
	LOSS [training: 0.6942774021432151 | validation: 1.749514228189968]
	TIME [epoch: 9.74 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9486796789434623		[learning rate: 0.0015]
	Learning Rate: 0.00150005
	LOSS [training: 0.9486796789434623 | validation: 0.9351152607453128]
	TIME [epoch: 9.71 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6922428637800347		[learning rate: 0.0014946]
	Learning Rate: 0.0014946
	LOSS [training: 0.6922428637800347 | validation: 0.9164532865010929]
	TIME [epoch: 9.71 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.624334343291248		[learning rate: 0.0014892]
	Learning Rate: 0.00148918
	LOSS [training: 0.624334343291248 | validation: 0.9647806780376514]
	TIME [epoch: 9.73 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6183730682346602		[learning rate: 0.0014838]
	Learning Rate: 0.00148378
	LOSS [training: 0.6183730682346602 | validation: 0.8903926966001006]
	TIME [epoch: 9.72 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6572397517861375		[learning rate: 0.0014784]
	Learning Rate: 0.00147839
	LOSS [training: 0.6572397517861375 | validation: 0.7922372587123161]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6788239682883427		[learning rate: 0.001473]
	Learning Rate: 0.00147303
	LOSS [training: 0.6788239682883427 | validation: 0.9128028875158176]
	TIME [epoch: 9.72 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.771106541911959		[learning rate: 0.0014677]
	Learning Rate: 0.00146768
	LOSS [training: 0.771106541911959 | validation: 0.8939220747604725]
	TIME [epoch: 9.72 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6063546999432166		[learning rate: 0.0014624]
	Learning Rate: 0.00146235
	LOSS [training: 0.6063546999432166 | validation: 1.087746696432522]
	TIME [epoch: 9.72 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6479693923504939		[learning rate: 0.001457]
	Learning Rate: 0.00145705
	LOSS [training: 0.6479693923504939 | validation: 0.7821473520595815]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6430593815647268		[learning rate: 0.0014518]
	Learning Rate: 0.00145176
	LOSS [training: 0.6430593815647268 | validation: 0.9043104674357987]
	TIME [epoch: 9.74 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6293031236535674		[learning rate: 0.0014465]
	Learning Rate: 0.00144649
	LOSS [training: 0.6293031236535674 | validation: 0.8659984508403327]
	TIME [epoch: 9.72 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6483123511306218		[learning rate: 0.0014412]
	Learning Rate: 0.00144124
	LOSS [training: 0.6483123511306218 | validation: 0.850903700740524]
	TIME [epoch: 9.72 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6480435156642852		[learning rate: 0.001436]
	Learning Rate: 0.00143601
	LOSS [training: 0.6480435156642852 | validation: 0.939010327511821]
	TIME [epoch: 9.74 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.631070800904743		[learning rate: 0.0014308]
	Learning Rate: 0.0014308
	LOSS [training: 0.631070800904743 | validation: 1.075903042944407]
	TIME [epoch: 9.72 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.630179494934844		[learning rate: 0.0014256]
	Learning Rate: 0.00142561
	LOSS [training: 0.630179494934844 | validation: 0.9885717315541358]
	TIME [epoch: 9.71 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6351518607319232		[learning rate: 0.0014204]
	Learning Rate: 0.00142043
	LOSS [training: 0.6351518607319232 | validation: 0.9000038302426856]
	TIME [epoch: 9.72 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7329617486826192		[learning rate: 0.0014153]
	Learning Rate: 0.00141528
	LOSS [training: 0.7329617486826192 | validation: 1.115231401766821]
	TIME [epoch: 9.73 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6461966560858765		[learning rate: 0.0014101]
	Learning Rate: 0.00141014
	LOSS [training: 0.6461966560858765 | validation: 0.8822092096758238]
	TIME [epoch: 9.72 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6269038947248576		[learning rate: 0.001405]
	Learning Rate: 0.00140503
	LOSS [training: 0.6269038947248576 | validation: 0.8485062532715649]
	TIME [epoch: 9.71 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6259161993918239		[learning rate: 0.0013999]
	Learning Rate: 0.00139993
	LOSS [training: 0.6259161993918239 | validation: 0.9051266149615944]
	TIME [epoch: 9.73 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5923306353217841		[learning rate: 0.0013948]
	Learning Rate: 0.00139485
	LOSS [training: 0.5923306353217841 | validation: 0.9059705325595314]
	TIME [epoch: 9.72 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.633687956508728		[learning rate: 0.0013898]
	Learning Rate: 0.00138978
	LOSS [training: 0.633687956508728 | validation: 0.9200967929054906]
	TIME [epoch: 9.72 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333617802223723		[learning rate: 0.0013847]
	Learning Rate: 0.00138474
	LOSS [training: 0.6333617802223723 | validation: 0.9218268400830824]
	TIME [epoch: 9.73 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.685118764279121		[learning rate: 0.0013797]
	Learning Rate: 0.00137972
	LOSS [training: 0.685118764279121 | validation: 0.87559975859424]
	TIME [epoch: 9.72 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6079916346513806		[learning rate: 0.0013747]
	Learning Rate: 0.00137471
	LOSS [training: 0.6079916346513806 | validation: 0.8409844262808001]
	TIME [epoch: 9.71 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6195410432921878		[learning rate: 0.0013697]
	Learning Rate: 0.00136972
	LOSS [training: 0.6195410432921878 | validation: 0.8526382453678896]
	TIME [epoch: 9.72 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6244863378166544		[learning rate: 0.0013647]
	Learning Rate: 0.00136475
	LOSS [training: 0.6244863378166544 | validation: 0.8195172532975894]
	TIME [epoch: 9.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6219654623311278		[learning rate: 0.0013598]
	Learning Rate: 0.0013598
	LOSS [training: 0.6219654623311278 | validation: 0.9149367484146723]
	TIME [epoch: 9.72 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5935351103715247		[learning rate: 0.0013549]
	Learning Rate: 0.00135486
	LOSS [training: 0.5935351103715247 | validation: 0.7764010941316518]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_650.pth
	Model improved!!!
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6188071440435685		[learning rate: 0.0013499]
	Learning Rate: 0.00134994
	LOSS [training: 0.6188071440435685 | validation: 0.9786798824171178]
	TIME [epoch: 9.73 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6282703785966515		[learning rate: 0.001345]
	Learning Rate: 0.00134505
	LOSS [training: 0.6282703785966515 | validation: 0.94660551368071]
	TIME [epoch: 9.72 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6165040540339003		[learning rate: 0.0013402]
	Learning Rate: 0.00134016
	LOSS [training: 0.6165040540339003 | validation: 0.8433391796155663]
	TIME [epoch: 9.71 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6191893757400272		[learning rate: 0.0013353]
	Learning Rate: 0.0013353
	LOSS [training: 0.6191893757400272 | validation: 0.867202069237012]
	TIME [epoch: 9.71 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.557564272213814		[learning rate: 0.0013305]
	Learning Rate: 0.00133045
	LOSS [training: 0.557564272213814 | validation: 0.8812981423309243]
	TIME [epoch: 9.73 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6064069047556881		[learning rate: 0.0013256]
	Learning Rate: 0.00132563
	LOSS [training: 0.6064069047556881 | validation: 0.9406613037465016]
	TIME [epoch: 9.72 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5671533707210102		[learning rate: 0.0013208]
	Learning Rate: 0.00132082
	LOSS [training: 0.5671533707210102 | validation: 1.100571860494498]
	TIME [epoch: 9.71 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9126905732992963		[learning rate: 0.001316]
	Learning Rate: 0.00131602
	LOSS [training: 0.9126905732992963 | validation: 1.3075866433014998]
	TIME [epoch: 9.73 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8184527655171576		[learning rate: 0.0013112]
	Learning Rate: 0.00131125
	LOSS [training: 0.8184527655171576 | validation: 0.974349145730962]
	TIME [epoch: 9.72 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5833799234678143		[learning rate: 0.0013065]
	Learning Rate: 0.00130649
	LOSS [training: 0.5833799234678143 | validation: 1.0219243459488698]
	TIME [epoch: 9.72 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6642947802331879		[learning rate: 0.0013017]
	Learning Rate: 0.00130175
	LOSS [training: 0.6642947802331879 | validation: 0.8991214900434394]
	TIME [epoch: 9.73 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6155025122690627		[learning rate: 0.001297]
	Learning Rate: 0.00129702
	LOSS [training: 0.6155025122690627 | validation: 0.9284456103587937]
	TIME [epoch: 9.73 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5948842975986717		[learning rate: 0.0012923]
	Learning Rate: 0.00129232
	LOSS [training: 0.5948842975986717 | validation: 0.8395704695384789]
	TIME [epoch: 9.72 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6198847894156149		[learning rate: 0.0012876]
	Learning Rate: 0.00128763
	LOSS [training: 0.6198847894156149 | validation: 1.0511511259401]
	TIME [epoch: 9.71 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6432781777967618		[learning rate: 0.001283]
	Learning Rate: 0.00128295
	LOSS [training: 0.6432781777967618 | validation: 0.8924843831512353]
	TIME [epoch: 9.74 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6119312700156342		[learning rate: 0.0012783]
	Learning Rate: 0.0012783
	LOSS [training: 0.6119312700156342 | validation: 0.8121115436668721]
	TIME [epoch: 9.71 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5854506634904395		[learning rate: 0.0012737]
	Learning Rate: 0.00127366
	LOSS [training: 0.5854506634904395 | validation: 0.8429377346728859]
	TIME [epoch: 9.71 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6519401898420452		[learning rate: 0.001269]
	Learning Rate: 0.00126904
	LOSS [training: 0.6519401898420452 | validation: 0.8232770159038458]
	TIME [epoch: 9.73 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5571137016667421		[learning rate: 0.0012644]
	Learning Rate: 0.00126443
	LOSS [training: 0.5571137016667421 | validation: 0.8222977932490031]
	TIME [epoch: 9.72 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5954496717294461		[learning rate: 0.0012598]
	Learning Rate: 0.00125984
	LOSS [training: 0.5954496717294461 | validation: 0.8356175342675687]
	TIME [epoch: 9.72 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333005856783644		[learning rate: 0.0012553]
	Learning Rate: 0.00125527
	LOSS [training: 0.6333005856783644 | validation: 0.9156076869813227]
	TIME [epoch: 9.72 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6415026973999047		[learning rate: 0.0012507]
	Learning Rate: 0.00125071
	LOSS [training: 0.6415026973999047 | validation: 0.8245436282822167]
	TIME [epoch: 9.74 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5819524544705159		[learning rate: 0.0012462]
	Learning Rate: 0.00124617
	LOSS [training: 0.5819524544705159 | validation: 0.8287198733768029]
	TIME [epoch: 9.72 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5942707691342686		[learning rate: 0.0012417]
	Learning Rate: 0.00124165
	LOSS [training: 0.5942707691342686 | validation: 0.8818077709441593]
	TIME [epoch: 9.71 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5717352973807632		[learning rate: 0.0012371]
	Learning Rate: 0.00123715
	LOSS [training: 0.5717352973807632 | validation: 1.005233573455015]
	TIME [epoch: 9.73 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9632205661563866		[learning rate: 0.0012327]
	Learning Rate: 0.00123266
	LOSS [training: 0.9632205661563866 | validation: 0.8630069666363942]
	TIME [epoch: 9.72 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6738820558361802		[learning rate: 0.0012282]
	Learning Rate: 0.00122818
	LOSS [training: 0.6738820558361802 | validation: 1.0171123301065752]
	TIME [epoch: 9.71 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9597748262815948		[learning rate: 0.0012237]
	Learning Rate: 0.00122373
	LOSS [training: 0.9597748262815948 | validation: 0.9315393824344474]
	TIME [epoch: 9.73 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6176087695229742		[learning rate: 0.0012193]
	Learning Rate: 0.00121929
	LOSS [training: 0.6176087695229742 | validation: 0.88366288259796]
	TIME [epoch: 9.73 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6809815288451873		[learning rate: 0.0012149]
	Learning Rate: 0.00121486
	LOSS [training: 0.6809815288451873 | validation: 0.8310609337810593]
	TIME [epoch: 9.72 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5731501698354792		[learning rate: 0.0012105]
	Learning Rate: 0.00121045
	LOSS [training: 0.5731501698354792 | validation: 0.9020881457005439]
	TIME [epoch: 9.72 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6800783315330827		[learning rate: 0.0012061]
	Learning Rate: 0.00120606
	LOSS [training: 0.6800783315330827 | validation: 0.8850080712550622]
	TIME [epoch: 9.73 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5930588645639723		[learning rate: 0.0012017]
	Learning Rate: 0.00120168
	LOSS [training: 0.5930588645639723 | validation: 0.7994492273351423]
	TIME [epoch: 9.72 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5496895355699113		[learning rate: 0.0011973]
	Learning Rate: 0.00119732
	LOSS [training: 0.5496895355699113 | validation: 0.857636986420064]
	TIME [epoch: 9.72 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5950108190321763		[learning rate: 0.001193]
	Learning Rate: 0.00119298
	LOSS [training: 0.5950108190321763 | validation: 0.8341662179921902]
	TIME [epoch: 9.72 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5586714474704679		[learning rate: 0.0011886]
	Learning Rate: 0.00118865
	LOSS [training: 0.5586714474704679 | validation: 0.9956858359159958]
	TIME [epoch: 9.72 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7404129470667187		[learning rate: 0.0011843]
	Learning Rate: 0.00118433
	LOSS [training: 0.7404129470667187 | validation: 0.8459991030332863]
	TIME [epoch: 9.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5701808818964934		[learning rate: 0.00118]
	Learning Rate: 0.00118003
	LOSS [training: 0.5701808818964934 | validation: 1.0441670824848506]
	TIME [epoch: 9.71 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6255487324502498		[learning rate: 0.0011758]
	Learning Rate: 0.00117575
	LOSS [training: 0.6255487324502498 | validation: 0.8095998514562516]
	TIME [epoch: 9.74 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5684435347887231		[learning rate: 0.0011715]
	Learning Rate: 0.00117149
	LOSS [training: 0.5684435347887231 | validation: 0.8019045275996026]
	TIME [epoch: 9.71 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5975629220184313		[learning rate: 0.0011672]
	Learning Rate: 0.00116723
	LOSS [training: 0.5975629220184313 | validation: 0.8544788752410775]
	TIME [epoch: 9.72 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7080359887829603		[learning rate: 0.001163]
	Learning Rate: 0.001163
	LOSS [training: 0.7080359887829603 | validation: 0.8575177561922962]
	TIME [epoch: 9.74 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6035211628540383		[learning rate: 0.0011588]
	Learning Rate: 0.00115878
	LOSS [training: 0.6035211628540383 | validation: 0.9042390207972568]
	TIME [epoch: 9.73 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6058977040627473		[learning rate: 0.0011546]
	Learning Rate: 0.00115457
	LOSS [training: 0.6058977040627473 | validation: 0.8510705935955614]
	TIME [epoch: 9.71 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5516409882402048		[learning rate: 0.0011504]
	Learning Rate: 0.00115038
	LOSS [training: 0.5516409882402048 | validation: 0.8342543001389621]
	TIME [epoch: 9.73 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5856186816253137		[learning rate: 0.0011462]
	Learning Rate: 0.00114621
	LOSS [training: 0.5856186816253137 | validation: 0.9787541476504481]
	TIME [epoch: 9.73 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6282983028576308		[learning rate: 0.001142]
	Learning Rate: 0.00114205
	LOSS [training: 0.6282983028576308 | validation: 0.8612134901385273]
	TIME [epoch: 9.73 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6014025699798026		[learning rate: 0.0011379]
	Learning Rate: 0.0011379
	LOSS [training: 0.6014025699798026 | validation: 0.8284282330591364]
	TIME [epoch: 9.72 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6064515850659856		[learning rate: 0.0011338]
	Learning Rate: 0.00113377
	LOSS [training: 0.6064515850659856 | validation: 0.8186817814255182]
	TIME [epoch: 9.73 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5658510533369512		[learning rate: 0.0011297]
	Learning Rate: 0.00112966
	LOSS [training: 0.5658510533369512 | validation: 0.7492136655821842]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_700.pth
	Model improved!!!
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5699976355475487		[learning rate: 0.0011256]
	Learning Rate: 0.00112556
	LOSS [training: 0.5699976355475487 | validation: 0.9182001247543882]
	TIME [epoch: 9.73 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.620714531006482		[learning rate: 0.0011215]
	Learning Rate: 0.00112147
	LOSS [training: 0.620714531006482 | validation: 0.87183089023728]
	TIME [epoch: 9.73 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6312374979739273		[learning rate: 0.0011174]
	Learning Rate: 0.0011174
	LOSS [training: 0.6312374979739273 | validation: 0.9097509836075187]
	TIME [epoch: 9.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6253229975711205		[learning rate: 0.0011133]
	Learning Rate: 0.00111335
	LOSS [training: 0.6253229975711205 | validation: 0.8880616720492543]
	TIME [epoch: 9.72 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.55933803048963		[learning rate: 0.0011093]
	Learning Rate: 0.00110931
	LOSS [training: 0.55933803048963 | validation: 0.8350067687960959]
	TIME [epoch: 9.72 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5906157038833686		[learning rate: 0.0011053]
	Learning Rate: 0.00110528
	LOSS [training: 0.5906157038833686 | validation: 0.8374559614925369]
	TIME [epoch: 9.74 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5684688812097086		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.5684688812097086 | validation: 0.919214791194523]
	TIME [epoch: 9.71 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6248937258023628		[learning rate: 0.0010973]
	Learning Rate: 0.00109728
	LOSS [training: 0.6248937258023628 | validation: 0.8953067776071524]
	TIME [epoch: 9.73 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5981317067937507		[learning rate: 0.0010933]
	Learning Rate: 0.00109329
	LOSS [training: 0.5981317067937507 | validation: 0.8737175286467573]
	TIME [epoch: 9.74 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5758812141278269		[learning rate: 0.0010893]
	Learning Rate: 0.00108933
	LOSS [training: 0.5758812141278269 | validation: 0.8215090767159541]
	TIME [epoch: 9.72 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5964018805579755		[learning rate: 0.0010854]
	Learning Rate: 0.00108537
	LOSS [training: 0.5964018805579755 | validation: 0.8269005518096577]
	TIME [epoch: 9.71 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5959616686711731		[learning rate: 0.0010814]
	Learning Rate: 0.00108143
	LOSS [training: 0.5959616686711731 | validation: 0.8392822697402398]
	TIME [epoch: 9.71 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6520414217686875		[learning rate: 0.0010775]
	Learning Rate: 0.00107751
	LOSS [training: 0.6520414217686875 | validation: 0.9801224788544767]
	TIME [epoch: 9.73 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6462573981978869		[learning rate: 0.0010736]
	Learning Rate: 0.0010736
	LOSS [training: 0.6462573981978869 | validation: 0.9694617005562822]
	TIME [epoch: 9.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5979032429132166		[learning rate: 0.0010697]
	Learning Rate: 0.0010697
	LOSS [training: 0.5979032429132166 | validation: 0.9864559220070611]
	TIME [epoch: 9.72 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5898095429226947		[learning rate: 0.0010658]
	Learning Rate: 0.00106582
	LOSS [training: 0.5898095429226947 | validation: 0.8530424537156848]
	TIME [epoch: 9.73 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6198488326284586		[learning rate: 0.001062]
	Learning Rate: 0.00106195
	LOSS [training: 0.6198488326284586 | validation: 0.8055082157417038]
	TIME [epoch: 9.72 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7160051638957478		[learning rate: 0.0010581]
	Learning Rate: 0.0010581
	LOSS [training: 0.7160051638957478 | validation: 0.8119904160617887]
	TIME [epoch: 9.72 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5955056691343042		[learning rate: 0.0010543]
	Learning Rate: 0.00105426
	LOSS [training: 0.5955056691343042 | validation: 0.9305481113951715]
	TIME [epoch: 9.73 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5889258507419546		[learning rate: 0.0010504]
	Learning Rate: 0.00105043
	LOSS [training: 0.5889258507419546 | validation: 0.7862784991199345]
	TIME [epoch: 9.71 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.616277146227356		[learning rate: 0.0010466]
	Learning Rate: 0.00104662
	LOSS [training: 0.616277146227356 | validation: 0.8361849717132609]
	TIME [epoch: 9.71 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5708642601158016		[learning rate: 0.0010428]
	Learning Rate: 0.00104282
	LOSS [training: 0.5708642601158016 | validation: 0.9091400756363754]
	TIME [epoch: 9.71 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5878186081965604		[learning rate: 0.001039]
	Learning Rate: 0.00103904
	LOSS [training: 0.5878186081965604 | validation: 0.9233062414908838]
	TIME [epoch: 9.73 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6109668738118679		[learning rate: 0.0010353]
	Learning Rate: 0.00103527
	LOSS [training: 0.6109668738118679 | validation: 0.8569971368692342]
	TIME [epoch: 9.71 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5676928584689908		[learning rate: 0.0010315]
	Learning Rate: 0.00103151
	LOSS [training: 0.5676928584689908 | validation: 0.8385858463053808]
	TIME [epoch: 9.71 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5431105221319731		[learning rate: 0.0010278]
	Learning Rate: 0.00102777
	LOSS [training: 0.5431105221319731 | validation: 0.9742021226062962]
	TIME [epoch: 9.72 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5948721557847579		[learning rate: 0.001024]
	Learning Rate: 0.00102404
	LOSS [training: 0.5948721557847579 | validation: 0.8756895407681694]
	TIME [epoch: 9.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.568582048198766		[learning rate: 0.0010203]
	Learning Rate: 0.00102032
	LOSS [training: 0.568582048198766 | validation: 1.0023907866364348]
	TIME [epoch: 9.71 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5830922480839626		[learning rate: 0.0010166]
	Learning Rate: 0.00101662
	LOSS [training: 0.5830922480839626 | validation: 0.8598774278060332]
	TIME [epoch: 9.73 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5851111398536045		[learning rate: 0.0010129]
	Learning Rate: 0.00101293
	LOSS [training: 0.5851111398536045 | validation: 1.1704527859567084]
	TIME [epoch: 9.71 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6095886912811043		[learning rate: 0.0010093]
	Learning Rate: 0.00100925
	LOSS [training: 0.6095886912811043 | validation: 1.0114030440146282]
	TIME [epoch: 9.71 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5990820236833052		[learning rate: 0.0010056]
	Learning Rate: 0.00100559
	LOSS [training: 0.5990820236833052 | validation: 0.9002516513201786]
	TIME [epoch: 9.71 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5965778036508319		[learning rate: 0.0010019]
	Learning Rate: 0.00100194
	LOSS [training: 0.5965778036508319 | validation: 0.9837011774872959]
	TIME [epoch: 9.72 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6839371449100529		[learning rate: 0.0009983]
	Learning Rate: 0.000998305
	LOSS [training: 0.6839371449100529 | validation: 0.9808056690757658]
	TIME [epoch: 9.71 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5884782614034971		[learning rate: 0.00099468]
	Learning Rate: 0.000994682
	LOSS [training: 0.5884782614034971 | validation: 0.9595901484021796]
	TIME [epoch: 9.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5633818529992997		[learning rate: 0.00099107]
	Learning Rate: 0.000991072
	LOSS [training: 0.5633818529992997 | validation: 0.779978814703205]
	TIME [epoch: 9.72 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5722486728556884		[learning rate: 0.00098748]
	Learning Rate: 0.000987475
	LOSS [training: 0.5722486728556884 | validation: 0.8234327292528003]
	TIME [epoch: 9.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8399187140569488		[learning rate: 0.00098389]
	Learning Rate: 0.000983892
	LOSS [training: 0.8399187140569488 | validation: 0.9740799322679271]
	TIME [epoch: 9.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5675569548618045		[learning rate: 0.00098032]
	Learning Rate: 0.000980321
	LOSS [training: 0.5675569548618045 | validation: 0.7899830712259049]
	TIME [epoch: 9.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5270451773741669		[learning rate: 0.00097676]
	Learning Rate: 0.000976764
	LOSS [training: 0.5270451773741669 | validation: 0.7849280879948798]
	TIME [epoch: 9.72 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.610105375392638		[learning rate: 0.00097322]
	Learning Rate: 0.000973219
	LOSS [training: 0.610105375392638 | validation: 0.8866370645058713]
	TIME [epoch: 9.71 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5639097458192944		[learning rate: 0.00096969]
	Learning Rate: 0.000969687
	LOSS [training: 0.5639097458192944 | validation: 0.8861497124922799]
	TIME [epoch: 9.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5930673300539151		[learning rate: 0.00096617]
	Learning Rate: 0.000966168
	LOSS [training: 0.5930673300539151 | validation: 0.8572734460882913]
	TIME [epoch: 9.71 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5746369584298564		[learning rate: 0.00096266]
	Learning Rate: 0.000962662
	LOSS [training: 0.5746369584298564 | validation: 0.9997789376639636]
	TIME [epoch: 9.72 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5428623400979309		[learning rate: 0.00095917]
	Learning Rate: 0.000959168
	LOSS [training: 0.5428623400979309 | validation: 0.7854479129699482]
	TIME [epoch: 9.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.521434494958629		[learning rate: 0.00095569]
	Learning Rate: 0.000955687
	LOSS [training: 0.521434494958629 | validation: 0.8111923608792335]
	TIME [epoch: 9.72 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5512252488207691		[learning rate: 0.00095222]
	Learning Rate: 0.000952219
	LOSS [training: 0.5512252488207691 | validation: 0.8045650403774616]
	TIME [epoch: 9.72 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5998812469208794		[learning rate: 0.00094876]
	Learning Rate: 0.000948763
	LOSS [training: 0.5998812469208794 | validation: 1.0004991357424475]
	TIME [epoch: 9.71 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5458125733246583		[learning rate: 0.00094532]
	Learning Rate: 0.00094532
	LOSS [training: 0.5458125733246583 | validation: 0.8321240445358682]
	TIME [epoch: 9.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5554158618804885		[learning rate: 0.00094189]
	Learning Rate: 0.000941889
	LOSS [training: 0.5554158618804885 | validation: 0.9123481628329433]
	TIME [epoch: 9.73 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5340956003868121		[learning rate: 0.00093847]
	Learning Rate: 0.000938471
	LOSS [training: 0.5340956003868121 | validation: 0.8317457362100288]
	TIME [epoch: 9.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5378849706763292		[learning rate: 0.00093507]
	Learning Rate: 0.000935066
	LOSS [training: 0.5378849706763292 | validation: 0.8049735064723238]
	TIME [epoch: 9.71 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5472969110656062		[learning rate: 0.00093167]
	Learning Rate: 0.000931672
	LOSS [training: 0.5472969110656062 | validation: 0.8373802542973059]
	TIME [epoch: 9.73 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49029459975349765		[learning rate: 0.00092829]
	Learning Rate: 0.000928291
	LOSS [training: 0.49029459975349765 | validation: 0.8008735461433074]
	TIME [epoch: 9.72 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.66566790876353		[learning rate: 0.00092492]
	Learning Rate: 0.000924922
	LOSS [training: 0.66566790876353 | validation: 0.8288225473468285]
	TIME [epoch: 9.71 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6118956792629712		[learning rate: 0.00092157]
	Learning Rate: 0.000921566
	LOSS [training: 0.6118956792629712 | validation: 0.9372719749538371]
	TIME [epoch: 9.72 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6599757093763962		[learning rate: 0.00091822]
	Learning Rate: 0.000918221
	LOSS [training: 0.6599757093763962 | validation: 0.987801495127351]
	TIME [epoch: 9.73 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5337761435594179		[learning rate: 0.00091489]
	Learning Rate: 0.000914889
	LOSS [training: 0.5337761435594179 | validation: 0.8102570688853188]
	TIME [epoch: 9.71 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49652789764789074		[learning rate: 0.00091157]
	Learning Rate: 0.000911569
	LOSS [training: 0.49652789764789074 | validation: 0.8271541037006347]
	TIME [epoch: 9.71 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5276482384413362		[learning rate: 0.00090826]
	Learning Rate: 0.000908261
	LOSS [training: 0.5276482384413362 | validation: 0.799441609465216]
	TIME [epoch: 9.73 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5804882794213758		[learning rate: 0.00090496]
	Learning Rate: 0.000904965
	LOSS [training: 0.5804882794213758 | validation: 0.898143321494553]
	TIME [epoch: 9.72 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7291694492421968		[learning rate: 0.00090168]
	Learning Rate: 0.00090168
	LOSS [training: 0.7291694492421968 | validation: 1.0705815256088829]
	TIME [epoch: 9.71 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6017941844858201		[learning rate: 0.00089841]
	Learning Rate: 0.000898408
	LOSS [training: 0.6017941844858201 | validation: 1.770303604080323]
	TIME [epoch: 9.72 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.854574219553942		[learning rate: 0.00089515]
	Learning Rate: 0.000895148
	LOSS [training: 0.854574219553942 | validation: 0.811975835229729]
	TIME [epoch: 9.72 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.529946983067368		[learning rate: 0.0008919]
	Learning Rate: 0.000891899
	LOSS [training: 0.529946983067368 | validation: 1.1044054666093517]
	TIME [epoch: 9.71 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5835067395101274		[learning rate: 0.00088866]
	Learning Rate: 0.000888663
	LOSS [training: 0.5835067395101274 | validation: 0.8454370326642263]
	TIME [epoch: 9.73 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5352322289976157		[learning rate: 0.00088544]
	Learning Rate: 0.000885438
	LOSS [training: 0.5352322289976157 | validation: 1.0437628841097704]
	TIME [epoch: 9.74 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7751334044467295		[learning rate: 0.00088222]
	Learning Rate: 0.000882224
	LOSS [training: 0.7751334044467295 | validation: 0.9914991324464458]
	TIME [epoch: 9.71 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6901041312304175		[learning rate: 0.00087902]
	Learning Rate: 0.000879022
	LOSS [training: 0.6901041312304175 | validation: 0.8582185032784029]
	TIME [epoch: 9.72 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5507738996312255		[learning rate: 0.00087583]
	Learning Rate: 0.000875833
	LOSS [training: 0.5507738996312255 | validation: 0.994013487221845]
	TIME [epoch: 9.73 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5300812071100744		[learning rate: 0.00087265]
	Learning Rate: 0.000872654
	LOSS [training: 0.5300812071100744 | validation: 0.9684412580987487]
	TIME [epoch: 9.72 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6094655600587422		[learning rate: 0.00086949]
	Learning Rate: 0.000869487
	LOSS [training: 0.6094655600587422 | validation: 0.7847530803979392]
	TIME [epoch: 9.72 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49539543474074854		[learning rate: 0.00086633]
	Learning Rate: 0.000866332
	LOSS [training: 0.49539543474074854 | validation: 0.7948152986052901]
	TIME [epoch: 9.71 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47404106090252274		[learning rate: 0.00086319]
	Learning Rate: 0.000863188
	LOSS [training: 0.47404106090252274 | validation: 0.8157289283078133]
	TIME [epoch: 9.73 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4998149017599694		[learning rate: 0.00086006]
	Learning Rate: 0.000860055
	LOSS [training: 0.4998149017599694 | validation: 0.7903305896332515]
	TIME [epoch: 9.71 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5203793559687372		[learning rate: 0.00085693]
	Learning Rate: 0.000856934
	LOSS [training: 0.5203793559687372 | validation: 0.7802249859406303]
	TIME [epoch: 9.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4763473223814324		[learning rate: 0.00085382]
	Learning Rate: 0.000853824
	LOSS [training: 0.4763473223814324 | validation: 0.8134692132218415]
	TIME [epoch: 9.73 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48533089079062997		[learning rate: 0.00085073]
	Learning Rate: 0.000850726
	LOSS [training: 0.48533089079062997 | validation: 0.9092516089191071]
	TIME [epoch: 9.71 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5174214379200713		[learning rate: 0.00084764]
	Learning Rate: 0.000847638
	LOSS [training: 0.5174214379200713 | validation: 0.7720610389160777]
	TIME [epoch: 9.71 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5162781817687206		[learning rate: 0.00084456]
	Learning Rate: 0.000844562
	LOSS [training: 0.5162781817687206 | validation: 0.8258677748170559]
	TIME [epoch: 9.73 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.526980995708967		[learning rate: 0.0008415]
	Learning Rate: 0.000841497
	LOSS [training: 0.526980995708967 | validation: 1.3385707355798184]
	TIME [epoch: 9.72 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7674484325374743		[learning rate: 0.00083844]
	Learning Rate: 0.000838443
	LOSS [training: 0.7674484325374743 | validation: 0.904514228447795]
	TIME [epoch: 9.72 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5469590628359486		[learning rate: 0.0008354]
	Learning Rate: 0.000835401
	LOSS [training: 0.5469590628359486 | validation: 1.159131101135808]
	TIME [epoch: 9.71 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6006120939994704		[learning rate: 0.00083237]
	Learning Rate: 0.000832369
	LOSS [training: 0.6006120939994704 | validation: 0.8534357991235864]
	TIME [epoch: 9.74 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5088503669999895		[learning rate: 0.00082935]
	Learning Rate: 0.000829348
	LOSS [training: 0.5088503669999895 | validation: 0.8717876372058403]
	TIME [epoch: 9.71 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5471003358054127		[learning rate: 0.00082634]
	Learning Rate: 0.000826338
	LOSS [training: 0.5471003358054127 | validation: 0.8315445145498351]
	TIME [epoch: 9.72 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5085837990052462		[learning rate: 0.00082334]
	Learning Rate: 0.00082334
	LOSS [training: 0.5085837990052462 | validation: 0.8161769857123886]
	TIME [epoch: 9.73 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46245901356766483		[learning rate: 0.00082035]
	Learning Rate: 0.000820352
	LOSS [training: 0.46245901356766483 | validation: 1.0293543582651383]
	TIME [epoch: 9.72 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5466622115361558		[learning rate: 0.00081737]
	Learning Rate: 0.000817375
	LOSS [training: 0.5466622115361558 | validation: 0.7660371123852694]
	TIME [epoch: 9.72 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5340858639217952		[learning rate: 0.00081441]
	Learning Rate: 0.000814408
	LOSS [training: 0.5340858639217952 | validation: 0.9302520280324724]
	TIME [epoch: 9.72 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5856158933374729		[learning rate: 0.00081145]
	Learning Rate: 0.000811453
	LOSS [training: 0.5856158933374729 | validation: 0.9126161412226168]
	TIME [epoch: 9.72 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5849542762058679		[learning rate: 0.00080851]
	Learning Rate: 0.000808508
	LOSS [training: 0.5849542762058679 | validation: 0.7712724507553328]
	TIME [epoch: 9.71 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4900923999535644		[learning rate: 0.00080557]
	Learning Rate: 0.000805574
	LOSS [training: 0.4900923999535644 | validation: 0.7597421622698691]
	TIME [epoch: 9.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.592239039907328		[learning rate: 0.00080265]
	Learning Rate: 0.00080265
	LOSS [training: 0.592239039907328 | validation: 0.9158792058865416]
	TIME [epoch: 9.73 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5491509279876136		[learning rate: 0.00079974]
	Learning Rate: 0.000799737
	LOSS [training: 0.5491509279876136 | validation: 0.8068639245461918]
	TIME [epoch: 9.72 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5378328558704014		[learning rate: 0.00079684]
	Learning Rate: 0.000796835
	LOSS [training: 0.5378328558704014 | validation: 0.8073282445398249]
	TIME [epoch: 9.72 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5001900520470401		[learning rate: 0.00079394]
	Learning Rate: 0.000793943
	LOSS [training: 0.5001900520470401 | validation: 0.7546495047269408]
	TIME [epoch: 9.73 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5763874265918509		[learning rate: 0.00079106]
	Learning Rate: 0.000791062
	LOSS [training: 0.5763874265918509 | validation: 0.7796598740368091]
	TIME [epoch: 9.74 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5413567186125474		[learning rate: 0.00078819]
	Learning Rate: 0.000788191
	LOSS [training: 0.5413567186125474 | validation: 0.7795927539246474]
	TIME [epoch: 9.72 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4834267056999675		[learning rate: 0.00078533]
	Learning Rate: 0.000785331
	LOSS [training: 0.4834267056999675 | validation: 0.8442644544061022]
	TIME [epoch: 9.71 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5480074550247489		[learning rate: 0.00078248]
	Learning Rate: 0.000782481
	LOSS [training: 0.5480074550247489 | validation: 0.9165097891147889]
	TIME [epoch: 9.73 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5946990790813648		[learning rate: 0.00077964]
	Learning Rate: 0.000779641
	LOSS [training: 0.5946990790813648 | validation: 0.8324322008533134]
	TIME [epoch: 9.71 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47661751702963107		[learning rate: 0.00077681]
	Learning Rate: 0.000776812
	LOSS [training: 0.47661751702963107 | validation: 0.827286026415627]
	TIME [epoch: 9.71 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5122070876211599		[learning rate: 0.00077399]
	Learning Rate: 0.000773993
	LOSS [training: 0.5122070876211599 | validation: 0.79318398709038]
	TIME [epoch: 9.73 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.497099322590093		[learning rate: 0.00077118]
	Learning Rate: 0.000771184
	LOSS [training: 0.497099322590093 | validation: 0.8260607085766881]
	TIME [epoch: 9.71 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6037205921128594		[learning rate: 0.00076839]
	Learning Rate: 0.000768385
	LOSS [training: 0.6037205921128594 | validation: 0.8440052047786978]
	TIME [epoch: 9.72 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4950066011524627		[learning rate: 0.0007656]
	Learning Rate: 0.000765597
	LOSS [training: 0.4950066011524627 | validation: 0.7616004467601788]
	TIME [epoch: 9.71 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5212346831855911		[learning rate: 0.00076282]
	Learning Rate: 0.000762818
	LOSS [training: 0.5212346831855911 | validation: 0.7838749101083863]
	TIME [epoch: 9.72 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46558998699004794		[learning rate: 0.00076005]
	Learning Rate: 0.00076005
	LOSS [training: 0.46558998699004794 | validation: 0.753872622145025]
	TIME [epoch: 9.73 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5167389650225968		[learning rate: 0.00075729]
	Learning Rate: 0.000757292
	LOSS [training: 0.5167389650225968 | validation: 0.792699801400494]
	TIME [epoch: 9.73 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4889002249137442		[learning rate: 0.00075454]
	Learning Rate: 0.000754543
	LOSS [training: 0.4889002249137442 | validation: 0.8150892115075338]
	TIME [epoch: 9.73 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4657274902870253		[learning rate: 0.00075181]
	Learning Rate: 0.000751805
	LOSS [training: 0.4657274902870253 | validation: 0.824143467246178]
	TIME [epoch: 9.72 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4532333454406091		[learning rate: 0.00074908]
	Learning Rate: 0.000749077
	LOSS [training: 0.4532333454406091 | validation: 1.0128495315639052]
	TIME [epoch: 9.72 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5838362105019488		[learning rate: 0.00074636]
	Learning Rate: 0.000746358
	LOSS [training: 0.5838362105019488 | validation: 0.8121304988226663]
	TIME [epoch: 9.73 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.450951241241545		[learning rate: 0.00074365]
	Learning Rate: 0.00074365
	LOSS [training: 0.450951241241545 | validation: 0.8065658922263829]
	TIME [epoch: 9.73 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47687501607265215		[learning rate: 0.00074095]
	Learning Rate: 0.000740951
	LOSS [training: 0.47687501607265215 | validation: 0.8772570851486109]
	TIME [epoch: 9.71 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4577765995278719		[learning rate: 0.00073826]
	Learning Rate: 0.000738262
	LOSS [training: 0.4577765995278719 | validation: 0.8343717038860075]
	TIME [epoch: 9.72 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5143521361137668		[learning rate: 0.00073558]
	Learning Rate: 0.000735583
	LOSS [training: 0.5143521361137668 | validation: 0.7349266994331041]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5246702863964349		[learning rate: 0.00073291]
	Learning Rate: 0.000732913
	LOSS [training: 0.5246702863964349 | validation: 0.7994866229823537]
	TIME [epoch: 9.71 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.57422854235924		[learning rate: 0.00073025]
	Learning Rate: 0.000730254
	LOSS [training: 0.57422854235924 | validation: 0.9557260001913366]
	TIME [epoch: 9.72 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5565949078220902		[learning rate: 0.0007276]
	Learning Rate: 0.000727603
	LOSS [training: 0.5565949078220902 | validation: 0.7967550774535426]
	TIME [epoch: 9.73 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5145730436305658		[learning rate: 0.00072496]
	Learning Rate: 0.000724963
	LOSS [training: 0.5145730436305658 | validation: 0.7477997538859353]
	TIME [epoch: 9.71 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5182017814122456		[learning rate: 0.00072233]
	Learning Rate: 0.000722332
	LOSS [training: 0.5182017814122456 | validation: 0.7591067003097317]
	TIME [epoch: 9.71 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43677925253977223		[learning rate: 0.00071971]
	Learning Rate: 0.000719711
	LOSS [training: 0.43677925253977223 | validation: 0.8877311769254804]
	TIME [epoch: 9.71 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5265420453870112		[learning rate: 0.0007171]
	Learning Rate: 0.000717099
	LOSS [training: 0.5265420453870112 | validation: 0.7528215960628964]
	TIME [epoch: 9.73 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5006832232986718		[learning rate: 0.0007145]
	Learning Rate: 0.000714496
	LOSS [training: 0.5006832232986718 | validation: 0.8269109227602689]
	TIME [epoch: 9.72 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48351849341301634		[learning rate: 0.0007119]
	Learning Rate: 0.000711903
	LOSS [training: 0.48351849341301634 | validation: 0.8099479654228771]
	TIME [epoch: 9.69 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4759393256376672		[learning rate: 0.00070932]
	Learning Rate: 0.00070932
	LOSS [training: 0.4759393256376672 | validation: 0.9426804213877564]
	TIME [epoch: 9.72 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5090974965795934		[learning rate: 0.00070675]
	Learning Rate: 0.000706746
	LOSS [training: 0.5090974965795934 | validation: 0.7732698337058913]
	TIME [epoch: 9.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47226651150495835		[learning rate: 0.00070418]
	Learning Rate: 0.000704181
	LOSS [training: 0.47226651150495835 | validation: 0.7761738265943815]
	TIME [epoch: 9.71 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43233095223177676		[learning rate: 0.00070163]
	Learning Rate: 0.000701625
	LOSS [training: 0.43233095223177676 | validation: 0.7623944814604164]
	TIME [epoch: 9.71 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4536438579481154		[learning rate: 0.00069908]
	Learning Rate: 0.000699079
	LOSS [training: 0.4536438579481154 | validation: 0.7367658397190207]
	TIME [epoch: 9.72 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47847743627410627		[learning rate: 0.00069654]
	Learning Rate: 0.000696542
	LOSS [training: 0.47847743627410627 | validation: 1.1445914419094478]
	TIME [epoch: 9.71 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6161429809390461		[learning rate: 0.00069401]
	Learning Rate: 0.000694014
	LOSS [training: 0.6161429809390461 | validation: 0.7951484778734751]
	TIME [epoch: 9.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4665071966347318		[learning rate: 0.0006915]
	Learning Rate: 0.000691496
	LOSS [training: 0.4665071966347318 | validation: 0.7933600337509039]
	TIME [epoch: 9.74 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44134774888257056		[learning rate: 0.00068899]
	Learning Rate: 0.000688986
	LOSS [training: 0.44134774888257056 | validation: 0.7829369145624692]
	TIME [epoch: 9.71 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4513946255668779		[learning rate: 0.00068649]
	Learning Rate: 0.000686486
	LOSS [training: 0.4513946255668779 | validation: 0.7277078583569463]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49975580487601967		[learning rate: 0.00068399]
	Learning Rate: 0.000683994
	LOSS [training: 0.49975580487601967 | validation: 0.7555567557841574]
	TIME [epoch: 9.73 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4535443783966683		[learning rate: 0.00068151]
	Learning Rate: 0.000681512
	LOSS [training: 0.4535443783966683 | validation: 0.8613466372325266]
	TIME [epoch: 9.71 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5813153722680963		[learning rate: 0.00067904]
	Learning Rate: 0.000679039
	LOSS [training: 0.5813153722680963 | validation: 0.8270976614051432]
	TIME [epoch: 9.71 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4426886671380605		[learning rate: 0.00067657]
	Learning Rate: 0.000676575
	LOSS [training: 0.4426886671380605 | validation: 0.7096004876464003]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_841.pth
	Model improved!!!
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4817513685064463		[learning rate: 0.00067412]
	Learning Rate: 0.00067412
	LOSS [training: 0.4817513685064463 | validation: 0.736768450492399]
	TIME [epoch: 9.72 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4834503908828385		[learning rate: 0.00067167]
	Learning Rate: 0.000671673
	LOSS [training: 0.4834503908828385 | validation: 0.8358267526407029]
	TIME [epoch: 9.71 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4846730324125085		[learning rate: 0.00066924]
	Learning Rate: 0.000669235
	LOSS [training: 0.4846730324125085 | validation: 0.7341376293531195]
	TIME [epoch: 9.71 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5292683100626464		[learning rate: 0.00066681]
	Learning Rate: 0.000666807
	LOSS [training: 0.5292683100626464 | validation: 0.7855071460798868]
	TIME [epoch: 9.72 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.489978747389835		[learning rate: 0.00066439]
	Learning Rate: 0.000664387
	LOSS [training: 0.489978747389835 | validation: 0.747522305343411]
	TIME [epoch: 9.71 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44758805053188533		[learning rate: 0.00066198]
	Learning Rate: 0.000661976
	LOSS [training: 0.44758805053188533 | validation: 0.7506880490864862]
	TIME [epoch: 9.71 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5497107684962422		[learning rate: 0.00065957]
	Learning Rate: 0.000659573
	LOSS [training: 0.5497107684962422 | validation: 0.8633717268499278]
	TIME [epoch: 9.72 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5224905832897883		[learning rate: 0.00065718]
	Learning Rate: 0.00065718
	LOSS [training: 0.5224905832897883 | validation: 0.8172542760417895]
	TIME [epoch: 9.72 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4944842577132781		[learning rate: 0.00065479]
	Learning Rate: 0.000654795
	LOSS [training: 0.4944842577132781 | validation: 0.7790549616999661]
	TIME [epoch: 9.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.477074537316762		[learning rate: 0.00065242]
	Learning Rate: 0.000652419
	LOSS [training: 0.477074537316762 | validation: 0.8194686566229118]
	TIME [epoch: 9.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4561814043890703		[learning rate: 0.00065005]
	Learning Rate: 0.000650051
	LOSS [training: 0.4561814043890703 | validation: 0.714218469810998]
	TIME [epoch: 9.71 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48629354441340994		[learning rate: 0.00064769]
	Learning Rate: 0.000647692
	LOSS [training: 0.48629354441340994 | validation: 0.7722423929215911]
	TIME [epoch: 9.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4970823171894748		[learning rate: 0.00064534]
	Learning Rate: 0.000645341
	LOSS [training: 0.4970823171894748 | validation: 0.7990671031568831]
	TIME [epoch: 9.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5308593754081706		[learning rate: 0.000643]
	Learning Rate: 0.000642999
	LOSS [training: 0.5308593754081706 | validation: 1.009880287662119]
	TIME [epoch: 9.72 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5523546278418169		[learning rate: 0.00064067]
	Learning Rate: 0.000640666
	LOSS [training: 0.5523546278418169 | validation: 1.0779292000295448]
	TIME [epoch: 9.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5183740983398742		[learning rate: 0.00063834]
	Learning Rate: 0.000638341
	LOSS [training: 0.5183740983398742 | validation: 0.9168573036059787]
	TIME [epoch: 9.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5149274801041761		[learning rate: 0.00063602]
	Learning Rate: 0.000636024
	LOSS [training: 0.5149274801041761 | validation: 0.8896143167226781]
	TIME [epoch: 9.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.505196510502834		[learning rate: 0.00063372]
	Learning Rate: 0.000633716
	LOSS [training: 0.505196510502834 | validation: 0.7510367021947545]
	TIME [epoch: 9.72 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45747996712268224		[learning rate: 0.00063142]
	Learning Rate: 0.000631416
	LOSS [training: 0.45747996712268224 | validation: 0.8142056316897527]
	TIME [epoch: 9.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4857647338826161		[learning rate: 0.00062912]
	Learning Rate: 0.000629125
	LOSS [training: 0.4857647338826161 | validation: 0.8007188783664243]
	TIME [epoch: 9.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4552175230011414		[learning rate: 0.00062684]
	Learning Rate: 0.000626842
	LOSS [training: 0.4552175230011414 | validation: 0.8352461235068142]
	TIME [epoch: 9.72 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4709520696498798		[learning rate: 0.00062457]
	Learning Rate: 0.000624567
	LOSS [training: 0.4709520696498798 | validation: 0.752258749326071]
	TIME [epoch: 9.7 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44099323590273204		[learning rate: 0.0006223]
	Learning Rate: 0.0006223
	LOSS [training: 0.44099323590273204 | validation: 0.7909363609709803]
	TIME [epoch: 9.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4420235553811941		[learning rate: 0.00062004]
	Learning Rate: 0.000620042
	LOSS [training: 0.4420235553811941 | validation: 0.7716361562729128]
	TIME [epoch: 9.71 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46459355323549617		[learning rate: 0.00061779]
	Learning Rate: 0.000617792
	LOSS [training: 0.46459355323549617 | validation: 0.8050765494497871]
	TIME [epoch: 9.71 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48778916696719754		[learning rate: 0.00061555]
	Learning Rate: 0.00061555
	LOSS [training: 0.48778916696719754 | validation: 0.8629502938272148]
	TIME [epoch: 9.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48253283234784455		[learning rate: 0.00061332]
	Learning Rate: 0.000613316
	LOSS [training: 0.48253283234784455 | validation: 0.7181836268485813]
	TIME [epoch: 9.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45506445394620787		[learning rate: 0.00061109]
	Learning Rate: 0.00061109
	LOSS [training: 0.45506445394620787 | validation: 0.8683928139065954]
	TIME [epoch: 9.72 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4979987359521646		[learning rate: 0.00060887]
	Learning Rate: 0.000608872
	LOSS [training: 0.4979987359521646 | validation: 0.750940080996763]
	TIME [epoch: 9.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4332123979754391		[learning rate: 0.00060666]
	Learning Rate: 0.000606663
	LOSS [training: 0.4332123979754391 | validation: 0.6975697882642597]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_871.pth
	Model improved!!!
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.514736970037089		[learning rate: 0.00060446]
	Learning Rate: 0.000604461
	LOSS [training: 0.514736970037089 | validation: 0.7349966332218881]
	TIME [epoch: 9.72 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6614809820149026		[learning rate: 0.00060227]
	Learning Rate: 0.000602268
	LOSS [training: 0.6614809820149026 | validation: 0.785119931461754]
	TIME [epoch: 9.71 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45118761980216754		[learning rate: 0.00060008]
	Learning Rate: 0.000600082
	LOSS [training: 0.45118761980216754 | validation: 0.7085085191061977]
	TIME [epoch: 9.71 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49977271498163656		[learning rate: 0.0005979]
	Learning Rate: 0.000597904
	LOSS [training: 0.49977271498163656 | validation: 0.7159903168812198]
	TIME [epoch: 9.71 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44269538916511025		[learning rate: 0.00059573]
	Learning Rate: 0.000595734
	LOSS [training: 0.44269538916511025 | validation: 0.7337892740324082]
	TIME [epoch: 9.72 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4496593325399691		[learning rate: 0.00059357]
	Learning Rate: 0.000593572
	LOSS [training: 0.4496593325399691 | validation: 0.7533275103341521]
	TIME [epoch: 9.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4265822515695218		[learning rate: 0.00059142]
	Learning Rate: 0.000591418
	LOSS [training: 0.4265822515695218 | validation: 0.8471171515123055]
	TIME [epoch: 9.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43137614092180093		[learning rate: 0.00058927]
	Learning Rate: 0.000589272
	LOSS [training: 0.43137614092180093 | validation: 0.7751015618513551]
	TIME [epoch: 9.71 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49584851527417395		[learning rate: 0.00058713]
	Learning Rate: 0.000587133
	LOSS [training: 0.49584851527417395 | validation: 0.713910545210316]
	TIME [epoch: 9.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49240906310934973		[learning rate: 0.000585]
	Learning Rate: 0.000585003
	LOSS [training: 0.49240906310934973 | validation: 0.7183572658520787]
	TIME [epoch: 9.69 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4595618387603223		[learning rate: 0.00058288]
	Learning Rate: 0.00058288
	LOSS [training: 0.4595618387603223 | validation: 0.7720232818310714]
	TIME [epoch: 9.71 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44839732609362526		[learning rate: 0.00058076]
	Learning Rate: 0.000580764
	LOSS [training: 0.44839732609362526 | validation: 0.7960263561415977]
	TIME [epoch: 9.71 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4208650883097541		[learning rate: 0.00057866]
	Learning Rate: 0.000578657
	LOSS [training: 0.4208650883097541 | validation: 0.7123048468624064]
	TIME [epoch: 9.71 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5025112726969082		[learning rate: 0.00057656]
	Learning Rate: 0.000576557
	LOSS [training: 0.5025112726969082 | validation: 0.7897671744410195]
	TIME [epoch: 9.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46850631673556753		[learning rate: 0.00057446]
	Learning Rate: 0.000574465
	LOSS [training: 0.46850631673556753 | validation: 0.7270154840056039]
	TIME [epoch: 9.72 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4233574795075882		[learning rate: 0.00057238]
	Learning Rate: 0.00057238
	LOSS [training: 0.4233574795075882 | validation: 0.7518546712890779]
	TIME [epoch: 9.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5197491628714921		[learning rate: 0.0005703]
	Learning Rate: 0.000570303
	LOSS [training: 0.5197491628714921 | validation: 0.767628104681387]
	TIME [epoch: 9.71 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4952816980992246		[learning rate: 0.00056823]
	Learning Rate: 0.000568233
	LOSS [training: 0.4952816980992246 | validation: 0.735544898278352]
	TIME [epoch: 9.71 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43849561156101746		[learning rate: 0.00056617]
	Learning Rate: 0.000566171
	LOSS [training: 0.43849561156101746 | validation: 0.7825116180443741]
	TIME [epoch: 9.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4409711983946152		[learning rate: 0.00056412]
	Learning Rate: 0.000564116
	LOSS [training: 0.4409711983946152 | validation: 0.6993991847698041]
	TIME [epoch: 9.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4261999384456906		[learning rate: 0.00056207]
	Learning Rate: 0.000562069
	LOSS [training: 0.4261999384456906 | validation: 0.7352126229947368]
	TIME [epoch: 9.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4265011672127651		[learning rate: 0.00056003]
	Learning Rate: 0.000560029
	LOSS [training: 0.4265011672127651 | validation: 0.761947963815077]
	TIME [epoch: 9.72 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4536975261188031		[learning rate: 0.000558]
	Learning Rate: 0.000557997
	LOSS [training: 0.4536975261188031 | validation: 0.7323959379309953]
	TIME [epoch: 9.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4165045834487714		[learning rate: 0.00055597]
	Learning Rate: 0.000555972
	LOSS [training: 0.4165045834487714 | validation: 0.7209615417440398]
	TIME [epoch: 9.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4272813784475412		[learning rate: 0.00055395]
	Learning Rate: 0.000553954
	LOSS [training: 0.4272813784475412 | validation: 0.7902684920980795]
	TIME [epoch: 9.71 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43612267546983263		[learning rate: 0.00055194]
	Learning Rate: 0.000551944
	LOSS [training: 0.43612267546983263 | validation: 0.7657752997330723]
	TIME [epoch: 9.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46393235774783326		[learning rate: 0.00054994]
	Learning Rate: 0.000549941
	LOSS [training: 0.46393235774783326 | validation: 0.6735816132379702]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_898.pth
	Model improved!!!
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49282094509668734		[learning rate: 0.00054794]
	Learning Rate: 0.000547945
	LOSS [training: 0.49282094509668734 | validation: 0.6785101490960466]
	TIME [epoch: 9.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4343644073152843		[learning rate: 0.00054596]
	Learning Rate: 0.000545956
	LOSS [training: 0.4343644073152843 | validation: 0.7161387759012664]
	TIME [epoch: 9.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45307071750736333		[learning rate: 0.00054397]
	Learning Rate: 0.000543975
	LOSS [training: 0.45307071750736333 | validation: 0.7455714011174464]
	TIME [epoch: 9.69 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4550405668541588		[learning rate: 0.000542]
	Learning Rate: 0.000542001
	LOSS [training: 0.4550405668541588 | validation: 0.6890807222799873]
	TIME [epoch: 9.69 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.539473606824403		[learning rate: 0.00054003]
	Learning Rate: 0.000540034
	LOSS [training: 0.539473606824403 | validation: 0.7787950900718221]
	TIME [epoch: 9.71 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4259060068399002		[learning rate: 0.00053807]
	Learning Rate: 0.000538074
	LOSS [training: 0.4259060068399002 | validation: 0.762390713401508]
	TIME [epoch: 9.69 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4467353119118543		[learning rate: 0.00053612]
	Learning Rate: 0.000536121
	LOSS [training: 0.4467353119118543 | validation: 0.7837678145163741]
	TIME [epoch: 9.69 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4835073382823638		[learning rate: 0.00053418]
	Learning Rate: 0.000534176
	LOSS [training: 0.4835073382823638 | validation: 0.9752099061908303]
	TIME [epoch: 9.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49535593875564177		[learning rate: 0.00053224]
	Learning Rate: 0.000532237
	LOSS [training: 0.49535593875564177 | validation: 0.7194976769213078]
	TIME [epoch: 9.69 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42568852871109175		[learning rate: 0.00053031]
	Learning Rate: 0.000530306
	LOSS [training: 0.42568852871109175 | validation: 0.7380759653045247]
	TIME [epoch: 9.69 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.445031016971183		[learning rate: 0.00052838]
	Learning Rate: 0.000528381
	LOSS [training: 0.445031016971183 | validation: 0.7160753870663499]
	TIME [epoch: 9.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4367261572465256		[learning rate: 0.00052646]
	Learning Rate: 0.000526464
	LOSS [training: 0.4367261572465256 | validation: 0.7346328729167795]
	TIME [epoch: 9.71 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5146336396736462		[learning rate: 0.00052455]
	Learning Rate: 0.000524553
	LOSS [training: 0.5146336396736462 | validation: 0.8643119733437317]
	TIME [epoch: 9.69 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4437931034446942		[learning rate: 0.00052265]
	Learning Rate: 0.000522649
	LOSS [training: 0.4437931034446942 | validation: 0.7150727407285646]
	TIME [epoch: 9.69 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47867034444201		[learning rate: 0.00052075]
	Learning Rate: 0.000520753
	LOSS [training: 0.47867034444201 | validation: 0.9789416960075805]
	TIME [epoch: 9.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46477305201141517		[learning rate: 0.00051886]
	Learning Rate: 0.000518863
	LOSS [training: 0.46477305201141517 | validation: 0.7331212875299936]
	TIME [epoch: 9.69 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4522802198538975		[learning rate: 0.00051698]
	Learning Rate: 0.00051698
	LOSS [training: 0.4522802198538975 | validation: 0.8164513738617165]
	TIME [epoch: 9.69 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42190635681891797		[learning rate: 0.0005151]
	Learning Rate: 0.000515104
	LOSS [training: 0.42190635681891797 | validation: 0.7296304887625297]
	TIME [epoch: 9.69 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4183416461796631		[learning rate: 0.00051323]
	Learning Rate: 0.000513235
	LOSS [training: 0.4183416461796631 | validation: 0.7799092236455489]
	TIME [epoch: 9.7 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5876019277729746		[learning rate: 0.00051137]
	Learning Rate: 0.000511372
	LOSS [training: 0.5876019277729746 | validation: 0.9240017422929843]
	TIME [epoch: 9.69 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46999868078260504		[learning rate: 0.00050952]
	Learning Rate: 0.000509516
	LOSS [training: 0.46999868078260504 | validation: 0.7602325248930617]
	TIME [epoch: 9.69 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4664657872091017		[learning rate: 0.00050767]
	Learning Rate: 0.000507667
	LOSS [training: 0.4664657872091017 | validation: 0.8099479099804464]
	TIME [epoch: 9.71 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41618805760418826		[learning rate: 0.00050582]
	Learning Rate: 0.000505825
	LOSS [training: 0.41618805760418826 | validation: 0.7085759153329056]
	TIME [epoch: 9.69 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40265815084518464		[learning rate: 0.00050399]
	Learning Rate: 0.000503989
	LOSS [training: 0.40265815084518464 | validation: 0.7025535585075412]
	TIME [epoch: 9.69 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41703622510014576		[learning rate: 0.00050216]
	Learning Rate: 0.00050216
	LOSS [training: 0.41703622510014576 | validation: 0.7551374083823994]
	TIME [epoch: 9.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4244463814780607		[learning rate: 0.00050034]
	Learning Rate: 0.000500338
	LOSS [training: 0.4244463814780607 | validation: 0.7620461355967735]
	TIME [epoch: 9.69 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4285889884465871		[learning rate: 0.00049852]
	Learning Rate: 0.000498522
	LOSS [training: 0.4285889884465871 | validation: 0.8110003716471721]
	TIME [epoch: 9.69 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.504569615697358		[learning rate: 0.00049671]
	Learning Rate: 0.000496713
	LOSS [training: 0.504569615697358 | validation: 0.7067445597400912]
	TIME [epoch: 9.69 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.465540237175255		[learning rate: 0.00049491]
	Learning Rate: 0.00049491
	LOSS [training: 0.465540237175255 | validation: 0.7197724805864403]
	TIME [epoch: 9.71 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.501531745666797		[learning rate: 0.00049311]
	Learning Rate: 0.000493114
	LOSS [training: 0.501531745666797 | validation: 0.73586873591343]
	TIME [epoch: 9.69 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45282733530595143		[learning rate: 0.00049132]
	Learning Rate: 0.000491325
	LOSS [training: 0.45282733530595143 | validation: 0.7652755778284462]
	TIME [epoch: 9.69 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4837083740590785		[learning rate: 0.00048954]
	Learning Rate: 0.000489542
	LOSS [training: 0.4837083740590785 | validation: 0.795978816124719]
	TIME [epoch: 9.71 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4145397116935114		[learning rate: 0.00048776]
	Learning Rate: 0.000487765
	LOSS [training: 0.4145397116935114 | validation: 0.7305970699989657]
	TIME [epoch: 9.69 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4887826532518151		[learning rate: 0.00048599]
	Learning Rate: 0.000485995
	LOSS [training: 0.4887826532518151 | validation: 0.7202514859915025]
	TIME [epoch: 9.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5419584427143189		[learning rate: 0.00048423]
	Learning Rate: 0.000484231
	LOSS [training: 0.5419584427143189 | validation: 0.7945720788468899]
	TIME [epoch: 9.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4020685724152774		[learning rate: 0.00048247]
	Learning Rate: 0.000482474
	LOSS [training: 0.4020685724152774 | validation: 0.7625949068382275]
	TIME [epoch: 9.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5630575582459071		[learning rate: 0.00048072]
	Learning Rate: 0.000480723
	LOSS [training: 0.5630575582459071 | validation: 0.7991222894319009]
	TIME [epoch: 9.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4350004236672402		[learning rate: 0.00047898]
	Learning Rate: 0.000478978
	LOSS [training: 0.4350004236672402 | validation: 0.6825768805450375]
	TIME [epoch: 9.69 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4325802111799799		[learning rate: 0.00047724]
	Learning Rate: 0.00047724
	LOSS [training: 0.4325802111799799 | validation: 0.7152906971987474]
	TIME [epoch: 9.72 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45423259841146757		[learning rate: 0.00047551]
	Learning Rate: 0.000475508
	LOSS [training: 0.45423259841146757 | validation: 0.7420517812027463]
	TIME [epoch: 9.69 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4223440654108844		[learning rate: 0.00047378]
	Learning Rate: 0.000473782
	LOSS [training: 0.4223440654108844 | validation: 0.8853149403384569]
	TIME [epoch: 9.69 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5038998613467126		[learning rate: 0.00047206]
	Learning Rate: 0.000472063
	LOSS [training: 0.5038998613467126 | validation: 0.7163453520012419]
	TIME [epoch: 9.71 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4825419987590494		[learning rate: 0.00047035]
	Learning Rate: 0.00047035
	LOSS [training: 0.4825419987590494 | validation: 0.7045257292036402]
	TIME [epoch: 9.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48609159964808074		[learning rate: 0.00046864]
	Learning Rate: 0.000468643
	LOSS [training: 0.48609159964808074 | validation: 0.7200728794073108]
	TIME [epoch: 9.69 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4352016189142126		[learning rate: 0.00046694]
	Learning Rate: 0.000466942
	LOSS [training: 0.4352016189142126 | validation: 0.7448801837477265]
	TIME [epoch: 9.69 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4577191728092691		[learning rate: 0.00046525]
	Learning Rate: 0.000465248
	LOSS [training: 0.4577191728092691 | validation: 0.7127710170073803]
	TIME [epoch: 9.71 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45785559778522317		[learning rate: 0.00046356]
	Learning Rate: 0.000463559
	LOSS [training: 0.45785559778522317 | validation: 0.7645279394019738]
	TIME [epoch: 9.69 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4745174069477837		[learning rate: 0.00046188]
	Learning Rate: 0.000461877
	LOSS [training: 0.4745174069477837 | validation: 0.7435858822683586]
	TIME [epoch: 9.69 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41534077104208367		[learning rate: 0.0004602]
	Learning Rate: 0.000460201
	LOSS [training: 0.41534077104208367 | validation: 0.8025440866793053]
	TIME [epoch: 9.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6590174076066448		[learning rate: 0.00045853]
	Learning Rate: 0.000458531
	LOSS [training: 0.6590174076066448 | validation: 0.7070565267978088]
	TIME [epoch: 9.69 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39394396602323195		[learning rate: 0.00045687]
	Learning Rate: 0.000456867
	LOSS [training: 0.39394396602323195 | validation: 0.8190986576889546]
	TIME [epoch: 9.69 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.479620184175789		[learning rate: 0.00045521]
	Learning Rate: 0.000455209
	LOSS [training: 0.479620184175789 | validation: 0.6936218399985897]
	TIME [epoch: 9.69 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4460147292997573		[learning rate: 0.00045356]
	Learning Rate: 0.000453557
	LOSS [training: 0.4460147292997573 | validation: 0.7359926426204126]
	TIME [epoch: 9.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3815987894650164		[learning rate: 0.00045191]
	Learning Rate: 0.000451911
	LOSS [training: 0.3815987894650164 | validation: 0.7042924375055409]
	TIME [epoch: 9.69 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3799727671200355		[learning rate: 0.00045027]
	Learning Rate: 0.000450271
	LOSS [training: 0.3799727671200355 | validation: 0.7502854683176581]
	TIME [epoch: 9.69 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44098217187774014		[learning rate: 0.00044864]
	Learning Rate: 0.000448637
	LOSS [training: 0.44098217187774014 | validation: 0.8768372827219699]
	TIME [epoch: 9.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.511878199598466		[learning rate: 0.00044701]
	Learning Rate: 0.000447009
	LOSS [training: 0.511878199598466 | validation: 0.7342393427193527]
	TIME [epoch: 9.69 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45832578971982835		[learning rate: 0.00044539]
	Learning Rate: 0.000445386
	LOSS [training: 0.45832578971982835 | validation: 0.8117098368441749]
	TIME [epoch: 9.69 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47938523584645426		[learning rate: 0.00044377]
	Learning Rate: 0.00044377
	LOSS [training: 0.47938523584645426 | validation: 0.6854769659285108]
	TIME [epoch: 9.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.424892426448045		[learning rate: 0.00044216]
	Learning Rate: 0.00044216
	LOSS [training: 0.424892426448045 | validation: 0.7826644756125215]
	TIME [epoch: 9.69 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42766555901097886		[learning rate: 0.00044055]
	Learning Rate: 0.000440555
	LOSS [training: 0.42766555901097886 | validation: 0.6817221819801518]
	TIME [epoch: 9.68 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.437577177492111		[learning rate: 0.00043896]
	Learning Rate: 0.000438956
	LOSS [training: 0.437577177492111 | validation: 0.6849656246876965]
	TIME [epoch: 9.69 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4466565559976183		[learning rate: 0.00043736]
	Learning Rate: 0.000437363
	LOSS [training: 0.4466565559976183 | validation: 0.807244354779553]
	TIME [epoch: 9.71 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4628149434854462		[learning rate: 0.00043578]
	Learning Rate: 0.000435776
	LOSS [training: 0.4628149434854462 | validation: 0.6623709142911903]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_962.pth
	Model improved!!!
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48698794594467393		[learning rate: 0.00043419]
	Learning Rate: 0.000434194
	LOSS [training: 0.48698794594467393 | validation: 0.7222784442036289]
	TIME [epoch: 9.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4087358975133757		[learning rate: 0.00043262]
	Learning Rate: 0.000432619
	LOSS [training: 0.4087358975133757 | validation: 0.7149407441166773]
	TIME [epoch: 9.71 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4197937584155807		[learning rate: 0.00043105]
	Learning Rate: 0.000431049
	LOSS [training: 0.4197937584155807 | validation: 0.7106532907535794]
	TIME [epoch: 9.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4103377213039214		[learning rate: 0.00042948]
	Learning Rate: 0.000429484
	LOSS [training: 0.4103377213039214 | validation: 0.7122832720088801]
	TIME [epoch: 9.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.400487347742681		[learning rate: 0.00042793]
	Learning Rate: 0.000427926
	LOSS [training: 0.400487347742681 | validation: 0.7673491019890214]
	TIME [epoch: 9.7 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42575216344430605		[learning rate: 0.00042637]
	Learning Rate: 0.000426373
	LOSS [training: 0.42575216344430605 | validation: 0.6850072199175778]
	TIME [epoch: 9.71 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4492457688443462		[learning rate: 0.00042483]
	Learning Rate: 0.000424825
	LOSS [training: 0.4492457688443462 | validation: 0.6994485441386987]
	TIME [epoch: 9.69 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4249823789117534		[learning rate: 0.00042328]
	Learning Rate: 0.000423284
	LOSS [training: 0.4249823789117534 | validation: 1.1906853248688112]
	TIME [epoch: 9.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6606724068123744		[learning rate: 0.00042175]
	Learning Rate: 0.000421748
	LOSS [training: 0.6606724068123744 | validation: 0.7482444640783115]
	TIME [epoch: 9.71 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39336206520534844		[learning rate: 0.00042022]
	Learning Rate: 0.000420217
	LOSS [training: 0.39336206520534844 | validation: 0.6773975023441443]
	TIME [epoch: 9.7 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41353969806470603		[learning rate: 0.00041869]
	Learning Rate: 0.000418692
	LOSS [training: 0.41353969806470603 | validation: 0.7072963496349511]
	TIME [epoch: 9.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3965788249986343		[learning rate: 0.00041717]
	Learning Rate: 0.000417173
	LOSS [training: 0.3965788249986343 | validation: 0.7237080243597588]
	TIME [epoch: 9.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3603909579194621		[learning rate: 0.00041566]
	Learning Rate: 0.000415659
	LOSS [training: 0.3603909579194621 | validation: 0.767385230195135]
	TIME [epoch: 9.71 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5090645087126384		[learning rate: 0.00041415]
	Learning Rate: 0.00041415
	LOSS [training: 0.5090645087126384 | validation: 0.7618936510269779]
	TIME [epoch: 9.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39943149868813754		[learning rate: 0.00041265]
	Learning Rate: 0.000412647
	LOSS [training: 0.39943149868813754 | validation: 0.7115203121207503]
	TIME [epoch: 9.69 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3795531557099068		[learning rate: 0.00041115]
	Learning Rate: 0.00041115
	LOSS [training: 0.3795531557099068 | validation: 0.7274788258348724]
	TIME [epoch: 9.71 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47837043847432625		[learning rate: 0.00040966]
	Learning Rate: 0.000409658
	LOSS [training: 0.47837043847432625 | validation: 0.7322023546540635]
	TIME [epoch: 9.69 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4328827313599932		[learning rate: 0.00040817]
	Learning Rate: 0.000408171
	LOSS [training: 0.4328827313599932 | validation: 0.691751920458583]
	TIME [epoch: 9.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42172693380812626		[learning rate: 0.00040669]
	Learning Rate: 0.00040669
	LOSS [training: 0.42172693380812626 | validation: 0.7174426445504514]
	TIME [epoch: 9.71 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3985876984690668		[learning rate: 0.00040521]
	Learning Rate: 0.000405214
	LOSS [training: 0.3985876984690668 | validation: 0.7238285581731367]
	TIME [epoch: 9.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3876181093782665		[learning rate: 0.00040374]
	Learning Rate: 0.000403743
	LOSS [training: 0.3876181093782665 | validation: 0.692656111004024]
	TIME [epoch: 9.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38287053004559707		[learning rate: 0.00040228]
	Learning Rate: 0.000402278
	LOSS [training: 0.38287053004559707 | validation: 0.7520681347651765]
	TIME [epoch: 9.69 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39159110175569		[learning rate: 0.00040082]
	Learning Rate: 0.000400818
	LOSS [training: 0.39159110175569 | validation: 0.7194686190753576]
	TIME [epoch: 9.71 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4118192166985507		[learning rate: 0.00039936]
	Learning Rate: 0.000399364
	LOSS [training: 0.4118192166985507 | validation: 0.6722968067460917]
	TIME [epoch: 9.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4389934778101967		[learning rate: 0.00039791]
	Learning Rate: 0.000397914
	LOSS [training: 0.4389934778101967 | validation: 0.7377386444843915]
	TIME [epoch: 9.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42803850464953086		[learning rate: 0.00039647]
	Learning Rate: 0.00039647
	LOSS [training: 0.42803850464953086 | validation: 0.6904417479155821]
	TIME [epoch: 9.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41377521134413237		[learning rate: 0.00039503]
	Learning Rate: 0.000395031
	LOSS [training: 0.41377521134413237 | validation: 0.8326085958581328]
	TIME [epoch: 9.69 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42985566459870694		[learning rate: 0.0003936]
	Learning Rate: 0.000393598
	LOSS [training: 0.42985566459870694 | validation: 0.7611402228364413]
	TIME [epoch: 9.69 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4223623956690263		[learning rate: 0.00039217]
	Learning Rate: 0.000392169
	LOSS [training: 0.4223623956690263 | validation: 0.7245727372636266]
	TIME [epoch: 9.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40454861405026976		[learning rate: 0.00039075]
	Learning Rate: 0.000390746
	LOSS [training: 0.40454861405026976 | validation: 0.6666771095817831]
	TIME [epoch: 9.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3823027722868243		[learning rate: 0.00038933]
	Learning Rate: 0.000389328
	LOSS [training: 0.3823027722868243 | validation: 0.688635593233207]
	TIME [epoch: 9.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4507853972214857		[learning rate: 0.00038792]
	Learning Rate: 0.000387915
	LOSS [training: 0.4507853972214857 | validation: 0.7410423825769493]
	TIME [epoch: 9.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6061057932204698		[learning rate: 0.00038651]
	Learning Rate: 0.000386508
	LOSS [training: 0.6061057932204698 | validation: 0.7372591368449071]
	TIME [epoch: 9.71 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39110706887027546		[learning rate: 0.0003851]
	Learning Rate: 0.000385105
	LOSS [training: 0.39110706887027546 | validation: 0.6588929101259454]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_996.pth
	Model improved!!!
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41342767853094176		[learning rate: 0.00038371]
	Learning Rate: 0.000383707
	LOSS [training: 0.41342767853094176 | validation: 0.6815111012434218]
	TIME [epoch: 9.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36172377934240363		[learning rate: 0.00038231]
	Learning Rate: 0.000382315
	LOSS [training: 0.36172377934240363 | validation: 0.7004105761068431]
	TIME [epoch: 9.71 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3949817001340147		[learning rate: 0.00038093]
	Learning Rate: 0.000380927
	LOSS [training: 0.3949817001340147 | validation: 0.7092995820945674]
	TIME [epoch: 9.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4391061105914936		[learning rate: 0.00037954]
	Learning Rate: 0.000379545
	LOSS [training: 0.4391061105914936 | validation: 0.6973666453614379]
	TIME [epoch: 9.69 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4252102168588839		[learning rate: 0.00037817]
	Learning Rate: 0.000378167
	LOSS [training: 0.4252102168588839 | validation: 0.7422797074331016]
	TIME [epoch: 9.69 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3999469459723287		[learning rate: 0.0003768]
	Learning Rate: 0.000376795
	LOSS [training: 0.3999469459723287 | validation: 0.7253614187347779]
	TIME [epoch: 9.72 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3720495406602987		[learning rate: 0.00037543]
	Learning Rate: 0.000375428
	LOSS [training: 0.3720495406602987 | validation: 0.6846917790237247]
	TIME [epoch: 9.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36300538672930427		[learning rate: 0.00037407]
	Learning Rate: 0.000374065
	LOSS [training: 0.36300538672930427 | validation: 0.6840907819365315]
	TIME [epoch: 9.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36195670036023475		[learning rate: 0.00037271]
	Learning Rate: 0.000372708
	LOSS [training: 0.36195670036023475 | validation: 0.6758931305364668]
	TIME [epoch: 9.71 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3702306420264988		[learning rate: 0.00037136]
	Learning Rate: 0.000371355
	LOSS [training: 0.3702306420264988 | validation: 0.6872173645559052]
	TIME [epoch: 9.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39494482384787793		[learning rate: 0.00037001]
	Learning Rate: 0.000370008
	LOSS [training: 0.39494482384787793 | validation: 0.6853527850728555]
	TIME [epoch: 9.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40410837128286053		[learning rate: 0.00036866]
	Learning Rate: 0.000368665
	LOSS [training: 0.40410837128286053 | validation: 0.7232824219223163]
	TIME [epoch: 9.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4006329779450928		[learning rate: 0.00036733]
	Learning Rate: 0.000367327
	LOSS [training: 0.4006329779450928 | validation: 0.6906946889682868]
	TIME [epoch: 9.71 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3626373587856909		[learning rate: 0.00036599]
	Learning Rate: 0.000365994
	LOSS [training: 0.3626373587856909 | validation: 0.6988533092609523]
	TIME [epoch: 9.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.382326939065241		[learning rate: 0.00036467]
	Learning Rate: 0.000364666
	LOSS [training: 0.382326939065241 | validation: 0.6925568276725176]
	TIME [epoch: 9.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3970436035499095		[learning rate: 0.00036334]
	Learning Rate: 0.000363342
	LOSS [training: 0.3970436035499095 | validation: 0.7013982269710359]
	TIME [epoch: 9.72 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3740547660218154		[learning rate: 0.00036202]
	Learning Rate: 0.000362024
	LOSS [training: 0.3740547660218154 | validation: 0.6971715164199845]
	TIME [epoch: 9.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4149148413498791		[learning rate: 0.00036071]
	Learning Rate: 0.00036071
	LOSS [training: 0.4149148413498791 | validation: 0.6881944738580394]
	TIME [epoch: 9.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4003276491330924		[learning rate: 0.0003594]
	Learning Rate: 0.000359401
	LOSS [training: 0.4003276491330924 | validation: 0.7184584483456132]
	TIME [epoch: 9.71 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49807141154027035		[learning rate: 0.0003581]
	Learning Rate: 0.000358096
	LOSS [training: 0.49807141154027035 | validation: 0.7083386490777938]
	TIME [epoch: 9.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38432080968380655		[learning rate: 0.0003568]
	Learning Rate: 0.000356797
	LOSS [training: 0.38432080968380655 | validation: 0.7484137639896875]
	TIME [epoch: 9.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3976194206463667		[learning rate: 0.0003555]
	Learning Rate: 0.000355502
	LOSS [training: 0.3976194206463667 | validation: 0.7345092412483404]
	TIME [epoch: 9.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40194002470088586		[learning rate: 0.00035421]
	Learning Rate: 0.000354212
	LOSS [training: 0.40194002470088586 | validation: 0.7022845917335455]
	TIME [epoch: 9.71 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3666258696936663		[learning rate: 0.00035293]
	Learning Rate: 0.000352926
	LOSS [training: 0.3666258696936663 | validation: 0.8583968461217498]
	TIME [epoch: 9.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5058199789380591		[learning rate: 0.00035165]
	Learning Rate: 0.000351646
	LOSS [training: 0.5058199789380591 | validation: 0.8042735177032521]
	TIME [epoch: 9.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42535966108838785		[learning rate: 0.00035037]
	Learning Rate: 0.00035037
	LOSS [training: 0.42535966108838785 | validation: 0.7409351851122793]
	TIME [epoch: 9.71 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41236005126216624		[learning rate: 0.0003491]
	Learning Rate: 0.000349098
	LOSS [training: 0.41236005126216624 | validation: 0.9096806837818807]
	TIME [epoch: 9.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49210576144181567		[learning rate: 0.00034783]
	Learning Rate: 0.000347831
	LOSS [training: 0.49210576144181567 | validation: 0.708761687966845]
	TIME [epoch: 9.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39493662943971447		[learning rate: 0.00034657]
	Learning Rate: 0.000346569
	LOSS [training: 0.39493662943971447 | validation: 0.6799249581904663]
	TIME [epoch: 9.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40734142585821564		[learning rate: 0.00034531]
	Learning Rate: 0.000345311
	LOSS [training: 0.40734142585821564 | validation: 0.8229352647955264]
	TIME [epoch: 9.71 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4064361357638006		[learning rate: 0.00034406]
	Learning Rate: 0.000344058
	LOSS [training: 0.4064361357638006 | validation: 0.7974564756701245]
	TIME [epoch: 9.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42343763616462676		[learning rate: 0.00034281]
	Learning Rate: 0.000342809
	LOSS [training: 0.42343763616462676 | validation: 0.6538009167866834]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1028.pth
	Model improved!!!
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3918576059180684		[learning rate: 0.00034157]
	Learning Rate: 0.000341565
	LOSS [training: 0.3918576059180684 | validation: 0.6873678784122343]
	TIME [epoch: 9.72 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3753995625294256		[learning rate: 0.00034033]
	Learning Rate: 0.000340326
	LOSS [training: 0.3753995625294256 | validation: 0.820982970046135]
	TIME [epoch: 9.71 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4403117470975526		[learning rate: 0.00033909]
	Learning Rate: 0.000339091
	LOSS [training: 0.4403117470975526 | validation: 0.7109232711258539]
	TIME [epoch: 9.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4199446391738003		[learning rate: 0.00033786]
	Learning Rate: 0.00033786
	LOSS [training: 0.4199446391738003 | validation: 0.749187701605143]
	TIME [epoch: 9.73 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39771471724589114		[learning rate: 0.00033663]
	Learning Rate: 0.000336634
	LOSS [training: 0.39771471724589114 | validation: 0.6973937826003282]
	TIME [epoch: 9.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4176502676369497		[learning rate: 0.00033541]
	Learning Rate: 0.000335412
	LOSS [training: 0.4176502676369497 | validation: 0.7020027459077939]
	TIME [epoch: 9.69 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4189308102840347		[learning rate: 0.0003342]
	Learning Rate: 0.000334195
	LOSS [training: 0.4189308102840347 | validation: 0.6600123174612728]
	TIME [epoch: 9.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3969107654047554		[learning rate: 0.00033298]
	Learning Rate: 0.000332982
	LOSS [training: 0.3969107654047554 | validation: 0.7518543288698174]
	TIME [epoch: 9.72 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4288086544127239		[learning rate: 0.00033177]
	Learning Rate: 0.000331774
	LOSS [training: 0.4288086544127239 | validation: 0.6736661827879354]
	TIME [epoch: 9.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3765599028295862		[learning rate: 0.00033057]
	Learning Rate: 0.00033057
	LOSS [training: 0.3765599028295862 | validation: 0.7005008508579029]
	TIME [epoch: 9.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3804505358022789		[learning rate: 0.00032937]
	Learning Rate: 0.00032937
	LOSS [training: 0.3804505358022789 | validation: 0.6880274219028715]
	TIME [epoch: 9.72 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4043783605582291		[learning rate: 0.00032817]
	Learning Rate: 0.000328175
	LOSS [training: 0.4043783605582291 | validation: 0.6915105672780917]
	TIME [epoch: 9.69 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3568301486670956		[learning rate: 0.00032698]
	Learning Rate: 0.000326984
	LOSS [training: 0.3568301486670956 | validation: 0.6290639683720692]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1041.pth
	Model improved!!!
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37280938334479485		[learning rate: 0.0003258]
	Learning Rate: 0.000325797
	LOSS [training: 0.37280938334479485 | validation: 0.679236177126361]
	TIME [epoch: 9.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3922570055393226		[learning rate: 0.00032461]
	Learning Rate: 0.000324615
	LOSS [training: 0.3922570055393226 | validation: 0.6774631589212728]
	TIME [epoch: 9.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3808218114450031		[learning rate: 0.00032344]
	Learning Rate: 0.000323437
	LOSS [training: 0.3808218114450031 | validation: 0.7474696061805024]
	TIME [epoch: 9.69 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3560913523489196		[learning rate: 0.00032226]
	Learning Rate: 0.000322263
	LOSS [training: 0.3560913523489196 | validation: 0.7028287960845345]
	TIME [epoch: 9.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38840806499942965		[learning rate: 0.00032109]
	Learning Rate: 0.000321094
	LOSS [training: 0.38840806499942965 | validation: 0.6641226665411892]
	TIME [epoch: 9.71 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34910493539298326		[learning rate: 0.00031993]
	Learning Rate: 0.000319928
	LOSS [training: 0.34910493539298326 | validation: 0.7162869846394776]
	TIME [epoch: 9.69 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42060285405378084		[learning rate: 0.00031877]
	Learning Rate: 0.000318767
	LOSS [training: 0.42060285405378084 | validation: 0.6684101062142916]
	TIME [epoch: 9.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3975781911604951		[learning rate: 0.00031761]
	Learning Rate: 0.000317611
	LOSS [training: 0.3975781911604951 | validation: 0.6662552824261282]
	TIME [epoch: 9.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3846676399634886		[learning rate: 0.00031646]
	Learning Rate: 0.000316458
	LOSS [training: 0.3846676399634886 | validation: 0.6848419960290335]
	TIME [epoch: 9.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35806971152470346		[learning rate: 0.00031531]
	Learning Rate: 0.000315309
	LOSS [training: 0.35806971152470346 | validation: 0.7021572329317126]
	TIME [epoch: 9.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4501918494990759		[learning rate: 0.00031417]
	Learning Rate: 0.000314165
	LOSS [training: 0.4501918494990759 | validation: 0.8344001502056164]
	TIME [epoch: 9.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44639198253901774		[learning rate: 0.00031302]
	Learning Rate: 0.000313025
	LOSS [training: 0.44639198253901774 | validation: 0.6432296418171825]
	TIME [epoch: 9.71 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3608102932990723		[learning rate: 0.00031189]
	Learning Rate: 0.000311889
	LOSS [training: 0.3608102932990723 | validation: 0.6267637147797689]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1054.pth
	Model improved!!!
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3749271017039376		[learning rate: 0.00031076]
	Learning Rate: 0.000310757
	LOSS [training: 0.3749271017039376 | validation: 0.6944683166684831]
	TIME [epoch: 9.69 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35318298985133		[learning rate: 0.00030963]
	Learning Rate: 0.000309629
	LOSS [training: 0.35318298985133 | validation: 0.6686877771474419]
	TIME [epoch: 9.72 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3738902732558823		[learning rate: 0.00030851]
	Learning Rate: 0.000308506
	LOSS [training: 0.3738902732558823 | validation: 0.695402676002798]
	TIME [epoch: 9.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38138545656798406		[learning rate: 0.00030739]
	Learning Rate: 0.000307386
	LOSS [training: 0.38138545656798406 | validation: 0.6693523229497916]
	TIME [epoch: 9.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37313553626110446		[learning rate: 0.00030627]
	Learning Rate: 0.000306271
	LOSS [training: 0.37313553626110446 | validation: 0.7106613763051643]
	TIME [epoch: 9.71 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3888885640582377		[learning rate: 0.00030516]
	Learning Rate: 0.000305159
	LOSS [training: 0.3888885640582377 | validation: 0.6885921608064547]
	TIME [epoch: 9.73 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3705310452809422		[learning rate: 0.00030405]
	Learning Rate: 0.000304052
	LOSS [training: 0.3705310452809422 | validation: 0.6666633672088659]
	TIME [epoch: 9.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34033035364353714		[learning rate: 0.00030295]
	Learning Rate: 0.000302948
	LOSS [training: 0.34033035364353714 | validation: 0.6470652032306657]
	TIME [epoch: 9.71 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35400973918861417		[learning rate: 0.00030185]
	Learning Rate: 0.000301849
	LOSS [training: 0.35400973918861417 | validation: 0.6665088698509203]
	TIME [epoch: 9.72 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3654264066860709		[learning rate: 0.00030075]
	Learning Rate: 0.000300753
	LOSS [training: 0.3654264066860709 | validation: 0.7408138588461823]
	TIME [epoch: 9.71 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43642370918201445		[learning rate: 0.00029966]
	Learning Rate: 0.000299662
	LOSS [training: 0.43642370918201445 | validation: 0.6424447968220314]
	TIME [epoch: 9.71 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35893893108291686		[learning rate: 0.00029857]
	Learning Rate: 0.000298574
	LOSS [training: 0.35893893108291686 | validation: 0.6540590049444893]
	TIME [epoch: 9.73 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3524478895732518		[learning rate: 0.00029749]
	Learning Rate: 0.000297491
	LOSS [training: 0.3524478895732518 | validation: 0.6585151118345105]
	TIME [epoch: 9.71 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3940881228598789		[learning rate: 0.00029641]
	Learning Rate: 0.000296411
	LOSS [training: 0.3940881228598789 | validation: 0.8244173782583875]
	TIME [epoch: 9.71 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47194402902593796		[learning rate: 0.00029534]
	Learning Rate: 0.000295336
	LOSS [training: 0.47194402902593796 | validation: 0.691763244473986]
	TIME [epoch: 9.71 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3662943060039584		[learning rate: 0.00029426]
	Learning Rate: 0.000294264
	LOSS [training: 0.3662943060039584 | validation: 0.7200236890679717]
	TIME [epoch: 9.72 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43256153178180307		[learning rate: 0.0002932]
	Learning Rate: 0.000293196
	LOSS [training: 0.43256153178180307 | validation: 0.8291493312273971]
	TIME [epoch: 9.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40818342421528697		[learning rate: 0.00029213]
	Learning Rate: 0.000292132
	LOSS [training: 0.40818342421528697 | validation: 0.7038163695570306]
	TIME [epoch: 9.71 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40619859832554617		[learning rate: 0.00029107]
	Learning Rate: 0.000291072
	LOSS [training: 0.40619859832554617 | validation: 0.7281143790431247]
	TIME [epoch: 9.71 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3891633986978614		[learning rate: 0.00029002]
	Learning Rate: 0.000290015
	LOSS [training: 0.3891633986978614 | validation: 0.7221492658454048]
	TIME [epoch: 9.71 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3478490033764637		[learning rate: 0.00028896]
	Learning Rate: 0.000288963
	LOSS [training: 0.3478490033764637 | validation: 0.6713858466891915]
	TIME [epoch: 9.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3765570777239936		[learning rate: 0.00028791]
	Learning Rate: 0.000287914
	LOSS [training: 0.3765570777239936 | validation: 0.6924261758111955]
	TIME [epoch: 9.73 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37272308763516915		[learning rate: 0.00028687]
	Learning Rate: 0.000286869
	LOSS [training: 0.37272308763516915 | validation: 0.6456162809992059]
	TIME [epoch: 9.72 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3643137559762038		[learning rate: 0.00028583]
	Learning Rate: 0.000285828
	LOSS [training: 0.3643137559762038 | validation: 0.6978850365853951]
	TIME [epoch: 9.71 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42380470103259943		[learning rate: 0.00028479]
	Learning Rate: 0.000284791
	LOSS [training: 0.42380470103259943 | validation: 0.7949841175567594]
	TIME [epoch: 9.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47151919368348016		[learning rate: 0.00028376]
	Learning Rate: 0.000283758
	LOSS [training: 0.47151919368348016 | validation: 0.7270426420759515]
	TIME [epoch: 9.72 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3657718071020163		[learning rate: 0.00028273]
	Learning Rate: 0.000282728
	LOSS [training: 0.3657718071020163 | validation: 0.7193904039011767]
	TIME [epoch: 9.71 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37642246055203427		[learning rate: 0.0002817]
	Learning Rate: 0.000281702
	LOSS [training: 0.37642246055203427 | validation: 0.6890390532408079]
	TIME [epoch: 9.72 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3626069096244136		[learning rate: 0.00028068]
	Learning Rate: 0.000280679
	LOSS [training: 0.3626069096244136 | validation: 0.6600695934431522]
	TIME [epoch: 9.73 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3806737163877133		[learning rate: 0.00027966]
	Learning Rate: 0.000279661
	LOSS [training: 0.3806737163877133 | validation: 0.7263096978657939]
	TIME [epoch: 9.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3609142846013788		[learning rate: 0.00027865]
	Learning Rate: 0.000278646
	LOSS [training: 0.3609142846013788 | validation: 0.733612098241159]
	TIME [epoch: 9.71 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42136660635857376		[learning rate: 0.00027763]
	Learning Rate: 0.000277635
	LOSS [training: 0.42136660635857376 | validation: 0.6336532553637263]
	TIME [epoch: 9.72 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36150904383717564		[learning rate: 0.00027663]
	Learning Rate: 0.000276627
	LOSS [training: 0.36150904383717564 | validation: 0.6945677046633688]
	TIME [epoch: 9.72 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35422647208446884		[learning rate: 0.00027562]
	Learning Rate: 0.000275623
	LOSS [training: 0.35422647208446884 | validation: 0.655160318498605]
	TIME [epoch: 9.72 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36918256892935675		[learning rate: 0.00027462]
	Learning Rate: 0.000274623
	LOSS [training: 0.36918256892935675 | validation: 0.7289588965186214]
	TIME [epoch: 9.71 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44196368065746733		[learning rate: 0.00027363]
	Learning Rate: 0.000273626
	LOSS [training: 0.44196368065746733 | validation: 0.6801736246544445]
	TIME [epoch: 9.72 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35811745750515434		[learning rate: 0.00027263]
	Learning Rate: 0.000272633
	LOSS [training: 0.35811745750515434 | validation: 0.6685307130017566]
	TIME [epoch: 9.71 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4296927227849615		[learning rate: 0.00027164]
	Learning Rate: 0.000271644
	LOSS [training: 0.4296927227849615 | validation: 0.6729501236791627]
	TIME [epoch: 9.71 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35861852588233567		[learning rate: 0.00027066]
	Learning Rate: 0.000270658
	LOSS [training: 0.35861852588233567 | validation: 0.6927884377902348]
	TIME [epoch: 9.71 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35121680605312866		[learning rate: 0.00026968]
	Learning Rate: 0.000269676
	LOSS [training: 0.35121680605312866 | validation: 0.6903549804640164]
	TIME [epoch: 9.71 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42043624235206556		[learning rate: 0.0002687]
	Learning Rate: 0.000268697
	LOSS [training: 0.42043624235206556 | validation: 0.6799344410262864]
	TIME [epoch: 9.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3537656507400298		[learning rate: 0.00026772]
	Learning Rate: 0.000267722
	LOSS [training: 0.3537656507400298 | validation: 0.6750203784662092]
	TIME [epoch: 9.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35998606908180364		[learning rate: 0.00026675]
	Learning Rate: 0.000266751
	LOSS [training: 0.35998606908180364 | validation: 0.7562825093767259]
	TIME [epoch: 9.72 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3925837863784954		[learning rate: 0.00026578]
	Learning Rate: 0.000265782
	LOSS [training: 0.3925837863784954 | validation: 0.7238043864988081]
	TIME [epoch: 9.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37489684176426763		[learning rate: 0.00026482]
	Learning Rate: 0.000264818
	LOSS [training: 0.37489684176426763 | validation: 0.7081401346757791]
	TIME [epoch: 9.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4289890576270299		[learning rate: 0.00026386]
	Learning Rate: 0.000263857
	LOSS [training: 0.4289890576270299 | validation: 0.6374493177970016]
	TIME [epoch: 9.71 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39974166030070185		[learning rate: 0.0002629]
	Learning Rate: 0.000262899
	LOSS [training: 0.39974166030070185 | validation: 0.7188458990994613]
	TIME [epoch: 9.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3643672524849674		[learning rate: 0.00026195]
	Learning Rate: 0.000261945
	LOSS [training: 0.3643672524849674 | validation: 0.6567475338963612]
	TIME [epoch: 9.69 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3430423822247485		[learning rate: 0.00026099]
	Learning Rate: 0.000260995
	LOSS [training: 0.3430423822247485 | validation: 0.6473540811636964]
	TIME [epoch: 9.71 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34890204407693204		[learning rate: 0.00026005]
	Learning Rate: 0.000260047
	LOSS [training: 0.34890204407693204 | validation: 0.6374660771855738]
	TIME [epoch: 9.72 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4245599219167616		[learning rate: 0.0002591]
	Learning Rate: 0.000259104
	LOSS [training: 0.4245599219167616 | validation: 0.6832973451433025]
	TIME [epoch: 9.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36704649344580403		[learning rate: 0.00025816]
	Learning Rate: 0.000258163
	LOSS [training: 0.36704649344580403 | validation: 0.6266055734935064]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1106.pth
	Model improved!!!
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32893900422877576		[learning rate: 0.00025723]
	Learning Rate: 0.000257227
	LOSS [training: 0.32893900422877576 | validation: 0.665648057931988]
	TIME [epoch: 9.72 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3647035091781424		[learning rate: 0.00025629]
	Learning Rate: 0.000256293
	LOSS [training: 0.3647035091781424 | validation: 0.6272283495321571]
	TIME [epoch: 9.71 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38990664248647944		[learning rate: 0.00025536]
	Learning Rate: 0.000255363
	LOSS [training: 0.38990664248647944 | validation: 0.7590980138996128]
	TIME [epoch: 9.72 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3830703867462713		[learning rate: 0.00025444]
	Learning Rate: 0.000254436
	LOSS [training: 0.3830703867462713 | validation: 0.670267762539379]
	TIME [epoch: 9.73 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3606507062122082		[learning rate: 0.00025351]
	Learning Rate: 0.000253513
	LOSS [training: 0.3606507062122082 | validation: 0.7330372881031564]
	TIME [epoch: 9.72 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35067691131802026		[learning rate: 0.00025259]
	Learning Rate: 0.000252593
	LOSS [training: 0.35067691131802026 | validation: 0.645500968148541]
	TIME [epoch: 9.71 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34523301674395956		[learning rate: 0.00025168]
	Learning Rate: 0.000251676
	LOSS [training: 0.34523301674395956 | validation: 0.7063269793458948]
	TIME [epoch: 9.71 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4058236599860379		[learning rate: 0.00025076]
	Learning Rate: 0.000250763
	LOSS [training: 0.4058236599860379 | validation: 0.656315709958329]
	TIME [epoch: 9.73 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3994272057754905		[learning rate: 0.00024985]
	Learning Rate: 0.000249853
	LOSS [training: 0.3994272057754905 | validation: 0.6981043428521213]
	TIME [epoch: 9.71 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38760981858225974		[learning rate: 0.00024895]
	Learning Rate: 0.000248946
	LOSS [training: 0.38760981858225974 | validation: 0.6277418267181077]
	TIME [epoch: 9.71 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40087032255218136		[learning rate: 0.00024804]
	Learning Rate: 0.000248043
	LOSS [training: 0.40087032255218136 | validation: 0.705490283760571]
	TIME [epoch: 9.73 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3700518046762473		[learning rate: 0.00024714]
	Learning Rate: 0.000247142
	LOSS [training: 0.3700518046762473 | validation: 0.710780237189403]
	TIME [epoch: 9.72 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44534469739173765		[learning rate: 0.00024625]
	Learning Rate: 0.000246246
	LOSS [training: 0.44534469739173765 | validation: 0.7043504059540027]
	TIME [epoch: 9.72 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4157860641960719		[learning rate: 0.00024535]
	Learning Rate: 0.000245352
	LOSS [training: 0.4157860641960719 | validation: 0.6550466841273209]
	TIME [epoch: 9.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36007051628698583		[learning rate: 0.00024446]
	Learning Rate: 0.000244462
	LOSS [training: 0.36007051628698583 | validation: 0.6665224618705443]
	TIME [epoch: 9.73 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3729760970863105		[learning rate: 0.00024357]
	Learning Rate: 0.000243574
	LOSS [training: 0.3729760970863105 | validation: 0.677205110777568]
	TIME [epoch: 9.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3793998611984753		[learning rate: 0.00024269]
	Learning Rate: 0.00024269
	LOSS [training: 0.3793998611984753 | validation: 0.6863268350825483]
	TIME [epoch: 9.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37071777567668307		[learning rate: 0.00024181]
	Learning Rate: 0.00024181
	LOSS [training: 0.37071777567668307 | validation: 0.7832035946399682]
	TIME [epoch: 9.72 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3971132195602463		[learning rate: 0.00024093]
	Learning Rate: 0.000240932
	LOSS [training: 0.3971132195602463 | validation: 0.637581707206111]
	TIME [epoch: 9.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38436181709437095		[learning rate: 0.00024006]
	Learning Rate: 0.000240058
	LOSS [training: 0.38436181709437095 | validation: 0.6936656522826374]
	TIME [epoch: 9.71 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.353685369429452		[learning rate: 0.00023919]
	Learning Rate: 0.000239187
	LOSS [training: 0.353685369429452 | validation: 0.6494483944619706]
	TIME [epoch: 9.72 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3472059560694995		[learning rate: 0.00023832]
	Learning Rate: 0.000238319
	LOSS [training: 0.3472059560694995 | validation: 0.6778605339986175]
	TIME [epoch: 9.71 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34966477130140233		[learning rate: 0.00023745]
	Learning Rate: 0.000237454
	LOSS [training: 0.34966477130140233 | validation: 0.6034678090098976]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1129.pth
	Model improved!!!
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35532396460414606		[learning rate: 0.00023659]
	Learning Rate: 0.000236592
	LOSS [training: 0.35532396460414606 | validation: 0.6848287426274575]
	TIME [epoch: 9.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35448995788875504		[learning rate: 0.00023573]
	Learning Rate: 0.000235733
	LOSS [training: 0.35448995788875504 | validation: 0.660899871660072]
	TIME [epoch: 9.94 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.347832706900315		[learning rate: 0.00023488]
	Learning Rate: 0.000234878
	LOSS [training: 0.347832706900315 | validation: 0.6391450807989978]
	TIME [epoch: 9.71 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36361070092433956		[learning rate: 0.00023403]
	Learning Rate: 0.000234026
	LOSS [training: 0.36361070092433956 | validation: 0.6668900836070799]
	TIME [epoch: 9.71 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3462142144810154		[learning rate: 0.00023318]
	Learning Rate: 0.000233176
	LOSS [training: 0.3462142144810154 | validation: 0.6754971388092207]
	TIME [epoch: 9.72 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3637443882875035		[learning rate: 0.00023233]
	Learning Rate: 0.00023233
	LOSS [training: 0.3637443882875035 | validation: 0.6191369489292682]
	TIME [epoch: 9.71 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36525733658007387		[learning rate: 0.00023149]
	Learning Rate: 0.000231487
	LOSS [training: 0.36525733658007387 | validation: 0.6120772810583927]
	TIME [epoch: 9.71 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3416367939844518		[learning rate: 0.00023065]
	Learning Rate: 0.000230647
	LOSS [training: 0.3416367939844518 | validation: 0.6326067839296783]
	TIME [epoch: 9.71 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37879960403819785		[learning rate: 0.00022981]
	Learning Rate: 0.00022981
	LOSS [training: 0.37879960403819785 | validation: 0.5815008942502425]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1138.pth
	Model improved!!!
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35567408076112117		[learning rate: 0.00022898]
	Learning Rate: 0.000228976
	LOSS [training: 0.35567408076112117 | validation: 0.6604123483353931]
	TIME [epoch: 9.71 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3340002663669481		[learning rate: 0.00022814]
	Learning Rate: 0.000228145
	LOSS [training: 0.3340002663669481 | validation: 0.6458820777985537]
	TIME [epoch: 9.72 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3408542195555354		[learning rate: 0.00022732]
	Learning Rate: 0.000227317
	LOSS [training: 0.3408542195555354 | validation: 0.6458708694100628]
	TIME [epoch: 9.73 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34225556829840487		[learning rate: 0.00022649]
	Learning Rate: 0.000226492
	LOSS [training: 0.34225556829840487 | validation: 0.5917673993717546]
	TIME [epoch: 9.72 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34668761527836245		[learning rate: 0.00022567]
	Learning Rate: 0.00022567
	LOSS [training: 0.34668761527836245 | validation: 0.6299156277825487]
	TIME [epoch: 9.72 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3376389010937567		[learning rate: 0.00022485]
	Learning Rate: 0.000224851
	LOSS [training: 0.3376389010937567 | validation: 0.6872174930182484]
	TIME [epoch: 9.73 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3686525202536107		[learning rate: 0.00022403]
	Learning Rate: 0.000224035
	LOSS [training: 0.3686525202536107 | validation: 0.6345461711028393]
	TIME [epoch: 9.72 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31923954790235626		[learning rate: 0.00022322]
	Learning Rate: 0.000223222
	LOSS [training: 0.31923954790235626 | validation: 0.7448653168414987]
	TIME [epoch: 9.72 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3870574357464475		[learning rate: 0.00022241]
	Learning Rate: 0.000222412
	LOSS [training: 0.3870574357464475 | validation: 0.6260211131835303]
	TIME [epoch: 9.71 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3474299305336962		[learning rate: 0.0002216]
	Learning Rate: 0.000221605
	LOSS [training: 0.3474299305336962 | validation: 0.6482533550278818]
	TIME [epoch: 9.73 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3427727201939791		[learning rate: 0.0002208]
	Learning Rate: 0.0002208
	LOSS [training: 0.3427727201939791 | validation: 0.6128844661605368]
	TIME [epoch: 9.72 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.340968688773656		[learning rate: 0.00022]
	Learning Rate: 0.000219999
	LOSS [training: 0.340968688773656 | validation: 0.66492653904636]
	TIME [epoch: 9.72 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3383244859006556		[learning rate: 0.0002192]
	Learning Rate: 0.000219201
	LOSS [training: 0.3383244859006556 | validation: 0.6486176566534649]
	TIME [epoch: 9.73 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3590052537955992		[learning rate: 0.00021841]
	Learning Rate: 0.000218405
	LOSS [training: 0.3590052537955992 | validation: 0.6204019491853882]
	TIME [epoch: 9.71 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33897709149629424		[learning rate: 0.00021761]
	Learning Rate: 0.000217613
	LOSS [training: 0.33897709149629424 | validation: 0.6921913651476435]
	TIME [epoch: 9.72 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3536400674864325		[learning rate: 0.00021682]
	Learning Rate: 0.000216823
	LOSS [training: 0.3536400674864325 | validation: 0.6318734068305374]
	TIME [epoch: 9.73 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36112359094458807		[learning rate: 0.00021604]
	Learning Rate: 0.000216036
	LOSS [training: 0.36112359094458807 | validation: 0.7179958601235624]
	TIME [epoch: 9.72 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4133715958178367		[learning rate: 0.00021525]
	Learning Rate: 0.000215252
	LOSS [training: 0.4133715958178367 | validation: 0.732024218000754]
	TIME [epoch: 9.72 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37762379138967256		[learning rate: 0.00021447]
	Learning Rate: 0.000214471
	LOSS [training: 0.37762379138967256 | validation: 0.6458472143536583]
	TIME [epoch: 9.71 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35453688266316874		[learning rate: 0.00021369]
	Learning Rate: 0.000213693
	LOSS [training: 0.35453688266316874 | validation: 0.6292930573290216]
	TIME [epoch: 9.73 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34951154435472215		[learning rate: 0.00021292]
	Learning Rate: 0.000212917
	LOSS [training: 0.34951154435472215 | validation: 0.6236472431457984]
	TIME [epoch: 9.72 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33662463524563074		[learning rate: 0.00021214]
	Learning Rate: 0.000212144
	LOSS [training: 0.33662463524563074 | validation: 0.6363341846110798]
	TIME [epoch: 9.72 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3482298924600947		[learning rate: 0.00021137]
	Learning Rate: 0.000211375
	LOSS [training: 0.3482298924600947 | validation: 0.6671861216092417]
	TIME [epoch: 9.73 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3619108148401297		[learning rate: 0.00021061]
	Learning Rate: 0.000210607
	LOSS [training: 0.3619108148401297 | validation: 0.5879202641238026]
	TIME [epoch: 9.71 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3623119621837251		[learning rate: 0.00020984]
	Learning Rate: 0.000209843
	LOSS [training: 0.3623119621837251 | validation: 0.639924716679858]
	TIME [epoch: 9.71 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34950397925753407		[learning rate: 0.00020908]
	Learning Rate: 0.000209082
	LOSS [training: 0.34950397925753407 | validation: 0.6047460255327787]
	TIME [epoch: 9.71 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3904548705571013		[learning rate: 0.00020832]
	Learning Rate: 0.000208323
	LOSS [training: 0.3904548705571013 | validation: 0.7506212229901692]
	TIME [epoch: 9.73 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3988537101233402		[learning rate: 0.00020757]
	Learning Rate: 0.000207567
	LOSS [training: 0.3988537101233402 | validation: 0.6172241141588602]
	TIME [epoch: 9.72 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.353307247122963		[learning rate: 0.00020681]
	Learning Rate: 0.000206814
	LOSS [training: 0.353307247122963 | validation: 0.6303240762284036]
	TIME [epoch: 9.72 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3619239929714159		[learning rate: 0.00020606]
	Learning Rate: 0.000206063
	LOSS [training: 0.3619239929714159 | validation: 0.6762832984244966]
	TIME [epoch: 9.73 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3633827502908776		[learning rate: 0.00020532]
	Learning Rate: 0.000205315
	LOSS [training: 0.3633827502908776 | validation: 0.67730543143289]
	TIME [epoch: 9.71 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36571722682332153		[learning rate: 0.00020457]
	Learning Rate: 0.00020457
	LOSS [training: 0.36571722682332153 | validation: 0.6831783370132689]
	TIME [epoch: 9.71 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32004842631432295		[learning rate: 0.00020383]
	Learning Rate: 0.000203828
	LOSS [training: 0.32004842631432295 | validation: 0.5959483187669309]
	TIME [epoch: 9.72 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3477309202322724		[learning rate: 0.00020309]
	Learning Rate: 0.000203088
	LOSS [training: 0.3477309202322724 | validation: 0.6982053817600706]
	TIME [epoch: 9.72 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3628547597028291		[learning rate: 0.00020235]
	Learning Rate: 0.000202351
	LOSS [training: 0.3628547597028291 | validation: 0.6317995620201023]
	TIME [epoch: 9.71 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3410524058002734		[learning rate: 0.00020162]
	Learning Rate: 0.000201617
	LOSS [training: 0.3410524058002734 | validation: 0.6253854032329529]
	TIME [epoch: 9.71 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3288403782256859		[learning rate: 0.00020088]
	Learning Rate: 0.000200885
	LOSS [training: 0.3288403782256859 | validation: 0.6469861389982322]
	TIME [epoch: 9.73 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3345555643924882		[learning rate: 0.00020016]
	Learning Rate: 0.000200156
	LOSS [training: 0.3345555643924882 | validation: 0.5995500303171004]
	TIME [epoch: 9.71 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3318408939711579		[learning rate: 0.00019943]
	Learning Rate: 0.00019943
	LOSS [training: 0.3318408939711579 | validation: 0.6493223412813568]
	TIME [epoch: 9.71 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3433757929777804		[learning rate: 0.00019871]
	Learning Rate: 0.000198706
	LOSS [training: 0.3433757929777804 | validation: 0.6923498674399002]
	TIME [epoch: 9.73 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3536063020315227		[learning rate: 0.00019798]
	Learning Rate: 0.000197985
	LOSS [training: 0.3536063020315227 | validation: 0.6564949671363928]
	TIME [epoch: 9.71 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3520008806550274		[learning rate: 0.00019727]
	Learning Rate: 0.000197266
	LOSS [training: 0.3520008806550274 | validation: 0.6094891182609136]
	TIME [epoch: 9.71 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3251758799399673		[learning rate: 0.00019655]
	Learning Rate: 0.00019655
	LOSS [training: 0.3251758799399673 | validation: 0.6283710791448445]
	TIME [epoch: 9.72 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3434549862848281		[learning rate: 0.00019584]
	Learning Rate: 0.000195837
	LOSS [training: 0.3434549862848281 | validation: 0.6518586260063189]
	TIME [epoch: 9.74 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3437591927757551		[learning rate: 0.00019513]
	Learning Rate: 0.000195126
	LOSS [training: 0.3437591927757551 | validation: 0.6202199393636871]
	TIME [epoch: 9.72 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3291061355791614		[learning rate: 0.00019442]
	Learning Rate: 0.000194418
	LOSS [training: 0.3291061355791614 | validation: 0.679002786539605]
	TIME [epoch: 9.72 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36326945560447527		[learning rate: 0.00019371]
	Learning Rate: 0.000193713
	LOSS [training: 0.36326945560447527 | validation: 0.671447648302796]
	TIME [epoch: 9.72 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36229231216610586		[learning rate: 0.00019301]
	Learning Rate: 0.00019301
	LOSS [training: 0.36229231216610586 | validation: 0.6335635294593642]
	TIME [epoch: 9.72 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33437027893689997		[learning rate: 0.00019231]
	Learning Rate: 0.000192309
	LOSS [training: 0.33437027893689997 | validation: 0.6403145244605429]
	TIME [epoch: 9.72 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33143743279961196		[learning rate: 0.00019161]
	Learning Rate: 0.000191611
	LOSS [training: 0.33143743279961196 | validation: 0.6585944243610059]
	TIME [epoch: 9.73 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.325003661573651		[learning rate: 0.00019092]
	Learning Rate: 0.000190916
	LOSS [training: 0.325003661573651 | validation: 0.5950976369673792]
	TIME [epoch: 9.72 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35527363752417324		[learning rate: 0.00019022]
	Learning Rate: 0.000190223
	LOSS [training: 0.35527363752417324 | validation: 0.6321147430879881]
	TIME [epoch: 9.72 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35098377376368467		[learning rate: 0.00018953]
	Learning Rate: 0.000189533
	LOSS [training: 0.35098377376368467 | validation: 0.6980780373823582]
	TIME [epoch: 9.71 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34356731317591443		[learning rate: 0.00018884]
	Learning Rate: 0.000188845
	LOSS [training: 0.34356731317591443 | validation: 0.6485908509656362]
	TIME [epoch: 9.74 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3789259374413832		[learning rate: 0.00018816]
	Learning Rate: 0.00018816
	LOSS [training: 0.3789259374413832 | validation: 0.6358295591816553]
	TIME [epoch: 9.71 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33751266716540906		[learning rate: 0.00018748]
	Learning Rate: 0.000187477
	LOSS [training: 0.33751266716540906 | validation: 0.5779018783602691]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1194.pth
	Model improved!!!
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31770820932264343		[learning rate: 0.0001868]
	Learning Rate: 0.000186796
	LOSS [training: 0.31770820932264343 | validation: 0.6022641533774996]
	TIME [epoch: 9.72 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3432795957900963		[learning rate: 0.00018612]
	Learning Rate: 0.000186119
	LOSS [training: 0.3432795957900963 | validation: 0.5884223680390804]
	TIME [epoch: 9.71 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3310897519120307		[learning rate: 0.00018544]
	Learning Rate: 0.000185443
	LOSS [training: 0.3310897519120307 | validation: 0.666374192536821]
	TIME [epoch: 9.71 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35442443296301845		[learning rate: 0.00018477]
	Learning Rate: 0.00018477
	LOSS [training: 0.35442443296301845 | validation: 0.6469147702440836]
	TIME [epoch: 9.71 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3343995097255303		[learning rate: 0.0001841]
	Learning Rate: 0.000184099
	LOSS [training: 0.3343995097255303 | validation: 0.6226760435411278]
	TIME [epoch: 9.72 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34966165597684407		[learning rate: 0.00018343]
	Learning Rate: 0.000183431
	LOSS [training: 0.34966165597684407 | validation: 0.6116023420860193]
	TIME [epoch: 9.71 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3461331387930609		[learning rate: 0.00018277]
	Learning Rate: 0.000182766
	LOSS [training: 0.3461331387930609 | validation: 0.6293663290120403]
	TIME [epoch: 9.71 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3362185546209956		[learning rate: 0.0001821]
	Learning Rate: 0.000182102
	LOSS [training: 0.3362185546209956 | validation: 0.6281929520484181]
	TIME [epoch: 9.72 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3479458559948683		[learning rate: 0.00018144]
	Learning Rate: 0.000181442
	LOSS [training: 0.3479458559948683 | validation: 0.6279063208352723]
	TIME [epoch: 9.71 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3655204315961181		[learning rate: 0.00018078]
	Learning Rate: 0.000180783
	LOSS [training: 0.3655204315961181 | validation: 0.6363152201572875]
	TIME [epoch: 9.71 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33187067425255595		[learning rate: 0.00018013]
	Learning Rate: 0.000180127
	LOSS [training: 0.33187067425255595 | validation: 0.6115540439914715]
	TIME [epoch: 9.72 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3511142608058485		[learning rate: 0.00017947]
	Learning Rate: 0.000179473
	LOSS [training: 0.3511142608058485 | validation: 0.6228438784611438]
	TIME [epoch: 9.71 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3512074373469686		[learning rate: 0.00017882]
	Learning Rate: 0.000178822
	LOSS [training: 0.3512074373469686 | validation: 0.6736644225626102]
	TIME [epoch: 9.71 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42281815988168175		[learning rate: 0.00017817]
	Learning Rate: 0.000178173
	LOSS [training: 0.42281815988168175 | validation: 0.6812260687293411]
	TIME [epoch: 9.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.361188396667675		[learning rate: 0.00017753]
	Learning Rate: 0.000177526
	LOSS [training: 0.361188396667675 | validation: 0.6918759426000693]
	TIME [epoch: 9.72 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3359308494985248		[learning rate: 0.00017688]
	Learning Rate: 0.000176882
	LOSS [training: 0.3359308494985248 | validation: 0.662484041541727]
	TIME [epoch: 9.71 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3478389835367105		[learning rate: 0.00017624]
	Learning Rate: 0.00017624
	LOSS [training: 0.3478389835367105 | validation: 0.6642370083315163]
	TIME [epoch: 9.71 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3772940545123619		[learning rate: 0.0001756]
	Learning Rate: 0.000175601
	LOSS [training: 0.3772940545123619 | validation: 0.6529281989651673]
	TIME [epoch: 9.72 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35792300244245173		[learning rate: 0.00017496]
	Learning Rate: 0.000174964
	LOSS [training: 0.35792300244245173 | validation: 0.5903028145031184]
	TIME [epoch: 9.71 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33466839343221555		[learning rate: 0.00017433]
	Learning Rate: 0.000174329
	LOSS [training: 0.33466839343221555 | validation: 0.6065744507840829]
	TIME [epoch: 9.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33979792561487787		[learning rate: 0.0001737]
	Learning Rate: 0.000173696
	LOSS [training: 0.33979792561487787 | validation: 0.637949526623319]
	TIME [epoch: 9.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3371542060876015		[learning rate: 0.00017307]
	Learning Rate: 0.000173066
	LOSS [training: 0.3371542060876015 | validation: 0.6787237243496514]
	TIME [epoch: 9.72 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3793502583547093		[learning rate: 0.00017244]
	Learning Rate: 0.000172437
	LOSS [training: 0.3793502583547093 | validation: 0.5774531690180402]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1217.pth
	Model improved!!!
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32739467118723786		[learning rate: 0.00017181]
	Learning Rate: 0.000171812
	LOSS [training: 0.32739467118723786 | validation: 0.6271859752882104]
	TIME [epoch: 9.71 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34509226453662456		[learning rate: 0.00017119]
	Learning Rate: 0.000171188
	LOSS [training: 0.34509226453662456 | validation: 0.6383970321911626]
	TIME [epoch: 9.72 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32463035293766107		[learning rate: 0.00017057]
	Learning Rate: 0.000170567
	LOSS [training: 0.32463035293766107 | validation: 0.6245142592973312]
	TIME [epoch: 9.71 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32243377719541616		[learning rate: 0.00016995]
	Learning Rate: 0.000169948
	LOSS [training: 0.32243377719541616 | validation: 0.5982256484092247]
	TIME [epoch: 9.71 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34782197496250217		[learning rate: 0.00016933]
	Learning Rate: 0.000169331
	LOSS [training: 0.34782197496250217 | validation: 0.6047999461533856]
	TIME [epoch: 9.71 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3204206313717731		[learning rate: 0.00016872]
	Learning Rate: 0.000168717
	LOSS [training: 0.3204206313717731 | validation: 0.6376978360301042]
	TIME [epoch: 9.72 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32059529952361576		[learning rate: 0.0001681]
	Learning Rate: 0.000168104
	LOSS [training: 0.32059529952361576 | validation: 0.6526909484816167]
	TIME [epoch: 9.71 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34044314306444595		[learning rate: 0.00016749]
	Learning Rate: 0.000167494
	LOSS [training: 0.34044314306444595 | validation: 0.6193035746061957]
	TIME [epoch: 9.71 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33519215182975765		[learning rate: 0.00016689]
	Learning Rate: 0.000166886
	LOSS [training: 0.33519215182975765 | validation: 0.6597452237337776]
	TIME [epoch: 9.72 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36716345208066853		[learning rate: 0.00016628]
	Learning Rate: 0.000166281
	LOSS [training: 0.36716345208066853 | validation: 0.6377778593088044]
	TIME [epoch: 9.71 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33792415569543466		[learning rate: 0.00016568]
	Learning Rate: 0.000165677
	LOSS [training: 0.33792415569543466 | validation: 0.6452370751028127]
	TIME [epoch: 9.7 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3912213434325141		[learning rate: 0.00016508]
	Learning Rate: 0.000165076
	LOSS [training: 0.3912213434325141 | validation: 0.6727232308330259]
	TIME [epoch: 9.72 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35669916640448057		[learning rate: 0.00016448]
	Learning Rate: 0.000164477
	LOSS [training: 0.35669916640448057 | validation: 0.6235786074127475]
	TIME [epoch: 9.71 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3303080455505258		[learning rate: 0.00016388]
	Learning Rate: 0.00016388
	LOSS [training: 0.3303080455505258 | validation: 0.6314453181335923]
	TIME [epoch: 9.71 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.342153694385117		[learning rate: 0.00016329]
	Learning Rate: 0.000163285
	LOSS [training: 0.342153694385117 | validation: 0.6566197288206195]
	TIME [epoch: 9.71 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33762699114811745		[learning rate: 0.00016269]
	Learning Rate: 0.000162693
	LOSS [training: 0.33762699114811745 | validation: 0.640850245709658]
	TIME [epoch: 9.71 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33349652856893464		[learning rate: 0.0001621]
	Learning Rate: 0.000162102
	LOSS [training: 0.33349652856893464 | validation: 0.6992614330024691]
	TIME [epoch: 9.71 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3443730762970817		[learning rate: 0.00016151]
	Learning Rate: 0.000161514
	LOSS [training: 0.3443730762970817 | validation: 0.6265804219476396]
	TIME [epoch: 9.71 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36636560211570207		[learning rate: 0.00016093]
	Learning Rate: 0.000160928
	LOSS [training: 0.36636560211570207 | validation: 0.6318504771937493]
	TIME [epoch: 9.72 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3390586409279205		[learning rate: 0.00016034]
	Learning Rate: 0.000160344
	LOSS [training: 0.3390586409279205 | validation: 0.6429739055785555]
	TIME [epoch: 9.71 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35580090428485045		[learning rate: 0.00015976]
	Learning Rate: 0.000159762
	LOSS [training: 0.35580090428485045 | validation: 0.6462871335552651]
	TIME [epoch: 9.71 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3367222527828816		[learning rate: 0.00015918]
	Learning Rate: 0.000159182
	LOSS [training: 0.3367222527828816 | validation: 0.6730393920942258]
	TIME [epoch: 9.72 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.345335290827692		[learning rate: 0.0001586]
	Learning Rate: 0.000158605
	LOSS [training: 0.345335290827692 | validation: 0.712672820216001]
	TIME [epoch: 9.71 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33043409115436406		[learning rate: 0.00015803]
	Learning Rate: 0.000158029
	LOSS [training: 0.33043409115436406 | validation: 0.6466115226241402]
	TIME [epoch: 9.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4217415371055866		[learning rate: 0.00015746]
	Learning Rate: 0.000157456
	LOSS [training: 0.4217415371055866 | validation: 0.609321414316111]
	TIME [epoch: 9.71 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3287837986439462		[learning rate: 0.00015688]
	Learning Rate: 0.000156884
	LOSS [training: 0.3287837986439462 | validation: 0.7063057010402238]
	TIME [epoch: 9.72 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33293018943662905		[learning rate: 0.00015631]
	Learning Rate: 0.000156315
	LOSS [training: 0.33293018943662905 | validation: 0.6151341201556523]
	TIME [epoch: 9.71 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3435221436715777		[learning rate: 0.00015575]
	Learning Rate: 0.000155748
	LOSS [training: 0.3435221436715777 | validation: 0.6170190056889777]
	TIME [epoch: 9.71 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34160255168421755		[learning rate: 0.00015518]
	Learning Rate: 0.000155182
	LOSS [training: 0.34160255168421755 | validation: 0.6793831170439409]
	TIME [epoch: 9.72 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34210159722614597		[learning rate: 0.00015462]
	Learning Rate: 0.000154619
	LOSS [training: 0.34210159722614597 | validation: 0.6231937021946448]
	TIME [epoch: 9.71 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3461035205780617		[learning rate: 0.00015406]
	Learning Rate: 0.000154058
	LOSS [training: 0.3461035205780617 | validation: 0.6642213506638406]
	TIME [epoch: 9.7 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3215346043465752		[learning rate: 0.0001535]
	Learning Rate: 0.000153499
	LOSS [training: 0.3215346043465752 | validation: 0.6632623084784005]
	TIME [epoch: 9.7 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3867887781548357		[learning rate: 0.00015294]
	Learning Rate: 0.000152942
	LOSS [training: 0.3867887781548357 | validation: 0.6776851735217962]
	TIME [epoch: 9.72 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34774536274076817		[learning rate: 0.00015239]
	Learning Rate: 0.000152387
	LOSS [training: 0.34774536274076817 | validation: 0.6368468601474541]
	TIME [epoch: 9.71 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36087140987324684		[learning rate: 0.00015183]
	Learning Rate: 0.000151834
	LOSS [training: 0.36087140987324684 | validation: 0.6206514291870961]
	TIME [epoch: 9.71 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32289628369407186		[learning rate: 0.00015128]
	Learning Rate: 0.000151283
	LOSS [training: 0.32289628369407186 | validation: 0.6700419216555881]
	TIME [epoch: 9.72 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3480719296988316		[learning rate: 0.00015073]
	Learning Rate: 0.000150734
	LOSS [training: 0.3480719296988316 | validation: 0.631884077001036]
	TIME [epoch: 9.71 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32329425878180984		[learning rate: 0.00015019]
	Learning Rate: 0.000150187
	LOSS [training: 0.32329425878180984 | validation: 0.5996666834996942]
	TIME [epoch: 9.71 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31895183709350156		[learning rate: 0.00014964]
	Learning Rate: 0.000149642
	LOSS [training: 0.31895183709350156 | validation: 0.6501517124533248]
	TIME [epoch: 9.72 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3360305977576028		[learning rate: 0.0001491]
	Learning Rate: 0.000149099
	LOSS [training: 0.3360305977576028 | validation: 0.6892659539805388]
	TIME [epoch: 9.71 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35213780586655585		[learning rate: 0.00014856]
	Learning Rate: 0.000148558
	LOSS [training: 0.35213780586655585 | validation: 0.6548641970173265]
	TIME [epoch: 9.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3243529813961466		[learning rate: 0.00014802]
	Learning Rate: 0.000148018
	LOSS [training: 0.3243529813961466 | validation: 0.6010474489923877]
	TIME [epoch: 9.7 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34728869370888243		[learning rate: 0.00014748]
	Learning Rate: 0.000147481
	LOSS [training: 0.34728869370888243 | validation: 0.617421656174329]
	TIME [epoch: 9.73 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34632514695945166		[learning rate: 0.00014695]
	Learning Rate: 0.000146946
	LOSS [training: 0.34632514695945166 | validation: 0.6000067412890299]
	TIME [epoch: 9.71 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3442319206793503		[learning rate: 0.00014641]
	Learning Rate: 0.000146413
	LOSS [training: 0.3442319206793503 | validation: 0.6379965965771994]
	TIME [epoch: 9.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3263222029209579		[learning rate: 0.00014588]
	Learning Rate: 0.000145881
	LOSS [training: 0.3263222029209579 | validation: 0.6616424875067185]
	TIME [epoch: 9.72 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3516822626092609		[learning rate: 0.00014535]
	Learning Rate: 0.000145352
	LOSS [training: 0.3516822626092609 | validation: 0.6097562735261619]
	TIME [epoch: 9.7 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3256725662702677		[learning rate: 0.00014482]
	Learning Rate: 0.000144825
	LOSS [training: 0.3256725662702677 | validation: 0.6605142218756936]
	TIME [epoch: 9.7 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.333923461427262		[learning rate: 0.0001443]
	Learning Rate: 0.000144299
	LOSS [training: 0.333923461427262 | validation: 0.6592345495803362]
	TIME [epoch: 9.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35462557121183924		[learning rate: 0.00014378]
	Learning Rate: 0.000143775
	LOSS [training: 0.35462557121183924 | validation: 0.6071552583214086]
	TIME [epoch: 9.72 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3357072029171782		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.3357072029171782 | validation: 0.6389024297734113]
	TIME [epoch: 9.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32145694916362794		[learning rate: 0.00014273]
	Learning Rate: 0.000142734
	LOSS [training: 0.32145694916362794 | validation: 0.5839874220801191]
	TIME [epoch: 9.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33443985033602674		[learning rate: 0.00014222]
	Learning Rate: 0.000142216
	LOSS [training: 0.33443985033602674 | validation: 0.6518795407234559]
	TIME [epoch: 9.72 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.338212683830123		[learning rate: 0.0001417]
	Learning Rate: 0.0001417
	LOSS [training: 0.338212683830123 | validation: 0.6465987900485185]
	TIME [epoch: 9.71 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3717855169605071		[learning rate: 0.00014119]
	Learning Rate: 0.000141185
	LOSS [training: 0.3717855169605071 | validation: 0.595519147134473]
	TIME [epoch: 9.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38543387526873085		[learning rate: 0.00014067]
	Learning Rate: 0.000140673
	LOSS [training: 0.38543387526873085 | validation: 0.6230867952601029]
	TIME [epoch: 9.72 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35399776997450366		[learning rate: 0.00014016]
	Learning Rate: 0.000140162
	LOSS [training: 0.35399776997450366 | validation: 0.6353857549615789]
	TIME [epoch: 9.71 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3350671815539298		[learning rate: 0.00013965]
	Learning Rate: 0.000139654
	LOSS [training: 0.3350671815539298 | validation: 0.635772031611126]
	TIME [epoch: 9.71 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33993123504961886		[learning rate: 0.00013915]
	Learning Rate: 0.000139147
	LOSS [training: 0.33993123504961886 | validation: 0.5801356742679473]
	TIME [epoch: 9.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33478566043474106		[learning rate: 0.00013864]
	Learning Rate: 0.000138642
	LOSS [training: 0.33478566043474106 | validation: 0.6179030146719476]
	TIME [epoch: 9.73 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33451395545595686		[learning rate: 0.00013814]
	Learning Rate: 0.000138139
	LOSS [training: 0.33451395545595686 | validation: 0.6956859877991322]
	TIME [epoch: 9.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3299298959905599		[learning rate: 0.00013764]
	Learning Rate: 0.000137638
	LOSS [training: 0.3299298959905599 | validation: 0.6450302400027274]
	TIME [epoch: 9.71 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3318223904879596		[learning rate: 0.00013714]
	Learning Rate: 0.000137138
	LOSS [training: 0.3318223904879596 | validation: 0.65558010425336]
	TIME [epoch: 9.72 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3360529272263149		[learning rate: 0.00013664]
	Learning Rate: 0.00013664
	LOSS [training: 0.3360529272263149 | validation: 0.6553625502156101]
	TIME [epoch: 9.71 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3276174896847551		[learning rate: 0.00013614]
	Learning Rate: 0.000136144
	LOSS [training: 0.3276174896847551 | validation: 0.6801581868729281]
	TIME [epoch: 9.71 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3655217060196291		[learning rate: 0.00013565]
	Learning Rate: 0.00013565
	LOSS [training: 0.3655217060196291 | validation: 0.6652860247020488]
	TIME [epoch: 9.71 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3344094622079462		[learning rate: 0.00013516]
	Learning Rate: 0.000135158
	LOSS [training: 0.3344094622079462 | validation: 0.5738875916778103]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1284.pth
	Model improved!!!
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3399769244430785		[learning rate: 0.00013467]
	Learning Rate: 0.000134668
	LOSS [training: 0.3399769244430785 | validation: 0.674953421513107]
	TIME [epoch: 9.71 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32464414407579867		[learning rate: 0.00013418]
	Learning Rate: 0.000134179
	LOSS [training: 0.32464414407579867 | validation: 0.621939510240868]
	TIME [epoch: 9.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3589950899321638		[learning rate: 0.00013369]
	Learning Rate: 0.000133692
	LOSS [training: 0.3589950899321638 | validation: 0.6417136604288237]
	TIME [epoch: 9.72 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33860865157809245		[learning rate: 0.00013321]
	Learning Rate: 0.000133207
	LOSS [training: 0.33860865157809245 | validation: 0.7333156902266363]
	TIME [epoch: 9.72 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3929796807052318		[learning rate: 0.00013272]
	Learning Rate: 0.000132723
	LOSS [training: 0.3929796807052318 | validation: 0.6552889650450586]
	TIME [epoch: 9.71 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33900179123430396		[learning rate: 0.00013224]
	Learning Rate: 0.000132242
	LOSS [training: 0.33900179123430396 | validation: 0.6761338117898396]
	TIME [epoch: 9.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3302514376893715		[learning rate: 0.00013176]
	Learning Rate: 0.000131762
	LOSS [training: 0.3302514376893715 | validation: 0.6576881120586531]
	TIME [epoch: 9.72 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3354261736720245		[learning rate: 0.00013128]
	Learning Rate: 0.000131284
	LOSS [training: 0.3354261736720245 | validation: 0.615323605771426]
	TIME [epoch: 9.71 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3287031003754985		[learning rate: 0.00013081]
	Learning Rate: 0.000130807
	LOSS [training: 0.3287031003754985 | validation: 0.6248839900320092]
	TIME [epoch: 9.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.329495405942622		[learning rate: 0.00013033]
	Learning Rate: 0.000130332
	LOSS [training: 0.329495405942622 | validation: 0.643269878892715]
	TIME [epoch: 9.73 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34777133328455617		[learning rate: 0.00012986]
	Learning Rate: 0.000129859
	LOSS [training: 0.34777133328455617 | validation: 0.6545067848653422]
	TIME [epoch: 9.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32834860223173823		[learning rate: 0.00012939]
	Learning Rate: 0.000129388
	LOSS [training: 0.32834860223173823 | validation: 0.6095101051331786]
	TIME [epoch: 9.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059947383683694		[learning rate: 0.00012892]
	Learning Rate: 0.000128919
	LOSS [training: 0.3059947383683694 | validation: 0.6808780631523211]
	TIME [epoch: 9.73 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3361663243543007		[learning rate: 0.00012845]
	Learning Rate: 0.000128451
	LOSS [training: 0.3361663243543007 | validation: 0.6884327221667917]
	TIME [epoch: 9.71 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3232445267237384		[learning rate: 0.00012798]
	Learning Rate: 0.000127985
	LOSS [training: 0.3232445267237384 | validation: 0.6002562702297698]
	TIME [epoch: 9.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31779067232079		[learning rate: 0.00012752]
	Learning Rate: 0.00012752
	LOSS [training: 0.31779067232079 | validation: 0.5807304821060829]
	TIME [epoch: 9.71 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32095270440982804		[learning rate: 0.00012706]
	Learning Rate: 0.000127057
	LOSS [training: 0.32095270440982804 | validation: 0.6417625503382687]
	TIME [epoch: 9.72 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146018990820388		[learning rate: 0.0001266]
	Learning Rate: 0.000126596
	LOSS [training: 0.3146018990820388 | validation: 0.589937066682558]
	TIME [epoch: 9.71 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32508798363127195		[learning rate: 0.00012614]
	Learning Rate: 0.000126137
	LOSS [training: 0.32508798363127195 | validation: 0.6369085584710328]
	TIME [epoch: 9.71 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3096810816264908		[learning rate: 0.00012568]
	Learning Rate: 0.000125679
	LOSS [training: 0.3096810816264908 | validation: 0.6024571780698988]
	TIME [epoch: 9.72 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30978061717798333		[learning rate: 0.00012522]
	Learning Rate: 0.000125223
	LOSS [training: 0.30978061717798333 | validation: 0.6834884821254591]
	TIME [epoch: 9.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3406902293980624		[learning rate: 0.00012477]
	Learning Rate: 0.000124769
	LOSS [training: 0.3406902293980624 | validation: 0.6160498049156151]
	TIME [epoch: 9.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.316409563348173		[learning rate: 0.00012432]
	Learning Rate: 0.000124316
	LOSS [training: 0.316409563348173 | validation: 0.6284882432182929]
	TIME [epoch: 9.71 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33045919593961603		[learning rate: 0.00012386]
	Learning Rate: 0.000123865
	LOSS [training: 0.33045919593961603 | validation: 0.5853900610845332]
	TIME [epoch: 9.72 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3138099496629018		[learning rate: 0.00012342]
	Learning Rate: 0.000123415
	LOSS [training: 0.3138099496629018 | validation: 0.5979810059054913]
	TIME [epoch: 9.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3299300452553092		[learning rate: 0.00012297]
	Learning Rate: 0.000122967
	LOSS [training: 0.3299300452553092 | validation: 0.6774192157583946]
	TIME [epoch: 9.7 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.351943639497038		[learning rate: 0.00012252]
	Learning Rate: 0.000122521
	LOSS [training: 0.351943639497038 | validation: 0.5843754394428017]
	TIME [epoch: 9.73 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.358053678537522		[learning rate: 0.00012208]
	Learning Rate: 0.000122076
	LOSS [training: 0.358053678537522 | validation: 0.6773903246638474]
	TIME [epoch: 9.71 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3539144860712666		[learning rate: 0.00012163]
	Learning Rate: 0.000121633
	LOSS [training: 0.3539144860712666 | validation: 0.7065460833017617]
	TIME [epoch: 9.7 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32790155047215874		[learning rate: 0.00012119]
	Learning Rate: 0.000121192
	LOSS [training: 0.32790155047215874 | validation: 0.6092116813712678]
	TIME [epoch: 9.73 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30970409171655316		[learning rate: 0.00012075]
	Learning Rate: 0.000120752
	LOSS [training: 0.30970409171655316 | validation: 0.6272971776332992]
	TIME [epoch: 9.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.328306507258533		[learning rate: 0.00012031]
	Learning Rate: 0.000120314
	LOSS [training: 0.328306507258533 | validation: 0.625291349174995]
	TIME [epoch: 9.69 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34773095073390325		[learning rate: 0.00011988]
	Learning Rate: 0.000119877
	LOSS [training: 0.34773095073390325 | validation: 0.6473843212404076]
	TIME [epoch: 9.7 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34624771588016867		[learning rate: 0.00011944]
	Learning Rate: 0.000119442
	LOSS [training: 0.34624771588016867 | validation: 0.6605094867582713]
	TIME [epoch: 9.71 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3935739286372917		[learning rate: 0.00011901]
	Learning Rate: 0.000119009
	LOSS [training: 0.3935739286372917 | validation: 0.6206419720146927]
	TIME [epoch: 9.71 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3283086842366016		[learning rate: 0.00011858]
	Learning Rate: 0.000118577
	LOSS [training: 0.3283086842366016 | validation: 0.616658391131869]
	TIME [epoch: 9.69 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3316994499048464		[learning rate: 0.00011815]
	Learning Rate: 0.000118147
	LOSS [training: 0.3316994499048464 | validation: 0.5744238852181737]
	TIME [epoch: 9.72 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3380818534943896		[learning rate: 0.00011772]
	Learning Rate: 0.000117718
	LOSS [training: 0.3380818534943896 | validation: 0.6387339984500148]
	TIME [epoch: 9.71 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34534030847087405		[learning rate: 0.00011729]
	Learning Rate: 0.000117291
	LOSS [training: 0.34534030847087405 | validation: 0.6287571955380822]
	TIME [epoch: 9.7 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34250677945729724		[learning rate: 0.00011686]
	Learning Rate: 0.000116865
	LOSS [training: 0.34250677945729724 | validation: 0.6074838858437366]
	TIME [epoch: 9.72 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32365115485965357		[learning rate: 0.00011644]
	Learning Rate: 0.000116441
	LOSS [training: 0.32365115485965357 | validation: 0.5539322773315886]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1325.pth
	Model improved!!!
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3127457112874348		[learning rate: 0.00011602]
	Learning Rate: 0.000116018
	LOSS [training: 0.3127457112874348 | validation: 0.6314168887212802]
	TIME [epoch: 9.69 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31370171267089103		[learning rate: 0.0001156]
	Learning Rate: 0.000115597
	LOSS [training: 0.31370171267089103 | validation: 0.5731272246113804]
	TIME [epoch: 9.69 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3319979268286056		[learning rate: 0.00011518]
	Learning Rate: 0.000115178
	LOSS [training: 0.3319979268286056 | validation: 0.6508916628441374]
	TIME [epoch: 9.72 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36243205417507063		[learning rate: 0.00011476]
	Learning Rate: 0.00011476
	LOSS [training: 0.36243205417507063 | validation: 0.5932103057419209]
	TIME [epoch: 9.7 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32393921659107355		[learning rate: 0.00011434]
	Learning Rate: 0.000114343
	LOSS [training: 0.32393921659107355 | validation: 0.6440252215689125]
	TIME [epoch: 9.69 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31644612322547927		[learning rate: 0.00011393]
	Learning Rate: 0.000113928
	LOSS [training: 0.31644612322547927 | validation: 0.6499646797072037]
	TIME [epoch: 9.72 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3473379861373761		[learning rate: 0.00011351]
	Learning Rate: 0.000113515
	LOSS [training: 0.3473379861373761 | validation: 0.5727295002511577]
	TIME [epoch: 9.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3179666270935436		[learning rate: 0.0001131]
	Learning Rate: 0.000113103
	LOSS [training: 0.3179666270935436 | validation: 0.6728636538571402]
	TIME [epoch: 9.7 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3259220655884564		[learning rate: 0.00011269]
	Learning Rate: 0.000112692
	LOSS [training: 0.3259220655884564 | validation: 0.6135815718377785]
	TIME [epoch: 9.7 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33362945915433173		[learning rate: 0.00011228]
	Learning Rate: 0.000112283
	LOSS [training: 0.33362945915433173 | validation: 0.6007461284845823]
	TIME [epoch: 9.72 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3212587468794658		[learning rate: 0.00011188]
	Learning Rate: 0.000111876
	LOSS [training: 0.3212587468794658 | validation: 0.6499333787450274]
	TIME [epoch: 9.7 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3834843387493708		[learning rate: 0.00011147]
	Learning Rate: 0.00011147
	LOSS [training: 0.3834843387493708 | validation: 0.6502035669296007]
	TIME [epoch: 9.69 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35438660860693955		[learning rate: 0.00011107]
	Learning Rate: 0.000111065
	LOSS [training: 0.35438660860693955 | validation: 0.5801508749094663]
	TIME [epoch: 9.7 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32361595046516706		[learning rate: 0.00011066]
	Learning Rate: 0.000110662
	LOSS [training: 0.32361595046516706 | validation: 0.666297135800594]
	TIME [epoch: 9.7 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33158916415111206		[learning rate: 0.00011026]
	Learning Rate: 0.000110261
	LOSS [training: 0.33158916415111206 | validation: 0.6104671983427473]
	TIME [epoch: 9.69 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31414976580380866		[learning rate: 0.00010986]
	Learning Rate: 0.000109861
	LOSS [training: 0.31414976580380866 | validation: 0.6341639289207168]
	TIME [epoch: 9.71 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3236213689970372		[learning rate: 0.00010946]
	Learning Rate: 0.000109462
	LOSS [training: 0.3236213689970372 | validation: 0.6352292018518899]
	TIME [epoch: 9.7 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3421528150034806		[learning rate: 0.00010906]
	Learning Rate: 0.000109065
	LOSS [training: 0.3421528150034806 | validation: 0.6335550867247572]
	TIME [epoch: 9.69 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.327678639257937		[learning rate: 0.00010867]
	Learning Rate: 0.000108669
	LOSS [training: 0.327678639257937 | validation: 0.6046613382335327]
	TIME [epoch: 9.7 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31401026299878687		[learning rate: 0.00010827]
	Learning Rate: 0.000108275
	LOSS [training: 0.31401026299878687 | validation: 0.6226222162257795]
	TIME [epoch: 9.71 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3406940150552439		[learning rate: 0.00010788]
	Learning Rate: 0.000107882
	LOSS [training: 0.3406940150552439 | validation: 0.5904847717427141]
	TIME [epoch: 9.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077342120046086		[learning rate: 0.00010749]
	Learning Rate: 0.00010749
	LOSS [training: 0.3077342120046086 | validation: 0.6109808621797231]
	TIME [epoch: 9.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3129725767769772		[learning rate: 0.0001071]
	Learning Rate: 0.0001071
	LOSS [training: 0.3129725767769772 | validation: 0.6209137688038585]
	TIME [epoch: 9.71 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31768396552961625		[learning rate: 0.00010671]
	Learning Rate: 0.000106711
	LOSS [training: 0.31768396552961625 | validation: 0.6184978014061832]
	TIME [epoch: 9.69 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32342115787356207		[learning rate: 0.00010632]
	Learning Rate: 0.000106324
	LOSS [training: 0.32342115787356207 | validation: 0.5628421646290839]
	TIME [epoch: 9.69 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32236432229470624		[learning rate: 0.00010594]
	Learning Rate: 0.000105938
	LOSS [training: 0.32236432229470624 | validation: 0.6463959607817573]
	TIME [epoch: 9.69 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30794943752163223		[learning rate: 0.00010555]
	Learning Rate: 0.000105554
	LOSS [training: 0.30794943752163223 | validation: 0.6615462450123301]
	TIME [epoch: 9.71 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3369993188887451		[learning rate: 0.00010517]
	Learning Rate: 0.000105171
	LOSS [training: 0.3369993188887451 | validation: 0.6701147730402665]
	TIME [epoch: 9.69 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3856938552529784		[learning rate: 0.00010479]
	Learning Rate: 0.000104789
	LOSS [training: 0.3856938552529784 | validation: 0.6120206003376029]
	TIME [epoch: 9.7 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3440954028881025		[learning rate: 0.00010441]
	Learning Rate: 0.000104409
	LOSS [training: 0.3440954028881025 | validation: 0.6144980109104133]
	TIME [epoch: 9.72 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3211298691497251		[learning rate: 0.00010403]
	Learning Rate: 0.00010403
	LOSS [training: 0.3211298691497251 | validation: 0.6728969429252075]
	TIME [epoch: 9.7 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3213066536129195		[learning rate: 0.00010365]
	Learning Rate: 0.000103652
	LOSS [training: 0.3213066536129195 | validation: 0.6788344026653842]
	TIME [epoch: 9.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3166866133749471		[learning rate: 0.00010328]
	Learning Rate: 0.000103276
	LOSS [training: 0.3166866133749471 | validation: 0.6459996404690495]
	TIME [epoch: 9.7 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.315981207741941		[learning rate: 0.0001029]
	Learning Rate: 0.000102901
	LOSS [training: 0.315981207741941 | validation: 0.635015469687681]
	TIME [epoch: 9.71 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33194743031261126		[learning rate: 0.00010253]
	Learning Rate: 0.000102528
	LOSS [training: 0.33194743031261126 | validation: 0.6264694058879162]
	TIME [epoch: 9.71 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3098562366288745		[learning rate: 0.00010216]
	Learning Rate: 0.000102156
	LOSS [training: 0.3098562366288745 | validation: 0.6327251984333185]
	TIME [epoch: 9.69 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3207842196378863		[learning rate: 0.00010179]
	Learning Rate: 0.000101785
	LOSS [training: 0.3207842196378863 | validation: 0.6412911918448074]
	TIME [epoch: 9.71 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3165921932617234		[learning rate: 0.00010142]
	Learning Rate: 0.000101416
	LOSS [training: 0.3165921932617234 | validation: 0.5754693256706895]
	TIME [epoch: 9.69 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3152313332062103		[learning rate: 0.00010105]
	Learning Rate: 0.000101048
	LOSS [training: 0.3152313332062103 | validation: 0.595996675642642]
	TIME [epoch: 9.69 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3267411267539333		[learning rate: 0.00010068]
	Learning Rate: 0.000100681
	LOSS [training: 0.3267411267539333 | validation: 0.6247707835593352]
	TIME [epoch: 9.71 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3290244081367677		[learning rate: 0.00010032]
	Learning Rate: 0.000100316
	LOSS [training: 0.3290244081367677 | validation: 0.6490650529534812]
	TIME [epoch: 9.7 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37758191281421516		[learning rate: 9.9952e-05]
	Learning Rate: 9.99515e-05
	LOSS [training: 0.37758191281421516 | validation: 0.588979443488732]
	TIME [epoch: 9.7 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168243213937574		[learning rate: 9.9589e-05]
	Learning Rate: 9.95888e-05
	LOSS [training: 0.3168243213937574 | validation: 0.5844632483880212]
	TIME [epoch: 9.69 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3237117655807521		[learning rate: 9.9227e-05]
	Learning Rate: 9.92274e-05
	LOSS [training: 0.3237117655807521 | validation: 0.5477938382695446]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1369.pth
	Model improved!!!
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3216942943811854		[learning rate: 9.8867e-05]
	Learning Rate: 9.88673e-05
	LOSS [training: 0.3216942943811854 | validation: 0.6738035915527862]
	TIME [epoch: 9.69 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34261723342811445		[learning rate: 9.8509e-05]
	Learning Rate: 9.85085e-05
	LOSS [training: 0.34261723342811445 | validation: 0.5950257743403781]
	TIME [epoch: 9.69 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3027557963665398		[learning rate: 9.8151e-05]
	Learning Rate: 9.8151e-05
	LOSS [training: 0.3027557963665398 | validation: 0.6255677164627852]
	TIME [epoch: 9.71 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3127061072677658		[learning rate: 9.7795e-05]
	Learning Rate: 9.77948e-05
	LOSS [training: 0.3127061072677658 | validation: 0.6253391114767866]
	TIME [epoch: 9.71 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3176830208655622		[learning rate: 9.744e-05]
	Learning Rate: 9.74399e-05
	LOSS [training: 0.3176830208655622 | validation: 0.6540426105202903]
	TIME [epoch: 9.71 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3158433002206502		[learning rate: 9.7086e-05]
	Learning Rate: 9.70863e-05
	LOSS [training: 0.3158433002206502 | validation: 0.5870880896834024]
	TIME [epoch: 9.7 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3157709406266878		[learning rate: 9.6734e-05]
	Learning Rate: 9.6734e-05
	LOSS [training: 0.3157709406266878 | validation: 0.6592495813682802]
	TIME [epoch: 9.71 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3388644847062395		[learning rate: 9.6383e-05]
	Learning Rate: 9.63829e-05
	LOSS [training: 0.3388644847062395 | validation: 0.6268299919271034]
	TIME [epoch: 9.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32974072993252623		[learning rate: 9.6033e-05]
	Learning Rate: 9.60331e-05
	LOSS [training: 0.32974072993252623 | validation: 0.6082465855360495]
	TIME [epoch: 9.69 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3267966778942137		[learning rate: 9.5685e-05]
	Learning Rate: 9.56846e-05
	LOSS [training: 0.3267966778942137 | validation: 0.6031908238371608]
	TIME [epoch: 9.72 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.335908385361123		[learning rate: 9.5337e-05]
	Learning Rate: 9.53374e-05
	LOSS [training: 0.335908385361123 | validation: 0.6358694190662612]
	TIME [epoch: 9.71 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3381557055123332		[learning rate: 9.4991e-05]
	Learning Rate: 9.49914e-05
	LOSS [training: 0.3381557055123332 | validation: 0.6064214476110534]
	TIME [epoch: 9.71 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31706913768516903		[learning rate: 9.4647e-05]
	Learning Rate: 9.46466e-05
	LOSS [training: 0.31706913768516903 | validation: 0.639657786115633]
	TIME [epoch: 9.71 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31907411052956514		[learning rate: 9.4303e-05]
	Learning Rate: 9.43032e-05
	LOSS [training: 0.31907411052956514 | validation: 0.6081428010524736]
	TIME [epoch: 9.7 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33227840586534213		[learning rate: 9.3961e-05]
	Learning Rate: 9.39609e-05
	LOSS [training: 0.33227840586534213 | validation: 0.6021396713432016]
	TIME [epoch: 9.69 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30761045195783554		[learning rate: 9.362e-05]
	Learning Rate: 9.362e-05
	LOSS [training: 0.30761045195783554 | validation: 0.5842778351971022]
	TIME [epoch: 9.69 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3115055318439485		[learning rate: 9.328e-05]
	Learning Rate: 9.32802e-05
	LOSS [training: 0.3115055318439485 | validation: 0.6299292140680038]
	TIME [epoch: 9.72 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31699236418911675		[learning rate: 9.2942e-05]
	Learning Rate: 9.29417e-05
	LOSS [training: 0.31699236418911675 | validation: 0.6104267285592107]
	TIME [epoch: 9.7 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32093678735996534		[learning rate: 9.2604e-05]
	Learning Rate: 9.26044e-05
	LOSS [training: 0.32093678735996534 | validation: 0.5942165419867055]
	TIME [epoch: 9.7 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31582391353601824		[learning rate: 9.2268e-05]
	Learning Rate: 9.22683e-05
	LOSS [training: 0.31582391353601824 | validation: 0.6089998478084668]
	TIME [epoch: 9.71 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32536765550071506		[learning rate: 9.1933e-05]
	Learning Rate: 9.19335e-05
	LOSS [training: 0.32536765550071506 | validation: 0.6519635329273038]
	TIME [epoch: 9.7 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3085135627162933		[learning rate: 9.16e-05]
	Learning Rate: 9.15998e-05
	LOSS [training: 0.3085135627162933 | validation: 0.6308672070589743]
	TIME [epoch: 9.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3258399154041586		[learning rate: 9.1267e-05]
	Learning Rate: 9.12674e-05
	LOSS [training: 0.3258399154041586 | validation: 0.6219210973298914]
	TIME [epoch: 9.71 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33822585502840297		[learning rate: 9.0936e-05]
	Learning Rate: 9.09362e-05
	LOSS [training: 0.33822585502840297 | validation: 0.6135659676127501]
	TIME [epoch: 9.71 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34083096967405957		[learning rate: 9.0606e-05]
	Learning Rate: 9.06062e-05
	LOSS [training: 0.34083096967405957 | validation: 0.6181721631609144]
	TIME [epoch: 9.7 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3106409459659716		[learning rate: 9.0277e-05]
	Learning Rate: 9.02774e-05
	LOSS [training: 0.3106409459659716 | validation: 0.5884833593630404]
	TIME [epoch: 9.69 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.310218490573687		[learning rate: 8.995e-05]
	Learning Rate: 8.99498e-05
	LOSS [training: 0.310218490573687 | validation: 0.6110145954524578]
	TIME [epoch: 9.72 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32709237157788407		[learning rate: 8.9623e-05]
	Learning Rate: 8.96233e-05
	LOSS [training: 0.32709237157788407 | validation: 0.5964648872073218]
	TIME [epoch: 9.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31966685589329946		[learning rate: 8.9298e-05]
	Learning Rate: 8.92981e-05
	LOSS [training: 0.31966685589329946 | validation: 0.5801658446609825]
	TIME [epoch: 9.69 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3071038678896837		[learning rate: 8.8974e-05]
	Learning Rate: 8.8974e-05
	LOSS [training: 0.3071038678896837 | validation: 0.6312262327734948]
	TIME [epoch: 9.73 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3312250099821804		[learning rate: 8.8651e-05]
	Learning Rate: 8.86511e-05
	LOSS [training: 0.3312250099821804 | validation: 0.6325024088211975]
	TIME [epoch: 9.71 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168186462549606		[learning rate: 8.8329e-05]
	Learning Rate: 8.83294e-05
	LOSS [training: 0.3168186462549606 | validation: 0.6229399732831905]
	TIME [epoch: 9.7 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3099051512174165		[learning rate: 8.8009e-05]
	Learning Rate: 8.80088e-05
	LOSS [training: 0.3099051512174165 | validation: 0.6324813355979749]
	TIME [epoch: 9.71 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3171270607319907		[learning rate: 8.7689e-05]
	Learning Rate: 8.76895e-05
	LOSS [training: 0.3171270607319907 | validation: 0.6104442041868123]
	TIME [epoch: 9.72 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30582848149978287		[learning rate: 8.7371e-05]
	Learning Rate: 8.73712e-05
	LOSS [training: 0.30582848149978287 | validation: 0.5747391886407158]
	TIME [epoch: 9.71 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3476958930383979		[learning rate: 8.7054e-05]
	Learning Rate: 8.70542e-05
	LOSS [training: 0.3476958930383979 | validation: 0.6419007824531902]
	TIME [epoch: 9.69 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3516192015962063		[learning rate: 8.6738e-05]
	Learning Rate: 8.67382e-05
	LOSS [training: 0.3516192015962063 | validation: 0.6704410767630127]
	TIME [epoch: 9.72 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3139614465271284		[learning rate: 8.6423e-05]
	Learning Rate: 8.64235e-05
	LOSS [training: 0.3139614465271284 | validation: 0.5975207778994333]
	TIME [epoch: 9.69 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3127683395768605		[learning rate: 8.611e-05]
	Learning Rate: 8.61098e-05
	LOSS [training: 0.3127683395768605 | validation: 0.6222335464432921]
	TIME [epoch: 9.71 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33915350187858107		[learning rate: 8.5797e-05]
	Learning Rate: 8.57973e-05
	LOSS [training: 0.33915350187858107 | validation: 0.6324682694714421]
	TIME [epoch: 9.72 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33098070622419895		[learning rate: 8.5486e-05]
	Learning Rate: 8.54859e-05
	LOSS [training: 0.33098070622419895 | validation: 0.5660434242080173]
	TIME [epoch: 9.72 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33774803904247264		[learning rate: 8.5176e-05]
	Learning Rate: 8.51757e-05
	LOSS [training: 0.33774803904247264 | validation: 0.5901072666434753]
	TIME [epoch: 9.71 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31404426672482577		[learning rate: 8.4867e-05]
	Learning Rate: 8.48666e-05
	LOSS [training: 0.31404426672482577 | validation: 0.6039643204713323]
	TIME [epoch: 9.7 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3236099399070203		[learning rate: 8.4559e-05]
	Learning Rate: 8.45586e-05
	LOSS [training: 0.3236099399070203 | validation: 0.6676738371365925]
	TIME [epoch: 9.71 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30644676751349575		[learning rate: 8.4252e-05]
	Learning Rate: 8.42518e-05
	LOSS [training: 0.30644676751349575 | validation: 0.6587514633419119]
	TIME [epoch: 9.69 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3339961509937136		[learning rate: 8.3946e-05]
	Learning Rate: 8.3946e-05
	LOSS [training: 0.3339961509937136 | validation: 0.6242640893285057]
	TIME [epoch: 9.71 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33371309906829333		[learning rate: 8.3641e-05]
	Learning Rate: 8.36414e-05
	LOSS [training: 0.33371309906829333 | validation: 0.643151462591263]
	TIME [epoch: 9.72 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3247502327892796		[learning rate: 8.3338e-05]
	Learning Rate: 8.33378e-05
	LOSS [training: 0.3247502327892796 | validation: 0.6008852721823448]
	TIME [epoch: 9.71 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31545369214181		[learning rate: 8.3035e-05]
	Learning Rate: 8.30354e-05
	LOSS [training: 0.31545369214181 | validation: 0.6044505102386903]
	TIME [epoch: 9.7 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32326192751703486		[learning rate: 8.2734e-05]
	Learning Rate: 8.2734e-05
	LOSS [training: 0.32326192751703486 | validation: 0.6312309538429022]
	TIME [epoch: 9.7 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2946545007821869		[learning rate: 8.2434e-05]
	Learning Rate: 8.24338e-05
	LOSS [training: 0.2946545007821869 | validation: 0.5715286439742682]
	TIME [epoch: 9.73 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31880722834187863		[learning rate: 8.2135e-05]
	Learning Rate: 8.21346e-05
	LOSS [training: 0.31880722834187863 | validation: 0.6662287225679933]
	TIME [epoch: 9.7 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33349837706379065		[learning rate: 8.1837e-05]
	Learning Rate: 8.18366e-05
	LOSS [training: 0.33349837706379065 | validation: 0.6205422133250926]
	TIME [epoch: 9.71 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31262736772128485		[learning rate: 8.154e-05]
	Learning Rate: 8.15396e-05
	LOSS [training: 0.31262736772128485 | validation: 0.6193282099454069]
	TIME [epoch: 9.73 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33197637351433124		[learning rate: 8.1244e-05]
	Learning Rate: 8.12437e-05
	LOSS [training: 0.33197637351433124 | validation: 0.6026368579316531]
	TIME [epoch: 9.71 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3031895748498957		[learning rate: 8.0949e-05]
	Learning Rate: 8.09488e-05
	LOSS [training: 0.3031895748498957 | validation: 0.556092431782908]
	TIME [epoch: 9.69 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30787639509831777		[learning rate: 8.0655e-05]
	Learning Rate: 8.0655e-05
	LOSS [training: 0.30787639509831777 | validation: 0.6041729751100764]
	TIME [epoch: 9.71 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31198481053407634		[learning rate: 8.0362e-05]
	Learning Rate: 8.03623e-05
	LOSS [training: 0.31198481053407634 | validation: 0.6339280840217508]
	TIME [epoch: 9.72 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.324310105787032		[learning rate: 8.0071e-05]
	Learning Rate: 8.00707e-05
	LOSS [training: 0.324310105787032 | validation: 0.5876698019989453]
	TIME [epoch: 9.7 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3083144002189552		[learning rate: 7.978e-05]
	Learning Rate: 7.97801e-05
	LOSS [training: 0.3083144002189552 | validation: 0.6386507170283193]
	TIME [epoch: 9.69 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31657185978695185		[learning rate: 7.9491e-05]
	Learning Rate: 7.94906e-05
	LOSS [training: 0.31657185978695185 | validation: 0.5969668032532651]
	TIME [epoch: 9.73 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3054967882020866		[learning rate: 7.9202e-05]
	Learning Rate: 7.92021e-05
	LOSS [training: 0.3054967882020866 | validation: 0.5765669028551896]
	TIME [epoch: 9.69 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3176579520937545		[learning rate: 7.8915e-05]
	Learning Rate: 7.89147e-05
	LOSS [training: 0.3176579520937545 | validation: 0.6660189040568543]
	TIME [epoch: 9.71 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3262748820181195		[learning rate: 7.8628e-05]
	Learning Rate: 7.86283e-05
	LOSS [training: 0.3262748820181195 | validation: 0.6072409739958597]
	TIME [epoch: 9.71 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33746308207294917		[learning rate: 7.8343e-05]
	Learning Rate: 7.8343e-05
	LOSS [training: 0.33746308207294917 | validation: 0.6549750721499089]
	TIME [epoch: 9.71 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059760535453746		[learning rate: 7.8059e-05]
	Learning Rate: 7.80586e-05
	LOSS [training: 0.3059760535453746 | validation: 0.6777376285145763]
	TIME [epoch: 9.7 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31862246779733255		[learning rate: 7.7775e-05]
	Learning Rate: 7.77754e-05
	LOSS [training: 0.31862246779733255 | validation: 0.6489196756874287]
	TIME [epoch: 9.7 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.305127881589031		[learning rate: 7.7493e-05]
	Learning Rate: 7.74931e-05
	LOSS [training: 0.305127881589031 | validation: 0.5994941882923231]
	TIME [epoch: 9.71 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3113099256343249		[learning rate: 7.7212e-05]
	Learning Rate: 7.72119e-05
	LOSS [training: 0.3113099256343249 | validation: 0.6059671599961404]
	TIME [epoch: 9.71 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3147260851729382		[learning rate: 7.6932e-05]
	Learning Rate: 7.69317e-05
	LOSS [training: 0.3147260851729382 | validation: 0.5816280619577981]
	TIME [epoch: 9.71 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3103628776911175		[learning rate: 7.6653e-05]
	Learning Rate: 7.66525e-05
	LOSS [training: 0.3103628776911175 | validation: 0.6366845540864894]
	TIME [epoch: 9.72 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31056106165911024		[learning rate: 7.6374e-05]
	Learning Rate: 7.63743e-05
	LOSS [training: 0.31056106165911024 | validation: 0.6383784245636199]
	TIME [epoch: 9.7 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.332763017979193		[learning rate: 7.6097e-05]
	Learning Rate: 7.60972e-05
	LOSS [training: 0.332763017979193 | validation: 0.621130671341695]
	TIME [epoch: 9.71 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.314298691497768		[learning rate: 7.5821e-05]
	Learning Rate: 7.5821e-05
	LOSS [training: 0.314298691497768 | validation: 0.6026862586135517]
	TIME [epoch: 9.7 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3011137708952466		[learning rate: 7.5546e-05]
	Learning Rate: 7.55458e-05
	LOSS [training: 0.3011137708952466 | validation: 0.6355250652660266]
	TIME [epoch: 9.72 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32076545120473776		[learning rate: 7.5272e-05]
	Learning Rate: 7.52717e-05
	LOSS [training: 0.32076545120473776 | validation: 0.6097230076281048]
	TIME [epoch: 9.7 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3196273247786802		[learning rate: 7.4999e-05]
	Learning Rate: 7.49985e-05
	LOSS [training: 0.3196273247786802 | validation: 0.5722357940667999]
	TIME [epoch: 9.71 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31446035280200757		[learning rate: 7.4726e-05]
	Learning Rate: 7.47263e-05
	LOSS [training: 0.31446035280200757 | validation: 0.5977306741971442]
	TIME [epoch: 9.73 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3138179864131121		[learning rate: 7.4455e-05]
	Learning Rate: 7.44552e-05
	LOSS [training: 0.3138179864131121 | validation: 0.6435407420919291]
	TIME [epoch: 9.71 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31901550645688437		[learning rate: 7.4185e-05]
	Learning Rate: 7.4185e-05
	LOSS [training: 0.31901550645688437 | validation: 0.5691669155103882]
	TIME [epoch: 9.7 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30871201341919335		[learning rate: 7.3916e-05]
	Learning Rate: 7.39157e-05
	LOSS [training: 0.30871201341919335 | validation: 0.618268434466105]
	TIME [epoch: 9.71 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3181105400944932		[learning rate: 7.3647e-05]
	Learning Rate: 7.36475e-05
	LOSS [training: 0.3181105400944932 | validation: 0.6001805365055186]
	TIME [epoch: 9.71 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3374179700055185		[learning rate: 7.338e-05]
	Learning Rate: 7.33802e-05
	LOSS [training: 0.3374179700055185 | validation: 0.6443276098783929]
	TIME [epoch: 9.71 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3827061698511509		[learning rate: 7.3114e-05]
	Learning Rate: 7.31139e-05
	LOSS [training: 0.3827061698511509 | validation: 0.601215380004359]
	TIME [epoch: 9.71 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3192798020186888		[learning rate: 7.2849e-05]
	Learning Rate: 7.28486e-05
	LOSS [training: 0.3192798020186888 | validation: 0.5952194158434994]
	TIME [epoch: 9.73 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.325685432102442		[learning rate: 7.2584e-05]
	Learning Rate: 7.25842e-05
	LOSS [training: 0.325685432102442 | validation: 0.6623286749123543]
	TIME [epoch: 9.7 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32036649609286283		[learning rate: 7.2321e-05]
	Learning Rate: 7.23208e-05
	LOSS [training: 0.32036649609286283 | validation: 0.6188013444392405]
	TIME [epoch: 9.7 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3200881391306486		[learning rate: 7.2058e-05]
	Learning Rate: 7.20583e-05
	LOSS [training: 0.3200881391306486 | validation: 0.5888573790271595]
	TIME [epoch: 9.71 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32311654859926414		[learning rate: 7.1797e-05]
	Learning Rate: 7.17968e-05
	LOSS [training: 0.32311654859926414 | validation: 0.6019184612371992]
	TIME [epoch: 9.7 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30045802741735983		[learning rate: 7.1536e-05]
	Learning Rate: 7.15363e-05
	LOSS [training: 0.30045802741735983 | validation: 0.6081850001612695]
	TIME [epoch: 9.71 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30666441445814846		[learning rate: 7.1277e-05]
	Learning Rate: 7.12767e-05
	LOSS [training: 0.30666441445814846 | validation: 0.6238303467532802]
	TIME [epoch: 9.7 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33416115941828484		[learning rate: 7.1018e-05]
	Learning Rate: 7.1018e-05
	LOSS [training: 0.33416115941828484 | validation: 0.6256747545556565]
	TIME [epoch: 9.71 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31775369108114365		[learning rate: 7.076e-05]
	Learning Rate: 7.07603e-05
	LOSS [training: 0.31775369108114365 | validation: 0.5907527332668107]
	TIME [epoch: 9.69 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3062569828777119		[learning rate: 7.0503e-05]
	Learning Rate: 7.05035e-05
	LOSS [training: 0.3062569828777119 | validation: 0.6474037775964265]
	TIME [epoch: 9.7 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32948313416501185		[learning rate: 7.0248e-05]
	Learning Rate: 7.02476e-05
	LOSS [training: 0.32948313416501185 | validation: 0.6865130928010763]
	TIME [epoch: 9.72 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32563481416701484		[learning rate: 6.9993e-05]
	Learning Rate: 6.99927e-05
	LOSS [training: 0.32563481416701484 | validation: 0.6698400436851095]
	TIME [epoch: 9.71 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3192537095870993		[learning rate: 6.9739e-05]
	Learning Rate: 6.97387e-05
	LOSS [training: 0.3192537095870993 | validation: 0.5911168218857352]
	TIME [epoch: 9.7 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29680771701855135		[learning rate: 6.9486e-05]
	Learning Rate: 6.94856e-05
	LOSS [training: 0.29680771701855135 | validation: 0.6042957808997872]
	TIME [epoch: 9.7 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3105439158195896		[learning rate: 6.9233e-05]
	Learning Rate: 6.92334e-05
	LOSS [training: 0.3105439158195896 | validation: 0.6445399214460734]
	TIME [epoch: 9.71 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3058947266970238		[learning rate: 6.8982e-05]
	Learning Rate: 6.89822e-05
	LOSS [training: 0.3058947266970238 | validation: 0.5994286273478098]
	TIME [epoch: 9.71 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33336865866040866		[learning rate: 6.8732e-05]
	Learning Rate: 6.87318e-05
	LOSS [training: 0.33336865866040866 | validation: 0.6016028136551208]
	TIME [epoch: 9.71 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32264396105018106		[learning rate: 6.8482e-05]
	Learning Rate: 6.84824e-05
	LOSS [training: 0.32264396105018106 | validation: 0.5863892498551627]
	TIME [epoch: 9.73 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32224154817669726		[learning rate: 6.8234e-05]
	Learning Rate: 6.82339e-05
	LOSS [training: 0.32224154817669726 | validation: 0.620523910646999]
	TIME [epoch: 9.71 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31434174874804094		[learning rate: 6.7986e-05]
	Learning Rate: 6.79862e-05
	LOSS [training: 0.31434174874804094 | validation: 0.5701541978739408]
	TIME [epoch: 9.71 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3086626735781116		[learning rate: 6.774e-05]
	Learning Rate: 6.77395e-05
	LOSS [training: 0.3086626735781116 | validation: 0.6199661965431323]
	TIME [epoch: 9.72 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3096075826738459		[learning rate: 6.7494e-05]
	Learning Rate: 6.74937e-05
	LOSS [training: 0.3096075826738459 | validation: 0.6571496409747195]
	TIME [epoch: 9.7 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3102383493693381		[learning rate: 6.7249e-05]
	Learning Rate: 6.72488e-05
	LOSS [training: 0.3102383493693381 | validation: 0.6222990931793799]
	TIME [epoch: 9.71 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2958383735665947		[learning rate: 6.7005e-05]
	Learning Rate: 6.70047e-05
	LOSS [training: 0.2958383735665947 | validation: 0.5926622251598714]
	TIME [epoch: 9.71 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077872239592269		[learning rate: 6.6762e-05]
	Learning Rate: 6.67616e-05
	LOSS [training: 0.3077872239592269 | validation: 0.6311476518272656]
	TIME [epoch: 9.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3203591283599111		[learning rate: 6.6519e-05]
	Learning Rate: 6.65192e-05
	LOSS [training: 0.3203591283599111 | validation: 0.6006114853618055]
	TIME [epoch: 9.71 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3219527398688241		[learning rate: 6.6278e-05]
	Learning Rate: 6.62778e-05
	LOSS [training: 0.3219527398688241 | validation: 0.6556854852305365]
	TIME [epoch: 9.69 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31011462832275627		[learning rate: 6.6037e-05]
	Learning Rate: 6.60373e-05
	LOSS [training: 0.31011462832275627 | validation: 0.6159253061694894]
	TIME [epoch: 9.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32466408120333		[learning rate: 6.5798e-05]
	Learning Rate: 6.57977e-05
	LOSS [training: 0.32466408120333 | validation: 0.5423617815683018]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1482.pth
	Model improved!!!
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31639573118371855		[learning rate: 6.5559e-05]
	Learning Rate: 6.55589e-05
	LOSS [training: 0.31639573118371855 | validation: 0.6303530151859615]
	TIME [epoch: 9.72 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31187165978842757		[learning rate: 6.5321e-05]
	Learning Rate: 6.5321e-05
	LOSS [training: 0.31187165978842757 | validation: 0.6370681668085767]
	TIME [epoch: 9.73 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30296589886774916		[learning rate: 6.5084e-05]
	Learning Rate: 6.50839e-05
	LOSS [training: 0.30296589886774916 | validation: 0.5981633238942194]
	TIME [epoch: 9.71 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32035830215229744		[learning rate: 6.4848e-05]
	Learning Rate: 6.48477e-05
	LOSS [training: 0.32035830215229744 | validation: 0.564969441154363]
	TIME [epoch: 9.69 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31239828928234437		[learning rate: 6.4612e-05]
	Learning Rate: 6.46124e-05
	LOSS [training: 0.31239828928234437 | validation: 0.6273269837298809]
	TIME [epoch: 9.7 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31432749811470123		[learning rate: 6.4378e-05]
	Learning Rate: 6.43779e-05
	LOSS [training: 0.31432749811470123 | validation: 0.5892261803406019]
	TIME [epoch: 9.71 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3033038493424994		[learning rate: 6.4144e-05]
	Learning Rate: 6.41443e-05
	LOSS [training: 0.3033038493424994 | validation: 0.5749406434681418]
	TIME [epoch: 9.69 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30604737420915795		[learning rate: 6.3911e-05]
	Learning Rate: 6.39115e-05
	LOSS [training: 0.30604737420915795 | validation: 0.5891658291438465]
	TIME [epoch: 9.71 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3074215014824638		[learning rate: 6.368e-05]
	Learning Rate: 6.36795e-05
	LOSS [training: 0.3074215014824638 | validation: 0.5565054759407666]
	TIME [epoch: 9.72 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3083007676359416		[learning rate: 6.3448e-05]
	Learning Rate: 6.34485e-05
	LOSS [training: 0.3083007676359416 | validation: 0.6254015514262138]
	TIME [epoch: 9.7 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3295486286355414		[learning rate: 6.3218e-05]
	Learning Rate: 6.32182e-05
	LOSS [training: 0.3295486286355414 | validation: 0.6053162812877859]
	TIME [epoch: 9.7 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32159057521285284		[learning rate: 6.2989e-05]
	Learning Rate: 6.29888e-05
	LOSS [training: 0.32159057521285284 | validation: 0.5985298200465747]
	TIME [epoch: 9.71 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31900696048240207		[learning rate: 6.276e-05]
	Learning Rate: 6.27602e-05
	LOSS [training: 0.31900696048240207 | validation: 0.6156717714725196]
	TIME [epoch: 9.71 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33176578488790065		[learning rate: 6.2532e-05]
	Learning Rate: 6.25324e-05
	LOSS [training: 0.33176578488790065 | validation: 0.6026329329036794]
	TIME [epoch: 9.7 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33198176377601313		[learning rate: 6.2305e-05]
	Learning Rate: 6.23055e-05
	LOSS [training: 0.33198176377601313 | validation: 0.596932243482817]
	TIME [epoch: 9.69 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31958210297461276		[learning rate: 6.2079e-05]
	Learning Rate: 6.20794e-05
	LOSS [training: 0.31958210297461276 | validation: 0.5491888260905692]
	TIME [epoch: 9.71 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3008758723940805		[learning rate: 6.1854e-05]
	Learning Rate: 6.18541e-05
	LOSS [training: 0.3008758723940805 | validation: 0.6049112341160269]
	TIME [epoch: 9.71 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31250519555994016		[learning rate: 6.163e-05]
	Learning Rate: 6.16296e-05
	LOSS [training: 0.31250519555994016 | validation: 0.6635677723939064]
	TIME [epoch: 9.71 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3104046190558032		[learning rate: 6.1406e-05]
	Learning Rate: 6.1406e-05
	LOSS [training: 0.3104046190558032 | validation: 0.5752222008029595]
	TIME [epoch: 9.7 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3169894563782861		[learning rate: 6.1183e-05]
	Learning Rate: 6.11831e-05
	LOSS [training: 0.3169894563782861 | validation: 0.6270385456587342]
	TIME [epoch: 9.71 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30071344732415717		[learning rate: 6.0961e-05]
	Learning Rate: 6.09611e-05
	LOSS [training: 0.30071344732415717 | validation: 0.6005495110792315]
	TIME [epoch: 9.71 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30106017854485917		[learning rate: 6.074e-05]
	Learning Rate: 6.07399e-05
	LOSS [training: 0.30106017854485917 | validation: 0.5898918600251526]
	TIME [epoch: 9.7 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33007607798401833		[learning rate: 6.0519e-05]
	Learning Rate: 6.05194e-05
	LOSS [training: 0.33007607798401833 | validation: 0.6541369517531297]
	TIME [epoch: 9.72 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.317703448734015		[learning rate: 6.03e-05]
	Learning Rate: 6.02998e-05
	LOSS [training: 0.317703448734015 | validation: 0.570824303105032]
	TIME [epoch: 9.7 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31011554881139103		[learning rate: 6.0081e-05]
	Learning Rate: 6.0081e-05
	LOSS [training: 0.31011554881139103 | validation: 0.6104890901651376]
	TIME [epoch: 9.71 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32135062795774366		[learning rate: 5.9863e-05]
	Learning Rate: 5.98629e-05
	LOSS [training: 0.32135062795774366 | validation: 0.6242283455316737]
	TIME [epoch: 9.72 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2944298105256647		[learning rate: 5.9646e-05]
	Learning Rate: 5.96457e-05
	LOSS [training: 0.2944298105256647 | validation: 0.5930244055334838]
	TIME [epoch: 9.72 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.304313089041005		[learning rate: 5.9429e-05]
	Learning Rate: 5.94292e-05
	LOSS [training: 0.304313089041005 | validation: 0.5870274126928914]
	TIME [epoch: 9.71 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.310381929582695		[learning rate: 5.9214e-05]
	Learning Rate: 5.92136e-05
	LOSS [training: 0.310381929582695 | validation: 0.5887329606035289]
	TIME [epoch: 9.7 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3041963080182115		[learning rate: 5.8999e-05]
	Learning Rate: 5.89987e-05
	LOSS [training: 0.3041963080182115 | validation: 0.6035931691040718]
	TIME [epoch: 9.72 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32139637553277794		[learning rate: 5.8785e-05]
	Learning Rate: 5.87846e-05
	LOSS [training: 0.32139637553277794 | validation: 0.5572523796776437]
	TIME [epoch: 9.7 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31151938673567314		[learning rate: 5.8571e-05]
	Learning Rate: 5.85712e-05
	LOSS [training: 0.31151938673567314 | validation: 0.5993218469309662]
	TIME [epoch: 9.69 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3178973735748615		[learning rate: 5.8359e-05]
	Learning Rate: 5.83586e-05
	LOSS [training: 0.3178973735748615 | validation: 0.5642796888423935]
	TIME [epoch: 9.72 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059329883151113		[learning rate: 5.8147e-05]
	Learning Rate: 5.81469e-05
	LOSS [training: 0.3059329883151113 | validation: 0.5697268135148901]
	TIME [epoch: 9.7 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3191053192737994		[learning rate: 5.7936e-05]
	Learning Rate: 5.79358e-05
	LOSS [training: 0.3191053192737994 | validation: 0.6043025759248674]
	TIME [epoch: 9.7 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3113560620732113		[learning rate: 5.7726e-05]
	Learning Rate: 5.77256e-05
	LOSS [training: 0.3113560620732113 | validation: 0.5729789426206001]
	TIME [epoch: 9.71 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3095283262399906		[learning rate: 5.7516e-05]
	Learning Rate: 5.75161e-05
	LOSS [training: 0.3095283262399906 | validation: 0.6023913775213823]
	TIME [epoch: 9.7 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3060524119188145		[learning rate: 5.7307e-05]
	Learning Rate: 5.73074e-05
	LOSS [training: 0.3060524119188145 | validation: 0.6218693137878171]
	TIME [epoch: 9.7 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30496151661801624		[learning rate: 5.7099e-05]
	Learning Rate: 5.70994e-05
	LOSS [training: 0.30496151661801624 | validation: 0.6149088139533226]
	TIME [epoch: 9.71 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2983822264805474		[learning rate: 5.6892e-05]
	Learning Rate: 5.68922e-05
	LOSS [training: 0.2983822264805474 | validation: 0.5819006289322347]
	TIME [epoch: 9.72 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30827524403488743		[learning rate: 5.6686e-05]
	Learning Rate: 5.66857e-05
	LOSS [training: 0.30827524403488743 | validation: 0.604612929289375]
	TIME [epoch: 9.7 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3021230586154774		[learning rate: 5.648e-05]
	Learning Rate: 5.648e-05
	LOSS [training: 0.3021230586154774 | validation: 0.5632431490500315]
	TIME [epoch: 9.69 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31839865583002486		[learning rate: 5.6275e-05]
	Learning Rate: 5.6275e-05
	LOSS [training: 0.31839865583002486 | validation: 0.6346774566197215]
	TIME [epoch: 9.71 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32173342545349043		[learning rate: 5.6071e-05]
	Learning Rate: 5.60708e-05
	LOSS [training: 0.32173342545349043 | validation: 0.5340487319977675]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1526.pth
	Model improved!!!
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.311489206963677		[learning rate: 5.5867e-05]
	Learning Rate: 5.58673e-05
	LOSS [training: 0.311489206963677 | validation: 0.61066131452878]
	TIME [epoch: 9.7 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3001765353666879		[learning rate: 5.5665e-05]
	Learning Rate: 5.56646e-05
	LOSS [training: 0.3001765353666879 | validation: 0.5976791588547148]
	TIME [epoch: 9.72 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30664827862314287		[learning rate: 5.5463e-05]
	Learning Rate: 5.54626e-05
	LOSS [training: 0.30664827862314287 | validation: 0.5729169636619768]
	TIME [epoch: 9.71 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30986463636801276		[learning rate: 5.5261e-05]
	Learning Rate: 5.52613e-05
	LOSS [training: 0.30986463636801276 | validation: 0.6094529534427044]
	TIME [epoch: 9.7 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3012913485983698		[learning rate: 5.5061e-05]
	Learning Rate: 5.50608e-05
	LOSS [training: 0.3012913485983698 | validation: 0.6003238822039859]
	TIME [epoch: 9.71 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3037195143077825		[learning rate: 5.4861e-05]
	Learning Rate: 5.48609e-05
	LOSS [training: 0.3037195143077825 | validation: 0.6368543628887222]
	TIME [epoch: 9.72 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30109073506953965		[learning rate: 5.4662e-05]
	Learning Rate: 5.46618e-05
	LOSS [training: 0.30109073506953965 | validation: 0.5721055145112823]
	TIME [epoch: 9.72 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2967934497861334		[learning rate: 5.4463e-05]
	Learning Rate: 5.44635e-05
	LOSS [training: 0.2967934497861334 | validation: 0.5889664965058669]
	TIME [epoch: 9.71 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3083750345859039		[learning rate: 5.4266e-05]
	Learning Rate: 5.42658e-05
	LOSS [training: 0.3083750345859039 | validation: 0.6102287571179965]
	TIME [epoch: 9.72 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31353654614908616		[learning rate: 5.4069e-05]
	Learning Rate: 5.40689e-05
	LOSS [training: 0.31353654614908616 | validation: 0.5746150909063775]
	TIME [epoch: 9.71 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31575186287294593		[learning rate: 5.3873e-05]
	Learning Rate: 5.38727e-05
	LOSS [training: 0.31575186287294593 | validation: 0.5986456791613202]
	TIME [epoch: 9.7 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30323729511867414		[learning rate: 5.3677e-05]
	Learning Rate: 5.36772e-05
	LOSS [training: 0.30323729511867414 | validation: 0.586946581057194]
	TIME [epoch: 9.71 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3071875704960736		[learning rate: 5.3482e-05]
	Learning Rate: 5.34824e-05
	LOSS [training: 0.3071875704960736 | validation: 0.5867851862278921]
	TIME [epoch: 9.74 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.300708419930191		[learning rate: 5.3288e-05]
	Learning Rate: 5.32883e-05
	LOSS [training: 0.300708419930191 | validation: 0.5868055087173323]
	TIME [epoch: 9.71 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3237444594715605		[learning rate: 5.3095e-05]
	Learning Rate: 5.30949e-05
	LOSS [training: 0.3237444594715605 | validation: 0.5618145611818798]
	TIME [epoch: 9.72 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2974594560673937		[learning rate: 5.2902e-05]
	Learning Rate: 5.29022e-05
	LOSS [training: 0.2974594560673937 | validation: 0.5870465641008672]
	TIME [epoch: 9.72 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.291358938012747		[learning rate: 5.271e-05]
	Learning Rate: 5.27102e-05
	LOSS [training: 0.291358938012747 | validation: 0.5946539513577239]
	TIME [epoch: 9.7 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29683416933029394		[learning rate: 5.2519e-05]
	Learning Rate: 5.25189e-05
	LOSS [training: 0.29683416933029394 | validation: 0.6136827110581077]
	TIME [epoch: 9.72 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30301562101162177		[learning rate: 5.2328e-05]
	Learning Rate: 5.23283e-05
	LOSS [training: 0.30301562101162177 | validation: 0.6057474251775464]
	TIME [epoch: 9.71 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31024693240658613		[learning rate: 5.2138e-05]
	Learning Rate: 5.21384e-05
	LOSS [training: 0.31024693240658613 | validation: 0.6171463906646818]
	TIME [epoch: 9.72 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29325102935880515		[learning rate: 5.1949e-05]
	Learning Rate: 5.19492e-05
	LOSS [training: 0.29325102935880515 | validation: 0.6286827079582887]
	TIME [epoch: 9.7 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3186314771905824		[learning rate: 5.1761e-05]
	Learning Rate: 5.17607e-05
	LOSS [training: 0.3186314771905824 | validation: 0.6175364991129064]
	TIME [epoch: 9.7 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31850484965339965		[learning rate: 5.1573e-05]
	Learning Rate: 5.15729e-05
	LOSS [training: 0.31850484965339965 | validation: 0.6303279229763133]
	TIME [epoch: 9.72 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31686576092887686		[learning rate: 5.1386e-05]
	Learning Rate: 5.13857e-05
	LOSS [training: 0.31686576092887686 | validation: 0.630056512852919]
	TIME [epoch: 9.71 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3078688667466448		[learning rate: 5.1199e-05]
	Learning Rate: 5.11992e-05
	LOSS [training: 0.3078688667466448 | validation: 0.6107154852174256]
	TIME [epoch: 9.71 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3063879844880694		[learning rate: 5.1013e-05]
	Learning Rate: 5.10134e-05
	LOSS [training: 0.3063879844880694 | validation: 0.5724805564740921]
	TIME [epoch: 9.72 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2948884655237687		[learning rate: 5.0828e-05]
	Learning Rate: 5.08283e-05
	LOSS [training: 0.2948884655237687 | validation: 0.5701582013956593]
	TIME [epoch: 9.71 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3020162100710907		[learning rate: 5.0644e-05]
	Learning Rate: 5.06438e-05
	LOSS [training: 0.3020162100710907 | validation: 0.5797720627416417]
	TIME [epoch: 9.7 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3069897003512344		[learning rate: 5.046e-05]
	Learning Rate: 5.046e-05
	LOSS [training: 0.3069897003512344 | validation: 0.5726315301598753]
	TIME [epoch: 9.71 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3207612790647799		[learning rate: 5.0277e-05]
	Learning Rate: 5.02769e-05
	LOSS [training: 0.3207612790647799 | validation: 0.6091006528039694]
	TIME [epoch: 9.71 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31815819674584983		[learning rate: 5.0094e-05]
	Learning Rate: 5.00944e-05
	LOSS [training: 0.31815819674584983 | validation: 0.6053125616022588]
	TIME [epoch: 9.7 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3076100734164112		[learning rate: 4.9913e-05]
	Learning Rate: 4.99127e-05
	LOSS [training: 0.3076100734164112 | validation: 0.6071914716407041]
	TIME [epoch: 9.71 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3058684113380551		[learning rate: 4.9732e-05]
	Learning Rate: 4.97315e-05
	LOSS [training: 0.3058684113380551 | validation: 0.5852099489948506]
	TIME [epoch: 9.72 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3031354038890206		[learning rate: 4.9551e-05]
	Learning Rate: 4.9551e-05
	LOSS [training: 0.3031354038890206 | validation: 0.6302834895007584]
	TIME [epoch: 9.7 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2898598010300203		[learning rate: 4.9371e-05]
	Learning Rate: 4.93712e-05
	LOSS [training: 0.2898598010300203 | validation: 0.6375886998816436]
	TIME [epoch: 9.71 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3026208391187491		[learning rate: 4.9192e-05]
	Learning Rate: 4.9192e-05
	LOSS [training: 0.3026208391187491 | validation: 0.6185026103818655]
	TIME [epoch: 9.69 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3018563027753543		[learning rate: 4.9014e-05]
	Learning Rate: 4.90135e-05
	LOSS [training: 0.3018563027753543 | validation: 0.639624495426668]
	TIME [epoch: 9.71 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31840325332292607		[learning rate: 4.8836e-05]
	Learning Rate: 4.88356e-05
	LOSS [training: 0.31840325332292607 | validation: 0.5647945934788604]
	TIME [epoch: 9.7 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30705835245653035		[learning rate: 4.8658e-05]
	Learning Rate: 4.86584e-05
	LOSS [training: 0.30705835245653035 | validation: 0.621033975003122]
	TIME [epoch: 9.71 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30537516710972873		[learning rate: 4.8482e-05]
	Learning Rate: 4.84818e-05
	LOSS [training: 0.30537516710972873 | validation: 0.6041922065960024]
	TIME [epoch: 9.72 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3064242719688479		[learning rate: 4.8306e-05]
	Learning Rate: 4.83059e-05
	LOSS [training: 0.3064242719688479 | validation: 0.598881234047978]
	TIME [epoch: 9.71 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3202024272627701		[learning rate: 4.8131e-05]
	Learning Rate: 4.81306e-05
	LOSS [training: 0.3202024272627701 | validation: 0.5669882215570883]
	TIME [epoch: 9.7 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30688790570832924		[learning rate: 4.7956e-05]
	Learning Rate: 4.79559e-05
	LOSS [training: 0.30688790570832924 | validation: 0.596890618872996]
	TIME [epoch: 9.72 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30115281520631376		[learning rate: 4.7782e-05]
	Learning Rate: 4.77819e-05
	LOSS [training: 0.30115281520631376 | validation: 0.6116061746171829]
	TIME [epoch: 9.7 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3037463369992282		[learning rate: 4.7608e-05]
	Learning Rate: 4.76085e-05
	LOSS [training: 0.3037463369992282 | validation: 0.6142474983340189]
	TIME [epoch: 9.71 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3035227510641107		[learning rate: 4.7436e-05]
	Learning Rate: 4.74357e-05
	LOSS [training: 0.3035227510641107 | validation: 0.6317964372094548]
	TIME [epoch: 9.71 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3075323997178845		[learning rate: 4.7264e-05]
	Learning Rate: 4.72636e-05
	LOSS [training: 0.3075323997178845 | validation: 0.650695818467468]
	TIME [epoch: 9.72 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.306405673151849		[learning rate: 4.7092e-05]
	Learning Rate: 4.7092e-05
	LOSS [training: 0.306405673151849 | validation: 0.5618446407299029]
	TIME [epoch: 9.71 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.301082175923312		[learning rate: 4.6921e-05]
	Learning Rate: 4.69211e-05
	LOSS [training: 0.301082175923312 | validation: 0.561668258638139]
	TIME [epoch: 9.7 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308099969696158		[learning rate: 4.6751e-05]
	Learning Rate: 4.67508e-05
	LOSS [training: 0.308099969696158 | validation: 0.5704241169655814]
	TIME [epoch: 9.72 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.306517573315063		[learning rate: 4.6581e-05]
	Learning Rate: 4.65812e-05
	LOSS [training: 0.306517573315063 | validation: 0.6370487659215738]
	TIME [epoch: 9.7 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2978774377800703		[learning rate: 4.6412e-05]
	Learning Rate: 4.64121e-05
	LOSS [training: 0.2978774377800703 | validation: 0.6000092926058072]
	TIME [epoch: 9.71 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3008069923266471		[learning rate: 4.6244e-05]
	Learning Rate: 4.62437e-05
	LOSS [training: 0.3008069923266471 | validation: 0.5845556545286599]
	TIME [epoch: 9.71 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3033140152720592		[learning rate: 4.6076e-05]
	Learning Rate: 4.60759e-05
	LOSS [training: 0.3033140152720592 | validation: 0.5805552632550129]
	TIME [epoch: 9.72 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29658114211005426		[learning rate: 4.5909e-05]
	Learning Rate: 4.59087e-05
	LOSS [training: 0.29658114211005426 | validation: 0.6135209529682549]
	TIME [epoch: 9.7 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29128702671666085		[learning rate: 4.5742e-05]
	Learning Rate: 4.57421e-05
	LOSS [training: 0.29128702671666085 | validation: 0.5590050375744402]
	TIME [epoch: 9.7 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30683019945337575		[learning rate: 4.5576e-05]
	Learning Rate: 4.55761e-05
	LOSS [training: 0.30683019945337575 | validation: 0.5838731240765855]
	TIME [epoch: 9.71 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3249874014981436		[learning rate: 4.5411e-05]
	Learning Rate: 4.54107e-05
	LOSS [training: 0.3249874014981436 | validation: 0.5613133186296415]
	TIME [epoch: 9.69 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3002094565160708		[learning rate: 4.5246e-05]
	Learning Rate: 4.52459e-05
	LOSS [training: 0.3002094565160708 | validation: 0.6270288427831927]
	TIME [epoch: 9.7 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.305619085479071		[learning rate: 4.5082e-05]
	Learning Rate: 4.50817e-05
	LOSS [training: 0.305619085479071 | validation: 0.6137571202173289]
	TIME [epoch: 9.71 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.295672520489929		[learning rate: 4.4918e-05]
	Learning Rate: 4.49181e-05
	LOSS [training: 0.295672520489929 | validation: 0.601140922578756]
	TIME [epoch: 9.71 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30282325352936634		[learning rate: 4.4755e-05]
	Learning Rate: 4.47551e-05
	LOSS [training: 0.30282325352936634 | validation: 0.616381148973535]
	TIME [epoch: 9.7 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32540294139733045		[learning rate: 4.4593e-05]
	Learning Rate: 4.45926e-05
	LOSS [training: 0.32540294139733045 | validation: 0.5920618889938764]
	TIME [epoch: 9.71 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3049075936956761		[learning rate: 4.4431e-05]
	Learning Rate: 4.44308e-05
	LOSS [training: 0.3049075936956761 | validation: 0.5641185726373671]
	TIME [epoch: 9.72 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29846897279981055		[learning rate: 4.427e-05]
	Learning Rate: 4.42696e-05
	LOSS [training: 0.29846897279981055 | validation: 0.6102614512994095]
	TIME [epoch: 9.7 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3062028062449106		[learning rate: 4.4109e-05]
	Learning Rate: 4.41089e-05
	LOSS [training: 0.3062028062449106 | validation: 0.6015597258377213]
	TIME [epoch: 9.71 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29610486043575346		[learning rate: 4.3949e-05]
	Learning Rate: 4.39489e-05
	LOSS [training: 0.29610486043575346 | validation: 0.5944896718934487]
	TIME [epoch: 9.72 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3069909012015735		[learning rate: 4.3789e-05]
	Learning Rate: 4.37893e-05
	LOSS [training: 0.3069909012015735 | validation: 0.6531062627881268]
	TIME [epoch: 9.7 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31107697443701554		[learning rate: 4.363e-05]
	Learning Rate: 4.36304e-05
	LOSS [training: 0.31107697443701554 | validation: 0.5928420634075844]
	TIME [epoch: 9.72 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30569247066534433		[learning rate: 4.3472e-05]
	Learning Rate: 4.34721e-05
	LOSS [training: 0.30569247066534433 | validation: 0.6235983337940905]
	TIME [epoch: 9.7 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30756202987010145		[learning rate: 4.3314e-05]
	Learning Rate: 4.33143e-05
	LOSS [training: 0.30756202987010145 | validation: 0.5806111548649374]
	TIME [epoch: 9.72 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31893958769466274		[learning rate: 4.3157e-05]
	Learning Rate: 4.31571e-05
	LOSS [training: 0.31893958769466274 | validation: 0.6111489898400402]
	TIME [epoch: 9.71 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30313743691452955		[learning rate: 4.3001e-05]
	Learning Rate: 4.30005e-05
	LOSS [training: 0.30313743691452955 | validation: 0.5794359517229092]
	TIME [epoch: 9.71 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.315304237731319		[learning rate: 4.2844e-05]
	Learning Rate: 4.28445e-05
	LOSS [training: 0.315304237731319 | validation: 0.5840764776594725]
	TIME [epoch: 9.73 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31132676901680145		[learning rate: 4.2689e-05]
	Learning Rate: 4.2689e-05
	LOSS [training: 0.31132676901680145 | validation: 0.5511240583183418]
	TIME [epoch: 9.71 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30789931219168665		[learning rate: 4.2534e-05]
	Learning Rate: 4.25341e-05
	LOSS [training: 0.30789931219168665 | validation: 0.6066373421770916]
	TIME [epoch: 9.71 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30901133422385785		[learning rate: 4.238e-05]
	Learning Rate: 4.23797e-05
	LOSS [training: 0.30901133422385785 | validation: 0.6085365287996153]
	TIME [epoch: 9.72 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31072645983613606		[learning rate: 4.2226e-05]
	Learning Rate: 4.22259e-05
	LOSS [training: 0.31072645983613606 | validation: 0.5777594721623913]
	TIME [epoch: 9.72 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30099872464309285		[learning rate: 4.2073e-05]
	Learning Rate: 4.20727e-05
	LOSS [training: 0.30099872464309285 | validation: 0.6044310535494725]
	TIME [epoch: 9.71 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30254786581525395		[learning rate: 4.192e-05]
	Learning Rate: 4.192e-05
	LOSS [training: 0.30254786581525395 | validation: 0.5872416010902053]
	TIME [epoch: 9.72 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3162466488690178		[learning rate: 4.1768e-05]
	Learning Rate: 4.17679e-05
	LOSS [training: 0.3162466488690178 | validation: 0.6395453963548923]
	TIME [epoch: 9.72 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.309166455951996		[learning rate: 4.1616e-05]
	Learning Rate: 4.16163e-05
	LOSS [training: 0.309166455951996 | validation: 0.6203324878982227]
	TIME [epoch: 9.71 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3085349599959457		[learning rate: 4.1465e-05]
	Learning Rate: 4.14652e-05
	LOSS [training: 0.3085349599959457 | validation: 0.5963940529069103]
	TIME [epoch: 9.72 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30874177238504374		[learning rate: 4.1315e-05]
	Learning Rate: 4.13148e-05
	LOSS [training: 0.30874177238504374 | validation: 0.6144231407718155]
	TIME [epoch: 9.72 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3061891055943271		[learning rate: 4.1165e-05]
	Learning Rate: 4.11648e-05
	LOSS [training: 0.3061891055943271 | validation: 0.5858096277978767]
	TIME [epoch: 9.72 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.295501687127982		[learning rate: 4.1015e-05]
	Learning Rate: 4.10154e-05
	LOSS [training: 0.295501687127982 | validation: 0.6149682767896206]
	TIME [epoch: 9.71 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3073123898230682		[learning rate: 4.0867e-05]
	Learning Rate: 4.08666e-05
	LOSS [training: 0.3073123898230682 | validation: 0.5763799644994169]
	TIME [epoch: 9.71 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32250066063788463		[learning rate: 4.0718e-05]
	Learning Rate: 4.07183e-05
	LOSS [training: 0.32250066063788463 | validation: 0.6451488417455826]
	TIME [epoch: 9.72 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3133339431424341		[learning rate: 4.0571e-05]
	Learning Rate: 4.05705e-05
	LOSS [training: 0.3133339431424341 | validation: 0.6422271145275308]
	TIME [epoch: 9.71 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29250480275348556		[learning rate: 4.0423e-05]
	Learning Rate: 4.04233e-05
	LOSS [training: 0.29250480275348556 | validation: 0.5933472543974925]
	TIME [epoch: 9.71 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2974849915354305		[learning rate: 4.0277e-05]
	Learning Rate: 4.02766e-05
	LOSS [training: 0.2974849915354305 | validation: 0.6332921634501453]
	TIME [epoch: 9.74 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2998797673704753		[learning rate: 4.013e-05]
	Learning Rate: 4.01304e-05
	LOSS [training: 0.2998797673704753 | validation: 0.6065516301023609]
	TIME [epoch: 9.71 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3029123465641383		[learning rate: 3.9985e-05]
	Learning Rate: 3.99848e-05
	LOSS [training: 0.3029123465641383 | validation: 0.6018408961147336]
	TIME [epoch: 9.71 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31662673541383013		[learning rate: 3.984e-05]
	Learning Rate: 3.98397e-05
	LOSS [training: 0.31662673541383013 | validation: 0.6020410564485946]
	TIME [epoch: 9.71 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3034464243994139		[learning rate: 3.9695e-05]
	Learning Rate: 3.96951e-05
	LOSS [training: 0.3034464243994139 | validation: 0.5648950022399857]
	TIME [epoch: 9.71 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30436239447893654		[learning rate: 3.9551e-05]
	Learning Rate: 3.9551e-05
	LOSS [training: 0.30436239447893654 | validation: 0.5968935227912584]
	TIME [epoch: 9.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3236787660457281		[learning rate: 3.9408e-05]
	Learning Rate: 3.94075e-05
	LOSS [training: 0.3236787660457281 | validation: 0.6229535237968803]
	TIME [epoch: 9.72 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32315366660703526		[learning rate: 3.9264e-05]
	Learning Rate: 3.92645e-05
	LOSS [training: 0.32315366660703526 | validation: 0.5843542934356962]
	TIME [epoch: 9.71 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3012101539446292		[learning rate: 3.9122e-05]
	Learning Rate: 3.9122e-05
	LOSS [training: 0.3012101539446292 | validation: 0.6193678137693397]
	TIME [epoch: 9.7 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3037752085048791		[learning rate: 3.898e-05]
	Learning Rate: 3.898e-05
	LOSS [training: 0.3037752085048791 | validation: 0.6117629390436694]
	TIME [epoch: 9.7 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29263817801367004		[learning rate: 3.8839e-05]
	Learning Rate: 3.88386e-05
	LOSS [training: 0.29263817801367004 | validation: 0.6000067618451581]
	TIME [epoch: 9.73 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31310251409125284		[learning rate: 3.8698e-05]
	Learning Rate: 3.86976e-05
	LOSS [training: 0.31310251409125284 | validation: 0.5700402825807744]
	TIME [epoch: 9.71 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2894809101403712		[learning rate: 3.8557e-05]
	Learning Rate: 3.85572e-05
	LOSS [training: 0.2894809101403712 | validation: 0.6324865477641134]
	TIME [epoch: 9.7 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2977541931638766		[learning rate: 3.8417e-05]
	Learning Rate: 3.84173e-05
	LOSS [training: 0.2977541931638766 | validation: 0.6554525137566108]
	TIME [epoch: 9.74 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2957359833986882		[learning rate: 3.8278e-05]
	Learning Rate: 3.82778e-05
	LOSS [training: 0.2957359833986882 | validation: 0.6048571436153525]
	TIME [epoch: 9.72 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3016497729666223		[learning rate: 3.8139e-05]
	Learning Rate: 3.81389e-05
	LOSS [training: 0.3016497729666223 | validation: 0.5823059782160881]
	TIME [epoch: 9.72 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3131123636245016		[learning rate: 3.8001e-05]
	Learning Rate: 3.80005e-05
	LOSS [training: 0.3131123636245016 | validation: 0.6111347308682809]
	TIME [epoch: 9.71 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3079252552314197		[learning rate: 3.7863e-05]
	Learning Rate: 3.78626e-05
	LOSS [training: 0.3079252552314197 | validation: 0.563103658453249]
	TIME [epoch: 9.72 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30679982043350945		[learning rate: 3.7725e-05]
	Learning Rate: 3.77252e-05
	LOSS [training: 0.30679982043350945 | validation: 0.6158297482720484]
	TIME [epoch: 9.72 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29121346933350056		[learning rate: 3.7588e-05]
	Learning Rate: 3.75883e-05
	LOSS [training: 0.29121346933350056 | validation: 0.575642672581388]
	TIME [epoch: 9.71 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3116622304513121		[learning rate: 3.7452e-05]
	Learning Rate: 3.74519e-05
	LOSS [training: 0.3116622304513121 | validation: 0.590173014631669]
	TIME [epoch: 9.71 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29763257932848713		[learning rate: 3.7316e-05]
	Learning Rate: 3.7316e-05
	LOSS [training: 0.29763257932848713 | validation: 0.5600185223750846]
	TIME [epoch: 9.71 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.297243259072794		[learning rate: 3.7181e-05]
	Learning Rate: 3.71805e-05
	LOSS [training: 0.297243259072794 | validation: 0.5612431051551865]
	TIME [epoch: 9.71 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2977937032876601		[learning rate: 3.7046e-05]
	Learning Rate: 3.70456e-05
	LOSS [training: 0.2977937032876601 | validation: 0.635700790316497]
	TIME [epoch: 9.7 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.282890638625214		[learning rate: 3.6911e-05]
	Learning Rate: 3.69112e-05
	LOSS [training: 0.282890638625214 | validation: 0.5507319081206279]
	TIME [epoch: 9.74 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32282044358712814		[learning rate: 3.6777e-05]
	Learning Rate: 3.67772e-05
	LOSS [training: 0.32282044358712814 | validation: 0.6813914179511781]
	TIME [epoch: 9.71 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32157443020084553		[learning rate: 3.6644e-05]
	Learning Rate: 3.66438e-05
	LOSS [training: 0.32157443020084553 | validation: 0.6016294379215592]
	TIME [epoch: 9.71 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30968827775178953		[learning rate: 3.6511e-05]
	Learning Rate: 3.65108e-05
	LOSS [training: 0.30968827775178953 | validation: 0.614643939412405]
	TIME [epoch: 9.73 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30821756891084895		[learning rate: 3.6378e-05]
	Learning Rate: 3.63783e-05
	LOSS [training: 0.30821756891084895 | validation: 0.5706317303548137]
	TIME [epoch: 9.71 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29233439665414507		[learning rate: 3.6246e-05]
	Learning Rate: 3.62463e-05
	LOSS [training: 0.29233439665414507 | validation: 0.5970328301773085]
	TIME [epoch: 9.71 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31468378991805934		[learning rate: 3.6115e-05]
	Learning Rate: 3.61147e-05
	LOSS [training: 0.31468378991805934 | validation: 0.5554391015600233]
	TIME [epoch: 9.71 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3005739442317086		[learning rate: 3.5984e-05]
	Learning Rate: 3.59837e-05
	LOSS [training: 0.3005739442317086 | validation: 0.6472904079785071]
	TIME [epoch: 9.72 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30615839760948577		[learning rate: 3.5853e-05]
	Learning Rate: 3.58531e-05
	LOSS [training: 0.30615839760948577 | validation: 0.5447943722338431]
	TIME [epoch: 9.71 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31339938060292505		[learning rate: 3.5723e-05]
	Learning Rate: 3.5723e-05
	LOSS [training: 0.31339938060292505 | validation: 0.5970459920960337]
	TIME [epoch: 9.71 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30934697495590546		[learning rate: 3.5593e-05]
	Learning Rate: 3.55933e-05
	LOSS [training: 0.30934697495590546 | validation: 0.5991439959390896]
	TIME [epoch: 9.72 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3091641920596234		[learning rate: 3.5464e-05]
	Learning Rate: 3.54641e-05
	LOSS [training: 0.3091641920596234 | validation: 0.5943692202412695]
	TIME [epoch: 9.71 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.293354532127425		[learning rate: 3.5335e-05]
	Learning Rate: 3.53354e-05
	LOSS [training: 0.293354532127425 | validation: 0.606692513599833]
	TIME [epoch: 9.7 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30166111487005903		[learning rate: 3.5207e-05]
	Learning Rate: 3.52072e-05
	LOSS [training: 0.30166111487005903 | validation: 0.5826563616887848]
	TIME [epoch: 9.71 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3015810067169573		[learning rate: 3.5079e-05]
	Learning Rate: 3.50794e-05
	LOSS [training: 0.3015810067169573 | validation: 0.630277384495412]
	TIME [epoch: 9.71 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.305895174201932		[learning rate: 3.4952e-05]
	Learning Rate: 3.49521e-05
	LOSS [training: 0.305895174201932 | validation: 0.6234051578680192]
	TIME [epoch: 9.71 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29907164936877495		[learning rate: 3.4825e-05]
	Learning Rate: 3.48253e-05
	LOSS [training: 0.29907164936877495 | validation: 0.5668422406236604]
	TIME [epoch: 9.71 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30342366818533995		[learning rate: 3.4699e-05]
	Learning Rate: 3.46989e-05
	LOSS [training: 0.30342366818533995 | validation: 0.5501322457119275]
	TIME [epoch: 9.72 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2974607848333717		[learning rate: 3.4573e-05]
	Learning Rate: 3.4573e-05
	LOSS [training: 0.2974607848333717 | validation: 0.6233579711036399]
	TIME [epoch: 9.71 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3011514846319457		[learning rate: 3.4448e-05]
	Learning Rate: 3.44475e-05
	LOSS [training: 0.3011514846319457 | validation: 0.669298585768013]
	TIME [epoch: 9.71 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059865810907036		[learning rate: 3.4323e-05]
	Learning Rate: 3.43225e-05
	LOSS [training: 0.3059865810907036 | validation: 0.6001752292338419]
	TIME [epoch: 9.72 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.302539948169606		[learning rate: 3.4198e-05]
	Learning Rate: 3.4198e-05
	LOSS [training: 0.302539948169606 | validation: 0.6303447403920831]
	TIME [epoch: 9.71 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29456931050773516		[learning rate: 3.4074e-05]
	Learning Rate: 3.40738e-05
	LOSS [training: 0.29456931050773516 | validation: 0.5492849590290906]
	TIME [epoch: 9.72 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29908560793746747		[learning rate: 3.395e-05]
	Learning Rate: 3.39502e-05
	LOSS [training: 0.29908560793746747 | validation: 0.5882116966090211]
	TIME [epoch: 9.72 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3031577701693899		[learning rate: 3.3827e-05]
	Learning Rate: 3.3827e-05
	LOSS [training: 0.3031577701693899 | validation: 0.6402675203279381]
	TIME [epoch: 9.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308415638106478		[learning rate: 3.3704e-05]
	Learning Rate: 3.37042e-05
	LOSS [training: 0.308415638106478 | validation: 0.5603973551332451]
	TIME [epoch: 9.72 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31287340558507915		[learning rate: 3.3582e-05]
	Learning Rate: 3.35819e-05
	LOSS [training: 0.31287340558507915 | validation: 0.6254250010750295]
	TIME [epoch: 9.72 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31837645670959563		[learning rate: 3.346e-05]
	Learning Rate: 3.346e-05
	LOSS [training: 0.31837645670959563 | validation: 0.6283428651276273]
	TIME [epoch: 9.72 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077183196750163		[learning rate: 3.3339e-05]
	Learning Rate: 3.33386e-05
	LOSS [training: 0.3077183196750163 | validation: 0.6015571455541234]
	TIME [epoch: 9.7 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2920261779571039		[learning rate: 3.3218e-05]
	Learning Rate: 3.32176e-05
	LOSS [training: 0.2920261779571039 | validation: 0.6101542666592981]
	TIME [epoch: 9.71 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3049333449247357		[learning rate: 3.3097e-05]
	Learning Rate: 3.30971e-05
	LOSS [training: 0.3049333449247357 | validation: 0.6499391378095742]
	TIME [epoch: 9.72 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30985312844747515		[learning rate: 3.2977e-05]
	Learning Rate: 3.2977e-05
	LOSS [training: 0.30985312844747515 | validation: 0.6443517535841456]
	TIME [epoch: 9.71 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3234775046844804		[learning rate: 3.2857e-05]
	Learning Rate: 3.28573e-05
	LOSS [training: 0.3234775046844804 | validation: 0.5868592233382098]
	TIME [epoch: 9.7 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3072219138633285		[learning rate: 3.2738e-05]
	Learning Rate: 3.2738e-05
	LOSS [training: 0.3072219138633285 | validation: 0.6647490667033847]
	TIME [epoch: 9.71 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3032240288662518		[learning rate: 3.2619e-05]
	Learning Rate: 3.26192e-05
	LOSS [training: 0.3032240288662518 | validation: 0.6644126966929587]
	TIME [epoch: 9.74 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31559138555575844		[learning rate: 3.2501e-05]
	Learning Rate: 3.25009e-05
	LOSS [training: 0.31559138555575844 | validation: 0.5959921866816899]
	TIME [epoch: 9.7 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3054800743737299		[learning rate: 3.2383e-05]
	Learning Rate: 3.23829e-05
	LOSS [training: 0.3054800743737299 | validation: 0.6343474648923575]
	TIME [epoch: 9.7 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3032365723492093		[learning rate: 3.2265e-05]
	Learning Rate: 3.22654e-05
	LOSS [training: 0.3032365723492093 | validation: 0.6054378867629364]
	TIME [epoch: 9.72 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30581592681099196		[learning rate: 3.2148e-05]
	Learning Rate: 3.21483e-05
	LOSS [training: 0.30581592681099196 | validation: 0.658839413348463]
	TIME [epoch: 9.72 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.329482400800616		[learning rate: 3.2032e-05]
	Learning Rate: 3.20316e-05
	LOSS [training: 0.329482400800616 | validation: 0.6240849334595998]
	TIME [epoch: 9.71 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31943951046831864		[learning rate: 3.1915e-05]
	Learning Rate: 3.19154e-05
	LOSS [training: 0.31943951046831864 | validation: 0.6122759131628898]
	TIME [epoch: 9.7 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3250055361729462		[learning rate: 3.18e-05]
	Learning Rate: 3.17996e-05
	LOSS [training: 0.3250055361729462 | validation: 0.6092676917465252]
	TIME [epoch: 9.74 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.309686788907468		[learning rate: 3.1684e-05]
	Learning Rate: 3.16842e-05
	LOSS [training: 0.309686788907468 | validation: 0.6061132520935567]
	TIME [epoch: 9.72 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2986432936545735		[learning rate: 3.1569e-05]
	Learning Rate: 3.15692e-05
	LOSS [training: 0.2986432936545735 | validation: 0.5943218817432314]
	TIME [epoch: 9.71 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2981650644023969		[learning rate: 3.1455e-05]
	Learning Rate: 3.14546e-05
	LOSS [training: 0.2981650644023969 | validation: 0.5769227563255095]
	TIME [epoch: 9.73 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30415326413709215		[learning rate: 3.134e-05]
	Learning Rate: 3.13405e-05
	LOSS [training: 0.30415326413709215 | validation: 0.6004932507510995]
	TIME [epoch: 9.71 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30517950998373033		[learning rate: 3.1227e-05]
	Learning Rate: 3.12267e-05
	LOSS [training: 0.30517950998373033 | validation: 0.6035925925268439]
	TIME [epoch: 9.7 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2992722775369977		[learning rate: 3.1113e-05]
	Learning Rate: 3.11134e-05
	LOSS [training: 0.2992722775369977 | validation: 0.6080454258393837]
	TIME [epoch: 9.72 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29659552648529475		[learning rate: 3.1e-05]
	Learning Rate: 3.10005e-05
	LOSS [training: 0.29659552648529475 | validation: 0.5921084654811322]
	TIME [epoch: 9.71 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2964573554071665		[learning rate: 3.0888e-05]
	Learning Rate: 3.0888e-05
	LOSS [training: 0.2964573554071665 | validation: 0.6051813895495961]
	TIME [epoch: 9.71 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30875698883304226		[learning rate: 3.0776e-05]
	Learning Rate: 3.07759e-05
	LOSS [training: 0.30875698883304226 | validation: 0.6262733850783472]
	TIME [epoch: 9.71 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30970783359157944		[learning rate: 3.0664e-05]
	Learning Rate: 3.06642e-05
	LOSS [training: 0.30970783359157944 | validation: 0.604337180827133]
	TIME [epoch: 9.72 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31191123414116523		[learning rate: 3.0553e-05]
	Learning Rate: 3.05529e-05
	LOSS [training: 0.31191123414116523 | validation: 0.619071961277243]
	TIME [epoch: 9.71 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30422045925888747		[learning rate: 3.0442e-05]
	Learning Rate: 3.0442e-05
	LOSS [training: 0.30422045925888747 | validation: 0.6050837821657035]
	TIME [epoch: 9.71 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31465256757870314		[learning rate: 3.0332e-05]
	Learning Rate: 3.03316e-05
	LOSS [training: 0.31465256757870314 | validation: 0.5786925683710615]
	TIME [epoch: 9.71 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31382823670741		[learning rate: 3.0221e-05]
	Learning Rate: 3.02215e-05
	LOSS [training: 0.31382823670741 | validation: 0.5804151360201412]
	TIME [epoch: 9.72 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30501446843537855		[learning rate: 3.0112e-05]
	Learning Rate: 3.01118e-05
	LOSS [training: 0.30501446843537855 | validation: 0.5844542631280498]
	TIME [epoch: 9.71 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31790295677704117		[learning rate: 3.0003e-05]
	Learning Rate: 3.00025e-05
	LOSS [training: 0.31790295677704117 | validation: 0.6115857295844372]
	TIME [epoch: 9.72 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3141463722441683		[learning rate: 2.9894e-05]
	Learning Rate: 2.98936e-05
	LOSS [training: 0.3141463722441683 | validation: 0.6377716174743532]
	TIME [epoch: 9.74 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146256378524345		[learning rate: 2.9785e-05]
	Learning Rate: 2.97852e-05
	LOSS [training: 0.3146256378524345 | validation: 0.6431504942028694]
	TIME [epoch: 9.72 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32104180737974347		[learning rate: 2.9677e-05]
	Learning Rate: 2.96771e-05
	LOSS [training: 0.32104180737974347 | validation: 0.5724664427334188]
	TIME [epoch: 9.7 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.316612716284918		[learning rate: 2.9569e-05]
	Learning Rate: 2.95694e-05
	LOSS [training: 0.316612716284918 | validation: 0.6406890905804765]
	TIME [epoch: 9.72 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3107150159366708		[learning rate: 2.9462e-05]
	Learning Rate: 2.94621e-05
	LOSS [training: 0.3107150159366708 | validation: 0.627322808349618]
	TIME [epoch: 9.72 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2933914734541592		[learning rate: 2.9355e-05]
	Learning Rate: 2.93551e-05
	LOSS [training: 0.2933914734541592 | validation: 0.622006664211146]
	TIME [epoch: 9.71 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2947290790267275		[learning rate: 2.9249e-05]
	Learning Rate: 2.92486e-05
	LOSS [training: 0.2947290790267275 | validation: 0.5820996386593629]
	TIME [epoch: 9.72 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3119371917801238		[learning rate: 2.9142e-05]
	Learning Rate: 2.91425e-05
	LOSS [training: 0.3119371917801238 | validation: 0.6348239064506559]
	TIME [epoch: 9.71 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3009362505845745		[learning rate: 2.9037e-05]
	Learning Rate: 2.90367e-05
	LOSS [training: 0.3009362505845745 | validation: 0.6078266235173487]
	TIME [epoch: 9.7 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29744918721556257		[learning rate: 2.8931e-05]
	Learning Rate: 2.89313e-05
	LOSS [training: 0.29744918721556257 | validation: 0.5850126589246035]
	TIME [epoch: 9.71 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3128837408455304		[learning rate: 2.8826e-05]
	Learning Rate: 2.88263e-05
	LOSS [training: 0.3128837408455304 | validation: 0.5647177903930338]
	TIME [epoch: 9.73 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30868294958863457		[learning rate: 2.8722e-05]
	Learning Rate: 2.87217e-05
	LOSS [training: 0.30868294958863457 | validation: 0.6009988355461653]
	TIME [epoch: 9.7 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2967086375614293		[learning rate: 2.8617e-05]
	Learning Rate: 2.86175e-05
	LOSS [training: 0.2967086375614293 | validation: 0.5925319990135668]
	TIME [epoch: 9.7 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31651432232608734		[learning rate: 2.8514e-05]
	Learning Rate: 2.85136e-05
	LOSS [training: 0.31651432232608734 | validation: 0.6099449692907974]
	TIME [epoch: 9.72 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29801847072245974		[learning rate: 2.841e-05]
	Learning Rate: 2.84102e-05
	LOSS [training: 0.29801847072245974 | validation: 0.5387015301039807]
	TIME [epoch: 9.71 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3062359137370683		[learning rate: 2.8307e-05]
	Learning Rate: 2.83071e-05
	LOSS [training: 0.3062359137370683 | validation: 0.5664953491623491]
	TIME [epoch: 9.69 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3041682212071451		[learning rate: 2.8204e-05]
	Learning Rate: 2.82043e-05
	LOSS [training: 0.3041682212071451 | validation: 0.6169301914977844]
	TIME [epoch: 9.71 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28405508359519255		[learning rate: 2.8102e-05]
	Learning Rate: 2.8102e-05
	LOSS [training: 0.28405508359519255 | validation: 0.6032497931875542]
	TIME [epoch: 9.71 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3054348180295763		[learning rate: 2.8e-05]
	Learning Rate: 2.8e-05
	LOSS [training: 0.3054348180295763 | validation: 0.5614423058176147]
	TIME [epoch: 9.71 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3024877314159808		[learning rate: 2.7898e-05]
	Learning Rate: 2.78984e-05
	LOSS [training: 0.3024877314159808 | validation: 0.6175867196535182]
	TIME [epoch: 9.71 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30111295238176805		[learning rate: 2.7797e-05]
	Learning Rate: 2.77971e-05
	LOSS [training: 0.30111295238176805 | validation: 0.5595840536766135]
	TIME [epoch: 9.72 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3060734511114974		[learning rate: 2.7696e-05]
	Learning Rate: 2.76963e-05
	LOSS [training: 0.3060734511114974 | validation: 0.5644580244978523]
	TIME [epoch: 9.71 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30636704832624145		[learning rate: 2.7596e-05]
	Learning Rate: 2.75957e-05
	LOSS [training: 0.30636704832624145 | validation: 0.6261235105191584]
	TIME [epoch: 9.7 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31731581934512687		[learning rate: 2.7496e-05]
	Learning Rate: 2.74956e-05
	LOSS [training: 0.31731581934512687 | validation: 0.6375623935239935]
	TIME [epoch: 9.7 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30212215103561324		[learning rate: 2.7396e-05]
	Learning Rate: 2.73958e-05
	LOSS [training: 0.30212215103561324 | validation: 0.5631927087412869]
	TIME [epoch: 9.71 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30019459822080996		[learning rate: 2.7296e-05]
	Learning Rate: 2.72964e-05
	LOSS [training: 0.30019459822080996 | validation: 0.5462516817950124]
	TIME [epoch: 9.71 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2967550192784925		[learning rate: 2.7197e-05]
	Learning Rate: 2.71973e-05
	LOSS [training: 0.2967550192784925 | validation: 0.5835610112565002]
	TIME [epoch: 9.7 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3124482568187375		[learning rate: 2.7099e-05]
	Learning Rate: 2.70986e-05
	LOSS [training: 0.3124482568187375 | validation: 0.5831616259360994]
	TIME [epoch: 9.71 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3075098428855848		[learning rate: 2.7e-05]
	Learning Rate: 2.70003e-05
	LOSS [training: 0.3075098428855848 | validation: 0.5866264752215843]
	TIME [epoch: 9.7 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.298574928354692		[learning rate: 2.6902e-05]
	Learning Rate: 2.69023e-05
	LOSS [training: 0.298574928354692 | validation: 0.5415270246816841]
	TIME [epoch: 9.7 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30642516027345684		[learning rate: 2.6805e-05]
	Learning Rate: 2.68047e-05
	LOSS [training: 0.30642516027345684 | validation: 0.6212521227101828]
	TIME [epoch: 9.71 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30411787969285337		[learning rate: 2.6707e-05]
	Learning Rate: 2.67074e-05
	LOSS [training: 0.30411787969285337 | validation: 0.5811701876398251]
	TIME [epoch: 9.7 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3185450063857132		[learning rate: 2.661e-05]
	Learning Rate: 2.66105e-05
	LOSS [training: 0.3185450063857132 | validation: 0.6161717776131244]
	TIME [epoch: 9.71 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30311339489678824		[learning rate: 2.6514e-05]
	Learning Rate: 2.65139e-05
	LOSS [training: 0.30311339489678824 | validation: 0.6249804527935365]
	TIME [epoch: 9.71 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30772564577027456		[learning rate: 2.6418e-05]
	Learning Rate: 2.64177e-05
	LOSS [training: 0.30772564577027456 | validation: 0.5755529133539699]
	TIME [epoch: 9.73 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3071345668272428		[learning rate: 2.6322e-05]
	Learning Rate: 2.63218e-05
	LOSS [training: 0.3071345668272428 | validation: 0.5922037005936496]
	TIME [epoch: 9.7 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2962241313189614		[learning rate: 2.6226e-05]
	Learning Rate: 2.62263e-05
	LOSS [training: 0.2962241313189614 | validation: 0.635928005109838]
	TIME [epoch: 9.7 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3009802618105954		[learning rate: 2.6131e-05]
	Learning Rate: 2.61311e-05
	LOSS [training: 0.3009802618105954 | validation: 0.55634856417403]
	TIME [epoch: 9.72 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.300051682441982		[learning rate: 2.6036e-05]
	Learning Rate: 2.60363e-05
	LOSS [training: 0.300051682441982 | validation: 0.573151471540569]
	TIME [epoch: 9.73 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29429088108833407		[learning rate: 2.5942e-05]
	Learning Rate: 2.59418e-05
	LOSS [training: 0.29429088108833407 | validation: 0.5666482247621637]
	TIME [epoch: 9.7 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2999425333676568		[learning rate: 2.5848e-05]
	Learning Rate: 2.58477e-05
	LOSS [training: 0.2999425333676568 | validation: 0.6304419009162023]
	TIME [epoch: 9.72 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30249276065559055		[learning rate: 2.5754e-05]
	Learning Rate: 2.57539e-05
	LOSS [training: 0.30249276065559055 | validation: 0.5616899892205413]
	TIME [epoch: 9.72 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29261672430092217		[learning rate: 2.566e-05]
	Learning Rate: 2.56604e-05
	LOSS [training: 0.29261672430092217 | validation: 0.6013418223125386]
	TIME [epoch: 9.71 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3177950632180693		[learning rate: 2.5567e-05]
	Learning Rate: 2.55673e-05
	LOSS [training: 0.3177950632180693 | validation: 0.6295946219716908]
	TIME [epoch: 9.71 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30378183823461985		[learning rate: 2.5474e-05]
	Learning Rate: 2.54745e-05
	LOSS [training: 0.30378183823461985 | validation: 0.5837429742401038]
	TIME [epoch: 9.73 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2982762415454454		[learning rate: 2.5382e-05]
	Learning Rate: 2.5382e-05
	LOSS [training: 0.2982762415454454 | validation: 0.584425052235863]
	TIME [epoch: 9.71 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3150023617422476		[learning rate: 2.529e-05]
	Learning Rate: 2.52899e-05
	LOSS [training: 0.3150023617422476 | validation: 0.5617176569029555]
	TIME [epoch: 9.71 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3069014098354789		[learning rate: 2.5198e-05]
	Learning Rate: 2.51981e-05
	LOSS [training: 0.3069014098354789 | validation: 0.5582521663643002]
	TIME [epoch: 9.73 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.299333226090562		[learning rate: 2.5107e-05]
	Learning Rate: 2.51067e-05
	LOSS [training: 0.299333226090562 | validation: 0.5678032841675916]
	TIME [epoch: 9.71 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30366152685496456		[learning rate: 2.5016e-05]
	Learning Rate: 2.50156e-05
	LOSS [training: 0.30366152685496456 | validation: 0.5922988202924991]
	TIME [epoch: 9.7 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059281535638333		[learning rate: 2.4925e-05]
	Learning Rate: 2.49248e-05
	LOSS [training: 0.3059281535638333 | validation: 0.6104194509050499]
	TIME [epoch: 9.71 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3100786236951955		[learning rate: 2.4834e-05]
	Learning Rate: 2.48343e-05
	LOSS [training: 0.3100786236951955 | validation: 0.620607379463271]
	TIME [epoch: 9.72 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3006767763424317		[learning rate: 2.4744e-05]
	Learning Rate: 2.47442e-05
	LOSS [training: 0.3006767763424317 | validation: 0.5856244301375538]
	TIME [epoch: 9.7 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30785989510584033		[learning rate: 2.4654e-05]
	Learning Rate: 2.46544e-05
	LOSS [training: 0.30785989510584033 | validation: 0.5674981978402538]
	TIME [epoch: 9.71 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2959919556599878		[learning rate: 2.4565e-05]
	Learning Rate: 2.45649e-05
	LOSS [training: 0.2959919556599878 | validation: 0.6731123652674806]
	TIME [epoch: 9.73 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2951053404084923		[learning rate: 2.4476e-05]
	Learning Rate: 2.44758e-05
	LOSS [training: 0.2951053404084923 | validation: 0.6282825866828772]
	TIME [epoch: 9.7 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308373742161065		[learning rate: 2.4387e-05]
	Learning Rate: 2.4387e-05
	LOSS [training: 0.308373742161065 | validation: 0.6004598182276604]
	TIME [epoch: 9.71 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30253578743108134		[learning rate: 2.4298e-05]
	Learning Rate: 2.42985e-05
	LOSS [training: 0.30253578743108134 | validation: 0.6278608186575957]
	TIME [epoch: 9.72 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3224801162902723		[learning rate: 2.421e-05]
	Learning Rate: 2.42103e-05
	LOSS [training: 0.3224801162902723 | validation: 0.6055095042488075]
	TIME [epoch: 9.71 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3120746342978471		[learning rate: 2.4122e-05]
	Learning Rate: 2.41224e-05
	LOSS [training: 0.3120746342978471 | validation: 0.5490512793792249]
	TIME [epoch: 9.7 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2928530101907142		[learning rate: 2.4035e-05]
	Learning Rate: 2.40349e-05
	LOSS [training: 0.2928530101907142 | validation: 0.5480626976836829]
	TIME [epoch: 9.71 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3010792930666474		[learning rate: 2.3948e-05]
	Learning Rate: 2.39477e-05
	LOSS [training: 0.3010792930666474 | validation: 0.6386070961695718]
	TIME [epoch: 9.72 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3003114470886682		[learning rate: 2.3861e-05]
	Learning Rate: 2.38608e-05
	LOSS [training: 0.3003114470886682 | validation: 0.5979321117136369]
	TIME [epoch: 9.7 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29834862434073856		[learning rate: 2.3774e-05]
	Learning Rate: 2.37742e-05
	LOSS [training: 0.29834862434073856 | validation: 0.6158247124165491]
	TIME [epoch: 9.7 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2914380465030309		[learning rate: 2.3688e-05]
	Learning Rate: 2.36879e-05
	LOSS [training: 0.2914380465030309 | validation: 0.5661052520879305]
	TIME [epoch: 9.72 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29714711811322403		[learning rate: 2.3602e-05]
	Learning Rate: 2.36019e-05
	LOSS [training: 0.29714711811322403 | validation: 0.5971290921624633]
	TIME [epoch: 9.71 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30213479245030944		[learning rate: 2.3516e-05]
	Learning Rate: 2.35163e-05
	LOSS [training: 0.30213479245030944 | validation: 0.5693680011403628]
	TIME [epoch: 9.71 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30332600124386144		[learning rate: 2.3431e-05]
	Learning Rate: 2.34309e-05
	LOSS [training: 0.30332600124386144 | validation: 0.5554164035778318]
	TIME [epoch: 9.7 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2924460043103771		[learning rate: 2.3346e-05]
	Learning Rate: 2.33459e-05
	LOSS [training: 0.2924460043103771 | validation: 0.5969609775363643]
	TIME [epoch: 9.7 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2996316530109702		[learning rate: 2.3261e-05]
	Learning Rate: 2.32612e-05
	LOSS [training: 0.2996316530109702 | validation: 0.6317880288342941]
	TIME [epoch: 9.7 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29052085768429414		[learning rate: 2.3177e-05]
	Learning Rate: 2.31768e-05
	LOSS [training: 0.29052085768429414 | validation: 0.590363038813377]
	TIME [epoch: 9.71 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30546262456363815		[learning rate: 2.3093e-05]
	Learning Rate: 2.30926e-05
	LOSS [training: 0.30546262456363815 | validation: 0.6319868204096197]
	TIME [epoch: 9.72 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30901638334458587		[learning rate: 2.3009e-05]
	Learning Rate: 2.30088e-05
	LOSS [training: 0.30901638334458587 | validation: 0.6144126752140088]
	TIME [epoch: 9.69 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2893413850451189		[learning rate: 2.2925e-05]
	Learning Rate: 2.29253e-05
	LOSS [training: 0.2893413850451189 | validation: 0.6123632912374327]
	TIME [epoch: 9.71 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27894440386416947		[learning rate: 2.2842e-05]
	Learning Rate: 2.28421e-05
	LOSS [training: 0.27894440386416947 | validation: 0.6136556767737714]
	TIME [epoch: 9.72 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2975550546234504		[learning rate: 2.2759e-05]
	Learning Rate: 2.27592e-05
	LOSS [training: 0.2975550546234504 | validation: 0.5760693024676998]
	TIME [epoch: 9.72 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.297094340019601		[learning rate: 2.2677e-05]
	Learning Rate: 2.26767e-05
	LOSS [training: 0.297094340019601 | validation: 0.5516982008261664]
	TIME [epoch: 9.7 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31314539121291923		[learning rate: 2.2594e-05]
	Learning Rate: 2.25944e-05
	LOSS [training: 0.31314539121291923 | validation: 0.5863897333668361]
	TIME [epoch: 9.7 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30977883223458935		[learning rate: 2.2512e-05]
	Learning Rate: 2.25124e-05
	LOSS [training: 0.30977883223458935 | validation: 0.5458184766712391]
	TIME [epoch: 9.71 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30281779282334115		[learning rate: 2.2431e-05]
	Learning Rate: 2.24307e-05
	LOSS [training: 0.30281779282334115 | validation: 0.5983293357184566]
	TIME [epoch: 9.7 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29583973781262907		[learning rate: 2.2349e-05]
	Learning Rate: 2.23493e-05
	LOSS [training: 0.29583973781262907 | validation: 0.5956167468792712]
	TIME [epoch: 9.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28984690767283466		[learning rate: 2.2268e-05]
	Learning Rate: 2.22682e-05
	LOSS [training: 0.28984690767283466 | validation: 0.6080775342360331]
	TIME [epoch: 9.71 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30468845965236013		[learning rate: 2.2187e-05]
	Learning Rate: 2.21873e-05
	LOSS [training: 0.30468845965236013 | validation: 0.6306353404046943]
	TIME [epoch: 9.7 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3117734320459376		[learning rate: 2.2107e-05]
	Learning Rate: 2.21068e-05
	LOSS [training: 0.3117734320459376 | validation: 0.6333353550043661]
	TIME [epoch: 9.71 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2919617975659514		[learning rate: 2.2027e-05]
	Learning Rate: 2.20266e-05
	LOSS [training: 0.2919617975659514 | validation: 0.6197320547271753]
	TIME [epoch: 9.71 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3148544092200167		[learning rate: 2.1947e-05]
	Learning Rate: 2.19467e-05
	LOSS [training: 0.3148544092200167 | validation: 0.5763919323502517]
	TIME [epoch: 9.73 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3135023750962325		[learning rate: 2.1867e-05]
	Learning Rate: 2.1867e-05
	LOSS [training: 0.3135023750962325 | validation: 0.5836832696018545]
	TIME [epoch: 9.71 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3031000272840358		[learning rate: 2.1788e-05]
	Learning Rate: 2.17877e-05
	LOSS [training: 0.3031000272840358 | validation: 0.6033591518072966]
	TIME [epoch: 9.69 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3009680133392979		[learning rate: 2.1709e-05]
	Learning Rate: 2.17086e-05
	LOSS [training: 0.3009680133392979 | validation: 0.6414290030547983]
	TIME [epoch: 9.71 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30541788069864684		[learning rate: 2.163e-05]
	Learning Rate: 2.16298e-05
	LOSS [training: 0.30541788069864684 | validation: 0.5677212750171465]
	TIME [epoch: 9.7 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.295189643482739		[learning rate: 2.1551e-05]
	Learning Rate: 2.15513e-05
	LOSS [training: 0.295189643482739 | validation: 0.5616023899307063]
	TIME [epoch: 9.7 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2930324927293594		[learning rate: 2.1473e-05]
	Learning Rate: 2.14731e-05
	LOSS [training: 0.2930324927293594 | validation: 0.5756391952069623]
	TIME [epoch: 9.71 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30435600282682623		[learning rate: 2.1395e-05]
	Learning Rate: 2.13952e-05
	LOSS [training: 0.30435600282682623 | validation: 0.536781769292382]
	TIME [epoch: 9.71 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29919630151807575		[learning rate: 2.1318e-05]
	Learning Rate: 2.13175e-05
	LOSS [training: 0.29919630151807575 | validation: 0.623882150275193]
	TIME [epoch: 9.71 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2860303927037723		[learning rate: 2.124e-05]
	Learning Rate: 2.12402e-05
	LOSS [training: 0.2860303927037723 | validation: 0.6274220837144432]
	TIME [epoch: 9.71 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29532724517714026		[learning rate: 2.1163e-05]
	Learning Rate: 2.11631e-05
	LOSS [training: 0.29532724517714026 | validation: 0.6314895074337403]
	TIME [epoch: 9.71 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3050182949986711		[learning rate: 2.1086e-05]
	Learning Rate: 2.10863e-05
	LOSS [training: 0.3050182949986711 | validation: 0.6206023893523132]
	TIME [epoch: 9.71 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29350916482883915		[learning rate: 2.101e-05]
	Learning Rate: 2.10098e-05
	LOSS [training: 0.29350916482883915 | validation: 0.5792033595964396]
	TIME [epoch: 9.7 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29957985358911693		[learning rate: 2.0934e-05]
	Learning Rate: 2.09335e-05
	LOSS [training: 0.29957985358911693 | validation: 0.6156027892350114]
	TIME [epoch: 9.72 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2959863261639779		[learning rate: 2.0858e-05]
	Learning Rate: 2.08575e-05
	LOSS [training: 0.2959863261639779 | validation: 0.5868806254148083]
	TIME [epoch: 9.73 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30533945543311586		[learning rate: 2.0782e-05]
	Learning Rate: 2.07819e-05
	LOSS [training: 0.30533945543311586 | validation: 0.5817078072992798]
	TIME [epoch: 9.71 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2953869512724189		[learning rate: 2.0706e-05]
	Learning Rate: 2.07064e-05
	LOSS [training: 0.2953869512724189 | validation: 0.6143350248996666]
	TIME [epoch: 9.71 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3042044224689989		[learning rate: 2.0631e-05]
	Learning Rate: 2.06313e-05
	LOSS [training: 0.3042044224689989 | validation: 0.5800557248629084]
	TIME [epoch: 9.73 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.310495264194279		[learning rate: 2.0556e-05]
	Learning Rate: 2.05564e-05
	LOSS [training: 0.310495264194279 | validation: 0.553414280673257]
	TIME [epoch: 9.71 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2881591959723492		[learning rate: 2.0482e-05]
	Learning Rate: 2.04818e-05
	LOSS [training: 0.2881591959723492 | validation: 0.5806228413774333]
	TIME [epoch: 9.71 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28654795140788136		[learning rate: 2.0407e-05]
	Learning Rate: 2.04075e-05
	LOSS [training: 0.28654795140788136 | validation: 0.6004222173136983]
	TIME [epoch: 9.73 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30547413386525635		[learning rate: 2.0333e-05]
	Learning Rate: 2.03334e-05
	LOSS [training: 0.30547413386525635 | validation: 0.6152300323509303]
	TIME [epoch: 9.71 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31311412436814245		[learning rate: 2.026e-05]
	Learning Rate: 2.02596e-05
	LOSS [training: 0.31311412436814245 | validation: 0.5818505190879869]
	TIME [epoch: 9.7 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31234512628898		[learning rate: 2.0186e-05]
	Learning Rate: 2.01861e-05
	LOSS [training: 0.31234512628898 | validation: 0.6042697775631709]
	TIME [epoch: 9.71 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.300157962046881		[learning rate: 2.0113e-05]
	Learning Rate: 2.01129e-05
	LOSS [training: 0.300157962046881 | validation: 0.6237222283509115]
	TIME [epoch: 9.71 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29960087232447885		[learning rate: 2.004e-05]
	Learning Rate: 2.00399e-05
	LOSS [training: 0.29960087232447885 | validation: 0.5823891086000298]
	TIME [epoch: 9.71 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30563644951577285		[learning rate: 1.9967e-05]
	Learning Rate: 1.99671e-05
	LOSS [training: 0.30563644951577285 | validation: 0.5899712388314954]
	TIME [epoch: 9.72 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077605116301534		[learning rate: 1.9895e-05]
	Learning Rate: 1.98947e-05
	LOSS [training: 0.3077605116301534 | validation: 0.6294772887630535]
	TIME [epoch: 9.72 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30527880328761825		[learning rate: 1.9822e-05]
	Learning Rate: 1.98225e-05
	LOSS [training: 0.30527880328761825 | validation: 0.5688259080877797]
	TIME [epoch: 9.7 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2943235879523989		[learning rate: 1.9751e-05]
	Learning Rate: 1.97505e-05
	LOSS [training: 0.2943235879523989 | validation: 0.5814178513215732]
	TIME [epoch: 9.71 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3138971943045714		[learning rate: 1.9679e-05]
	Learning Rate: 1.96789e-05
	LOSS [training: 0.3138971943045714 | validation: 0.6162902618769531]
	TIME [epoch: 9.71 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2949183262263749		[learning rate: 1.9607e-05]
	Learning Rate: 1.96074e-05
	LOSS [training: 0.2949183262263749 | validation: 0.5802955870196859]
	TIME [epoch: 9.71 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29744391987364943		[learning rate: 1.9536e-05]
	Learning Rate: 1.95363e-05
	LOSS [training: 0.29744391987364943 | validation: 0.5873473835513692]
	TIME [epoch: 9.71 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3013341323868701		[learning rate: 1.9465e-05]
	Learning Rate: 1.94654e-05
	LOSS [training: 0.3013341323868701 | validation: 0.5816164238314926]
	TIME [epoch: 9.71 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308960850029918		[learning rate: 1.9395e-05]
	Learning Rate: 1.93948e-05
	LOSS [training: 0.308960850029918 | validation: 0.6063764129166577]
	TIME [epoch: 9.73 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3084905408364639		[learning rate: 1.9324e-05]
	Learning Rate: 1.93244e-05
	LOSS [training: 0.3084905408364639 | validation: 0.6100066530361186]
	TIME [epoch: 9.71 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28929481578524235		[learning rate: 1.9254e-05]
	Learning Rate: 1.92542e-05
	LOSS [training: 0.28929481578524235 | validation: 0.6522571954478802]
	TIME [epoch: 9.7 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30068928110340887		[learning rate: 1.9184e-05]
	Learning Rate: 1.91844e-05
	LOSS [training: 0.30068928110340887 | validation: 0.6114322523655633]
	TIME [epoch: 9.72 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3130038777692163		[learning rate: 1.9115e-05]
	Learning Rate: 1.91147e-05
	LOSS [training: 0.3130038777692163 | validation: 0.6186387585899814]
	TIME [epoch: 9.7 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3029362564959005		[learning rate: 1.9045e-05]
	Learning Rate: 1.90454e-05
	LOSS [training: 0.3029362564959005 | validation: 0.6200839376457199]
	TIME [epoch: 9.7 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29547071112879386		[learning rate: 1.8976e-05]
	Learning Rate: 1.89763e-05
	LOSS [training: 0.29547071112879386 | validation: 0.6034887763343124]
	TIME [epoch: 9.71 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3056449766354591		[learning rate: 1.8907e-05]
	Learning Rate: 1.89074e-05
	LOSS [training: 0.3056449766354591 | validation: 0.6031200905624106]
	TIME [epoch: 9.71 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29353033525977973		[learning rate: 1.8839e-05]
	Learning Rate: 1.88388e-05
	LOSS [training: 0.29353033525977973 | validation: 0.5618143183913898]
	TIME [epoch: 9.71 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29680551920652615		[learning rate: 1.877e-05]
	Learning Rate: 1.87704e-05
	LOSS [training: 0.29680551920652615 | validation: 0.5685356115974364]
	TIME [epoch: 9.71 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3018384368675692		[learning rate: 1.8702e-05]
	Learning Rate: 1.87023e-05
	LOSS [training: 0.3018384368675692 | validation: 0.6104812243048082]
	TIME [epoch: 9.73 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30832512593327166		[learning rate: 1.8634e-05]
	Learning Rate: 1.86344e-05
	LOSS [training: 0.30832512593327166 | validation: 0.596684014037883]
	TIME [epoch: 9.71 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30128530748345883		[learning rate: 1.8567e-05]
	Learning Rate: 1.85668e-05
	LOSS [training: 0.30128530748345883 | validation: 0.6191062908161292]
	TIME [epoch: 9.73 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30329706189458133		[learning rate: 1.8499e-05]
	Learning Rate: 1.84994e-05
	LOSS [training: 0.30329706189458133 | validation: 0.6274995853187799]
	TIME [epoch: 9.72 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2959435621844616		[learning rate: 1.8432e-05]
	Learning Rate: 1.84323e-05
	LOSS [training: 0.2959435621844616 | validation: 0.6250289175030994]
	TIME [epoch: 9.71 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30374120908064395		[learning rate: 1.8365e-05]
	Learning Rate: 1.83654e-05
	LOSS [training: 0.30374120908064395 | validation: 0.580612595472196]
	TIME [epoch: 9.71 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30374783595269356		[learning rate: 1.8299e-05]
	Learning Rate: 1.82987e-05
	LOSS [training: 0.30374783595269356 | validation: 0.6131018981210634]
	TIME [epoch: 9.7 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30669044731131617		[learning rate: 1.8232e-05]
	Learning Rate: 1.82323e-05
	LOSS [training: 0.30669044731131617 | validation: 0.6231010155161342]
	TIME [epoch: 9.72 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3149791637840099		[learning rate: 1.8166e-05]
	Learning Rate: 1.81662e-05
	LOSS [training: 0.3149791637840099 | validation: 0.5956749154590609]
	TIME [epoch: 9.72 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2900710007754981		[learning rate: 1.81e-05]
	Learning Rate: 1.81002e-05
	LOSS [training: 0.2900710007754981 | validation: 0.603152224191458]
	TIME [epoch: 9.71 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3040935676801061		[learning rate: 1.8035e-05]
	Learning Rate: 1.80346e-05
	LOSS [training: 0.3040935676801061 | validation: 0.637701606029212]
	TIME [epoch: 9.73 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30390467172729346		[learning rate: 1.7969e-05]
	Learning Rate: 1.79691e-05
	LOSS [training: 0.30390467172729346 | validation: 0.5485011968639949]
	TIME [epoch: 9.71 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29259396364416557		[learning rate: 1.7904e-05]
	Learning Rate: 1.79039e-05
	LOSS [training: 0.29259396364416557 | validation: 0.5695662231232531]
	TIME [epoch: 9.71 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31202592260406153		[learning rate: 1.7839e-05]
	Learning Rate: 1.78389e-05
	LOSS [training: 0.31202592260406153 | validation: 0.5755120322553057]
	TIME [epoch: 9.73 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29233456071360847		[learning rate: 1.7774e-05]
	Learning Rate: 1.77742e-05
	LOSS [training: 0.29233456071360847 | validation: 0.5830785837527485]
	TIME [epoch: 9.71 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2957801667654935		[learning rate: 1.771e-05]
	Learning Rate: 1.77097e-05
	LOSS [training: 0.2957801667654935 | validation: 0.5877457684382474]
	TIME [epoch: 9.7 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3002480756305905		[learning rate: 1.7645e-05]
	Learning Rate: 1.76454e-05
	LOSS [training: 0.3002480756305905 | validation: 0.6032235435052117]
	TIME [epoch: 9.71 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3015586099808309		[learning rate: 1.7581e-05]
	Learning Rate: 1.75814e-05
	LOSS [training: 0.3015586099808309 | validation: 0.5925807543191353]
	TIME [epoch: 9.72 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31322386523065726		[learning rate: 1.7518e-05]
	Learning Rate: 1.75176e-05
	LOSS [training: 0.31322386523065726 | validation: 0.6073464449974562]
	TIME [epoch: 9.71 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31032166793126137		[learning rate: 1.7454e-05]
	Learning Rate: 1.7454e-05
	LOSS [training: 0.31032166793126137 | validation: 0.6066573710765747]
	TIME [epoch: 9.7 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2903575262796149		[learning rate: 1.7391e-05]
	Learning Rate: 1.73907e-05
	LOSS [training: 0.2903575262796149 | validation: 0.601825075982098]
	TIME [epoch: 9.73 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29835087611933786		[learning rate: 1.7328e-05]
	Learning Rate: 1.73275e-05
	LOSS [training: 0.29835087611933786 | validation: 0.567686629454264]
	TIME [epoch: 9.71 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3022045144505446		[learning rate: 1.7265e-05]
	Learning Rate: 1.72647e-05
	LOSS [training: 0.3022045144505446 | validation: 0.5567825326347501]
	TIME [epoch: 9.7 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30129522279588594		[learning rate: 1.7202e-05]
	Learning Rate: 1.7202e-05
	LOSS [training: 0.30129522279588594 | validation: 0.6275463644672575]
	TIME [epoch: 9.7 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3012792044578175		[learning rate: 1.714e-05]
	Learning Rate: 1.71396e-05
	LOSS [training: 0.3012792044578175 | validation: 0.5906233500862523]
	TIME [epoch: 9.72 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3009739291378373		[learning rate: 1.7077e-05]
	Learning Rate: 1.70774e-05
	LOSS [training: 0.3009739291378373 | validation: 0.6006655196104709]
	TIME [epoch: 9.71 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3088847789861987		[learning rate: 1.7015e-05]
	Learning Rate: 1.70154e-05
	LOSS [training: 0.3088847789861987 | validation: 0.6065998033100648]
	TIME [epoch: 9.7 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30975531787611954		[learning rate: 1.6954e-05]
	Learning Rate: 1.69537e-05
	LOSS [training: 0.30975531787611954 | validation: 0.5732486199146957]
	TIME [epoch: 9.71 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2998221227756204		[learning rate: 1.6892e-05]
	Learning Rate: 1.68921e-05
	LOSS [training: 0.2998221227756204 | validation: 0.5987738911627626]
	TIME [epoch: 9.72 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30882762463189195		[learning rate: 1.6831e-05]
	Learning Rate: 1.68308e-05
	LOSS [training: 0.30882762463189195 | validation: 0.6041239164594803]
	TIME [epoch: 9.72 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2948158873036264		[learning rate: 1.677e-05]
	Learning Rate: 1.67697e-05
	LOSS [training: 0.2948158873036264 | validation: 0.5478861444056519]
	TIME [epoch: 9.74 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3021302872609641		[learning rate: 1.6709e-05]
	Learning Rate: 1.67089e-05
	LOSS [training: 0.3021302872609641 | validation: 0.5563215618898345]
	TIME [epoch: 9.71 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3052432828808071		[learning rate: 1.6648e-05]
	Learning Rate: 1.66482e-05
	LOSS [training: 0.3052432828808071 | validation: 0.5737953089902625]
	TIME [epoch: 9.71 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30390093748882535		[learning rate: 1.6588e-05]
	Learning Rate: 1.65878e-05
	LOSS [training: 0.30390093748882535 | validation: 0.6059741867965812]
	TIME [epoch: 9.7 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29710277167683496		[learning rate: 1.6528e-05]
	Learning Rate: 1.65276e-05
	LOSS [training: 0.29710277167683496 | validation: 0.6028229911270767]
	TIME [epoch: 9.72 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30427453475217575		[learning rate: 1.6468e-05]
	Learning Rate: 1.64677e-05
	LOSS [training: 0.30427453475217575 | validation: 0.6346118722267059]
	TIME [epoch: 9.71 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2959611130905104		[learning rate: 1.6408e-05]
	Learning Rate: 1.64079e-05
	LOSS [training: 0.2959611130905104 | validation: 0.6195435035810026]
	TIME [epoch: 9.73 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2912645091101628		[learning rate: 1.6348e-05]
	Learning Rate: 1.63483e-05
	LOSS [training: 0.2912645091101628 | validation: 0.5451481099043699]
	TIME [epoch: 9.74 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29884725820233327		[learning rate: 1.6289e-05]
	Learning Rate: 1.6289e-05
	LOSS [training: 0.29884725820233327 | validation: 0.6004060484049434]
	TIME [epoch: 9.72 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31093882721081323		[learning rate: 1.623e-05]
	Learning Rate: 1.62299e-05
	LOSS [training: 0.31093882721081323 | validation: 0.5661660326138417]
	TIME [epoch: 9.72 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3035790301765256		[learning rate: 1.6171e-05]
	Learning Rate: 1.6171e-05
	LOSS [training: 0.3035790301765256 | validation: 0.6310895718040344]
	TIME [epoch: 9.72 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3012232777545182		[learning rate: 1.6112e-05]
	Learning Rate: 1.61123e-05
	LOSS [training: 0.3012232777545182 | validation: 0.6032645666906892]
	TIME [epoch: 9.72 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30504446027257553		[learning rate: 1.6054e-05]
	Learning Rate: 1.60538e-05
	LOSS [training: 0.30504446027257553 | validation: 0.5935057061839306]
	TIME [epoch: 9.72 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2975474378239241		[learning rate: 1.5996e-05]
	Learning Rate: 1.59956e-05
	LOSS [training: 0.2975474378239241 | validation: 0.6180429127472727]
	TIME [epoch: 9.71 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3010483184232187		[learning rate: 1.5938e-05]
	Learning Rate: 1.59375e-05
	LOSS [training: 0.3010483184232187 | validation: 0.5827969809798027]
	TIME [epoch: 9.73 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30255122226204934		[learning rate: 1.588e-05]
	Learning Rate: 1.58797e-05
	LOSS [training: 0.30255122226204934 | validation: 0.5836427225986769]
	TIME [epoch: 9.72 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30438380313845714		[learning rate: 1.5822e-05]
	Learning Rate: 1.58221e-05
	LOSS [training: 0.30438380313845714 | validation: 0.5375945405317085]
	TIME [epoch: 9.7 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30032592834755134		[learning rate: 1.5765e-05]
	Learning Rate: 1.57647e-05
	LOSS [training: 0.30032592834755134 | validation: 0.6168678325947842]
	TIME [epoch: 9.74 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31764026949451474		[learning rate: 1.5707e-05]
	Learning Rate: 1.57074e-05
	LOSS [training: 0.31764026949451474 | validation: 0.5967971943603567]
	TIME [epoch: 9.72 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30552302068405324		[learning rate: 1.565e-05]
	Learning Rate: 1.56504e-05
	LOSS [training: 0.30552302068405324 | validation: 0.5910668221318104]
	TIME [epoch: 9.71 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3058557490992192		[learning rate: 1.5594e-05]
	Learning Rate: 1.55936e-05
	LOSS [training: 0.3058557490992192 | validation: 0.5871566893255862]
	TIME [epoch: 9.71 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2970211391149339		[learning rate: 1.5537e-05]
	Learning Rate: 1.5537e-05
	LOSS [training: 0.2970211391149339 | validation: 0.5482630208991447]
	TIME [epoch: 9.73 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30051140400240245		[learning rate: 1.5481e-05]
	Learning Rate: 1.54807e-05
	LOSS [training: 0.30051140400240245 | validation: 0.5576826010646441]
	TIME [epoch: 9.72 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29674622147889906		[learning rate: 1.5424e-05]
	Learning Rate: 1.54245e-05
	LOSS [training: 0.29674622147889906 | validation: 0.5758416915848773]
	TIME [epoch: 9.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29829942320543285		[learning rate: 1.5369e-05]
	Learning Rate: 1.53685e-05
	LOSS [training: 0.29829942320543285 | validation: 0.5742330551992921]
	TIME [epoch: 9.73 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2993213684283792		[learning rate: 1.5313e-05]
	Learning Rate: 1.53127e-05
	LOSS [training: 0.2993213684283792 | validation: 0.6279779898640631]
	TIME [epoch: 9.71 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2992102074507759		[learning rate: 1.5257e-05]
	Learning Rate: 1.52572e-05
	LOSS [training: 0.2992102074507759 | validation: 0.5981058959764]
	TIME [epoch: 9.7 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2965475133239649		[learning rate: 1.5202e-05]
	Learning Rate: 1.52018e-05
	LOSS [training: 0.2965475133239649 | validation: 0.6288277917715364]
	TIME [epoch: 9.72 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.313379433431871		[learning rate: 1.5147e-05]
	Learning Rate: 1.51466e-05
	LOSS [training: 0.313379433431871 | validation: 0.5769388522139376]
	TIME [epoch: 9.72 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2943972534446112		[learning rate: 1.5092e-05]
	Learning Rate: 1.50917e-05
	LOSS [training: 0.2943972534446112 | validation: 0.5690052511909582]
	TIME [epoch: 9.71 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2904401265153959		[learning rate: 1.5037e-05]
	Learning Rate: 1.50369e-05
	LOSS [training: 0.2904401265153959 | validation: 0.5589265593643464]
	TIME [epoch: 9.71 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2868639724510453		[learning rate: 1.4982e-05]
	Learning Rate: 1.49823e-05
	LOSS [training: 0.2868639724510453 | validation: 0.6381469588939865]
	TIME [epoch: 9.73 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29565937990452495		[learning rate: 1.4928e-05]
	Learning Rate: 1.49279e-05
	LOSS [training: 0.29565937990452495 | validation: 0.5775502381334748]
	TIME [epoch: 9.71 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32092146908384284		[learning rate: 1.4874e-05]
	Learning Rate: 1.48738e-05
	LOSS [training: 0.32092146908384284 | validation: 0.57711035692291]
	TIME [epoch: 9.72 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3063114947876392		[learning rate: 1.482e-05]
	Learning Rate: 1.48198e-05
	LOSS [training: 0.3063114947876392 | validation: 0.5734470405183753]
	TIME [epoch: 9.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28630178641846743		[learning rate: 1.4766e-05]
	Learning Rate: 1.4766e-05
	LOSS [training: 0.28630178641846743 | validation: 0.5800327164399105]
	TIME [epoch: 9.71 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29201578476954343		[learning rate: 1.4712e-05]
	Learning Rate: 1.47124e-05
	LOSS [training: 0.29201578476954343 | validation: 0.5935942607462148]
	TIME [epoch: 9.71 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30386054628964343		[learning rate: 1.4659e-05]
	Learning Rate: 1.4659e-05
	LOSS [training: 0.30386054628964343 | validation: 0.5994162747233746]
	TIME [epoch: 9.7 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29493676737321206		[learning rate: 1.4606e-05]
	Learning Rate: 1.46058e-05
	LOSS [training: 0.29493676737321206 | validation: 0.6312128714469981]
	TIME [epoch: 9.71 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2961181643112355		[learning rate: 1.4553e-05]
	Learning Rate: 1.45528e-05
	LOSS [training: 0.2961181643112355 | validation: 0.5810671721357916]
	TIME [epoch: 9.7 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30490266525086906		[learning rate: 1.45e-05]
	Learning Rate: 1.45e-05
	LOSS [training: 0.30490266525086906 | validation: 0.6390656042054692]
	TIME [epoch: 9.71 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29354260847051655		[learning rate: 1.4447e-05]
	Learning Rate: 1.44474e-05
	LOSS [training: 0.29354260847051655 | validation: 0.6507862691394758]
	TIME [epoch: 9.72 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29175459870888026		[learning rate: 1.4395e-05]
	Learning Rate: 1.4395e-05
	LOSS [training: 0.29175459870888026 | validation: 0.616990758295674]
	TIME [epoch: 9.71 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3008257889078102		[learning rate: 1.4343e-05]
	Learning Rate: 1.43427e-05
	LOSS [training: 0.3008257889078102 | validation: 0.5675359054408924]
	TIME [epoch: 9.71 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30608119876341533		[learning rate: 1.4291e-05]
	Learning Rate: 1.42907e-05
	LOSS [training: 0.30608119876341533 | validation: 0.6362823148751916]
	TIME [epoch: 9.71 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31274977193817227		[learning rate: 1.4239e-05]
	Learning Rate: 1.42388e-05
	LOSS [training: 0.31274977193817227 | validation: 0.6202149912209093]
	TIME [epoch: 9.72 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3219717838613362		[learning rate: 1.4187e-05]
	Learning Rate: 1.41871e-05
	LOSS [training: 0.3219717838613362 | validation: 0.5898369533395773]
	TIME [epoch: 9.71 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31558183540130513		[learning rate: 1.4136e-05]
	Learning Rate: 1.41357e-05
	LOSS [training: 0.31558183540130513 | validation: 0.6032887930695098]
	TIME [epoch: 9.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2927919179031161		[learning rate: 1.4084e-05]
	Learning Rate: 1.40844e-05
	LOSS [training: 0.2927919179031161 | validation: 0.5722543940766329]
	TIME [epoch: 9.72 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30566614353615285		[learning rate: 1.4033e-05]
	Learning Rate: 1.40332e-05
	LOSS [training: 0.30566614353615285 | validation: 0.5845555773548925]
	TIME [epoch: 9.71 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2924595802201718		[learning rate: 1.3982e-05]
	Learning Rate: 1.39823e-05
	LOSS [training: 0.2924595802201718 | validation: 0.5620016852290327]
	TIME [epoch: 9.7 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30223523555386445		[learning rate: 1.3932e-05]
	Learning Rate: 1.39316e-05
	LOSS [training: 0.30223523555386445 | validation: 0.617391731548089]
	TIME [epoch: 9.72 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3144623264628587		[learning rate: 1.3881e-05]
	Learning Rate: 1.3881e-05
	LOSS [training: 0.3144623264628587 | validation: 0.625751412563173]
	TIME [epoch: 9.71 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30899675270862964		[learning rate: 1.3831e-05]
	Learning Rate: 1.38306e-05
	LOSS [training: 0.30899675270862964 | validation: 0.5547638052892937]
	TIME [epoch: 9.71 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3061998010668588		[learning rate: 1.378e-05]
	Learning Rate: 1.37804e-05
	LOSS [training: 0.3061998010668588 | validation: 0.5903965224804817]
	TIME [epoch: 9.71 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2920341756730254		[learning rate: 1.373e-05]
	Learning Rate: 1.37304e-05
	LOSS [training: 0.2920341756730254 | validation: 0.6032559864802665]
	TIME [epoch: 9.73 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29564883893195226		[learning rate: 1.3681e-05]
	Learning Rate: 1.36806e-05
	LOSS [training: 0.29564883893195226 | validation: 0.576434761178809]
	TIME [epoch: 9.72 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3131865077033119		[learning rate: 1.3631e-05]
	Learning Rate: 1.3631e-05
	LOSS [training: 0.3131865077033119 | validation: 0.6191102359538322]
	TIME [epoch: 9.7 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2965680397126479		[learning rate: 1.3581e-05]
	Learning Rate: 1.35815e-05
	LOSS [training: 0.2965680397126479 | validation: 0.5324875573603076]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r1_20240219_205156/states/model_tr_study205_1916.pth
	Model improved!!!
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30166034573644057		[learning rate: 1.3532e-05]
	Learning Rate: 1.35322e-05
	LOSS [training: 0.30166034573644057 | validation: 0.5936405373568255]
	TIME [epoch: 9.72 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30627318527118136		[learning rate: 1.3483e-05]
	Learning Rate: 1.34831e-05
	LOSS [training: 0.30627318527118136 | validation: 0.5703819385812691]
	TIME [epoch: 9.71 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3060923571045436		[learning rate: 1.3434e-05]
	Learning Rate: 1.34342e-05
	LOSS [training: 0.3060923571045436 | validation: 0.5634607607215772]
	TIME [epoch: 9.72 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2962202781438414		[learning rate: 1.3385e-05]
	Learning Rate: 1.33854e-05
	LOSS [training: 0.2962202781438414 | validation: 0.5966644027150614]
	TIME [epoch: 9.72 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30129127681218576		[learning rate: 1.3337e-05]
	Learning Rate: 1.33368e-05
	LOSS [training: 0.30129127681218576 | validation: 0.5694900908060668]
	TIME [epoch: 9.71 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3087109319657614		[learning rate: 1.3288e-05]
	Learning Rate: 1.32884e-05
	LOSS [training: 0.3087109319657614 | validation: 0.5542430372198621]
	TIME [epoch: 9.71 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29891228112699975		[learning rate: 1.324e-05]
	Learning Rate: 1.32402e-05
	LOSS [training: 0.29891228112699975 | validation: 0.60051630768205]
	TIME [epoch: 9.73 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28665655179772737		[learning rate: 1.3192e-05]
	Learning Rate: 1.31922e-05
	LOSS [training: 0.28665655179772737 | validation: 0.6226856058228668]
	TIME [epoch: 9.71 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2953180323410332		[learning rate: 1.3144e-05]
	Learning Rate: 1.31443e-05
	LOSS [training: 0.2953180323410332 | validation: 0.573147055917926]
	TIME [epoch: 9.71 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30742476330762464		[learning rate: 1.3097e-05]
	Learning Rate: 1.30966e-05
	LOSS [training: 0.30742476330762464 | validation: 0.5852406238748091]
	TIME [epoch: 9.72 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30544162283095294		[learning rate: 1.3049e-05]
	Learning Rate: 1.30491e-05
	LOSS [training: 0.30544162283095294 | validation: 0.5756977486177627]
	TIME [epoch: 9.71 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29063019992354666		[learning rate: 1.3002e-05]
	Learning Rate: 1.30017e-05
	LOSS [training: 0.29063019992354666 | validation: 0.6122830028684412]
	TIME [epoch: 9.71 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29377290703273673		[learning rate: 1.2955e-05]
	Learning Rate: 1.29545e-05
	LOSS [training: 0.29377290703273673 | validation: 0.5547645933306659]
	TIME [epoch: 9.72 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3034863847501818		[learning rate: 1.2907e-05]
	Learning Rate: 1.29075e-05
	LOSS [training: 0.3034863847501818 | validation: 0.636501475289713]
	TIME [epoch: 9.73 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29921138503099576		[learning rate: 1.2861e-05]
	Learning Rate: 1.28607e-05
	LOSS [training: 0.29921138503099576 | validation: 0.5839444931063277]
	TIME [epoch: 9.71 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2956985528057359		[learning rate: 1.2814e-05]
	Learning Rate: 1.2814e-05
	LOSS [training: 0.2956985528057359 | validation: 0.5823954404124717]
	TIME [epoch: 9.72 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2939020361357621		[learning rate: 1.2767e-05]
	Learning Rate: 1.27675e-05
	LOSS [training: 0.2939020361357621 | validation: 0.6005644602269993]
	TIME [epoch: 9.73 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30687588893373186		[learning rate: 1.2721e-05]
	Learning Rate: 1.27212e-05
	LOSS [training: 0.30687588893373186 | validation: 0.5853879146902454]
	TIME [epoch: 9.71 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3114449936898749		[learning rate: 1.2675e-05]
	Learning Rate: 1.2675e-05
	LOSS [training: 0.3114449936898749 | validation: 0.5817213769290901]
	TIME [epoch: 9.7 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3040375335857189		[learning rate: 1.2629e-05]
	Learning Rate: 1.2629e-05
	LOSS [training: 0.3040375335857189 | validation: 0.6089987513777128]
	TIME [epoch: 9.72 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30951686687341706		[learning rate: 1.2583e-05]
	Learning Rate: 1.25832e-05
	LOSS [training: 0.30951686687341706 | validation: 0.6316556483941494]
	TIME [epoch: 9.72 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3081917972713592		[learning rate: 1.2537e-05]
	Learning Rate: 1.25375e-05
	LOSS [training: 0.3081917972713592 | validation: 0.5862197673255699]
	TIME [epoch: 9.7 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30754433089577576		[learning rate: 1.2492e-05]
	Learning Rate: 1.2492e-05
	LOSS [training: 0.30754433089577576 | validation: 0.6176209029933333]
	TIME [epoch: 9.7 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3052708404387718		[learning rate: 1.2447e-05]
	Learning Rate: 1.24467e-05
	LOSS [training: 0.3052708404387718 | validation: 0.60418903175314]
	TIME [epoch: 9.73 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30176908131487135		[learning rate: 1.2401e-05]
	Learning Rate: 1.24015e-05
	LOSS [training: 0.30176908131487135 | validation: 0.6193847902917281]
	TIME [epoch: 9.71 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2969757159041545		[learning rate: 1.2356e-05]
	Learning Rate: 1.23565e-05
	LOSS [training: 0.2969757159041545 | validation: 0.6334186407895425]
	TIME [epoch: 9.71 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2935741252607221		[learning rate: 1.2312e-05]
	Learning Rate: 1.23116e-05
	LOSS [training: 0.2935741252607221 | validation: 0.603635264884043]
	TIME [epoch: 9.72 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30425382801913525		[learning rate: 1.2267e-05]
	Learning Rate: 1.2267e-05
	LOSS [training: 0.30425382801913525 | validation: 0.6087481731176664]
	TIME [epoch: 9.72 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2969031433448615		[learning rate: 1.2222e-05]
	Learning Rate: 1.22224e-05
	LOSS [training: 0.2969031433448615 | validation: 0.6429890654235723]
	TIME [epoch: 9.71 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3048485431088773		[learning rate: 1.2178e-05]
	Learning Rate: 1.21781e-05
	LOSS [training: 0.3048485431088773 | validation: 0.5841368376679285]
	TIME [epoch: 9.71 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3020183216873512		[learning rate: 1.2134e-05]
	Learning Rate: 1.21339e-05
	LOSS [training: 0.3020183216873512 | validation: 0.5776819410970631]
	TIME [epoch: 9.73 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.295156326545227		[learning rate: 1.209e-05]
	Learning Rate: 1.20899e-05
	LOSS [training: 0.295156326545227 | validation: 0.5867684933947842]
	TIME [epoch: 9.71 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30105898776171053		[learning rate: 1.2046e-05]
	Learning Rate: 1.2046e-05
	LOSS [training: 0.30105898776171053 | validation: 0.6072379441832702]
	TIME [epoch: 9.71 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3125926166715938		[learning rate: 1.2002e-05]
	Learning Rate: 1.20023e-05
	LOSS [training: 0.3125926166715938 | validation: 0.6135835034391373]
	TIME [epoch: 9.73 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31857416899702895		[learning rate: 1.1959e-05]
	Learning Rate: 1.19587e-05
	LOSS [training: 0.31857416899702895 | validation: 0.5952205661865179]
	TIME [epoch: 9.71 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.298848083298923		[learning rate: 1.1915e-05]
	Learning Rate: 1.19153e-05
	LOSS [training: 0.298848083298923 | validation: 0.6626869436963271]
	TIME [epoch: 9.71 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3055563285332808		[learning rate: 1.1872e-05]
	Learning Rate: 1.18721e-05
	LOSS [training: 0.3055563285332808 | validation: 0.6225604818059145]
	TIME [epoch: 9.72 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2929131431558652		[learning rate: 1.1829e-05]
	Learning Rate: 1.1829e-05
	LOSS [training: 0.2929131431558652 | validation: 0.6340334597459321]
	TIME [epoch: 9.72 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3039118920226668		[learning rate: 1.1786e-05]
	Learning Rate: 1.17861e-05
	LOSS [training: 0.3039118920226668 | validation: 0.6106233815946033]
	TIME [epoch: 9.71 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3022592694834981		[learning rate: 1.1743e-05]
	Learning Rate: 1.17433e-05
	LOSS [training: 0.3022592694834981 | validation: 0.6111256905107988]
	TIME [epoch: 9.71 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3023245706035584		[learning rate: 1.1701e-05]
	Learning Rate: 1.17007e-05
	LOSS [training: 0.3023245706035584 | validation: 0.5788920715539151]
	TIME [epoch: 9.73 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29749282575019015		[learning rate: 1.1658e-05]
	Learning Rate: 1.16582e-05
	LOSS [training: 0.29749282575019015 | validation: 0.559497754624042]
	TIME [epoch: 9.72 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29974118170168523		[learning rate: 1.1616e-05]
	Learning Rate: 1.16159e-05
	LOSS [training: 0.29974118170168523 | validation: 0.5912252675395824]
	TIME [epoch: 9.71 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2955437317299797		[learning rate: 1.1574e-05]
	Learning Rate: 1.15737e-05
	LOSS [training: 0.2955437317299797 | validation: 0.5500278306555162]
	TIME [epoch: 9.72 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2915567644626782		[learning rate: 1.1532e-05]
	Learning Rate: 1.15317e-05
	LOSS [training: 0.2915567644626782 | validation: 0.5552181710600368]
	TIME [epoch: 9.72 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29466307435170636		[learning rate: 1.149e-05]
	Learning Rate: 1.14899e-05
	LOSS [training: 0.29466307435170636 | validation: 0.5514696072038374]
	TIME [epoch: 9.71 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3010699731488883		[learning rate: 1.1448e-05]
	Learning Rate: 1.14482e-05
	LOSS [training: 0.3010699731488883 | validation: 0.5953164262561588]
	TIME [epoch: 9.72 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30623575352258525		[learning rate: 1.1407e-05]
	Learning Rate: 1.14066e-05
	LOSS [training: 0.30623575352258525 | validation: 0.5776137230328883]
	TIME [epoch: 9.72 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2934329578368383		[learning rate: 1.1365e-05]
	Learning Rate: 1.13652e-05
	LOSS [training: 0.2934329578368383 | validation: 0.5986476644624257]
	TIME [epoch: 9.71 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29925741067981354		[learning rate: 1.1324e-05]
	Learning Rate: 1.1324e-05
	LOSS [training: 0.29925741067981354 | validation: 0.6093160670483038]
	TIME [epoch: 9.71 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29279576934124885		[learning rate: 1.1283e-05]
	Learning Rate: 1.12829e-05
	LOSS [training: 0.29279576934124885 | validation: 0.5629907131184492]
	TIME [epoch: 9.72 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2848787467320109		[learning rate: 1.1242e-05]
	Learning Rate: 1.1242e-05
	LOSS [training: 0.2848787467320109 | validation: 0.5743052721896187]
	TIME [epoch: 9.71 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3001151813275424		[learning rate: 1.1201e-05]
	Learning Rate: 1.12012e-05
	LOSS [training: 0.3001151813275424 | validation: 0.6319318401907065]
	TIME [epoch: 9.71 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30686494973071177		[learning rate: 1.1161e-05]
	Learning Rate: 1.11605e-05
	LOSS [training: 0.30686494973071177 | validation: 0.6292335095908362]
	TIME [epoch: 9.72 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3021188129593739		[learning rate: 1.112e-05]
	Learning Rate: 1.112e-05
	LOSS [training: 0.3021188129593739 | validation: 0.5852373224927065]
	TIME [epoch: 9.72 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2948983115146415		[learning rate: 1.108e-05]
	Learning Rate: 1.10797e-05
	LOSS [training: 0.2948983115146415 | validation: 0.5934975852509473]
	TIME [epoch: 9.71 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29752212892793367		[learning rate: 1.1039e-05]
	Learning Rate: 1.10394e-05
	LOSS [training: 0.29752212892793367 | validation: 0.5985917565156796]
	TIME [epoch: 9.71 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28652403322059794		[learning rate: 1.0999e-05]
	Learning Rate: 1.09994e-05
	LOSS [training: 0.28652403322059794 | validation: 0.602959186858616]
	TIME [epoch: 9.73 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2996496543623305		[learning rate: 1.0959e-05]
	Learning Rate: 1.09595e-05
	LOSS [training: 0.2996496543623305 | validation: 0.5556449710330459]
	TIME [epoch: 9.71 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28471664844030464		[learning rate: 1.092e-05]
	Learning Rate: 1.09197e-05
	LOSS [training: 0.28471664844030464 | validation: 0.5783066290073093]
	TIME [epoch: 9.72 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.291221400138019		[learning rate: 1.088e-05]
	Learning Rate: 1.08801e-05
	LOSS [training: 0.291221400138019 | validation: 0.5614717453307828]
	TIME [epoch: 9.72 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2999781778097818		[learning rate: 1.0841e-05]
	Learning Rate: 1.08406e-05
	LOSS [training: 0.2999781778097818 | validation: 0.591913121515642]
	TIME [epoch: 9.72 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29890203379369307		[learning rate: 1.0801e-05]
	Learning Rate: 1.08012e-05
	LOSS [training: 0.29890203379369307 | validation: 0.6570756886945412]
	TIME [epoch: 9.71 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29781635531553086		[learning rate: 1.0762e-05]
	Learning Rate: 1.0762e-05
	LOSS [training: 0.29781635531553086 | validation: 0.6254746647671015]
	TIME [epoch: 9.71 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2982320539872697		[learning rate: 1.0723e-05]
	Learning Rate: 1.0723e-05
	LOSS [training: 0.2982320539872697 | validation: 0.5610350268366255]
	TIME [epoch: 9.72 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29792866534325196		[learning rate: 1.0684e-05]
	Learning Rate: 1.06841e-05
	LOSS [training: 0.29792866534325196 | validation: 0.600675487672473]
	TIME [epoch: 9.71 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29834835905635393		[learning rate: 1.0645e-05]
	Learning Rate: 1.06453e-05
	LOSS [training: 0.29834835905635393 | validation: 0.5924106539698706]
	TIME [epoch: 9.71 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3092878644730027		[learning rate: 1.0607e-05]
	Learning Rate: 1.06067e-05
	LOSS [training: 0.3092878644730027 | validation: 0.5884120023954925]
	TIME [epoch: 9.73 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30014860501714785		[learning rate: 1.0568e-05]
	Learning Rate: 1.05682e-05
	LOSS [training: 0.30014860501714785 | validation: 0.579745137733969]
	TIME [epoch: 9.72 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29465928674729536		[learning rate: 1.053e-05]
	Learning Rate: 1.05298e-05
	LOSS [training: 0.29465928674729536 | validation: 0.5444677316232985]
	TIME [epoch: 9.71 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2978303144424365		[learning rate: 1.0492e-05]
	Learning Rate: 1.04916e-05
	LOSS [training: 0.2978303144424365 | validation: 0.6315241823158021]
	TIME [epoch: 9.72 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28953779766755194		[learning rate: 1.0454e-05]
	Learning Rate: 1.04535e-05
	LOSS [training: 0.28953779766755194 | validation: 0.5799269588135415]
	TIME [epoch: 9.72 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2927264969486504		[learning rate: 1.0416e-05]
	Learning Rate: 1.04156e-05
	LOSS [training: 0.2927264969486504 | validation: 0.6158297066296757]
	TIME [epoch: 9.71 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29703928531765		[learning rate: 1.0378e-05]
	Learning Rate: 1.03778e-05
	LOSS [training: 0.29703928531765 | validation: 0.622389649617852]
	TIME [epoch: 9.71 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.314259837152973		[learning rate: 1.034e-05]
	Learning Rate: 1.03401e-05
	LOSS [training: 0.314259837152973 | validation: 0.5984247341284717]
	TIME [epoch: 9.72 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3091829206236226		[learning rate: 1.0303e-05]
	Learning Rate: 1.03026e-05
	LOSS [training: 0.3091829206236226 | validation: 0.5728362660043527]
	TIME [epoch: 9.71 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2919544219698206		[learning rate: 1.0265e-05]
	Learning Rate: 1.02652e-05
	LOSS [training: 0.2919544219698206 | validation: 0.562205522909759]
	TIME [epoch: 9.71 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28905161098610566		[learning rate: 1.0228e-05]
	Learning Rate: 1.0228e-05
	LOSS [training: 0.28905161098610566 | validation: 0.5793679549337639]
	TIME [epoch: 9.73 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30556670573482486		[learning rate: 1.0191e-05]
	Learning Rate: 1.01909e-05
	LOSS [training: 0.30556670573482486 | validation: 0.6039940721843791]
	TIME [epoch: 9.71 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29044676212307163		[learning rate: 1.0154e-05]
	Learning Rate: 1.01539e-05
	LOSS [training: 0.29044676212307163 | validation: 0.6507856559827028]
	TIME [epoch: 9.71 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2931136892703484		[learning rate: 1.0117e-05]
	Learning Rate: 1.0117e-05
	LOSS [training: 0.2931136892703484 | validation: 0.5728155352308472]
	TIME [epoch: 9.71 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30179219157549625		[learning rate: 1.008e-05]
	Learning Rate: 1.00803e-05
	LOSS [training: 0.30179219157549625 | validation: 0.6132818783067889]
	TIME [epoch: 9.71 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2948445005006703		[learning rate: 1.0044e-05]
	Learning Rate: 1.00437e-05
	LOSS [training: 0.2948445005006703 | validation: 0.5605125423655417]
	TIME [epoch: 9.71 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30338702718058824		[learning rate: 1.0007e-05]
	Learning Rate: 1.00073e-05
	LOSS [training: 0.30338702718058824 | validation: 0.6495254742181716]
	TIME [epoch: 9.71 sec]
Finished training in 19584.589 seconds.
