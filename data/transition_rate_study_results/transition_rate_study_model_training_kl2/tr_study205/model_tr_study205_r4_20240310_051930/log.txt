Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r4', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 774491913

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.924015741851182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.924015741851182 | validation: 13.011043582151556]
	TIME [epoch: 111 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.147334883494732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 13.147334883494732 | validation: 12.393176767586729]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.42235843419586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.42235843419586 | validation: 11.12741238332392]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.813438685853589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.813438685853589 | validation: 9.065932446732837]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.5080270635448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.5080270635448 | validation: 6.511565152611682]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.099682000821113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.099682000821113 | validation: 5.731734138860311]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2813315987193175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2813315987193175 | validation: 5.925294878574495]
	TIME [epoch: 25 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.111732671752946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.111732671752946 | validation: 5.452109878787674]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.094469646566932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.094469646566932 | validation: 5.430132153532193]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.903290125081165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.903290125081165 | validation: 5.423704680003609]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.836651831414238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.836651831414238 | validation: 5.869780300982532]
	TIME [epoch: 25 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.024626487353634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.024626487353634 | validation: 6.117434727426614]
	TIME [epoch: 25 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.41885416467935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.41885416467935 | validation: 5.5433603411499535]
	TIME [epoch: 25 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.879249703316064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.879249703316064 | validation: 5.492321662359859]
	TIME [epoch: 24.9 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.718837475934789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.718837475934789 | validation: 5.932134661661953]
	TIME [epoch: 25 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.330883034219187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.330883034219187 | validation: 5.386972608597993]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.673486332319745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.673486332319745 | validation: 5.941555017522352]
	TIME [epoch: 24.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.635222306791797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.635222306791797 | validation: 6.590361655796296]
	TIME [epoch: 24.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.125727265088781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.125727265088781 | validation: 5.265415734495957]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8993386817602245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8993386817602245 | validation: 5.549187152495521]
	TIME [epoch: 24.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7357108323771975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7357108323771975 | validation: 5.713011068349233]
	TIME [epoch: 24.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.804472881470835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.804472881470835 | validation: 5.289775023180632]
	TIME [epoch: 24.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.756919472211743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.756919472211743 | validation: 5.172199331926598]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.890689074077608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.890689074077608 | validation: 5.152333619261301]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.49971113030829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.49971113030829 | validation: 6.320653522989483]
	TIME [epoch: 24.9 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.925958841111713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.925958841111713 | validation: 5.423105321782138]
	TIME [epoch: 24.9 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.54923022217941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.54923022217941 | validation: 5.323688112527574]
	TIME [epoch: 24.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.641472591647359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.641472591647359 | validation: 5.515610063945221]
	TIME [epoch: 24.9 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.873058259958936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.873058259958936 | validation: 4.931757302148985]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.763083298387903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.763083298387903 | validation: 5.371037220567464]
	TIME [epoch: 24.9 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.688433823940951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.688433823940951 | validation: 4.955381192029107]
	TIME [epoch: 24.9 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3457673159919255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3457673159919255 | validation: 5.089996630853482]
	TIME [epoch: 24.9 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.288834726237204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.288834726237204 | validation: 6.355078098034267]
	TIME [epoch: 24.9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.621796677288987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.621796677288987 | validation: 5.237100896274399]
	TIME [epoch: 24.9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.383451780244634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.383451780244634 | validation: 4.819771749206534]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.254339217007627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.254339217007627 | validation: 5.693312817455363]
	TIME [epoch: 24.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.670839667386057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.670839667386057 | validation: 5.010691610246122]
	TIME [epoch: 24.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2292226263496095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2292226263496095 | validation: 4.831194826816438]
	TIME [epoch: 24.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.361249512991119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.361249512991119 | validation: 5.8744378905221035]
	TIME [epoch: 24.9 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.344410924272374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.344410924272374 | validation: 4.902423553454491]
	TIME [epoch: 24.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.181174360129748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.181174360129748 | validation: 5.722617557035314]
	TIME [epoch: 24.9 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.348855817788678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.348855817788678 | validation: 5.64370855044945]
	TIME [epoch: 24.9 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.400050540637295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.400050540637295 | validation: 4.853808359134235]
	TIME [epoch: 24.9 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.154399223467976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.154399223467976 | validation: 4.669327255666219]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.833487045337917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.833487045337917 | validation: 6.4549344978553975]
	TIME [epoch: 25 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.699024106545394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.699024106545394 | validation: 5.250206809338659]
	TIME [epoch: 24.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2114218790403175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2114218790403175 | validation: 4.822571159939158]
	TIME [epoch: 24.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.15448243857262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.15448243857262 | validation: 4.813776792284263]
	TIME [epoch: 24.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.171873942240778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.171873942240778 | validation: 4.664798079227171]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.111348231204266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.111348231204266 | validation: 4.752900061755773]
	TIME [epoch: 24.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1755177675679285		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.1755177675679285 | validation: 4.582622141922765]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.109973243213142		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.109973243213142 | validation: 5.033422537287353]
	TIME [epoch: 25 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.119926848209196		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.119926848209196 | validation: 4.565933390633388]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.747300483171764		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.747300483171764 | validation: 4.314931788073227]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.373733014441521		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.373733014441521 | validation: 5.255698037822531]
	TIME [epoch: 25 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.253142056987818		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.253142056987818 | validation: 4.775034104143243]
	TIME [epoch: 24.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.076858672295893		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.076858672295893 | validation: 4.507926525947184]
	TIME [epoch: 24.9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.986076666842956		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.986076666842956 | validation: 4.81015613994472]
	TIME [epoch: 24.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.939638540770198		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.939638540770198 | validation: 4.394390697795319]
	TIME [epoch: 24.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.982050139758499		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.982050139758499 | validation: 5.064473691189341]
	TIME [epoch: 24.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.119606060452108		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.119606060452108 | validation: 4.302486980562856]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8802668893923515		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.8802668893923515 | validation: 4.1150850552081355]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.889177996561917		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.889177996561917 | validation: 4.597962726165484]
	TIME [epoch: 24.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.359509301302003		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.359509301302003 | validation: 4.343855961280017]
	TIME [epoch: 24.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.708756898812979		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.708756898812979 | validation: 4.6229959479719405]
	TIME [epoch: 24.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.434842069320962		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.434842069320962 | validation: 4.665858193135677]
	TIME [epoch: 25 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.341531122614756		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 5.341531122614756 | validation: 4.430094233257943]
	TIME [epoch: 24.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.05165495726668		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.05165495726668 | validation: 5.222357989318689]
	TIME [epoch: 24.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.901944486173685		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.901944486173685 | validation: 4.298027316232066]
	TIME [epoch: 24.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.839524026106515		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.839524026106515 | validation: 4.840327073417226]
	TIME [epoch: 24.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.942758598282376		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.942758598282376 | validation: 4.457611036217566]
	TIME [epoch: 24.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7533694997767215		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.7533694997767215 | validation: 4.468768268496836]
	TIME [epoch: 25 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.824282791167618		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.824282791167618 | validation: 4.382047137578389]
	TIME [epoch: 24.9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8074188109201135		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.8074188109201135 | validation: 4.281355732901075]
	TIME [epoch: 24.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.736648380926143		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.736648380926143 | validation: 4.362731300348634]
	TIME [epoch: 24.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.743361099152642		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.743361099152642 | validation: 4.298361481929745]
	TIME [epoch: 24.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.96545321342262		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.96545321342262 | validation: 5.58230943926513]
	TIME [epoch: 24.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.48555074281024		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 5.48555074281024 | validation: 5.4860291592134365]
	TIME [epoch: 24.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.471249254440524		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 5.471249254440524 | validation: 4.4048385166406865]
	TIME [epoch: 24.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7713803674820285		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.7713803674820285 | validation: 4.2092407616534375]
	TIME [epoch: 24.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.570086783028671		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.570086783028671 | validation: 5.18229469948977]
	TIME [epoch: 25 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.836996260005549		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.836996260005549 | validation: 4.420658522920167]
	TIME [epoch: 24.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.439582992317369		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 5.439582992317369 | validation: 4.602035066906267]
	TIME [epoch: 24.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.767306314688372		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.767306314688372 | validation: 3.9941196838390547]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.864611428292979		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.864611428292979 | validation: 7.27856271352636]
	TIME [epoch: 25 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.937673816740315		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 5.937673816740315 | validation: 5.056837043826879]
	TIME [epoch: 25 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.971428492765451		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.971428492765451 | validation: 4.0319957399920865]
	TIME [epoch: 25 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.196201588886193		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 5.196201588886193 | validation: 4.475614860032846]
	TIME [epoch: 25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.995336762451429		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.995336762451429 | validation: 4.887789524383256]
	TIME [epoch: 24.9 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.248606641843113		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 5.248606641843113 | validation: 4.842048519406163]
	TIME [epoch: 25 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.736070687696471		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.736070687696471 | validation: 4.932535294305037]
	TIME [epoch: 24.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.007733271067151		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 5.007733271067151 | validation: 4.088151995842948]
	TIME [epoch: 24.9 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.433766561679926		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.433766561679926 | validation: 4.620656884653251]
	TIME [epoch: 24.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.823854903396489		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.823854903396489 | validation: 4.255932043077978]
	TIME [epoch: 25 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.626373533545892		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.626373533545892 | validation: 4.268931857313202]
	TIME [epoch: 24.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.573634318896074		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.573634318896074 | validation: 4.315618951185084]
	TIME [epoch: 24.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.603023588473233		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.603023588473233 | validation: 4.345870738400667]
	TIME [epoch: 24.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511092096226649		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 4.511092096226649 | validation: 3.9913800125376895]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.376480326998951		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 4.376480326998951 | validation: 5.583410836831437]
	TIME [epoch: 25 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.840228628786569		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.840228628786569 | validation: 4.372958973796023]
	TIME [epoch: 24.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.548638748393058		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 4.548638748393058 | validation: 4.126166608212475]
	TIME [epoch: 24.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.477060160900756		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.477060160900756 | validation: 4.147846142518399]
	TIME [epoch: 25 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.434897621861728		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.434897621861728 | validation: 4.510852445061172]
	TIME [epoch: 24.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.513631301015437		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.513631301015437 | validation: 4.105400394128035]
	TIME [epoch: 24.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3926996625564865		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 4.3926996625564865 | validation: 4.11090230969134]
	TIME [epoch: 25 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.423736173148625		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.423736173148625 | validation: 4.389714629708614]
	TIME [epoch: 25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465657401036873		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 4.465657401036873 | validation: 3.849675403416544]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.405310865081979		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.405310865081979 | validation: 4.394958018885112]
	TIME [epoch: 25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.49088093031899		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.49088093031899 | validation: 4.668101909004179]
	TIME [epoch: 25 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.448302378405476		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 4.448302378405476 | validation: 4.748444552687585]
	TIME [epoch: 24.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4200716514691845		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 4.4200716514691845 | validation: 4.116482019413239]
	TIME [epoch: 25 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.753558864816823		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 4.753558864816823 | validation: 4.2198352145444975]
	TIME [epoch: 25 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.562736284653171		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 4.562736284653171 | validation: 3.918957025795456]
	TIME [epoch: 24.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.608777055825394		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.608777055825394 | validation: 4.0597233823272925]
	TIME [epoch: 24.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.40044419819787		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.40044419819787 | validation: 3.8485896184874533]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.40318255907835		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.40318255907835 | validation: 4.474680981255781]
	TIME [epoch: 24.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6429965852303345		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.6429965852303345 | validation: 5.523163720355756]
	TIME [epoch: 25 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.977895891686028		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 4.977895891686028 | validation: 5.022065515529451]
	TIME [epoch: 25 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.765037824540371		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.765037824540371 | validation: 4.132476142136557]
	TIME [epoch: 24.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.338606689190203		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 4.338606689190203 | validation: 4.419060533949995]
	TIME [epoch: 25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.474908906193932		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 4.474908906193932 | validation: 4.0617976084129825]
	TIME [epoch: 25 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3630469899715925		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.3630469899715925 | validation: 3.960938101678365]
	TIME [epoch: 24.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.424849358987973		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 4.424849358987973 | validation: 3.666270825416483]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.132688202010904		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 4.132688202010904 | validation: 3.9461147452494334]
	TIME [epoch: 25 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.378271277615164		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.378271277615164 | validation: 4.14440155639557]
	TIME [epoch: 24.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3409469815565815		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.3409469815565815 | validation: 4.077942641245346]
	TIME [epoch: 25 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.299003734421205		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 4.299003734421205 | validation: 4.148469831387552]
	TIME [epoch: 25 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.303323539553505		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.303323539553505 | validation: 4.053541347640233]
	TIME [epoch: 24.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4440336923037895		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.4440336923037895 | validation: 3.862034001735525]
	TIME [epoch: 25 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2785788753317675		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.2785788753317675 | validation: 3.7728115924935435]
	TIME [epoch: 25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.25846014667984		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 4.25846014667984 | validation: 3.7766466591687875]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.093037004953006		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 4.093037004953006 | validation: 5.07788162795896]
	TIME [epoch: 24.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.643812377778862		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.643812377778862 | validation: 4.975771230390159]
	TIME [epoch: 25 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.572124759512867		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.572124759512867 | validation: 3.8957286045972768]
	TIME [epoch: 24.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.179937012330239		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 4.179937012330239 | validation: 3.6346557697049184]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.255885803240542		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 4.255885803240542 | validation: 4.47670400467734]
	TIME [epoch: 25 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.359819697452432		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 4.359819697452432 | validation: 3.8067804524744693]
	TIME [epoch: 25 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.30928498758895		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 4.30928498758895 | validation: 4.553697533961871]
	TIME [epoch: 25 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454958220034083		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 4.454958220034083 | validation: 3.9039452134260446]
	TIME [epoch: 25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.539965100681528		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 4.539965100681528 | validation: 3.540935193195461]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462472125242025		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 4.462472125242025 | validation: 3.634687204307779]
	TIME [epoch: 25 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0093361916217845		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 5.0093361916217845 | validation: 4.16736544648667]
	TIME [epoch: 25 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.599689388010539		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 4.599689388010539 | validation: 3.9495786784765987]
	TIME [epoch: 24.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.515783978747752		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 4.515783978747752 | validation: 4.0690387597095325]
	TIME [epoch: 25 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.244832912732854		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 4.244832912732854 | validation: 4.0606091946460525]
	TIME [epoch: 25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.233173892396499		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 4.233173892396499 | validation: 3.9315217365752972]
	TIME [epoch: 25 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.264339556766101		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 4.264339556766101 | validation: 4.030473155870434]
	TIME [epoch: 24.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.233950380087631		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 4.233950380087631 | validation: 3.793238029360946]
	TIME [epoch: 25 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.140895568166801		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 4.140895568166801 | validation: 4.305934341558839]
	TIME [epoch: 24.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.174512524068362		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 4.174512524068362 | validation: 4.166502173455816]
	TIME [epoch: 25 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.220927537974148		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 4.220927537974148 | validation: 4.886911694374949]
	TIME [epoch: 25 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5219035583885026		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 4.5219035583885026 | validation: 6.0222327601659105]
	TIME [epoch: 24.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8058864827980905		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 4.8058864827980905 | validation: 5.230786993396889]
	TIME [epoch: 25 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531064169122335		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 4.531064169122335 | validation: 4.605962652862892]
	TIME [epoch: 25 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7380113898037415		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 4.7380113898037415 | validation: 4.44191009459473]
	TIME [epoch: 24.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5146588450457035		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 4.5146588450457035 | validation: 4.360459536779116]
	TIME [epoch: 25 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.482213352150814		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 4.482213352150814 | validation: 3.8179349239585942]
	TIME [epoch: 25 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.213387641925352		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 4.213387641925352 | validation: 3.58116299234355]
	TIME [epoch: 24.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.202277188292932		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 4.202277188292932 | validation: 3.5832706218728165]
	TIME [epoch: 25 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.002045580591345		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 4.002045580591345 | validation: 3.747387988821379]
	TIME [epoch: 25 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.163450902950781		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 5.163450902950781 | validation: 5.747320245361502]
	TIME [epoch: 24.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.561337780317244		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 4.561337780317244 | validation: 4.196305408027822]
	TIME [epoch: 25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.222931256764721		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 4.222931256764721 | validation: 4.208923889743399]
	TIME [epoch: 24.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.177482939180355		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 4.177482939180355 | validation: 3.7944045598131586]
	TIME [epoch: 24.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.077064357235006		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 4.077064357235006 | validation: 3.8606916368243915]
	TIME [epoch: 25 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.044467633993467		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 4.044467633993467 | validation: 3.9328805265487983]
	TIME [epoch: 24.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.02263697552467		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 4.02263697552467 | validation: 3.8723924096227185]
	TIME [epoch: 24.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.012025183160698		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 4.012025183160698 | validation: 4.573450448309103]
	TIME [epoch: 24.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.265822001376792		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 4.265822001376792 | validation: 3.911644473444198]
	TIME [epoch: 25 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0832256761196675		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 4.0832256761196675 | validation: 3.741669445040924]
	TIME [epoch: 24.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.008487293645089		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 4.008487293645089 | validation: 4.108793439017342]
	TIME [epoch: 25 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.221056466483384		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 4.221056466483384 | validation: 3.9079647481592064]
	TIME [epoch: 25 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.29022282561675		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 4.29022282561675 | validation: 3.4302172375460986]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.040211948022636		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 4.040211948022636 | validation: 4.3371330356037525]
	TIME [epoch: 24.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.35987362741731		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 4.35987362741731 | validation: 4.971945283092411]
	TIME [epoch: 25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5387628114107255		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 4.5387628114107255 | validation: 4.305664026342518]
	TIME [epoch: 24.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.199829470305224		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 4.199829470305224 | validation: 3.6782455884121483]
	TIME [epoch: 24.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.105184832488138		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 4.105184832488138 | validation: 3.714554392313212]
	TIME [epoch: 25 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.048747269609823		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 4.048747269609823 | validation: 3.724964034590367]
	TIME [epoch: 24.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9727390724318816		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.9727390724318816 | validation: 3.7994566377960997]
	TIME [epoch: 25 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.082646668671964		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 4.082646668671964 | validation: 4.077760075028108]
	TIME [epoch: 25 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.030879324834487		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 4.030879324834487 | validation: 3.5432717993797485]
	TIME [epoch: 25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.051160823462819		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 4.051160823462819 | validation: 3.6660152016029968]
	TIME [epoch: 24.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011493772158358		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 4.011493772158358 | validation: 4.227101479878285]
	TIME [epoch: 25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.364492428482363		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 4.364492428482363 | validation: 5.410719321044114]
	TIME [epoch: 25 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6133155310363785		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 4.6133155310363785 | validation: 4.026282192340717]
	TIME [epoch: 25 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.108130520388098		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 4.108130520388098 | validation: 3.6446000146270547]
	TIME [epoch: 25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.017887749722017		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 4.017887749722017 | validation: 3.66259794224287]
	TIME [epoch: 25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9791273581790874		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.9791273581790874 | validation: 3.5984982555709673]
	TIME [epoch: 25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.884522984149542		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.884522984149542 | validation: 3.5030634519850943]
	TIME [epoch: 24.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.064548570852915		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 4.064548570852915 | validation: 5.263168258394692]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.734745108377661		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 4.734745108377661 | validation: 4.492731029851101]
	TIME [epoch: 25 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.288574325877455		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 4.288574325877455 | validation: 3.918357818041014]
	TIME [epoch: 25 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.596605712450314		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 4.596605712450314 | validation: 3.9775378944043345]
	TIME [epoch: 24.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7423845567274325		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 4.7423845567274325 | validation: 4.019561008112498]
	TIME [epoch: 24.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.736536127865307		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 4.736536127865307 | validation: 3.883775438188605]
	TIME [epoch: 25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.596481697655426		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 4.596481697655426 | validation: 3.820686609000219]
	TIME [epoch: 24.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493962747147059		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 4.493962747147059 | validation: 3.7632533502234082]
	TIME [epoch: 24.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.431008391134704		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 4.431008391134704 | validation: 3.6213276108354284]
	TIME [epoch: 25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3874768805177995		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 4.3874768805177995 | validation: 3.750596872340891]
	TIME [epoch: 24.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.186694344551004		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 4.186694344551004 | validation: 3.72663542166874]
	TIME [epoch: 24.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8518274334515716		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 3.8518274334515716 | validation: 3.8965965581473907]
	TIME [epoch: 25 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.039532153023833		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 4.039532153023833 | validation: 3.5897115117654366]
	TIME [epoch: 24.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9975154721229824		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.9975154721229824 | validation: 3.5182238366790046]
	TIME [epoch: 24.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.855117441464448		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.855117441464448 | validation: 3.900134814328384]
	TIME [epoch: 25 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.906448719333508		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 3.906448719333508 | validation: 4.029358104469878]
	TIME [epoch: 25 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9992487109268224		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 3.9992487109268224 | validation: 3.4990479150498466]
	TIME [epoch: 24.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.092117436984244		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 4.092117436984244 | validation: 3.348636031750725]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.219192991008276		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 4.219192991008276 | validation: 3.3825816255302072]
	TIME [epoch: 24.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.953901899465876		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 3.953901899465876 | validation: 3.8355713133516462]
	TIME [epoch: 24.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.037647593095331		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 4.037647593095331 | validation: 5.916126753091976]
	TIME [epoch: 24.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.762294446467347		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 4.762294446467347 | validation: 4.2496064066456976]
	TIME [epoch: 24.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.146470379574332		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 4.146470379574332 | validation: 3.3990953943060687]
	TIME [epoch: 24.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.816095412723315		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 4.816095412723315 | validation: 5.895390692213316]
	TIME [epoch: 25 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.464173803535424		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 4.464173803535424 | validation: 3.666310120348908]
	TIME [epoch: 24.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.006710580783441		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 4.006710580783441 | validation: 3.634864161342465]
	TIME [epoch: 24.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.920440470724627		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.920440470724627 | validation: 3.7319841679121852]
	TIME [epoch: 24.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.885808739467292		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.885808739467292 | validation: 3.9867216528476224]
	TIME [epoch: 24.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.936312700013011		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.936312700013011 | validation: 3.5798953949243923]
	TIME [epoch: 24.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8689545778844754		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 3.8689545778844754 | validation: 3.5613702713891833]
	TIME [epoch: 24.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.596141192095222		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 5.596141192095222 | validation: 4.493947131262798]
	TIME [epoch: 24.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.092375850881687		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 4.092375850881687 | validation: 3.5568480531628563]
	TIME [epoch: 24.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9086180175780787		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 3.9086180175780787 | validation: 4.0886161466329405]
	TIME [epoch: 24.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.96403348298415		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 3.96403348298415 | validation: 3.8042269678672826]
	TIME [epoch: 24.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9667280926651545		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 3.9667280926651545 | validation: 4.596231242368019]
	TIME [epoch: 24.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4097343734872485		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 4.4097343734872485 | validation: 4.282500207335142]
	TIME [epoch: 24.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478692519710693		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 4.478692519710693 | validation: 3.4290976684035885]
	TIME [epoch: 24.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.621013987777269		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 4.621013987777269 | validation: 3.715125117997153]
	TIME [epoch: 24.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1986637250935495		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 4.1986637250935495 | validation: 3.566636267459502]
	TIME [epoch: 25 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.225148811378497		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 4.225148811378497 | validation: 3.6263344291724455]
	TIME [epoch: 24.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.017545400669445		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 4.017545400669445 | validation: 3.441655946618578]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.298914940712502		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 4.298914940712502 | validation: 3.6063494060371055]
	TIME [epoch: 24.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.141512445663588		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 4.141512445663588 | validation: 3.5592409734473693]
	TIME [epoch: 24.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.966295882192049		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 3.966295882192049 | validation: 4.138374820453339]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.987986128669621		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 3.987986128669621 | validation: 4.263369186407852]
	TIME [epoch: 24.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.101744630809863		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 4.101744630809863 | validation: 3.7633983318454556]
	TIME [epoch: 24.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.909605381204738		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 3.909605381204738 | validation: 3.653129037215732]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.816946375721561		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 3.816946375721561 | validation: 3.4166177530977784]
	TIME [epoch: 24.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9686359654029326		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 3.9686359654029326 | validation: 3.3799202225322147]
	TIME [epoch: 24.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.939600885083106		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 3.939600885083106 | validation: 4.0114804148998475]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9139588044183693		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 3.9139588044183693 | validation: 3.4579371210804783]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8557245780197222		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 3.8557245780197222 | validation: 3.507427762967577]
	TIME [epoch: 24.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8117197932329216		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 3.8117197932329216 | validation: 3.655676979566647]
	TIME [epoch: 24.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9787563343416332		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 3.9787563343416332 | validation: 3.461182303690631]
	TIME [epoch: 24.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.814947743347287		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 3.814947743347287 | validation: 4.106444927469828]
	TIME [epoch: 24.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.068408369999656		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 4.068408369999656 | validation: 3.576711962301853]
	TIME [epoch: 24.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.186322819609439		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 4.186322819609439 | validation: 3.57776482731256]
	TIME [epoch: 24.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.199446267033225		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 4.199446267033225 | validation: 4.220098029661555]
	TIME [epoch: 24.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.994533779688083		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 3.994533779688083 | validation: 3.3977343186558415]
	TIME [epoch: 24.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1848890979903555		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 4.1848890979903555 | validation: 3.7358370290596974]
	TIME [epoch: 24.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.000665435990762		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 4.000665435990762 | validation: 3.360753342323993]
	TIME [epoch: 24.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.096511710145549		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 4.096511710145549 | validation: 3.54671212539363]
	TIME [epoch: 24.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.231830262683654		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 4.231830262683654 | validation: 4.6868356853631]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2179902687145665		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 4.2179902687145665 | validation: 4.10191182152131]
	TIME [epoch: 24.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9672646335675377		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 3.9672646335675377 | validation: 4.3258663891551565]
	TIME [epoch: 24.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1162619289091635		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 4.1162619289091635 | validation: 4.0052100290942585]
	TIME [epoch: 24.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8377479565605643		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 3.8377479565605643 | validation: 3.7754741998975927]
	TIME [epoch: 24.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.028937104084733		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 4.028937104084733 | validation: 3.7215384880567774]
	TIME [epoch: 24.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8672790267419312		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 3.8672790267419312 | validation: 3.519369954798916]
	TIME [epoch: 24.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8384397635495913		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 3.8384397635495913 | validation: 3.4340365394583454]
	TIME [epoch: 24.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.322567763464935		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 4.322567763464935 | validation: 3.927742457086024]
	TIME [epoch: 24.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.936358042673259		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 3.936358042673259 | validation: 4.371045627565989]
	TIME [epoch: 24.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.32868783092207		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 4.32868783092207 | validation: 3.8922804452214637]
	TIME [epoch: 24.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.019837034778806		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 4.019837034778806 | validation: 3.7710655729135847]
	TIME [epoch: 24.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9095530050736262		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 3.9095530050736262 | validation: 3.395095807136621]
	TIME [epoch: 24.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.265084581079112		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 4.265084581079112 | validation: 3.971399898087294]
	TIME [epoch: 24.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.922604863269401		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 3.922604863269401 | validation: 3.4452918308834284]
	TIME [epoch: 24.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9735525357963777		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 3.9735525357963777 | validation: 3.4348603763493517]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.936306387613398		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 3.936306387613398 | validation: 3.341874845366412]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.979519040463854		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 3.979519040463854 | validation: 3.600817740130893]
	TIME [epoch: 24.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.986890071392454		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 3.986890071392454 | validation: 3.365804974821963]
	TIME [epoch: 24.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9144935706021937		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 3.9144935706021937 | validation: 3.4044023435583517]
	TIME [epoch: 24.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.701180585985605		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 3.701180585985605 | validation: 3.4782064253527576]
	TIME [epoch: 24.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.807317406389997		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 3.807317406389997 | validation: 3.6364515615472626]
	TIME [epoch: 24.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.927488720675642		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 3.927488720675642 | validation: 3.327912531611578]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.551079492528661		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 4.551079492528661 | validation: 3.7958799775754626]
	TIME [epoch: 24.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8543996900013187		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 3.8543996900013187 | validation: 3.398293476261607]
	TIME [epoch: 24.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.793495839393487		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 3.793495839393487 | validation: 3.4482352082279535]
	TIME [epoch: 24.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.743915333269737		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 3.743915333269737 | validation: 3.4272352443117313]
	TIME [epoch: 24.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7026724004642233		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 3.7026724004642233 | validation: 4.4000185239740714]
	TIME [epoch: 24.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9507183177854417		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 3.9507183177854417 | validation: 4.4333014058801385]
	TIME [epoch: 24.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.110782413757545		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 4.110782413757545 | validation: 3.88365944805559]
	TIME [epoch: 24.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.005170760223998		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 4.005170760223998 | validation: 3.5185188322700767]
	TIME [epoch: 24.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.937287885610516		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 3.937287885610516 | validation: 3.3360231229165964]
	TIME [epoch: 24.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.160702870658638		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 4.160702870658638 | validation: 3.4296583160807756]
	TIME [epoch: 24.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.928597484066782		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 3.928597484066782 | validation: 3.4044146552639543]
	TIME [epoch: 24.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.073437269091455		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 4.073437269091455 | validation: 3.5776187509727233]
	TIME [epoch: 24.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.052567566709265		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 4.052567566709265 | validation: 3.353208329700267]
	TIME [epoch: 24.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.748423526465264		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 3.748423526465264 | validation: 3.5299652287620247]
	TIME [epoch: 24.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7187377065745766		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 3.7187377065745766 | validation: 3.7535159000112204]
	TIME [epoch: 24.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.239424929921693		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 4.239424929921693 | validation: 3.4098610768408526]
	TIME [epoch: 24.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.871802148607346		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 3.871802148607346 | validation: 4.167969430469376]
	TIME [epoch: 24.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.011371162057282		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 4.011371162057282 | validation: 3.4180694238049423]
	TIME [epoch: 24.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.833049037597256		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 3.833049037597256 | validation: 3.2912635007945816]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7523471798905117		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 3.7523471798905117 | validation: 3.302311429559334]
	TIME [epoch: 24.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.786010758306521		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 3.786010758306521 | validation: 3.2767114248636493]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7641106368107726		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 3.7641106368107726 | validation: 3.414933718996281]
	TIME [epoch: 24.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6976455955234457		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 3.6976455955234457 | validation: 3.3926853102595063]
	TIME [epoch: 24.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.840148236878721		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 3.840148236878721 | validation: 3.271417772779404]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7363726622302935		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 3.7363726622302935 | validation: 3.5801909749187315]
	TIME [epoch: 24.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.778365687044653		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 3.778365687044653 | validation: 3.270311646069574]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8180548321100867		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 3.8180548321100867 | validation: 4.088629509495596]
	TIME [epoch: 24.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.089278839034294		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 4.089278839034294 | validation: 3.7036219845168503]
	TIME [epoch: 24.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.767532365434194		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 3.767532365434194 | validation: 3.3777847062733826]
	TIME [epoch: 24.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.672761248243863		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 3.672761248243863 | validation: 3.434226983070837]
	TIME [epoch: 24.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6893004586874216		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 3.6893004586874216 | validation: 3.2634380542665027]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.639286503654629		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 3.639286503654629 | validation: 3.4221441326050575]
	TIME [epoch: 24.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7077614134843513		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 3.7077614134843513 | validation: 3.2870015376828468]
	TIME [epoch: 24.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7303963182510804		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 3.7303963182510804 | validation: 3.2653590851716867]
	TIME [epoch: 24.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5975659610473816		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 3.5975659610473816 | validation: 3.721182600469409]
	TIME [epoch: 24.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9515112215706427		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 3.9515112215706427 | validation: 3.3228645408565116]
	TIME [epoch: 24.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9780191953536423		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 3.9780191953536423 | validation: 3.5166296845314715]
	TIME [epoch: 24.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8160441219960948		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 3.8160441219960948 | validation: 3.3143447498702905]
	TIME [epoch: 24.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7335367645750077		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 3.7335367645750077 | validation: 3.4825947428127235]
	TIME [epoch: 24.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.681712794158152		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 3.681712794158152 | validation: 3.8388396623370102]
	TIME [epoch: 24.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.731133696299142		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 3.731133696299142 | validation: 3.842019666285427]
	TIME [epoch: 24.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.734734205395724		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 3.734734205395724 | validation: 4.1478561017435345]
	TIME [epoch: 24.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.007618898408328		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 4.007618898408328 | validation: 3.9076011716002825]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.97322412122149		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 3.97322412122149 | validation: 3.8969776587126606]
	TIME [epoch: 24.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8333973243284194		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 3.8333973243284194 | validation: 3.4139396696309454]
	TIME [epoch: 24.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6761229533966144		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 3.6761229533966144 | validation: 3.3413568135568155]
	TIME [epoch: 24.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.778831283645945		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 3.778831283645945 | validation: 3.720129059939854]
	TIME [epoch: 24.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7773135069948856		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 3.7773135069948856 | validation: 3.6651714793960286]
	TIME [epoch: 24.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7747458558369673		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 3.7747458558369673 | validation: 4.177445092574234]
	TIME [epoch: 24.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1377204863169315		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 4.1377204863169315 | validation: 3.298683917604094]
	TIME [epoch: 24.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7888383975879982		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 3.7888383975879982 | validation: 3.308264441420975]
	TIME [epoch: 24.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.902978011092162		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 3.902978011092162 | validation: 3.6901861884625853]
	TIME [epoch: 24.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.756991648540543		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 3.756991648540543 | validation: 3.403384033957517]
	TIME [epoch: 24.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7140404260849307		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 3.7140404260849307 | validation: 3.4333099361320194]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6783276327038856		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 3.6783276327038856 | validation: 3.3120442433892343]
	TIME [epoch: 24.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7435556111864603		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 3.7435556111864603 | validation: 3.284499790423758]
	TIME [epoch: 24.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7963853951169297		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 3.7963853951169297 | validation: 3.2994672391178597]
	TIME [epoch: 24.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7811414803212844		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 3.7811414803212844 | validation: 3.890873313408595]
	TIME [epoch: 24.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8549104360158175		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 3.8549104360158175 | validation: 3.4356607967841515]
	TIME [epoch: 24.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7784615045441567		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 3.7784615045441567 | validation: 3.938608105796359]
	TIME [epoch: 24.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8609283334499063		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 3.8609283334499063 | validation: 3.5274515429290694]
	TIME [epoch: 24.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7819067521780676		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 3.7819067521780676 | validation: 3.7573753584053136]
	TIME [epoch: 24.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7924801537993797		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 3.7924801537993797 | validation: 3.2818712229957896]
	TIME [epoch: 24.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7061434776677897		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 3.7061434776677897 | validation: 3.3587284769140773]
	TIME [epoch: 24.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6502422574135736		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 3.6502422574135736 | validation: 3.3105659149422557]
	TIME [epoch: 24.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6356900216588124		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 3.6356900216588124 | validation: 3.294667568601393]
	TIME [epoch: 24.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6300842623652647		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 3.6300842623652647 | validation: 3.2783793164818724]
	TIME [epoch: 24.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6621649174009168		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 3.6621649174009168 | validation: 4.472737662688123]
	TIME [epoch: 24.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.973141233935354		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 3.973141233935354 | validation: 3.8604963885477823]
	TIME [epoch: 24.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9175150457423706		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 3.9175150457423706 | validation: 3.605753078215315]
	TIME [epoch: 24.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.670119005542684		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 3.670119005542684 | validation: 3.344740321948247]
	TIME [epoch: 24.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9494284694067976		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 3.9494284694067976 | validation: 3.6034562248058295]
	TIME [epoch: 24.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9540648649960373		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 3.9540648649960373 | validation: 3.421407723481373]
	TIME [epoch: 24.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6519676304129876		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 3.6519676304129876 | validation: 3.2466755919582524]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6720481098377444		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 3.6720481098377444 | validation: 3.3290987634418374]
	TIME [epoch: 24.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.596746986138718		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 3.596746986138718 | validation: 3.2352821709953328]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_351.pth
	Model improved!!!
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8102587765192255		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 3.8102587765192255 | validation: 3.3278487803029875]
	TIME [epoch: 24.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.686848506226534		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 3.686848506226534 | validation: 3.5915448342098073]
	TIME [epoch: 25 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6886735133156794		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 3.6886735133156794 | validation: 3.427842919433682]
	TIME [epoch: 24.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.675579947791869		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 3.675579947791869 | validation: 3.3471204537910775]
	TIME [epoch: 24.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8970753203939004		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 3.8970753203939004 | validation: 3.3975370701653196]
	TIME [epoch: 24.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6427488460477364		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 3.6427488460477364 | validation: 3.2407968839006704]
	TIME [epoch: 24.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7292615883975575		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 3.7292615883975575 | validation: 3.3210202197950456]
	TIME [epoch: 24.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.699557594735472		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 3.699557594735472 | validation: 3.5489959915322333]
	TIME [epoch: 24.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6336456139886204		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 3.6336456139886204 | validation: 3.3142125671502516]
	TIME [epoch: 24.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6114963788115753		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 3.6114963788115753 | validation: 3.5524642875057517]
	TIME [epoch: 24.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.755950979569133		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 3.755950979569133 | validation: 3.498580164704795]
	TIME [epoch: 25 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6232751568431594		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 3.6232751568431594 | validation: 3.4912252447437626]
	TIME [epoch: 24.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7423306045100926		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 3.7423306045100926 | validation: 3.2195206568379184]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.777922661867619		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 3.777922661867619 | validation: 3.282964634133485]
	TIME [epoch: 24.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5547419712467816		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 3.5547419712467816 | validation: 3.2272188174960945]
	TIME [epoch: 24.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5883669429694067		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 3.5883669429694067 | validation: 3.4467885158019183]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.61068079830323		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 3.61068079830323 | validation: 3.499849084080454]
	TIME [epoch: 25 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6827913734508186		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 3.6827913734508186 | validation: 3.2071997033657262]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_369.pth
	Model improved!!!
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7604939007144944		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 3.7604939007144944 | validation: 3.6290812416603213]
	TIME [epoch: 24.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.681438431080816		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 3.681438431080816 | validation: 3.412267657980591]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.661231706245167		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 3.661231706245167 | validation: 3.3334250577698716]
	TIME [epoch: 24.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.652775445388828		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 3.652775445388828 | validation: 3.342472854761462]
	TIME [epoch: 24.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.714530262742707		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 3.714530262742707 | validation: 3.4990046257532548]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.61442940690032		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 3.61442940690032 | validation: 3.2103384495629586]
	TIME [epoch: 24.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.817726731070413		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 3.817726731070413 | validation: 3.4534008649338217]
	TIME [epoch: 24.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.886233602827656		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 3.886233602827656 | validation: 3.3042130952958924]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.822526458645698		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 3.822526458645698 | validation: 3.331303664732851]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7769699998513815		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 3.7769699998513815 | validation: 3.2777856764018356]
	TIME [epoch: 24.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.665392741219124		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 3.665392741219124 | validation: 3.3023677952472683]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.56909382894052		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 3.56909382894052 | validation: 3.218724284893889]
	TIME [epoch: 24.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6649841056115426		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 3.6649841056115426 | validation: 3.368564482748336]
	TIME [epoch: 24.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.641813864000209		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 3.641813864000209 | validation: 3.2933116646365477]
	TIME [epoch: 24.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.601745377343133		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 3.601745377343133 | validation: 3.3064426882927216]
	TIME [epoch: 24.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.735732502676816		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 3.735732502676816 | validation: 3.2831394473108]
	TIME [epoch: 24.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.801905749708732		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 3.801905749708732 | validation: 3.409983256453649]
	TIME [epoch: 24.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.577502727503072		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 3.577502727503072 | validation: 3.259962054316899]
	TIME [epoch: 24.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.694825377478889		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 3.694825377478889 | validation: 3.214919066430075]
	TIME [epoch: 24.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.624833291836164		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 3.624833291836164 | validation: 3.9683066973959242]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.841381825357362		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 3.841381825357362 | validation: 3.241530374973379]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.684200626501422		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 3.684200626501422 | validation: 3.4613852682969215]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.664346326165723		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 3.664346326165723 | validation: 3.352357444171311]
	TIME [epoch: 24.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.565787976882687		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 3.565787976882687 | validation: 3.358328719263436]
	TIME [epoch: 24.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.579445354404525		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 3.579445354404525 | validation: 3.2672288875481947]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.544801790903425		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 3.544801790903425 | validation: 3.2821157892418826]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5961985830574976		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 3.5961985830574976 | validation: 3.3774003663327767]
	TIME [epoch: 24.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6335778682529463		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 3.6335778682529463 | validation: 3.20354888255423]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5589025008061985		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 3.5589025008061985 | validation: 3.33130021045882]
	TIME [epoch: 24.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5884682039192075		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 3.5884682039192075 | validation: 3.289570508332442]
	TIME [epoch: 24.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.63057478369229		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 3.63057478369229 | validation: 3.1903912976015927]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7250079306032804		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 3.7250079306032804 | validation: 3.7372573897223083]
	TIME [epoch: 24.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8364093897062053		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 3.8364093897062053 | validation: 3.2316646500813455]
	TIME [epoch: 24.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.536609430068637		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 3.536609430068637 | validation: 3.3914397105330636]
	TIME [epoch: 24.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.578839457388527		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 3.578839457388527 | validation: 3.4159919752341783]
	TIME [epoch: 24.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.60004610949769		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 3.60004610949769 | validation: 3.2371882457820504]
	TIME [epoch: 24.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5194630182223325		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 3.5194630182223325 | validation: 3.5912384914880113]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6768691071575854		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 3.6768691071575854 | validation: 3.2799928664424614]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7658861910917727		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 3.7658861910917727 | validation: 3.300908925578734]
	TIME [epoch: 24.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5505879777424987		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 3.5505879777424987 | validation: 3.3118454514074007]
	TIME [epoch: 24.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.854039581332363		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 3.854039581332363 | validation: 3.6196569942033228]
	TIME [epoch: 24.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6509070384904296		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 3.6509070384904296 | validation: 3.208787355937433]
	TIME [epoch: 24.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5722338445373865		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 3.5722338445373865 | validation: 3.9887300126361924]
	TIME [epoch: 24.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.797071075662629		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 3.797071075662629 | validation: 3.354969543772248]
	TIME [epoch: 24.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6617210123428947		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 3.6617210123428947 | validation: 3.1948572298557396]
	TIME [epoch: 24.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.573192848293622		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 3.573192848293622 | validation: 3.235008510698916]
	TIME [epoch: 24.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.567696680892911		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 3.567696680892911 | validation: 3.2454427255804372]
	TIME [epoch: 24.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.567151233419266		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 3.567151233419266 | validation: 3.5105744554802505]
	TIME [epoch: 24.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6101751705594074		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 3.6101751705594074 | validation: 3.4921637542557336]
	TIME [epoch: 24.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.65064832755179		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 3.65064832755179 | validation: 3.573513318415813]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.688672788271398		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 3.688672788271398 | validation: 3.4492567970040295]
	TIME [epoch: 24.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5490678945252316		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 3.5490678945252316 | validation: 3.3710912873360135]
	TIME [epoch: 24.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.582802097266802		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 3.582802097266802 | validation: 3.3495103640042503]
	TIME [epoch: 24.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6273778967149966		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 3.6273778967149966 | validation: 3.261978006544105]
	TIME [epoch: 24.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8311789452606932		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 3.8311789452606932 | validation: 3.2052286553833915]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5947754826377185		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 3.5947754826377185 | validation: 3.2289582428892825]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7592392692583796		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 3.7592392692583796 | validation: 3.310084875221279]
	TIME [epoch: 24.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6230925352941226		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 3.6230925352941226 | validation: 3.2004557077844416]
	TIME [epoch: 24.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.703649609398523		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 3.703649609398523 | validation: 3.198148322536968]
	TIME [epoch: 24.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7212859520212316		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 3.7212859520212316 | validation: 3.4825080717213894]
	TIME [epoch: 24.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.691635203029702		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 3.691635203029702 | validation: 3.44272228911474]
	TIME [epoch: 24.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6333262126183468		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 3.6333262126183468 | validation: 3.2068446012498124]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.516823802276825		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 3.516823802276825 | validation: 3.2241459548424554]
	TIME [epoch: 24.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.544468676632666		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 3.544468676632666 | validation: 3.544604831979971]
	TIME [epoch: 24.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.678279439749433		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 3.678279439749433 | validation: 3.1929159817498243]
	TIME [epoch: 24.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8238389158478956		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 3.8238389158478956 | validation: 3.2125289048447936]
	TIME [epoch: 24.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5569643723101594		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 3.5569643723101594 | validation: 3.24118948228096]
	TIME [epoch: 24.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7554632273388897		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 3.7554632273388897 | validation: 3.3182435597160866]
	TIME [epoch: 24.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.575930005103867		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 3.575930005103867 | validation: 3.2337601515083705]
	TIME [epoch: 24.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5201819396758043		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 3.5201819396758043 | validation: 3.289328540139993]
	TIME [epoch: 24.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.540480022280241		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 3.540480022280241 | validation: 3.442524591551121]
	TIME [epoch: 24.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5574330819792066		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 3.5574330819792066 | validation: 3.3766856298967793]
	TIME [epoch: 24.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.558053782752775		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 3.558053782752775 | validation: 3.213531685722631]
	TIME [epoch: 24.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.559062288107652		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 3.559062288107652 | validation: 3.2899700802223584]
	TIME [epoch: 24.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.536990489438546		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 3.536990489438546 | validation: 3.298755823162744]
	TIME [epoch: 24.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.583574549242164		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 3.583574549242164 | validation: 3.4164292308207087]
	TIME [epoch: 24.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.627927042327115		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 3.627927042327115 | validation: 3.2191043742090915]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.547165754353904		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 3.547165754353904 | validation: 3.309908565932909]
	TIME [epoch: 24.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.548674589502042		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 3.548674589502042 | validation: 3.221838418105653]
	TIME [epoch: 24.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.56388021329004		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 3.56388021329004 | validation: 3.283939618158236]
	TIME [epoch: 24.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6065530354968853		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 3.6065530354968853 | validation: 3.301358727447708]
	TIME [epoch: 24.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5427011217914153		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 3.5427011217914153 | validation: 3.2680679589253754]
	TIME [epoch: 24.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5072030700824186		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 3.5072030700824186 | validation: 3.214331431220436]
	TIME [epoch: 24.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.531357524552697		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 3.531357524552697 | validation: 3.2891330703638086]
	TIME [epoch: 24.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.631124129337426		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 3.631124129337426 | validation: 3.2666914229689255]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.542528968377309		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 3.542528968377309 | validation: 3.2696139307393066]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.501943955123035		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 3.501943955123035 | validation: 3.1967841473663534]
	TIME [epoch: 24.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.629638567908784		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 3.629638567908784 | validation: 3.281610108919602]
	TIME [epoch: 24.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.508721902349225		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 3.508721902349225 | validation: 3.2134066281102696]
	TIME [epoch: 24.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5161371331453832		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 3.5161371331453832 | validation: 3.286381398516962]
	TIME [epoch: 24.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5262452568372695		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 3.5262452568372695 | validation: 3.18355860246487]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5166182218440376		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 3.5166182218440376 | validation: 3.1871279679477595]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5523036884019312		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 3.5523036884019312 | validation: 3.1921577331379707]
	TIME [epoch: 24.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.573145539436107		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 3.573145539436107 | validation: 3.824322292393301]
	TIME [epoch: 24.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.716746028501267		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 3.716746028501267 | validation: 3.3486574302816003]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.607364378513369		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 3.607364378513369 | validation: 3.1927504736037378]
	TIME [epoch: 25 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.497828659399967		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 3.497828659399967 | validation: 3.1595594594545897]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5872165493671146		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 3.5872165493671146 | validation: 3.2075813211376314]
	TIME [epoch: 25 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7284045032804567		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 3.7284045032804567 | validation: 3.248963995650953]
	TIME [epoch: 25 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5256955733924507		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 3.5256955733924507 | validation: 3.368489953942798]
	TIME [epoch: 24.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5542692231146717		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 3.5542692231146717 | validation: 3.397770588064759]
	TIME [epoch: 24.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5963656459285174		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 3.5963656459285174 | validation: 3.1952928343518288]
	TIME [epoch: 24.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6167707284872206		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 3.6167707284872206 | validation: 3.281516062829792]
	TIME [epoch: 24.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.616708762626838		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 3.616708762626838 | validation: 3.550927626352837]
	TIME [epoch: 25 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6733197187916327		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 3.6733197187916327 | validation: 3.2006906075572297]
	TIME [epoch: 25 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.472732846079724		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 3.472732846079724 | validation: 3.447013319181268]
	TIME [epoch: 25 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6497818699267888		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 3.6497818699267888 | validation: 3.438394015731392]
	TIME [epoch: 25 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7455956502215937		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 3.7455956502215937 | validation: 3.2707485214634984]
	TIME [epoch: 25 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.511180458059694		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 3.511180458059694 | validation: 3.189456257594035]
	TIME [epoch: 24.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4972267164364097		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 3.4972267164364097 | validation: 3.2654190606519387]
	TIME [epoch: 25 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5848610253856843		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 3.5848610253856843 | validation: 3.171060808805927]
	TIME [epoch: 25 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.610959416013601		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 3.610959416013601 | validation: 3.3583519725266116]
	TIME [epoch: 24.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.546338330931563		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 3.546338330931563 | validation: 3.2057258094073062]
	TIME [epoch: 24.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5083753166723164		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 3.5083753166723164 | validation: 3.21285000456778]
	TIME [epoch: 25 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5718295545803205		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 3.5718295545803205 | validation: 3.2920727747644123]
	TIME [epoch: 24.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5372410416726234		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 3.5372410416726234 | validation: 3.37516595679399]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.594902079295001		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 3.594902079295001 | validation: 3.2170617043225893]
	TIME [epoch: 25 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5003573225954785		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 3.5003573225954785 | validation: 3.151438752120629]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.577022034029727		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 3.577022034029727 | validation: 3.4428372969273617]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.012465325799828		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 4.012465325799828 | validation: 3.216250462946772]
	TIME [epoch: 25 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.632711657276976		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 3.632711657276976 | validation: 3.2135953447700896]
	TIME [epoch: 24.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4755021317748516		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 3.4755021317748516 | validation: 3.1572926337578906]
	TIME [epoch: 24.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4913136228079127		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 3.4913136228079127 | validation: 3.2211504147118295]
	TIME [epoch: 25 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5282916895454846		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 3.5282916895454846 | validation: 3.21775566108151]
	TIME [epoch: 25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5157271142823188		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 3.5157271142823188 | validation: 3.1598334220533344]
	TIME [epoch: 25 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6276797493342703		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 3.6276797493342703 | validation: 3.2815920332437747]
	TIME [epoch: 25 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.530364061201216		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 3.530364061201216 | validation: 3.2393423721892316]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.646404686479911		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 3.646404686479911 | validation: 3.169334439092886]
	TIME [epoch: 24.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4505530262158537		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 3.4505530262158537 | validation: 3.424165433628133]
	TIME [epoch: 24.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6305538924353713		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 3.6305538924353713 | validation: 3.248923165259427]
	TIME [epoch: 24.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.493975418480979		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 3.493975418480979 | validation: 3.372112884633884]
	TIME [epoch: 24.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.52190243112763		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 3.52190243112763 | validation: 3.2107369811055584]
	TIME [epoch: 25 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5910264338657676		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 3.5910264338657676 | validation: 3.2293507718753336]
	TIME [epoch: 24.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.493166506255368		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 3.493166506255368 | validation: 3.183972560593848]
	TIME [epoch: 24.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5142106651084895		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 3.5142106651084895 | validation: 3.5931286007453775]
	TIME [epoch: 25 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5915492768325157		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 3.5915492768325157 | validation: 3.205975380656213]
	TIME [epoch: 25 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4788793631355746		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 3.4788793631355746 | validation: 3.299235413696731]
	TIME [epoch: 25 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5209327923872893		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 3.5209327923872893 | validation: 3.1639692880459394]
	TIME [epoch: 25 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.570079702238207		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 3.570079702238207 | validation: 3.5528711342722183]
	TIME [epoch: 24.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.656886974003514		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 3.656886974003514 | validation: 3.5506642804655257]
	TIME [epoch: 24.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.589547374841396		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 3.589547374841396 | validation: 3.2429785959890935]
	TIME [epoch: 25 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4959629176632254		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 3.4959629176632254 | validation: 3.2108319941843626]
	TIME [epoch: 24.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4747644383248106		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 3.4747644383248106 | validation: 3.241639672981437]
	TIME [epoch: 25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.508728012520564		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 3.508728012520564 | validation: 3.200149767832745]
	TIME [epoch: 25 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6729720952135176		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 3.6729720952135176 | validation: 3.5046223247427175]
	TIME [epoch: 24.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5321895657594427		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 3.5321895657594427 | validation: 3.1884404123450243]
	TIME [epoch: 24.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.569823457765277		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 3.569823457765277 | validation: 3.339696158772473]
	TIME [epoch: 25 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5275080003708013		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 3.5275080003708013 | validation: 3.3245950017900623]
	TIME [epoch: 25 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4790988336514705		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 3.4790988336514705 | validation: 3.1808944097605694]
	TIME [epoch: 25 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.475963617411945		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 3.475963617411945 | validation: 3.4081152713679383]
	TIME [epoch: 25 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6132887533631277		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 3.6132887533631277 | validation: 3.2548292570919655]
	TIME [epoch: 25 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.549831222372029		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 3.549831222372029 | validation: 3.1690581354476843]
	TIME [epoch: 24.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.470002520131936		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 3.470002520131936 | validation: 3.24040458051412]
	TIME [epoch: 24.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.468292555283954		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 3.468292555283954 | validation: 3.257410141363887]
	TIME [epoch: 24.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.55259493935205		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 3.55259493935205 | validation: 3.168052216963594]
	TIME [epoch: 24.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.523434396020223		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 3.523434396020223 | validation: 3.4537574779944107]
	TIME [epoch: 25 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5663994475401797		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 3.5663994475401797 | validation: 3.5325110916764606]
	TIME [epoch: 24.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6252163857180344		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 3.6252163857180344 | validation: 3.1638791976694933]
	TIME [epoch: 24.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5587095081616242		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 3.5587095081616242 | validation: 3.671703273180449]
	TIME [epoch: 24.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.61754683681937		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 3.61754683681937 | validation: 3.1395772114385267]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.487023565441707		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 3.487023565441707 | validation: 3.2462115037749015]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.503253797501923		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 3.503253797501923 | validation: 3.320981238341651]
	TIME [epoch: 25 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5633208177568982		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 3.5633208177568982 | validation: 3.3020869670977446]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5886817500252226		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 3.5886817500252226 | validation: 3.3418682861055435]
	TIME [epoch: 24.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.540320823005276		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 3.540320823005276 | validation: 3.241971967305643]
	TIME [epoch: 25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.49393345344688		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 3.49393345344688 | validation: 3.271989467395356]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.514167277671529		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 3.514167277671529 | validation: 3.2043766349104397]
	TIME [epoch: 24.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4639724162259284		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 3.4639724162259284 | validation: 3.3527721947431]
	TIME [epoch: 25 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.539482843930254		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 3.539482843930254 | validation: 3.26134904340076]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5913387585999734		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 3.5913387585999734 | validation: 3.2226587279266545]
	TIME [epoch: 24.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4729265579198074		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 3.4729265579198074 | validation: 3.287187002920351]
	TIME [epoch: 25 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4968333125125586		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 3.4968333125125586 | validation: 3.314963409414911]
	TIME [epoch: 24.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.537744484072773		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 3.537744484072773 | validation: 3.3623292350982905]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.511525080419391		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 3.511525080419391 | validation: 3.3824013140756404]
	TIME [epoch: 25 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5331518810293066		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 3.5331518810293066 | validation: 3.498798219518272]
	TIME [epoch: 24.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5979920578636158		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 3.5979920578636158 | validation: 3.1641586066933054]
	TIME [epoch: 25 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.476332969262921		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 3.476332969262921 | validation: 3.388303699415209]
	TIME [epoch: 24.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.557072854947392		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 3.557072854947392 | validation: 3.4693204938078814]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.616439987418718		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 3.616439987418718 | validation: 3.232056077125078]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5763543983450234		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 3.5763543983450234 | validation: 3.3832170298979882]
	TIME [epoch: 25 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5252099480618146		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 3.5252099480618146 | validation: 3.154653175765941]
	TIME [epoch: 25 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5514198786233497		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 3.5514198786233497 | validation: 3.155629810746765]
	TIME [epoch: 24.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.45511679313402		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 3.45511679313402 | validation: 3.2196925531920106]
	TIME [epoch: 25 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5750481834515053		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 3.5750481834515053 | validation: 3.514905508239116]
	TIME [epoch: 25 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5794460990944725		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 3.5794460990944725 | validation: 3.168112399764378]
	TIME [epoch: 24.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.509578056898621		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 3.509578056898621 | validation: 3.180333590730603]
	TIME [epoch: 25 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4750817824218343		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 3.4750817824218343 | validation: 3.2065539361496382]
	TIME [epoch: 25 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4692872408250173		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 3.4692872408250173 | validation: 3.2322837227415953]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.574443968649952		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 3.574443968649952 | validation: 3.3232512665162814]
	TIME [epoch: 25 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.507103762166544		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 3.507103762166544 | validation: 3.218404047052983]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.498882661526165		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 3.498882661526165 | validation: 3.2065612185909944]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.501220813496542		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 3.501220813496542 | validation: 3.234381123252133]
	TIME [epoch: 25 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.531250275173045		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 3.531250275173045 | validation: 3.201715043286478]
	TIME [epoch: 25 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5093806356271458		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 3.5093806356271458 | validation: 3.1477291083483943]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4337144742600896		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 3.4337144742600896 | validation: 3.204234758422528]
	TIME [epoch: 24.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6536636335956603		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 3.6536636335956603 | validation: 3.5959291017578856]
	TIME [epoch: 25 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7509869240743257		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 3.7509869240743257 | validation: 3.4495938916952444]
	TIME [epoch: 24.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.735678545005296		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 3.735678545005296 | validation: 3.2171505006153347]
	TIME [epoch: 25 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.55538928361321		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 3.55538928361321 | validation: 3.1999974277792576]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5050306382107546		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 3.5050306382107546 | validation: 3.1715210199117583]
	TIME [epoch: 25 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5044499693556848		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 3.5044499693556848 | validation: 3.1458359750337967]
	TIME [epoch: 25 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4584635206610344		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 3.4584635206610344 | validation: 3.1717916637964914]
	TIME [epoch: 25 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5357544448089917		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 3.5357544448089917 | validation: 3.457111017650729]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5486179432770264		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 3.5486179432770264 | validation: 3.1598670164625577]
	TIME [epoch: 25 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4805728747285687		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 3.4805728747285687 | validation: 3.383877267579448]
	TIME [epoch: 25 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5698639322194348		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 3.5698639322194348 | validation: 3.29882788048801]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.487094424863405		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 3.487094424863405 | validation: 3.265777361037273]
	TIME [epoch: 25 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4693239211119637		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 3.4693239211119637 | validation: 3.271083442923475]
	TIME [epoch: 25 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5136723336949656		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 3.5136723336949656 | validation: 3.2607412573032644]
	TIME [epoch: 25 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.604386588981063		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 3.604386588981063 | validation: 3.249494216507883]
	TIME [epoch: 25 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5214011128284106		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 3.5214011128284106 | validation: 3.1703372569291504]
	TIME [epoch: 25 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4661269791587093		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 3.4661269791587093 | validation: 3.2854371148780683]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5229126911096573		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 3.5229126911096573 | validation: 3.2610205304179107]
	TIME [epoch: 25 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.50508844358938		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 3.50508844358938 | validation: 3.272608875796312]
	TIME [epoch: 25 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.538000298913934		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 3.538000298913934 | validation: 3.3582892407134324]
	TIME [epoch: 24.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.568045147111417		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 3.568045147111417 | validation: 3.269533150370451]
	TIME [epoch: 24.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.49882641660104		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 3.49882641660104 | validation: 3.347978237921858]
	TIME [epoch: 25 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.491097064794903		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 3.491097064794903 | validation: 3.2046548800980053]
	TIME [epoch: 24.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4974474584803907		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 3.4974474584803907 | validation: 3.220128045608516]
	TIME [epoch: 25 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5336963989595214		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 3.5336963989595214 | validation: 3.1843894658671683]
	TIME [epoch: 25 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4754976739846617		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 3.4754976739846617 | validation: 3.2588544265184853]
	TIME [epoch: 24.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.494417672046979		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 3.494417672046979 | validation: 3.23088436038739]
	TIME [epoch: 25 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4646601978881315		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 3.4646601978881315 | validation: 3.3148744683113307]
	TIME [epoch: 25 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5801356084304023		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 3.5801356084304023 | validation: 3.213654011042229]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.48062286742221		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 3.48062286742221 | validation: 3.232662164987927]
	TIME [epoch: 24.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4723590413391117		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 3.4723590413391117 | validation: 3.5507000258483834]
	TIME [epoch: 25 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6109957489860327		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 3.6109957489860327 | validation: 3.218255927261038]
	TIME [epoch: 24.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4694872450541414		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 3.4694872450541414 | validation: 3.1816644473439175]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4772986437663636		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 3.4772986437663636 | validation: 3.202378479314627]
	TIME [epoch: 25 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4606444257159916		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 3.4606444257159916 | validation: 3.1556463033709203]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4874287165668973		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 3.4874287165668973 | validation: 3.185390920368103]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.465468115151319		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 3.465468115151319 | validation: 3.147636670518864]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4607560113595466		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 3.4607560113595466 | validation: 3.2278398706796105]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5969738997372755		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 3.5969738997372755 | validation: 3.1977228263144646]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4978370601138806		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 3.4978370601138806 | validation: 3.157628972470035]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4800872392274043		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 3.4800872392274043 | validation: 3.3412728752182983]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5108760290454883		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 3.5108760290454883 | validation: 3.191573253005407]
	TIME [epoch: 24.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4866002195945436		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 3.4866002195945436 | validation: 3.209602546692878]
	TIME [epoch: 25 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.515221787866774		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 3.515221787866774 | validation: 3.220695999246643]
	TIME [epoch: 24.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4863066956261806		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 3.4863066956261806 | validation: 3.185641397892204]
	TIME [epoch: 24.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.532916361600313		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 3.532916361600313 | validation: 3.2051573944102607]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.439512738420472		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 3.439512738420472 | validation: 3.2630988826899]
	TIME [epoch: 24.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4633670934325513		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 3.4633670934325513 | validation: 3.199600040493359]
	TIME [epoch: 24.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4416530824386964		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 3.4416530824386964 | validation: 3.261447954399947]
	TIME [epoch: 24.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.461801952968475		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 3.461801952968475 | validation: 3.1944879253249163]
	TIME [epoch: 24.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4474213279299297		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 3.4474213279299297 | validation: 3.1791416632747773]
	TIME [epoch: 24.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5222265317335353		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 3.5222265317335353 | validation: 3.2346710275806596]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4594139082048008		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 3.4594139082048008 | validation: 3.267094900653959]
	TIME [epoch: 24.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4606496609919564		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 3.4606496609919564 | validation: 3.1679570274737627]
	TIME [epoch: 25 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4480242311510754		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 3.4480242311510754 | validation: 3.1530043964936953]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4910482094656383		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 3.4910482094656383 | validation: 3.1530750859557233]
	TIME [epoch: 24.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4843151324167843		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 3.4843151324167843 | validation: 3.1679463410928053]
	TIME [epoch: 24.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4708136644950334		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 3.4708136644950334 | validation: 3.357168341387421]
	TIME [epoch: 25 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5061153475226945		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 3.5061153475226945 | validation: 3.150545704391922]
	TIME [epoch: 25 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.452508897710529		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 3.452508897710529 | validation: 3.1573654069189185]
	TIME [epoch: 24.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.462578140447901		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 3.462578140447901 | validation: 3.1853050318843374]
	TIME [epoch: 25 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.429955083111424		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 3.429955083111424 | validation: 3.270580613763532]
	TIME [epoch: 25 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.463630010036489		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 3.463630010036489 | validation: 3.1509576538515853]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.56718114974509		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 3.56718114974509 | validation: 3.1500184322399676]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.518713363698192		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 3.518713363698192 | validation: 3.2984346114817003]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.469651672812964		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 3.469651672812964 | validation: 3.1290625565183787]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4431292780016154		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 3.4431292780016154 | validation: 3.1784241571129463]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4526173571455976		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 3.4526173571455976 | validation: 3.1824251115599647]
	TIME [epoch: 24.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4292091467272465		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 3.4292091467272465 | validation: 3.148842045481655]
	TIME [epoch: 24.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4811491314470304		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 3.4811491314470304 | validation: 3.2756804538351436]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5430146246949725		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 3.5430146246949725 | validation: 3.564954097941296]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5549714280822107		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 3.5549714280822107 | validation: 3.141741589056238]
	TIME [epoch: 24.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4683357585054173		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 3.4683357585054173 | validation: 3.190590080860112]
	TIME [epoch: 24.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4546070604711896		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 3.4546070604711896 | validation: 3.2235072449580686]
	TIME [epoch: 24.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4861990962064504		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 3.4861990962064504 | validation: 3.138917779575412]
	TIME [epoch: 24.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.452741089025758		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 3.452741089025758 | validation: 3.18140159264221]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4670281009946677		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 3.4670281009946677 | validation: 3.171549371791109]
	TIME [epoch: 24.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.482824577528977		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 3.482824577528977 | validation: 3.181505120682822]
	TIME [epoch: 24.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.431353243566196		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 3.431353243566196 | validation: 3.388716372777317]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4839602027121224		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 3.4839602027121224 | validation: 3.167921835870447]
	TIME [epoch: 24.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4540568395224467		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 3.4540568395224467 | validation: 3.314657557303361]
	TIME [epoch: 24.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4841687028066533		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 3.4841687028066533 | validation: 3.164510033690129]
	TIME [epoch: 24.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.431558629322938		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 3.431558629322938 | validation: 3.434345408970551]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5055102428519853		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 3.5055102428519853 | validation: 3.1889120169748786]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.431207320332528		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 3.431207320332528 | validation: 3.323066024587853]
	TIME [epoch: 25 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4590833710504616		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 3.4590833710504616 | validation: 3.157032062348201]
	TIME [epoch: 24.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.576808702538207		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 3.576808702538207 | validation: 3.5017934994877327]
	TIME [epoch: 24.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5044147425482675		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 3.5044147425482675 | validation: 3.193133848955596]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4443937079050158		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 3.4443937079050158 | validation: 3.182333002418095]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4284786368134514		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 3.4284786368134514 | validation: 3.1476694055181746]
	TIME [epoch: 24.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.460655819283306		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 3.460655819283306 | validation: 3.1298372385158104]
	TIME [epoch: 24.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.492216128372308		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 3.492216128372308 | validation: 3.3972996487235627]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5416242626817		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 3.5416242626817 | validation: 3.177926432985153]
	TIME [epoch: 24.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.468350327783692		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 3.468350327783692 | validation: 3.2787086134157724]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4769646311402362		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 3.4769646311402362 | validation: 3.1440133714600638]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.451696677191726		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 3.451696677191726 | validation: 3.2298401088248045]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.448921310026976		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 3.448921310026976 | validation: 3.1500445736760287]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.475006911196703		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 3.475006911196703 | validation: 3.1420457053889472]
	TIME [epoch: 25 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4334223336905314		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 3.4334223336905314 | validation: 3.1326614842355607]
	TIME [epoch: 25 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.450358199045574		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 3.450358199045574 | validation: 3.1929921498602485]
	TIME [epoch: 25 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.43322199365386		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 3.43322199365386 | validation: 3.1383819379221007]
	TIME [epoch: 25 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.451335863353506		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 3.451335863353506 | validation: 3.2169450692761674]
	TIME [epoch: 24.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4528524069088244		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 3.4528524069088244 | validation: 3.130281645626338]
	TIME [epoch: 25 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4629153499090837		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 3.4629153499090837 | validation: 3.2347199924006693]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.464555623013547		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 3.464555623013547 | validation: 3.130502575774962]
	TIME [epoch: 24.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.496052659953571		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 3.496052659953571 | validation: 3.2100300259748833]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4382236537377255		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 3.4382236537377255 | validation: 3.139157167547686]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.443324855127911		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 3.443324855127911 | validation: 3.118090232662746]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_672.pth
	Model improved!!!
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4199694964805953		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 3.4199694964805953 | validation: 3.1866023179915635]
	TIME [epoch: 25 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.457577932968634		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 3.457577932968634 | validation: 3.1901142561046245]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.466301761715512		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 3.466301761715512 | validation: 3.1772519818044955]
	TIME [epoch: 24.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.503017548597128		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 3.503017548597128 | validation: 3.1496004463458838]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.461165954611576		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 3.461165954611576 | validation: 3.181728390825209]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4393127824266156		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 3.4393127824266156 | validation: 3.12801981094417]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5035114089436385		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 3.5035114089436385 | validation: 3.2757263061672153]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5076227190454405		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 3.5076227190454405 | validation: 3.147283952806431]
	TIME [epoch: 25 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4431114675194303		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 3.4431114675194303 | validation: 3.1210274576827395]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.418267156004251		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 3.418267156004251 | validation: 3.134628110011621]
	TIME [epoch: 25 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.516249188149058		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 3.516249188149058 | validation: 3.1712301090810078]
	TIME [epoch: 25 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4387371844128825		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 3.4387371844128825 | validation: 3.2710327195475024]
	TIME [epoch: 24.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.451224197355446		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 3.451224197355446 | validation: 3.19809409965654]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4940097024688734		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 3.4940097024688734 | validation: 3.1301776376851898]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.443618195494155		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 3.443618195494155 | validation: 3.1284633727590787]
	TIME [epoch: 24.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4112426967614824		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 3.4112426967614824 | validation: 3.2381721268275476]
	TIME [epoch: 25 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4526309889575133		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 3.4526309889575133 | validation: 3.1186401381732822]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4463493120486746		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 3.4463493120486746 | validation: 3.1538310746608205]
	TIME [epoch: 25 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4384313345528255		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 3.4384313345528255 | validation: 3.1300240465801212]
	TIME [epoch: 24.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.427992270023441		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 3.427992270023441 | validation: 3.227174139575585]
	TIME [epoch: 25 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4447332895453284		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 3.4447332895453284 | validation: 3.1819204197323177]
	TIME [epoch: 25 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4409505538750573		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 3.4409505538750573 | validation: 3.242574111757841]
	TIME [epoch: 25 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4678831466408098		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 3.4678831466408098 | validation: 3.163768874805057]
	TIME [epoch: 25 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4186256870021343		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 3.4186256870021343 | validation: 3.1780080987506087]
	TIME [epoch: 24.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4705889047060365		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 3.4705889047060365 | validation: 3.1755256979757576]
	TIME [epoch: 25 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.430323712939278		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 3.430323712939278 | validation: 3.149753700725745]
	TIME [epoch: 24.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4179656018067983		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 3.4179656018067983 | validation: 3.246334701001857]
	TIME [epoch: 25 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5191726368141802		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 3.5191726368141802 | validation: 3.233961229415969]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4739371165717916		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 3.4739371165717916 | validation: 3.422680219502712]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5036572447662433		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 3.5036572447662433 | validation: 3.1731740676567943]
	TIME [epoch: 24.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4863348376840646		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 3.4863348376840646 | validation: 3.1389701912059156]
	TIME [epoch: 24.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.445029495658983		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 3.445029495658983 | validation: 3.130203194556201]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4106304803358354		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 3.4106304803358354 | validation: 3.13356347841598]
	TIME [epoch: 24.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4169563881882667		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 3.4169563881882667 | validation: 3.2957385099458123]
	TIME [epoch: 25 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.513677558927029		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 3.513677558927029 | validation: 3.1431154911367134]
	TIME [epoch: 25 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4456651032276904		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 3.4456651032276904 | validation: 3.163402580715573]
	TIME [epoch: 24.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4580396178347943		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 3.4580396178347943 | validation: 3.141483061949622]
	TIME [epoch: 24.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.423722760962241		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 3.423722760962241 | validation: 3.2136293697752936]
	TIME [epoch: 25 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.485087193511527		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 3.485087193511527 | validation: 3.236484003017589]
	TIME [epoch: 24.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.462024036741744		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 3.462024036741744 | validation: 3.1480156050140797]
	TIME [epoch: 25 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4161096435279266		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 3.4161096435279266 | validation: 3.127217985826972]
	TIME [epoch: 25 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.444021107664198		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 3.444021107664198 | validation: 3.2000169947442374]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.467401950821893		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 3.467401950821893 | validation: 3.3363129935250364]
	TIME [epoch: 24.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.494249870884329		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 3.494249870884329 | validation: 3.404029878979533]
	TIME [epoch: 24.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5088680930828353		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 3.5088680930828353 | validation: 3.1607527436631315]
	TIME [epoch: 24.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.445040386733771		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 3.445040386733771 | validation: 3.2560415999586936]
	TIME [epoch: 25 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.459401096911182		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 3.459401096911182 | validation: 3.1563493392065727]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4543250877441514		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 3.4543250877441514 | validation: 3.194788046527202]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4951687263151117		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 3.4951687263151117 | validation: 3.165719663640569]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4392351488615605		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 3.4392351488615605 | validation: 3.188939245436141]
	TIME [epoch: 25 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.420816888364739		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 3.420816888364739 | validation: 3.159311175149968]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.420689965574641		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 3.420689965574641 | validation: 3.210826072997461]
	TIME [epoch: 25 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.494427263377678		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 3.494427263377678 | validation: 3.15329252096808]
	TIME [epoch: 25 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4357115897196104		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 3.4357115897196104 | validation: 3.2468756897147353]
	TIME [epoch: 24.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4924126692987816		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 3.4924126692987816 | validation: 3.1806317522822587]
	TIME [epoch: 25 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4403889815862456		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 3.4403889815862456 | validation: 3.1692724139401047]
	TIME [epoch: 25 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.427424083164876		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 3.427424083164876 | validation: 3.131531319242189]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4244801847057866		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 3.4244801847057866 | validation: 3.246037579910568]
	TIME [epoch: 25 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.434646135174267		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 3.434646135174267 | validation: 3.1236266340258623]
	TIME [epoch: 25 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4380472268114106		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 3.4380472268114106 | validation: 3.1397741965873935]
	TIME [epoch: 24.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4119852936808663		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 3.4119852936808663 | validation: 3.1314582797808748]
	TIME [epoch: 25 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.47287560032572		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 3.47287560032572 | validation: 3.1506813939791325]
	TIME [epoch: 25 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4539749138263556		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 3.4539749138263556 | validation: 3.186758340731012]
	TIME [epoch: 24.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4206773725880404		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 3.4206773725880404 | validation: 3.1251264778985535]
	TIME [epoch: 24.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4258955070295483		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 3.4258955070295483 | validation: 3.19394094288049]
	TIME [epoch: 25 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.42219075381802		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 3.42219075381802 | validation: 3.159395148488767]
	TIME [epoch: 24.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.472497735794031		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 3.472497735794031 | validation: 3.392012101937683]
	TIME [epoch: 24.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4757225960852978		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 3.4757225960852978 | validation: 3.206114318569745]
	TIME [epoch: 25 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4463344419757176		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 3.4463344419757176 | validation: 3.2546957040315814]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.476835967184397		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 3.476835967184397 | validation: 3.1623398063103947]
	TIME [epoch: 25 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4003278178885945		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 3.4003278178885945 | validation: 3.1532727503472113]
	TIME [epoch: 24.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4445657282145112		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 3.4445657282145112 | validation: 3.141492779933344]
	TIME [epoch: 25 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4273648489196384		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 3.4273648489196384 | validation: 3.174623508861878]
	TIME [epoch: 24.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.433120447937428		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 3.433120447937428 | validation: 3.243482492936409]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.456046956995708		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 3.456046956995708 | validation: 3.161535200750129]
	TIME [epoch: 24.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4387652364162866		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 3.4387652364162866 | validation: 3.1315667276764794]
	TIME [epoch: 25 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4369714291829703		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 3.4369714291829703 | validation: 3.1508416590278046]
	TIME [epoch: 25 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4283831556586666		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 3.4283831556586666 | validation: 3.131406809490743]
	TIME [epoch: 25 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4160318243020202		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 3.4160318243020202 | validation: 3.129979177999058]
	TIME [epoch: 25 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4326725670595666		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 3.4326725670595666 | validation: 3.1717784989386315]
	TIME [epoch: 25 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.431285342927202		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 3.431285342927202 | validation: 3.2066566631571263]
	TIME [epoch: 24.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4408371412232346		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 3.4408371412232346 | validation: 3.286111986441349]
	TIME [epoch: 24.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.483206534189459		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 3.483206534189459 | validation: 3.2459063888574895]
	TIME [epoch: 25 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.480622876587071		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 3.480622876587071 | validation: 3.187813569474213]
	TIME [epoch: 24.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.442947525755713		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 3.442947525755713 | validation: 3.159124464013125]
	TIME [epoch: 25 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4761560213650258		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 3.4761560213650258 | validation: 3.111898567898762]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4015114856122484		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 3.4015114856122484 | validation: 3.133118387733469]
	TIME [epoch: 24.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4002346879434686		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 3.4002346879434686 | validation: 3.1466260654660907]
	TIME [epoch: 24.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4171719736936663		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 3.4171719736936663 | validation: 3.1320028693663007]
	TIME [epoch: 24.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4300001791249475		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 3.4300001791249475 | validation: 3.182078995216079]
	TIME [epoch: 25 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.429587579109991		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 3.429587579109991 | validation: 3.1466664750608966]
	TIME [epoch: 25 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.394625061055708		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 3.394625061055708 | validation: 3.15151342012947]
	TIME [epoch: 25 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4368118514936503		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 3.4368118514936503 | validation: 3.1569561276210107]
	TIME [epoch: 24.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.438223215417457		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 3.438223215417457 | validation: 3.1545917554245184]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.425250585134651		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 3.425250585134651 | validation: 3.2020091089008527]
	TIME [epoch: 25 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4440675070892124		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 3.4440675070892124 | validation: 3.184057884971792]
	TIME [epoch: 24.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5037537037208546		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 3.5037537037208546 | validation: 3.1796658332271317]
	TIME [epoch: 24.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4261264590910687		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 3.4261264590910687 | validation: 3.1282045511820304]
	TIME [epoch: 24.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4267335846937055		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 3.4267335846937055 | validation: 3.684813290464051]
	TIME [epoch: 24.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7119083015746144		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 3.7119083015746144 | validation: 3.18217928022987]
	TIME [epoch: 24.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4300879523986256		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 3.4300879523986256 | validation: 3.138149055937187]
	TIME [epoch: 25 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3975813612302623		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 3.3975813612302623 | validation: 3.1166446965578194]
	TIME [epoch: 24.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405489194453448		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 3.405489194453448 | validation: 3.1742362300287246]
	TIME [epoch: 24.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4231042996468695		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 3.4231042996468695 | validation: 3.1633032550282474]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4392494924517947		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 3.4392494924517947 | validation: 3.1249328502180522]
	TIME [epoch: 24.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.429627141080751		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 3.429627141080751 | validation: 3.1753010636032424]
	TIME [epoch: 24.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4479391393261247		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 3.4479391393261247 | validation: 3.1753621973485395]
	TIME [epoch: 24.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.485599492220871		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 3.485599492220871 | validation: 3.1399258029205943]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4030677645184695		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 3.4030677645184695 | validation: 3.2446940124218417]
	TIME [epoch: 24.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.492083292855202		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 3.492083292855202 | validation: 3.2063617384367253]
	TIME [epoch: 24.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4208491441379936		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 3.4208491441379936 | validation: 3.160546923157225]
	TIME [epoch: 24.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4000588334737896		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 3.4000588334737896 | validation: 3.141741268270152]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4040963549780554		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 3.4040963549780554 | validation: 3.1354526046854665]
	TIME [epoch: 24.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4208528760529946		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 3.4208528760529946 | validation: 3.2448241626827397]
	TIME [epoch: 24.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.445649088653461		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 3.445649088653461 | validation: 3.1645986762619738]
	TIME [epoch: 24.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4267698744786634		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 3.4267698744786634 | validation: 3.130184595267644]
	TIME [epoch: 24.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5150191758932205		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 3.5150191758932205 | validation: 3.1138610545698624]
	TIME [epoch: 24.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4267776625499886		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 3.4267776625499886 | validation: 3.1821030207364784]
	TIME [epoch: 24.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4159568520710644		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 3.4159568520710644 | validation: 3.1691968027257422]
	TIME [epoch: 25 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4204025101915176		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 3.4204025101915176 | validation: 3.1788978268146146]
	TIME [epoch: 24.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.413012716405425		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 3.413012716405425 | validation: 3.1283865731146627]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4114101511587704		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 3.4114101511587704 | validation: 3.2101612140773916]
	TIME [epoch: 24.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.441418517544606		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 3.441418517544606 | validation: 3.145328346236049]
	TIME [epoch: 24.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4587262910337166		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 3.4587262910337166 | validation: 3.1888871003744077]
	TIME [epoch: 24.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4310387670514806		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 3.4310387670514806 | validation: 3.1203543300996786]
	TIME [epoch: 25 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4308292663075353		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 3.4308292663075353 | validation: 3.1969907393964627]
	TIME [epoch: 24.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4290965697448277		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 3.4290965697448277 | validation: 3.133569810659446]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395180773575563		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 3.395180773575563 | validation: 3.141048928930449]
	TIME [epoch: 25 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405187457162521		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 3.405187457162521 | validation: 3.11109688484485]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4068627389065558		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 3.4068627389065558 | validation: 3.220968605011667]
	TIME [epoch: 24.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4276016775683953		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 3.4276016775683953 | validation: 3.213797209848126]
	TIME [epoch: 24.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.436106004689189		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 3.436106004689189 | validation: 3.1227968621910276]
	TIME [epoch: 24.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.466667698893932		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 3.466667698893932 | validation: 3.1431749570722003]
	TIME [epoch: 24.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.435326974607626		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 3.435326974607626 | validation: 3.1952905602514945]
	TIME [epoch: 24.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4457415620092617		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 3.4457415620092617 | validation: 3.1800410103621477]
	TIME [epoch: 24.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.421928193100398		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 3.421928193100398 | validation: 3.135634705599081]
	TIME [epoch: 24.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4605053424145265		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 3.4605053424145265 | validation: 3.156268885386997]
	TIME [epoch: 24.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6363620511393404		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 3.6363620511393404 | validation: 3.2799229832508185]
	TIME [epoch: 24.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4809466083004152		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 3.4809466083004152 | validation: 3.2129120824065036]
	TIME [epoch: 24.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4075864403538083		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 3.4075864403538083 | validation: 3.122556513158894]
	TIME [epoch: 24.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4296142419857243		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 3.4296142419857243 | validation: 3.129283347570053]
	TIME [epoch: 24.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.404207236516038		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 3.404207236516038 | validation: 3.1362504684605677]
	TIME [epoch: 24.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4111986655608235		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 3.4111986655608235 | validation: 3.111811868960142]
	TIME [epoch: 25 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.406642701372217		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 3.406642701372217 | validation: 3.121316935955016]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4120504092686557		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 3.4120504092686557 | validation: 3.1210181158904495]
	TIME [epoch: 24.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.402537207329813		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 3.402537207329813 | validation: 3.14397148160521]
	TIME [epoch: 25 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4033159566891875		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 3.4033159566891875 | validation: 3.1882429314108154]
	TIME [epoch: 24.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4654946463260754		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 3.4654946463260754 | validation: 3.183048227250176]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4203521944883812		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 3.4203521944883812 | validation: 3.131078518772154]
	TIME [epoch: 24.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.437772360337274		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 3.437772360337274 | validation: 3.132865237158917]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.435296684524856		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 3.435296684524856 | validation: 3.1634834923337896]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4324218276642844		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 3.4324218276642844 | validation: 3.1215302376905734]
	TIME [epoch: 25 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4167711644107532		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 3.4167711644107532 | validation: 3.1292837680917067]
	TIME [epoch: 25 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405176254272962		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 3.405176254272962 | validation: 3.124980340944287]
	TIME [epoch: 24.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.415732065226117		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 3.415732065226117 | validation: 3.1421926710188544]
	TIME [epoch: 25 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.406621300056375		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 3.406621300056375 | validation: 3.114161598598215]
	TIME [epoch: 24.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4133028780120425		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 3.4133028780120425 | validation: 3.1302852444396727]
	TIME [epoch: 24.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.391171626014581		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 3.391171626014581 | validation: 3.1086595115353015]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_830.pth
	Model improved!!!
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4088935598788943		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 3.4088935598788943 | validation: 3.154771945965249]
	TIME [epoch: 25 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4123460098146086		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 3.4123460098146086 | validation: 3.1277887185565785]
	TIME [epoch: 24.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4111311947079117		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 3.4111311947079117 | validation: 3.124730128703926]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4011166151698524		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 3.4011166151698524 | validation: 3.1201035220990336]
	TIME [epoch: 24.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4243354804302744		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 3.4243354804302744 | validation: 3.118239670631551]
	TIME [epoch: 24.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4183214802155604		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 3.4183214802155604 | validation: 3.1552240152111732]
	TIME [epoch: 24.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.408559505683968		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 3.408559505683968 | validation: 3.1170567693065427]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393175806447789		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 3.393175806447789 | validation: 3.125915773748115]
	TIME [epoch: 24.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4127973308749384		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 3.4127973308749384 | validation: 3.256103433857131]
	TIME [epoch: 24.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4758755975962314		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 3.4758755975962314 | validation: 3.1107088033538264]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3931471985919073		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 3.3931471985919073 | validation: 3.1244724967059554]
	TIME [epoch: 24.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4817878585874844		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 3.4817878585874844 | validation: 3.129236322606299]
	TIME [epoch: 24.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4123471424071647		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 3.4123471424071647 | validation: 3.1301649126328357]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.44256326048742		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 3.44256326048742 | validation: 3.113656392163347]
	TIME [epoch: 24.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4263662989626895		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 3.4263662989626895 | validation: 3.1068447051015675]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_845.pth
	Model improved!!!
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.387864368016018		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 3.387864368016018 | validation: 3.1199945479361646]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.408164058707859		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 3.408164058707859 | validation: 3.1842280178650055]
	TIME [epoch: 24.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4152903523886433		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 3.4152903523886433 | validation: 3.117178981561699]
	TIME [epoch: 24.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5035189252295496		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 3.5035189252295496 | validation: 3.2160608974951983]
	TIME [epoch: 24.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4126773412953457		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 3.4126773412953457 | validation: 3.142964751124517]
	TIME [epoch: 24.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4111130537587173		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 3.4111130537587173 | validation: 3.1843429197192497]
	TIME [epoch: 24.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.415554850225667		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 3.415554850225667 | validation: 3.113110972802664]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4102146951720615		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 3.4102146951720615 | validation: 3.1100476212173214]
	TIME [epoch: 24.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.400800252522261		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 3.400800252522261 | validation: 3.160293864448208]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.40329019355516		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 3.40329019355516 | validation: 3.1263335780064607]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.399510912329942		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 3.399510912329942 | validation: 3.1145049186929716]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3867868680569115		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 3.3867868680569115 | validation: 3.105131323434381]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_857.pth
	Model improved!!!
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405395769898724		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 3.405395769898724 | validation: 3.1655289026729028]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.413947761821927		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 3.413947761821927 | validation: 3.1336121788169944]
	TIME [epoch: 24.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3899664908552447		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 3.3899664908552447 | validation: 3.1473074808228634]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.401313476994639		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 3.401313476994639 | validation: 3.1346345329502743]
	TIME [epoch: 24.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.400222519842077		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 3.400222519842077 | validation: 3.1872208869131247]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4204183829569765		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 3.4204183829569765 | validation: 3.1591653640857715]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4197227781352924		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 3.4197227781352924 | validation: 3.1096007015317113]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.406543512943043		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 3.406543512943043 | validation: 3.107147966520856]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4154182307964396		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 3.4154182307964396 | validation: 3.160370452640907]
	TIME [epoch: 24.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.418339758772073		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 3.418339758772073 | validation: 3.146670319464255]
	TIME [epoch: 24.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.449434958874354		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 3.449434958874354 | validation: 3.1035978271374143]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_868.pth
	Model improved!!!
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4355604215481863		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 3.4355604215481863 | validation: 3.110953205255419]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382184914186759		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 3.382184914186759 | validation: 3.123626664521207]
	TIME [epoch: 24.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3949822388468056		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 3.3949822388468056 | validation: 3.127241495017287]
	TIME [epoch: 24.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.417477857511681		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 3.417477857511681 | validation: 3.2058327258801977]
	TIME [epoch: 24.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.444558050342948		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 3.444558050342948 | validation: 3.2016986615811027]
	TIME [epoch: 24.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.421831077442273		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 3.421831077442273 | validation: 3.1727057086420354]
	TIME [epoch: 24.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4149380814765196		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 3.4149380814765196 | validation: 3.135544635345103]
	TIME [epoch: 24.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3919316985806076		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 3.3919316985806076 | validation: 3.1083347911459875]
	TIME [epoch: 24.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3918334710438454		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 3.3918334710438454 | validation: 3.1064646993483187]
	TIME [epoch: 24.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4035886964928523		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 3.4035886964928523 | validation: 3.136309197788675]
	TIME [epoch: 24.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3972393165890837		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 3.3972393165890837 | validation: 3.1165741143361743]
	TIME [epoch: 24.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4306335818515774		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 3.4306335818515774 | validation: 3.1161888246534053]
	TIME [epoch: 24.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.418536723894439		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 3.418536723894439 | validation: 3.163455350429119]
	TIME [epoch: 24.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4042907709191983		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 3.4042907709191983 | validation: 3.1355662254403214]
	TIME [epoch: 24.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.404000476340835		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 3.404000476340835 | validation: 3.1123028848429626]
	TIME [epoch: 24.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.427252232939749		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 3.427252232939749 | validation: 3.106044994763892]
	TIME [epoch: 24.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3891301849258695		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 3.3891301849258695 | validation: 3.159809457430106]
	TIME [epoch: 24.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3982101567138576		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 3.3982101567138576 | validation: 3.176129226309717]
	TIME [epoch: 24.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4161703423943934		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 3.4161703423943934 | validation: 3.164488023716182]
	TIME [epoch: 24.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4054212691891776		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 3.4054212691891776 | validation: 3.0960470561001454]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_888.pth
	Model improved!!!
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.412462639912073		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 3.412462639912073 | validation: 3.1176286432613836]
	TIME [epoch: 24.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.391885835098848		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 3.391885835098848 | validation: 3.124232421290385]
	TIME [epoch: 24.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.400502867431435		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 3.400502867431435 | validation: 3.096638588131118]
	TIME [epoch: 24.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.396401839648813		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 3.396401839648813 | validation: 3.1250926164494888]
	TIME [epoch: 24.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395346466839401		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 3.395346466839401 | validation: 3.1216243450753804]
	TIME [epoch: 24.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.409797309636676		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 3.409797309636676 | validation: 3.1216868085305065]
	TIME [epoch: 24.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3859125832138113		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 3.3859125832138113 | validation: 3.113973157910849]
	TIME [epoch: 24.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.41702003778501		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 3.41702003778501 | validation: 3.226157730586576]
	TIME [epoch: 24.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4405751369934783		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 3.4405751369934783 | validation: 3.115711715523169]
	TIME [epoch: 24.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395864787188752		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 3.395864787188752 | validation: 3.1110134654434383]
	TIME [epoch: 24.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.398541917261873		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 3.398541917261873 | validation: 3.124908426674275]
	TIME [epoch: 24.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4059151366842544		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 3.4059151366842544 | validation: 3.151288207170254]
	TIME [epoch: 24.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4010735141013884		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 3.4010735141013884 | validation: 3.1158788552807004]
	TIME [epoch: 24.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39228550974458		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 3.39228550974458 | validation: 3.162634712011233]
	TIME [epoch: 24.9 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4051735491496613		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 3.4051735491496613 | validation: 3.125059246699061]
	TIME [epoch: 24.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.416816244286771		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 3.416816244286771 | validation: 3.1512353171197165]
	TIME [epoch: 24.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4075845939297325		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 3.4075845939297325 | validation: 3.136313155115662]
	TIME [epoch: 24.9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4060318867479777		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 3.4060318867479777 | validation: 3.11398152258819]
	TIME [epoch: 24.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393260188896829		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 3.393260188896829 | validation: 3.1339198448230086]
	TIME [epoch: 24.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.396042520542751		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 3.396042520542751 | validation: 3.1743307789899995]
	TIME [epoch: 24.9 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.400945330275501		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 3.400945330275501 | validation: 3.193374979552683]
	TIME [epoch: 24.9 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4065534654452763		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 3.4065534654452763 | validation: 3.1049934307926503]
	TIME [epoch: 24.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3876830028391125		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 3.3876830028391125 | validation: 3.196009794212344]
	TIME [epoch: 24.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.413736420275784		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 3.413736420275784 | validation: 3.125731723174272]
	TIME [epoch: 24.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3942579891884437		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 3.3942579891884437 | validation: 3.1462162107379266]
	TIME [epoch: 24.9 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.427738581051342		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 3.427738581051342 | validation: 3.1178400645933317]
	TIME [epoch: 24.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393900100134022		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 3.393900100134022 | validation: 3.1350406906569894]
	TIME [epoch: 24.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3980619564456918		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 3.3980619564456918 | validation: 3.1327662363086617]
	TIME [epoch: 24.9 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4626942799649756		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 3.4626942799649756 | validation: 3.151525735151008]
	TIME [epoch: 24.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405730391849217		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 3.405730391849217 | validation: 3.118308472334171]
	TIME [epoch: 24.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.400006534679007		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 3.400006534679007 | validation: 3.205159897610962]
	TIME [epoch: 24.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4257040681887343		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 3.4257040681887343 | validation: 3.139459793957077]
	TIME [epoch: 24.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.424553591276025		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 3.424553591276025 | validation: 3.1299690275700596]
	TIME [epoch: 24.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3926653852194653		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 3.3926653852194653 | validation: 3.143572054251314]
	TIME [epoch: 24.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3876079642454617		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 3.3876079642454617 | validation: 3.095268761750347]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_923.pth
	Model improved!!!
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4007407829300327		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 3.4007407829300327 | validation: 3.1398469907620545]
	TIME [epoch: 24.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4157426123487475		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 3.4157426123487475 | validation: 3.1445737546879107]
	TIME [epoch: 24.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3984350565441526		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 3.3984350565441526 | validation: 3.1163885495336467]
	TIME [epoch: 24.9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3969953898091525		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 3.3969953898091525 | validation: 3.1415367613749403]
	TIME [epoch: 24.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4114149178942226		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 3.4114149178942226 | validation: 3.1670851441246133]
	TIME [epoch: 24.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4101403225471647		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 3.4101403225471647 | validation: 3.1326247050581304]
	TIME [epoch: 24.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.390906399826984		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 3.390906399826984 | validation: 3.1185414659429904]
	TIME [epoch: 24.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4166611561638973		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 3.4166611561638973 | validation: 3.1308413920454017]
	TIME [epoch: 24.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.402454009017793		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 3.402454009017793 | validation: 3.100913575261665]
	TIME [epoch: 24.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.38264419544907		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 3.38264419544907 | validation: 3.1048362606304334]
	TIME [epoch: 24.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.406857552325307		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 3.406857552325307 | validation: 3.104579681306525]
	TIME [epoch: 24.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4055420098789804		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 3.4055420098789804 | validation: 3.1346871226324184]
	TIME [epoch: 24.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.40601779022096		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 3.40601779022096 | validation: 3.1128248249689388]
	TIME [epoch: 24.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3812019721536855		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 3.3812019721536855 | validation: 3.1534483751211613]
	TIME [epoch: 24.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.431658977435941		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 3.431658977435941 | validation: 3.1428518987249925]
	TIME [epoch: 24.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4043328445146557		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 3.4043328445146557 | validation: 3.1051421568700692]
	TIME [epoch: 24.9 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.418761081339381		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 3.418761081339381 | validation: 3.116828179319166]
	TIME [epoch: 24.9 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3848151475900936		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 3.3848151475900936 | validation: 3.1035277793070146]
	TIME [epoch: 24.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3790547558217505		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 3.3790547558217505 | validation: 3.11297762733739]
	TIME [epoch: 24.9 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.37904600714511		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 3.37904600714511 | validation: 3.100875797193018]
	TIME [epoch: 24.9 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3844850262736914		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 3.3844850262736914 | validation: 3.12314228274739]
	TIME [epoch: 24.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.406244449744515		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 3.406244449744515 | validation: 3.1088213764244834]
	TIME [epoch: 24.9 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.391724612415251		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 3.391724612415251 | validation: 3.104554107961931]
	TIME [epoch: 24.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3966083720336497		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 3.3966083720336497 | validation: 3.130247047840038]
	TIME [epoch: 24.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3818635900640563		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 3.3818635900640563 | validation: 3.0988664887000534]
	TIME [epoch: 24.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382432148567119		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 3.382432148567119 | validation: 3.1055142526243573]
	TIME [epoch: 24.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.38056032222518		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 3.38056032222518 | validation: 3.1238412238278195]
	TIME [epoch: 24.9 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382550147174455		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 3.382550147174455 | validation: 3.131817625505308]
	TIME [epoch: 24.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4361583578129715		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 3.4361583578129715 | validation: 3.113344553362233]
	TIME [epoch: 24.9 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3929734619208656		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 3.3929734619208656 | validation: 3.15217064083772]
	TIME [epoch: 24.9 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.392606075662931		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 3.392606075662931 | validation: 3.126981936470222]
	TIME [epoch: 24.9 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.388731175189076		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 3.388731175189076 | validation: 3.1514046081106875]
	TIME [epoch: 24.9 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3983623833006216		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 3.3983623833006216 | validation: 3.1147652508949495]
	TIME [epoch: 24.9 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3872664001065846		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 3.3872664001065846 | validation: 3.1653635389083044]
	TIME [epoch: 24.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4213430685935884		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 3.4213430685935884 | validation: 3.1330599500182683]
	TIME [epoch: 24.9 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.408171241990498		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 3.408171241990498 | validation: 3.109655002854401]
	TIME [epoch: 24.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.394732193613287		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 3.394732193613287 | validation: 3.122307932799339]
	TIME [epoch: 24.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.410323796772384		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 3.410323796772384 | validation: 3.1325653101253437]
	TIME [epoch: 24.9 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.384125104250929		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 3.384125104250929 | validation: 3.1157920694148507]
	TIME [epoch: 24.9 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3980260848245787		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 3.3980260848245787 | validation: 3.115706430292157]
	TIME [epoch: 24.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3921750835026225		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 3.3921750835026225 | validation: 3.121489190094219]
	TIME [epoch: 24.9 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3836052132430634		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 3.3836052132430634 | validation: 3.1061690068145213]
	TIME [epoch: 24.9 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3891968615079255		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 3.3891968615079255 | validation: 3.1233292081038484]
	TIME [epoch: 24.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3950398464723026		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 3.3950398464723026 | validation: 3.1313413550336135]
	TIME [epoch: 24.9 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4054202542438756		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 3.4054202542438756 | validation: 3.111594770232104]
	TIME [epoch: 24.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4036719455685334		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 3.4036719455685334 | validation: 3.121987164283857]
	TIME [epoch: 24.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3802159248955173		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 3.3802159248955173 | validation: 3.1068509059326095]
	TIME [epoch: 24.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.391237282999845		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 3.391237282999845 | validation: 3.1255048678613253]
	TIME [epoch: 24.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.404061830748599		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 3.404061830748599 | validation: 3.126890336210276]
	TIME [epoch: 24.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3856187051861433		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 3.3856187051861433 | validation: 3.1187227212205553]
	TIME [epoch: 24.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.385646419179727		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 3.385646419179727 | validation: 3.1220353310109528]
	TIME [epoch: 24.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393521577198915		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 3.393521577198915 | validation: 3.110739906958081]
	TIME [epoch: 24.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3785815977718707		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 3.3785815977718707 | validation: 3.1135684983412095]
	TIME [epoch: 24.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3867367350036726		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 3.3867367350036726 | validation: 3.126406755949601]
	TIME [epoch: 24.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.425596507077046		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 3.425596507077046 | validation: 3.176633799748091]
	TIME [epoch: 24.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4270957004897467		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 3.4270957004897467 | validation: 3.1625046704045277]
	TIME [epoch: 24.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3991137020626976		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 3.3991137020626976 | validation: 3.121980595657674]
	TIME [epoch: 24.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3946841326714887		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 3.3946841326714887 | validation: 3.1514969342532773]
	TIME [epoch: 24.9 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3883630237768063		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 3.3883630237768063 | validation: 3.1078238156405824]
	TIME [epoch: 24.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3894958196227414		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 3.3894958196227414 | validation: 3.1486515623466897]
	TIME [epoch: 24.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39996195432904		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 3.39996195432904 | validation: 3.19633747431961]
	TIME [epoch: 24.9 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.397118626447794		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 3.397118626447794 | validation: 3.104288103752972]
	TIME [epoch: 24.9 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.417892185293339		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 3.417892185293339 | validation: 3.1362217298278723]
	TIME [epoch: 24.9 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.40518945722837		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 3.40518945722837 | validation: 3.10100514309166]
	TIME [epoch: 24.9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382554367569707		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 3.382554367569707 | validation: 3.122233269131152]
	TIME [epoch: 24.9 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.377655324537912		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 3.377655324537912 | validation: 3.1000838475705548]
	TIME [epoch: 24.9 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4094823867818085		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 3.4094823867818085 | validation: 3.1413773681609065]
	TIME [epoch: 24.9 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3803680669324514		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 3.3803680669324514 | validation: 3.1009060289876835]
	TIME [epoch: 24.9 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.392712064638183		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 3.392712064638183 | validation: 3.103200928532291]
	TIME [epoch: 24.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3934098773248658		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 3.3934098773248658 | validation: 3.115609395316655]
	TIME [epoch: 24.9 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.392780308169322		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 3.392780308169322 | validation: 3.1425794321588967]
	TIME [epoch: 24.9 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3853639874965094		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 3.3853639874965094 | validation: 3.1068093978650073]
	TIME [epoch: 24.9 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.40905311348623		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 3.40905311348623 | validation: 3.136505156250223]
	TIME [epoch: 24.9 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3972855729974825		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 3.3972855729974825 | validation: 3.167731663855862]
	TIME [epoch: 24.9 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5216421274424503		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 3.5216421274424503 | validation: 3.118865455431771]
	TIME [epoch: 24.9 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.407476109016473		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 3.407476109016473 | validation: 3.182177775325333]
	TIME [epoch: 24.9 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.398358574577111		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 3.398358574577111 | validation: 3.100767392917016]
	TIME [epoch: 24.9 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.383201250924345		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 3.383201250924345 | validation: 3.105421731713189]
	TIME [epoch: 24.9 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3826054193154635		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 3.3826054193154635 | validation: 3.1037074607150408]
	TIME [epoch: 24.9 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.389349072016769		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 3.389349072016769 | validation: 3.107162802432569]
	TIME [epoch: 24.9 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.406324394705535		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 3.406324394705535 | validation: 3.1354966008287715]
	TIME [epoch: 24.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.403391108008858		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 3.403391108008858 | validation: 3.111090768511636]
	TIME [epoch: 24.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3869165762869646		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 3.3869165762869646 | validation: 3.0919895045103107]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_1006.pth
	Model improved!!!
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3903622063729446		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 3.3903622063729446 | validation: 3.1092335095540147]
	TIME [epoch: 24.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4013640281445343		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 3.4013640281445343 | validation: 3.1095610272105167]
	TIME [epoch: 24.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4019439662453745		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 3.4019439662453745 | validation: 3.1209087428905877]
	TIME [epoch: 24.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.38646753775551		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 3.38646753775551 | validation: 3.1150904138138347]
	TIME [epoch: 24.9 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4057908618188266		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 3.4057908618188266 | validation: 3.2005589070109512]
	TIME [epoch: 24.9 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395992909987103		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 3.395992909987103 | validation: 3.095519290552094]
	TIME [epoch: 24.9 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376216606105544		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 3.376216606105544 | validation: 3.1097499245685105]
	TIME [epoch: 24.9 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3814715100500705		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 3.3814715100500705 | validation: 3.1006780084342775]
	TIME [epoch: 24.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3848617582020553		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 3.3848617582020553 | validation: 3.120206320082695]
	TIME [epoch: 24.9 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.38748816384374		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 3.38748816384374 | validation: 3.1273827052639174]
	TIME [epoch: 24.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3911789819937708		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 3.3911789819937708 | validation: 3.13117854553919]
	TIME [epoch: 24.9 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3852645898185663		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 3.3852645898185663 | validation: 3.1200596095934108]
	TIME [epoch: 24.9 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.387239073560897		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 3.387239073560897 | validation: 3.1037121844694737]
	TIME [epoch: 24.9 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3818738103282096		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 3.3818738103282096 | validation: 3.1012685482543816]
	TIME [epoch: 24.9 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3866602651506863		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 3.3866602651506863 | validation: 3.120318824173817]
	TIME [epoch: 24.9 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3828185112309312		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 3.3828185112309312 | validation: 3.0987333428633765]
	TIME [epoch: 24.9 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395170006360237		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 3.395170006360237 | validation: 3.1090287255896443]
	TIME [epoch: 24.9 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3880319046074843		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 3.3880319046074843 | validation: 3.1487457422687823]
	TIME [epoch: 24.9 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3870282381180967		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 3.3870282381180967 | validation: 3.113057427775107]
	TIME [epoch: 24.9 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3876654856608703		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 3.3876654856608703 | validation: 3.121401605467556]
	TIME [epoch: 25 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.386212954310477		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 3.386212954310477 | validation: 3.126422510351789]
	TIME [epoch: 25 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3805112926388707		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 3.3805112926388707 | validation: 3.1057699340938703]
	TIME [epoch: 24.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.38945266762837		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 3.38945266762837 | validation: 3.0999032767283428]
	TIME [epoch: 24.9 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.377341114653748		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 3.377341114653748 | validation: 3.120040300991793]
	TIME [epoch: 24.9 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.381887130774204		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 3.381887130774204 | validation: 3.1138810374606622]
	TIME [epoch: 24.9 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4457589456904545		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 3.4457589456904545 | validation: 3.15101507833418]
	TIME [epoch: 25 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.410725346172701		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 3.410725346172701 | validation: 3.0992512057400883]
	TIME [epoch: 24.9 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.389839193321758		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 3.389839193321758 | validation: 3.120159082344756]
	TIME [epoch: 24.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4020018524663724		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 3.4020018524663724 | validation: 3.1315344079996716]
	TIME [epoch: 25 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3900731542005706		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 3.3900731542005706 | validation: 3.1031304247200597]
	TIME [epoch: 24.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3824932720363137		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 3.3824932720363137 | validation: 3.0986187463320602]
	TIME [epoch: 24.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.37538128014134		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 3.37538128014134 | validation: 3.1087611499693093]
	TIME [epoch: 25 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3804546189825846		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 3.3804546189825846 | validation: 3.1219457666863524]
	TIME [epoch: 24.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3840136457518573		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 3.3840136457518573 | validation: 3.113779584517495]
	TIME [epoch: 24.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380820043348554		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 3.380820043348554 | validation: 3.101360184089664]
	TIME [epoch: 24.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3962039397041623		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 3.3962039397041623 | validation: 3.108357649304431]
	TIME [epoch: 24.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3858237588358677		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 3.3858237588358677 | validation: 3.1198892717466538]
	TIME [epoch: 24.9 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.38695579628893		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 3.38695579628893 | validation: 3.126997309238669]
	TIME [epoch: 25 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.397875853705541		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 3.397875853705541 | validation: 3.148350753998357]
	TIME [epoch: 25 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3916281380435924		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 3.3916281380435924 | validation: 3.103104699164457]
	TIME [epoch: 24.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3977666371614323		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 3.3977666371614323 | validation: 3.1310146343214886]
	TIME [epoch: 25 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3882834750720767		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 3.3882834750720767 | validation: 3.101329703525763]
	TIME [epoch: 25 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.37748709381603		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 3.37748709381603 | validation: 3.106298702326201]
	TIME [epoch: 25 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39542689319024		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 3.39542689319024 | validation: 3.1236891899667647]
	TIME [epoch: 25 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3852351686221063		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 3.3852351686221063 | validation: 3.0946569350870936]
	TIME [epoch: 25 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.37363056872002		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 3.37363056872002 | validation: 3.101468441747331]
	TIME [epoch: 24.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3843474442867985		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 3.3843474442867985 | validation: 3.1093518869164156]
	TIME [epoch: 24.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3875663535511573		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 3.3875663535511573 | validation: 3.1468591654332783]
	TIME [epoch: 25 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3963282771880214		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 3.3963282771880214 | validation: 3.1215697990539457]
	TIME [epoch: 24.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378814719460558		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 3.378814719460558 | validation: 3.125887128582092]
	TIME [epoch: 24.9 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3869528442756494		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 3.3869528442756494 | validation: 3.1340698071678355]
	TIME [epoch: 25 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3911422455507845		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 3.3911422455507845 | validation: 3.1284095918191874]
	TIME [epoch: 25 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3802790959288256		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 3.3802790959288256 | validation: 3.120915782367965]
	TIME [epoch: 25 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3890562178867105		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 3.3890562178867105 | validation: 3.0925917104889242]
	TIME [epoch: 25 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3724963785531714		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 3.3724963785531714 | validation: 3.111579206802683]
	TIME [epoch: 25 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3845355433281865		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 3.3845355433281865 | validation: 3.1067191040915487]
	TIME [epoch: 24.9 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.398477610106026		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 3.398477610106026 | validation: 3.1042882591836993]
	TIME [epoch: 25 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3746591801320225		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 3.3746591801320225 | validation: 3.1045673362104798]
	TIME [epoch: 25 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3943068216623766		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 3.3943068216623766 | validation: 3.1298527331365205]
	TIME [epoch: 25 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4016849042220505		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 3.4016849042220505 | validation: 3.125599397915522]
	TIME [epoch: 25 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.407310290609944		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 3.407310290609944 | validation: 3.138320052061014]
	TIME [epoch: 24.9 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3753110199259497		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 3.3753110199259497 | validation: 3.1343650359118227]
	TIME [epoch: 25 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.40276664661607		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 3.40276664661607 | validation: 3.1152808476737164]
	TIME [epoch: 25 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4273358281598867		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 3.4273358281598867 | validation: 3.1267826269606314]
	TIME [epoch: 25 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3923662955709877		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 3.3923662955709877 | validation: 3.104546130787096]
	TIME [epoch: 25 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3840031664966586		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 3.3840031664966586 | validation: 3.129416761642707]
	TIME [epoch: 25 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3805670014251277		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 3.3805670014251277 | validation: 3.091907871214933]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_1073.pth
	Model improved!!!
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3752600944831403		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 3.3752600944831403 | validation: 3.089197243613398]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_1074.pth
	Model improved!!!
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4180167994447075		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 3.4180167994447075 | validation: 3.1863680463898936]
	TIME [epoch: 25 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.413740780809662		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 3.413740780809662 | validation: 3.1270731719081635]
	TIME [epoch: 24.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3936801414926836		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 3.3936801414926836 | validation: 3.1124782622615523]
	TIME [epoch: 24.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3960139558077653		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 3.3960139558077653 | validation: 3.1537589261664456]
	TIME [epoch: 24.9 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4063334800272225		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 3.4063334800272225 | validation: 3.1061805712615365]
	TIME [epoch: 24.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3802315935115996		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 3.3802315935115996 | validation: 3.0997020548913645]
	TIME [epoch: 24.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3827814691347964		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 3.3827814691347964 | validation: 3.105686656074104]
	TIME [epoch: 25 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3802275594821247		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 3.3802275594821247 | validation: 3.108654173701262]
	TIME [epoch: 24.9 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3833257642203898		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 3.3833257642203898 | validation: 3.1216773620823877]
	TIME [epoch: 24.9 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.375585226979962		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 3.375585226979962 | validation: 3.0935608311411107]
	TIME [epoch: 25 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3818129941562196		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 3.3818129941562196 | validation: 3.108708889845741]
	TIME [epoch: 24.9 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373562567927739		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 3.373562567927739 | validation: 3.118379571363746]
	TIME [epoch: 25 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3753935115047558		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 3.3753935115047558 | validation: 3.1106292636227186]
	TIME [epoch: 25 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379598551023046		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 3.379598551023046 | validation: 3.095225706221526]
	TIME [epoch: 25 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3881910926452514		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 3.3881910926452514 | validation: 3.1129738655382977]
	TIME [epoch: 24.9 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3798043401291356		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 3.3798043401291356 | validation: 3.1099630562644482]
	TIME [epoch: 25 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3775543988831505		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 3.3775543988831505 | validation: 3.1108317294730865]
	TIME [epoch: 24.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3887503040235485		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 3.3887503040235485 | validation: 3.1055227880139924]
	TIME [epoch: 24.9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376590495375264		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 3.376590495375264 | validation: 3.137394339099837]
	TIME [epoch: 24.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3913079370715886		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 3.3913079370715886 | validation: 3.1136314062861925]
	TIME [epoch: 24.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3774145857734306		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 3.3774145857734306 | validation: 3.1018825551939893]
	TIME [epoch: 24.9 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3732767656585843		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 3.3732767656585843 | validation: 3.106997559768172]
	TIME [epoch: 24.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.386535215701397		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 3.386535215701397 | validation: 3.0937685199454643]
	TIME [epoch: 24.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3813570434404556		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 3.3813570434404556 | validation: 3.100157974206778]
	TIME [epoch: 24.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.372877200836292		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 3.372877200836292 | validation: 3.0926079548947705]
	TIME [epoch: 24.9 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3820534827332733		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 3.3820534827332733 | validation: 3.101846813736238]
	TIME [epoch: 24.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.388618296156535		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 3.388618296156535 | validation: 3.104941965497169]
	TIME [epoch: 24.9 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.375085110087982		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 3.375085110087982 | validation: 3.0966457832958576]
	TIME [epoch: 24.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3771165646590253		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 3.3771165646590253 | validation: 3.098620647939067]
	TIME [epoch: 24.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3814752361444476		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 3.3814752361444476 | validation: 3.096067162888447]
	TIME [epoch: 24.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3765147853216084		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 3.3765147853216084 | validation: 3.122025008573286]
	TIME [epoch: 24.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3805693445268816		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 3.3805693445268816 | validation: 3.1102789098778674]
	TIME [epoch: 24.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378571823304996		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 3.378571823304996 | validation: 3.100894060097247]
	TIME [epoch: 24.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376905043152435		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 3.376905043152435 | validation: 3.157751793160274]
	TIME [epoch: 24.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.392195513995203		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 3.392195513995203 | validation: 3.1106071104736532]
	TIME [epoch: 24.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3878972153806752		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 3.3878972153806752 | validation: 3.1524724562920854]
	TIME [epoch: 24.9 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3963509816345874		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 3.3963509816345874 | validation: 3.0995859578066236]
	TIME [epoch: 24.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380637278840256		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 3.380637278840256 | validation: 3.1181939194510195]
	TIME [epoch: 24.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3798003030311126		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 3.3798003030311126 | validation: 3.1147940552295417]
	TIME [epoch: 24.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.399433912788036		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 3.399433912788036 | validation: 3.1458540519341156]
	TIME [epoch: 24.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3880589999594415		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 3.3880589999594415 | validation: 3.108615040392359]
	TIME [epoch: 24.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3757538483965317		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 3.3757538483965317 | validation: 3.1210872572661312]
	TIME [epoch: 24.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374473806881665		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 3.374473806881665 | validation: 3.112272466233782]
	TIME [epoch: 24.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.372003527012108		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 3.372003527012108 | validation: 3.1160616079677914]
	TIME [epoch: 24.9 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.386885107301888		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 3.386885107301888 | validation: 3.1029875717781232]
	TIME [epoch: 24.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.372525307054383		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 3.372525307054383 | validation: 3.105376159318985]
	TIME [epoch: 24.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.371312109798951		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 3.371312109798951 | validation: 3.1426887083325425]
	TIME [epoch: 24.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.389324750220893		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 3.389324750220893 | validation: 3.104899889076404]
	TIME [epoch: 24.9 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3804749756236756		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 3.3804749756236756 | validation: 3.146820213680464]
	TIME [epoch: 24.9 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3818550141757306		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 3.3818550141757306 | validation: 3.095573966726158]
	TIME [epoch: 24.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39177200941258		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 3.39177200941258 | validation: 3.114497756705847]
	TIME [epoch: 24.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378382410694572		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 3.378382410694572 | validation: 3.162148919417551]
	TIME [epoch: 24.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.423158224940396		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 3.423158224940396 | validation: 3.1211871030198384]
	TIME [epoch: 24.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382310776491531		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 3.382310776491531 | validation: 3.1241343733641087]
	TIME [epoch: 24.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374431429805303		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 3.374431429805303 | validation: 3.1020671857718107]
	TIME [epoch: 24.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3738238711828927		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 3.3738238711828927 | validation: 3.1003048332443597]
	TIME [epoch: 24.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.384117081985256		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 3.384117081985256 | validation: 3.0987201662456454]
	TIME [epoch: 24.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.377472692981334		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 3.377472692981334 | validation: 3.101561209160361]
	TIME [epoch: 25 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4067443605531187		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 3.4067443605531187 | validation: 3.1102278399174557]
	TIME [epoch: 25 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3749001291657743		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 3.3749001291657743 | validation: 3.106515751965943]
	TIME [epoch: 24.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.369105730826267		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 3.369105730826267 | validation: 3.1033588336903084]
	TIME [epoch: 24.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3848802828119586		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 3.3848802828119586 | validation: 3.1371557400624157]
	TIME [epoch: 25 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.41932192247267		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 3.41932192247267 | validation: 3.0944902501683687]
	TIME [epoch: 24.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3846809839318053		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 3.3846809839318053 | validation: 3.119740343052373]
	TIME [epoch: 25 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.369958323282459		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 3.369958323282459 | validation: 3.1018142319487616]
	TIME [epoch: 24.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3842930556454442		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 3.3842930556454442 | validation: 3.10140758868494]
	TIME [epoch: 24.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376059569148912		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 3.376059569148912 | validation: 3.1119546531248337]
	TIME [epoch: 25 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379114895505233		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 3.379114895505233 | validation: 3.0968004117858086]
	TIME [epoch: 25 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3745382903194705		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 3.3745382903194705 | validation: 3.10530832662651]
	TIME [epoch: 24.9 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380355761290779		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 3.380355761290779 | validation: 3.095411024806162]
	TIME [epoch: 25 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3792797748049543		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 3.3792797748049543 | validation: 3.1005732893492506]
	TIME [epoch: 24.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374932309876213		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 3.374932309876213 | validation: 3.127048044401167]
	TIME [epoch: 24.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3846014687077055		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 3.3846014687077055 | validation: 3.117492650103441]
	TIME [epoch: 24.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3782344862717033		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 3.3782344862717033 | validation: 3.105876315972913]
	TIME [epoch: 25 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3929552318211256		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 3.3929552318211256 | validation: 3.117565557338035]
	TIME [epoch: 24.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376199092049635		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 3.376199092049635 | validation: 3.1029410239793207]
	TIME [epoch: 24.9 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3871854908092995		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 3.3871854908092995 | validation: 3.1084820976783134]
	TIME [epoch: 25 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3687262970317944		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 3.3687262970317944 | validation: 3.0992884088386665]
	TIME [epoch: 24.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3709148915744525		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 3.3709148915744525 | validation: 3.1346221814907977]
	TIME [epoch: 24.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3910260195775788		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 3.3910260195775788 | validation: 3.12438425099336]
	TIME [epoch: 25 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.37290189933706		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 3.37290189933706 | validation: 3.1148680772966557]
	TIME [epoch: 24.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.41036123102531		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 3.41036123102531 | validation: 3.1283486741823596]
	TIME [epoch: 24.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3727679123365633		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 3.3727679123365633 | validation: 3.100946210764795]
	TIME [epoch: 24.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.368858104229861		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 3.368858104229861 | validation: 3.10657104680604]
	TIME [epoch: 24.9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378558032358349		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 3.378558032358349 | validation: 3.10860836667178]
	TIME [epoch: 25 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3700161534411768		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 3.3700161534411768 | validation: 3.1274570014497782]
	TIME [epoch: 25 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3783180200328897		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 3.3783180200328897 | validation: 3.1048939763585044]
	TIME [epoch: 24.9 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3697617044488886		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 3.3697617044488886 | validation: 3.097349219943012]
	TIME [epoch: 25 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3701546473088504		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 3.3701546473088504 | validation: 3.1071219288671923]
	TIME [epoch: 24.9 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380747288976118		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 3.380747288976118 | validation: 3.0990251415414014]
	TIME [epoch: 24.9 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3720804212114697		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 3.3720804212114697 | validation: 3.101107065729615]
	TIME [epoch: 24.9 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.371817543836027		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 3.371817543836027 | validation: 3.1125473797213647]
	TIME [epoch: 25 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3739845553134704		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 3.3739845553134704 | validation: 3.1025090921422733]
	TIME [epoch: 24.9 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3688790594086973		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 3.3688790594086973 | validation: 3.1067825669960314]
	TIME [epoch: 25 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3738781612318602		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 3.3738781612318602 | validation: 3.1135494754127415]
	TIME [epoch: 24.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.372227372549074		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 3.372227372549074 | validation: 3.1090737414332352]
	TIME [epoch: 24.9 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3693982919497873		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 3.3693982919497873 | validation: 3.1068115868037354]
	TIME [epoch: 25 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3771040501333403		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 3.3771040501333403 | validation: 3.1055087712805562]
	TIME [epoch: 24.9 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.371929370946516		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 3.371929370946516 | validation: 3.097454052173447]
	TIME [epoch: 24.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.372529200009453		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 3.372529200009453 | validation: 3.1120430303569835]
	TIME [epoch: 24.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3703785179487458		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 3.3703785179487458 | validation: 3.096316054188028]
	TIME [epoch: 24.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3818022726816754		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 3.3818022726816754 | validation: 3.116795940840827]
	TIME [epoch: 24.9 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.375199900374325		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 3.375199900374325 | validation: 3.126095474752383]
	TIME [epoch: 24.9 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.384107415420882		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 3.384107415420882 | validation: 3.14052718093968]
	TIME [epoch: 25 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3822135392561856		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 3.3822135392561856 | validation: 3.100245070525216]
	TIME [epoch: 24.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3817712325648284		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 3.3817712325648284 | validation: 3.111139232621856]
	TIME [epoch: 24.9 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380650798543263		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 3.380650798543263 | validation: 3.0863498978213624]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_1181.pth
	Model improved!!!
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3703257460526554		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 3.3703257460526554 | validation: 3.1087551075836144]
	TIME [epoch: 25 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3755320702227776		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 3.3755320702227776 | validation: 3.116835034721423]
	TIME [epoch: 24.9 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3744781902569922		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 3.3744781902569922 | validation: 3.0967724298717054]
	TIME [epoch: 25 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.377034260762762		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 3.377034260762762 | validation: 3.100345181626456]
	TIME [epoch: 24.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.366717832262948		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 3.366717832262948 | validation: 3.1069109115340257]
	TIME [epoch: 24.9 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376464089205515		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 3.376464089205515 | validation: 3.1039613831908697]
	TIME [epoch: 24.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3790260483963097		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 3.3790260483963097 | validation: 3.1001075394328064]
	TIME [epoch: 24.9 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3741515247389273		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 3.3741515247389273 | validation: 3.1172163052072626]
	TIME [epoch: 24.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3782315611835756		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 3.3782315611835756 | validation: 3.0974287701220558]
	TIME [epoch: 25 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.385648643205472		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 3.385648643205472 | validation: 3.1405184186745636]
	TIME [epoch: 24.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3914872456602163		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 3.3914872456602163 | validation: 3.096979873774635]
	TIME [epoch: 25 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.370200057541869		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 3.370200057541869 | validation: 3.11932853743458]
	TIME [epoch: 25 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39424366120546		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 3.39424366120546 | validation: 3.107812887495027]
	TIME [epoch: 24.9 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.375562927111662		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 3.375562927111662 | validation: 3.090020378003859]
	TIME [epoch: 25 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.368948918680114		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 3.368948918680114 | validation: 3.097545439152341]
	TIME [epoch: 24.9 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3755013023134035		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 3.3755013023134035 | validation: 3.104288256503526]
	TIME [epoch: 24.9 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.366625363733804		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 3.366625363733804 | validation: 3.104297149570755]
	TIME [epoch: 24.9 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3781908225871127		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 3.3781908225871127 | validation: 3.0972028731501577]
	TIME [epoch: 24.9 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3701054820200613		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 3.3701054820200613 | validation: 3.1143962555323514]
	TIME [epoch: 24.9 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3741354566434487		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 3.3741354566434487 | validation: 3.09839629501172]
	TIME [epoch: 24.9 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374497509674795		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 3.374497509674795 | validation: 3.116607324543453]
	TIME [epoch: 24.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379305147101488		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 3.379305147101488 | validation: 3.1090223109950457]
	TIME [epoch: 25 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379968439360662		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 3.379968439360662 | validation: 3.1246728775984427]
	TIME [epoch: 24.9 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.403916282006996		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 3.403916282006996 | validation: 3.1018587967441715]
	TIME [epoch: 24.9 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3687442003304118		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 3.3687442003304118 | validation: 3.1037194558573136]
	TIME [epoch: 24.9 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3706716867010633		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 3.3706716867010633 | validation: 3.1176898076183]
	TIME [epoch: 24.9 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.370795720024317		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 3.370795720024317 | validation: 3.1001353520069608]
	TIME [epoch: 25 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.375727122477367		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 3.375727122477367 | validation: 3.114120511140969]
	TIME [epoch: 25 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.383294487234385		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 3.383294487234385 | validation: 3.1007031086225094]
	TIME [epoch: 24.9 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374039700235569		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 3.374039700235569 | validation: 3.109878892412636]
	TIME [epoch: 24.9 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.38048951200019		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 3.38048951200019 | validation: 3.128830270347572]
	TIME [epoch: 24.9 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3957694255241653		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 3.3957694255241653 | validation: 3.122407798979702]
	TIME [epoch: 24.9 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3785313762695415		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 3.3785313762695415 | validation: 3.098423032698162]
	TIME [epoch: 24.9 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3667192649500506		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 3.3667192649500506 | validation: 3.0997838892603604]
	TIME [epoch: 25 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.387733274075424		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 3.387733274075424 | validation: 3.096292628332078]
	TIME [epoch: 24.9 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373616795916162		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 3.373616795916162 | validation: 3.1005732283375598]
	TIME [epoch: 25 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.369952581556686		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 3.369952581556686 | validation: 3.099970276616927]
	TIME [epoch: 24.9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373419440287628		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 3.373419440287628 | validation: 3.103711206407753]
	TIME [epoch: 25 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3805063812923577		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 3.3805063812923577 | validation: 3.1204440158584124]
	TIME [epoch: 24.9 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3775575320885833		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 3.3775575320885833 | validation: 3.0989944656387802]
	TIME [epoch: 24.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3765736805111133		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 3.3765736805111133 | validation: 3.0960342510990753]
	TIME [epoch: 24.9 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3760151675507593		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 3.3760151675507593 | validation: 3.0933765711545926]
	TIME [epoch: 25 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.37199779198473		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 3.37199779198473 | validation: 3.096201475236328]
	TIME [epoch: 24.9 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3688667258171257		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 3.3688667258171257 | validation: 3.105466028714358]
	TIME [epoch: 24.9 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378307511022272		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 3.378307511022272 | validation: 3.1071741020760317]
	TIME [epoch: 24.9 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380663524674863		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 3.380663524674863 | validation: 3.103231323168216]
	TIME [epoch: 24.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3743037474328528		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 3.3743037474328528 | validation: 3.1056824239063294]
	TIME [epoch: 24.9 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3733172883405684		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 3.3733172883405684 | validation: 3.106031325889756]
	TIME [epoch: 24.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3844438813491586		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 3.3844438813491586 | validation: 3.0974975540377256]
	TIME [epoch: 24.9 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.371628232667409		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 3.371628232667409 | validation: 3.1017941884420317]
	TIME [epoch: 25 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3712493410838595		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 3.3712493410838595 | validation: 3.1247858000594375]
	TIME [epoch: 24.9 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.385879029999334		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 3.385879029999334 | validation: 3.1133018453399774]
	TIME [epoch: 24.9 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3915128258093112		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 3.3915128258093112 | validation: 3.141517085440517]
	TIME [epoch: 24.9 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382883482108068		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 3.382883482108068 | validation: 3.0997467619986385]
	TIME [epoch: 24.9 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3697750777993507		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 3.3697750777993507 | validation: 3.1083802251148724]
	TIME [epoch: 24.9 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3712126188364206		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 3.3712126188364206 | validation: 3.0971730329533544]
	TIME [epoch: 24.9 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3716720060276977		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 3.3716720060276977 | validation: 3.0962685187404304]
	TIME [epoch: 24.9 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.372558299970235		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 3.372558299970235 | validation: 3.131493094114223]
	TIME [epoch: 25 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3864096263094248		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 3.3864096263094248 | validation: 3.1016006484567598]
	TIME [epoch: 24.9 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3735894551966856		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 3.3735894551966856 | validation: 3.100096655019198]
	TIME [epoch: 25 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3754108357365533		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 3.3754108357365533 | validation: 3.0954059229769233]
	TIME [epoch: 25 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380432806759159		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 3.380432806759159 | validation: 3.123809445996777]
	TIME [epoch: 24.9 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374039280207485		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 3.374039280207485 | validation: 3.091090508220095]
	TIME [epoch: 25 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374117309298982		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 3.374117309298982 | validation: 3.090742938858104]
	TIME [epoch: 25 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.372425613282525		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 3.372425613282525 | validation: 3.105087769516883]
	TIME [epoch: 24.9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3757698105120797		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 3.3757698105120797 | validation: 3.0904238570061704]
	TIME [epoch: 25 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.370377647152843		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 3.370377647152843 | validation: 3.105910306031202]
	TIME [epoch: 24.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.370353188533832		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 3.370353188533832 | validation: 3.097853724107143]
	TIME [epoch: 24.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.370397649893203		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 3.370397649893203 | validation: 3.1095371196700503]
	TIME [epoch: 24.9 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.375314192149609		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 3.375314192149609 | validation: 3.1157430219396454]
	TIME [epoch: 25 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3738552022160837		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 3.3738552022160837 | validation: 3.1032035502085145]
	TIME [epoch: 24.9 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3688987983559233		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 3.3688987983559233 | validation: 3.1037955357124676]
	TIME [epoch: 25 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3817713844232102		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 3.3817713844232102 | validation: 3.1319137682213474]
	TIME [epoch: 24.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376586978834848		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 3.376586978834848 | validation: 3.1027552367366513]
	TIME [epoch: 24.9 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.388224876617092		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 3.388224876617092 | validation: 3.1013172238931594]
	TIME [epoch: 25 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373981229759116		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 3.373981229759116 | validation: 3.1195256489046774]
	TIME [epoch: 24.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3723691663855906		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 3.3723691663855906 | validation: 3.093859166816632]
	TIME [epoch: 24.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3787326084760974		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 3.3787326084760974 | validation: 3.1213578829065445]
	TIME [epoch: 25 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3912308311803327		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 3.3912308311803327 | validation: 3.1102173124782726]
	TIME [epoch: 24.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.368647315939731		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 3.368647315939731 | validation: 3.09207760254961]
	TIME [epoch: 24.9 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.383448914829967		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 3.383448914829967 | validation: 3.1073610259630824]
	TIME [epoch: 24.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.369773360482806		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 3.369773360482806 | validation: 3.0972347236194926]
	TIME [epoch: 25 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373056181720978		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 3.373056181720978 | validation: 3.1021499736880807]
	TIME [epoch: 24.9 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.368203565124003		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 3.368203565124003 | validation: 3.0971700106147875]
	TIME [epoch: 25 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.367377686224719		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 3.367377686224719 | validation: 3.103603236422566]
	TIME [epoch: 24.9 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3690542599228044		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 3.3690542599228044 | validation: 3.1077845234578536]
	TIME [epoch: 24.9 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3719421820817237		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 3.3719421820817237 | validation: 3.1128999737222856]
	TIME [epoch: 24.9 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3722857712212955		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 3.3722857712212955 | validation: 3.102658359585002]
	TIME [epoch: 25 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.384717273063455		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 3.384717273063455 | validation: 3.112081694908403]
	TIME [epoch: 24.9 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374161550459185		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 3.374161550459185 | validation: 3.104381270916332]
	TIME [epoch: 25 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.372972957779153		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 3.372972957779153 | validation: 3.1081451043998016]
	TIME [epoch: 24.9 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3804054135450814		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 3.3804054135450814 | validation: 3.0909454983885194]
	TIME [epoch: 24.9 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3707759912978235		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 3.3707759912978235 | validation: 3.105937533565691]
	TIME [epoch: 24.9 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3773820810382196		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 3.3773820810382196 | validation: 3.0974340744350535]
	TIME [epoch: 25 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373751175270078		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 3.373751175270078 | validation: 3.102133806280507]
	TIME [epoch: 24.9 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3751490151468726		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 3.3751490151468726 | validation: 3.13724758453726]
	TIME [epoch: 25 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3807807492587827		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 3.3807807492587827 | validation: 3.0993590833908025]
	TIME [epoch: 25 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3687477888303308		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 3.3687477888303308 | validation: 3.095825876568282]
	TIME [epoch: 24.9 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3729452306905836		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 3.3729452306905836 | validation: 3.1038377986877426]
	TIME [epoch: 24.9 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3823420708319047		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 3.3823420708319047 | validation: 3.138769445632223]
	TIME [epoch: 25 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3863560496588443		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 3.3863560496588443 | validation: 3.106954034537714]
	TIME [epoch: 24.9 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3708263097140554		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 3.3708263097140554 | validation: 3.0959676931330473]
	TIME [epoch: 25 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3704533645794252		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 3.3704533645794252 | validation: 3.106436320103612]
	TIME [epoch: 25 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3975277066579235		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 3.3975277066579235 | validation: 3.1083816644292916]
	TIME [epoch: 24.9 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3829894592618666		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 3.3829894592618666 | validation: 3.090740240950116]
	TIME [epoch: 24.9 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3744532847936464		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 3.3744532847936464 | validation: 3.094346006040438]
	TIME [epoch: 25 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3656808129943374		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 3.3656808129943374 | validation: 3.10106126842872]
	TIME [epoch: 24.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.370584411504793		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 3.370584411504793 | validation: 3.0948730913982225]
	TIME [epoch: 25 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3705472374137924		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 3.3705472374137924 | validation: 3.11080068737258]
	TIME [epoch: 24.9 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3848057452787366		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 3.3848057452787366 | validation: 3.100890579302296]
	TIME [epoch: 24.9 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379285870706356		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 3.379285870706356 | validation: 3.098524108084183]
	TIME [epoch: 24.9 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3657256022219273		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 3.3657256022219273 | validation: 3.09036563068867]
	TIME [epoch: 25 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3729210091846387		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 3.3729210091846387 | validation: 3.1050418079928046]
	TIME [epoch: 24.9 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3789015098127626		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 3.3789015098127626 | validation: 3.0853435452470843]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r4_20240310_051930/states/model_tr_study205_1295.pth
	Model improved!!!
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.364460036003802		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 3.364460036003802 | validation: 3.0942095201799056]
	TIME [epoch: 24.9 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3714669983726906		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 3.3714669983726906 | validation: 3.096061815891581]
	TIME [epoch: 24.9 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3845319599275356		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 3.3845319599275356 | validation: 3.112212762654476]
	TIME [epoch: 25 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.377935596355613		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 3.377935596355613 | validation: 3.0965512915846465]
	TIME [epoch: 24.9 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.366706449287401		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 3.366706449287401 | validation: 3.0941243771073834]
	TIME [epoch: 24.9 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.363508861684758		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 3.363508861684758 | validation: 3.1050599571961075]
	TIME [epoch: 24.9 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3741485484199134		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 3.3741485484199134 | validation: 3.111279538901182]
	TIME [epoch: 24.9 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.383207474455748		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 3.383207474455748 | validation: 3.102006898815696]
	TIME [epoch: 24.9 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3977426767374714		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 3.3977426767374714 | validation: 3.1262831900874866]
	TIME [epoch: 25.2 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3773028438170867		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 3.3773028438170867 | validation: 3.099999349734327]
	TIME [epoch: 24.9 sec]
EPOCH 1306/2000:
	Training over batches...
